[19:28:54.051] Namespace(root_path='D:\\data\\Synapse\\train_npz', dataset='Synapse', list_dir='./lists/lists_Synapse', num_classes=9, output_dir='D:\\data\\output', max_iterations=30000, max_epochs=150, batch_size=24, n_gpu=1, deterministic=1, base_lr=0.05, img_size=224, seed=1234, cfg='configs/swin_tiny_patch4_window7_224_lite.yaml', opts=None, zip=False, cache_mode='part', resume=None, accumulation_steps=None, use_checkpoint=False, amp_opt_level='O1', tag=None, eval=False, throughput=False)
[19:28:54.057] 93 iterations per epoch. 13950 max iterations 
[19:29:59.722] Namespace(root_path='D:\\data\\Synapse\\train_npz', dataset='Synapse', list_dir='./lists/lists_Synapse', num_classes=9, output_dir='D:\\data\\output', max_iterations=30000, max_epochs=150, batch_size=24, n_gpu=1, deterministic=1, base_lr=0.05, img_size=224, seed=1234, cfg='configs/swin_tiny_patch4_window7_224_lite.yaml', opts=None, zip=False, cache_mode='part', resume=None, accumulation_steps=None, use_checkpoint=False, amp_opt_level='O1', tag=None, eval=False, throughput=False)
[19:29:59.729] 93 iterations per epoch. 13950 max iterations 
[19:31:12.659] Namespace(root_path='D:\\data\\Synapse\\train_npz', dataset='Synapse', list_dir='./lists/lists_Synapse', num_classes=9, output_dir='D:\\data\\output', max_iterations=30000, max_epochs=150, batch_size=12, n_gpu=1, deterministic=1, base_lr=0.025, img_size=224, seed=1234, cfg='configs/swin_tiny_patch4_window7_224_lite.yaml', opts=None, zip=False, cache_mode='part', resume=None, accumulation_steps=None, use_checkpoint=False, amp_opt_level='O1', tag=None, eval=False, throughput=False)
[19:31:12.673] 185 iterations per epoch. 27750 max iterations 
[19:31:36.538] iteration 1 : loss : 1.463476, loss_ce: 2.229445
[19:31:36.773] iteration 2 : loss : 1.235244, loss_ce: 1.731322
[19:31:36.992] iteration 3 : loss : 0.938332, loss_ce: 1.016040
[19:31:37.216] iteration 4 : loss : 0.714875, loss_ce: 0.478214
[19:31:37.441] iteration 5 : loss : 0.697836, loss_ce: 0.440765
[19:31:37.659] iteration 6 : loss : 0.608418, loss_ce: 0.203202
[19:31:37.893] iteration 7 : loss : 0.635128, loss_ce: 0.260561
[19:31:38.112] iteration 8 : loss : 0.632696, loss_ce: 0.250717
[19:31:38.331] iteration 9 : loss : 0.692091, loss_ce: 0.395668
[19:31:38.552] iteration 10 : loss : 0.707794, loss_ce: 0.433720
[19:31:38.786] iteration 11 : loss : 0.743036, loss_ce: 0.520332
[19:31:38.998] iteration 12 : loss : 0.661337, loss_ce: 0.318558
[19:31:39.217] iteration 13 : loss : 0.677520, loss_ce: 0.357716
[19:31:39.446] iteration 14 : loss : 0.671833, loss_ce: 0.344586
[19:31:39.665] iteration 15 : loss : 0.627954, loss_ce: 0.237146
[19:31:39.884] iteration 16 : loss : 0.657751, loss_ce: 0.311643
[19:31:40.118] iteration 17 : loss : 0.587888, loss_ce: 0.140727
[19:31:40.332] iteration 18 : loss : 0.621600, loss_ce: 0.227572
[19:31:40.562] iteration 19 : loss : 0.653971, loss_ce: 0.313982
[19:31:40.773] iteration 20 : loss : 0.604769, loss_ce: 0.201004
[19:31:41.043] iteration 21 : loss : 0.653062, loss_ce: 0.333345
[19:31:41.254] iteration 22 : loss : 0.603557, loss_ce: 0.215484
[19:31:41.476] iteration 23 : loss : 0.596164, loss_ce: 0.195313
[19:31:41.696] iteration 24 : loss : 0.604994, loss_ce: 0.220674
[19:31:41.916] iteration 25 : loss : 0.648105, loss_ce: 0.314853
[19:31:42.136] iteration 26 : loss : 0.606905, loss_ce: 0.231739
[19:31:42.358] iteration 27 : loss : 0.616418, loss_ce: 0.316233
[19:31:42.578] iteration 28 : loss : 0.604218, loss_ce: 0.315487
[19:31:42.799] iteration 29 : loss : 0.583239, loss_ce: 0.168308
[19:31:43.019] iteration 30 : loss : 0.656756, loss_ce: 0.340317
[19:31:43.240] iteration 31 : loss : 0.581623, loss_ce: 0.186983
[19:31:43.461] iteration 32 : loss : 0.581952, loss_ce: 0.209496
[19:31:43.681] iteration 33 : loss : 0.608750, loss_ce: 0.306644
[19:31:43.901] iteration 34 : loss : 0.579367, loss_ce: 0.228236
[19:31:44.122] iteration 35 : loss : 0.598590, loss_ce: 0.257453
[19:31:44.342] iteration 36 : loss : 0.584750, loss_ce: 0.217546
[19:31:44.568] iteration 37 : loss : 0.580460, loss_ce: 0.226120
[19:31:44.788] iteration 38 : loss : 0.583822, loss_ce: 0.236792
[19:31:45.007] iteration 39 : loss : 0.579484, loss_ce: 0.215056
[19:31:45.227] iteration 40 : loss : 0.576874, loss_ce: 0.181295
[19:31:45.468] iteration 41 : loss : 0.577039, loss_ce: 0.176664
[19:31:45.688] iteration 42 : loss : 0.568922, loss_ce: 0.107896
[19:31:45.908] iteration 43 : loss : 0.608222, loss_ce: 0.232165
[19:31:46.129] iteration 44 : loss : 0.595870, loss_ce: 0.218557
[19:31:46.349] iteration 45 : loss : 0.557257, loss_ce: 0.147196
[19:31:46.569] iteration 46 : loss : 0.560655, loss_ce: 0.197598
[19:31:46.789] iteration 47 : loss : 0.597285, loss_ce: 0.328121
[19:31:47.010] iteration 48 : loss : 0.590700, loss_ce: 0.295651
[19:31:47.220] iteration 49 : loss : 0.581736, loss_ce: 0.241776
[19:31:47.447] iteration 50 : loss : 0.593860, loss_ce: 0.259563
[19:31:47.667] iteration 51 : loss : 0.581464, loss_ce: 0.212008
[19:31:47.893] iteration 52 : loss : 0.561076, loss_ce: 0.120231
[19:31:48.123] iteration 53 : loss : 0.578025, loss_ce: 0.199808
[19:31:48.354] iteration 54 : loss : 0.600875, loss_ce: 0.299195
[19:31:48.577] iteration 55 : loss : 0.591614, loss_ce: 0.259396
[19:31:48.807] iteration 56 : loss : 0.562327, loss_ce: 0.197268
[19:31:49.035] iteration 57 : loss : 0.569664, loss_ce: 0.225587
[19:31:49.253] iteration 58 : loss : 0.565672, loss_ce: 0.193864
[19:31:49.483] iteration 59 : loss : 0.562340, loss_ce: 0.109349
[19:31:49.704] iteration 60 : loss : 0.574695, loss_ce: 0.170742
[19:31:49.944] iteration 61 : loss : 0.549091, loss_ce: 0.067998
[19:31:50.164] iteration 62 : loss : 0.563308, loss_ce: 0.113507
[19:31:50.386] iteration 63 : loss : 0.567896, loss_ce: 0.136548
[19:31:50.619] iteration 64 : loss : 0.574926, loss_ce: 0.194432
[19:31:50.839] iteration 65 : loss : 0.557370, loss_ce: 0.174522
[19:31:51.069] iteration 66 : loss : 0.567269, loss_ce: 0.219633
[19:31:51.288] iteration 67 : loss : 0.596278, loss_ce: 0.298084
[19:31:51.508] iteration 68 : loss : 0.565893, loss_ce: 0.223860
[19:31:51.728] iteration 69 : loss : 0.567863, loss_ce: 0.191186
[19:31:51.954] iteration 70 : loss : 0.552472, loss_ce: 0.157283
[19:31:52.178] iteration 71 : loss : 0.580563, loss_ce: 0.178865
[19:31:52.403] iteration 72 : loss : 0.571726, loss_ce: 0.148181
[19:31:52.643] iteration 73 : loss : 0.568950, loss_ce: 0.155586
[19:31:52.890] iteration 74 : loss : 0.555032, loss_ce: 0.118672
[19:31:53.121] iteration 75 : loss : 0.554214, loss_ce: 0.185603
[19:31:53.346] iteration 76 : loss : 0.558801, loss_ce: 0.143776
[19:31:53.572] iteration 77 : loss : 0.560627, loss_ce: 0.137644
[19:31:53.793] iteration 78 : loss : 0.533881, loss_ce: 0.102118
[19:31:54.018] iteration 79 : loss : 0.553954, loss_ce: 0.147445
[19:31:54.238] iteration 80 : loss : 0.574645, loss_ce: 0.188809
[19:31:54.482] iteration 81 : loss : 0.581357, loss_ce: 0.189258
[19:31:54.704] iteration 82 : loss : 0.576092, loss_ce: 0.183794
[19:31:54.926] iteration 83 : loss : 0.554329, loss_ce: 0.165060
[19:31:55.148] iteration 84 : loss : 0.602184, loss_ce: 0.294073
[19:31:55.369] iteration 85 : loss : 0.568788, loss_ce: 0.209002
[19:31:55.598] iteration 86 : loss : 0.573250, loss_ce: 0.142795
[19:31:55.817] iteration 87 : loss : 0.559488, loss_ce: 0.175031
[19:31:56.039] iteration 88 : loss : 0.571577, loss_ce: 0.164177
[19:31:56.260] iteration 89 : loss : 0.572321, loss_ce: 0.172859
[19:31:56.483] iteration 90 : loss : 0.550931, loss_ce: 0.099565
[19:31:56.713] iteration 91 : loss : 0.557500, loss_ce: 0.129306
[19:31:56.935] iteration 92 : loss : 0.581653, loss_ce: 0.226745
[19:31:57.157] iteration 93 : loss : 0.539821, loss_ce: 0.135263
[19:31:57.389] iteration 94 : loss : 0.543788, loss_ce: 0.149485
[19:31:57.616] iteration 95 : loss : 0.545618, loss_ce: 0.197588
[19:31:57.848] iteration 96 : loss : 0.559629, loss_ce: 0.210370
[19:31:58.083] iteration 97 : loss : 0.588126, loss_ce: 0.270572
[19:31:58.307] iteration 98 : loss : 0.546036, loss_ce: 0.150922
[19:31:58.529] iteration 99 : loss : 0.560133, loss_ce: 0.145491
[19:31:58.751] iteration 100 : loss : 0.558865, loss_ce: 0.163017
[19:31:58.994] iteration 101 : loss : 0.543106, loss_ce: 0.182602
[19:31:59.218] iteration 102 : loss : 0.532589, loss_ce: 0.138790
[19:31:59.430] iteration 103 : loss : 0.553762, loss_ce: 0.129550
[19:31:59.652] iteration 104 : loss : 0.537306, loss_ce: 0.140045
[19:31:59.873] iteration 105 : loss : 0.567530, loss_ce: 0.157206
[19:32:00.096] iteration 106 : loss : 0.530568, loss_ce: 0.113379
[19:32:00.317] iteration 107 : loss : 0.531083, loss_ce: 0.096310
[19:32:00.538] iteration 108 : loss : 0.524521, loss_ce: 0.107532
[19:32:00.761] iteration 109 : loss : 0.556920, loss_ce: 0.190425
[19:32:00.984] iteration 110 : loss : 0.541595, loss_ce: 0.175593
[19:32:01.217] iteration 111 : loss : 0.549801, loss_ce: 0.189215
[19:32:01.437] iteration 112 : loss : 0.537865, loss_ce: 0.194352
[19:32:01.659] iteration 113 : loss : 0.546489, loss_ce: 0.189227
[19:32:01.882] iteration 114 : loss : 0.536161, loss_ce: 0.110275
[19:32:02.103] iteration 115 : loss : 0.572566, loss_ce: 0.229129
[19:32:02.324] iteration 116 : loss : 0.547622, loss_ce: 0.107927
[19:32:02.544] iteration 117 : loss : 0.541967, loss_ce: 0.141915
[19:32:02.767] iteration 118 : loss : 0.521589, loss_ce: 0.106174
[19:32:02.990] iteration 119 : loss : 0.551194, loss_ce: 0.218220
[19:32:03.204] iteration 120 : loss : 0.518687, loss_ce: 0.123009
[19:32:03.454] iteration 121 : loss : 0.542534, loss_ce: 0.192605
[19:32:03.674] iteration 122 : loss : 0.574534, loss_ce: 0.251428
[19:32:03.891] iteration 123 : loss : 0.513747, loss_ce: 0.109631
[19:32:04.119] iteration 124 : loss : 0.527486, loss_ce: 0.109463
[19:32:04.330] iteration 125 : loss : 0.527137, loss_ce: 0.110253
[19:32:04.553] iteration 126 : loss : 0.517485, loss_ce: 0.113006
[19:32:04.780] iteration 127 : loss : 0.505525, loss_ce: 0.101775
[19:32:04.996] iteration 128 : loss : 0.514092, loss_ce: 0.131957
[19:32:05.217] iteration 129 : loss : 0.494483, loss_ce: 0.104140
[19:32:05.437] iteration 130 : loss : 0.531719, loss_ce: 0.110981
[19:32:05.665] iteration 131 : loss : 0.581956, loss_ce: 0.192369
[19:32:05.880] iteration 132 : loss : 0.520677, loss_ce: 0.138255
[19:32:06.101] iteration 133 : loss : 0.554201, loss_ce: 0.249538
[19:32:06.325] iteration 134 : loss : 0.565352, loss_ce: 0.267523
[19:32:06.546] iteration 135 : loss : 0.550933, loss_ce: 0.229009
[19:32:06.768] iteration 136 : loss : 0.554193, loss_ce: 0.182742
[19:32:06.990] iteration 137 : loss : 0.540847, loss_ce: 0.144832
[19:32:07.209] iteration 138 : loss : 0.542761, loss_ce: 0.135256
[19:32:07.431] iteration 139 : loss : 0.544048, loss_ce: 0.157338
[19:32:07.650] iteration 140 : loss : 0.549222, loss_ce: 0.176029
[19:32:07.894] iteration 141 : loss : 0.553691, loss_ce: 0.245867
[19:32:08.121] iteration 142 : loss : 0.563704, loss_ce: 0.226281
[19:32:08.341] iteration 143 : loss : 0.535369, loss_ce: 0.167120
[19:32:08.561] iteration 144 : loss : 0.538516, loss_ce: 0.156180
[19:32:08.789] iteration 145 : loss : 0.512695, loss_ce: 0.094593
[19:32:09.011] iteration 146 : loss : 0.553792, loss_ce: 0.118492
[19:32:09.235] iteration 147 : loss : 0.561733, loss_ce: 0.197734
[19:32:09.454] iteration 148 : loss : 0.515331, loss_ce: 0.154936
[19:32:09.674] iteration 149 : loss : 0.555908, loss_ce: 0.230917
[19:32:09.895] iteration 150 : loss : 0.535053, loss_ce: 0.181589
[19:32:10.124] iteration 151 : loss : 0.517777, loss_ce: 0.102879
[19:32:10.351] iteration 152 : loss : 0.555254, loss_ce: 0.154058
[19:32:10.563] iteration 153 : loss : 0.526060, loss_ce: 0.155656
[19:32:10.793] iteration 154 : loss : 0.499280, loss_ce: 0.093601
[19:32:11.015] iteration 155 : loss : 0.515782, loss_ce: 0.142261
[19:32:11.235] iteration 156 : loss : 0.525401, loss_ce: 0.193884
[19:32:11.458] iteration 157 : loss : 0.529715, loss_ce: 0.151734
[19:32:11.671] iteration 158 : loss : 0.492473, loss_ce: 0.085283
[19:32:11.895] iteration 159 : loss : 0.512594, loss_ce: 0.163766
[19:32:12.119] iteration 160 : loss : 0.512604, loss_ce: 0.133334
[19:32:12.360] iteration 161 : loss : 0.491256, loss_ce: 0.087070
[19:32:12.577] iteration 162 : loss : 0.505713, loss_ce: 0.135947
[19:32:12.799] iteration 163 : loss : 0.506257, loss_ce: 0.160387
[19:32:13.017] iteration 164 : loss : 0.547117, loss_ce: 0.226977
[19:32:13.242] iteration 165 : loss : 0.508348, loss_ce: 0.137281
[19:32:13.464] iteration 166 : loss : 0.523084, loss_ce: 0.138090
[19:32:13.686] iteration 167 : loss : 0.538060, loss_ce: 0.219322
[19:32:13.906] iteration 168 : loss : 0.509001, loss_ce: 0.159748
[19:32:14.125] iteration 169 : loss : 0.509126, loss_ce: 0.131449
[19:32:14.357] iteration 170 : loss : 0.551140, loss_ce: 0.268994
[19:32:14.583] iteration 171 : loss : 0.527089, loss_ce: 0.127612
[19:32:14.803] iteration 172 : loss : 0.506565, loss_ce: 0.158222
[19:32:15.038] iteration 173 : loss : 0.493805, loss_ce: 0.102814
[19:32:15.262] iteration 174 : loss : 0.519386, loss_ce: 0.156308
[19:32:15.484] iteration 175 : loss : 0.547174, loss_ce: 0.245027
[19:32:15.708] iteration 176 : loss : 0.516916, loss_ce: 0.154035
[19:32:15.932] iteration 177 : loss : 0.501189, loss_ce: 0.113490
[19:32:16.154] iteration 178 : loss : 0.505525, loss_ce: 0.120685
[19:32:16.379] iteration 179 : loss : 0.509160, loss_ce: 0.088533
[19:32:16.604] iteration 180 : loss : 0.525663, loss_ce: 0.095964
[19:32:16.871] iteration 181 : loss : 0.517886, loss_ce: 0.196795
[19:32:17.091] iteration 182 : loss : 0.516251, loss_ce: 0.190566
[19:32:17.316] iteration 183 : loss : 0.520496, loss_ce: 0.154515
[19:32:17.538] iteration 184 : loss : 0.511746, loss_ce: 0.155478
[19:32:17.634] iteration 185 : loss : 0.490378, loss_ce: 0.131956
[19:32:34.511] iteration 186 : loss : 0.535743, loss_ce: 0.185232
[19:32:34.731] iteration 187 : loss : 0.527876, loss_ce: 0.167923
[19:32:34.950] iteration 188 : loss : 0.540271, loss_ce: 0.201945
[19:32:35.169] iteration 189 : loss : 0.488645, loss_ce: 0.110951
[19:32:35.388] iteration 190 : loss : 0.527857, loss_ce: 0.174649
[19:32:35.607] iteration 191 : loss : 0.510436, loss_ce: 0.180967
[19:32:35.843] iteration 192 : loss : 0.510280, loss_ce: 0.111129
[19:32:36.057] iteration 193 : loss : 0.499224, loss_ce: 0.130140
[19:32:36.288] iteration 194 : loss : 0.538336, loss_ce: 0.197543
[19:32:36.508] iteration 195 : loss : 0.474405, loss_ce: 0.063332
[19:32:36.731] iteration 196 : loss : 0.481427, loss_ce: 0.107503
[19:32:36.952] iteration 197 : loss : 0.545767, loss_ce: 0.258406
[19:32:37.178] iteration 198 : loss : 0.516739, loss_ce: 0.177526
[19:32:37.398] iteration 199 : loss : 0.501783, loss_ce: 0.144170
[19:32:37.620] iteration 200 : loss : 0.537446, loss_ce: 0.159828
[19:32:37.856] iteration 201 : loss : 0.504829, loss_ce: 0.110778
[19:32:38.083] iteration 202 : loss : 0.514219, loss_ce: 0.096647
[19:32:38.300] iteration 203 : loss : 0.520458, loss_ce: 0.190883
[19:32:38.528] iteration 204 : loss : 0.501216, loss_ce: 0.136898
[19:32:38.748] iteration 205 : loss : 0.494568, loss_ce: 0.147296
[19:32:38.972] iteration 206 : loss : 0.523250, loss_ce: 0.216612
[19:32:39.197] iteration 207 : loss : 0.517559, loss_ce: 0.218680
[19:32:39.416] iteration 208 : loss : 0.513005, loss_ce: 0.191409
[19:32:39.646] iteration 209 : loss : 0.497444, loss_ce: 0.090988
[19:32:39.865] iteration 210 : loss : 0.496209, loss_ce: 0.128971
[19:32:40.092] iteration 211 : loss : 0.531214, loss_ce: 0.114901
[19:32:40.315] iteration 212 : loss : 0.494188, loss_ce: 0.109705
[19:32:40.535] iteration 213 : loss : 0.486767, loss_ce: 0.146845
[19:32:40.755] iteration 214 : loss : 0.487650, loss_ce: 0.142983
[19:32:40.985] iteration 215 : loss : 0.481470, loss_ce: 0.103506
[19:32:41.205] iteration 216 : loss : 0.521589, loss_ce: 0.173040
[19:32:41.426] iteration 217 : loss : 0.507310, loss_ce: 0.098938
[19:32:41.652] iteration 218 : loss : 0.479027, loss_ce: 0.118307
[19:32:41.878] iteration 219 : loss : 0.488943, loss_ce: 0.144898
[19:32:42.099] iteration 220 : loss : 0.483421, loss_ce: 0.113481
[19:32:42.346] iteration 221 : loss : 0.483074, loss_ce: 0.114786
[19:32:42.565] iteration 222 : loss : 0.467893, loss_ce: 0.114032
[19:32:42.785] iteration 223 : loss : 0.465611, loss_ce: 0.065853
[19:32:43.015] iteration 224 : loss : 0.537432, loss_ce: 0.123234
[19:32:43.240] iteration 225 : loss : 0.514512, loss_ce: 0.200550
[19:32:43.458] iteration 226 : loss : 0.562119, loss_ce: 0.329943
[19:32:43.686] iteration 227 : loss : 0.490500, loss_ce: 0.176004
[19:32:43.916] iteration 228 : loss : 0.513418, loss_ce: 0.209570
[19:32:44.144] iteration 229 : loss : 0.495299, loss_ce: 0.127014
[19:32:44.364] iteration 230 : loss : 0.522594, loss_ce: 0.219653
[19:32:44.584] iteration 231 : loss : 0.498859, loss_ce: 0.184140
[19:32:44.804] iteration 232 : loss : 0.490097, loss_ce: 0.172460
[19:32:45.025] iteration 233 : loss : 0.464916, loss_ce: 0.094798
[19:32:45.255] iteration 234 : loss : 0.500099, loss_ce: 0.167698
[19:32:45.475] iteration 235 : loss : 0.487970, loss_ce: 0.128568
[19:32:45.694] iteration 236 : loss : 0.499809, loss_ce: 0.173553
[19:32:45.914] iteration 237 : loss : 0.495360, loss_ce: 0.144507
[19:32:46.135] iteration 238 : loss : 0.505133, loss_ce: 0.187720
[19:32:46.355] iteration 239 : loss : 0.498272, loss_ce: 0.169164
[19:32:46.575] iteration 240 : loss : 0.490346, loss_ce: 0.171422
[19:32:46.816] iteration 241 : loss : 0.499876, loss_ce: 0.144059
[19:32:47.046] iteration 242 : loss : 0.478308, loss_ce: 0.086297
[19:32:47.267] iteration 243 : loss : 0.471933, loss_ce: 0.086648
[19:32:47.487] iteration 244 : loss : 0.533141, loss_ce: 0.186276
[19:32:47.707] iteration 245 : loss : 0.489569, loss_ce: 0.143438
[19:32:47.927] iteration 246 : loss : 0.489508, loss_ce: 0.146823
[19:32:48.156] iteration 247 : loss : 0.519820, loss_ce: 0.179024
[19:32:48.377] iteration 248 : loss : 0.475562, loss_ce: 0.108624
[19:32:48.598] iteration 249 : loss : 0.495231, loss_ce: 0.117413
[19:32:48.818] iteration 250 : loss : 0.478827, loss_ce: 0.143472
[19:32:49.038] iteration 251 : loss : 0.488510, loss_ce: 0.125090
[19:32:49.259] iteration 252 : loss : 0.472004, loss_ce: 0.119868
[19:32:49.479] iteration 253 : loss : 0.493499, loss_ce: 0.124825
[19:32:49.699] iteration 254 : loss : 0.477804, loss_ce: 0.141826
[19:32:49.929] iteration 255 : loss : 0.519024, loss_ce: 0.133424
[19:32:50.149] iteration 256 : loss : 0.490662, loss_ce: 0.113911
[19:32:50.369] iteration 257 : loss : 0.490587, loss_ce: 0.145344
[19:32:50.589] iteration 258 : loss : 0.487828, loss_ce: 0.128899
[19:32:50.809] iteration 259 : loss : 0.477299, loss_ce: 0.174205
[19:32:51.041] iteration 260 : loss : 0.499603, loss_ce: 0.169537
[19:32:51.274] iteration 261 : loss : 0.479442, loss_ce: 0.143167
[19:32:51.494] iteration 262 : loss : 0.566845, loss_ce: 0.169074
[19:32:51.720] iteration 263 : loss : 0.486196, loss_ce: 0.077812
[19:32:51.941] iteration 264 : loss : 0.494897, loss_ce: 0.133217
[19:32:52.181] iteration 265 : loss : 0.485197, loss_ce: 0.162693
[19:32:52.413] iteration 266 : loss : 0.484901, loss_ce: 0.142772
[19:32:52.643] iteration 267 : loss : 0.489488, loss_ce: 0.150323
[19:32:52.873] iteration 268 : loss : 0.434928, loss_ce: 0.055412
[19:32:53.103] iteration 269 : loss : 0.528574, loss_ce: 0.084399
[19:32:53.333] iteration 270 : loss : 0.493129, loss_ce: 0.116571
[19:32:53.553] iteration 271 : loss : 0.464657, loss_ce: 0.061425
[19:32:53.773] iteration 272 : loss : 0.507251, loss_ce: 0.160742
[19:32:54.003] iteration 273 : loss : 0.494937, loss_ce: 0.193698
[19:32:54.224] iteration 274 : loss : 0.480772, loss_ce: 0.183020
[19:32:54.446] iteration 275 : loss : 0.488121, loss_ce: 0.183403
[19:32:54.666] iteration 276 : loss : 0.481923, loss_ce: 0.117718
[19:32:54.886] iteration 277 : loss : 0.486461, loss_ce: 0.135480
[14:51:00.395] Namespace(root_path='D:\\data/Synapse/train_npz\\train_npz', dataset='Synapse', list_dir='./lists/lists_Synapse', num_classes=9, output_dir='D:\\data/output', max_iterations=30000, max_epochs=150, batch_size=16, n_gpu=1, deterministic=1, base_lr=0.01, img_size=224, seed=1234, cfg='configs/swin_tiny_patch4_window7_224_lite.yaml', opts=None, zip=False, cache_mode='part', resume=None, accumulation_steps=None, use_checkpoint=False, amp_opt_level='O1', tag=None, eval=False, throughput=False)
[14:51:00.400] 139 iterations per epoch. 20850 max iterations 
[14:52:24.873] Namespace(root_path='D:\\data/Synapse/train\\train_npz', dataset='Synapse', list_dir='./lists/lists_Synapse', num_classes=9, output_dir='D:\\data/output', max_iterations=30000, max_epochs=150, batch_size=16, n_gpu=1, deterministic=1, base_lr=0.01, img_size=224, seed=1234, cfg='configs/swin_tiny_patch4_window7_224_lite.yaml', opts=None, zip=False, cache_mode='part', resume=None, accumulation_steps=None, use_checkpoint=False, amp_opt_level='O1', tag=None, eval=False, throughput=False)
[14:52:24.877] 139 iterations per epoch. 20850 max iterations 
[14:53:41.988] Namespace(root_path='D:\\data/Synapse/train', dataset='Synapse', list_dir='./lists/lists_Synapse', num_classes=9, output_dir='D:\\data/output', max_iterations=30000, max_epochs=150, batch_size=16, n_gpu=1, deterministic=1, base_lr=0.01, img_size=224, seed=1234, cfg='configs/swin_tiny_patch4_window7_224_lite.yaml', opts=None, zip=False, cache_mode='part', resume=None, accumulation_steps=None, use_checkpoint=False, amp_opt_level='O1', tag=None, eval=False, throughput=False)
[14:53:41.995] 139 iterations per epoch. 20850 max iterations 
[14:54:05.797] iteration 1 : loss : 1.463958, loss_ce: 2.234431
[14:54:06.911] iteration 2 : loss : 1.362587, loss_ce: 2.026518
[14:54:07.761] iteration 3 : loss : 1.207965, loss_ce: 1.637840
[14:54:08.601] iteration 4 : loss : 1.056117, loss_ce: 1.305276
[14:54:09.441] iteration 5 : loss : 0.845675, loss_ce: 0.801525
[14:54:10.287] iteration 6 : loss : 0.746403, loss_ce: 0.569570
[14:54:11.126] iteration 7 : loss : 0.703337, loss_ce: 0.463305
[14:54:11.976] iteration 8 : loss : 0.698379, loss_ce: 0.445791
[14:54:12.820] iteration 9 : loss : 0.649538, loss_ce: 0.313923
[14:54:13.669] iteration 10 : loss : 0.640000, loss_ce: 0.277069
[14:54:14.515] iteration 11 : loss : 0.647168, loss_ce: 0.293086
[14:54:15.367] iteration 12 : loss : 0.651027, loss_ce: 0.299663
[14:54:16.213] iteration 13 : loss : 0.632551, loss_ce: 0.252080
[14:54:17.064] iteration 14 : loss : 0.625255, loss_ce: 0.232934
[14:54:17.919] iteration 15 : loss : 0.627184, loss_ce: 0.236640
[14:54:18.773] iteration 16 : loss : 0.671620, loss_ce: 0.345951
[14:54:19.623] iteration 17 : loss : 0.585180, loss_ce: 0.132364
[14:54:20.471] iteration 18 : loss : 0.667238, loss_ce: 0.334600
[14:54:21.321] iteration 19 : loss : 0.691185, loss_ce: 0.393568
[14:54:22.175] iteration 20 : loss : 0.737733, loss_ce: 0.508338
[14:54:23.028] iteration 21 : loss : 0.648666, loss_ce: 0.288800
[14:54:23.898] iteration 22 : loss : 0.634671, loss_ce: 0.254611
[14:54:24.760] iteration 23 : loss : 0.708587, loss_ce: 0.437456
[14:54:25.615] iteration 24 : loss : 0.611421, loss_ce: 0.197628
[14:54:26.473] iteration 25 : loss : 0.691902, loss_ce: 0.397463
[14:54:27.327] iteration 26 : loss : 0.625170, loss_ce: 0.233867
[14:54:28.184] iteration 27 : loss : 0.668765, loss_ce: 0.343233
[14:54:29.034] iteration 28 : loss : 0.651139, loss_ce: 0.301936
[14:54:29.914] iteration 29 : loss : 0.627878, loss_ce: 0.247455
[23:25:33.322] Namespace(root_path='D:\\data/Synapse/train', dataset='Synapse', list_dir='./lists/lists_Synapse', num_classes=9, output_dir='D:\\data/output', max_iterations=30000, max_epochs=150, batch_size=16, n_gpu=1, deterministic=1, base_lr=0.01, img_size=224, seed=1234, cfg='configs/swin_tiny_patch4_window7_224_lite.yaml', opts=None, zip=False, cache_mode='part', resume=None, accumulation_steps=None, use_checkpoint=False, amp_opt_level='O1', tag=None, eval=False, throughput=False)
[23:25:33.328] 139 iterations per epoch. 20850 max iterations 
[23:25:57.441] iteration 1 : loss : 1.463958, loss_ce: 2.234431
[23:25:58.112] iteration 2 : loss : 1.362587, loss_ce: 2.026518
[23:25:58.402] iteration 3 : loss : 1.207965, loss_ce: 1.637840
[23:25:58.680] iteration 4 : loss : 1.056117, loss_ce: 1.305276
[23:25:58.957] iteration 5 : loss : 0.845675, loss_ce: 0.801525
[23:25:59.238] iteration 6 : loss : 0.746403, loss_ce: 0.569570
[23:25:59.520] iteration 7 : loss : 0.703337, loss_ce: 0.463305
[23:25:59.799] iteration 8 : loss : 0.698379, loss_ce: 0.445791
[23:26:00.083] iteration 9 : loss : 0.649538, loss_ce: 0.313923
[23:26:00.362] iteration 10 : loss : 0.640000, loss_ce: 0.277069
[23:26:00.640] iteration 11 : loss : 0.647168, loss_ce: 0.293086
[23:26:00.919] iteration 12 : loss : 0.651027, loss_ce: 0.299663
[23:26:01.200] iteration 13 : loss : 0.632551, loss_ce: 0.252080
[23:26:01.494] iteration 14 : loss : 0.625255, loss_ce: 0.232934
[23:26:01.791] iteration 15 : loss : 0.627184, loss_ce: 0.236640
[23:26:02.067] iteration 16 : loss : 0.671620, loss_ce: 0.345951
[23:26:02.344] iteration 17 : loss : 0.585180, loss_ce: 0.132364
[23:26:02.625] iteration 18 : loss : 0.667238, loss_ce: 0.334600
[23:26:02.901] iteration 19 : loss : 0.691185, loss_ce: 0.393568
[23:26:03.180] iteration 20 : loss : 0.737733, loss_ce: 0.508338
[23:26:03.490] iteration 21 : loss : 0.648666, loss_ce: 0.288800
[23:26:03.767] iteration 22 : loss : 0.634671, loss_ce: 0.254611
[23:26:04.055] iteration 23 : loss : 0.708587, loss_ce: 0.437456
[23:26:04.332] iteration 24 : loss : 0.611421, loss_ce: 0.197628
[23:26:04.614] iteration 25 : loss : 0.691902, loss_ce: 0.397463
[23:26:04.890] iteration 26 : loss : 0.625170, loss_ce: 0.233867
[23:26:05.171] iteration 27 : loss : 0.668765, loss_ce: 0.343233
[23:26:05.457] iteration 28 : loss : 0.651139, loss_ce: 0.301936
[23:26:05.738] iteration 29 : loss : 0.627878, loss_ce: 0.247455
[23:26:06.022] iteration 30 : loss : 0.606536, loss_ce: 0.198083
[23:26:06.308] iteration 31 : loss : 0.597331, loss_ce: 0.192767
[23:26:06.588] iteration 32 : loss : 0.611812, loss_ce: 0.221483
[23:26:06.875] iteration 33 : loss : 0.654702, loss_ce: 0.343687
[23:26:07.153] iteration 34 : loss : 0.605163, loss_ce: 0.231836
[23:26:07.430] iteration 35 : loss : 0.638844, loss_ce: 0.307441
[23:26:07.713] iteration 36 : loss : 0.648503, loss_ce: 0.336910
[23:26:07.987] iteration 37 : loss : 0.635265, loss_ce: 0.307442
[23:26:08.268] iteration 38 : loss : 0.632995, loss_ce: 0.320540
[23:26:08.546] iteration 39 : loss : 0.579874, loss_ce: 0.184163
[23:26:08.828] iteration 40 : loss : 0.607006, loss_ce: 0.284664
[23:26:09.121] iteration 41 : loss : 0.641639, loss_ce: 0.359823
[23:26:09.400] iteration 42 : loss : 0.589657, loss_ce: 0.241367
[23:26:09.679] iteration 43 : loss : 0.573051, loss_ce: 0.216197
[23:26:09.962] iteration 44 : loss : 0.581050, loss_ce: 0.193696
[23:26:10.240] iteration 45 : loss : 0.586582, loss_ce: 0.199200
[23:26:10.529] iteration 46 : loss : 0.564574, loss_ce: 0.122219
[23:26:10.817] iteration 47 : loss : 0.581776, loss_ce: 0.178824
[23:26:11.098] iteration 48 : loss : 0.580879, loss_ce: 0.223508
[23:26:11.378] iteration 49 : loss : 0.579625, loss_ce: 0.219467
[23:26:11.659] iteration 50 : loss : 0.569268, loss_ce: 0.176484
[23:26:11.939] iteration 51 : loss : 0.602778, loss_ce: 0.282271
[23:26:12.214] iteration 52 : loss : 0.579921, loss_ce: 0.217490
[23:26:12.491] iteration 53 : loss : 0.559823, loss_ce: 0.165776
[23:26:12.784] iteration 54 : loss : 0.573677, loss_ce: 0.188881
[23:26:13.069] iteration 55 : loss : 0.562016, loss_ce: 0.173500
[23:26:13.346] iteration 56 : loss : 0.562084, loss_ce: 0.180559
[23:26:13.625] iteration 57 : loss : 0.564162, loss_ce: 0.139455
[23:26:13.908] iteration 58 : loss : 0.552901, loss_ce: 0.126733
[23:26:14.190] iteration 59 : loss : 0.549418, loss_ce: 0.141934
[23:26:14.474] iteration 60 : loss : 0.580367, loss_ce: 0.202071
[23:26:14.774] iteration 61 : loss : 0.588353, loss_ce: 0.202220
[23:26:15.053] iteration 62 : loss : 0.567914, loss_ce: 0.162546
[23:26:15.329] iteration 63 : loss : 0.591278, loss_ce: 0.264510
[23:26:15.610] iteration 64 : loss : 0.572738, loss_ce: 0.200188
[23:26:15.894] iteration 65 : loss : 0.567481, loss_ce: 0.193800
[23:26:16.174] iteration 66 : loss : 0.571640, loss_ce: 0.195996
[23:26:16.451] iteration 67 : loss : 0.559889, loss_ce: 0.158492
[23:26:16.730] iteration 68 : loss : 0.560371, loss_ce: 0.151213
[23:26:17.007] iteration 69 : loss : 0.588096, loss_ce: 0.217063
[23:26:17.288] iteration 70 : loss : 0.564510, loss_ce: 0.151472
[23:26:17.580] iteration 71 : loss : 0.560092, loss_ce: 0.162318
[23:26:17.860] iteration 72 : loss : 0.570533, loss_ce: 0.201379
[23:26:18.141] iteration 73 : loss : 0.581310, loss_ce: 0.237166
[23:26:18.424] iteration 74 : loss : 0.563106, loss_ce: 0.188789
[23:26:18.703] iteration 75 : loss : 0.556645, loss_ce: 0.181938
[23:26:18.982] iteration 76 : loss : 0.555855, loss_ce: 0.198353
[23:26:19.260] iteration 77 : loss : 0.551091, loss_ce: 0.132894
[23:26:19.541] iteration 78 : loss : 0.555725, loss_ce: 0.163820
[23:26:19.839] iteration 79 : loss : 0.563963, loss_ce: 0.154362
[23:26:20.121] iteration 80 : loss : 0.539982, loss_ce: 0.148032
[23:26:20.435] iteration 81 : loss : 0.541317, loss_ce: 0.148877
[23:26:20.714] iteration 82 : loss : 0.569418, loss_ce: 0.211314
[23:26:20.998] iteration 83 : loss : 0.578086, loss_ce: 0.198829
[23:26:21.279] iteration 84 : loss : 0.564605, loss_ce: 0.194586
[23:26:21.557] iteration 85 : loss : 0.564097, loss_ce: 0.190747
[23:26:21.838] iteration 86 : loss : 0.556343, loss_ce: 0.179120
[23:26:22.121] iteration 87 : loss : 0.569517, loss_ce: 0.205773
[23:26:22.405] iteration 88 : loss : 0.554096, loss_ce: 0.150855
[23:26:22.682] iteration 89 : loss : 0.578922, loss_ce: 0.211140
[23:26:22.958] iteration 90 : loss : 0.550226, loss_ce: 0.131443
[23:26:23.238] iteration 91 : loss : 0.588697, loss_ce: 0.243887
[23:26:23.515] iteration 92 : loss : 0.568296, loss_ce: 0.212048
[23:26:23.793] iteration 93 : loss : 0.544131, loss_ce: 0.166399
[23:26:24.071] iteration 94 : loss : 0.549765, loss_ce: 0.175324
[23:26:24.348] iteration 95 : loss : 0.530327, loss_ce: 0.106178
[23:26:24.627] iteration 96 : loss : 0.566567, loss_ce: 0.144061
[23:26:24.903] iteration 97 : loss : 0.550174, loss_ce: 0.143650
[23:26:25.180] iteration 98 : loss : 0.559710, loss_ce: 0.168630
[23:26:25.459] iteration 99 : loss : 0.558768, loss_ce: 0.198590
[23:26:25.735] iteration 100 : loss : 0.564096, loss_ce: 0.249145
[23:26:26.027] iteration 101 : loss : 0.579532, loss_ce: 0.265283
[23:26:26.304] iteration 102 : loss : 0.561266, loss_ce: 0.228468
[23:26:26.580] iteration 103 : loss : 0.544898, loss_ce: 0.153794
[23:26:26.861] iteration 104 : loss : 0.567579, loss_ce: 0.181216
[23:26:27.137] iteration 105 : loss : 0.560783, loss_ce: 0.134331
[23:26:27.416] iteration 106 : loss : 0.579971, loss_ce: 0.208285
[23:26:27.700] iteration 107 : loss : 0.559117, loss_ce: 0.165989
[23:26:27.977] iteration 108 : loss : 0.546548, loss_ce: 0.188109
[23:26:28.259] iteration 109 : loss : 0.561708, loss_ce: 0.185925
[23:26:28.539] iteration 110 : loss : 0.554799, loss_ce: 0.214870
[23:26:28.817] iteration 111 : loss : 0.555516, loss_ce: 0.206036
[23:26:29.098] iteration 112 : loss : 0.559461, loss_ce: 0.205851
[23:26:29.376] iteration 113 : loss : 0.547860, loss_ce: 0.134178
[23:26:29.658] iteration 114 : loss : 0.573065, loss_ce: 0.153832
[23:26:29.937] iteration 115 : loss : 0.576159, loss_ce: 0.195848
[23:26:30.216] iteration 116 : loss : 0.542486, loss_ce: 0.121735
[23:26:30.498] iteration 117 : loss : 0.557137, loss_ce: 0.201206
[23:26:30.776] iteration 118 : loss : 0.543947, loss_ce: 0.167893
[23:26:31.057] iteration 119 : loss : 0.557026, loss_ce: 0.221740
[23:26:31.338] iteration 120 : loss : 0.552010, loss_ce: 0.203063
[23:26:31.636] iteration 121 : loss : 0.537632, loss_ce: 0.148484
[23:26:31.914] iteration 122 : loss : 0.549326, loss_ce: 0.141445
[23:26:32.193] iteration 123 : loss : 0.600902, loss_ce: 0.247641
[23:26:32.477] iteration 124 : loss : 0.554901, loss_ce: 0.174684
[23:26:32.758] iteration 125 : loss : 0.539229, loss_ce: 0.176804
[23:26:33.037] iteration 126 : loss : 0.547471, loss_ce: 0.196593
[23:26:33.319] iteration 127 : loss : 0.563967, loss_ce: 0.203540
[23:26:33.600] iteration 128 : loss : 0.554003, loss_ce: 0.209760
[23:26:33.879] iteration 129 : loss : 0.541855, loss_ce: 0.157431
[23:26:34.156] iteration 130 : loss : 0.553956, loss_ce: 0.167509
[23:26:34.434] iteration 131 : loss : 0.571342, loss_ce: 0.235527
[23:26:34.712] iteration 132 : loss : 0.538581, loss_ce: 0.154098
[23:26:34.994] iteration 133 : loss : 0.524625, loss_ce: 0.138659
[23:26:35.275] iteration 134 : loss : 0.523074, loss_ce: 0.134470
[23:26:35.556] iteration 135 : loss : 0.528824, loss_ce: 0.116179
[23:26:35.839] iteration 136 : loss : 0.554399, loss_ce: 0.205957
[23:26:36.119] iteration 137 : loss : 0.563856, loss_ce: 0.181810
[23:26:36.402] iteration 138 : loss : 0.518570, loss_ce: 0.130090
[23:26:36.495] iteration 139 : loss : 0.517769, loss_ce: 0.157201
[23:26:53.870] iteration 140 : loss : 0.541158, loss_ce: 0.198491
[23:26:54.184] iteration 141 : loss : 0.531142, loss_ce: 0.169068
[23:26:54.477] iteration 142 : loss : 0.527159, loss_ce: 0.153046
[23:26:54.771] iteration 143 : loss : 0.524373, loss_ce: 0.132997
[23:26:55.096] iteration 144 : loss : 0.531914, loss_ce: 0.159220
[23:26:55.394] iteration 145 : loss : 0.508788, loss_ce: 0.130987
[23:26:55.698] iteration 146 : loss : 0.525316, loss_ce: 0.152663
[23:26:56.001] iteration 147 : loss : 0.498455, loss_ce: 0.084460
[23:26:56.307] iteration 148 : loss : 0.552354, loss_ce: 0.240407
[23:26:56.603] iteration 149 : loss : 0.522992, loss_ce: 0.173706
[23:26:56.895] iteration 150 : loss : 0.517648, loss_ce: 0.103578
[23:26:57.185] iteration 151 : loss : 0.544543, loss_ce: 0.151744
[23:26:57.470] iteration 152 : loss : 0.508040, loss_ce: 0.127851
[23:26:57.752] iteration 153 : loss : 0.538643, loss_ce: 0.175406
[23:26:58.036] iteration 154 : loss : 0.551911, loss_ce: 0.194065
[23:26:58.324] iteration 155 : loss : 0.535330, loss_ce: 0.207807
[23:26:58.614] iteration 156 : loss : 0.533738, loss_ce: 0.201429
[23:26:58.897] iteration 157 : loss : 0.518206, loss_ce: 0.137265
[23:26:59.179] iteration 158 : loss : 0.515552, loss_ce: 0.102589
[23:26:59.459] iteration 159 : loss : 0.542862, loss_ce: 0.135484
[23:26:59.740] iteration 160 : loss : 0.509241, loss_ce: 0.138975
[23:27:00.037] iteration 161 : loss : 0.517155, loss_ce: 0.126072
[23:27:00.324] iteration 162 : loss : 0.526598, loss_ce: 0.143490
[23:27:00.607] iteration 163 : loss : 0.509337, loss_ce: 0.120805
[23:27:00.902] iteration 164 : loss : 0.520610, loss_ce: 0.157170
[23:27:01.185] iteration 165 : loss : 0.524298, loss_ce: 0.182873
[23:27:01.468] iteration 166 : loss : 0.497088, loss_ce: 0.108030
[23:27:01.758] iteration 167 : loss : 0.519055, loss_ce: 0.104485
[23:27:02.051] iteration 168 : loss : 0.502980, loss_ce: 0.087910
[23:27:02.342] iteration 169 : loss : 0.548029, loss_ce: 0.178869
[23:27:02.641] iteration 170 : loss : 0.557714, loss_ce: 0.276812
[23:27:02.937] iteration 171 : loss : 0.537840, loss_ce: 0.212024
[23:27:03.219] iteration 172 : loss : 0.532839, loss_ce: 0.184562
[23:27:03.501] iteration 173 : loss : 0.552013, loss_ce: 0.236132
[23:27:03.782] iteration 174 : loss : 0.552760, loss_ce: 0.214476
[23:27:04.059] iteration 175 : loss : 0.502505, loss_ce: 0.105955
[23:27:04.336] iteration 176 : loss : 0.521307, loss_ce: 0.164991
[23:27:04.616] iteration 177 : loss : 0.516416, loss_ce: 0.124105
[23:27:04.894] iteration 178 : loss : 0.545045, loss_ce: 0.191534
[23:27:05.171] iteration 179 : loss : 0.538828, loss_ce: 0.227804
[23:27:05.448] iteration 180 : loss : 0.522908, loss_ce: 0.182877
[23:27:05.744] iteration 181 : loss : 0.527647, loss_ce: 0.123068
[23:27:06.020] iteration 182 : loss : 0.497905, loss_ce: 0.073401
[23:27:06.302] iteration 183 : loss : 0.539369, loss_ce: 0.154232
[23:27:06.580] iteration 184 : loss : 0.505891, loss_ce: 0.124434
[23:27:06.860] iteration 185 : loss : 0.514696, loss_ce: 0.163566
[23:27:07.139] iteration 186 : loss : 0.547509, loss_ce: 0.218195
[23:27:07.417] iteration 187 : loss : 0.517704, loss_ce: 0.166138
[23:27:07.694] iteration 188 : loss : 0.524765, loss_ce: 0.168329
[23:27:07.973] iteration 189 : loss : 0.511183, loss_ce: 0.106170
[23:27:08.253] iteration 190 : loss : 0.528156, loss_ce: 0.115619
[23:27:08.531] iteration 191 : loss : 0.505883, loss_ce: 0.116124
[23:27:08.811] iteration 192 : loss : 0.538600, loss_ce: 0.152248
[23:27:09.090] iteration 193 : loss : 0.502427, loss_ce: 0.111848
[23:27:09.369] iteration 194 : loss : 0.534408, loss_ce: 0.172483
[23:27:09.647] iteration 195 : loss : 0.523625, loss_ce: 0.184821
[23:27:09.929] iteration 196 : loss : 0.530280, loss_ce: 0.184986
[23:27:10.207] iteration 197 : loss : 0.504227, loss_ce: 0.112617
[23:27:10.484] iteration 198 : loss : 0.540445, loss_ce: 0.150380
[23:27:10.762] iteration 199 : loss : 0.522594, loss_ce: 0.123342
[23:27:11.046] iteration 200 : loss : 0.500230, loss_ce: 0.086612
[23:27:11.344] iteration 201 : loss : 0.496677, loss_ce: 0.108501
[23:27:11.623] iteration 202 : loss : 0.499741, loss_ce: 0.108399
[23:27:11.903] iteration 203 : loss : 0.500360, loss_ce: 0.131312
[23:27:12.185] iteration 204 : loss : 0.513713, loss_ce: 0.155715
[23:27:12.464] iteration 205 : loss : 0.517234, loss_ce: 0.150461
[23:27:12.741] iteration 206 : loss : 0.520333, loss_ce: 0.177356
[23:27:13.021] iteration 207 : loss : 0.530258, loss_ce: 0.172146
[23:27:13.302] iteration 208 : loss : 0.511811, loss_ce: 0.144273
[23:27:13.582] iteration 209 : loss : 0.520632, loss_ce: 0.177313
[23:27:13.859] iteration 210 : loss : 0.529325, loss_ce: 0.191049
[23:27:14.147] iteration 211 : loss : 0.538240, loss_ce: 0.220472
[23:27:14.460] iteration 212 : loss : 0.536973, loss_ce: 0.196304
[23:27:14.773] iteration 213 : loss : 0.508919, loss_ce: 0.144269
[23:27:15.091] iteration 214 : loss : 0.524879, loss_ce: 0.137349
[23:27:15.387] iteration 215 : loss : 0.539223, loss_ce: 0.175584
[23:27:15.667] iteration 216 : loss : 0.482232, loss_ce: 0.060086
[23:27:15.971] iteration 217 : loss : 0.504237, loss_ce: 0.137619
[23:27:16.291] iteration 218 : loss : 0.487778, loss_ce: 0.101329
[23:27:16.572] iteration 219 : loss : 0.497882, loss_ce: 0.134679
[23:27:16.855] iteration 220 : loss : 0.482579, loss_ce: 0.087832
[23:27:17.176] iteration 221 : loss : 0.496678, loss_ce: 0.087367
[23:27:17.457] iteration 222 : loss : 0.498126, loss_ce: 0.131050
[23:27:17.735] iteration 223 : loss : 0.491049, loss_ce: 0.108777
[23:27:18.046] iteration 224 : loss : 0.491904, loss_ce: 0.088821
[23:27:18.323] iteration 225 : loss : 0.538641, loss_ce: 0.209247
[23:27:18.632] iteration 226 : loss : 0.507968, loss_ce: 0.124461
[23:27:18.909] iteration 227 : loss : 0.510699, loss_ce: 0.163503
[23:27:19.187] iteration 228 : loss : 0.511941, loss_ce: 0.167884
[23:27:19.475] iteration 229 : loss : 0.494183, loss_ce: 0.092191
[23:27:19.765] iteration 230 : loss : 0.517062, loss_ce: 0.175385
[23:27:20.058] iteration 231 : loss : 0.494624, loss_ce: 0.109555
[23:27:20.339] iteration 232 : loss : 0.521606, loss_ce: 0.112241
[23:27:20.627] iteration 233 : loss : 0.498891, loss_ce: 0.104960
[23:27:20.921] iteration 234 : loss : 0.472162, loss_ce: 0.083731
[23:27:21.205] iteration 235 : loss : 0.494186, loss_ce: 0.132140
[23:27:21.485] iteration 236 : loss : 0.491978, loss_ce: 0.117690
[23:27:21.765] iteration 237 : loss : 0.548381, loss_ce: 0.255372
[23:27:22.046] iteration 238 : loss : 0.514133, loss_ce: 0.167591
[23:27:22.327] iteration 239 : loss : 0.500346, loss_ce: 0.159102
[23:27:22.606] iteration 240 : loss : 0.520900, loss_ce: 0.150727
[23:27:22.903] iteration 241 : loss : 0.499499, loss_ce: 0.139045
[23:27:23.181] iteration 242 : loss : 0.502089, loss_ce: 0.097685
[23:27:23.464] iteration 243 : loss : 0.494319, loss_ce: 0.119462
[23:27:23.744] iteration 244 : loss : 0.507491, loss_ce: 0.130430
[23:27:24.030] iteration 245 : loss : 0.495418, loss_ce: 0.152107
[23:27:24.313] iteration 246 : loss : 0.495262, loss_ce: 0.096590
[23:27:24.594] iteration 247 : loss : 0.490091, loss_ce: 0.067554
[23:27:24.874] iteration 248 : loss : 0.535275, loss_ce: 0.186791
[23:27:25.155] iteration 249 : loss : 0.530268, loss_ce: 0.090360
[23:27:25.437] iteration 250 : loss : 0.505593, loss_ce: 0.156917
[23:27:25.720] iteration 251 : loss : 0.531995, loss_ce: 0.217872
[23:27:25.997] iteration 252 : loss : 0.505645, loss_ce: 0.161033
[23:27:26.289] iteration 253 : loss : 0.492607, loss_ce: 0.146099
[23:27:26.591] iteration 254 : loss : 0.489448, loss_ce: 0.139779
[23:27:26.873] iteration 255 : loss : 0.507466, loss_ce: 0.183483
[23:27:27.164] iteration 256 : loss : 0.493113, loss_ce: 0.118708
[23:27:27.459] iteration 257 : loss : 0.516189, loss_ce: 0.181487
[23:27:27.744] iteration 258 : loss : 0.504020, loss_ce: 0.150556
[23:27:28.035] iteration 259 : loss : 0.489882, loss_ce: 0.109441
[23:27:28.337] iteration 260 : loss : 0.487834, loss_ce: 0.134983
[23:27:28.643] iteration 261 : loss : 0.486444, loss_ce: 0.064523
[23:27:28.929] iteration 262 : loss : 0.502940, loss_ce: 0.127903
[23:27:29.215] iteration 263 : loss : 0.502912, loss_ce: 0.136973
[23:27:29.501] iteration 264 : loss : 0.513961, loss_ce: 0.115221
[23:27:29.786] iteration 265 : loss : 0.505811, loss_ce: 0.142522
[23:27:30.063] iteration 266 : loss : 0.484261, loss_ce: 0.108702
[23:27:30.342] iteration 267 : loss : 0.502115, loss_ce: 0.139273
[23:27:30.622] iteration 268 : loss : 0.504705, loss_ce: 0.184788
[23:27:30.906] iteration 269 : loss : 0.481954, loss_ce: 0.137316
[23:27:31.185] iteration 270 : loss : 0.486169, loss_ce: 0.124911
[23:27:31.469] iteration 271 : loss : 0.512049, loss_ce: 0.157606
[23:27:31.748] iteration 272 : loss : 0.499418, loss_ce: 0.130214
[23:27:32.027] iteration 273 : loss : 0.484841, loss_ce: 0.123388
[23:27:32.304] iteration 274 : loss : 0.490344, loss_ce: 0.135651
[23:27:32.587] iteration 275 : loss : 0.510157, loss_ce: 0.181259
[23:27:32.866] iteration 276 : loss : 0.484827, loss_ce: 0.074689
[23:27:33.148] iteration 277 : loss : 0.491734, loss_ce: 0.114197
[23:27:33.232] iteration 278 : loss : 0.522263, loss_ce: 0.171290
[23:27:50.993] iteration 279 : loss : 0.499387, loss_ce: 0.108498
[23:27:51.278] iteration 280 : loss : 0.482880, loss_ce: 0.151405
[23:27:51.584] iteration 281 : loss : 0.488650, loss_ce: 0.150460
[23:27:51.876] iteration 282 : loss : 0.506918, loss_ce: 0.169118
[23:27:52.163] iteration 283 : loss : 0.477350, loss_ce: 0.108962
[23:27:52.445] iteration 284 : loss : 0.495478, loss_ce: 0.125747
[23:27:52.723] iteration 285 : loss : 0.495558, loss_ce: 0.116425
[23:27:53.001] iteration 286 : loss : 0.496131, loss_ce: 0.152259
[23:27:53.279] iteration 287 : loss : 0.481993, loss_ce: 0.135510
[23:27:53.556] iteration 288 : loss : 0.501502, loss_ce: 0.145181
[23:27:53.834] iteration 289 : loss : 0.495256, loss_ce: 0.112305
[23:27:54.109] iteration 290 : loss : 0.480355, loss_ce: 0.121008
[23:27:54.387] iteration 291 : loss : 0.456805, loss_ce: 0.071779
[23:27:54.665] iteration 292 : loss : 0.487093, loss_ce: 0.130827
[23:27:54.950] iteration 293 : loss : 0.483881, loss_ce: 0.131856
[23:27:55.227] iteration 294 : loss : 0.502224, loss_ce: 0.173974
[23:27:55.504] iteration 295 : loss : 0.490905, loss_ce: 0.116716
[23:27:55.783] iteration 296 : loss : 0.483086, loss_ce: 0.115796
[23:27:56.065] iteration 297 : loss : 0.482735, loss_ce: 0.142918
[23:27:56.374] iteration 298 : loss : 0.472385, loss_ce: 0.116740
[23:27:56.656] iteration 299 : loss : 0.525511, loss_ce: 0.233027
[23:27:56.933] iteration 300 : loss : 0.504935, loss_ce: 0.179468
[23:27:57.223] iteration 301 : loss : 0.474473, loss_ce: 0.113322
[23:27:57.499] iteration 302 : loss : 0.494168, loss_ce: 0.148464
[23:27:57.773] iteration 303 : loss : 0.476234, loss_ce: 0.093380
[23:27:58.053] iteration 304 : loss : 0.527861, loss_ce: 0.226846
[23:27:58.328] iteration 305 : loss : 0.488260, loss_ce: 0.147595
[23:27:58.604] iteration 306 : loss : 0.479250, loss_ce: 0.126242
[23:27:58.882] iteration 307 : loss : 0.509269, loss_ce: 0.218136
[23:27:59.158] iteration 308 : loss : 0.480074, loss_ce: 0.122268
[23:27:59.438] iteration 309 : loss : 0.451072, loss_ce: 0.097565
[23:27:59.713] iteration 310 : loss : 0.469043, loss_ce: 0.152388
[23:27:59.987] iteration 311 : loss : 0.476797, loss_ce: 0.108316
[23:28:00.269] iteration 312 : loss : 0.475202, loss_ce: 0.094999
[23:28:00.546] iteration 313 : loss : 0.469262, loss_ce: 0.111232
[23:28:00.855] iteration 314 : loss : 0.471832, loss_ce: 0.129926
[23:28:01.140] iteration 315 : loss : 0.463723, loss_ce: 0.108771
[23:28:01.428] iteration 316 : loss : 0.460375, loss_ce: 0.137761
[23:28:01.712] iteration 317 : loss : 0.474723, loss_ce: 0.161609
[23:28:01.990] iteration 318 : loss : 0.462881, loss_ce: 0.071705
[23:28:02.271] iteration 319 : loss : 0.489363, loss_ce: 0.168150
[23:28:02.552] iteration 320 : loss : 0.455857, loss_ce: 0.110448
[23:28:02.847] iteration 321 : loss : 0.483507, loss_ce: 0.142713
[23:28:03.124] iteration 322 : loss : 0.486873, loss_ce: 0.106691
[23:28:03.403] iteration 323 : loss : 0.498165, loss_ce: 0.167402
[23:28:03.680] iteration 324 : loss : 0.465399, loss_ce: 0.123219
[23:28:03.957] iteration 325 : loss : 0.456434, loss_ce: 0.077093
[23:28:04.235] iteration 326 : loss : 0.477482, loss_ce: 0.120140
[23:28:04.516] iteration 327 : loss : 0.485454, loss_ce: 0.146344
[23:28:04.797] iteration 328 : loss : 0.529859, loss_ce: 0.208214
[23:28:05.073] iteration 329 : loss : 0.471420, loss_ce: 0.132562
[23:28:05.352] iteration 330 : loss : 0.489779, loss_ce: 0.148689
[23:28:05.629] iteration 331 : loss : 0.472244, loss_ce: 0.150582
[23:28:05.906] iteration 332 : loss : 0.507443, loss_ce: 0.154865
[23:28:06.188] iteration 333 : loss : 0.500146, loss_ce: 0.180663
[23:28:06.468] iteration 334 : loss : 0.484805, loss_ce: 0.118735
[23:28:06.743] iteration 335 : loss : 0.490360, loss_ce: 0.181640
[23:28:07.023] iteration 336 : loss : 0.482770, loss_ce: 0.105001
[23:28:07.300] iteration 337 : loss : 0.477804, loss_ce: 0.152362
[23:28:07.581] iteration 338 : loss : 0.472500, loss_ce: 0.126501
[23:28:07.859] iteration 339 : loss : 0.498381, loss_ce: 0.137476
[23:28:08.167] iteration 340 : loss : 0.480541, loss_ce: 0.119209
[23:28:08.464] iteration 341 : loss : 0.484035, loss_ce: 0.151333
[23:28:08.756] iteration 342 : loss : 0.469172, loss_ce: 0.156140
[23:28:09.057] iteration 343 : loss : 0.507219, loss_ce: 0.230585
[23:28:09.352] iteration 344 : loss : 0.490853, loss_ce: 0.092047
[23:28:09.636] iteration 345 : loss : 0.506203, loss_ce: 0.207751
[23:28:09.915] iteration 346 : loss : 0.468921, loss_ce: 0.104096
[23:28:10.194] iteration 347 : loss : 0.473035, loss_ce: 0.121359
[23:28:10.477] iteration 348 : loss : 0.475732, loss_ce: 0.092947
[23:28:10.779] iteration 349 : loss : 0.480962, loss_ce: 0.088246
[23:28:11.082] iteration 350 : loss : 0.454942, loss_ce: 0.088682
[23:28:11.362] iteration 351 : loss : 0.468329, loss_ce: 0.139992
[23:28:11.683] iteration 352 : loss : 0.461157, loss_ce: 0.124579
[23:28:11.975] iteration 353 : loss : 0.474074, loss_ce: 0.133076
[23:28:12.249] iteration 354 : loss : 0.476374, loss_ce: 0.104726
[23:28:12.557] iteration 355 : loss : 0.453938, loss_ce: 0.119530
[23:28:12.863] iteration 356 : loss : 0.476334, loss_ce: 0.138201
[23:28:13.141] iteration 357 : loss : 0.449943, loss_ce: 0.104116
[23:28:13.420] iteration 358 : loss : 0.474680, loss_ce: 0.092813
[23:28:13.696] iteration 359 : loss : 0.461395, loss_ce: 0.133055
[23:28:13.971] iteration 360 : loss : 0.454000, loss_ce: 0.120431
[23:28:14.263] iteration 361 : loss : 0.459853, loss_ce: 0.101165
[23:28:14.543] iteration 362 : loss : 0.447644, loss_ce: 0.101734
[23:28:14.819] iteration 363 : loss : 0.450860, loss_ce: 0.084096
[23:28:15.095] iteration 364 : loss : 0.445390, loss_ce: 0.126759
[23:28:15.374] iteration 365 : loss : 0.466905, loss_ce: 0.145188
[23:28:15.653] iteration 366 : loss : 0.484769, loss_ce: 0.136833
[23:28:15.930] iteration 367 : loss : 0.467108, loss_ce: 0.152734
[23:28:16.207] iteration 368 : loss : 0.506335, loss_ce: 0.237349
[23:28:16.483] iteration 369 : loss : 0.461230, loss_ce: 0.147473
[23:28:16.761] iteration 370 : loss : 0.501539, loss_ce: 0.172075
[23:28:17.044] iteration 371 : loss : 0.488346, loss_ce: 0.066105
[23:28:17.335] iteration 372 : loss : 0.452342, loss_ce: 0.105460
[23:28:17.628] iteration 373 : loss : 0.472592, loss_ce: 0.107693
[23:28:17.961] iteration 374 : loss : 0.467970, loss_ce: 0.164990
[23:28:18.275] iteration 375 : loss : 0.495727, loss_ce: 0.204887
[23:28:18.583] iteration 376 : loss : 0.451767, loss_ce: 0.123469
[23:28:18.876] iteration 377 : loss : 0.474435, loss_ce: 0.056542
[23:28:19.169] iteration 378 : loss : 0.456551, loss_ce: 0.129859
[23:28:19.456] iteration 379 : loss : 0.456479, loss_ce: 0.135901
[23:28:19.736] iteration 380 : loss : 0.498038, loss_ce: 0.123728
[23:28:20.030] iteration 381 : loss : 0.454124, loss_ce: 0.133462
[23:28:20.307] iteration 382 : loss : 0.466411, loss_ce: 0.126817
[23:28:20.585] iteration 383 : loss : 0.499718, loss_ce: 0.157791
[23:28:20.863] iteration 384 : loss : 0.456398, loss_ce: 0.129807
[23:28:21.143] iteration 385 : loss : 0.439729, loss_ce: 0.108827
[23:28:21.424] iteration 386 : loss : 0.439207, loss_ce: 0.074424
[23:28:21.746] iteration 387 : loss : 0.505817, loss_ce: 0.196708
[23:28:22.060] iteration 388 : loss : 0.518615, loss_ce: 0.042303
[23:28:22.402] iteration 389 : loss : 0.488536, loss_ce: 0.153108
[23:28:22.694] iteration 390 : loss : 0.439319, loss_ce: 0.096213
[23:28:22.985] iteration 391 : loss : 0.494828, loss_ce: 0.236753
[23:28:23.283] iteration 392 : loss : 0.461073, loss_ce: 0.148584
[23:28:23.578] iteration 393 : loss : 0.451293, loss_ce: 0.117111
[23:28:23.860] iteration 394 : loss : 0.456552, loss_ce: 0.086274
[23:28:24.142] iteration 395 : loss : 0.459183, loss_ce: 0.091481
[23:28:24.453] iteration 396 : loss : 0.455642, loss_ce: 0.081424
[23:28:24.760] iteration 397 : loss : 0.476632, loss_ce: 0.169269
[23:28:25.040] iteration 398 : loss : 0.478678, loss_ce: 0.189912
[23:28:25.326] iteration 399 : loss : 0.455930, loss_ce: 0.145231
[23:28:25.608] iteration 400 : loss : 0.481635, loss_ce: 0.156712
[23:28:25.919] iteration 401 : loss : 0.439933, loss_ce: 0.102488
[23:28:26.232] iteration 402 : loss : 0.483248, loss_ce: 0.179045
[23:28:26.535] iteration 403 : loss : 0.449385, loss_ce: 0.100606
[23:28:26.828] iteration 404 : loss : 0.463203, loss_ce: 0.128262
[23:28:27.121] iteration 405 : loss : 0.488272, loss_ce: 0.103705
[23:28:27.414] iteration 406 : loss : 0.426263, loss_ce: 0.055142
[23:28:27.705] iteration 407 : loss : 0.461732, loss_ce: 0.120716
[23:28:27.996] iteration 408 : loss : 0.448210, loss_ce: 0.077505
[23:28:28.288] iteration 409 : loss : 0.435271, loss_ce: 0.109004
[23:28:28.578] iteration 410 : loss : 0.456449, loss_ce: 0.172365
[23:28:28.858] iteration 411 : loss : 0.459182, loss_ce: 0.130589
[23:28:29.147] iteration 412 : loss : 0.469844, loss_ce: 0.140676
[23:28:29.430] iteration 413 : loss : 0.424848, loss_ce: 0.062560
[23:28:29.725] iteration 414 : loss : 0.429168, loss_ce: 0.140310
[23:28:30.010] iteration 415 : loss : 0.453277, loss_ce: 0.092018
[23:28:30.300] iteration 416 : loss : 0.455388, loss_ce: 0.176192
[23:28:30.389] iteration 417 : loss : 0.462147, loss_ce: 0.090152
[23:28:49.902] iteration 418 : loss : 0.464809, loss_ce: 0.146862
[23:28:50.190] iteration 419 : loss : 0.456858, loss_ce: 0.096803
[23:28:50.480] iteration 420 : loss : 0.443889, loss_ce: 0.106904
[23:28:50.786] iteration 421 : loss : 0.467850, loss_ce: 0.166708
[23:28:51.074] iteration 422 : loss : 0.464512, loss_ce: 0.088287
[23:28:51.351] iteration 423 : loss : 0.442567, loss_ce: 0.126299
[23:28:51.629] iteration 424 : loss : 0.445318, loss_ce: 0.128798
[23:28:51.908] iteration 425 : loss : 0.464866, loss_ce: 0.182200
[23:28:52.185] iteration 426 : loss : 0.452483, loss_ce: 0.118458
[23:28:52.462] iteration 427 : loss : 0.459493, loss_ce: 0.119045
[23:28:52.738] iteration 428 : loss : 0.444377, loss_ce: 0.151075
[23:28:53.013] iteration 429 : loss : 0.451324, loss_ce: 0.077976
[23:28:53.290] iteration 430 : loss : 0.473347, loss_ce: 0.135961
[23:28:53.569] iteration 431 : loss : 0.453325, loss_ce: 0.162579
[23:28:53.850] iteration 432 : loss : 0.485865, loss_ce: 0.159241
[23:28:54.129] iteration 433 : loss : 0.491708, loss_ce: 0.145044
[23:28:54.407] iteration 434 : loss : 0.454707, loss_ce: 0.142694
[23:28:54.688] iteration 435 : loss : 0.462202, loss_ce: 0.174782
[23:28:54.968] iteration 436 : loss : 0.453944, loss_ce: 0.128480
[23:28:55.245] iteration 437 : loss : 0.452730, loss_ce: 0.122009
[23:28:55.530] iteration 438 : loss : 0.423317, loss_ce: 0.117130
[23:28:55.810] iteration 439 : loss : 0.441148, loss_ce: 0.170203
[23:28:56.089] iteration 440 : loss : 0.453117, loss_ce: 0.132784
[23:28:56.384] iteration 441 : loss : 0.447405, loss_ce: 0.064180
[23:28:56.661] iteration 442 : loss : 0.417439, loss_ce: 0.096147
[23:28:56.942] iteration 443 : loss : 0.413637, loss_ce: 0.073499
[23:28:57.219] iteration 444 : loss : 0.457564, loss_ce: 0.140842
[23:28:57.498] iteration 445 : loss : 0.415572, loss_ce: 0.117212
[23:28:57.777] iteration 446 : loss : 0.451743, loss_ce: 0.135992
[23:28:58.057] iteration 447 : loss : 0.448179, loss_ce: 0.117714
[23:28:58.337] iteration 448 : loss : 0.435513, loss_ce: 0.099834
[23:28:58.618] iteration 449 : loss : 0.418475, loss_ce: 0.111399
[23:28:58.899] iteration 450 : loss : 0.437178, loss_ce: 0.118038
[23:28:59.178] iteration 451 : loss : 0.429332, loss_ce: 0.095785
[23:28:59.458] iteration 452 : loss : 0.443655, loss_ce: 0.103201
[23:28:59.737] iteration 453 : loss : 0.424697, loss_ce: 0.070706
[23:29:00.014] iteration 454 : loss : 0.419762, loss_ce: 0.119204
[23:29:00.298] iteration 455 : loss : 0.441127, loss_ce: 0.100083
[23:29:00.580] iteration 456 : loss : 0.401266, loss_ce: 0.056229
[23:29:00.866] iteration 457 : loss : 0.449245, loss_ce: 0.114895
[23:29:01.148] iteration 458 : loss : 0.440000, loss_ce: 0.109031
[23:29:01.426] iteration 459 : loss : 0.437615, loss_ce: 0.130172
[23:29:01.705] iteration 460 : loss : 0.460183, loss_ce: 0.151180
[23:29:02.004] iteration 461 : loss : 0.411679, loss_ce: 0.094906
[23:29:02.283] iteration 462 : loss : 0.429568, loss_ce: 0.137219
[23:29:02.588] iteration 463 : loss : 0.439721, loss_ce: 0.093194
[23:29:02.877] iteration 464 : loss : 0.430516, loss_ce: 0.127380
[23:29:03.168] iteration 465 : loss : 0.397592, loss_ce: 0.111846
[23:29:03.449] iteration 466 : loss : 0.426631, loss_ce: 0.113520
[23:29:03.730] iteration 467 : loss : 0.417665, loss_ce: 0.097983
[23:29:04.013] iteration 468 : loss : 0.407853, loss_ce: 0.112163
[23:29:04.311] iteration 469 : loss : 0.472893, loss_ce: 0.190498
[23:29:04.597] iteration 470 : loss : 0.415389, loss_ce: 0.159884
[23:29:04.882] iteration 471 : loss : 0.447359, loss_ce: 0.138371
[23:29:05.164] iteration 472 : loss : 0.433037, loss_ce: 0.106592
[23:29:05.446] iteration 473 : loss : 0.421724, loss_ce: 0.117081
[23:29:05.726] iteration 474 : loss : 0.430883, loss_ce: 0.121471
[23:29:06.004] iteration 475 : loss : 0.401154, loss_ce: 0.126149
[23:29:06.287] iteration 476 : loss : 0.451850, loss_ce: 0.165468
[23:29:06.565] iteration 477 : loss : 0.415318, loss_ce: 0.078322
[23:29:06.846] iteration 478 : loss : 0.431987, loss_ce: 0.092467
[23:29:07.126] iteration 479 : loss : 0.422503, loss_ce: 0.098828
[23:29:07.406] iteration 480 : loss : 0.461375, loss_ce: 0.109715
[23:29:07.698] iteration 481 : loss : 0.428975, loss_ce: 0.107933
[23:29:07.976] iteration 482 : loss : 0.424977, loss_ce: 0.114234
[23:29:08.260] iteration 483 : loss : 0.436137, loss_ce: 0.158694
[23:29:08.539] iteration 484 : loss : 0.443247, loss_ce: 0.080543
[23:29:08.816] iteration 485 : loss : 0.401895, loss_ce: 0.107127
[23:29:09.102] iteration 486 : loss : 0.394969, loss_ce: 0.083178
[23:29:09.395] iteration 487 : loss : 0.425204, loss_ce: 0.092011
[23:29:09.678] iteration 488 : loss : 0.434364, loss_ce: 0.065733
[23:29:09.972] iteration 489 : loss : 0.420110, loss_ce: 0.106575
[23:29:10.255] iteration 490 : loss : 0.437549, loss_ce: 0.153988
[23:29:10.548] iteration 491 : loss : 0.432635, loss_ce: 0.117258
[23:29:10.829] iteration 492 : loss : 0.405280, loss_ce: 0.082088
[23:29:11.108] iteration 493 : loss : 0.434064, loss_ce: 0.132540
[23:29:11.393] iteration 494 : loss : 0.399958, loss_ce: 0.087487
[23:29:11.677] iteration 495 : loss : 0.468991, loss_ce: 0.102757
[23:29:11.960] iteration 496 : loss : 0.444021, loss_ce: 0.095005
[23:29:12.243] iteration 497 : loss : 0.433347, loss_ce: 0.074705
[23:29:12.523] iteration 498 : loss : 0.451567, loss_ce: 0.154783
[23:29:12.811] iteration 499 : loss : 0.404316, loss_ce: 0.078325
[23:29:13.090] iteration 500 : loss : 0.429697, loss_ce: 0.058573
[23:29:13.380] iteration 501 : loss : 0.426580, loss_ce: 0.125551
[23:29:13.659] iteration 502 : loss : 0.449511, loss_ce: 0.091097
[23:29:13.938] iteration 503 : loss : 0.432835, loss_ce: 0.109466
[23:29:14.216] iteration 504 : loss : 0.467240, loss_ce: 0.188221
[23:29:14.493] iteration 505 : loss : 0.481897, loss_ce: 0.170794
[23:29:14.772] iteration 506 : loss : 0.435447, loss_ce: 0.145931
[23:29:15.050] iteration 507 : loss : 0.424504, loss_ce: 0.094345
[23:29:15.328] iteration 508 : loss : 0.456070, loss_ce: 0.137334
[23:29:15.606] iteration 509 : loss : 0.452233, loss_ce: 0.078745
[23:29:15.887] iteration 510 : loss : 0.466543, loss_ce: 0.134390
[23:29:16.167] iteration 511 : loss : 0.430328, loss_ce: 0.130566
[23:29:16.446] iteration 512 : loss : 0.462896, loss_ce: 0.204949
[23:29:16.723] iteration 513 : loss : 0.462685, loss_ce: 0.129128
[23:29:17.000] iteration 514 : loss : 0.411213, loss_ce: 0.085724
[23:29:17.281] iteration 515 : loss : 0.412725, loss_ce: 0.080530
[23:29:17.558] iteration 516 : loss : 0.447805, loss_ce: 0.112533
[23:29:17.838] iteration 517 : loss : 0.457092, loss_ce: 0.101664
[23:29:18.115] iteration 518 : loss : 0.451481, loss_ce: 0.112049
[23:29:18.391] iteration 519 : loss : 0.522214, loss_ce: 0.050088
[23:29:18.673] iteration 520 : loss : 0.448047, loss_ce: 0.134631
[23:29:18.978] iteration 521 : loss : 0.471764, loss_ce: 0.112461
[23:29:19.256] iteration 522 : loss : 0.435039, loss_ce: 0.145684
[23:29:19.536] iteration 523 : loss : 0.436862, loss_ce: 0.137218
[23:29:19.815] iteration 524 : loss : 0.430481, loss_ce: 0.140053
[23:29:20.092] iteration 525 : loss : 0.425024, loss_ce: 0.044029
[23:29:20.373] iteration 526 : loss : 0.437497, loss_ce: 0.058429
[23:29:20.651] iteration 527 : loss : 0.405825, loss_ce: 0.101798
[23:29:20.932] iteration 528 : loss : 0.384557, loss_ce: 0.082973
[23:29:21.213] iteration 529 : loss : 0.434374, loss_ce: 0.135063
[23:29:21.490] iteration 530 : loss : 0.431041, loss_ce: 0.129555
[23:29:21.771] iteration 531 : loss : 0.434945, loss_ce: 0.110358
[23:29:22.050] iteration 532 : loss : 0.423468, loss_ce: 0.118893
[23:29:22.330] iteration 533 : loss : 0.408750, loss_ce: 0.128014
[23:29:22.611] iteration 534 : loss : 0.440648, loss_ce: 0.094759
[23:29:22.891] iteration 535 : loss : 0.439930, loss_ce: 0.102798
[23:29:23.170] iteration 536 : loss : 0.449125, loss_ce: 0.135937
[23:29:23.446] iteration 537 : loss : 0.417465, loss_ce: 0.074051
[23:29:23.725] iteration 538 : loss : 0.416027, loss_ce: 0.114859
[23:29:24.002] iteration 539 : loss : 0.416672, loss_ce: 0.121988
[23:29:24.283] iteration 540 : loss : 0.470454, loss_ce: 0.182686
[23:29:24.583] iteration 541 : loss : 0.499499, loss_ce: 0.150219
[23:29:24.869] iteration 542 : loss : 0.412459, loss_ce: 0.096414
[23:29:25.150] iteration 543 : loss : 0.451370, loss_ce: 0.191153
[23:29:25.442] iteration 544 : loss : 0.424138, loss_ce: 0.090209
[23:29:25.722] iteration 545 : loss : 0.424240, loss_ce: 0.074688
[23:29:26.006] iteration 546 : loss : 0.418323, loss_ce: 0.100972
[23:29:26.291] iteration 547 : loss : 0.405531, loss_ce: 0.107376
[23:29:26.571] iteration 548 : loss : 0.407436, loss_ce: 0.098378
[23:29:26.854] iteration 549 : loss : 0.413706, loss_ce: 0.104701
[23:29:27.135] iteration 550 : loss : 0.431358, loss_ce: 0.080401
[23:29:27.416] iteration 551 : loss : 0.402210, loss_ce: 0.041875
[23:29:27.698] iteration 552 : loss : 0.444059, loss_ce: 0.176110
[23:29:27.976] iteration 553 : loss : 0.462951, loss_ce: 0.140122
[23:29:28.262] iteration 554 : loss : 0.456627, loss_ce: 0.132497
[23:29:28.540] iteration 555 : loss : 0.416506, loss_ce: 0.124583
[23:29:28.615] iteration 556 : loss : 0.456654, loss_ce: 0.106649
[23:29:48.743] iteration 557 : loss : 0.448013, loss_ce: 0.137748
[23:29:49.022] iteration 558 : loss : 0.380543, loss_ce: 0.102116
[23:29:49.306] iteration 559 : loss : 0.407482, loss_ce: 0.084233
[23:29:49.587] iteration 560 : loss : 0.427307, loss_ce: 0.156636
[23:29:49.882] iteration 561 : loss : 0.407259, loss_ce: 0.125707
[23:29:50.158] iteration 562 : loss : 0.400633, loss_ce: 0.110296
[23:29:50.435] iteration 563 : loss : 0.385661, loss_ce: 0.092012
[23:29:50.710] iteration 564 : loss : 0.398666, loss_ce: 0.094018
[23:29:50.988] iteration 565 : loss : 0.400550, loss_ce: 0.096571
[23:29:51.265] iteration 566 : loss : 0.395345, loss_ce: 0.086875
[23:29:51.542] iteration 567 : loss : 0.377124, loss_ce: 0.080822
[23:29:51.819] iteration 568 : loss : 0.411488, loss_ce: 0.127297
[23:29:52.093] iteration 569 : loss : 0.431177, loss_ce: 0.145684
[23:29:52.369] iteration 570 : loss : 0.424690, loss_ce: 0.144276
[23:29:52.646] iteration 571 : loss : 0.362830, loss_ce: 0.083444
[23:29:52.922] iteration 572 : loss : 0.416682, loss_ce: 0.140412
[23:29:53.200] iteration 573 : loss : 0.403956, loss_ce: 0.136185
[23:29:53.475] iteration 574 : loss : 0.382546, loss_ce: 0.109975
[23:29:53.753] iteration 575 : loss : 0.403897, loss_ce: 0.131782
[23:29:54.033] iteration 576 : loss : 0.400286, loss_ce: 0.121503
[23:29:54.313] iteration 577 : loss : 0.407573, loss_ce: 0.089038
[23:29:54.591] iteration 578 : loss : 0.383005, loss_ce: 0.075868
[23:29:54.866] iteration 579 : loss : 0.377210, loss_ce: 0.066905
[23:29:55.146] iteration 580 : loss : 0.394260, loss_ce: 0.104524
[23:29:55.442] iteration 581 : loss : 0.438313, loss_ce: 0.103694
[23:29:55.718] iteration 582 : loss : 0.455782, loss_ce: 0.113264
[23:29:55.994] iteration 583 : loss : 0.418524, loss_ce: 0.032480
[23:29:56.273] iteration 584 : loss : 0.403986, loss_ce: 0.096414
[23:29:56.550] iteration 585 : loss : 0.418767, loss_ce: 0.115487
[23:29:56.827] iteration 586 : loss : 0.414607, loss_ce: 0.080886
[23:29:57.103] iteration 587 : loss : 0.374710, loss_ce: 0.091865
[23:29:57.380] iteration 588 : loss : 0.434832, loss_ce: 0.114669
[23:29:57.658] iteration 589 : loss : 0.398517, loss_ce: 0.077441
[23:29:57.934] iteration 590 : loss : 0.347132, loss_ce: 0.110677
[23:29:58.208] iteration 591 : loss : 0.344867, loss_ce: 0.089880
[23:29:58.485] iteration 592 : loss : 0.387842, loss_ce: 0.117919
[23:29:58.763] iteration 593 : loss : 0.401669, loss_ce: 0.143663
[23:29:59.043] iteration 594 : loss : 0.368050, loss_ce: 0.091611
[23:29:59.322] iteration 595 : loss : 0.379636, loss_ce: 0.054459
[23:29:59.600] iteration 596 : loss : 0.406603, loss_ce: 0.091784
[23:29:59.878] iteration 597 : loss : 0.424781, loss_ce: 0.078263
[23:30:00.157] iteration 598 : loss : 0.411558, loss_ce: 0.067173
[23:30:00.436] iteration 599 : loss : 0.361639, loss_ce: 0.096796
[23:30:00.713] iteration 600 : loss : 0.409730, loss_ce: 0.139353
[23:30:01.009] iteration 601 : loss : 0.402550, loss_ce: 0.132886
[23:30:01.285] iteration 602 : loss : 0.429465, loss_ce: 0.069212
[23:30:01.564] iteration 603 : loss : 0.421764, loss_ce: 0.178211
[23:30:01.841] iteration 604 : loss : 0.385460, loss_ce: 0.075192
[23:30:02.117] iteration 605 : loss : 0.383720, loss_ce: 0.044872
[23:30:02.395] iteration 606 : loss : 0.365359, loss_ce: 0.033150
[23:30:02.672] iteration 607 : loss : 0.388651, loss_ce: 0.145632
[23:30:02.949] iteration 608 : loss : 0.411140, loss_ce: 0.121925
[23:30:03.226] iteration 609 : loss : 0.386747, loss_ce: 0.103725
[23:30:03.506] iteration 610 : loss : 0.379005, loss_ce: 0.113313
[23:30:03.783] iteration 611 : loss : 0.382810, loss_ce: 0.104174
[23:30:04.059] iteration 612 : loss : 0.400650, loss_ce: 0.120990
[23:30:04.338] iteration 613 : loss : 0.438634, loss_ce: 0.128931
[23:30:04.617] iteration 614 : loss : 0.391768, loss_ce: 0.105114
[23:30:04.893] iteration 615 : loss : 0.416361, loss_ce: 0.109829
[23:30:05.172] iteration 616 : loss : 0.364392, loss_ce: 0.064610
[23:30:05.451] iteration 617 : loss : 0.434003, loss_ce: 0.089798
[23:30:05.728] iteration 618 : loss : 0.380214, loss_ce: 0.136719
[23:30:06.006] iteration 619 : loss : 0.336503, loss_ce: 0.050239
[23:30:06.285] iteration 620 : loss : 0.440189, loss_ce: 0.087452
[23:30:06.582] iteration 621 : loss : 0.369668, loss_ce: 0.102721
[23:30:06.858] iteration 622 : loss : 0.377445, loss_ce: 0.094207
[23:30:07.135] iteration 623 : loss : 0.406385, loss_ce: 0.142783
[23:30:07.413] iteration 624 : loss : 0.379818, loss_ce: 0.067099
[23:30:07.690] iteration 625 : loss : 0.356453, loss_ce: 0.105635
[23:30:07.970] iteration 626 : loss : 0.339706, loss_ce: 0.054161
[23:30:08.247] iteration 627 : loss : 0.354684, loss_ce: 0.072195
[23:30:08.522] iteration 628 : loss : 0.414707, loss_ce: 0.069827
[23:30:08.796] iteration 629 : loss : 0.404959, loss_ce: 0.119489
[23:30:09.077] iteration 630 : loss : 0.450468, loss_ce: 0.060467
[23:30:09.356] iteration 631 : loss : 0.420666, loss_ce: 0.136458
[23:30:09.632] iteration 632 : loss : 0.369953, loss_ce: 0.125047
[23:30:09.909] iteration 633 : loss : 0.388781, loss_ce: 0.086248
[23:30:10.301] iteration 634 : loss : 0.441216, loss_ce: 0.122386
[23:30:10.592] iteration 635 : loss : 0.429466, loss_ce: 0.152223
[23:30:10.884] iteration 636 : loss : 0.391547, loss_ce: 0.135685
[23:30:11.175] iteration 637 : loss : 0.406116, loss_ce: 0.094978
[23:30:11.469] iteration 638 : loss : 0.372984, loss_ce: 0.081205
[23:30:11.756] iteration 639 : loss : 0.388375, loss_ce: 0.075358
[23:30:12.048] iteration 640 : loss : 0.357099, loss_ce: 0.059127
[23:30:12.361] iteration 641 : loss : 0.368377, loss_ce: 0.099928
[23:30:12.651] iteration 642 : loss : 0.406825, loss_ce: 0.111033
[23:30:12.945] iteration 643 : loss : 0.413194, loss_ce: 0.086816
[23:30:13.235] iteration 644 : loss : 0.421471, loss_ce: 0.110879
[23:30:13.527] iteration 645 : loss : 0.379300, loss_ce: 0.066630
[23:30:13.820] iteration 646 : loss : 0.397845, loss_ce: 0.123100
[23:30:14.108] iteration 647 : loss : 0.406856, loss_ce: 0.140189
[23:30:14.469] iteration 648 : loss : 0.412928, loss_ce: 0.154025
[23:30:14.765] iteration 649 : loss : 0.395015, loss_ce: 0.114821
[23:30:15.060] iteration 650 : loss : 0.429774, loss_ce: 0.182402
[23:30:15.363] iteration 651 : loss : 0.406930, loss_ce: 0.138838
[23:30:15.661] iteration 652 : loss : 0.414953, loss_ce: 0.132975
[23:30:15.955] iteration 653 : loss : 0.434373, loss_ce: 0.164263
[23:30:16.232] iteration 654 : loss : 0.360158, loss_ce: 0.107671
[23:30:16.512] iteration 655 : loss : 0.338564, loss_ce: 0.071100
[23:30:16.791] iteration 656 : loss : 0.377079, loss_ce: 0.096498
[23:30:17.069] iteration 657 : loss : 0.379122, loss_ce: 0.088040
[23:30:17.346] iteration 658 : loss : 0.377986, loss_ce: 0.090581
[23:30:17.628] iteration 659 : loss : 0.437239, loss_ce: 0.068204
[23:30:17.906] iteration 660 : loss : 0.376400, loss_ce: 0.099575
[23:30:18.203] iteration 661 : loss : 0.385415, loss_ce: 0.079802
[23:30:18.483] iteration 662 : loss : 0.376591, loss_ce: 0.127974
[23:30:18.763] iteration 663 : loss : 0.361972, loss_ce: 0.096080
[23:30:19.043] iteration 664 : loss : 0.339718, loss_ce: 0.064966
[23:30:19.323] iteration 665 : loss : 0.387263, loss_ce: 0.108845
[23:30:19.600] iteration 666 : loss : 0.376228, loss_ce: 0.152776
[23:30:19.879] iteration 667 : loss : 0.380072, loss_ce: 0.128237
[23:30:20.161] iteration 668 : loss : 0.352954, loss_ce: 0.130421
[23:30:20.442] iteration 669 : loss : 0.354690, loss_ce: 0.115079
[23:30:20.721] iteration 670 : loss : 0.377453, loss_ce: 0.112360
[23:30:21.004] iteration 671 : loss : 0.410083, loss_ce: 0.131681
[23:30:21.284] iteration 672 : loss : 0.388806, loss_ce: 0.116161
[23:30:21.567] iteration 673 : loss : 0.342824, loss_ce: 0.080036
[23:30:21.844] iteration 674 : loss : 0.345553, loss_ce: 0.062947
[23:30:22.126] iteration 675 : loss : 0.439862, loss_ce: 0.122711
[23:30:22.405] iteration 676 : loss : 0.419357, loss_ce: 0.113399
[23:30:22.688] iteration 677 : loss : 0.346004, loss_ce: 0.108850
[23:30:22.969] iteration 678 : loss : 0.360280, loss_ce: 0.098990
[23:30:23.255] iteration 679 : loss : 0.374388, loss_ce: 0.122325
[23:30:23.538] iteration 680 : loss : 0.405850, loss_ce: 0.066930
[23:30:23.833] iteration 681 : loss : 0.376159, loss_ce: 0.104290
[23:30:24.114] iteration 682 : loss : 0.335251, loss_ce: 0.093196
[23:30:24.393] iteration 683 : loss : 0.344789, loss_ce: 0.097773
[23:30:24.678] iteration 684 : loss : 0.355295, loss_ce: 0.084188
[23:30:24.956] iteration 685 : loss : 0.378717, loss_ce: 0.103087
[23:30:25.241] iteration 686 : loss : 0.343423, loss_ce: 0.131032
[23:30:25.521] iteration 687 : loss : 0.323089, loss_ce: 0.069761
[23:30:25.800] iteration 688 : loss : 0.362958, loss_ce: 0.094444
[23:30:26.081] iteration 689 : loss : 0.375955, loss_ce: 0.109090
[23:30:26.363] iteration 690 : loss : 0.390462, loss_ce: 0.098386
[23:30:26.644] iteration 691 : loss : 0.361774, loss_ce: 0.115695
[23:30:26.925] iteration 692 : loss : 0.333738, loss_ce: 0.052043
[23:30:27.205] iteration 693 : loss : 0.353693, loss_ce: 0.052850
[23:30:27.491] iteration 694 : loss : 0.354632, loss_ce: 0.106209
[23:30:27.567] iteration 695 : loss : 0.501893, loss_ce: 0.044125
[23:30:45.891] iteration 696 : loss : 0.343168, loss_ce: 0.084003
[23:30:46.174] iteration 697 : loss : 0.373030, loss_ce: 0.125537
[23:30:46.453] iteration 698 : loss : 0.369412, loss_ce: 0.114210
[23:30:46.734] iteration 699 : loss : 0.428299, loss_ce: 0.070636
[23:30:47.016] iteration 700 : loss : 0.357017, loss_ce: 0.057511
[23:30:47.314] iteration 701 : loss : 0.351527, loss_ce: 0.049978
[23:30:47.591] iteration 702 : loss : 0.460569, loss_ce: 0.111291
[23:30:47.870] iteration 703 : loss : 0.386644, loss_ce: 0.065885
[23:30:48.146] iteration 704 : loss : 0.374454, loss_ce: 0.081383
[23:30:48.423] iteration 705 : loss : 0.414950, loss_ce: 0.129656
[23:30:48.702] iteration 706 : loss : 0.425457, loss_ce: 0.174381
[23:30:48.977] iteration 707 : loss : 0.364328, loss_ce: 0.094238
[23:30:49.263] iteration 708 : loss : 0.384472, loss_ce: 0.107418
[23:30:49.541] iteration 709 : loss : 0.414679, loss_ce: 0.137516
[23:30:49.819] iteration 710 : loss : 0.363197, loss_ce: 0.109352
[23:30:50.097] iteration 711 : loss : 0.314040, loss_ce: 0.099253
[23:30:50.372] iteration 712 : loss : 0.334365, loss_ce: 0.072453
[23:30:50.650] iteration 713 : loss : 0.389362, loss_ce: 0.135750
[23:30:50.925] iteration 714 : loss : 0.359893, loss_ce: 0.085146
[23:30:51.207] iteration 715 : loss : 0.363224, loss_ce: 0.109709
[23:30:51.486] iteration 716 : loss : 0.346839, loss_ce: 0.106813
[23:30:51.764] iteration 717 : loss : 0.326552, loss_ce: 0.083122
[23:30:52.042] iteration 718 : loss : 0.380269, loss_ce: 0.109778
[23:30:52.320] iteration 719 : loss : 0.351277, loss_ce: 0.090995
[23:30:52.595] iteration 720 : loss : 0.333433, loss_ce: 0.128153
[23:30:52.892] iteration 721 : loss : 0.363981, loss_ce: 0.077114
[23:30:53.171] iteration 722 : loss : 0.311970, loss_ce: 0.057404
[23:30:53.450] iteration 723 : loss : 0.372751, loss_ce: 0.104814
[23:30:53.731] iteration 724 : loss : 0.352034, loss_ce: 0.079356
[23:30:54.008] iteration 725 : loss : 0.290458, loss_ce: 0.083041
[23:30:54.293] iteration 726 : loss : 0.345965, loss_ce: 0.084011
[23:30:54.571] iteration 727 : loss : 0.337399, loss_ce: 0.097111
[23:30:54.846] iteration 728 : loss : 0.368367, loss_ce: 0.091321
[23:30:55.126] iteration 729 : loss : 0.306515, loss_ce: 0.073569
[23:30:55.404] iteration 730 : loss : 0.389948, loss_ce: 0.112821
[23:30:55.682] iteration 731 : loss : 0.321207, loss_ce: 0.097289
[23:30:55.965] iteration 732 : loss : 0.345321, loss_ce: 0.106804
[23:30:56.241] iteration 733 : loss : 0.374086, loss_ce: 0.043015
[23:30:56.518] iteration 734 : loss : 0.329177, loss_ce: 0.076501
[23:30:56.798] iteration 735 : loss : 0.354871, loss_ce: 0.109666
[23:30:57.078] iteration 736 : loss : 0.354236, loss_ce: 0.084524
[23:30:57.354] iteration 737 : loss : 0.362464, loss_ce: 0.136573
[23:30:57.632] iteration 738 : loss : 0.323053, loss_ce: 0.094479
[23:30:57.912] iteration 739 : loss : 0.344784, loss_ce: 0.073244
[23:30:58.191] iteration 740 : loss : 0.307694, loss_ce: 0.073469
[23:30:58.484] iteration 741 : loss : 0.326654, loss_ce: 0.111702
[23:30:58.766] iteration 742 : loss : 0.366963, loss_ce: 0.083333
[23:30:59.045] iteration 743 : loss : 0.378110, loss_ce: 0.167762
[23:30:59.327] iteration 744 : loss : 0.321327, loss_ce: 0.151560
[23:30:59.602] iteration 745 : loss : 0.327790, loss_ce: 0.073184
[23:30:59.879] iteration 746 : loss : 0.370874, loss_ce: 0.098674
[23:31:00.161] iteration 747 : loss : 0.387473, loss_ce: 0.100384
[23:31:00.445] iteration 748 : loss : 0.335779, loss_ce: 0.097872
[23:31:00.725] iteration 749 : loss : 0.344828, loss_ce: 0.114599
[23:31:01.009] iteration 750 : loss : 0.311389, loss_ce: 0.097777
[23:31:01.286] iteration 751 : loss : 0.336038, loss_ce: 0.075681
[23:31:01.567] iteration 752 : loss : 0.332630, loss_ce: 0.084712
[23:31:01.846] iteration 753 : loss : 0.354607, loss_ce: 0.085128
[23:31:02.124] iteration 754 : loss : 0.340923, loss_ce: 0.059379
[23:31:02.407] iteration 755 : loss : 0.325243, loss_ce: 0.092006
[23:31:02.684] iteration 756 : loss : 0.292621, loss_ce: 0.105781
[23:31:02.965] iteration 757 : loss : 0.337279, loss_ce: 0.116915
[23:31:03.248] iteration 758 : loss : 0.336707, loss_ce: 0.054925
[23:31:03.528] iteration 759 : loss : 0.265775, loss_ce: 0.055662
[23:31:03.805] iteration 760 : loss : 0.328929, loss_ce: 0.067411
[23:31:04.100] iteration 761 : loss : 0.277778, loss_ce: 0.065327
[23:31:04.377] iteration 762 : loss : 0.306699, loss_ce: 0.058398
[23:31:04.655] iteration 763 : loss : 0.329246, loss_ce: 0.071053
[23:31:04.935] iteration 764 : loss : 0.291837, loss_ce: 0.086398
[23:31:05.213] iteration 765 : loss : 0.356564, loss_ce: 0.088576
[23:31:05.495] iteration 766 : loss : 0.322422, loss_ce: 0.097861
[23:31:05.772] iteration 767 : loss : 0.354605, loss_ce: 0.073421
[23:31:06.051] iteration 768 : loss : 0.357111, loss_ce: 0.086660
[23:31:06.331] iteration 769 : loss : 0.323729, loss_ce: 0.097684
[23:31:06.610] iteration 770 : loss : 0.375301, loss_ce: 0.082691
[23:31:06.891] iteration 771 : loss : 0.280617, loss_ce: 0.083090
[23:31:07.167] iteration 772 : loss : 0.335891, loss_ce: 0.138717
[23:31:07.448] iteration 773 : loss : 0.313896, loss_ce: 0.085585
[23:31:07.729] iteration 774 : loss : 0.302667, loss_ce: 0.086324
[23:31:08.006] iteration 775 : loss : 0.334955, loss_ce: 0.064488
[23:31:08.289] iteration 776 : loss : 0.303316, loss_ce: 0.078183
[23:31:08.566] iteration 777 : loss : 0.289296, loss_ce: 0.047678
[23:31:08.846] iteration 778 : loss : 0.316999, loss_ce: 0.071767
[23:31:09.128] iteration 779 : loss : 0.282955, loss_ce: 0.043241
[23:31:09.407] iteration 780 : loss : 0.298129, loss_ce: 0.088334
[23:31:09.702] iteration 781 : loss : 0.341776, loss_ce: 0.057179
[23:31:09.977] iteration 782 : loss : 0.307181, loss_ce: 0.043299
[23:31:10.256] iteration 783 : loss : 0.302092, loss_ce: 0.084410
[23:31:10.539] iteration 784 : loss : 0.291459, loss_ce: 0.080856
[23:31:10.815] iteration 785 : loss : 0.316199, loss_ce: 0.078711
[23:31:11.095] iteration 786 : loss : 0.287111, loss_ce: 0.082909
[23:31:11.374] iteration 787 : loss : 0.299573, loss_ce: 0.088282
[23:31:11.652] iteration 788 : loss : 0.329038, loss_ce: 0.061368
[23:31:11.932] iteration 789 : loss : 0.334613, loss_ce: 0.086620
[23:31:12.212] iteration 790 : loss : 0.319125, loss_ce: 0.094209
[23:31:12.492] iteration 791 : loss : 0.303392, loss_ce: 0.084570
[23:31:12.774] iteration 792 : loss : 0.273379, loss_ce: 0.086180
[23:31:13.050] iteration 793 : loss : 0.349549, loss_ce: 0.097672
[23:31:13.330] iteration 794 : loss : 0.264194, loss_ce: 0.066776
[23:31:13.613] iteration 795 : loss : 0.321976, loss_ce: 0.086800
[23:31:13.894] iteration 796 : loss : 0.348130, loss_ce: 0.125930
[23:31:14.176] iteration 797 : loss : 0.260204, loss_ce: 0.075742
[23:31:14.453] iteration 798 : loss : 0.338213, loss_ce: 0.031695
[23:31:14.735] iteration 799 : loss : 0.308782, loss_ce: 0.060267
[23:31:15.012] iteration 800 : loss : 0.311322, loss_ce: 0.095306
[23:31:15.309] iteration 801 : loss : 0.305451, loss_ce: 0.050255
[23:31:15.593] iteration 802 : loss : 0.323228, loss_ce: 0.034717
[23:31:15.869] iteration 803 : loss : 0.260882, loss_ce: 0.056130
[23:31:16.148] iteration 804 : loss : 0.349802, loss_ce: 0.091861
[23:31:16.428] iteration 805 : loss : 0.286388, loss_ce: 0.075687
[23:31:16.703] iteration 806 : loss : 0.291298, loss_ce: 0.052203
[23:31:16.983] iteration 807 : loss : 0.316231, loss_ce: 0.076834
[23:31:17.265] iteration 808 : loss : 0.329175, loss_ce: 0.116422
[23:31:17.542] iteration 809 : loss : 0.282237, loss_ce: 0.063349
[23:31:17.826] iteration 810 : loss : 0.315290, loss_ce: 0.035590
[23:31:18.107] iteration 811 : loss : 0.280642, loss_ce: 0.070718
[23:31:18.386] iteration 812 : loss : 0.335699, loss_ce: 0.096681
[23:31:18.665] iteration 813 : loss : 0.325018, loss_ce: 0.103161
[23:31:18.942] iteration 814 : loss : 0.311422, loss_ce: 0.063032
[23:31:19.221] iteration 815 : loss : 0.323681, loss_ce: 0.106534
[23:31:19.507] iteration 816 : loss : 0.259901, loss_ce: 0.054435
[23:31:19.783] iteration 817 : loss : 0.281392, loss_ce: 0.064175
[23:31:20.067] iteration 818 : loss : 0.293499, loss_ce: 0.073276
[23:31:20.349] iteration 819 : loss : 0.298475, loss_ce: 0.102536
[23:31:20.637] iteration 820 : loss : 0.390673, loss_ce: 0.087896
[23:31:20.952] iteration 821 : loss : 0.352906, loss_ce: 0.162454
[23:31:21.232] iteration 822 : loss : 0.338203, loss_ce: 0.125468
[23:31:21.516] iteration 823 : loss : 0.343714, loss_ce: 0.088171
[23:31:21.799] iteration 824 : loss : 0.352272, loss_ce: 0.097963
[23:31:22.084] iteration 825 : loss : 0.290503, loss_ce: 0.100749
[23:31:22.370] iteration 826 : loss : 0.285503, loss_ce: 0.119526
[23:31:22.652] iteration 827 : loss : 0.325841, loss_ce: 0.074250
[23:31:22.935] iteration 828 : loss : 0.312831, loss_ce: 0.072260
[23:31:23.219] iteration 829 : loss : 0.328142, loss_ce: 0.069606
[23:31:23.498] iteration 830 : loss : 0.354729, loss_ce: 0.081316
[23:31:23.782] iteration 831 : loss : 0.305701, loss_ce: 0.116659
[23:31:24.065] iteration 832 : loss : 0.304673, loss_ce: 0.087414
[23:31:24.347] iteration 833 : loss : 0.301717, loss_ce: 0.096662
[23:31:24.427] iteration 834 : loss : 0.522561, loss_ce: 0.026580
[23:31:42.066] iteration 835 : loss : 0.322165, loss_ce: 0.111163
[23:31:42.350] iteration 836 : loss : 0.295352, loss_ce: 0.091060
[23:31:42.634] iteration 837 : loss : 0.315378, loss_ce: 0.044563
[23:31:42.915] iteration 838 : loss : 0.352893, loss_ce: 0.143837
[23:31:43.199] iteration 839 : loss : 0.319036, loss_ce: 0.074447
[23:31:43.471] iteration 840 : loss : 0.286229, loss_ce: 0.059422
[23:31:43.767] iteration 841 : loss : 0.295625, loss_ce: 0.060799
[23:31:44.043] iteration 842 : loss : 0.317423, loss_ce: 0.093681
[23:31:44.325] iteration 843 : loss : 0.306301, loss_ce: 0.048452
[23:31:44.604] iteration 844 : loss : 0.293543, loss_ce: 0.044360
[23:31:44.880] iteration 845 : loss : 0.304873, loss_ce: 0.136660
[23:31:45.157] iteration 846 : loss : 0.295262, loss_ce: 0.067694
[23:31:45.434] iteration 847 : loss : 0.278085, loss_ce: 0.098346
[23:31:45.710] iteration 848 : loss : 0.394334, loss_ce: 0.105646
[23:31:45.987] iteration 849 : loss : 0.298419, loss_ce: 0.075394
[23:31:46.266] iteration 850 : loss : 0.313633, loss_ce: 0.081787
[23:31:46.542] iteration 851 : loss : 0.281494, loss_ce: 0.099834
[23:31:46.821] iteration 852 : loss : 0.328548, loss_ce: 0.040210
[23:31:47.096] iteration 853 : loss : 0.286247, loss_ce: 0.080526
[23:31:47.375] iteration 854 : loss : 0.262857, loss_ce: 0.063611
[23:31:47.651] iteration 855 : loss : 0.319757, loss_ce: 0.089065
[23:31:47.933] iteration 856 : loss : 0.267738, loss_ce: 0.100253
[23:31:48.210] iteration 857 : loss : 0.287572, loss_ce: 0.079005
[23:31:48.490] iteration 858 : loss : 0.251760, loss_ce: 0.079576
[23:31:48.771] iteration 859 : loss : 0.250154, loss_ce: 0.091157
[23:31:49.048] iteration 860 : loss : 0.260255, loss_ce: 0.109720
[23:31:49.344] iteration 861 : loss : 0.248377, loss_ce: 0.075787
[23:31:49.622] iteration 862 : loss : 0.234783, loss_ce: 0.062864
[23:31:49.900] iteration 863 : loss : 0.350803, loss_ce: 0.134492
[23:31:50.181] iteration 864 : loss : 0.317232, loss_ce: 0.067320
[23:31:50.461] iteration 865 : loss : 0.301460, loss_ce: 0.074798
[23:31:50.735] iteration 866 : loss : 0.320693, loss_ce: 0.080602
[23:31:51.015] iteration 867 : loss : 0.332894, loss_ce: 0.163525
[23:31:51.293] iteration 868 : loss : 0.322499, loss_ce: 0.130551
[23:31:51.572] iteration 869 : loss : 0.325252, loss_ce: 0.049880
[23:31:51.850] iteration 870 : loss : 0.367808, loss_ce: 0.103131
[23:31:52.128] iteration 871 : loss : 0.357288, loss_ce: 0.115208
[23:31:52.407] iteration 872 : loss : 0.263824, loss_ce: 0.055862
[23:31:52.684] iteration 873 : loss : 0.266998, loss_ce: 0.066896
[23:31:52.959] iteration 874 : loss : 0.341352, loss_ce: 0.113110
[23:31:53.238] iteration 875 : loss : 0.352581, loss_ce: 0.139658
[23:31:53.517] iteration 876 : loss : 0.325099, loss_ce: 0.090946
[23:31:53.793] iteration 877 : loss : 0.348847, loss_ce: 0.059857
[23:31:54.069] iteration 878 : loss : 0.306155, loss_ce: 0.092649
[23:31:54.350] iteration 879 : loss : 0.344092, loss_ce: 0.066514
[23:31:54.627] iteration 880 : loss : 0.302553, loss_ce: 0.095379
[23:31:54.922] iteration 881 : loss : 0.346659, loss_ce: 0.101115
[23:31:55.196] iteration 882 : loss : 0.264807, loss_ce: 0.053234
[23:31:55.477] iteration 883 : loss : 0.240615, loss_ce: 0.073741
[23:31:55.757] iteration 884 : loss : 0.293830, loss_ce: 0.097820
[23:31:56.035] iteration 885 : loss : 0.329051, loss_ce: 0.110188
[23:31:56.314] iteration 886 : loss : 0.267107, loss_ce: 0.123477
[23:31:56.590] iteration 887 : loss : 0.308719, loss_ce: 0.043184
[23:31:56.869] iteration 888 : loss : 0.240109, loss_ce: 0.053167
[23:31:57.149] iteration 889 : loss : 0.254353, loss_ce: 0.059519
[23:31:57.425] iteration 890 : loss : 0.265082, loss_ce: 0.075762
[23:31:57.705] iteration 891 : loss : 0.231214, loss_ce: 0.052221
[23:31:57.983] iteration 892 : loss : 0.299952, loss_ce: 0.130519
[23:31:58.260] iteration 893 : loss : 0.323808, loss_ce: 0.041605
[23:31:58.535] iteration 894 : loss : 0.326311, loss_ce: 0.038028
[23:31:58.812] iteration 895 : loss : 0.293287, loss_ce: 0.099403
[23:31:59.092] iteration 896 : loss : 0.227816, loss_ce: 0.050577
[23:31:59.368] iteration 897 : loss : 0.253119, loss_ce: 0.092320
[23:31:59.648] iteration 898 : loss : 0.254948, loss_ce: 0.033928
[23:31:59.928] iteration 899 : loss : 0.218528, loss_ce: 0.032144
[23:32:00.211] iteration 900 : loss : 0.326427, loss_ce: 0.101081
[23:32:00.509] iteration 901 : loss : 0.287199, loss_ce: 0.040859
[23:32:00.788] iteration 902 : loss : 0.264808, loss_ce: 0.076609
[23:32:01.065] iteration 903 : loss : 0.249149, loss_ce: 0.064174
[23:32:01.347] iteration 904 : loss : 0.281493, loss_ce: 0.118025
[23:32:01.622] iteration 905 : loss : 0.261940, loss_ce: 0.104201
[23:32:01.903] iteration 906 : loss : 0.279957, loss_ce: 0.072967
[23:32:02.183] iteration 907 : loss : 0.313859, loss_ce: 0.030502
[23:32:02.460] iteration 908 : loss : 0.290788, loss_ce: 0.071492
[23:32:02.738] iteration 909 : loss : 0.270217, loss_ce: 0.054268
[23:32:03.014] iteration 910 : loss : 0.317855, loss_ce: 0.084804
[23:32:03.289] iteration 911 : loss : 0.331098, loss_ce: 0.123864
[23:32:03.565] iteration 912 : loss : 0.288996, loss_ce: 0.064856
[23:32:03.842] iteration 913 : loss : 0.311020, loss_ce: 0.080393
[23:32:04.121] iteration 914 : loss : 0.292687, loss_ce: 0.082371
[23:32:04.403] iteration 915 : loss : 0.288271, loss_ce: 0.095316
[23:32:04.679] iteration 916 : loss : 0.232064, loss_ce: 0.049205
[23:32:04.958] iteration 917 : loss : 0.281336, loss_ce: 0.049381
[23:32:05.236] iteration 918 : loss : 0.294600, loss_ce: 0.095669
[23:32:05.514] iteration 919 : loss : 0.266640, loss_ce: 0.065790
[23:32:05.795] iteration 920 : loss : 0.248956, loss_ce: 0.062998
[23:32:06.094] iteration 921 : loss : 0.228898, loss_ce: 0.091704
[23:32:06.372] iteration 922 : loss : 0.264742, loss_ce: 0.062335
[23:32:06.652] iteration 923 : loss : 0.352501, loss_ce: 0.090539
[23:32:06.929] iteration 924 : loss : 0.327844, loss_ce: 0.056141
[23:32:07.207] iteration 925 : loss : 0.265912, loss_ce: 0.063315
[23:32:07.484] iteration 926 : loss : 0.281781, loss_ce: 0.044972
[23:32:07.763] iteration 927 : loss : 0.253057, loss_ce: 0.062140
[23:32:08.045] iteration 928 : loss : 0.257136, loss_ce: 0.065957
[23:32:08.320] iteration 929 : loss : 0.255999, loss_ce: 0.062583
[23:32:08.598] iteration 930 : loss : 0.234851, loss_ce: 0.050532
[23:32:08.875] iteration 931 : loss : 0.370694, loss_ce: 0.076915
[23:32:09.155] iteration 932 : loss : 0.286169, loss_ce: 0.055262
[23:32:09.434] iteration 933 : loss : 0.278591, loss_ce: 0.044573
[23:32:09.711] iteration 934 : loss : 0.216768, loss_ce: 0.087925
[23:32:09.990] iteration 935 : loss : 0.276252, loss_ce: 0.114294
[23:32:10.270] iteration 936 : loss : 0.278820, loss_ce: 0.060435
[23:32:10.546] iteration 937 : loss : 0.247179, loss_ce: 0.073028
[23:32:10.824] iteration 938 : loss : 0.250369, loss_ce: 0.078819
[23:32:11.099] iteration 939 : loss : 0.259525, loss_ce: 0.060455
[23:32:11.382] iteration 940 : loss : 0.279521, loss_ce: 0.090109
[23:32:11.678] iteration 941 : loss : 0.288215, loss_ce: 0.098707
[23:32:11.953] iteration 942 : loss : 0.249558, loss_ce: 0.068180
[23:32:12.233] iteration 943 : loss : 0.303611, loss_ce: 0.049040
[23:32:12.511] iteration 944 : loss : 0.261656, loss_ce: 0.102788
[23:32:12.788] iteration 945 : loss : 0.271326, loss_ce: 0.041896
[23:32:13.065] iteration 946 : loss : 0.290791, loss_ce: 0.092501
[23:32:13.343] iteration 947 : loss : 0.265911, loss_ce: 0.083925
[23:32:13.623] iteration 948 : loss : 0.324576, loss_ce: 0.049349
[23:32:13.902] iteration 949 : loss : 0.292546, loss_ce: 0.097595
[23:32:14.177] iteration 950 : loss : 0.292350, loss_ce: 0.057229
[23:32:14.457] iteration 951 : loss : 0.236975, loss_ce: 0.065147
[23:32:14.735] iteration 952 : loss : 0.260150, loss_ce: 0.047426
[23:32:15.013] iteration 953 : loss : 0.283560, loss_ce: 0.102324
[23:32:15.295] iteration 954 : loss : 0.330571, loss_ce: 0.104674
[23:32:15.572] iteration 955 : loss : 0.321820, loss_ce: 0.087363
[23:32:15.849] iteration 956 : loss : 0.295958, loss_ce: 0.066791
[23:32:16.127] iteration 957 : loss : 0.257555, loss_ce: 0.135106
[23:32:16.407] iteration 958 : loss : 0.259987, loss_ce: 0.053117
[23:32:16.685] iteration 959 : loss : 0.271237, loss_ce: 0.088840
[23:32:16.962] iteration 960 : loss : 0.347897, loss_ce: 0.059214
[23:32:17.259] iteration 961 : loss : 0.250052, loss_ce: 0.074921
[23:32:17.538] iteration 962 : loss : 0.237807, loss_ce: 0.064171
[23:32:17.814] iteration 963 : loss : 0.299584, loss_ce: 0.072577
[23:32:18.097] iteration 964 : loss : 0.360303, loss_ce: 0.073777
[23:32:18.377] iteration 965 : loss : 0.310531, loss_ce: 0.036649
[23:32:18.663] iteration 966 : loss : 0.264046, loss_ce: 0.086017
[23:32:18.949] iteration 967 : loss : 0.261222, loss_ce: 0.088717
[23:32:19.227] iteration 968 : loss : 0.362097, loss_ce: 0.101997
[23:32:19.508] iteration 969 : loss : 0.324470, loss_ce: 0.062746
[23:32:19.792] iteration 970 : loss : 0.337261, loss_ce: 0.079234
[23:32:20.069] iteration 971 : loss : 0.282008, loss_ce: 0.070219
[23:32:20.354] iteration 972 : loss : 0.307473, loss_ce: 0.079980
[23:32:20.431] iteration 973 : loss : 0.312060, loss_ce: 0.041580
[23:32:39.026] iteration 974 : loss : 0.269500, loss_ce: 0.053309
[23:32:39.308] iteration 975 : loss : 0.333164, loss_ce: 0.072719
[23:32:39.588] iteration 976 : loss : 0.379151, loss_ce: 0.015761
[23:32:39.867] iteration 977 : loss : 0.286561, loss_ce: 0.095394
[23:32:40.150] iteration 978 : loss : 0.285460, loss_ce: 0.131694
[23:32:40.432] iteration 979 : loss : 0.309014, loss_ce: 0.038913
[23:32:40.709] iteration 980 : loss : 0.279692, loss_ce: 0.119841
[23:32:41.004] iteration 981 : loss : 0.388051, loss_ce: 0.038402
[23:32:41.281] iteration 982 : loss : 0.317632, loss_ce: 0.060313
[23:32:41.556] iteration 983 : loss : 0.273220, loss_ce: 0.048516
[23:32:41.834] iteration 984 : loss : 0.330385, loss_ce: 0.053831
[23:32:42.112] iteration 985 : loss : 0.327771, loss_ce: 0.074685
[23:32:42.387] iteration 986 : loss : 0.242731, loss_ce: 0.057554
[23:32:42.664] iteration 987 : loss : 0.260294, loss_ce: 0.064871
[23:32:42.942] iteration 988 : loss : 0.242916, loss_ce: 0.055200
[23:32:43.219] iteration 989 : loss : 0.269705, loss_ce: 0.063536
[23:32:43.498] iteration 990 : loss : 0.222005, loss_ce: 0.086648
[23:32:43.772] iteration 991 : loss : 0.266161, loss_ce: 0.113607
[23:32:44.050] iteration 992 : loss : 0.161681, loss_ce: 0.029883
[23:32:44.326] iteration 993 : loss : 0.248830, loss_ce: 0.072948
[23:32:44.604] iteration 994 : loss : 0.250729, loss_ce: 0.070447
[23:32:44.884] iteration 995 : loss : 0.280839, loss_ce: 0.133210
[23:32:45.159] iteration 996 : loss : 0.297219, loss_ce: 0.072366
[23:32:45.437] iteration 997 : loss : 0.183596, loss_ce: 0.046491
[23:32:45.718] iteration 998 : loss : 0.360312, loss_ce: 0.048603
[23:32:45.992] iteration 999 : loss : 0.255006, loss_ce: 0.086819
[23:32:46.268] iteration 1000 : loss : 0.274525, loss_ce: 0.066596
[23:32:46.563] iteration 1001 : loss : 0.214928, loss_ce: 0.053361
[23:32:46.838] iteration 1002 : loss : 0.259555, loss_ce: 0.065297
[23:32:47.116] iteration 1003 : loss : 0.232533, loss_ce: 0.090043
[23:32:47.393] iteration 1004 : loss : 0.283807, loss_ce: 0.075251
[23:32:47.670] iteration 1005 : loss : 0.227611, loss_ce: 0.094132
[23:32:47.950] iteration 1006 : loss : 0.239696, loss_ce: 0.074152
[23:32:48.228] iteration 1007 : loss : 0.282975, loss_ce: 0.064301
[23:32:48.508] iteration 1008 : loss : 0.254280, loss_ce: 0.038966
[23:32:48.784] iteration 1009 : loss : 0.285994, loss_ce: 0.101777
[23:32:49.064] iteration 1010 : loss : 0.198220, loss_ce: 0.060935
[23:32:49.344] iteration 1011 : loss : 0.296850, loss_ce: 0.064541
[23:32:49.621] iteration 1012 : loss : 0.246970, loss_ce: 0.068683
[23:32:49.899] iteration 1013 : loss : 0.261080, loss_ce: 0.071846
[23:32:50.180] iteration 1014 : loss : 0.271442, loss_ce: 0.093500
[23:32:50.456] iteration 1015 : loss : 0.250139, loss_ce: 0.063168
[23:32:50.733] iteration 1016 : loss : 0.211930, loss_ce: 0.067737
[23:32:51.010] iteration 1017 : loss : 0.255462, loss_ce: 0.066938
[23:32:51.291] iteration 1018 : loss : 0.274830, loss_ce: 0.063647
[23:32:51.567] iteration 1019 : loss : 0.346116, loss_ce: 0.060036
[23:32:51.843] iteration 1020 : loss : 0.268842, loss_ce: 0.111414
[23:32:52.147] iteration 1021 : loss : 0.314619, loss_ce: 0.063290
[23:32:52.424] iteration 1022 : loss : 0.246933, loss_ce: 0.046511
[23:32:52.698] iteration 1023 : loss : 0.212301, loss_ce: 0.055947
[23:32:52.977] iteration 1024 : loss : 0.302689, loss_ce: 0.092548
[23:32:53.254] iteration 1025 : loss : 0.288999, loss_ce: 0.078781
[23:32:53.534] iteration 1026 : loss : 0.235807, loss_ce: 0.069436
[23:32:53.810] iteration 1027 : loss : 0.291268, loss_ce: 0.041650
[23:32:54.087] iteration 1028 : loss : 0.272326, loss_ce: 0.083510
[23:32:54.370] iteration 1029 : loss : 0.254029, loss_ce: 0.105622
[23:32:54.650] iteration 1030 : loss : 0.268585, loss_ce: 0.141041
[23:32:54.931] iteration 1031 : loss : 0.273555, loss_ce: 0.080474
[23:32:55.212] iteration 1032 : loss : 0.218713, loss_ce: 0.065455
[23:32:55.492] iteration 1033 : loss : 0.240429, loss_ce: 0.060584
[23:32:55.774] iteration 1034 : loss : 0.226539, loss_ce: 0.089871
[23:32:56.055] iteration 1035 : loss : 0.248448, loss_ce: 0.063225
[23:32:56.334] iteration 1036 : loss : 0.267019, loss_ce: 0.113079
[23:32:56.617] iteration 1037 : loss : 0.196690, loss_ce: 0.093797
[23:32:56.896] iteration 1038 : loss : 0.216761, loss_ce: 0.055219
[23:32:57.174] iteration 1039 : loss : 0.245790, loss_ce: 0.069144
[23:32:57.453] iteration 1040 : loss : 0.233434, loss_ce: 0.050990
[23:32:57.750] iteration 1041 : loss : 0.214960, loss_ce: 0.033484
[23:32:58.036] iteration 1042 : loss : 0.253621, loss_ce: 0.048044
[23:32:58.312] iteration 1043 : loss : 0.231649, loss_ce: 0.082405
[23:32:58.592] iteration 1044 : loss : 0.265581, loss_ce: 0.078859
[23:32:58.875] iteration 1045 : loss : 0.216093, loss_ce: 0.051114
[23:32:59.157] iteration 1046 : loss : 0.288476, loss_ce: 0.108446
[23:32:59.442] iteration 1047 : loss : 0.218111, loss_ce: 0.041198
[23:32:59.720] iteration 1048 : loss : 0.171841, loss_ce: 0.036981
[23:32:59.996] iteration 1049 : loss : 0.297621, loss_ce: 0.070111
[23:33:00.283] iteration 1050 : loss : 0.252676, loss_ce: 0.024900
[23:33:00.563] iteration 1051 : loss : 0.175260, loss_ce: 0.043868
[23:33:00.846] iteration 1052 : loss : 0.230870, loss_ce: 0.056608
[23:33:01.130] iteration 1053 : loss : 0.260053, loss_ce: 0.074928
[23:33:01.410] iteration 1054 : loss : 0.303516, loss_ce: 0.079746
[23:33:01.690] iteration 1055 : loss : 0.240460, loss_ce: 0.069409
[23:33:01.969] iteration 1056 : loss : 0.302359, loss_ce: 0.080678
[23:33:02.250] iteration 1057 : loss : 0.216940, loss_ce: 0.072233
[23:33:02.528] iteration 1058 : loss : 0.243619, loss_ce: 0.058489
[23:33:02.808] iteration 1059 : loss : 0.253665, loss_ce: 0.076363
[23:33:03.090] iteration 1060 : loss : 0.291891, loss_ce: 0.056700
[23:33:03.388] iteration 1061 : loss : 0.321315, loss_ce: 0.058671
[23:33:03.662] iteration 1062 : loss : 0.236678, loss_ce: 0.108730
[23:33:03.942] iteration 1063 : loss : 0.165683, loss_ce: 0.039108
[23:33:04.220] iteration 1064 : loss : 0.336545, loss_ce: 0.034662
[23:33:04.503] iteration 1065 : loss : 0.283412, loss_ce: 0.070238
[23:33:04.785] iteration 1066 : loss : 0.264069, loss_ce: 0.057447
[23:33:05.066] iteration 1067 : loss : 0.240389, loss_ce: 0.055951
[23:33:05.347] iteration 1068 : loss : 0.299658, loss_ce: 0.047556
[23:33:05.627] iteration 1069 : loss : 0.237934, loss_ce: 0.083809
[23:33:05.906] iteration 1070 : loss : 0.257924, loss_ce: 0.058491
[23:33:06.185] iteration 1071 : loss : 0.216739, loss_ce: 0.107846
[23:33:06.464] iteration 1072 : loss : 0.406149, loss_ce: 0.016900
[23:33:06.746] iteration 1073 : loss : 0.309266, loss_ce: 0.102160
[23:33:07.027] iteration 1074 : loss : 0.266358, loss_ce: 0.078871
[23:33:07.303] iteration 1075 : loss : 0.264101, loss_ce: 0.080085
[23:33:07.586] iteration 1076 : loss : 0.229372, loss_ce: 0.050982
[23:33:07.863] iteration 1077 : loss : 0.184956, loss_ce: 0.058000
[23:33:08.144] iteration 1078 : loss : 0.245788, loss_ce: 0.053936
[23:33:08.424] iteration 1079 : loss : 0.276904, loss_ce: 0.121617
[23:33:08.702] iteration 1080 : loss : 0.219415, loss_ce: 0.045658
[23:33:09.003] iteration 1081 : loss : 0.194197, loss_ce: 0.062386
[23:33:09.281] iteration 1082 : loss : 0.244551, loss_ce: 0.049656
[23:33:09.559] iteration 1083 : loss : 0.218358, loss_ce: 0.063002
[23:33:09.842] iteration 1084 : loss : 0.323315, loss_ce: 0.072521
[23:33:10.122] iteration 1085 : loss : 0.246973, loss_ce: 0.044729
[23:33:10.405] iteration 1086 : loss : 0.252550, loss_ce: 0.062834
[23:33:10.683] iteration 1087 : loss : 0.271010, loss_ce: 0.102550
[23:33:10.962] iteration 1088 : loss : 0.264542, loss_ce: 0.066352
[23:33:11.242] iteration 1089 : loss : 0.286699, loss_ce: 0.067608
[23:33:11.522] iteration 1090 : loss : 0.193294, loss_ce: 0.046103
[23:33:11.800] iteration 1091 : loss : 0.263562, loss_ce: 0.065600
[23:33:12.085] iteration 1092 : loss : 0.304384, loss_ce: 0.044767
[23:33:12.367] iteration 1093 : loss : 0.168529, loss_ce: 0.040591
[23:33:12.648] iteration 1094 : loss : 0.244084, loss_ce: 0.074435
[23:33:12.933] iteration 1095 : loss : 0.288252, loss_ce: 0.053632
[23:33:13.216] iteration 1096 : loss : 0.232895, loss_ce: 0.041982
[23:33:13.495] iteration 1097 : loss : 0.269019, loss_ce: 0.060721
[23:33:13.777] iteration 1098 : loss : 0.180443, loss_ce: 0.036717
[23:33:14.060] iteration 1099 : loss : 0.255730, loss_ce: 0.049704
[23:33:14.339] iteration 1100 : loss : 0.205858, loss_ce: 0.055284
[23:33:14.642] iteration 1101 : loss : 0.251002, loss_ce: 0.062780
[23:33:14.924] iteration 1102 : loss : 0.238636, loss_ce: 0.057871
[23:33:15.207] iteration 1103 : loss : 0.216601, loss_ce: 0.063071
[23:33:15.491] iteration 1104 : loss : 0.217381, loss_ce: 0.051143
[23:33:15.775] iteration 1105 : loss : 0.276055, loss_ce: 0.040461
[23:33:16.059] iteration 1106 : loss : 0.255722, loss_ce: 0.048959
[23:33:16.339] iteration 1107 : loss : 0.178616, loss_ce: 0.037177
[23:33:16.625] iteration 1108 : loss : 0.279283, loss_ce: 0.066579
[23:33:16.907] iteration 1109 : loss : 0.232845, loss_ce: 0.078719
[23:33:17.190] iteration 1110 : loss : 0.231054, loss_ce: 0.086675
[23:33:17.474] iteration 1111 : loss : 0.217096, loss_ce: 0.089691
[23:33:17.552] iteration 1112 : loss : 0.249349, loss_ce: 0.075205
[23:33:36.844] iteration 1113 : loss : 0.265542, loss_ce: 0.057194
[23:33:37.122] iteration 1114 : loss : 0.192200, loss_ce: 0.051023
[23:33:37.403] iteration 1115 : loss : 0.212464, loss_ce: 0.077376
[23:33:37.684] iteration 1116 : loss : 0.178569, loss_ce: 0.049691
[23:33:37.967] iteration 1117 : loss : 0.209407, loss_ce: 0.044422
[23:33:38.241] iteration 1118 : loss : 0.295065, loss_ce: 0.051218
[23:33:38.517] iteration 1119 : loss : 0.190889, loss_ce: 0.059536
[23:33:38.792] iteration 1120 : loss : 0.236137, loss_ce: 0.103036
[23:33:39.087] iteration 1121 : loss : 0.242126, loss_ce: 0.066772
[23:33:39.366] iteration 1122 : loss : 0.242523, loss_ce: 0.043329
[23:33:39.644] iteration 1123 : loss : 0.294686, loss_ce: 0.077674
[23:33:39.920] iteration 1124 : loss : 0.197017, loss_ce: 0.052173
[23:33:40.199] iteration 1125 : loss : 0.132983, loss_ce: 0.024669
[23:33:40.478] iteration 1126 : loss : 0.313634, loss_ce: 0.062654
[23:33:40.760] iteration 1127 : loss : 0.270346, loss_ce: 0.042377
[23:33:41.034] iteration 1128 : loss : 0.227253, loss_ce: 0.050353
[23:33:41.310] iteration 1129 : loss : 0.206092, loss_ce: 0.047180
[23:33:41.586] iteration 1130 : loss : 0.272540, loss_ce: 0.071966
[23:33:41.866] iteration 1131 : loss : 0.226704, loss_ce: 0.021061
[23:33:42.142] iteration 1132 : loss : 0.265183, loss_ce: 0.076989
[23:33:42.423] iteration 1133 : loss : 0.225730, loss_ce: 0.065630
[23:33:42.702] iteration 1134 : loss : 0.216500, loss_ce: 0.056431
[23:33:42.983] iteration 1135 : loss : 0.222117, loss_ce: 0.057445
[23:33:43.263] iteration 1136 : loss : 0.246481, loss_ce: 0.040549
[23:33:43.543] iteration 1137 : loss : 0.227335, loss_ce: 0.091656
[23:33:43.821] iteration 1138 : loss : 0.285983, loss_ce: 0.059645
[23:33:44.100] iteration 1139 : loss : 0.269091, loss_ce: 0.072076
[23:33:44.374] iteration 1140 : loss : 0.210847, loss_ce: 0.045447
[23:33:44.676] iteration 1141 : loss : 0.306835, loss_ce: 0.093339
[23:33:44.968] iteration 1142 : loss : 0.182998, loss_ce: 0.074074
[23:33:45.248] iteration 1143 : loss : 0.313923, loss_ce: 0.087577
[23:33:45.530] iteration 1144 : loss : 0.219316, loss_ce: 0.064580
[23:33:45.807] iteration 1145 : loss : 0.181486, loss_ce: 0.076250
[23:33:46.086] iteration 1146 : loss : 0.213005, loss_ce: 0.082180
[23:33:46.364] iteration 1147 : loss : 0.261924, loss_ce: 0.046209
[23:33:46.641] iteration 1148 : loss : 0.294115, loss_ce: 0.112234
[23:33:46.919] iteration 1149 : loss : 0.207759, loss_ce: 0.062230
[23:33:47.195] iteration 1150 : loss : 0.195755, loss_ce: 0.056060
[23:33:47.474] iteration 1151 : loss : 0.330732, loss_ce: 0.068189
[23:33:47.791] iteration 1152 : loss : 0.251770, loss_ce: 0.062666
[23:33:48.119] iteration 1153 : loss : 0.219586, loss_ce: 0.067540
[23:33:48.425] iteration 1154 : loss : 0.269696, loss_ce: 0.046856
[23:33:48.725] iteration 1155 : loss : 0.189958, loss_ce: 0.090372
[23:33:49.053] iteration 1156 : loss : 0.181098, loss_ce: 0.054565
[23:33:49.377] iteration 1157 : loss : 0.188596, loss_ce: 0.055772
[23:33:49.666] iteration 1158 : loss : 0.188573, loss_ce: 0.055560
[23:33:49.942] iteration 1159 : loss : 0.188229, loss_ce: 0.049881
[23:33:50.222] iteration 1160 : loss : 0.175514, loss_ce: 0.052058
[23:33:50.517] iteration 1161 : loss : 0.186843, loss_ce: 0.062926
[23:33:50.792] iteration 1162 : loss : 0.207156, loss_ce: 0.059016
[23:33:51.072] iteration 1163 : loss : 0.180649, loss_ce: 0.049121
[23:33:51.352] iteration 1164 : loss : 0.217591, loss_ce: 0.031219
[23:33:51.627] iteration 1165 : loss : 0.260751, loss_ce: 0.071998
[23:33:51.906] iteration 1166 : loss : 0.214948, loss_ce: 0.074613
[23:33:52.184] iteration 1167 : loss : 0.165725, loss_ce: 0.062269
[23:33:52.465] iteration 1168 : loss : 0.211718, loss_ce: 0.068053
[23:33:52.742] iteration 1169 : loss : 0.254155, loss_ce: 0.043350
[23:33:53.020] iteration 1170 : loss : 0.161675, loss_ce: 0.051893
[23:33:53.299] iteration 1171 : loss : 0.250013, loss_ce: 0.024221
[23:33:53.576] iteration 1172 : loss : 0.200837, loss_ce: 0.044088
[23:33:53.856] iteration 1173 : loss : 0.247173, loss_ce: 0.023505
[23:33:54.135] iteration 1174 : loss : 0.216292, loss_ce: 0.039105
[23:33:54.413] iteration 1175 : loss : 0.180378, loss_ce: 0.064377
[23:33:54.693] iteration 1176 : loss : 0.213024, loss_ce: 0.054922
[23:33:54.973] iteration 1177 : loss : 0.223570, loss_ce: 0.039224
[23:33:55.249] iteration 1178 : loss : 0.223210, loss_ce: 0.067686
[23:33:55.527] iteration 1179 : loss : 0.201301, loss_ce: 0.099270
[23:33:55.803] iteration 1180 : loss : 0.257358, loss_ce: 0.096298
[23:33:56.099] iteration 1181 : loss : 0.191076, loss_ce: 0.065791
[23:33:56.377] iteration 1182 : loss : 0.208915, loss_ce: 0.064643
[23:33:56.659] iteration 1183 : loss : 0.221693, loss_ce: 0.094748
[23:33:56.952] iteration 1184 : loss : 0.270126, loss_ce: 0.033759
[23:33:57.244] iteration 1185 : loss : 0.244277, loss_ce: 0.030662
[23:33:57.531] iteration 1186 : loss : 0.186874, loss_ce: 0.044368
[23:33:57.823] iteration 1187 : loss : 0.171102, loss_ce: 0.034748
[23:33:58.110] iteration 1188 : loss : 0.186803, loss_ce: 0.061291
[23:33:58.396] iteration 1189 : loss : 0.251874, loss_ce: 0.061581
[23:33:58.680] iteration 1190 : loss : 0.275971, loss_ce: 0.109147
[23:33:58.959] iteration 1191 : loss : 0.225973, loss_ce: 0.059619
[23:33:59.240] iteration 1192 : loss : 0.190224, loss_ce: 0.024321
[23:33:59.517] iteration 1193 : loss : 0.397173, loss_ce: 0.029378
[23:33:59.793] iteration 1194 : loss : 0.261574, loss_ce: 0.098209
[23:34:00.076] iteration 1195 : loss : 0.313930, loss_ce: 0.070419
[23:34:00.358] iteration 1196 : loss : 0.272389, loss_ce: 0.045509
[23:34:00.637] iteration 1197 : loss : 0.213653, loss_ce: 0.068371
[23:34:00.918] iteration 1198 : loss : 0.305178, loss_ce: 0.031584
[23:34:01.196] iteration 1199 : loss : 0.247114, loss_ce: 0.063094
[23:34:01.476] iteration 1200 : loss : 0.211352, loss_ce: 0.083405
[23:34:01.774] iteration 1201 : loss : 0.246078, loss_ce: 0.028662
[23:34:02.053] iteration 1202 : loss : 0.209420, loss_ce: 0.043236
[23:34:02.330] iteration 1203 : loss : 0.213102, loss_ce: 0.060776
[23:34:02.607] iteration 1204 : loss : 0.246435, loss_ce: 0.077285
[23:34:02.886] iteration 1205 : loss : 0.217615, loss_ce: 0.078002
[23:34:03.163] iteration 1206 : loss : 0.258263, loss_ce: 0.078582
[23:34:03.437] iteration 1207 : loss : 0.317665, loss_ce: 0.089942
[23:34:03.719] iteration 1208 : loss : 0.329616, loss_ce: 0.063139
[23:34:03.999] iteration 1209 : loss : 0.209158, loss_ce: 0.034622
[23:34:04.280] iteration 1210 : loss : 0.213503, loss_ce: 0.074754
[23:34:04.560] iteration 1211 : loss : 0.215645, loss_ce: 0.098653
[23:34:04.838] iteration 1212 : loss : 0.217717, loss_ce: 0.106033
[23:34:05.120] iteration 1213 : loss : 0.261949, loss_ce: 0.103306
[23:34:05.403] iteration 1214 : loss : 0.243580, loss_ce: 0.069112
[23:34:05.678] iteration 1215 : loss : 0.231056, loss_ce: 0.024614
[23:34:05.958] iteration 1216 : loss : 0.205075, loss_ce: 0.049999
[23:34:06.234] iteration 1217 : loss : 0.187965, loss_ce: 0.066797
[23:34:06.515] iteration 1218 : loss : 0.223710, loss_ce: 0.036662
[23:34:06.792] iteration 1219 : loss : 0.325919, loss_ce: 0.112818
[23:34:07.069] iteration 1220 : loss : 0.219960, loss_ce: 0.095261
[23:34:07.363] iteration 1221 : loss : 0.225696, loss_ce: 0.069476
[23:34:07.640] iteration 1222 : loss : 0.176356, loss_ce: 0.039123
[23:34:07.919] iteration 1223 : loss : 0.188884, loss_ce: 0.079593
[23:34:08.198] iteration 1224 : loss : 0.233836, loss_ce: 0.064605
[23:34:08.477] iteration 1225 : loss : 0.188446, loss_ce: 0.061447
[23:34:08.757] iteration 1226 : loss : 0.287931, loss_ce: 0.073179
[23:34:09.033] iteration 1227 : loss : 0.209011, loss_ce: 0.069072
[23:34:09.309] iteration 1228 : loss : 0.254995, loss_ce: 0.013790
[23:34:09.590] iteration 1229 : loss : 0.236840, loss_ce: 0.053047
[23:34:09.868] iteration 1230 : loss : 0.224408, loss_ce: 0.070575
[23:34:10.147] iteration 1231 : loss : 0.342052, loss_ce: 0.082433
[23:34:10.423] iteration 1232 : loss : 0.173266, loss_ce: 0.041916
[23:34:10.699] iteration 1233 : loss : 0.258232, loss_ce: 0.059944
[23:34:10.980] iteration 1234 : loss : 0.266581, loss_ce: 0.092116
[23:34:11.261] iteration 1235 : loss : 0.231563, loss_ce: 0.056898
[23:34:11.542] iteration 1236 : loss : 0.256884, loss_ce: 0.067314
[23:34:11.824] iteration 1237 : loss : 0.204488, loss_ce: 0.039832
[23:34:12.106] iteration 1238 : loss : 0.213759, loss_ce: 0.057837
[23:34:12.385] iteration 1239 : loss : 0.319275, loss_ce: 0.045896
[23:34:12.667] iteration 1240 : loss : 0.267926, loss_ce: 0.080861
[23:34:12.969] iteration 1241 : loss : 0.295802, loss_ce: 0.021385
[23:34:13.252] iteration 1242 : loss : 0.269112, loss_ce: 0.057386
[23:34:13.529] iteration 1243 : loss : 0.217208, loss_ce: 0.050505
[23:34:13.810] iteration 1244 : loss : 0.180803, loss_ce: 0.064092
[23:34:14.089] iteration 1245 : loss : 0.206476, loss_ce: 0.089930
[23:34:14.371] iteration 1246 : loss : 0.206121, loss_ce: 0.055905
[23:34:14.651] iteration 1247 : loss : 0.246551, loss_ce: 0.052505
[23:34:14.936] iteration 1248 : loss : 0.274994, loss_ce: 0.077972
[23:34:15.212] iteration 1249 : loss : 0.235870, loss_ce: 0.101161
[23:34:15.489] iteration 1250 : loss : 0.182134, loss_ce: 0.040186
[23:34:15.565] iteration 1251 : loss : 0.279137, loss_ce: 0.060490
[23:34:33.409] iteration 1252 : loss : 0.244451, loss_ce: 0.083158
[23:34:33.696] iteration 1253 : loss : 0.317710, loss_ce: 0.016286
[23:34:33.980] iteration 1254 : loss : 0.300652, loss_ce: 0.051637
[23:34:34.262] iteration 1255 : loss : 0.222167, loss_ce: 0.059568
[23:34:34.546] iteration 1256 : loss : 0.216970, loss_ce: 0.066380
[23:34:34.828] iteration 1257 : loss : 0.203912, loss_ce: 0.063467
[23:34:35.105] iteration 1258 : loss : 0.163649, loss_ce: 0.059981
[23:34:35.385] iteration 1259 : loss : 0.181690, loss_ce: 0.061233
[23:34:35.664] iteration 1260 : loss : 0.306033, loss_ce: 0.016463
[23:34:35.958] iteration 1261 : loss : 0.200680, loss_ce: 0.076698
[23:34:36.233] iteration 1262 : loss : 0.284627, loss_ce: 0.035287
[23:34:36.508] iteration 1263 : loss : 0.192299, loss_ce: 0.048809
[23:34:36.786] iteration 1264 : loss : 0.176254, loss_ce: 0.045926
[23:34:37.062] iteration 1265 : loss : 0.146098, loss_ce: 0.039699
[23:34:37.343] iteration 1266 : loss : 0.239954, loss_ce: 0.067405
[23:34:37.620] iteration 1267 : loss : 0.293920, loss_ce: 0.066056
[23:34:37.895] iteration 1268 : loss : 0.178942, loss_ce: 0.061595
[23:34:38.173] iteration 1269 : loss : 0.210524, loss_ce: 0.079908
[23:34:38.453] iteration 1270 : loss : 0.233243, loss_ce: 0.066886
[23:34:38.726] iteration 1271 : loss : 0.195796, loss_ce: 0.034655
[23:34:39.007] iteration 1272 : loss : 0.217730, loss_ce: 0.035195
[23:34:39.283] iteration 1273 : loss : 0.173277, loss_ce: 0.059103
[23:34:39.561] iteration 1274 : loss : 0.283107, loss_ce: 0.048747
[23:34:39.836] iteration 1275 : loss : 0.147174, loss_ce: 0.045420
[23:34:40.112] iteration 1276 : loss : 0.173919, loss_ce: 0.043293
[23:34:40.389] iteration 1277 : loss : 0.205033, loss_ce: 0.045761
[23:34:40.668] iteration 1278 : loss : 0.240076, loss_ce: 0.029637
[23:34:40.949] iteration 1279 : loss : 0.186821, loss_ce: 0.033418
[23:34:41.228] iteration 1280 : loss : 0.209776, loss_ce: 0.041528
[23:34:41.523] iteration 1281 : loss : 0.163502, loss_ce: 0.053616
[23:34:41.800] iteration 1282 : loss : 0.165927, loss_ce: 0.067161
[23:34:42.079] iteration 1283 : loss : 0.125247, loss_ce: 0.041015
[23:34:42.364] iteration 1284 : loss : 0.254357, loss_ce: 0.054323
[23:34:42.640] iteration 1285 : loss : 0.149363, loss_ce: 0.055190
[23:34:42.918] iteration 1286 : loss : 0.154046, loss_ce: 0.054080
[23:34:43.198] iteration 1287 : loss : 0.224289, loss_ce: 0.028280
[23:34:43.474] iteration 1288 : loss : 0.196970, loss_ce: 0.074276
[23:34:43.751] iteration 1289 : loss : 0.235973, loss_ce: 0.045397
[23:34:44.028] iteration 1290 : loss : 0.221777, loss_ce: 0.054437
[23:34:44.306] iteration 1291 : loss : 0.234265, loss_ce: 0.034524
[23:34:44.585] iteration 1292 : loss : 0.183115, loss_ce: 0.065400
[23:34:44.860] iteration 1293 : loss : 0.179259, loss_ce: 0.050030
[23:34:45.137] iteration 1294 : loss : 0.210934, loss_ce: 0.036924
[23:34:45.418] iteration 1295 : loss : 0.166393, loss_ce: 0.051273
[23:34:45.692] iteration 1296 : loss : 0.234879, loss_ce: 0.078251
[23:34:45.968] iteration 1297 : loss : 0.366124, loss_ce: 0.016003
[23:34:46.247] iteration 1298 : loss : 0.257269, loss_ce: 0.067160
[23:34:46.525] iteration 1299 : loss : 0.162077, loss_ce: 0.062461
[23:34:46.806] iteration 1300 : loss : 0.177797, loss_ce: 0.045608
[23:34:47.101] iteration 1301 : loss : 0.179003, loss_ce: 0.054576
[23:34:47.379] iteration 1302 : loss : 0.229173, loss_ce: 0.039811
[23:34:47.660] iteration 1303 : loss : 0.256610, loss_ce: 0.051272
[23:34:47.940] iteration 1304 : loss : 0.222376, loss_ce: 0.039295
[23:34:48.218] iteration 1305 : loss : 0.303875, loss_ce: 0.050413
[23:34:48.494] iteration 1306 : loss : 0.223578, loss_ce: 0.081883
[23:34:48.770] iteration 1307 : loss : 0.223723, loss_ce: 0.081934
[23:34:49.050] iteration 1308 : loss : 0.168997, loss_ce: 0.079514
[23:34:49.328] iteration 1309 : loss : 0.248959, loss_ce: 0.060183
[23:34:49.610] iteration 1310 : loss : 0.255455, loss_ce: 0.018840
[23:34:49.889] iteration 1311 : loss : 0.182018, loss_ce: 0.053759
[23:34:50.165] iteration 1312 : loss : 0.199928, loss_ce: 0.079420
[23:34:50.448] iteration 1313 : loss : 0.190735, loss_ce: 0.056730
[23:34:50.727] iteration 1314 : loss : 0.157134, loss_ce: 0.034203
[23:34:51.003] iteration 1315 : loss : 0.240423, loss_ce: 0.056090
[23:34:51.281] iteration 1316 : loss : 0.220804, loss_ce: 0.043806
[23:34:51.558] iteration 1317 : loss : 0.183702, loss_ce: 0.062283
[23:34:51.837] iteration 1318 : loss : 0.209457, loss_ce: 0.046082
[23:34:52.116] iteration 1319 : loss : 0.251039, loss_ce: 0.031466
[23:34:52.396] iteration 1320 : loss : 0.227978, loss_ce: 0.034639
[23:34:52.697] iteration 1321 : loss : 0.214678, loss_ce: 0.031907
[23:34:52.977] iteration 1322 : loss : 0.210307, loss_ce: 0.064159
[23:34:53.253] iteration 1323 : loss : 0.155622, loss_ce: 0.060544
[23:34:53.535] iteration 1324 : loss : 0.188630, loss_ce: 0.056274
[23:34:53.817] iteration 1325 : loss : 0.325847, loss_ce: 0.022897
[23:34:54.098] iteration 1326 : loss : 0.181142, loss_ce: 0.067214
[23:34:54.377] iteration 1327 : loss : 0.250863, loss_ce: 0.060596
[23:34:54.658] iteration 1328 : loss : 0.340746, loss_ce: 0.069363
[23:34:54.938] iteration 1329 : loss : 0.151937, loss_ce: 0.058504
[23:34:55.219] iteration 1330 : loss : 0.164738, loss_ce: 0.043992
[23:34:55.495] iteration 1331 : loss : 0.231848, loss_ce: 0.021797
[23:34:55.774] iteration 1332 : loss : 0.181613, loss_ce: 0.064527
[23:34:56.053] iteration 1333 : loss : 0.161684, loss_ce: 0.050545
[23:34:56.334] iteration 1334 : loss : 0.135583, loss_ce: 0.046685
[23:34:56.611] iteration 1335 : loss : 0.178457, loss_ce: 0.030429
[23:34:56.889] iteration 1336 : loss : 0.231162, loss_ce: 0.033578
[23:34:57.168] iteration 1337 : loss : 0.239697, loss_ce: 0.061113
[23:34:57.447] iteration 1338 : loss : 0.184784, loss_ce: 0.070557
[23:34:57.728] iteration 1339 : loss : 0.192209, loss_ce: 0.066018
[23:34:58.006] iteration 1340 : loss : 0.182538, loss_ce: 0.041597
[23:34:58.308] iteration 1341 : loss : 0.200992, loss_ce: 0.053857
[23:34:58.589] iteration 1342 : loss : 0.210201, loss_ce: 0.037498
[23:34:58.868] iteration 1343 : loss : 0.289104, loss_ce: 0.058360
[23:34:59.144] iteration 1344 : loss : 0.238650, loss_ce: 0.058196
[23:34:59.428] iteration 1345 : loss : 0.174534, loss_ce: 0.043702
[23:34:59.703] iteration 1346 : loss : 0.215212, loss_ce: 0.063038
[23:34:59.984] iteration 1347 : loss : 0.201794, loss_ce: 0.053304
[23:35:00.271] iteration 1348 : loss : 0.217269, loss_ce: 0.051886
[23:35:00.549] iteration 1349 : loss : 0.157874, loss_ce: 0.049770
[23:35:00.835] iteration 1350 : loss : 0.214705, loss_ce: 0.049656
[23:35:01.114] iteration 1351 : loss : 0.186760, loss_ce: 0.068898
[23:35:01.392] iteration 1352 : loss : 0.242047, loss_ce: 0.084768
[23:35:01.672] iteration 1353 : loss : 0.178599, loss_ce: 0.054817
[23:35:01.953] iteration 1354 : loss : 0.141771, loss_ce: 0.032004
[23:35:02.233] iteration 1355 : loss : 0.178743, loss_ce: 0.039536
[23:35:02.510] iteration 1356 : loss : 0.236633, loss_ce: 0.043003
[23:35:02.790] iteration 1357 : loss : 0.240232, loss_ce: 0.033661
[23:35:03.072] iteration 1358 : loss : 0.272967, loss_ce: 0.019017
[23:35:03.356] iteration 1359 : loss : 0.217325, loss_ce: 0.055007
[23:35:03.639] iteration 1360 : loss : 0.233370, loss_ce: 0.060481
[23:35:03.936] iteration 1361 : loss : 0.201556, loss_ce: 0.030679
[23:35:04.219] iteration 1362 : loss : 0.153784, loss_ce: 0.049548
[23:35:04.499] iteration 1363 : loss : 0.161675, loss_ce: 0.045523
[23:35:04.778] iteration 1364 : loss : 0.249926, loss_ce: 0.041164
[23:35:05.055] iteration 1365 : loss : 0.176385, loss_ce: 0.046165
[23:35:05.337] iteration 1366 : loss : 0.263115, loss_ce: 0.035918
[23:35:05.616] iteration 1367 : loss : 0.202151, loss_ce: 0.098004
[23:35:05.896] iteration 1368 : loss : 0.223885, loss_ce: 0.077852
[23:35:06.174] iteration 1369 : loss : 0.287663, loss_ce: 0.072435
[23:35:06.455] iteration 1370 : loss : 0.220478, loss_ce: 0.094216
[23:35:06.734] iteration 1371 : loss : 0.201974, loss_ce: 0.076061
[23:35:07.014] iteration 1372 : loss : 0.210636, loss_ce: 0.053096
[23:35:07.291] iteration 1373 : loss : 0.141955, loss_ce: 0.029405
[23:35:07.574] iteration 1374 : loss : 0.170557, loss_ce: 0.052906
[23:35:07.856] iteration 1375 : loss : 0.230824, loss_ce: 0.041548
[23:35:08.142] iteration 1376 : loss : 0.195742, loss_ce: 0.061885
[23:35:08.426] iteration 1377 : loss : 0.187393, loss_ce: 0.035674
[23:35:08.707] iteration 1378 : loss : 0.237654, loss_ce: 0.094638
[23:35:08.990] iteration 1379 : loss : 0.180750, loss_ce: 0.073262
[23:35:09.275] iteration 1380 : loss : 0.194768, loss_ce: 0.042813
[23:35:09.581] iteration 1381 : loss : 0.253940, loss_ce: 0.067603
[23:35:09.863] iteration 1382 : loss : 0.179760, loss_ce: 0.065837
[23:35:10.145] iteration 1383 : loss : 0.178869, loss_ce: 0.081546
[23:35:10.431] iteration 1384 : loss : 0.130458, loss_ce: 0.037495
[23:35:10.714] iteration 1385 : loss : 0.181502, loss_ce: 0.045252
[23:35:10.998] iteration 1386 : loss : 0.237368, loss_ce: 0.076965
[23:35:11.280] iteration 1387 : loss : 0.217807, loss_ce: 0.086972
[23:35:11.566] iteration 1388 : loss : 0.142634, loss_ce: 0.028508
[23:35:11.849] iteration 1389 : loss : 0.194445, loss_ce: 0.056569
[23:35:11.933] iteration 1390 : loss : 0.281450, loss_ce: 0.042670
[23:35:29.544] iteration 1391 : loss : 0.160801, loss_ce: 0.040630
[23:35:29.826] iteration 1392 : loss : 0.153676, loss_ce: 0.052986
[23:35:30.109] iteration 1393 : loss : 0.186223, loss_ce: 0.046786
[23:35:30.388] iteration 1394 : loss : 0.164850, loss_ce: 0.059810
[23:35:30.671] iteration 1395 : loss : 0.204671, loss_ce: 0.039919
[23:35:30.950] iteration 1396 : loss : 0.201774, loss_ce: 0.043219
[23:35:31.226] iteration 1397 : loss : 0.270492, loss_ce: 0.027861
[23:35:31.502] iteration 1398 : loss : 0.175294, loss_ce: 0.060491
[23:35:31.778] iteration 1399 : loss : 0.179252, loss_ce: 0.059266
[23:35:32.054] iteration 1400 : loss : 0.144535, loss_ce: 0.052653
[23:35:32.349] iteration 1401 : loss : 0.212592, loss_ce: 0.034001
[23:35:32.625] iteration 1402 : loss : 0.230318, loss_ce: 0.039640
[23:35:32.908] iteration 1403 : loss : 0.217648, loss_ce: 0.050763
[23:35:33.185] iteration 1404 : loss : 0.209446, loss_ce: 0.044432
[23:35:33.465] iteration 1405 : loss : 0.224323, loss_ce: 0.044203
[23:35:33.744] iteration 1406 : loss : 0.205244, loss_ce: 0.034433
[23:35:34.021] iteration 1407 : loss : 0.156480, loss_ce: 0.078740
[23:35:34.298] iteration 1408 : loss : 0.184825, loss_ce: 0.061861
[23:35:34.577] iteration 1409 : loss : 0.178474, loss_ce: 0.034623
[23:35:34.855] iteration 1410 : loss : 0.258155, loss_ce: 0.033604
[23:35:35.131] iteration 1411 : loss : 0.137624, loss_ce: 0.023515
[23:35:35.406] iteration 1412 : loss : 0.126932, loss_ce: 0.019096
[23:35:35.683] iteration 1413 : loss : 0.170681, loss_ce: 0.051935
[23:35:35.959] iteration 1414 : loss : 0.240332, loss_ce: 0.038640
[23:35:36.235] iteration 1415 : loss : 0.243296, loss_ce: 0.035491
[23:35:36.512] iteration 1416 : loss : 0.193775, loss_ce: 0.053831
[23:35:36.790] iteration 1417 : loss : 0.222908, loss_ce: 0.027474
[23:35:37.070] iteration 1418 : loss : 0.150843, loss_ce: 0.046199
[23:35:37.350] iteration 1419 : loss : 0.133568, loss_ce: 0.055095
[23:35:37.628] iteration 1420 : loss : 0.184249, loss_ce: 0.041171
[23:35:37.919] iteration 1421 : loss : 0.190684, loss_ce: 0.091046
[23:35:38.197] iteration 1422 : loss : 0.165184, loss_ce: 0.065522
[23:35:38.476] iteration 1423 : loss : 0.171926, loss_ce: 0.065771
[23:35:38.756] iteration 1424 : loss : 0.206637, loss_ce: 0.044431
[23:35:39.033] iteration 1425 : loss : 0.149231, loss_ce: 0.053575
[23:35:39.310] iteration 1426 : loss : 0.319063, loss_ce: 0.046783
[23:35:39.588] iteration 1427 : loss : 0.173316, loss_ce: 0.035850
[23:35:39.865] iteration 1428 : loss : 0.159307, loss_ce: 0.057606
[23:35:40.144] iteration 1429 : loss : 0.159720, loss_ce: 0.021367
[23:35:40.421] iteration 1430 : loss : 0.123757, loss_ce: 0.022719
[23:35:40.698] iteration 1431 : loss : 0.150264, loss_ce: 0.036799
[23:35:40.974] iteration 1432 : loss : 0.234024, loss_ce: 0.058561
[23:35:41.254] iteration 1433 : loss : 0.226299, loss_ce: 0.019736
[23:35:41.533] iteration 1434 : loss : 0.250983, loss_ce: 0.041688
[23:35:41.810] iteration 1435 : loss : 0.170358, loss_ce: 0.038025
[23:35:42.094] iteration 1436 : loss : 0.206973, loss_ce: 0.049158
[23:35:42.370] iteration 1437 : loss : 0.273745, loss_ce: 0.043750
[23:35:42.648] iteration 1438 : loss : 0.177689, loss_ce: 0.048245
[23:35:42.925] iteration 1439 : loss : 0.239152, loss_ce: 0.028851
[23:35:43.206] iteration 1440 : loss : 0.193188, loss_ce: 0.069944
[23:35:43.508] iteration 1441 : loss : 0.186753, loss_ce: 0.049083
[23:35:43.787] iteration 1442 : loss : 0.169449, loss_ce: 0.061612
[23:35:44.064] iteration 1443 : loss : 0.327444, loss_ce: 0.024052
[23:35:44.346] iteration 1444 : loss : 0.205780, loss_ce: 0.049826
[23:35:44.624] iteration 1445 : loss : 0.185814, loss_ce: 0.041202
[23:35:44.900] iteration 1446 : loss : 0.175905, loss_ce: 0.059412
[23:35:45.182] iteration 1447 : loss : 0.179448, loss_ce: 0.049147
[23:35:45.459] iteration 1448 : loss : 0.237710, loss_ce: 0.048200
[23:35:45.736] iteration 1449 : loss : 0.177559, loss_ce: 0.046491
[23:35:46.012] iteration 1450 : loss : 0.144843, loss_ce: 0.024534
[23:35:46.288] iteration 1451 : loss : 0.208569, loss_ce: 0.042001
[23:35:46.569] iteration 1452 : loss : 0.205690, loss_ce: 0.041974
[23:35:46.846] iteration 1453 : loss : 0.213715, loss_ce: 0.020681
[23:35:47.126] iteration 1454 : loss : 0.166173, loss_ce: 0.035423
[23:35:47.405] iteration 1455 : loss : 0.131503, loss_ce: 0.050818
[23:35:47.683] iteration 1456 : loss : 0.182506, loss_ce: 0.011933
[23:35:47.960] iteration 1457 : loss : 0.201346, loss_ce: 0.035239
[23:35:48.238] iteration 1458 : loss : 0.186944, loss_ce: 0.045078
[23:35:48.512] iteration 1459 : loss : 0.175168, loss_ce: 0.025667
[23:35:48.792] iteration 1460 : loss : 0.173852, loss_ce: 0.049915
[23:35:49.088] iteration 1461 : loss : 0.200019, loss_ce: 0.047117
[23:35:49.367] iteration 1462 : loss : 0.198144, loss_ce: 0.046826
[23:35:49.647] iteration 1463 : loss : 0.155058, loss_ce: 0.049466
[23:35:49.926] iteration 1464 : loss : 0.191364, loss_ce: 0.058915
[23:35:50.207] iteration 1465 : loss : 0.173745, loss_ce: 0.042042
[23:35:50.485] iteration 1466 : loss : 0.145780, loss_ce: 0.052546
[23:35:50.764] iteration 1467 : loss : 0.156321, loss_ce: 0.065247
[23:35:51.043] iteration 1468 : loss : 0.215997, loss_ce: 0.044912
[23:35:51.321] iteration 1469 : loss : 0.157909, loss_ce: 0.050375
[23:35:51.598] iteration 1470 : loss : 0.169981, loss_ce: 0.057043
[23:35:51.876] iteration 1471 : loss : 0.166882, loss_ce: 0.058951
[23:35:52.156] iteration 1472 : loss : 0.222449, loss_ce: 0.054744
[23:35:52.432] iteration 1473 : loss : 0.183837, loss_ce: 0.056025
[23:35:52.712] iteration 1474 : loss : 0.140174, loss_ce: 0.047437
[23:35:52.990] iteration 1475 : loss : 0.211273, loss_ce: 0.056776
[23:35:53.268] iteration 1476 : loss : 0.200324, loss_ce: 0.042281
[23:35:53.548] iteration 1477 : loss : 0.154950, loss_ce: 0.043391
[23:35:53.829] iteration 1478 : loss : 0.218935, loss_ce: 0.044713
[23:35:54.106] iteration 1479 : loss : 0.181285, loss_ce: 0.068094
[23:35:54.384] iteration 1480 : loss : 0.152898, loss_ce: 0.050507
[23:35:54.680] iteration 1481 : loss : 0.185882, loss_ce: 0.076534
[23:35:54.955] iteration 1482 : loss : 0.164846, loss_ce: 0.049603
[23:35:55.233] iteration 1483 : loss : 0.243067, loss_ce: 0.048137
[23:35:55.512] iteration 1484 : loss : 0.167928, loss_ce: 0.040048
[23:35:55.791] iteration 1485 : loss : 0.162430, loss_ce: 0.043259
[23:35:56.071] iteration 1486 : loss : 0.219242, loss_ce: 0.080661
[23:35:56.350] iteration 1487 : loss : 0.185570, loss_ce: 0.042253
[23:35:56.628] iteration 1488 : loss : 0.163140, loss_ce: 0.055793
[23:35:56.909] iteration 1489 : loss : 0.212861, loss_ce: 0.043944
[23:35:57.184] iteration 1490 : loss : 0.167600, loss_ce: 0.028661
[23:35:57.463] iteration 1491 : loss : 0.196334, loss_ce: 0.039358
[23:35:57.740] iteration 1492 : loss : 0.180757, loss_ce: 0.043760
[23:35:58.022] iteration 1493 : loss : 0.202428, loss_ce: 0.064829
[23:35:58.300] iteration 1494 : loss : 0.210113, loss_ce: 0.027499
[23:35:58.577] iteration 1495 : loss : 0.168695, loss_ce: 0.037300
[23:35:58.854] iteration 1496 : loss : 0.222070, loss_ce: 0.092747
[23:35:59.131] iteration 1497 : loss : 0.176610, loss_ce: 0.043358
[23:35:59.412] iteration 1498 : loss : 0.200085, loss_ce: 0.041761
[23:35:59.689] iteration 1499 : loss : 0.169444, loss_ce: 0.035040
[23:35:59.966] iteration 1500 : loss : 0.154367, loss_ce: 0.026770
[23:36:00.264] iteration 1501 : loss : 0.190800, loss_ce: 0.046354
[23:36:00.543] iteration 1502 : loss : 0.200016, loss_ce: 0.055558
[23:36:00.824] iteration 1503 : loss : 0.166921, loss_ce: 0.059140
[23:36:01.102] iteration 1504 : loss : 0.201703, loss_ce: 0.071617
[23:36:01.380] iteration 1505 : loss : 0.213501, loss_ce: 0.097129
[23:36:01.655] iteration 1506 : loss : 0.153052, loss_ce: 0.044839
[23:36:01.932] iteration 1507 : loss : 0.158373, loss_ce: 0.040036
[23:36:02.209] iteration 1508 : loss : 0.248234, loss_ce: 0.047234
[23:36:02.489] iteration 1509 : loss : 0.152282, loss_ce: 0.048088
[23:36:02.764] iteration 1510 : loss : 0.207040, loss_ce: 0.113361
[23:36:03.041] iteration 1511 : loss : 0.174090, loss_ce: 0.067627
[23:36:03.319] iteration 1512 : loss : 0.156115, loss_ce: 0.056622
[23:36:03.600] iteration 1513 : loss : 0.215882, loss_ce: 0.042295
[23:36:03.879] iteration 1514 : loss : 0.173230, loss_ce: 0.045421
[23:36:04.160] iteration 1515 : loss : 0.180444, loss_ce: 0.067019
[23:36:04.442] iteration 1516 : loss : 0.192071, loss_ce: 0.063360
[23:36:04.728] iteration 1517 : loss : 0.192302, loss_ce: 0.064831
[23:36:05.005] iteration 1518 : loss : 0.165471, loss_ce: 0.022955
[23:36:05.282] iteration 1519 : loss : 0.175349, loss_ce: 0.080978
[23:36:05.564] iteration 1520 : loss : 0.239405, loss_ce: 0.035524
[23:36:05.861] iteration 1521 : loss : 0.178317, loss_ce: 0.022681
[23:36:06.137] iteration 1522 : loss : 0.203334, loss_ce: 0.041859
[23:36:06.413] iteration 1523 : loss : 0.215461, loss_ce: 0.043992
[23:36:06.691] iteration 1524 : loss : 0.154331, loss_ce: 0.031384
[23:36:06.970] iteration 1525 : loss : 0.202331, loss_ce: 0.040397
[23:36:07.247] iteration 1526 : loss : 0.341608, loss_ce: 0.033740
[23:36:07.530] iteration 1527 : loss : 0.192300, loss_ce: 0.039358
[23:36:07.814] iteration 1528 : loss : 0.209675, loss_ce: 0.062429
[23:36:07.886] iteration 1529 : loss : 0.224366, loss_ce: 0.049368
[23:36:25.739] iteration 1530 : loss : 0.190757, loss_ce: 0.051556
[23:36:26.018] iteration 1531 : loss : 0.209265, loss_ce: 0.056054
[23:36:26.301] iteration 1532 : loss : 0.242522, loss_ce: 0.021487
[23:36:26.577] iteration 1533 : loss : 0.226133, loss_ce: 0.069719
[23:36:26.864] iteration 1534 : loss : 0.222745, loss_ce: 0.063375
[23:36:27.143] iteration 1535 : loss : 0.206405, loss_ce: 0.079185
[23:36:27.419] iteration 1536 : loss : 0.197612, loss_ce: 0.059971
[23:36:27.697] iteration 1537 : loss : 0.164656, loss_ce: 0.033303
[23:36:27.974] iteration 1538 : loss : 0.125400, loss_ce: 0.027717
[23:36:28.256] iteration 1539 : loss : 0.147458, loss_ce: 0.048614
[23:36:28.529] iteration 1540 : loss : 0.165260, loss_ce: 0.068072
[23:36:28.825] iteration 1541 : loss : 0.199118, loss_ce: 0.085228
[23:36:29.105] iteration 1542 : loss : 0.143153, loss_ce: 0.027660
[23:36:29.381] iteration 1543 : loss : 0.174414, loss_ce: 0.048338
[23:36:29.661] iteration 1544 : loss : 0.191815, loss_ce: 0.078571
[23:36:29.941] iteration 1545 : loss : 0.162719, loss_ce: 0.053626
[23:36:30.214] iteration 1546 : loss : 0.210854, loss_ce: 0.037301
[23:36:30.494] iteration 1547 : loss : 0.223108, loss_ce: 0.055559
[23:36:30.772] iteration 1548 : loss : 0.183866, loss_ce: 0.029168
[23:36:31.049] iteration 1549 : loss : 0.135059, loss_ce: 0.052840
[23:36:31.324] iteration 1550 : loss : 0.140520, loss_ce: 0.035350
[23:36:31.600] iteration 1551 : loss : 0.216422, loss_ce: 0.026502
[23:36:31.875] iteration 1552 : loss : 0.282722, loss_ce: 0.065909
[23:36:32.150] iteration 1553 : loss : 0.145801, loss_ce: 0.057520
[23:36:32.428] iteration 1554 : loss : 0.210746, loss_ce: 0.059585
[23:36:32.707] iteration 1555 : loss : 0.166156, loss_ce: 0.054955
[23:36:32.984] iteration 1556 : loss : 0.199676, loss_ce: 0.041493
[23:36:33.263] iteration 1557 : loss : 0.172909, loss_ce: 0.067529
[23:36:33.541] iteration 1558 : loss : 0.182863, loss_ce: 0.037910
[23:36:33.816] iteration 1559 : loss : 0.128346, loss_ce: 0.040620
[23:36:34.091] iteration 1560 : loss : 0.242659, loss_ce: 0.039535
[23:36:34.384] iteration 1561 : loss : 0.198566, loss_ce: 0.033696
[23:36:34.660] iteration 1562 : loss : 0.180592, loss_ce: 0.041556
[23:36:34.937] iteration 1563 : loss : 0.120185, loss_ce: 0.042164
[23:36:35.214] iteration 1564 : loss : 0.161415, loss_ce: 0.068103
[23:36:35.490] iteration 1565 : loss : 0.158119, loss_ce: 0.063522
[23:36:35.767] iteration 1566 : loss : 0.150495, loss_ce: 0.036383
[23:36:36.048] iteration 1567 : loss : 0.228351, loss_ce: 0.049985
[23:36:36.327] iteration 1568 : loss : 0.116223, loss_ce: 0.045527
[23:36:36.605] iteration 1569 : loss : 0.157532, loss_ce: 0.060015
[23:36:36.884] iteration 1570 : loss : 0.171551, loss_ce: 0.032988
[23:36:37.160] iteration 1571 : loss : 0.149007, loss_ce: 0.053318
[23:36:37.438] iteration 1572 : loss : 0.176355, loss_ce: 0.036751
[23:36:37.715] iteration 1573 : loss : 0.177160, loss_ce: 0.044659
[23:36:37.992] iteration 1574 : loss : 0.189273, loss_ce: 0.043826
[23:36:38.269] iteration 1575 : loss : 0.165148, loss_ce: 0.035702
[23:36:38.543] iteration 1576 : loss : 0.131276, loss_ce: 0.026021
[23:36:38.822] iteration 1577 : loss : 0.167728, loss_ce: 0.043842
[23:36:39.101] iteration 1578 : loss : 0.160352, loss_ce: 0.051278
[23:36:39.376] iteration 1579 : loss : 0.118512, loss_ce: 0.032502
[23:36:39.659] iteration 1580 : loss : 0.139137, loss_ce: 0.040955
[23:36:39.957] iteration 1581 : loss : 0.136603, loss_ce: 0.038505
[23:36:40.233] iteration 1582 : loss : 0.135544, loss_ce: 0.038206
[23:36:40.511] iteration 1583 : loss : 0.161690, loss_ce: 0.053850
[23:36:40.791] iteration 1584 : loss : 0.205840, loss_ce: 0.022980
[23:36:41.070] iteration 1585 : loss : 0.145045, loss_ce: 0.039972
[23:36:41.348] iteration 1586 : loss : 0.221521, loss_ce: 0.040941
[23:36:41.624] iteration 1587 : loss : 0.167956, loss_ce: 0.035861
[23:36:41.904] iteration 1588 : loss : 0.152694, loss_ce: 0.046791
[23:36:42.183] iteration 1589 : loss : 0.153108, loss_ce: 0.064631
[23:36:42.459] iteration 1590 : loss : 0.215697, loss_ce: 0.046907
[23:36:42.738] iteration 1591 : loss : 0.235729, loss_ce: 0.033377
[23:36:43.016] iteration 1592 : loss : 0.110659, loss_ce: 0.042281
[23:36:43.296] iteration 1593 : loss : 0.304764, loss_ce: 0.003736
[23:36:43.574] iteration 1594 : loss : 0.154896, loss_ce: 0.026024
[23:36:43.851] iteration 1595 : loss : 0.138922, loss_ce: 0.022630
[23:36:44.130] iteration 1596 : loss : 0.186765, loss_ce: 0.057684
[23:36:44.405] iteration 1597 : loss : 0.152824, loss_ce: 0.049661
[23:36:44.685] iteration 1598 : loss : 0.189213, loss_ce: 0.028830
[23:36:44.964] iteration 1599 : loss : 0.144680, loss_ce: 0.033488
[23:36:45.242] iteration 1600 : loss : 0.156576, loss_ce: 0.050743
[23:36:45.534] iteration 1601 : loss : 0.218167, loss_ce: 0.070404
[23:36:45.814] iteration 1602 : loss : 0.175405, loss_ce: 0.044432
[23:36:46.091] iteration 1603 : loss : 0.169152, loss_ce: 0.081519
[23:36:46.369] iteration 1604 : loss : 0.181707, loss_ce: 0.020415
[23:36:46.645] iteration 1605 : loss : 0.194815, loss_ce: 0.044366
[23:36:46.924] iteration 1606 : loss : 0.164630, loss_ce: 0.055610
[23:36:47.203] iteration 1607 : loss : 0.191847, loss_ce: 0.050906
[23:36:47.481] iteration 1608 : loss : 0.209036, loss_ce: 0.020658
[23:36:47.761] iteration 1609 : loss : 0.148242, loss_ce: 0.041776
[23:36:48.038] iteration 1610 : loss : 0.204505, loss_ce: 0.049101
[23:36:48.317] iteration 1611 : loss : 0.257848, loss_ce: 0.042026
[23:36:48.594] iteration 1612 : loss : 0.139733, loss_ce: 0.053148
[23:36:48.873] iteration 1613 : loss : 0.123474, loss_ce: 0.049382
[23:36:49.151] iteration 1614 : loss : 0.198792, loss_ce: 0.029953
[23:36:49.428] iteration 1615 : loss : 0.226495, loss_ce: 0.042674
[23:36:49.706] iteration 1616 : loss : 0.235419, loss_ce: 0.036669
[23:36:49.984] iteration 1617 : loss : 0.220862, loss_ce: 0.014607
[23:36:50.264] iteration 1618 : loss : 0.167464, loss_ce: 0.032391
[23:36:50.543] iteration 1619 : loss : 0.246297, loss_ce: 0.010627
[23:36:50.822] iteration 1620 : loss : 0.179748, loss_ce: 0.060639
[23:36:51.116] iteration 1621 : loss : 0.264079, loss_ce: 0.031818
[23:36:51.396] iteration 1622 : loss : 0.167542, loss_ce: 0.014978
[23:36:51.672] iteration 1623 : loss : 0.164329, loss_ce: 0.038803
[23:36:51.950] iteration 1624 : loss : 0.210287, loss_ce: 0.067755
[23:36:52.227] iteration 1625 : loss : 0.216483, loss_ce: 0.044400
[23:36:52.508] iteration 1626 : loss : 0.144143, loss_ce: 0.027785
[23:36:52.786] iteration 1627 : loss : 0.186151, loss_ce: 0.056952
[23:36:53.065] iteration 1628 : loss : 0.221366, loss_ce: 0.037302
[23:36:53.341] iteration 1629 : loss : 0.153910, loss_ce: 0.048691
[23:36:53.618] iteration 1630 : loss : 0.285731, loss_ce: 0.045856
[23:36:53.899] iteration 1631 : loss : 0.197316, loss_ce: 0.050564
[23:36:54.176] iteration 1632 : loss : 0.139481, loss_ce: 0.021574
[23:36:54.458] iteration 1633 : loss : 0.150508, loss_ce: 0.048318
[23:36:54.739] iteration 1634 : loss : 0.166328, loss_ce: 0.054852
[23:36:55.020] iteration 1635 : loss : 0.157937, loss_ce: 0.036672
[23:36:55.300] iteration 1636 : loss : 0.161405, loss_ce: 0.064319
[23:36:55.585] iteration 1637 : loss : 0.198953, loss_ce: 0.047481
[23:36:55.866] iteration 1638 : loss : 0.160339, loss_ce: 0.046421
[23:36:56.144] iteration 1639 : loss : 0.169357, loss_ce: 0.037174
[23:36:56.427] iteration 1640 : loss : 0.216095, loss_ce: 0.046029
[23:36:56.718] iteration 1641 : loss : 0.127269, loss_ce: 0.032494
[23:36:56.998] iteration 1642 : loss : 0.130850, loss_ce: 0.032149
[23:36:57.276] iteration 1643 : loss : 0.183408, loss_ce: 0.020407
[23:36:57.554] iteration 1644 : loss : 0.157423, loss_ce: 0.046864
[23:36:57.835] iteration 1645 : loss : 0.167721, loss_ce: 0.040950
[23:36:58.117] iteration 1646 : loss : 0.134621, loss_ce: 0.045211
[23:36:58.394] iteration 1647 : loss : 0.174094, loss_ce: 0.054205
[23:36:58.677] iteration 1648 : loss : 0.170899, loss_ce: 0.053883
[23:36:58.961] iteration 1649 : loss : 0.160555, loss_ce: 0.058896
[23:36:59.240] iteration 1650 : loss : 0.193924, loss_ce: 0.038266
[23:36:59.523] iteration 1651 : loss : 0.131947, loss_ce: 0.046742
[23:36:59.806] iteration 1652 : loss : 0.151029, loss_ce: 0.065105
[23:37:00.086] iteration 1653 : loss : 0.164634, loss_ce: 0.067017
[23:37:00.374] iteration 1654 : loss : 0.140429, loss_ce: 0.036926
[23:37:00.657] iteration 1655 : loss : 0.215885, loss_ce: 0.041165
[23:37:00.946] iteration 1656 : loss : 0.161206, loss_ce: 0.035481
[23:37:01.228] iteration 1657 : loss : 0.167513, loss_ce: 0.027908
[23:37:01.512] iteration 1658 : loss : 0.195990, loss_ce: 0.048501
[23:37:01.796] iteration 1659 : loss : 0.126664, loss_ce: 0.042923
[23:37:02.081] iteration 1660 : loss : 0.166173, loss_ce: 0.037198
[23:37:02.383] iteration 1661 : loss : 0.166904, loss_ce: 0.031988
[23:37:02.664] iteration 1662 : loss : 0.161014, loss_ce: 0.051692
[23:37:02.944] iteration 1663 : loss : 0.118124, loss_ce: 0.045715
[23:37:03.231] iteration 1664 : loss : 0.149807, loss_ce: 0.040605
[23:37:03.517] iteration 1665 : loss : 0.144350, loss_ce: 0.041431
[23:37:03.802] iteration 1666 : loss : 0.145673, loss_ce: 0.044286
[23:37:04.085] iteration 1667 : loss : 0.177723, loss_ce: 0.080778
[23:37:04.172] iteration 1668 : loss : 0.394275, loss_ce: 0.028690
[23:37:21.298] iteration 1669 : loss : 0.163583, loss_ce: 0.028789
[23:37:21.580] iteration 1670 : loss : 0.203871, loss_ce: 0.028631
[23:37:21.864] iteration 1671 : loss : 0.273641, loss_ce: 0.014569
[23:37:22.143] iteration 1672 : loss : 0.113924, loss_ce: 0.027691
[23:37:22.427] iteration 1673 : loss : 0.191200, loss_ce: 0.027258
[23:37:22.703] iteration 1674 : loss : 0.185784, loss_ce: 0.088433
[23:37:22.981] iteration 1675 : loss : 0.150650, loss_ce: 0.037429
[23:37:23.258] iteration 1676 : loss : 0.198737, loss_ce: 0.082851
[23:37:23.535] iteration 1677 : loss : 0.171379, loss_ce: 0.073059
[23:37:23.811] iteration 1678 : loss : 0.205506, loss_ce: 0.023858
[23:37:24.088] iteration 1679 : loss : 0.280235, loss_ce: 0.038495
[23:37:24.363] iteration 1680 : loss : 0.227301, loss_ce: 0.044992
[23:37:24.662] iteration 1681 : loss : 0.242478, loss_ce: 0.043096
[23:37:24.940] iteration 1682 : loss : 0.204639, loss_ce: 0.056430
[23:37:25.217] iteration 1683 : loss : 0.179901, loss_ce: 0.037106
[23:37:25.496] iteration 1684 : loss : 0.202317, loss_ce: 0.035061
[23:37:25.775] iteration 1685 : loss : 0.193235, loss_ce: 0.036843
[23:37:26.055] iteration 1686 : loss : 0.164311, loss_ce: 0.048193
[23:37:26.334] iteration 1687 : loss : 0.158688, loss_ce: 0.048014
[23:37:26.613] iteration 1688 : loss : 0.168171, loss_ce: 0.031234
[23:37:26.890] iteration 1689 : loss : 0.168820, loss_ce: 0.043367
[23:37:27.170] iteration 1690 : loss : 0.172132, loss_ce: 0.042009
[23:37:27.446] iteration 1691 : loss : 0.207837, loss_ce: 0.025800
[23:37:27.726] iteration 1692 : loss : 0.141796, loss_ce: 0.064713
[23:37:28.005] iteration 1693 : loss : 0.166706, loss_ce: 0.048074
[23:37:28.283] iteration 1694 : loss : 0.155302, loss_ce: 0.058985
[23:37:28.561] iteration 1695 : loss : 0.149996, loss_ce: 0.077424
[23:37:28.837] iteration 1696 : loss : 0.131850, loss_ce: 0.023322
[23:37:29.117] iteration 1697 : loss : 0.114767, loss_ce: 0.029300
[23:37:29.396] iteration 1698 : loss : 0.176758, loss_ce: 0.048367
[23:37:29.674] iteration 1699 : loss : 0.135192, loss_ce: 0.044191
[23:37:29.951] iteration 1700 : loss : 0.126533, loss_ce: 0.037977
[23:37:30.244] iteration 1701 : loss : 0.193586, loss_ce: 0.040535
[23:37:30.521] iteration 1702 : loss : 0.168727, loss_ce: 0.028352
[23:37:30.799] iteration 1703 : loss : 0.204840, loss_ce: 0.077376
[23:37:31.078] iteration 1704 : loss : 0.200552, loss_ce: 0.050480
[23:37:31.357] iteration 1705 : loss : 0.201266, loss_ce: 0.069768
[23:37:31.634] iteration 1706 : loss : 0.173907, loss_ce: 0.042173
[23:37:31.909] iteration 1707 : loss : 0.137628, loss_ce: 0.045775
[23:37:32.188] iteration 1708 : loss : 0.128194, loss_ce: 0.027500
[23:37:32.463] iteration 1709 : loss : 0.201499, loss_ce: 0.046575
[23:37:32.739] iteration 1710 : loss : 0.141262, loss_ce: 0.037900
[23:37:33.016] iteration 1711 : loss : 0.146396, loss_ce: 0.046199
[23:37:33.294] iteration 1712 : loss : 0.220028, loss_ce: 0.077012
[23:37:33.571] iteration 1713 : loss : 0.156078, loss_ce: 0.013351
[23:37:33.847] iteration 1714 : loss : 0.178456, loss_ce: 0.046474
[23:37:34.124] iteration 1715 : loss : 0.189746, loss_ce: 0.045833
[23:37:34.401] iteration 1716 : loss : 0.135601, loss_ce: 0.044709
[23:37:34.682] iteration 1717 : loss : 0.142079, loss_ce: 0.038585
[23:37:34.962] iteration 1718 : loss : 0.140185, loss_ce: 0.060368
[23:37:35.236] iteration 1719 : loss : 0.218768, loss_ce: 0.048191
[23:37:35.514] iteration 1720 : loss : 0.194107, loss_ce: 0.067521
[23:37:35.805] iteration 1721 : loss : 0.180656, loss_ce: 0.036279
[23:37:36.082] iteration 1722 : loss : 0.183548, loss_ce: 0.060239
[23:37:36.360] iteration 1723 : loss : 0.207474, loss_ce: 0.034002
[23:37:36.639] iteration 1724 : loss : 0.174724, loss_ce: 0.020759
[23:37:36.914] iteration 1725 : loss : 0.187137, loss_ce: 0.043938
[23:37:37.193] iteration 1726 : loss : 0.128213, loss_ce: 0.038161
[23:37:37.472] iteration 1727 : loss : 0.119246, loss_ce: 0.029189
[23:37:37.749] iteration 1728 : loss : 0.143419, loss_ce: 0.021778
[23:37:38.026] iteration 1729 : loss : 0.136080, loss_ce: 0.046684
[23:37:38.302] iteration 1730 : loss : 0.170180, loss_ce: 0.023385
[23:37:38.579] iteration 1731 : loss : 0.143024, loss_ce: 0.058138
[23:37:38.856] iteration 1732 : loss : 0.139740, loss_ce: 0.041928
[23:37:39.134] iteration 1733 : loss : 0.123360, loss_ce: 0.037273
[23:37:39.416] iteration 1734 : loss : 0.220624, loss_ce: 0.040680
[23:37:39.697] iteration 1735 : loss : 0.156843, loss_ce: 0.034393
[23:37:39.976] iteration 1736 : loss : 0.124511, loss_ce: 0.039024
[23:37:40.256] iteration 1737 : loss : 0.110669, loss_ce: 0.032620
[23:37:40.531] iteration 1738 : loss : 0.173507, loss_ce: 0.045744
[23:37:40.810] iteration 1739 : loss : 0.127590, loss_ce: 0.037532
[23:37:41.088] iteration 1740 : loss : 0.120289, loss_ce: 0.033285
[23:37:41.384] iteration 1741 : loss : 0.122186, loss_ce: 0.042974
[23:37:41.664] iteration 1742 : loss : 0.144912, loss_ce: 0.039250
[23:37:41.943] iteration 1743 : loss : 0.135564, loss_ce: 0.043298
[23:37:42.226] iteration 1744 : loss : 0.140101, loss_ce: 0.039334
[23:37:42.503] iteration 1745 : loss : 0.123094, loss_ce: 0.035467
[23:37:42.782] iteration 1746 : loss : 0.150185, loss_ce: 0.052005
[23:37:43.065] iteration 1747 : loss : 0.224287, loss_ce: 0.031871
[23:37:43.340] iteration 1748 : loss : 0.236173, loss_ce: 0.064300
[23:37:43.618] iteration 1749 : loss : 0.182155, loss_ce: 0.041605
[23:37:43.899] iteration 1750 : loss : 0.138985, loss_ce: 0.046075
[23:37:44.179] iteration 1751 : loss : 0.158031, loss_ce: 0.049513
[23:37:44.457] iteration 1752 : loss : 0.217183, loss_ce: 0.027150
[23:37:44.736] iteration 1753 : loss : 0.175023, loss_ce: 0.042690
[23:37:45.014] iteration 1754 : loss : 0.107466, loss_ce: 0.033668
[23:37:45.291] iteration 1755 : loss : 0.135498, loss_ce: 0.055221
[23:37:45.567] iteration 1756 : loss : 0.158535, loss_ce: 0.049260
[23:37:45.844] iteration 1757 : loss : 0.165979, loss_ce: 0.048012
[23:37:46.126] iteration 1758 : loss : 0.158518, loss_ce: 0.028118
[23:37:46.403] iteration 1759 : loss : 0.128385, loss_ce: 0.034192
[23:37:46.682] iteration 1760 : loss : 0.289236, loss_ce: 0.039713
[23:37:46.975] iteration 1761 : loss : 0.176635, loss_ce: 0.047667
[23:37:47.252] iteration 1762 : loss : 0.188290, loss_ce: 0.037388
[23:37:47.533] iteration 1763 : loss : 0.209314, loss_ce: 0.044133
[23:37:47.809] iteration 1764 : loss : 0.190253, loss_ce: 0.039100
[23:37:48.088] iteration 1765 : loss : 0.141616, loss_ce: 0.067252
[23:37:48.366] iteration 1766 : loss : 0.201155, loss_ce: 0.042571
[23:37:48.642] iteration 1767 : loss : 0.194539, loss_ce: 0.055592
[23:37:48.920] iteration 1768 : loss : 0.144123, loss_ce: 0.041956
[23:37:49.196] iteration 1769 : loss : 0.165757, loss_ce: 0.048164
[23:37:49.476] iteration 1770 : loss : 0.232828, loss_ce: 0.029849
[23:37:49.754] iteration 1771 : loss : 0.237228, loss_ce: 0.038371
[23:37:50.034] iteration 1772 : loss : 0.191136, loss_ce: 0.031063
[23:37:50.313] iteration 1773 : loss : 0.180102, loss_ce: 0.032410
[23:37:50.589] iteration 1774 : loss : 0.125986, loss_ce: 0.032200
[23:37:50.870] iteration 1775 : loss : 0.142182, loss_ce: 0.058944
[23:37:51.149] iteration 1776 : loss : 0.158724, loss_ce: 0.041693
[23:37:51.424] iteration 1777 : loss : 0.178221, loss_ce: 0.068040
[23:37:51.704] iteration 1778 : loss : 0.220217, loss_ce: 0.068078
[23:37:51.983] iteration 1779 : loss : 0.191447, loss_ce: 0.029266
[23:37:52.261] iteration 1780 : loss : 0.139869, loss_ce: 0.050506
[23:37:52.559] iteration 1781 : loss : 0.224047, loss_ce: 0.021321
[23:37:52.837] iteration 1782 : loss : 0.171618, loss_ce: 0.050338
[23:37:53.117] iteration 1783 : loss : 0.253120, loss_ce: 0.024309
[23:37:53.400] iteration 1784 : loss : 0.174375, loss_ce: 0.028298
[23:37:53.675] iteration 1785 : loss : 0.173368, loss_ce: 0.043511
[23:37:53.959] iteration 1786 : loss : 0.244453, loss_ce: 0.048337
[23:37:54.237] iteration 1787 : loss : 0.222423, loss_ce: 0.071271
[23:37:54.517] iteration 1788 : loss : 0.158892, loss_ce: 0.070243
[23:37:54.795] iteration 1789 : loss : 0.139628, loss_ce: 0.046045
[23:37:55.070] iteration 1790 : loss : 0.218286, loss_ce: 0.057544
[23:37:55.352] iteration 1791 : loss : 0.141940, loss_ce: 0.048493
[23:37:55.636] iteration 1792 : loss : 0.247100, loss_ce: 0.039078
[23:37:55.919] iteration 1793 : loss : 0.182715, loss_ce: 0.022982
[23:37:56.208] iteration 1794 : loss : 0.199383, loss_ce: 0.036670
[23:37:56.488] iteration 1795 : loss : 0.230786, loss_ce: 0.059263
[23:37:56.766] iteration 1796 : loss : 0.141387, loss_ce: 0.049353
[23:37:57.046] iteration 1797 : loss : 0.159910, loss_ce: 0.065039
[23:37:57.338] iteration 1798 : loss : 0.165201, loss_ce: 0.029200
[23:37:57.620] iteration 1799 : loss : 0.180032, loss_ce: 0.033910
[23:37:57.909] iteration 1800 : loss : 0.171599, loss_ce: 0.063811
[23:37:58.209] iteration 1801 : loss : 0.156655, loss_ce: 0.044324
[23:37:58.494] iteration 1802 : loss : 0.146994, loss_ce: 0.041877
[23:37:58.777] iteration 1803 : loss : 0.125441, loss_ce: 0.019275
[23:37:59.060] iteration 1804 : loss : 0.174261, loss_ce: 0.044385
[23:37:59.348] iteration 1805 : loss : 0.195496, loss_ce: 0.048967
[23:37:59.631] iteration 1806 : loss : 0.098863, loss_ce: 0.026010
[23:37:59.708] iteration 1807 : loss : 0.313626, loss_ce: 0.027995
[23:38:19.484] iteration 1808 : loss : 0.209252, loss_ce: 0.026560
[23:38:19.765] iteration 1809 : loss : 0.170543, loss_ce: 0.058093
[23:38:20.044] iteration 1810 : loss : 0.180311, loss_ce: 0.040423
[23:38:20.320] iteration 1811 : loss : 0.192822, loss_ce: 0.039099
[23:38:20.600] iteration 1812 : loss : 0.201232, loss_ce: 0.044985
[23:38:20.880] iteration 1813 : loss : 0.140834, loss_ce: 0.047166
[23:38:21.155] iteration 1814 : loss : 0.138229, loss_ce: 0.038424
[23:38:21.430] iteration 1815 : loss : 0.146030, loss_ce: 0.035486
[23:38:21.706] iteration 1816 : loss : 0.182833, loss_ce: 0.018201
[23:38:21.987] iteration 1817 : loss : 0.195707, loss_ce: 0.038058
[23:38:22.264] iteration 1818 : loss : 0.138266, loss_ce: 0.038852
[23:38:22.542] iteration 1819 : loss : 0.167342, loss_ce: 0.072204
[23:38:22.818] iteration 1820 : loss : 0.211143, loss_ce: 0.043021
[23:38:23.112] iteration 1821 : loss : 0.283801, loss_ce: 0.083832
[23:38:23.388] iteration 1822 : loss : 0.148872, loss_ce: 0.039512
[23:38:23.666] iteration 1823 : loss : 0.161632, loss_ce: 0.065483
[23:38:23.947] iteration 1824 : loss : 0.212990, loss_ce: 0.055126
[23:38:24.225] iteration 1825 : loss : 0.129951, loss_ce: 0.042270
[23:38:24.504] iteration 1826 : loss : 0.163494, loss_ce: 0.033774
[23:38:24.782] iteration 1827 : loss : 0.151832, loss_ce: 0.050230
[23:38:25.063] iteration 1828 : loss : 0.157060, loss_ce: 0.038500
[23:38:25.341] iteration 1829 : loss : 0.134217, loss_ce: 0.053986
[23:38:25.618] iteration 1830 : loss : 0.137203, loss_ce: 0.034941
[23:38:25.898] iteration 1831 : loss : 0.122378, loss_ce: 0.023628
[23:38:26.179] iteration 1832 : loss : 0.187291, loss_ce: 0.055203
[23:38:26.454] iteration 1833 : loss : 0.190379, loss_ce: 0.037321
[23:38:26.732] iteration 1834 : loss : 0.120328, loss_ce: 0.061160
[23:38:27.015] iteration 1835 : loss : 0.102831, loss_ce: 0.012783
[23:38:27.290] iteration 1836 : loss : 0.175060, loss_ce: 0.035103
[23:38:27.565] iteration 1837 : loss : 0.128981, loss_ce: 0.024411
[23:38:27.844] iteration 1838 : loss : 0.167266, loss_ce: 0.022215
[23:38:28.121] iteration 1839 : loss : 0.132309, loss_ce: 0.051698
[23:38:28.400] iteration 1840 : loss : 0.130828, loss_ce: 0.033115
[23:38:28.692] iteration 1841 : loss : 0.151449, loss_ce: 0.048455
[23:38:28.971] iteration 1842 : loss : 0.160822, loss_ce: 0.044346
[23:38:29.248] iteration 1843 : loss : 0.164444, loss_ce: 0.021120
[23:38:29.528] iteration 1844 : loss : 0.296277, loss_ce: 0.039614
[23:38:29.807] iteration 1845 : loss : 0.198515, loss_ce: 0.034915
[23:38:30.084] iteration 1846 : loss : 0.291774, loss_ce: 0.025131
[23:38:30.364] iteration 1847 : loss : 0.138342, loss_ce: 0.039338
[23:38:30.640] iteration 1848 : loss : 0.153566, loss_ce: 0.036447
[23:38:30.918] iteration 1849 : loss : 0.190853, loss_ce: 0.041295
[23:38:31.193] iteration 1850 : loss : 0.140053, loss_ce: 0.047570
[23:38:31.475] iteration 1851 : loss : 0.125928, loss_ce: 0.052176
[23:38:31.751] iteration 1852 : loss : 0.131978, loss_ce: 0.028310
[23:38:32.035] iteration 1853 : loss : 0.164228, loss_ce: 0.045206
[23:38:32.316] iteration 1854 : loss : 0.186274, loss_ce: 0.040919
[23:38:32.601] iteration 1855 : loss : 0.129497, loss_ce: 0.042495
[23:38:32.883] iteration 1856 : loss : 0.090735, loss_ce: 0.024061
[23:38:33.161] iteration 1857 : loss : 0.139843, loss_ce: 0.040156
[23:38:33.438] iteration 1858 : loss : 0.141048, loss_ce: 0.038490
[23:38:33.715] iteration 1859 : loss : 0.155545, loss_ce: 0.035335
[23:38:33.992] iteration 1860 : loss : 0.138026, loss_ce: 0.063277
[23:38:34.289] iteration 1861 : loss : 0.156630, loss_ce: 0.051761
[23:38:34.574] iteration 1862 : loss : 0.170183, loss_ce: 0.050497
[23:38:34.849] iteration 1863 : loss : 0.182465, loss_ce: 0.025921
[23:38:35.127] iteration 1864 : loss : 0.139711, loss_ce: 0.047841
[23:38:35.405] iteration 1865 : loss : 0.212431, loss_ce: 0.036554
[23:38:35.682] iteration 1866 : loss : 0.163685, loss_ce: 0.050235
[23:38:35.962] iteration 1867 : loss : 0.109963, loss_ce: 0.031165
[23:38:36.236] iteration 1868 : loss : 0.124232, loss_ce: 0.047583
[23:38:36.517] iteration 1869 : loss : 0.123327, loss_ce: 0.028884
[23:38:36.794] iteration 1870 : loss : 0.134807, loss_ce: 0.051680
[23:38:37.076] iteration 1871 : loss : 0.176944, loss_ce: 0.035028
[23:38:37.352] iteration 1872 : loss : 0.169212, loss_ce: 0.038880
[23:38:37.629] iteration 1873 : loss : 0.165833, loss_ce: 0.035912
[23:38:37.909] iteration 1874 : loss : 0.212757, loss_ce: 0.029807
[23:38:38.193] iteration 1875 : loss : 0.141362, loss_ce: 0.047273
[23:38:38.468] iteration 1876 : loss : 0.143738, loss_ce: 0.029629
[23:38:38.749] iteration 1877 : loss : 0.127064, loss_ce: 0.026488
[23:38:39.025] iteration 1878 : loss : 0.161621, loss_ce: 0.038049
[23:38:39.307] iteration 1879 : loss : 0.152470, loss_ce: 0.062868
[23:38:39.588] iteration 1880 : loss : 0.168408, loss_ce: 0.057504
[23:38:39.875] iteration 1881 : loss : 0.201212, loss_ce: 0.038807
[23:38:40.154] iteration 1882 : loss : 0.174882, loss_ce: 0.059770
[23:38:40.430] iteration 1883 : loss : 0.178946, loss_ce: 0.035149
[23:38:40.712] iteration 1884 : loss : 0.150135, loss_ce: 0.040707
[23:38:40.993] iteration 1885 : loss : 0.225717, loss_ce: 0.054663
[23:38:41.269] iteration 1886 : loss : 0.157612, loss_ce: 0.040496
[23:38:41.547] iteration 1887 : loss : 0.200720, loss_ce: 0.051276
[23:38:41.825] iteration 1888 : loss : 0.171207, loss_ce: 0.057080
[23:38:42.101] iteration 1889 : loss : 0.179025, loss_ce: 0.065057
[23:38:42.378] iteration 1890 : loss : 0.156166, loss_ce: 0.068625
[23:38:42.657] iteration 1891 : loss : 0.136899, loss_ce: 0.041907
[23:38:42.937] iteration 1892 : loss : 0.141921, loss_ce: 0.031336
[23:38:43.218] iteration 1893 : loss : 0.120406, loss_ce: 0.032249
[23:38:43.493] iteration 1894 : loss : 0.150036, loss_ce: 0.044585
[23:38:43.772] iteration 1895 : loss : 0.147766, loss_ce: 0.057571
[23:38:44.047] iteration 1896 : loss : 0.207322, loss_ce: 0.053608
[23:38:44.326] iteration 1897 : loss : 0.137441, loss_ce: 0.032167
[23:38:44.608] iteration 1898 : loss : 0.144904, loss_ce: 0.052292
[23:38:44.884] iteration 1899 : loss : 0.114964, loss_ce: 0.041459
[23:38:45.161] iteration 1900 : loss : 0.153962, loss_ce: 0.036578
[23:38:45.460] iteration 1901 : loss : 0.140459, loss_ce: 0.042809
[23:38:45.735] iteration 1902 : loss : 0.195423, loss_ce: 0.051030
[23:38:46.012] iteration 1903 : loss : 0.134218, loss_ce: 0.052049
[23:38:46.291] iteration 1904 : loss : 0.192729, loss_ce: 0.035667
[23:38:46.571] iteration 1905 : loss : 0.160084, loss_ce: 0.052828
[23:38:46.848] iteration 1906 : loss : 0.167359, loss_ce: 0.035748
[23:38:47.128] iteration 1907 : loss : 0.154402, loss_ce: 0.043938
[23:38:47.407] iteration 1908 : loss : 0.175847, loss_ce: 0.041206
[23:38:47.685] iteration 1909 : loss : 0.152140, loss_ce: 0.021094
[23:38:47.964] iteration 1910 : loss : 0.157230, loss_ce: 0.048888
[23:38:48.246] iteration 1911 : loss : 0.178070, loss_ce: 0.064956
[23:38:48.526] iteration 1912 : loss : 0.234022, loss_ce: 0.034855
[23:38:48.805] iteration 1913 : loss : 0.126763, loss_ce: 0.035636
[23:38:49.084] iteration 1914 : loss : 0.156696, loss_ce: 0.052431
[23:38:49.367] iteration 1915 : loss : 0.168825, loss_ce: 0.028588
[23:38:49.648] iteration 1916 : loss : 0.155148, loss_ce: 0.017653
[23:38:49.928] iteration 1917 : loss : 0.142371, loss_ce: 0.025403
[23:38:50.205] iteration 1918 : loss : 0.105400, loss_ce: 0.012926
[23:38:50.485] iteration 1919 : loss : 0.189611, loss_ce: 0.041175
[23:38:50.761] iteration 1920 : loss : 0.188389, loss_ce: 0.046892
[23:38:51.054] iteration 1921 : loss : 0.159549, loss_ce: 0.026139
[23:38:51.333] iteration 1922 : loss : 0.191390, loss_ce: 0.085435
[23:38:51.609] iteration 1923 : loss : 0.174172, loss_ce: 0.035107
[23:38:51.889] iteration 1924 : loss : 0.149024, loss_ce: 0.043002
[23:38:52.164] iteration 1925 : loss : 0.160681, loss_ce: 0.014568
[23:38:52.445] iteration 1926 : loss : 0.119696, loss_ce: 0.024706
[23:38:52.723] iteration 1927 : loss : 0.156659, loss_ce: 0.036306
[23:38:53.002] iteration 1928 : loss : 0.191883, loss_ce: 0.018935
[23:38:53.279] iteration 1929 : loss : 0.156585, loss_ce: 0.050702
[23:38:53.556] iteration 1930 : loss : 0.131809, loss_ce: 0.052454
[23:38:53.841] iteration 1931 : loss : 0.169546, loss_ce: 0.036138
[23:38:54.126] iteration 1932 : loss : 0.123098, loss_ce: 0.033598
[23:38:54.406] iteration 1933 : loss : 0.095319, loss_ce: 0.029278
[23:38:54.694] iteration 1934 : loss : 0.139415, loss_ce: 0.037724
[23:38:54.976] iteration 1935 : loss : 0.230825, loss_ce: 0.075830
[23:38:55.258] iteration 1936 : loss : 0.222120, loss_ce: 0.023774
[23:38:55.543] iteration 1937 : loss : 0.161551, loss_ce: 0.020237
[23:38:55.825] iteration 1938 : loss : 0.134049, loss_ce: 0.031487
[23:38:56.112] iteration 1939 : loss : 0.149135, loss_ce: 0.033590
[23:38:56.396] iteration 1940 : loss : 0.165398, loss_ce: 0.037809
[23:38:56.714] iteration 1941 : loss : 0.121339, loss_ce: 0.040088
[23:38:56.994] iteration 1942 : loss : 0.180855, loss_ce: 0.052784
[23:38:57.280] iteration 1943 : loss : 0.216928, loss_ce: 0.037642
[23:38:57.563] iteration 1944 : loss : 0.141363, loss_ce: 0.035336
[23:38:57.848] iteration 1945 : loss : 0.167939, loss_ce: 0.019888
[23:38:57.924] iteration 1946 : loss : 0.313271, loss_ce: 0.071561
[23:39:15.268] iteration 1947 : loss : 0.141633, loss_ce: 0.028707
[23:39:15.546] iteration 1948 : loss : 0.130982, loss_ce: 0.028221
[23:39:15.831] iteration 1949 : loss : 0.182952, loss_ce: 0.016840
[23:39:16.110] iteration 1950 : loss : 0.179113, loss_ce: 0.028145
[23:39:16.395] iteration 1951 : loss : 0.132241, loss_ce: 0.050964
[23:39:16.673] iteration 1952 : loss : 0.190283, loss_ce: 0.057699
[23:39:16.950] iteration 1953 : loss : 0.204474, loss_ce: 0.079389
[23:39:17.225] iteration 1954 : loss : 0.177850, loss_ce: 0.045956
[23:39:17.499] iteration 1955 : loss : 0.219591, loss_ce: 0.023439
[23:39:17.775] iteration 1956 : loss : 0.131273, loss_ce: 0.061714
[23:39:18.053] iteration 1957 : loss : 0.120794, loss_ce: 0.029311
[23:39:18.328] iteration 1958 : loss : 0.176187, loss_ce: 0.035571
[23:39:18.604] iteration 1959 : loss : 0.147879, loss_ce: 0.017681
[23:39:18.885] iteration 1960 : loss : 0.120094, loss_ce: 0.028802
[23:39:19.184] iteration 1961 : loss : 0.176674, loss_ce: 0.025188
[23:39:19.462] iteration 1962 : loss : 0.163534, loss_ce: 0.026508
[23:39:19.741] iteration 1963 : loss : 0.302455, loss_ce: 0.022066
[23:39:20.025] iteration 1964 : loss : 0.101572, loss_ce: 0.033697
[23:39:20.301] iteration 1965 : loss : 0.177443, loss_ce: 0.024779
[23:39:20.582] iteration 1966 : loss : 0.191848, loss_ce: 0.047864
[23:39:20.862] iteration 1967 : loss : 0.206280, loss_ce: 0.057702
[23:39:21.142] iteration 1968 : loss : 0.110154, loss_ce: 0.047891
[23:39:21.422] iteration 1969 : loss : 0.118775, loss_ce: 0.038662
[23:39:21.704] iteration 1970 : loss : 0.224817, loss_ce: 0.040563
[23:39:21.983] iteration 1971 : loss : 0.205885, loss_ce: 0.043247
[23:39:22.268] iteration 1972 : loss : 0.181207, loss_ce: 0.054466
[23:39:22.544] iteration 1973 : loss : 0.133793, loss_ce: 0.058747
[23:39:22.819] iteration 1974 : loss : 0.191825, loss_ce: 0.037837
[23:39:23.099] iteration 1975 : loss : 0.178607, loss_ce: 0.025106
[23:39:23.377] iteration 1976 : loss : 0.156006, loss_ce: 0.063763
[23:39:23.654] iteration 1977 : loss : 0.220288, loss_ce: 0.049428
[23:39:23.931] iteration 1978 : loss : 0.153858, loss_ce: 0.037001
[23:39:24.211] iteration 1979 : loss : 0.182964, loss_ce: 0.032470
[23:39:24.491] iteration 1980 : loss : 0.195506, loss_ce: 0.041567
[23:39:24.783] iteration 1981 : loss : 0.124874, loss_ce: 0.058550
[23:39:25.058] iteration 1982 : loss : 0.129801, loss_ce: 0.060023
[23:39:25.343] iteration 1983 : loss : 0.221350, loss_ce: 0.052301
[23:39:25.619] iteration 1984 : loss : 0.170423, loss_ce: 0.035781
[23:39:25.897] iteration 1985 : loss : 0.187958, loss_ce: 0.024125
[23:39:26.176] iteration 1986 : loss : 0.194271, loss_ce: 0.040487
[23:39:26.456] iteration 1987 : loss : 0.143336, loss_ce: 0.017374
[23:39:26.732] iteration 1988 : loss : 0.117150, loss_ce: 0.055046
[23:39:27.007] iteration 1989 : loss : 0.191810, loss_ce: 0.035829
[23:39:27.285] iteration 1990 : loss : 0.193299, loss_ce: 0.104269
[23:39:27.566] iteration 1991 : loss : 0.140671, loss_ce: 0.048066
[23:39:27.847] iteration 1992 : loss : 0.224303, loss_ce: 0.034086
[23:39:28.123] iteration 1993 : loss : 0.140826, loss_ce: 0.051670
[23:39:28.400] iteration 1994 : loss : 0.105117, loss_ce: 0.026007
[23:39:28.682] iteration 1995 : loss : 0.210261, loss_ce: 0.043776
[23:39:28.958] iteration 1996 : loss : 0.170172, loss_ce: 0.075260
[23:39:29.238] iteration 1997 : loss : 0.243639, loss_ce: 0.101093
[23:39:29.521] iteration 1998 : loss : 0.203722, loss_ce: 0.013438
[23:39:29.798] iteration 1999 : loss : 0.194619, loss_ce: 0.023296
[23:39:30.076] iteration 2000 : loss : 0.199677, loss_ce: 0.019117
[23:39:30.372] iteration 2001 : loss : 0.168958, loss_ce: 0.023719
[23:39:30.647] iteration 2002 : loss : 0.115818, loss_ce: 0.035025
[23:39:30.923] iteration 2003 : loss : 0.222521, loss_ce: 0.047555
[23:39:31.204] iteration 2004 : loss : 0.146320, loss_ce: 0.055923
[23:39:31.482] iteration 2005 : loss : 0.198765, loss_ce: 0.034910
[23:39:31.759] iteration 2006 : loss : 0.152347, loss_ce: 0.040911
[23:39:32.034] iteration 2007 : loss : 0.145999, loss_ce: 0.032553
[23:39:32.316] iteration 2008 : loss : 0.184584, loss_ce: 0.036572
[23:39:32.598] iteration 2009 : loss : 0.148407, loss_ce: 0.042793
[23:39:32.878] iteration 2010 : loss : 0.211534, loss_ce: 0.053831
[23:39:33.160] iteration 2011 : loss : 0.103232, loss_ce: 0.019061
[23:39:33.434] iteration 2012 : loss : 0.152948, loss_ce: 0.038049
[23:39:33.711] iteration 2013 : loss : 0.121195, loss_ce: 0.049886
[23:39:33.990] iteration 2014 : loss : 0.193023, loss_ce: 0.019002
[23:39:34.267] iteration 2015 : loss : 0.156130, loss_ce: 0.049973
[23:39:34.549] iteration 2016 : loss : 0.143052, loss_ce: 0.045836
[23:39:34.827] iteration 2017 : loss : 0.121750, loss_ce: 0.038865
[23:39:35.107] iteration 2018 : loss : 0.158418, loss_ce: 0.036482
[23:39:35.384] iteration 2019 : loss : 0.115861, loss_ce: 0.036257
[23:39:35.664] iteration 2020 : loss : 0.098392, loss_ce: 0.022108
[23:39:35.961] iteration 2021 : loss : 0.142047, loss_ce: 0.034702
[23:39:36.235] iteration 2022 : loss : 0.248398, loss_ce: 0.026841
[23:39:36.514] iteration 2023 : loss : 0.216676, loss_ce: 0.026045
[23:39:36.795] iteration 2024 : loss : 0.195109, loss_ce: 0.022882
[23:39:37.072] iteration 2025 : loss : 0.198111, loss_ce: 0.033195
[23:39:37.347] iteration 2026 : loss : 0.116694, loss_ce: 0.029634
[23:39:37.627] iteration 2027 : loss : 0.112409, loss_ce: 0.045305
[23:39:37.903] iteration 2028 : loss : 0.122241, loss_ce: 0.069223
[23:39:38.184] iteration 2029 : loss : 0.231488, loss_ce: 0.030058
[23:39:38.461] iteration 2030 : loss : 0.117485, loss_ce: 0.044354
[23:39:38.742] iteration 2031 : loss : 0.110148, loss_ce: 0.034892
[23:39:39.021] iteration 2032 : loss : 0.131406, loss_ce: 0.038164
[23:39:39.302] iteration 2033 : loss : 0.162197, loss_ce: 0.055682
[23:39:39.583] iteration 2034 : loss : 0.107069, loss_ce: 0.039819
[23:39:39.860] iteration 2035 : loss : 0.145444, loss_ce: 0.058180
[23:39:40.143] iteration 2036 : loss : 0.120603, loss_ce: 0.036174
[23:39:40.422] iteration 2037 : loss : 0.125878, loss_ce: 0.038640
[23:39:40.699] iteration 2038 : loss : 0.189560, loss_ce: 0.024298
[23:39:40.978] iteration 2039 : loss : 0.197813, loss_ce: 0.026147
[23:39:41.257] iteration 2040 : loss : 0.155772, loss_ce: 0.039472
[23:39:41.552] iteration 2041 : loss : 0.106140, loss_ce: 0.025774
[23:39:41.831] iteration 2042 : loss : 0.156303, loss_ce: 0.044270
[23:39:42.108] iteration 2043 : loss : 0.188737, loss_ce: 0.050124
[23:39:42.387] iteration 2044 : loss : 0.142084, loss_ce: 0.028375
[23:39:42.666] iteration 2045 : loss : 0.205848, loss_ce: 0.017124
[23:39:42.943] iteration 2046 : loss : 0.166250, loss_ce: 0.046321
[23:39:43.223] iteration 2047 : loss : 0.131857, loss_ce: 0.069880
[23:39:43.503] iteration 2048 : loss : 0.162774, loss_ce: 0.047883
[23:39:43.779] iteration 2049 : loss : 0.144345, loss_ce: 0.032123
[23:39:44.054] iteration 2050 : loss : 0.174328, loss_ce: 0.051856
[23:39:44.332] iteration 2051 : loss : 0.200169, loss_ce: 0.045693
[23:39:44.614] iteration 2052 : loss : 0.133596, loss_ce: 0.058847
[23:39:44.888] iteration 2053 : loss : 0.181916, loss_ce: 0.040718
[23:39:45.166] iteration 2054 : loss : 0.160970, loss_ce: 0.039077
[23:39:45.444] iteration 2055 : loss : 0.180092, loss_ce: 0.020658
[23:39:45.723] iteration 2056 : loss : 0.165489, loss_ce: 0.038448
[23:39:46.001] iteration 2057 : loss : 0.116628, loss_ce: 0.030172
[23:39:46.280] iteration 2058 : loss : 0.160121, loss_ce: 0.039756
[23:39:46.558] iteration 2059 : loss : 0.147427, loss_ce: 0.052836
[23:39:46.839] iteration 2060 : loss : 0.104097, loss_ce: 0.027558
[23:39:47.131] iteration 2061 : loss : 0.144953, loss_ce: 0.036835
[23:39:47.408] iteration 2062 : loss : 0.110395, loss_ce: 0.038992
[23:39:47.685] iteration 2063 : loss : 0.147733, loss_ce: 0.072952
[23:39:47.962] iteration 2064 : loss : 0.169802, loss_ce: 0.052270
[23:39:48.240] iteration 2065 : loss : 0.118944, loss_ce: 0.039855
[23:39:48.517] iteration 2066 : loss : 0.187210, loss_ce: 0.033169
[23:39:48.793] iteration 2067 : loss : 0.111995, loss_ce: 0.033567
[23:39:49.075] iteration 2068 : loss : 0.131359, loss_ce: 0.059549
[23:39:49.361] iteration 2069 : loss : 0.119260, loss_ce: 0.033404
[23:39:49.645] iteration 2070 : loss : 0.132337, loss_ce: 0.056078
[23:39:49.925] iteration 2071 : loss : 0.102403, loss_ce: 0.029261
[23:39:50.210] iteration 2072 : loss : 0.211784, loss_ce: 0.019957
[23:39:50.494] iteration 2073 : loss : 0.126397, loss_ce: 0.037446
[23:39:50.774] iteration 2074 : loss : 0.169316, loss_ce: 0.034329
[23:39:51.055] iteration 2075 : loss : 0.194170, loss_ce: 0.035035
[23:39:51.338] iteration 2076 : loss : 0.146635, loss_ce: 0.030940
[23:39:51.616] iteration 2077 : loss : 0.090226, loss_ce: 0.030681
[23:39:51.902] iteration 2078 : loss : 0.130992, loss_ce: 0.043735
[23:39:52.183] iteration 2079 : loss : 0.116270, loss_ce: 0.033767
[23:39:52.461] iteration 2080 : loss : 0.206551, loss_ce: 0.055527
[23:39:52.777] iteration 2081 : loss : 0.097435, loss_ce: 0.039073
[23:39:53.057] iteration 2082 : loss : 0.174455, loss_ce: 0.049940
[23:39:53.338] iteration 2083 : loss : 0.173118, loss_ce: 0.028212
[23:39:53.618] iteration 2084 : loss : 0.349803, loss_ce: 0.033199
[23:39:53.695] iteration 2085 : loss : 0.345401, loss_ce: 0.098983
[23:40:11.349] iteration 2086 : loss : 0.111952, loss_ce: 0.043865
[23:40:11.628] iteration 2087 : loss : 0.140785, loss_ce: 0.033153
[23:40:11.911] iteration 2088 : loss : 0.152354, loss_ce: 0.063785
[23:40:12.199] iteration 2089 : loss : 0.141777, loss_ce: 0.033839
[23:40:12.483] iteration 2090 : loss : 0.170689, loss_ce: 0.033965
[23:40:12.757] iteration 2091 : loss : 0.099908, loss_ce: 0.024154
[23:40:13.034] iteration 2092 : loss : 0.112893, loss_ce: 0.040956
[23:40:13.309] iteration 2093 : loss : 0.120003, loss_ce: 0.025346
[23:40:13.587] iteration 2094 : loss : 0.187433, loss_ce: 0.044997
[23:40:13.865] iteration 2095 : loss : 0.127782, loss_ce: 0.062982
[23:40:14.139] iteration 2096 : loss : 0.124485, loss_ce: 0.042228
[23:40:14.417] iteration 2097 : loss : 0.121216, loss_ce: 0.024725
[23:40:14.694] iteration 2098 : loss : 0.139479, loss_ce: 0.040694
[23:40:14.969] iteration 2099 : loss : 0.118213, loss_ce: 0.037227
[23:40:15.245] iteration 2100 : loss : 0.167019, loss_ce: 0.031551
[23:40:15.535] iteration 2101 : loss : 0.129979, loss_ce: 0.035718
[23:40:15.812] iteration 2102 : loss : 0.098306, loss_ce: 0.033020
[23:40:16.090] iteration 2103 : loss : 0.176495, loss_ce: 0.040975
[23:40:16.368] iteration 2104 : loss : 0.127164, loss_ce: 0.040489
[23:40:16.647] iteration 2105 : loss : 0.093794, loss_ce: 0.044376
[23:40:16.921] iteration 2106 : loss : 0.140679, loss_ce: 0.032121
[23:40:17.200] iteration 2107 : loss : 0.138128, loss_ce: 0.030068
[23:40:17.479] iteration 2108 : loss : 0.156629, loss_ce: 0.025565
[23:40:17.756] iteration 2109 : loss : 0.205911, loss_ce: 0.027796
[23:40:18.034] iteration 2110 : loss : 0.098646, loss_ce: 0.038839
[23:40:18.310] iteration 2111 : loss : 0.141850, loss_ce: 0.028569
[23:40:18.587] iteration 2112 : loss : 0.104239, loss_ce: 0.034025
[23:40:18.864] iteration 2113 : loss : 0.166330, loss_ce: 0.030321
[23:40:19.142] iteration 2114 : loss : 0.114858, loss_ce: 0.048418
[23:40:19.420] iteration 2115 : loss : 0.110662, loss_ce: 0.040092
[23:40:19.699] iteration 2116 : loss : 0.267588, loss_ce: 0.018736
[23:40:19.976] iteration 2117 : loss : 0.170155, loss_ce: 0.027165
[23:40:20.254] iteration 2118 : loss : 0.150936, loss_ce: 0.037560
[23:40:20.530] iteration 2119 : loss : 0.160032, loss_ce: 0.039572
[23:40:20.810] iteration 2120 : loss : 0.104222, loss_ce: 0.034932
[23:40:21.100] iteration 2121 : loss : 0.147983, loss_ce: 0.041142
[23:40:21.376] iteration 2122 : loss : 0.137753, loss_ce: 0.030484
[23:40:21.653] iteration 2123 : loss : 0.088206, loss_ce: 0.030287
[23:40:21.932] iteration 2124 : loss : 0.105181, loss_ce: 0.038069
[23:40:22.209] iteration 2125 : loss : 0.156066, loss_ce: 0.055280
[23:40:22.486] iteration 2126 : loss : 0.202175, loss_ce: 0.015013
[23:40:22.762] iteration 2127 : loss : 0.111752, loss_ce: 0.049503
[23:40:23.039] iteration 2128 : loss : 0.155363, loss_ce: 0.033982
[23:40:23.316] iteration 2129 : loss : 0.106198, loss_ce: 0.029070
[23:40:23.598] iteration 2130 : loss : 0.081801, loss_ce: 0.021256
[23:40:23.876] iteration 2131 : loss : 0.194578, loss_ce: 0.017985
[23:40:24.154] iteration 2132 : loss : 0.150872, loss_ce: 0.056145
[23:40:24.433] iteration 2133 : loss : 0.146961, loss_ce: 0.024908
[23:40:24.712] iteration 2134 : loss : 0.127470, loss_ce: 0.015439
[23:40:24.991] iteration 2135 : loss : 0.182163, loss_ce: 0.023300
[23:40:25.269] iteration 2136 : loss : 0.137314, loss_ce: 0.034689
[23:40:25.547] iteration 2137 : loss : 0.146631, loss_ce: 0.048460
[23:40:25.826] iteration 2138 : loss : 0.236643, loss_ce: 0.053789
[23:40:26.105] iteration 2139 : loss : 0.113101, loss_ce: 0.037604
[23:40:26.380] iteration 2140 : loss : 0.110650, loss_ce: 0.036601
[23:40:26.671] iteration 2141 : loss : 0.150695, loss_ce: 0.039022
[23:40:26.949] iteration 2142 : loss : 0.167288, loss_ce: 0.022757
[23:40:27.225] iteration 2143 : loss : 0.140893, loss_ce: 0.039104
[23:40:27.502] iteration 2144 : loss : 0.143598, loss_ce: 0.026977
[23:40:27.780] iteration 2145 : loss : 0.129312, loss_ce: 0.028427
[23:40:28.058] iteration 2146 : loss : 0.119098, loss_ce: 0.045888
[23:40:28.334] iteration 2147 : loss : 0.146888, loss_ce: 0.033847
[23:40:28.614] iteration 2148 : loss : 0.107125, loss_ce: 0.023179
[23:40:28.894] iteration 2149 : loss : 0.124966, loss_ce: 0.036088
[23:40:29.174] iteration 2150 : loss : 0.094503, loss_ce: 0.033429
[23:40:29.456] iteration 2151 : loss : 0.183655, loss_ce: 0.013053
[23:40:29.736] iteration 2152 : loss : 0.195331, loss_ce: 0.029434
[23:40:30.014] iteration 2153 : loss : 0.176854, loss_ce: 0.029966
[23:40:30.294] iteration 2154 : loss : 0.098832, loss_ce: 0.034131
[23:40:30.572] iteration 2155 : loss : 0.118535, loss_ce: 0.045883
[23:40:30.849] iteration 2156 : loss : 0.090963, loss_ce: 0.028413
[23:40:31.128] iteration 2157 : loss : 0.093667, loss_ce: 0.033837
[23:40:31.406] iteration 2158 : loss : 0.205237, loss_ce: 0.049079
[23:40:31.689] iteration 2159 : loss : 0.129695, loss_ce: 0.031845
[23:40:31.965] iteration 2160 : loss : 0.132312, loss_ce: 0.050001
[23:40:32.258] iteration 2161 : loss : 0.126901, loss_ce: 0.050677
[23:40:32.537] iteration 2162 : loss : 0.152064, loss_ce: 0.024943
[23:40:32.812] iteration 2163 : loss : 0.077735, loss_ce: 0.023602
[23:40:33.094] iteration 2164 : loss : 0.107399, loss_ce: 0.030973
[23:40:33.369] iteration 2165 : loss : 0.152005, loss_ce: 0.048817
[23:40:33.646] iteration 2166 : loss : 0.181712, loss_ce: 0.031785
[23:40:33.924] iteration 2167 : loss : 0.264887, loss_ce: 0.006033
[23:40:34.197] iteration 2168 : loss : 0.142786, loss_ce: 0.035626
[23:40:34.478] iteration 2169 : loss : 0.108580, loss_ce: 0.044467
[23:40:34.755] iteration 2170 : loss : 0.116733, loss_ce: 0.023185
[23:40:35.032] iteration 2171 : loss : 0.134698, loss_ce: 0.029658
[23:40:35.312] iteration 2172 : loss : 0.107960, loss_ce: 0.050102
[23:40:35.589] iteration 2173 : loss : 0.194372, loss_ce: 0.049454
[23:40:35.869] iteration 2174 : loss : 0.102706, loss_ce: 0.024340
[23:40:36.149] iteration 2175 : loss : 0.104822, loss_ce: 0.068708
[23:40:36.429] iteration 2176 : loss : 0.109377, loss_ce: 0.028368
[23:40:36.708] iteration 2177 : loss : 0.144703, loss_ce: 0.049076
[23:40:36.985] iteration 2178 : loss : 0.146177, loss_ce: 0.042208
[23:40:37.264] iteration 2179 : loss : 0.162794, loss_ce: 0.045807
[23:40:37.542] iteration 2180 : loss : 0.189211, loss_ce: 0.028169
[23:40:37.836] iteration 2181 : loss : 0.133158, loss_ce: 0.044747
[23:40:38.115] iteration 2182 : loss : 0.198592, loss_ce: 0.027289
[23:40:38.393] iteration 2183 : loss : 0.168438, loss_ce: 0.048010
[23:40:38.672] iteration 2184 : loss : 0.154341, loss_ce: 0.045159
[23:40:38.952] iteration 2185 : loss : 0.114311, loss_ce: 0.037251
[23:40:39.237] iteration 2186 : loss : 0.120030, loss_ce: 0.036765
[23:40:39.515] iteration 2187 : loss : 0.186834, loss_ce: 0.048014
[23:40:39.793] iteration 2188 : loss : 0.118129, loss_ce: 0.037200
[23:40:40.067] iteration 2189 : loss : 0.146819, loss_ce: 0.041364
[23:40:40.346] iteration 2190 : loss : 0.130929, loss_ce: 0.052669
[23:40:40.623] iteration 2191 : loss : 0.179520, loss_ce: 0.052697
[23:40:40.901] iteration 2192 : loss : 0.101988, loss_ce: 0.024741
[23:40:41.181] iteration 2193 : loss : 0.154464, loss_ce: 0.037969
[23:40:41.459] iteration 2194 : loss : 0.114990, loss_ce: 0.043117
[23:40:41.737] iteration 2195 : loss : 0.272838, loss_ce: 0.012549
[23:40:42.014] iteration 2196 : loss : 0.121492, loss_ce: 0.030863
[23:40:42.291] iteration 2197 : loss : 0.093318, loss_ce: 0.028220
[23:40:42.569] iteration 2198 : loss : 0.133208, loss_ce: 0.026372
[23:40:42.847] iteration 2199 : loss : 0.142095, loss_ce: 0.039225
[23:40:43.129] iteration 2200 : loss : 0.198774, loss_ce: 0.022395
[23:40:43.429] iteration 2201 : loss : 0.448221, loss_ce: 0.009286
[23:40:43.705] iteration 2202 : loss : 0.196320, loss_ce: 0.023877
[23:40:43.986] iteration 2203 : loss : 0.135110, loss_ce: 0.040341
[23:40:44.264] iteration 2204 : loss : 0.151072, loss_ce: 0.041431
[23:40:44.541] iteration 2205 : loss : 0.151924, loss_ce: 0.048366
[23:40:44.819] iteration 2206 : loss : 0.196205, loss_ce: 0.022400
[23:40:45.100] iteration 2207 : loss : 0.138970, loss_ce: 0.028486
[23:40:45.387] iteration 2208 : loss : 0.202569, loss_ce: 0.058933
[23:40:45.669] iteration 2209 : loss : 0.135602, loss_ce: 0.034172
[23:40:45.949] iteration 2210 : loss : 0.201316, loss_ce: 0.045432
[23:40:46.232] iteration 2211 : loss : 0.130260, loss_ce: 0.036178
[23:40:46.509] iteration 2212 : loss : 0.160889, loss_ce: 0.027012
[23:40:46.788] iteration 2213 : loss : 0.174906, loss_ce: 0.027095
[23:40:47.070] iteration 2214 : loss : 0.181063, loss_ce: 0.037746
[23:40:47.354] iteration 2215 : loss : 0.123280, loss_ce: 0.026998
[23:40:47.632] iteration 2216 : loss : 0.131278, loss_ce: 0.042128
[23:40:47.918] iteration 2217 : loss : 0.132968, loss_ce: 0.040445
[23:40:48.198] iteration 2218 : loss : 0.225856, loss_ce: 0.024491
[23:40:48.480] iteration 2219 : loss : 0.219893, loss_ce: 0.056528
[23:40:48.765] iteration 2220 : loss : 0.102704, loss_ce: 0.037954
[23:40:49.069] iteration 2221 : loss : 0.131431, loss_ce: 0.039665
[23:40:49.353] iteration 2222 : loss : 0.126698, loss_ce: 0.045256
[23:40:49.632] iteration 2223 : loss : 0.215710, loss_ce: 0.030799
[23:40:49.711] iteration 2224 : loss : 0.339319, loss_ce: 0.034525
[23:41:07.247] iteration 2225 : loss : 0.184349, loss_ce: 0.064094
[23:41:07.529] iteration 2226 : loss : 0.208888, loss_ce: 0.043221
[23:41:07.811] iteration 2227 : loss : 0.131214, loss_ce: 0.031201
[23:41:08.097] iteration 2228 : loss : 0.172608, loss_ce: 0.041222
[23:41:08.383] iteration 2229 : loss : 0.187515, loss_ce: 0.025779
[23:41:08.658] iteration 2230 : loss : 0.126861, loss_ce: 0.023203
[23:41:08.938] iteration 2231 : loss : 0.114578, loss_ce: 0.022225
[23:41:09.217] iteration 2232 : loss : 0.184846, loss_ce: 0.022440
[23:41:09.497] iteration 2233 : loss : 0.085721, loss_ce: 0.026000
[23:41:09.774] iteration 2234 : loss : 0.170201, loss_ce: 0.050179
[23:41:10.048] iteration 2235 : loss : 0.120894, loss_ce: 0.049875
[23:41:10.329] iteration 2236 : loss : 0.161668, loss_ce: 0.030307
[23:41:10.610] iteration 2237 : loss : 0.115594, loss_ce: 0.034925
[23:41:10.890] iteration 2238 : loss : 0.132190, loss_ce: 0.035559
[23:41:11.166] iteration 2239 : loss : 0.120145, loss_ce: 0.022449
[23:41:11.444] iteration 2240 : loss : 0.093277, loss_ce: 0.026659
[23:41:11.742] iteration 2241 : loss : 0.110866, loss_ce: 0.028170
[23:41:12.022] iteration 2242 : loss : 0.100972, loss_ce: 0.020964
[23:41:12.301] iteration 2243 : loss : 0.139572, loss_ce: 0.036503
[23:41:12.579] iteration 2244 : loss : 0.121677, loss_ce: 0.025314
[23:41:12.861] iteration 2245 : loss : 0.175573, loss_ce: 0.041125
[23:41:13.139] iteration 2246 : loss : 0.145503, loss_ce: 0.041113
[23:41:13.420] iteration 2247 : loss : 0.111954, loss_ce: 0.032785
[23:41:13.699] iteration 2248 : loss : 0.117717, loss_ce: 0.034462
[23:41:13.976] iteration 2249 : loss : 0.135189, loss_ce: 0.020749
[23:41:14.255] iteration 2250 : loss : 0.206668, loss_ce: 0.046914
[23:41:14.540] iteration 2251 : loss : 0.153684, loss_ce: 0.058267
[23:41:14.815] iteration 2252 : loss : 0.099578, loss_ce: 0.026706
[23:41:15.097] iteration 2253 : loss : 0.133036, loss_ce: 0.042468
[23:41:15.378] iteration 2254 : loss : 0.148046, loss_ce: 0.044929
[23:41:15.655] iteration 2255 : loss : 0.183919, loss_ce: 0.029753
[23:41:15.932] iteration 2256 : loss : 0.127627, loss_ce: 0.056524
[23:41:16.214] iteration 2257 : loss : 0.159388, loss_ce: 0.028282
[23:41:16.493] iteration 2258 : loss : 0.164175, loss_ce: 0.032454
[23:41:16.769] iteration 2259 : loss : 0.194155, loss_ce: 0.052659
[23:41:17.051] iteration 2260 : loss : 0.126315, loss_ce: 0.049559
[23:41:17.345] iteration 2261 : loss : 0.166330, loss_ce: 0.037632
[23:41:17.623] iteration 2262 : loss : 0.154504, loss_ce: 0.042002
[23:41:17.902] iteration 2263 : loss : 0.104225, loss_ce: 0.025569
[23:41:18.182] iteration 2264 : loss : 0.139647, loss_ce: 0.022523
[23:41:18.464] iteration 2265 : loss : 0.131585, loss_ce: 0.045502
[23:41:18.744] iteration 2266 : loss : 0.158120, loss_ce: 0.028173
[23:41:19.022] iteration 2267 : loss : 0.134019, loss_ce: 0.043058
[23:41:19.304] iteration 2268 : loss : 0.125728, loss_ce: 0.052967
[23:41:19.588] iteration 2269 : loss : 0.108543, loss_ce: 0.031396
[23:41:19.867] iteration 2270 : loss : 0.156828, loss_ce: 0.043148
[23:41:20.147] iteration 2271 : loss : 0.155031, loss_ce: 0.030272
[23:41:20.427] iteration 2272 : loss : 0.292242, loss_ce: 0.030819
[23:41:20.706] iteration 2273 : loss : 0.161532, loss_ce: 0.029210
[23:41:20.986] iteration 2274 : loss : 0.123937, loss_ce: 0.018165
[23:41:21.266] iteration 2275 : loss : 0.189746, loss_ce: 0.025752
[23:41:21.549] iteration 2276 : loss : 0.081846, loss_ce: 0.010770
[23:41:21.826] iteration 2277 : loss : 0.130590, loss_ce: 0.045478
[23:41:22.103] iteration 2278 : loss : 0.207711, loss_ce: 0.022168
[23:41:22.382] iteration 2279 : loss : 0.150949, loss_ce: 0.021085
[23:41:22.661] iteration 2280 : loss : 0.126337, loss_ce: 0.035662
[23:41:22.964] iteration 2281 : loss : 0.155360, loss_ce: 0.038616
[23:41:23.249] iteration 2282 : loss : 0.165962, loss_ce: 0.037025
[23:41:23.529] iteration 2283 : loss : 0.186613, loss_ce: 0.026118
[23:41:23.807] iteration 2284 : loss : 0.144491, loss_ce: 0.055376
[23:41:24.084] iteration 2285 : loss : 0.085268, loss_ce: 0.035954
[23:41:24.362] iteration 2286 : loss : 0.156103, loss_ce: 0.046462
[23:41:24.641] iteration 2287 : loss : 0.135983, loss_ce: 0.014059
[23:41:24.920] iteration 2288 : loss : 0.157291, loss_ce: 0.014704
[23:41:25.198] iteration 2289 : loss : 0.161848, loss_ce: 0.034999
[23:41:25.478] iteration 2290 : loss : 0.183424, loss_ce: 0.038868
[23:41:25.755] iteration 2291 : loss : 0.223352, loss_ce: 0.042284
[23:41:26.035] iteration 2292 : loss : 0.192898, loss_ce: 0.041782
[23:41:26.316] iteration 2293 : loss : 0.114192, loss_ce: 0.044969
[23:41:26.594] iteration 2294 : loss : 0.208658, loss_ce: 0.039815
[23:41:26.870] iteration 2295 : loss : 0.085049, loss_ce: 0.031275
[23:41:27.145] iteration 2296 : loss : 0.125942, loss_ce: 0.053874
[23:41:27.421] iteration 2297 : loss : 0.131071, loss_ce: 0.045229
[23:41:27.702] iteration 2298 : loss : 0.169684, loss_ce: 0.071635
[23:41:27.978] iteration 2299 : loss : 0.309837, loss_ce: 0.016206
[23:41:28.257] iteration 2300 : loss : 0.157120, loss_ce: 0.035244
[23:41:28.550] iteration 2301 : loss : 0.198301, loss_ce: 0.018282
[23:41:28.832] iteration 2302 : loss : 0.164797, loss_ce: 0.031607
[23:41:29.110] iteration 2303 : loss : 0.157429, loss_ce: 0.026880
[23:41:29.389] iteration 2304 : loss : 0.146179, loss_ce: 0.049103
[23:41:29.669] iteration 2305 : loss : 0.136641, loss_ce: 0.034678
[23:41:29.945] iteration 2306 : loss : 0.172704, loss_ce: 0.037318
[23:41:30.225] iteration 2307 : loss : 0.135051, loss_ce: 0.050786
[23:41:30.504] iteration 2308 : loss : 0.126050, loss_ce: 0.032134
[23:41:30.779] iteration 2309 : loss : 0.107265, loss_ce: 0.019864
[23:41:31.056] iteration 2310 : loss : 0.123897, loss_ce: 0.056053
[23:41:31.333] iteration 2311 : loss : 0.134337, loss_ce: 0.054068
[23:41:31.610] iteration 2312 : loss : 0.179515, loss_ce: 0.045111
[23:41:31.890] iteration 2313 : loss : 0.103050, loss_ce: 0.022300
[23:41:32.166] iteration 2314 : loss : 0.119482, loss_ce: 0.029603
[23:41:32.444] iteration 2315 : loss : 0.161504, loss_ce: 0.041454
[23:41:32.722] iteration 2316 : loss : 0.102571, loss_ce: 0.048147
[23:41:33.001] iteration 2317 : loss : 0.118446, loss_ce: 0.031498
[23:41:33.285] iteration 2318 : loss : 0.088400, loss_ce: 0.028781
[23:41:33.561] iteration 2319 : loss : 0.157939, loss_ce: 0.049928
[23:41:33.841] iteration 2320 : loss : 0.143448, loss_ce: 0.021813
[23:41:34.142] iteration 2321 : loss : 0.099294, loss_ce: 0.026618
[23:41:34.417] iteration 2322 : loss : 0.093143, loss_ce: 0.014591
[23:41:34.696] iteration 2323 : loss : 0.158290, loss_ce: 0.042717
[23:41:34.977] iteration 2324 : loss : 0.099944, loss_ce: 0.020413
[23:41:35.254] iteration 2325 : loss : 0.143418, loss_ce: 0.023268
[23:41:35.531] iteration 2326 : loss : 0.143046, loss_ce: 0.016179
[23:41:35.807] iteration 2327 : loss : 0.170547, loss_ce: 0.026870
[23:41:36.089] iteration 2328 : loss : 0.118587, loss_ce: 0.044528
[23:41:36.365] iteration 2329 : loss : 0.114551, loss_ce: 0.027970
[23:41:36.640] iteration 2330 : loss : 0.099658, loss_ce: 0.028497
[23:41:36.923] iteration 2331 : loss : 0.165460, loss_ce: 0.044664
[23:41:37.201] iteration 2332 : loss : 0.125343, loss_ce: 0.026969
[23:41:37.482] iteration 2333 : loss : 0.150443, loss_ce: 0.036386
[23:41:37.762] iteration 2334 : loss : 0.102324, loss_ce: 0.021272
[23:41:38.042] iteration 2335 : loss : 0.094754, loss_ce: 0.034960
[23:41:38.321] iteration 2336 : loss : 0.130554, loss_ce: 0.050534
[23:41:38.598] iteration 2337 : loss : 0.098282, loss_ce: 0.032648
[23:41:38.876] iteration 2338 : loss : 0.086622, loss_ce: 0.032978
[23:41:39.153] iteration 2339 : loss : 0.139161, loss_ce: 0.025052
[23:41:39.429] iteration 2340 : loss : 0.115719, loss_ce: 0.022090
[23:41:39.726] iteration 2341 : loss : 0.089438, loss_ce: 0.016253
[23:41:40.002] iteration 2342 : loss : 0.114785, loss_ce: 0.049592
[23:41:40.281] iteration 2343 : loss : 0.098865, loss_ce: 0.046805
[23:41:40.565] iteration 2344 : loss : 0.145540, loss_ce: 0.019689
[23:41:40.841] iteration 2345 : loss : 0.116195, loss_ce: 0.032172
[23:41:41.122] iteration 2346 : loss : 0.169865, loss_ce: 0.032205
[23:41:41.405] iteration 2347 : loss : 0.092015, loss_ce: 0.038738
[23:41:41.684] iteration 2348 : loss : 0.142243, loss_ce: 0.046563
[23:41:41.964] iteration 2349 : loss : 0.116516, loss_ce: 0.035643
[23:41:42.248] iteration 2350 : loss : 0.126271, loss_ce: 0.043550
[23:41:42.530] iteration 2351 : loss : 0.095330, loss_ce: 0.046240
[23:41:42.813] iteration 2352 : loss : 0.114841, loss_ce: 0.047250
[23:41:43.091] iteration 2353 : loss : 0.089544, loss_ce: 0.028032
[23:41:43.377] iteration 2354 : loss : 0.082540, loss_ce: 0.031088
[23:41:43.661] iteration 2355 : loss : 0.153402, loss_ce: 0.038153
[23:41:43.947] iteration 2356 : loss : 0.109806, loss_ce: 0.017625
[23:41:44.230] iteration 2357 : loss : 0.258399, loss_ce: 0.031721
[23:41:44.525] iteration 2358 : loss : 0.250490, loss_ce: 0.018632
[23:41:44.805] iteration 2359 : loss : 0.104508, loss_ce: 0.014580
[23:41:45.090] iteration 2360 : loss : 0.136597, loss_ce: 0.039437
[23:41:45.400] iteration 2361 : loss : 0.136532, loss_ce: 0.024059
[23:41:45.688] iteration 2362 : loss : 0.142427, loss_ce: 0.074257
[23:41:45.771] iteration 2363 : loss : 0.506004, loss_ce: 0.000394
[23:42:05.729] iteration 2364 : loss : 0.081566, loss_ce: 0.021375
[23:42:06.010] iteration 2365 : loss : 0.143385, loss_ce: 0.039140
[23:42:06.290] iteration 2366 : loss : 0.157660, loss_ce: 0.029062
[23:42:06.570] iteration 2367 : loss : 0.111071, loss_ce: 0.039485
[23:42:06.852] iteration 2368 : loss : 0.140114, loss_ce: 0.042811
[23:42:07.124] iteration 2369 : loss : 0.117706, loss_ce: 0.059615
[23:42:07.401] iteration 2370 : loss : 0.108163, loss_ce: 0.029771
[23:42:07.680] iteration 2371 : loss : 0.198940, loss_ce: 0.031182
[23:42:07.956] iteration 2372 : loss : 0.150657, loss_ce: 0.019345
[23:42:08.232] iteration 2373 : loss : 0.129169, loss_ce: 0.049214
[23:42:08.510] iteration 2374 : loss : 0.165392, loss_ce: 0.036426
[23:42:08.789] iteration 2375 : loss : 0.120109, loss_ce: 0.034738
[23:42:09.066] iteration 2376 : loss : 0.168487, loss_ce: 0.019297
[23:42:09.342] iteration 2377 : loss : 0.085718, loss_ce: 0.019589
[23:42:09.620] iteration 2378 : loss : 0.127253, loss_ce: 0.040211
[23:42:09.900] iteration 2379 : loss : 0.098416, loss_ce: 0.043227
[23:42:10.174] iteration 2380 : loss : 0.124324, loss_ce: 0.045583
[23:42:10.472] iteration 2381 : loss : 0.140044, loss_ce: 0.054914
[23:42:10.747] iteration 2382 : loss : 0.141291, loss_ce: 0.049187
[23:42:11.025] iteration 2383 : loss : 0.141881, loss_ce: 0.034604
[23:42:11.303] iteration 2384 : loss : 0.130260, loss_ce: 0.025628
[23:42:11.580] iteration 2385 : loss : 0.144943, loss_ce: 0.037229
[23:42:11.855] iteration 2386 : loss : 0.180682, loss_ce: 0.020961
[23:42:12.131] iteration 2387 : loss : 0.102783, loss_ce: 0.026002
[23:42:12.409] iteration 2388 : loss : 0.107970, loss_ce: 0.057316
[23:42:12.689] iteration 2389 : loss : 0.107120, loss_ce: 0.036804
[23:42:12.966] iteration 2390 : loss : 0.172084, loss_ce: 0.012631
[23:42:13.244] iteration 2391 : loss : 0.106914, loss_ce: 0.029322
[23:42:13.522] iteration 2392 : loss : 0.172116, loss_ce: 0.027007
[23:42:13.796] iteration 2393 : loss : 0.150015, loss_ce: 0.032736
[23:42:14.073] iteration 2394 : loss : 0.124654, loss_ce: 0.052271
[23:42:14.349] iteration 2395 : loss : 0.096100, loss_ce: 0.028385
[23:42:14.631] iteration 2396 : loss : 0.136158, loss_ce: 0.028936
[23:42:14.907] iteration 2397 : loss : 0.108774, loss_ce: 0.019136
[23:42:15.181] iteration 2398 : loss : 0.095832, loss_ce: 0.033683
[23:42:15.457] iteration 2399 : loss : 0.099229, loss_ce: 0.021549
[23:42:15.734] iteration 2400 : loss : 0.104151, loss_ce: 0.028514
[23:42:16.024] iteration 2401 : loss : 0.152629, loss_ce: 0.029546
[23:42:16.300] iteration 2402 : loss : 0.121769, loss_ce: 0.052869
[23:42:16.578] iteration 2403 : loss : 0.166326, loss_ce: 0.035014
[23:42:16.858] iteration 2404 : loss : 0.118260, loss_ce: 0.037439
[23:42:17.137] iteration 2405 : loss : 0.089281, loss_ce: 0.036075
[23:42:17.413] iteration 2406 : loss : 0.101061, loss_ce: 0.026925
[23:42:17.691] iteration 2407 : loss : 0.095204, loss_ce: 0.023159
[23:42:17.967] iteration 2408 : loss : 0.140754, loss_ce: 0.025806
[23:42:18.245] iteration 2409 : loss : 0.126022, loss_ce: 0.038941
[23:42:18.523] iteration 2410 : loss : 0.098396, loss_ce: 0.024535
[23:42:18.805] iteration 2411 : loss : 0.184208, loss_ce: 0.033317
[23:42:19.085] iteration 2412 : loss : 0.116332, loss_ce: 0.041932
[23:42:19.359] iteration 2413 : loss : 0.190152, loss_ce: 0.027458
[23:42:19.641] iteration 2414 : loss : 0.171314, loss_ce: 0.022165
[23:42:19.922] iteration 2415 : loss : 0.154267, loss_ce: 0.035246
[23:42:20.196] iteration 2416 : loss : 0.126533, loss_ce: 0.044108
[23:42:20.473] iteration 2417 : loss : 0.117735, loss_ce: 0.078653
[23:42:20.752] iteration 2418 : loss : 0.078823, loss_ce: 0.018981
[23:42:21.028] iteration 2419 : loss : 0.102150, loss_ce: 0.040627
[23:42:21.306] iteration 2420 : loss : 0.100036, loss_ce: 0.043984
[23:42:21.597] iteration 2421 : loss : 0.114374, loss_ce: 0.045080
[23:42:21.877] iteration 2422 : loss : 0.145795, loss_ce: 0.029871
[23:42:22.158] iteration 2423 : loss : 0.114596, loss_ce: 0.029604
[23:42:22.435] iteration 2424 : loss : 0.144695, loss_ce: 0.042818
[23:42:22.712] iteration 2425 : loss : 0.135070, loss_ce: 0.016518
[23:42:22.987] iteration 2426 : loss : 0.092553, loss_ce: 0.043288
[23:42:23.266] iteration 2427 : loss : 0.122606, loss_ce: 0.022796
[23:42:23.546] iteration 2428 : loss : 0.119749, loss_ce: 0.036748
[23:42:23.823] iteration 2429 : loss : 0.167284, loss_ce: 0.037245
[23:42:24.103] iteration 2430 : loss : 0.213825, loss_ce: 0.026243
[23:42:24.383] iteration 2431 : loss : 0.230850, loss_ce: 0.018456
[23:42:24.662] iteration 2432 : loss : 0.090829, loss_ce: 0.014187
[23:42:24.941] iteration 2433 : loss : 0.158582, loss_ce: 0.010601
[23:42:25.222] iteration 2434 : loss : 0.101208, loss_ce: 0.009159
[23:42:25.507] iteration 2435 : loss : 0.156158, loss_ce: 0.014904
[23:42:25.781] iteration 2436 : loss : 0.164530, loss_ce: 0.027988
[23:42:26.059] iteration 2437 : loss : 0.211843, loss_ce: 0.029352
[23:42:26.337] iteration 2438 : loss : 0.102574, loss_ce: 0.033365
[23:42:26.616] iteration 2439 : loss : 0.172073, loss_ce: 0.031886
[23:42:26.895] iteration 2440 : loss : 0.118549, loss_ce: 0.029823
[23:42:27.186] iteration 2441 : loss : 0.172525, loss_ce: 0.026616
[23:42:27.462] iteration 2442 : loss : 0.103422, loss_ce: 0.023606
[23:42:27.742] iteration 2443 : loss : 0.103422, loss_ce: 0.022172
[23:42:28.019] iteration 2444 : loss : 0.173924, loss_ce: 0.032768
[23:42:28.301] iteration 2445 : loss : 0.105401, loss_ce: 0.044877
[23:42:28.578] iteration 2446 : loss : 0.161013, loss_ce: 0.027265
[23:42:28.854] iteration 2447 : loss : 0.168349, loss_ce: 0.018128
[23:42:29.132] iteration 2448 : loss : 0.142415, loss_ce: 0.042036
[23:42:29.407] iteration 2449 : loss : 0.130375, loss_ce: 0.038898
[23:42:29.690] iteration 2450 : loss : 0.111743, loss_ce: 0.035260
[23:42:29.971] iteration 2451 : loss : 0.115627, loss_ce: 0.049014
[23:42:30.250] iteration 2452 : loss : 0.153237, loss_ce: 0.018689
[23:42:30.529] iteration 2453 : loss : 0.156769, loss_ce: 0.030965
[23:42:30.811] iteration 2454 : loss : 0.151178, loss_ce: 0.022984
[23:42:31.086] iteration 2455 : loss : 0.105124, loss_ce: 0.031917
[23:42:31.365] iteration 2456 : loss : 0.107474, loss_ce: 0.037223
[23:42:31.641] iteration 2457 : loss : 0.143577, loss_ce: 0.022144
[23:42:31.920] iteration 2458 : loss : 0.116395, loss_ce: 0.018865
[23:42:32.198] iteration 2459 : loss : 0.121609, loss_ce: 0.030329
[23:42:32.478] iteration 2460 : loss : 0.118827, loss_ce: 0.037810
[23:42:32.771] iteration 2461 : loss : 0.181677, loss_ce: 0.042042
[23:42:33.046] iteration 2462 : loss : 0.096286, loss_ce: 0.032962
[23:42:33.325] iteration 2463 : loss : 0.116345, loss_ce: 0.055878
[23:42:33.605] iteration 2464 : loss : 0.155637, loss_ce: 0.030779
[23:42:33.879] iteration 2465 : loss : 0.156725, loss_ce: 0.058365
[23:42:34.161] iteration 2466 : loss : 0.177532, loss_ce: 0.060694
[23:42:34.442] iteration 2467 : loss : 0.115151, loss_ce: 0.049165
[23:42:34.720] iteration 2468 : loss : 0.145261, loss_ce: 0.031062
[23:42:35.001] iteration 2469 : loss : 0.145171, loss_ce: 0.031230
[23:42:35.281] iteration 2470 : loss : 0.108833, loss_ce: 0.037730
[23:42:35.558] iteration 2471 : loss : 0.134202, loss_ce: 0.058154
[23:42:35.835] iteration 2472 : loss : 0.101846, loss_ce: 0.020567
[23:42:36.115] iteration 2473 : loss : 0.159447, loss_ce: 0.040424
[23:42:36.393] iteration 2474 : loss : 0.101468, loss_ce: 0.033153
[23:42:36.672] iteration 2475 : loss : 0.161534, loss_ce: 0.031490
[23:42:36.952] iteration 2476 : loss : 0.122385, loss_ce: 0.036310
[23:42:37.231] iteration 2477 : loss : 0.094945, loss_ce: 0.021225
[23:42:37.509] iteration 2478 : loss : 0.114832, loss_ce: 0.023597
[23:42:37.790] iteration 2479 : loss : 0.119336, loss_ce: 0.032172
[23:42:38.068] iteration 2480 : loss : 0.114602, loss_ce: 0.034313
[23:42:38.362] iteration 2481 : loss : 0.099256, loss_ce: 0.035971
[23:42:38.638] iteration 2482 : loss : 0.134342, loss_ce: 0.037075
[23:42:38.920] iteration 2483 : loss : 0.189021, loss_ce: 0.029812
[23:42:39.199] iteration 2484 : loss : 0.116927, loss_ce: 0.049138
[23:42:39.479] iteration 2485 : loss : 0.134787, loss_ce: 0.043017
[23:42:39.760] iteration 2486 : loss : 0.159040, loss_ce: 0.020147
[23:42:40.047] iteration 2487 : loss : 0.148872, loss_ce: 0.047316
[23:42:40.330] iteration 2488 : loss : 0.120500, loss_ce: 0.049175
[23:42:40.608] iteration 2489 : loss : 0.094821, loss_ce: 0.017826
[23:42:40.892] iteration 2490 : loss : 0.109481, loss_ce: 0.043608
[23:42:41.176] iteration 2491 : loss : 0.137503, loss_ce: 0.019355
[23:42:41.457] iteration 2492 : loss : 0.160636, loss_ce: 0.030430
[23:42:41.742] iteration 2493 : loss : 0.141781, loss_ce: 0.037556
[23:42:42.021] iteration 2494 : loss : 0.109016, loss_ce: 0.045993
[23:42:42.306] iteration 2495 : loss : 0.250936, loss_ce: 0.016809
[23:42:42.590] iteration 2496 : loss : 0.128989, loss_ce: 0.024889
[23:42:42.869] iteration 2497 : loss : 0.103834, loss_ce: 0.034357
[23:42:43.150] iteration 2498 : loss : 0.111293, loss_ce: 0.033104
[23:42:43.430] iteration 2499 : loss : 0.122129, loss_ce: 0.036521
[23:42:43.709] iteration 2500 : loss : 0.088431, loss_ce: 0.034534
[23:42:44.007] iteration 2501 : loss : 0.154409, loss_ce: 0.037142
[23:42:44.089] iteration 2502 : loss : 0.359322, loss_ce: 0.012078
[23:43:01.626] iteration 2503 : loss : 0.126503, loss_ce: 0.048803
[23:43:01.906] iteration 2504 : loss : 0.100104, loss_ce: 0.036172
[23:43:02.194] iteration 2505 : loss : 0.142450, loss_ce: 0.021045
[23:43:02.475] iteration 2506 : loss : 0.204929, loss_ce: 0.031268
[23:43:02.756] iteration 2507 : loss : 0.169117, loss_ce: 0.057016
[23:43:03.032] iteration 2508 : loss : 0.256996, loss_ce: 0.023653
[23:43:03.308] iteration 2509 : loss : 0.114822, loss_ce: 0.039743
[23:43:03.585] iteration 2510 : loss : 0.141745, loss_ce: 0.044835
[23:43:03.862] iteration 2511 : loss : 0.129671, loss_ce: 0.043664
[23:43:04.138] iteration 2512 : loss : 0.169181, loss_ce: 0.012959
[23:43:04.417] iteration 2513 : loss : 0.114252, loss_ce: 0.028553
[23:43:04.695] iteration 2514 : loss : 0.130803, loss_ce: 0.022435
[23:43:04.973] iteration 2515 : loss : 0.126315, loss_ce: 0.043749
[23:43:05.251] iteration 2516 : loss : 0.100595, loss_ce: 0.022540
[23:43:05.528] iteration 2517 : loss : 0.131283, loss_ce: 0.016403
[23:43:05.812] iteration 2518 : loss : 0.179807, loss_ce: 0.025884
[23:43:06.089] iteration 2519 : loss : 0.069756, loss_ce: 0.031076
[23:43:06.372] iteration 2520 : loss : 0.122984, loss_ce: 0.051995
[23:43:06.668] iteration 2521 : loss : 0.152630, loss_ce: 0.030291
[23:43:06.945] iteration 2522 : loss : 0.104495, loss_ce: 0.022480
[23:43:07.225] iteration 2523 : loss : 0.100041, loss_ce: 0.033597
[23:43:07.506] iteration 2524 : loss : 0.129027, loss_ce: 0.026487
[23:43:07.788] iteration 2525 : loss : 0.126092, loss_ce: 0.057142
[23:43:08.067] iteration 2526 : loss : 0.100799, loss_ce: 0.045808
[23:43:08.349] iteration 2527 : loss : 0.139524, loss_ce: 0.034743
[23:43:08.628] iteration 2528 : loss : 0.141294, loss_ce: 0.031606
[23:43:08.903] iteration 2529 : loss : 0.076933, loss_ce: 0.032192
[23:43:09.180] iteration 2530 : loss : 0.096161, loss_ce: 0.046072
[23:43:09.461] iteration 2531 : loss : 0.108469, loss_ce: 0.041774
[23:43:09.744] iteration 2532 : loss : 0.110560, loss_ce: 0.038703
[23:43:10.020] iteration 2533 : loss : 0.093416, loss_ce: 0.025070
[23:43:10.301] iteration 2534 : loss : 0.140604, loss_ce: 0.024606
[23:43:10.577] iteration 2535 : loss : 0.133560, loss_ce: 0.038343
[23:43:10.856] iteration 2536 : loss : 0.091830, loss_ce: 0.033007
[23:43:11.134] iteration 2537 : loss : 0.088152, loss_ce: 0.022117
[23:43:11.412] iteration 2538 : loss : 0.173672, loss_ce: 0.032080
[23:43:11.688] iteration 2539 : loss : 0.102190, loss_ce: 0.047667
[23:43:11.966] iteration 2540 : loss : 0.143515, loss_ce: 0.031014
[23:43:12.268] iteration 2541 : loss : 0.101290, loss_ce: 0.035600
[23:43:12.546] iteration 2542 : loss : 0.132893, loss_ce: 0.044515
[23:43:12.824] iteration 2543 : loss : 0.124937, loss_ce: 0.024450
[23:43:13.107] iteration 2544 : loss : 0.127494, loss_ce: 0.032056
[23:43:13.387] iteration 2545 : loss : 0.131201, loss_ce: 0.037215
[23:43:13.666] iteration 2546 : loss : 0.180865, loss_ce: 0.030501
[23:43:13.944] iteration 2547 : loss : 0.142961, loss_ce: 0.056185
[23:43:14.223] iteration 2548 : loss : 0.101335, loss_ce: 0.054529
[23:43:14.501] iteration 2549 : loss : 0.136819, loss_ce: 0.022624
[23:43:14.782] iteration 2550 : loss : 0.081874, loss_ce: 0.028722
[23:43:15.061] iteration 2551 : loss : 0.174531, loss_ce: 0.033010
[23:43:15.341] iteration 2552 : loss : 0.114385, loss_ce: 0.052289
[23:43:15.624] iteration 2553 : loss : 0.084688, loss_ce: 0.019086
[23:43:15.900] iteration 2554 : loss : 0.143264, loss_ce: 0.019202
[23:43:16.182] iteration 2555 : loss : 0.134351, loss_ce: 0.022106
[23:43:16.461] iteration 2556 : loss : 0.184391, loss_ce: 0.030581
[23:43:16.739] iteration 2557 : loss : 0.092708, loss_ce: 0.016368
[23:43:17.021] iteration 2558 : loss : 0.249436, loss_ce: 0.011134
[23:43:17.295] iteration 2559 : loss : 0.208477, loss_ce: 0.025251
[23:43:17.575] iteration 2560 : loss : 0.101953, loss_ce: 0.027246
[23:43:17.870] iteration 2561 : loss : 0.140895, loss_ce: 0.018687
[23:43:18.146] iteration 2562 : loss : 0.082649, loss_ce: 0.022985
[23:43:18.422] iteration 2563 : loss : 0.110048, loss_ce: 0.047759
[23:43:18.701] iteration 2564 : loss : 0.157620, loss_ce: 0.028348
[23:43:18.980] iteration 2565 : loss : 0.168500, loss_ce: 0.022648
[23:43:19.259] iteration 2566 : loss : 0.100647, loss_ce: 0.022382
[23:43:19.538] iteration 2567 : loss : 0.116303, loss_ce: 0.046562
[23:43:19.818] iteration 2568 : loss : 0.097844, loss_ce: 0.024415
[23:43:20.099] iteration 2569 : loss : 0.084642, loss_ce: 0.021852
[23:43:20.378] iteration 2570 : loss : 0.159388, loss_ce: 0.026720
[23:43:20.657] iteration 2571 : loss : 0.285752, loss_ce: 0.031036
[23:43:20.938] iteration 2572 : loss : 0.127410, loss_ce: 0.037228
[23:43:21.218] iteration 2573 : loss : 0.094328, loss_ce: 0.039070
[23:43:21.498] iteration 2574 : loss : 0.238130, loss_ce: 0.028078
[23:43:21.777] iteration 2575 : loss : 0.165785, loss_ce: 0.030347
[23:43:22.058] iteration 2576 : loss : 0.126743, loss_ce: 0.047384
[23:43:22.336] iteration 2577 : loss : 0.099490, loss_ce: 0.027177
[23:43:22.618] iteration 2578 : loss : 0.084714, loss_ce: 0.024768
[23:43:22.896] iteration 2579 : loss : 0.107808, loss_ce: 0.032045
[23:43:23.173] iteration 2580 : loss : 0.166984, loss_ce: 0.032412
[23:43:23.476] iteration 2581 : loss : 0.091095, loss_ce: 0.023209
[23:43:23.758] iteration 2582 : loss : 0.178189, loss_ce: 0.023264
[23:43:24.034] iteration 2583 : loss : 0.120597, loss_ce: 0.047148
[23:43:24.314] iteration 2584 : loss : 0.094853, loss_ce: 0.048095
[23:43:24.591] iteration 2585 : loss : 0.092650, loss_ce: 0.024241
[23:43:24.871] iteration 2586 : loss : 0.118307, loss_ce: 0.042498
[23:43:25.150] iteration 2587 : loss : 0.074118, loss_ce: 0.029485
[23:43:25.426] iteration 2588 : loss : 0.141418, loss_ce: 0.065266
[23:43:25.704] iteration 2589 : loss : 0.100088, loss_ce: 0.040523
[23:43:25.987] iteration 2590 : loss : 0.192993, loss_ce: 0.024399
[23:43:26.263] iteration 2591 : loss : 0.195582, loss_ce: 0.026085
[23:43:26.542] iteration 2592 : loss : 0.133564, loss_ce: 0.032753
[23:43:26.819] iteration 2593 : loss : 0.120781, loss_ce: 0.037540
[23:43:27.098] iteration 2594 : loss : 0.149922, loss_ce: 0.020585
[23:43:27.374] iteration 2595 : loss : 0.095996, loss_ce: 0.016277
[23:43:27.653] iteration 2596 : loss : 0.113890, loss_ce: 0.032112
[23:43:27.930] iteration 2597 : loss : 0.146319, loss_ce: 0.030898
[23:43:28.211] iteration 2598 : loss : 0.154860, loss_ce: 0.030288
[23:43:28.491] iteration 2599 : loss : 0.168102, loss_ce: 0.011175
[23:43:28.767] iteration 2600 : loss : 0.079807, loss_ce: 0.025550
[23:43:29.060] iteration 2601 : loss : 0.166925, loss_ce: 0.027131
[23:43:29.341] iteration 2602 : loss : 0.119629, loss_ce: 0.021828
[23:43:29.618] iteration 2603 : loss : 0.104109, loss_ce: 0.026041
[23:43:29.897] iteration 2604 : loss : 0.098249, loss_ce: 0.034323
[23:43:30.174] iteration 2605 : loss : 0.123204, loss_ce: 0.026510
[23:43:30.451] iteration 2606 : loss : 0.137170, loss_ce: 0.025348
[23:43:30.727] iteration 2607 : loss : 0.130440, loss_ce: 0.029177
[23:43:31.007] iteration 2608 : loss : 0.091414, loss_ce: 0.025136
[23:43:31.284] iteration 2609 : loss : 0.091524, loss_ce: 0.034619
[23:43:31.564] iteration 2610 : loss : 0.177721, loss_ce: 0.013690
[23:43:31.841] iteration 2611 : loss : 0.098781, loss_ce: 0.016927
[23:43:32.120] iteration 2612 : loss : 0.110591, loss_ce: 0.028943
[23:43:32.396] iteration 2613 : loss : 0.092813, loss_ce: 0.022553
[23:43:32.678] iteration 2614 : loss : 0.123109, loss_ce: 0.036176
[23:43:32.960] iteration 2615 : loss : 0.116398, loss_ce: 0.045590
[23:43:33.235] iteration 2616 : loss : 0.107427, loss_ce: 0.021896
[23:43:33.516] iteration 2617 : loss : 0.193360, loss_ce: 0.012086
[23:43:33.793] iteration 2618 : loss : 0.143746, loss_ce: 0.013287
[23:43:34.074] iteration 2619 : loss : 0.106268, loss_ce: 0.031919
[23:43:34.352] iteration 2620 : loss : 0.100048, loss_ce: 0.029173
[23:43:34.645] iteration 2621 : loss : 0.076886, loss_ce: 0.020998
[23:43:34.921] iteration 2622 : loss : 0.146927, loss_ce: 0.026505
[23:43:35.198] iteration 2623 : loss : 0.094544, loss_ce: 0.017704
[23:43:35.477] iteration 2624 : loss : 0.223553, loss_ce: 0.016404
[23:43:35.758] iteration 2625 : loss : 0.103160, loss_ce: 0.043108
[23:43:36.038] iteration 2626 : loss : 0.149426, loss_ce: 0.061646
[23:43:36.321] iteration 2627 : loss : 0.138127, loss_ce: 0.043181
[23:43:36.604] iteration 2628 : loss : 0.101578, loss_ce: 0.038762
[23:43:36.887] iteration 2629 : loss : 0.154738, loss_ce: 0.028983
[23:43:37.175] iteration 2630 : loss : 0.171043, loss_ce: 0.024523
[23:43:37.457] iteration 2631 : loss : 0.136402, loss_ce: 0.031432
[23:43:37.741] iteration 2632 : loss : 0.140587, loss_ce: 0.027926
[23:43:38.023] iteration 2633 : loss : 0.145141, loss_ce: 0.040724
[23:43:38.305] iteration 2634 : loss : 0.191428, loss_ce: 0.049675
[23:43:38.587] iteration 2635 : loss : 0.135792, loss_ce: 0.035994
[23:43:38.875] iteration 2636 : loss : 0.156739, loss_ce: 0.025707
[23:43:39.151] iteration 2637 : loss : 0.141563, loss_ce: 0.034841
[23:43:39.435] iteration 2638 : loss : 0.146286, loss_ce: 0.024434
[23:43:39.723] iteration 2639 : loss : 0.166372, loss_ce: 0.022918
[23:43:40.002] iteration 2640 : loss : 0.174546, loss_ce: 0.046644
[23:43:40.093] iteration 2641 : loss : 0.518821, loss_ce: 0.026623
[23:43:57.903] iteration 2642 : loss : 0.116735, loss_ce: 0.032531
[23:43:58.183] iteration 2643 : loss : 0.103922, loss_ce: 0.037656
[23:43:58.462] iteration 2644 : loss : 0.108524, loss_ce: 0.028223
[23:43:58.746] iteration 2645 : loss : 0.143754, loss_ce: 0.021444
[23:43:59.028] iteration 2646 : loss : 0.148378, loss_ce: 0.040313
[23:43:59.307] iteration 2647 : loss : 0.092357, loss_ce: 0.022793
[23:43:59.582] iteration 2648 : loss : 0.120152, loss_ce: 0.037784
[23:43:59.858] iteration 2649 : loss : 0.105332, loss_ce: 0.038341
[23:44:00.136] iteration 2650 : loss : 0.073597, loss_ce: 0.023651
[23:44:00.421] iteration 2651 : loss : 0.164188, loss_ce: 0.016498
[23:44:00.698] iteration 2652 : loss : 0.101679, loss_ce: 0.036694
[23:44:00.977] iteration 2653 : loss : 0.128543, loss_ce: 0.025023
[23:44:01.254] iteration 2654 : loss : 0.174023, loss_ce: 0.020190
[23:44:01.534] iteration 2655 : loss : 0.188164, loss_ce: 0.009614
[23:44:01.809] iteration 2656 : loss : 0.152725, loss_ce: 0.034443
[23:44:02.085] iteration 2657 : loss : 0.106231, loss_ce: 0.034399
[23:44:02.363] iteration 2658 : loss : 0.090077, loss_ce: 0.020204
[23:44:02.639] iteration 2659 : loss : 0.154092, loss_ce: 0.022327
[23:44:02.917] iteration 2660 : loss : 0.148546, loss_ce: 0.034889
[23:44:03.217] iteration 2661 : loss : 0.111490, loss_ce: 0.036248
[23:44:03.496] iteration 2662 : loss : 0.188550, loss_ce: 0.039540
[23:44:03.776] iteration 2663 : loss : 0.098560, loss_ce: 0.036211
[23:44:04.051] iteration 2664 : loss : 0.110305, loss_ce: 0.033638
[23:44:04.331] iteration 2665 : loss : 0.163129, loss_ce: 0.051925
[23:44:04.611] iteration 2666 : loss : 0.137437, loss_ce: 0.048970
[23:44:04.887] iteration 2667 : loss : 0.138438, loss_ce: 0.032852
[23:44:05.166] iteration 2668 : loss : 0.134020, loss_ce: 0.020250
[23:44:05.446] iteration 2669 : loss : 0.108674, loss_ce: 0.032440
[23:44:05.722] iteration 2670 : loss : 0.135193, loss_ce: 0.018689
[23:44:06.001] iteration 2671 : loss : 0.177839, loss_ce: 0.023193
[23:44:06.278] iteration 2672 : loss : 0.090869, loss_ce: 0.031349
[23:44:06.555] iteration 2673 : loss : 0.187802, loss_ce: 0.022198
[23:44:06.831] iteration 2674 : loss : 0.081300, loss_ce: 0.019986
[23:44:07.108] iteration 2675 : loss : 0.128755, loss_ce: 0.022436
[23:44:07.387] iteration 2676 : loss : 0.131805, loss_ce: 0.058254
[23:44:07.662] iteration 2677 : loss : 0.117856, loss_ce: 0.029670
[23:44:07.939] iteration 2678 : loss : 0.114652, loss_ce: 0.030133
[23:44:08.219] iteration 2679 : loss : 0.139814, loss_ce: 0.023165
[23:44:08.496] iteration 2680 : loss : 0.140263, loss_ce: 0.017361
[23:44:08.785] iteration 2681 : loss : 0.116685, loss_ce: 0.035551
[23:44:09.064] iteration 2682 : loss : 0.200166, loss_ce: 0.016386
[23:44:09.340] iteration 2683 : loss : 0.122724, loss_ce: 0.055221
[23:44:09.620] iteration 2684 : loss : 0.097989, loss_ce: 0.024964
[23:44:09.896] iteration 2685 : loss : 0.118779, loss_ce: 0.045782
[23:44:10.175] iteration 2686 : loss : 0.199433, loss_ce: 0.013538
[23:44:10.449] iteration 2687 : loss : 0.126494, loss_ce: 0.030242
[23:44:10.727] iteration 2688 : loss : 0.129119, loss_ce: 0.021066
[23:44:11.005] iteration 2689 : loss : 0.132332, loss_ce: 0.029856
[23:44:11.282] iteration 2690 : loss : 0.097332, loss_ce: 0.022254
[23:44:11.560] iteration 2691 : loss : 0.103004, loss_ce: 0.031397
[23:44:11.840] iteration 2692 : loss : 0.167273, loss_ce: 0.031170
[23:44:12.115] iteration 2693 : loss : 0.089569, loss_ce: 0.029455
[23:44:12.395] iteration 2694 : loss : 0.157135, loss_ce: 0.047461
[23:44:12.671] iteration 2695 : loss : 0.115023, loss_ce: 0.040487
[23:44:12.949] iteration 2696 : loss : 0.112253, loss_ce: 0.024653
[23:44:13.226] iteration 2697 : loss : 0.082741, loss_ce: 0.030262
[23:44:13.501] iteration 2698 : loss : 0.206823, loss_ce: 0.050686
[23:44:13.783] iteration 2699 : loss : 0.158908, loss_ce: 0.028845
[23:44:14.062] iteration 2700 : loss : 0.121354, loss_ce: 0.039861
[23:44:14.356] iteration 2701 : loss : 0.112116, loss_ce: 0.035880
[23:44:14.637] iteration 2702 : loss : 0.106212, loss_ce: 0.034688
[23:44:14.911] iteration 2703 : loss : 0.119654, loss_ce: 0.040447
[23:44:15.191] iteration 2704 : loss : 0.126049, loss_ce: 0.018524
[23:44:15.468] iteration 2705 : loss : 0.128352, loss_ce: 0.054358
[23:44:15.745] iteration 2706 : loss : 0.170174, loss_ce: 0.040513
[23:44:16.023] iteration 2707 : loss : 0.090561, loss_ce: 0.021753
[23:44:16.301] iteration 2708 : loss : 0.144499, loss_ce: 0.031220
[23:44:16.584] iteration 2709 : loss : 0.094439, loss_ce: 0.041907
[23:44:16.860] iteration 2710 : loss : 0.138590, loss_ce: 0.016868
[23:44:17.139] iteration 2711 : loss : 0.084159, loss_ce: 0.026834
[23:44:17.418] iteration 2712 : loss : 0.104683, loss_ce: 0.043806
[23:44:17.694] iteration 2713 : loss : 0.108435, loss_ce: 0.023457
[23:44:17.972] iteration 2714 : loss : 0.157543, loss_ce: 0.024784
[23:44:18.251] iteration 2715 : loss : 0.086821, loss_ce: 0.034994
[23:44:18.527] iteration 2716 : loss : 0.106812, loss_ce: 0.033055
[23:44:18.804] iteration 2717 : loss : 0.095010, loss_ce: 0.028633
[23:44:19.079] iteration 2718 : loss : 0.106306, loss_ce: 0.037850
[23:44:19.356] iteration 2719 : loss : 0.162281, loss_ce: 0.038573
[23:44:19.637] iteration 2720 : loss : 0.106928, loss_ce: 0.033059
[23:44:19.933] iteration 2721 : loss : 0.135699, loss_ce: 0.019617
[23:44:20.212] iteration 2722 : loss : 0.109792, loss_ce: 0.019574
[23:44:20.490] iteration 2723 : loss : 0.108461, loss_ce: 0.032788
[23:44:20.768] iteration 2724 : loss : 0.108084, loss_ce: 0.021136
[23:44:21.046] iteration 2725 : loss : 0.130008, loss_ce: 0.023754
[23:44:21.326] iteration 2726 : loss : 0.103285, loss_ce: 0.029915
[23:44:21.603] iteration 2727 : loss : 0.080858, loss_ce: 0.029351
[23:44:21.886] iteration 2728 : loss : 0.082988, loss_ce: 0.016750
[23:44:22.162] iteration 2729 : loss : 0.152811, loss_ce: 0.018961
[23:44:22.440] iteration 2730 : loss : 0.117002, loss_ce: 0.012175
[23:44:22.719] iteration 2731 : loss : 0.108714, loss_ce: 0.033126
[23:44:22.996] iteration 2732 : loss : 0.116943, loss_ce: 0.039967
[23:44:23.277] iteration 2733 : loss : 0.106522, loss_ce: 0.029677
[23:44:23.553] iteration 2734 : loss : 0.116402, loss_ce: 0.023377
[23:44:23.833] iteration 2735 : loss : 0.086526, loss_ce: 0.038698
[23:44:24.110] iteration 2736 : loss : 0.145795, loss_ce: 0.018025
[23:44:24.390] iteration 2737 : loss : 0.098496, loss_ce: 0.038759
[23:44:24.670] iteration 2738 : loss : 0.101076, loss_ce: 0.036101
[23:44:24.950] iteration 2739 : loss : 0.086016, loss_ce: 0.037446
[23:44:25.226] iteration 2740 : loss : 0.215277, loss_ce: 0.020078
[23:44:25.519] iteration 2741 : loss : 0.092218, loss_ce: 0.042903
[23:44:25.796] iteration 2742 : loss : 0.157474, loss_ce: 0.029291
[23:44:26.078] iteration 2743 : loss : 0.123310, loss_ce: 0.032986
[23:44:26.357] iteration 2744 : loss : 0.187676, loss_ce: 0.032801
[23:44:26.638] iteration 2745 : loss : 0.077940, loss_ce: 0.024975
[23:44:26.918] iteration 2746 : loss : 0.101470, loss_ce: 0.020633
[23:44:27.196] iteration 2747 : loss : 0.104740, loss_ce: 0.025891
[23:44:27.474] iteration 2748 : loss : 0.138602, loss_ce: 0.017817
[23:44:27.755] iteration 2749 : loss : 0.096058, loss_ce: 0.022303
[23:44:28.033] iteration 2750 : loss : 0.162149, loss_ce: 0.030674
[23:44:28.311] iteration 2751 : loss : 0.163710, loss_ce: 0.035537
[23:44:28.587] iteration 2752 : loss : 0.130146, loss_ce: 0.026385
[23:44:28.867] iteration 2753 : loss : 0.155387, loss_ce: 0.022129
[23:44:29.145] iteration 2754 : loss : 0.126372, loss_ce: 0.020230
[23:44:29.420] iteration 2755 : loss : 0.210045, loss_ce: 0.015483
[23:44:29.701] iteration 2756 : loss : 0.078157, loss_ce: 0.018995
[23:44:29.981] iteration 2757 : loss : 0.094658, loss_ce: 0.033845
[23:44:30.257] iteration 2758 : loss : 0.160759, loss_ce: 0.016317
[23:44:30.537] iteration 2759 : loss : 0.074391, loss_ce: 0.028585
[23:44:30.819] iteration 2760 : loss : 0.111625, loss_ce: 0.044141
[23:44:31.110] iteration 2761 : loss : 0.158416, loss_ce: 0.027521
[23:44:31.387] iteration 2762 : loss : 0.212563, loss_ce: 0.026254
[23:44:31.663] iteration 2763 : loss : 0.113440, loss_ce: 0.027898
[23:44:31.949] iteration 2764 : loss : 0.101202, loss_ce: 0.039767
[23:44:32.229] iteration 2765 : loss : 0.102354, loss_ce: 0.024225
[23:44:32.511] iteration 2766 : loss : 0.119204, loss_ce: 0.040164
[23:44:32.794] iteration 2767 : loss : 0.098568, loss_ce: 0.024973
[23:44:33.076] iteration 2768 : loss : 0.204722, loss_ce: 0.028988
[23:44:33.351] iteration 2769 : loss : 0.092039, loss_ce: 0.030766
[23:44:33.639] iteration 2770 : loss : 0.108798, loss_ce: 0.027560
[23:44:33.924] iteration 2771 : loss : 0.095190, loss_ce: 0.032317
[23:44:34.206] iteration 2772 : loss : 0.084516, loss_ce: 0.022562
[23:44:34.488] iteration 2773 : loss : 0.109434, loss_ce: 0.038632
[23:44:34.774] iteration 2774 : loss : 0.090829, loss_ce: 0.034704
[23:44:35.056] iteration 2775 : loss : 0.137607, loss_ce: 0.028953
[23:44:35.337] iteration 2776 : loss : 0.109040, loss_ce: 0.039356
[23:44:35.621] iteration 2777 : loss : 0.083940, loss_ce: 0.030890
[23:44:35.905] iteration 2778 : loss : 0.181942, loss_ce: 0.012035
[23:44:36.188] iteration 2779 : loss : 0.128187, loss_ce: 0.036758
[23:44:36.273] iteration 2780 : loss : 0.420488, loss_ce: 0.009914
[23:44:54.705] iteration 2781 : loss : 0.169232, loss_ce: 0.027600
[23:44:54.986] iteration 2782 : loss : 0.097103, loss_ce: 0.039169
[23:44:55.264] iteration 2783 : loss : 0.080889, loss_ce: 0.022129
[23:44:55.545] iteration 2784 : loss : 0.092665, loss_ce: 0.032474
[23:44:55.823] iteration 2785 : loss : 0.147986, loss_ce: 0.029460
[23:44:56.101] iteration 2786 : loss : 0.099702, loss_ce: 0.026970
[23:44:56.380] iteration 2787 : loss : 0.162603, loss_ce: 0.027629
[23:44:56.660] iteration 2788 : loss : 0.187258, loss_ce: 0.017226
[23:44:56.939] iteration 2789 : loss : 0.132989, loss_ce: 0.010328
[23:44:57.216] iteration 2790 : loss : 0.106025, loss_ce: 0.033384
[23:44:57.496] iteration 2791 : loss : 0.106577, loss_ce: 0.047850
[23:44:57.777] iteration 2792 : loss : 0.155575, loss_ce: 0.021240
[23:44:58.053] iteration 2793 : loss : 0.230169, loss_ce: 0.019936
[23:44:58.329] iteration 2794 : loss : 0.367552, loss_ce: 0.010015
[23:44:58.609] iteration 2795 : loss : 0.118167, loss_ce: 0.043637
[23:44:58.888] iteration 2796 : loss : 0.292610, loss_ce: 0.008790
[23:44:59.170] iteration 2797 : loss : 0.102183, loss_ce: 0.035182
[23:44:59.450] iteration 2798 : loss : 0.100875, loss_ce: 0.050282
[23:44:59.733] iteration 2799 : loss : 0.129470, loss_ce: 0.049311
[23:45:00.013] iteration 2800 : loss : 0.239571, loss_ce: 0.012804
[23:45:00.312] iteration 2801 : loss : 0.195387, loss_ce: 0.017031
[23:45:00.593] iteration 2802 : loss : 0.183949, loss_ce: 0.034657
[23:45:00.881] iteration 2803 : loss : 0.163874, loss_ce: 0.020450
[23:45:01.160] iteration 2804 : loss : 0.126595, loss_ce: 0.058453
[23:45:01.446] iteration 2805 : loss : 0.134987, loss_ce: 0.017715
[23:45:01.723] iteration 2806 : loss : 0.110181, loss_ce: 0.051774
[23:45:02.002] iteration 2807 : loss : 0.118581, loss_ce: 0.024536
[23:45:02.287] iteration 2808 : loss : 0.097784, loss_ce: 0.048819
[23:45:02.566] iteration 2809 : loss : 0.084504, loss_ce: 0.016101
[23:45:02.844] iteration 2810 : loss : 0.107537, loss_ce: 0.024009
[23:45:03.126] iteration 2811 : loss : 0.120532, loss_ce: 0.022453
[23:45:03.402] iteration 2812 : loss : 0.158001, loss_ce: 0.019989
[23:45:03.684] iteration 2813 : loss : 0.111760, loss_ce: 0.024632
[23:45:03.962] iteration 2814 : loss : 0.086561, loss_ce: 0.024510
[23:45:04.238] iteration 2815 : loss : 0.108097, loss_ce: 0.039378
[23:45:04.516] iteration 2816 : loss : 0.160659, loss_ce: 0.027610
[23:45:04.798] iteration 2817 : loss : 0.078378, loss_ce: 0.024489
[23:45:05.079] iteration 2818 : loss : 0.174593, loss_ce: 0.012420
[23:45:05.357] iteration 2819 : loss : 0.236529, loss_ce: 0.018501
[23:45:05.637] iteration 2820 : loss : 0.146833, loss_ce: 0.024069
[23:45:05.937] iteration 2821 : loss : 0.100790, loss_ce: 0.037485
[23:45:06.218] iteration 2822 : loss : 0.084072, loss_ce: 0.031830
[23:45:06.500] iteration 2823 : loss : 0.147110, loss_ce: 0.026378
[23:45:06.778] iteration 2824 : loss : 0.125655, loss_ce: 0.022601
[23:45:07.057] iteration 2825 : loss : 0.096912, loss_ce: 0.033999
[23:45:07.333] iteration 2826 : loss : 0.113440, loss_ce: 0.041651
[23:45:07.615] iteration 2827 : loss : 0.120490, loss_ce: 0.016399
[23:45:07.894] iteration 2828 : loss : 0.186755, loss_ce: 0.010569
[23:45:08.173] iteration 2829 : loss : 0.089344, loss_ce: 0.020345
[23:45:08.450] iteration 2830 : loss : 0.098198, loss_ce: 0.032834
[23:45:08.730] iteration 2831 : loss : 0.108341, loss_ce: 0.045033
[23:45:09.008] iteration 2832 : loss : 0.139262, loss_ce: 0.016602
[23:45:09.285] iteration 2833 : loss : 0.110719, loss_ce: 0.026864
[23:45:09.570] iteration 2834 : loss : 0.106505, loss_ce: 0.038643
[23:45:09.849] iteration 2835 : loss : 0.111657, loss_ce: 0.034612
[23:45:10.126] iteration 2836 : loss : 0.102600, loss_ce: 0.018594
[23:45:10.403] iteration 2837 : loss : 0.115519, loss_ce: 0.026978
[23:45:10.683] iteration 2838 : loss : 0.103135, loss_ce: 0.030791
[23:45:10.965] iteration 2839 : loss : 0.096382, loss_ce: 0.035221
[23:45:11.244] iteration 2840 : loss : 0.168955, loss_ce: 0.030623
[23:45:11.535] iteration 2841 : loss : 0.156775, loss_ce: 0.038044
[23:45:11.815] iteration 2842 : loss : 0.080498, loss_ce: 0.023142
[23:45:12.097] iteration 2843 : loss : 0.148325, loss_ce: 0.041699
[23:45:12.375] iteration 2844 : loss : 0.136388, loss_ce: 0.024082
[23:45:12.655] iteration 2845 : loss : 0.089453, loss_ce: 0.026879
[23:45:12.934] iteration 2846 : loss : 0.173047, loss_ce: 0.020425
[23:45:13.215] iteration 2847 : loss : 0.110568, loss_ce: 0.042242
[23:45:13.500] iteration 2848 : loss : 0.135226, loss_ce: 0.043960
[23:45:13.780] iteration 2849 : loss : 0.080511, loss_ce: 0.022300
[23:45:14.064] iteration 2850 : loss : 0.104528, loss_ce: 0.031264
[23:45:14.340] iteration 2851 : loss : 0.088772, loss_ce: 0.035614
[23:45:14.622] iteration 2852 : loss : 0.160300, loss_ce: 0.019874
[23:45:14.903] iteration 2853 : loss : 0.106743, loss_ce: 0.039575
[23:45:15.179] iteration 2854 : loss : 0.143443, loss_ce: 0.011071
[23:45:15.459] iteration 2855 : loss : 0.154447, loss_ce: 0.027254
[23:45:15.741] iteration 2856 : loss : 0.098288, loss_ce: 0.038905
[23:45:16.021] iteration 2857 : loss : 0.111152, loss_ce: 0.047664
[23:45:16.300] iteration 2858 : loss : 0.120488, loss_ce: 0.035697
[23:45:16.580] iteration 2859 : loss : 0.094250, loss_ce: 0.038967
[23:45:16.858] iteration 2860 : loss : 0.173575, loss_ce: 0.031631
[23:45:17.167] iteration 2861 : loss : 0.119804, loss_ce: 0.029886
[23:45:17.443] iteration 2862 : loss : 0.144256, loss_ce: 0.029027
[23:45:17.725] iteration 2863 : loss : 0.083283, loss_ce: 0.041482
[23:45:18.003] iteration 2864 : loss : 0.085879, loss_ce: 0.025650
[23:45:18.283] iteration 2865 : loss : 0.145982, loss_ce: 0.024759
[23:45:18.559] iteration 2866 : loss : 0.153374, loss_ce: 0.028674
[23:45:18.841] iteration 2867 : loss : 0.154908, loss_ce: 0.014893
[23:45:19.122] iteration 2868 : loss : 0.092627, loss_ce: 0.025283
[23:45:19.400] iteration 2869 : loss : 0.147306, loss_ce: 0.009588
[23:45:19.680] iteration 2870 : loss : 0.088506, loss_ce: 0.038057
[23:45:19.959] iteration 2871 : loss : 0.120858, loss_ce: 0.036627
[23:45:20.239] iteration 2872 : loss : 0.111051, loss_ce: 0.034190
[23:45:20.519] iteration 2873 : loss : 0.169754, loss_ce: 0.039030
[23:45:20.800] iteration 2874 : loss : 0.080052, loss_ce: 0.032618
[23:45:21.081] iteration 2875 : loss : 0.204420, loss_ce: 0.026616
[23:45:21.359] iteration 2876 : loss : 0.118920, loss_ce: 0.039913
[23:45:21.638] iteration 2877 : loss : 0.164025, loss_ce: 0.043222
[23:45:21.920] iteration 2878 : loss : 0.111777, loss_ce: 0.049000
[23:45:22.200] iteration 2879 : loss : 0.152705, loss_ce: 0.019913
[23:45:22.482] iteration 2880 : loss : 0.093276, loss_ce: 0.038173
[23:45:22.780] iteration 2881 : loss : 0.093389, loss_ce: 0.038030
[23:45:23.058] iteration 2882 : loss : 0.166190, loss_ce: 0.021255
[23:45:23.338] iteration 2883 : loss : 0.103130, loss_ce: 0.033329
[23:45:23.621] iteration 2884 : loss : 0.151130, loss_ce: 0.047881
[23:45:23.896] iteration 2885 : loss : 0.143697, loss_ce: 0.034937
[23:45:24.171] iteration 2886 : loss : 0.123187, loss_ce: 0.034272
[23:45:24.451] iteration 2887 : loss : 0.099354, loss_ce: 0.023041
[23:45:24.730] iteration 2888 : loss : 0.098373, loss_ce: 0.018567
[23:45:25.012] iteration 2889 : loss : 0.101442, loss_ce: 0.034292
[23:45:25.292] iteration 2890 : loss : 0.084219, loss_ce: 0.032674
[23:45:25.568] iteration 2891 : loss : 0.106360, loss_ce: 0.025298
[23:45:25.847] iteration 2892 : loss : 0.097473, loss_ce: 0.032566
[23:45:26.126] iteration 2893 : loss : 0.114539, loss_ce: 0.040091
[23:45:26.404] iteration 2894 : loss : 0.094694, loss_ce: 0.034997
[23:45:26.681] iteration 2895 : loss : 0.187770, loss_ce: 0.013488
[23:45:26.959] iteration 2896 : loss : 0.162720, loss_ce: 0.044027
[23:45:27.243] iteration 2897 : loss : 0.124488, loss_ce: 0.020119
[23:45:27.522] iteration 2898 : loss : 0.099861, loss_ce: 0.020238
[23:45:27.798] iteration 2899 : loss : 0.107335, loss_ce: 0.033444
[23:45:28.077] iteration 2900 : loss : 0.080243, loss_ce: 0.023631
[23:45:28.375] iteration 2901 : loss : 0.097970, loss_ce: 0.029850
[23:45:28.655] iteration 2902 : loss : 0.081257, loss_ce: 0.024258
[23:45:28.939] iteration 2903 : loss : 0.122402, loss_ce: 0.028753
[23:45:29.221] iteration 2904 : loss : 0.074082, loss_ce: 0.017182
[23:45:29.507] iteration 2905 : loss : 0.091005, loss_ce: 0.022794
[23:45:29.788] iteration 2906 : loss : 0.107956, loss_ce: 0.026571
[23:45:30.070] iteration 2907 : loss : 0.120672, loss_ce: 0.021001
[23:45:30.357] iteration 2908 : loss : 0.128095, loss_ce: 0.024995
[23:45:30.636] iteration 2909 : loss : 0.170702, loss_ce: 0.031967
[23:45:30.919] iteration 2910 : loss : 0.132289, loss_ce: 0.021088
[23:45:31.205] iteration 2911 : loss : 0.166959, loss_ce: 0.026683
[23:45:31.482] iteration 2912 : loss : 0.161401, loss_ce: 0.019755
[23:45:31.766] iteration 2913 : loss : 0.103047, loss_ce: 0.032332
[23:45:32.048] iteration 2914 : loss : 0.137157, loss_ce: 0.028240
[23:45:32.329] iteration 2915 : loss : 0.112746, loss_ce: 0.038248
[23:45:32.614] iteration 2916 : loss : 0.174410, loss_ce: 0.023014
[23:45:32.895] iteration 2917 : loss : 0.097375, loss_ce: 0.026969
[23:45:33.179] iteration 2918 : loss : 0.109127, loss_ce: 0.044029
[23:45:33.259] iteration 2919 : loss : 0.141845, loss_ce: 0.040849
[23:45:53.132] iteration 2920 : loss : 0.120283, loss_ce: 0.035623
[23:45:53.433] iteration 2921 : loss : 0.119981, loss_ce: 0.034837
[23:45:53.715] iteration 2922 : loss : 0.161663, loss_ce: 0.021076
[23:45:53.991] iteration 2923 : loss : 0.100719, loss_ce: 0.028920
[23:45:54.272] iteration 2924 : loss : 0.078906, loss_ce: 0.031086
[23:45:54.546] iteration 2925 : loss : 0.101575, loss_ce: 0.029535
[23:45:54.822] iteration 2926 : loss : 0.118575, loss_ce: 0.047855
[23:45:55.100] iteration 2927 : loss : 0.094788, loss_ce: 0.035547
[23:45:55.378] iteration 2928 : loss : 0.146899, loss_ce: 0.038770
[23:45:55.654] iteration 2929 : loss : 0.072633, loss_ce: 0.025807
[23:45:55.929] iteration 2930 : loss : 0.147950, loss_ce: 0.024952
[23:45:56.204] iteration 2931 : loss : 0.125735, loss_ce: 0.028031
[23:45:56.481] iteration 2932 : loss : 0.145729, loss_ce: 0.046928
[23:45:56.756] iteration 2933 : loss : 0.096051, loss_ce: 0.039605
[23:45:57.033] iteration 2934 : loss : 0.126485, loss_ce: 0.025329
[23:45:57.309] iteration 2935 : loss : 0.092872, loss_ce: 0.032657
[23:45:57.586] iteration 2936 : loss : 0.098147, loss_ce: 0.029425
[23:45:57.868] iteration 2937 : loss : 0.096145, loss_ce: 0.019441
[23:45:58.143] iteration 2938 : loss : 0.105762, loss_ce: 0.037258
[23:45:58.426] iteration 2939 : loss : 0.150053, loss_ce: 0.032832
[23:45:58.700] iteration 2940 : loss : 0.132546, loss_ce: 0.033352
[23:45:58.998] iteration 2941 : loss : 0.105375, loss_ce: 0.035837
[23:45:59.277] iteration 2942 : loss : 0.089810, loss_ce: 0.025545
[23:45:59.556] iteration 2943 : loss : 0.153565, loss_ce: 0.018961
[23:45:59.838] iteration 2944 : loss : 0.093274, loss_ce: 0.020108
[23:46:00.115] iteration 2945 : loss : 0.091674, loss_ce: 0.024100
[23:46:00.399] iteration 2946 : loss : 0.140029, loss_ce: 0.044197
[23:46:00.680] iteration 2947 : loss : 0.104545, loss_ce: 0.047532
[23:46:00.958] iteration 2948 : loss : 0.103189, loss_ce: 0.038428
[23:46:01.236] iteration 2949 : loss : 0.102190, loss_ce: 0.037181
[23:46:01.514] iteration 2950 : loss : 0.078852, loss_ce: 0.019304
[23:46:01.793] iteration 2951 : loss : 0.088564, loss_ce: 0.026735
[23:46:02.071] iteration 2952 : loss : 0.099791, loss_ce: 0.035681
[23:46:02.349] iteration 2953 : loss : 0.073202, loss_ce: 0.026386
[23:46:02.628] iteration 2954 : loss : 0.123911, loss_ce: 0.025354
[23:46:02.905] iteration 2955 : loss : 0.107822, loss_ce: 0.012848
[23:46:03.183] iteration 2956 : loss : 0.125601, loss_ce: 0.022790
[23:46:03.462] iteration 2957 : loss : 0.154557, loss_ce: 0.019872
[23:46:03.743] iteration 2958 : loss : 0.138444, loss_ce: 0.025520
[23:46:04.018] iteration 2959 : loss : 0.159526, loss_ce: 0.032281
[23:46:04.296] iteration 2960 : loss : 0.137037, loss_ce: 0.026502
[23:46:04.594] iteration 2961 : loss : 0.094762, loss_ce: 0.025588
[23:46:04.872] iteration 2962 : loss : 0.176603, loss_ce: 0.020479
[23:46:05.147] iteration 2963 : loss : 0.307308, loss_ce: 0.021827
[23:46:05.423] iteration 2964 : loss : 0.106536, loss_ce: 0.013397
[23:46:05.703] iteration 2965 : loss : 0.123394, loss_ce: 0.047189
[23:46:05.980] iteration 2966 : loss : 0.141649, loss_ce: 0.072012
[23:46:06.260] iteration 2967 : loss : 0.106697, loss_ce: 0.032513
[23:46:06.539] iteration 2968 : loss : 0.097496, loss_ce: 0.029493
[23:46:06.816] iteration 2969 : loss : 0.115953, loss_ce: 0.013877
[23:46:07.097] iteration 2970 : loss : 0.169651, loss_ce: 0.028239
[23:46:07.374] iteration 2971 : loss : 0.147065, loss_ce: 0.027981
[23:46:07.652] iteration 2972 : loss : 0.146394, loss_ce: 0.026405
[23:46:07.930] iteration 2973 : loss : 0.147262, loss_ce: 0.014486
[23:46:08.205] iteration 2974 : loss : 0.095152, loss_ce: 0.026743
[23:46:08.483] iteration 2975 : loss : 0.073566, loss_ce: 0.015643
[23:46:08.758] iteration 2976 : loss : 0.148586, loss_ce: 0.018537
[23:46:09.033] iteration 2977 : loss : 0.132370, loss_ce: 0.029423
[23:46:09.311] iteration 2978 : loss : 0.079111, loss_ce: 0.014292
[23:46:09.587] iteration 2979 : loss : 0.109742, loss_ce: 0.040469
[23:46:09.867] iteration 2980 : loss : 0.292945, loss_ce: 0.009706
[23:46:10.157] iteration 2981 : loss : 0.096871, loss_ce: 0.031332
[23:46:10.433] iteration 2982 : loss : 0.129022, loss_ce: 0.036801
[23:46:10.710] iteration 2983 : loss : 0.082936, loss_ce: 0.020689
[23:46:10.990] iteration 2984 : loss : 0.082206, loss_ce: 0.033010
[23:46:11.271] iteration 2985 : loss : 0.088278, loss_ce: 0.033593
[23:46:11.551] iteration 2986 : loss : 0.138223, loss_ce: 0.021855
[23:46:11.829] iteration 2987 : loss : 0.134755, loss_ce: 0.035187
[23:46:12.107] iteration 2988 : loss : 0.073414, loss_ce: 0.026547
[23:46:12.387] iteration 2989 : loss : 0.135555, loss_ce: 0.015584
[23:46:12.662] iteration 2990 : loss : 0.107039, loss_ce: 0.034031
[23:46:12.942] iteration 2991 : loss : 0.138823, loss_ce: 0.018589
[23:46:13.219] iteration 2992 : loss : 0.124216, loss_ce: 0.023383
[23:46:13.498] iteration 2993 : loss : 0.097483, loss_ce: 0.025184
[23:46:13.775] iteration 2994 : loss : 0.088206, loss_ce: 0.035582
[23:46:14.049] iteration 2995 : loss : 0.075021, loss_ce: 0.023471
[23:46:14.326] iteration 2996 : loss : 0.138807, loss_ce: 0.021999
[23:46:14.609] iteration 2997 : loss : 0.096012, loss_ce: 0.031534
[23:46:14.887] iteration 2998 : loss : 0.069671, loss_ce: 0.025795
[23:46:15.165] iteration 2999 : loss : 0.104747, loss_ce: 0.027766
[23:46:15.442] iteration 3000 : loss : 0.102744, loss_ce: 0.026364
[23:46:15.736] iteration 3001 : loss : 0.094701, loss_ce: 0.024775
[23:46:16.015] iteration 3002 : loss : 0.115040, loss_ce: 0.022775
[23:46:16.292] iteration 3003 : loss : 0.161106, loss_ce: 0.013427
[23:46:16.571] iteration 3004 : loss : 0.114645, loss_ce: 0.020711
[23:46:16.849] iteration 3005 : loss : 0.116998, loss_ce: 0.014670
[23:46:17.126] iteration 3006 : loss : 0.257750, loss_ce: 0.010312
[23:46:17.406] iteration 3007 : loss : 0.103295, loss_ce: 0.039091
[23:46:17.682] iteration 3008 : loss : 0.111883, loss_ce: 0.045804
[23:46:17.962] iteration 3009 : loss : 0.150413, loss_ce: 0.029104
[23:46:18.237] iteration 3010 : loss : 0.121254, loss_ce: 0.037319
[23:46:18.516] iteration 3011 : loss : 0.103901, loss_ce: 0.034001
[23:46:18.797] iteration 3012 : loss : 0.121760, loss_ce: 0.037839
[23:46:19.078] iteration 3013 : loss : 0.121183, loss_ce: 0.042110
[23:46:19.357] iteration 3014 : loss : 0.145617, loss_ce: 0.020924
[23:46:19.636] iteration 3015 : loss : 0.112330, loss_ce: 0.027839
[23:46:19.912] iteration 3016 : loss : 0.170872, loss_ce: 0.021780
[23:46:20.192] iteration 3017 : loss : 0.109399, loss_ce: 0.015373
[23:46:20.469] iteration 3018 : loss : 0.123555, loss_ce: 0.032833
[23:46:20.747] iteration 3019 : loss : 0.203327, loss_ce: 0.027294
[23:46:21.026] iteration 3020 : loss : 0.175786, loss_ce: 0.029443
[23:46:21.321] iteration 3021 : loss : 0.118321, loss_ce: 0.036553
[23:46:21.597] iteration 3022 : loss : 0.125880, loss_ce: 0.028617
[23:46:21.878] iteration 3023 : loss : 0.120162, loss_ce: 0.015200
[23:46:22.157] iteration 3024 : loss : 0.149437, loss_ce: 0.033261
[23:46:22.435] iteration 3025 : loss : 0.144735, loss_ce: 0.034768
[23:46:22.713] iteration 3026 : loss : 0.127678, loss_ce: 0.050353
[23:46:22.993] iteration 3027 : loss : 0.126310, loss_ce: 0.052712
[23:46:23.270] iteration 3028 : loss : 0.179299, loss_ce: 0.011550
[23:46:23.544] iteration 3029 : loss : 0.071498, loss_ce: 0.025379
[23:46:23.824] iteration 3030 : loss : 0.123160, loss_ce: 0.022475
[23:46:24.105] iteration 3031 : loss : 0.102136, loss_ce: 0.028114
[23:46:24.382] iteration 3032 : loss : 0.134676, loss_ce: 0.016860
[23:46:24.662] iteration 3033 : loss : 0.111592, loss_ce: 0.030525
[23:46:24.939] iteration 3034 : loss : 0.150492, loss_ce: 0.029122
[23:46:25.215] iteration 3035 : loss : 0.099371, loss_ce: 0.016586
[23:46:25.494] iteration 3036 : loss : 0.207690, loss_ce: 0.013949
[23:46:25.769] iteration 3037 : loss : 0.180589, loss_ce: 0.042126
[23:46:26.049] iteration 3038 : loss : 0.092916, loss_ce: 0.029035
[23:46:26.325] iteration 3039 : loss : 0.110550, loss_ce: 0.033892
[23:46:26.607] iteration 3040 : loss : 0.101144, loss_ce: 0.026603
[23:46:26.903] iteration 3041 : loss : 0.087553, loss_ce: 0.040856
[23:46:27.182] iteration 3042 : loss : 0.110456, loss_ce: 0.026923
[23:46:27.467] iteration 3043 : loss : 0.087717, loss_ce: 0.031926
[23:46:27.748] iteration 3044 : loss : 0.082364, loss_ce: 0.028066
[23:46:28.032] iteration 3045 : loss : 0.096736, loss_ce: 0.023105
[23:46:28.317] iteration 3046 : loss : 0.160287, loss_ce: 0.009363
[23:46:28.598] iteration 3047 : loss : 0.119605, loss_ce: 0.025910
[23:46:28.882] iteration 3048 : loss : 0.200268, loss_ce: 0.029635
[23:46:29.159] iteration 3049 : loss : 0.161664, loss_ce: 0.050490
[23:46:29.441] iteration 3050 : loss : 0.169231, loss_ce: 0.037083
[23:46:29.723] iteration 3051 : loss : 0.302528, loss_ce: 0.015587
[23:46:30.003] iteration 3052 : loss : 0.109761, loss_ce: 0.030603
[23:46:30.284] iteration 3053 : loss : 0.081548, loss_ce: 0.029674
[23:46:30.565] iteration 3054 : loss : 0.147465, loss_ce: 0.024534
[23:46:30.848] iteration 3055 : loss : 0.196635, loss_ce: 0.029645
[23:46:31.128] iteration 3056 : loss : 0.122099, loss_ce: 0.056423
[23:46:31.414] iteration 3057 : loss : 0.141311, loss_ce: 0.021320
[23:46:31.493] iteration 3058 : loss : 0.192169, loss_ce: 0.022108
[23:46:49.778] iteration 3059 : loss : 0.115219, loss_ce: 0.044041
[23:46:50.055] iteration 3060 : loss : 0.107924, loss_ce: 0.022980
[23:46:50.358] iteration 3061 : loss : 0.157826, loss_ce: 0.018024
[23:46:50.638] iteration 3062 : loss : 0.139596, loss_ce: 0.022808
[23:46:50.919] iteration 3063 : loss : 0.132851, loss_ce: 0.046219
[23:46:51.194] iteration 3064 : loss : 0.105939, loss_ce: 0.025028
[23:46:51.471] iteration 3065 : loss : 0.192891, loss_ce: 0.060116
[23:46:51.749] iteration 3066 : loss : 0.090739, loss_ce: 0.030971
[23:46:52.026] iteration 3067 : loss : 0.102667, loss_ce: 0.032454
[23:46:52.304] iteration 3068 : loss : 0.232027, loss_ce: 0.015669
[23:46:52.580] iteration 3069 : loss : 0.061085, loss_ce: 0.009423
[23:46:52.860] iteration 3070 : loss : 0.152793, loss_ce: 0.047996
[23:46:53.143] iteration 3071 : loss : 0.090145, loss_ce: 0.019804
[23:46:53.417] iteration 3072 : loss : 0.133026, loss_ce: 0.047726
[23:46:53.695] iteration 3073 : loss : 0.175187, loss_ce: 0.024595
[23:46:53.971] iteration 3074 : loss : 0.158792, loss_ce: 0.029123
[23:46:54.249] iteration 3075 : loss : 0.096700, loss_ce: 0.032698
[23:46:54.531] iteration 3076 : loss : 0.129624, loss_ce: 0.040975
[23:46:54.807] iteration 3077 : loss : 0.099063, loss_ce: 0.017737
[23:46:55.086] iteration 3078 : loss : 0.099499, loss_ce: 0.040723
[23:46:55.364] iteration 3079 : loss : 0.105596, loss_ce: 0.027248
[23:46:55.644] iteration 3080 : loss : 0.118697, loss_ce: 0.017890
[23:46:55.938] iteration 3081 : loss : 0.112600, loss_ce: 0.044685
[23:46:56.215] iteration 3082 : loss : 0.107963, loss_ce: 0.025770
[23:46:56.495] iteration 3083 : loss : 0.098044, loss_ce: 0.032628
[23:46:56.773] iteration 3084 : loss : 0.105491, loss_ce: 0.038956
[23:46:57.050] iteration 3085 : loss : 0.117565, loss_ce: 0.025476
[23:46:57.330] iteration 3086 : loss : 0.154192, loss_ce: 0.025131
[23:46:57.610] iteration 3087 : loss : 0.121503, loss_ce: 0.050902
[23:46:57.892] iteration 3088 : loss : 0.195738, loss_ce: 0.024151
[23:46:58.169] iteration 3089 : loss : 0.155581, loss_ce: 0.028621
[23:46:58.446] iteration 3090 : loss : 0.128880, loss_ce: 0.040629
[23:46:58.728] iteration 3091 : loss : 0.138086, loss_ce: 0.042645
[23:46:59.005] iteration 3092 : loss : 0.080592, loss_ce: 0.020692
[23:46:59.286] iteration 3093 : loss : 0.087087, loss_ce: 0.029371
[23:46:59.565] iteration 3094 : loss : 0.134091, loss_ce: 0.047229
[23:46:59.841] iteration 3095 : loss : 0.093661, loss_ce: 0.043646
[23:47:00.119] iteration 3096 : loss : 0.125020, loss_ce: 0.058640
[23:47:00.403] iteration 3097 : loss : 0.145430, loss_ce: 0.027950
[23:47:00.681] iteration 3098 : loss : 0.273685, loss_ce: 0.014225
[23:47:00.963] iteration 3099 : loss : 0.074514, loss_ce: 0.014077
[23:47:01.245] iteration 3100 : loss : 0.117572, loss_ce: 0.021551
[23:47:01.548] iteration 3101 : loss : 0.158089, loss_ce: 0.028401
[23:47:01.826] iteration 3102 : loss : 0.124443, loss_ce: 0.031753
[23:47:02.102] iteration 3103 : loss : 0.110817, loss_ce: 0.041526
[23:47:02.386] iteration 3104 : loss : 0.087195, loss_ce: 0.013713
[23:47:02.667] iteration 3105 : loss : 0.087925, loss_ce: 0.017932
[23:47:02.946] iteration 3106 : loss : 0.099059, loss_ce: 0.038355
[23:47:03.230] iteration 3107 : loss : 0.076223, loss_ce: 0.027131
[23:47:03.512] iteration 3108 : loss : 0.092722, loss_ce: 0.029062
[23:47:03.792] iteration 3109 : loss : 0.136445, loss_ce: 0.033064
[23:47:04.068] iteration 3110 : loss : 0.099082, loss_ce: 0.037651
[23:47:04.345] iteration 3111 : loss : 0.092185, loss_ce: 0.019161
[23:47:04.626] iteration 3112 : loss : 0.132817, loss_ce: 0.045324
[23:47:04.904] iteration 3113 : loss : 0.158526, loss_ce: 0.018402
[23:47:05.183] iteration 3114 : loss : 0.129035, loss_ce: 0.036518
[23:47:05.463] iteration 3115 : loss : 0.106738, loss_ce: 0.039524
[23:47:05.743] iteration 3116 : loss : 0.144275, loss_ce: 0.025326
[23:47:06.024] iteration 3117 : loss : 0.105695, loss_ce: 0.022841
[23:47:06.301] iteration 3118 : loss : 0.139187, loss_ce: 0.031499
[23:47:06.582] iteration 3119 : loss : 0.141138, loss_ce: 0.015152
[23:47:06.863] iteration 3120 : loss : 0.143570, loss_ce: 0.027237
[23:47:07.164] iteration 3121 : loss : 0.179411, loss_ce: 0.016866
[23:47:07.443] iteration 3122 : loss : 0.107766, loss_ce: 0.032765
[23:47:07.723] iteration 3123 : loss : 0.123393, loss_ce: 0.025430
[23:47:08.001] iteration 3124 : loss : 0.160560, loss_ce: 0.021927
[23:47:08.282] iteration 3125 : loss : 0.098271, loss_ce: 0.024189
[23:47:08.563] iteration 3126 : loss : 0.108531, loss_ce: 0.052934
[23:47:08.838] iteration 3127 : loss : 0.098216, loss_ce: 0.040264
[23:47:09.118] iteration 3128 : loss : 0.119461, loss_ce: 0.034156
[23:47:09.395] iteration 3129 : loss : 0.093365, loss_ce: 0.033780
[23:47:09.677] iteration 3130 : loss : 0.091313, loss_ce: 0.023334
[23:47:09.954] iteration 3131 : loss : 0.101766, loss_ce: 0.025284
[23:47:10.235] iteration 3132 : loss : 0.161321, loss_ce: 0.034137
[23:47:10.514] iteration 3133 : loss : 0.106446, loss_ce: 0.037474
[23:47:10.796] iteration 3134 : loss : 0.110378, loss_ce: 0.025479
[23:47:11.078] iteration 3135 : loss : 0.088275, loss_ce: 0.019032
[23:47:11.358] iteration 3136 : loss : 0.141592, loss_ce: 0.024512
[23:47:11.639] iteration 3137 : loss : 0.122910, loss_ce: 0.024821
[23:47:11.920] iteration 3138 : loss : 0.148254, loss_ce: 0.013143
[23:47:12.198] iteration 3139 : loss : 0.154883, loss_ce: 0.031715
[23:47:12.474] iteration 3140 : loss : 0.133129, loss_ce: 0.028992
[23:47:12.779] iteration 3141 : loss : 0.187493, loss_ce: 0.023247
[23:47:13.055] iteration 3142 : loss : 0.078357, loss_ce: 0.023359
[23:47:13.332] iteration 3143 : loss : 0.078827, loss_ce: 0.031754
[23:47:13.614] iteration 3144 : loss : 0.132646, loss_ce: 0.023924
[23:47:13.896] iteration 3145 : loss : 0.099346, loss_ce: 0.039044
[23:47:14.180] iteration 3146 : loss : 0.082779, loss_ce: 0.013339
[23:47:14.458] iteration 3147 : loss : 0.139051, loss_ce: 0.020923
[23:47:14.737] iteration 3148 : loss : 0.118843, loss_ce: 0.039674
[23:47:15.014] iteration 3149 : loss : 0.152397, loss_ce: 0.022506
[23:47:15.291] iteration 3150 : loss : 0.127180, loss_ce: 0.020007
[23:47:15.572] iteration 3151 : loss : 0.070946, loss_ce: 0.021045
[23:47:15.850] iteration 3152 : loss : 0.093049, loss_ce: 0.026304
[23:47:16.130] iteration 3153 : loss : 0.152646, loss_ce: 0.017666
[23:47:16.415] iteration 3154 : loss : 0.138257, loss_ce: 0.038459
[23:47:16.694] iteration 3155 : loss : 0.099675, loss_ce: 0.039596
[23:47:16.974] iteration 3156 : loss : 0.128274, loss_ce: 0.028131
[23:47:17.255] iteration 3157 : loss : 0.151783, loss_ce: 0.022530
[23:47:17.535] iteration 3158 : loss : 0.086414, loss_ce: 0.030619
[23:47:17.818] iteration 3159 : loss : 0.140572, loss_ce: 0.039815
[23:47:18.097] iteration 3160 : loss : 0.103507, loss_ce: 0.025452
[23:47:18.397] iteration 3161 : loss : 0.179166, loss_ce: 0.034540
[23:47:18.678] iteration 3162 : loss : 0.117401, loss_ce: 0.030114
[23:47:18.958] iteration 3163 : loss : 0.124614, loss_ce: 0.027040
[23:47:19.238] iteration 3164 : loss : 0.103268, loss_ce: 0.033434
[23:47:19.521] iteration 3165 : loss : 0.130525, loss_ce: 0.026357
[23:47:19.803] iteration 3166 : loss : 0.161783, loss_ce: 0.028556
[23:47:20.083] iteration 3167 : loss : 0.091342, loss_ce: 0.020948
[23:47:20.366] iteration 3168 : loss : 0.166781, loss_ce: 0.028195
[23:47:20.644] iteration 3169 : loss : 0.126971, loss_ce: 0.041560
[23:47:20.926] iteration 3170 : loss : 0.188801, loss_ce: 0.009453
[23:47:21.206] iteration 3171 : loss : 0.090219, loss_ce: 0.024815
[23:47:21.484] iteration 3172 : loss : 0.228254, loss_ce: 0.007657
[23:47:21.766] iteration 3173 : loss : 0.117416, loss_ce: 0.042623
[23:47:22.045] iteration 3174 : loss : 0.087020, loss_ce: 0.025686
[23:47:22.326] iteration 3175 : loss : 0.126351, loss_ce: 0.033103
[23:47:22.605] iteration 3176 : loss : 0.152354, loss_ce: 0.036792
[23:47:22.885] iteration 3177 : loss : 0.082222, loss_ce: 0.016448
[23:47:23.167] iteration 3178 : loss : 0.147359, loss_ce: 0.028409
[23:47:23.444] iteration 3179 : loss : 0.069893, loss_ce: 0.013674
[23:47:23.722] iteration 3180 : loss : 0.079081, loss_ce: 0.020846
[23:47:24.021] iteration 3181 : loss : 0.107019, loss_ce: 0.024209
[23:47:24.300] iteration 3182 : loss : 0.108599, loss_ce: 0.033348
[23:47:24.583] iteration 3183 : loss : 0.071878, loss_ce: 0.021568
[23:47:24.869] iteration 3184 : loss : 0.142215, loss_ce: 0.037756
[23:47:25.150] iteration 3185 : loss : 0.145071, loss_ce: 0.028614
[23:47:25.432] iteration 3186 : loss : 0.154009, loss_ce: 0.012575
[23:47:25.709] iteration 3187 : loss : 0.099906, loss_ce: 0.031351
[23:47:25.992] iteration 3188 : loss : 0.128187, loss_ce: 0.037264
[23:47:26.281] iteration 3189 : loss : 0.125429, loss_ce: 0.036995
[23:47:26.560] iteration 3190 : loss : 0.086588, loss_ce: 0.019105
[23:47:26.846] iteration 3191 : loss : 0.244525, loss_ce: 0.007169
[23:47:27.128] iteration 3192 : loss : 0.137327, loss_ce: 0.020013
[23:47:27.409] iteration 3193 : loss : 0.113577, loss_ce: 0.017709
[23:47:27.688] iteration 3194 : loss : 0.150305, loss_ce: 0.044894
[23:47:27.968] iteration 3195 : loss : 0.144884, loss_ce: 0.027697
[23:47:28.252] iteration 3196 : loss : 0.219605, loss_ce: 0.031893
[23:47:28.331] iteration 3197 : loss : 0.374362, loss_ce: 0.030622
[23:47:46.123] iteration 3198 : loss : 0.183743, loss_ce: 0.007976
[23:47:46.407] iteration 3199 : loss : 0.298754, loss_ce: 0.008925
[23:47:46.687] iteration 3200 : loss : 0.086970, loss_ce: 0.041113
[23:47:46.983] iteration 3201 : loss : 0.078925, loss_ce: 0.039140
[23:47:47.266] iteration 3202 : loss : 0.175543, loss_ce: 0.028915
[23:47:47.545] iteration 3203 : loss : 0.076931, loss_ce: 0.028364
[23:47:47.823] iteration 3204 : loss : 0.099804, loss_ce: 0.043117
[23:47:48.102] iteration 3205 : loss : 0.081205, loss_ce: 0.018853
[23:47:48.379] iteration 3206 : loss : 0.164032, loss_ce: 0.021726
[23:47:48.654] iteration 3207 : loss : 0.090159, loss_ce: 0.038547
[23:47:48.933] iteration 3208 : loss : 0.155645, loss_ce: 0.023226
[23:47:49.214] iteration 3209 : loss : 0.092505, loss_ce: 0.026207
[23:47:49.490] iteration 3210 : loss : 0.147328, loss_ce: 0.023368
[23:47:49.771] iteration 3211 : loss : 0.099559, loss_ce: 0.036321
[23:47:50.048] iteration 3212 : loss : 0.104870, loss_ce: 0.050906
[23:47:50.329] iteration 3213 : loss : 0.087717, loss_ce: 0.022570
[23:47:50.607] iteration 3214 : loss : 0.088726, loss_ce: 0.013762
[23:47:50.885] iteration 3215 : loss : 0.116427, loss_ce: 0.036105
[23:47:51.167] iteration 3216 : loss : 0.096964, loss_ce: 0.019463
[23:47:51.443] iteration 3217 : loss : 0.126393, loss_ce: 0.031246
[23:47:51.725] iteration 3218 : loss : 0.149135, loss_ce: 0.033429
[23:47:52.004] iteration 3219 : loss : 0.147641, loss_ce: 0.018253
[23:47:52.281] iteration 3220 : loss : 0.106928, loss_ce: 0.046121
[23:47:52.582] iteration 3221 : loss : 0.087822, loss_ce: 0.020132
[23:47:52.862] iteration 3222 : loss : 0.088860, loss_ce: 0.025745
[23:47:53.139] iteration 3223 : loss : 0.087704, loss_ce: 0.025676
[23:47:53.419] iteration 3224 : loss : 0.074951, loss_ce: 0.022392
[23:47:53.696] iteration 3225 : loss : 0.083611, loss_ce: 0.033862
[23:47:53.972] iteration 3226 : loss : 0.101722, loss_ce: 0.019692
[23:47:54.251] iteration 3227 : loss : 0.091384, loss_ce: 0.025069
[23:47:54.532] iteration 3228 : loss : 0.101060, loss_ce: 0.045878
[23:47:54.814] iteration 3229 : loss : 0.084875, loss_ce: 0.018699
[23:47:55.090] iteration 3230 : loss : 0.115594, loss_ce: 0.036626
[23:47:55.369] iteration 3231 : loss : 0.098653, loss_ce: 0.028593
[23:47:55.644] iteration 3232 : loss : 0.069635, loss_ce: 0.021139
[23:47:55.922] iteration 3233 : loss : 0.154068, loss_ce: 0.036340
[23:47:56.202] iteration 3234 : loss : 0.102667, loss_ce: 0.024721
[23:47:56.480] iteration 3235 : loss : 0.119389, loss_ce: 0.038155
[23:47:56.761] iteration 3236 : loss : 0.104169, loss_ce: 0.024889
[23:47:57.043] iteration 3237 : loss : 0.081681, loss_ce: 0.030365
[23:47:57.322] iteration 3238 : loss : 0.116614, loss_ce: 0.036647
[23:47:57.603] iteration 3239 : loss : 0.141560, loss_ce: 0.030431
[23:47:57.881] iteration 3240 : loss : 0.087363, loss_ce: 0.026852
[23:47:58.197] iteration 3241 : loss : 0.144837, loss_ce: 0.015186
[23:47:58.487] iteration 3242 : loss : 0.075110, loss_ce: 0.018072
[23:47:58.783] iteration 3243 : loss : 0.098551, loss_ce: 0.015784
[23:47:59.073] iteration 3244 : loss : 0.080436, loss_ce: 0.023199
[23:47:59.359] iteration 3245 : loss : 0.113078, loss_ce: 0.027677
[23:47:59.648] iteration 3246 : loss : 0.088181, loss_ce: 0.015549
[23:47:59.944] iteration 3247 : loss : 0.105253, loss_ce: 0.028691
[23:48:00.225] iteration 3248 : loss : 0.182236, loss_ce: 0.052591
[23:48:00.513] iteration 3249 : loss : 0.095703, loss_ce: 0.032715
[23:48:00.792] iteration 3250 : loss : 0.093671, loss_ce: 0.034360
[23:48:01.076] iteration 3251 : loss : 0.091667, loss_ce: 0.027218
[23:48:01.361] iteration 3252 : loss : 0.136296, loss_ce: 0.019605
[23:48:01.650] iteration 3253 : loss : 0.073105, loss_ce: 0.022288
[23:48:01.934] iteration 3254 : loss : 0.108602, loss_ce: 0.044923
[23:48:02.219] iteration 3255 : loss : 0.102037, loss_ce: 0.015946
[23:48:02.506] iteration 3256 : loss : 0.134864, loss_ce: 0.021622
[23:48:02.791] iteration 3257 : loss : 0.147694, loss_ce: 0.024621
[23:48:03.078] iteration 3258 : loss : 0.166246, loss_ce: 0.008199
[23:48:03.357] iteration 3259 : loss : 0.154172, loss_ce: 0.041853
[23:48:03.636] iteration 3260 : loss : 0.149992, loss_ce: 0.018476
[23:48:03.929] iteration 3261 : loss : 0.150106, loss_ce: 0.035433
[23:48:04.206] iteration 3262 : loss : 0.089383, loss_ce: 0.037160
[23:48:04.497] iteration 3263 : loss : 0.295034, loss_ce: 0.014338
[23:48:04.775] iteration 3264 : loss : 0.082559, loss_ce: 0.030641
[23:48:05.051] iteration 3265 : loss : 0.090676, loss_ce: 0.023031
[23:48:05.329] iteration 3266 : loss : 0.114249, loss_ce: 0.031590
[23:48:05.626] iteration 3267 : loss : 0.121392, loss_ce: 0.041042
[23:48:05.903] iteration 3268 : loss : 0.143637, loss_ce: 0.014917
[23:48:06.181] iteration 3269 : loss : 0.103697, loss_ce: 0.021073
[23:48:06.458] iteration 3270 : loss : 0.125179, loss_ce: 0.040216
[23:48:06.739] iteration 3271 : loss : 0.187361, loss_ce: 0.034353
[23:48:07.017] iteration 3272 : loss : 0.188435, loss_ce: 0.015836
[23:48:07.294] iteration 3273 : loss : 0.108101, loss_ce: 0.034858
[23:48:07.569] iteration 3274 : loss : 0.114214, loss_ce: 0.045389
[23:48:07.847] iteration 3275 : loss : 0.105038, loss_ce: 0.042371
[23:48:08.129] iteration 3276 : loss : 0.098425, loss_ce: 0.039051
[23:48:08.419] iteration 3277 : loss : 0.102376, loss_ce: 0.031413
[23:48:08.708] iteration 3278 : loss : 0.103992, loss_ce: 0.018516
[23:48:08.999] iteration 3279 : loss : 0.140494, loss_ce: 0.022504
[23:48:09.279] iteration 3280 : loss : 0.237386, loss_ce: 0.018948
[23:48:09.575] iteration 3281 : loss : 0.156055, loss_ce: 0.017873
[23:48:09.852] iteration 3282 : loss : 0.108557, loss_ce: 0.016682
[23:48:10.133] iteration 3283 : loss : 0.418786, loss_ce: 0.006144
[23:48:10.412] iteration 3284 : loss : 0.127870, loss_ce: 0.022428
[23:48:10.690] iteration 3285 : loss : 0.097043, loss_ce: 0.025646
[23:48:10.967] iteration 3286 : loss : 0.096823, loss_ce: 0.035786
[23:48:11.246] iteration 3287 : loss : 0.085066, loss_ce: 0.030767
[23:48:11.524] iteration 3288 : loss : 0.112115, loss_ce: 0.015406
[23:48:11.799] iteration 3289 : loss : 0.101962, loss_ce: 0.023380
[23:48:12.076] iteration 3290 : loss : 0.087074, loss_ce: 0.035128
[23:48:12.352] iteration 3291 : loss : 0.086739, loss_ce: 0.023648
[23:48:12.638] iteration 3292 : loss : 0.187289, loss_ce: 0.019582
[23:48:12.916] iteration 3293 : loss : 0.252888, loss_ce: 0.024133
[23:48:13.193] iteration 3294 : loss : 0.111935, loss_ce: 0.045487
[23:48:13.497] iteration 3295 : loss : 0.094949, loss_ce: 0.019043
[23:48:13.800] iteration 3296 : loss : 0.111645, loss_ce: 0.031899
[23:48:14.097] iteration 3297 : loss : 0.164790, loss_ce: 0.019226
[23:48:14.389] iteration 3298 : loss : 0.120228, loss_ce: 0.026570
[23:48:14.669] iteration 3299 : loss : 0.127206, loss_ce: 0.012747
[23:48:14.946] iteration 3300 : loss : 0.135393, loss_ce: 0.038268
[23:48:15.260] iteration 3301 : loss : 0.163809, loss_ce: 0.018635
[23:48:15.554] iteration 3302 : loss : 0.113169, loss_ce: 0.051994
[23:48:15.842] iteration 3303 : loss : 0.113722, loss_ce: 0.037252
[23:48:16.123] iteration 3304 : loss : 0.130565, loss_ce: 0.031230
[23:48:16.404] iteration 3305 : loss : 0.101938, loss_ce: 0.038147
[23:48:16.685] iteration 3306 : loss : 0.099234, loss_ce: 0.034233
[23:48:16.966] iteration 3307 : loss : 0.096175, loss_ce: 0.029198
[23:48:17.249] iteration 3308 : loss : 0.090513, loss_ce: 0.023802
[23:48:17.535] iteration 3309 : loss : 0.097006, loss_ce: 0.042305
[23:48:17.816] iteration 3310 : loss : 0.088848, loss_ce: 0.043033
[23:48:18.097] iteration 3311 : loss : 0.123564, loss_ce: 0.033606
[23:48:18.383] iteration 3312 : loss : 0.084833, loss_ce: 0.019792
[23:48:18.664] iteration 3313 : loss : 0.115701, loss_ce: 0.030475
[23:48:18.946] iteration 3314 : loss : 0.105559, loss_ce: 0.043474
[23:48:19.241] iteration 3315 : loss : 0.097451, loss_ce: 0.030391
[23:48:19.529] iteration 3316 : loss : 0.097343, loss_ce: 0.020596
[23:48:19.826] iteration 3317 : loss : 0.118771, loss_ce: 0.027576
[23:48:20.130] iteration 3318 : loss : 0.135001, loss_ce: 0.025124
[23:48:20.446] iteration 3319 : loss : 0.235772, loss_ce: 0.018632
[23:48:20.802] iteration 3320 : loss : 0.083020, loss_ce: 0.024379
[23:48:21.131] iteration 3321 : loss : 0.155077, loss_ce: 0.013469
[23:48:21.437] iteration 3322 : loss : 0.067961, loss_ce: 0.016224
[23:48:21.739] iteration 3323 : loss : 0.115835, loss_ce: 0.042445
[23:48:22.055] iteration 3324 : loss : 0.123384, loss_ce: 0.041152
[23:48:22.406] iteration 3325 : loss : 0.097522, loss_ce: 0.021865
[23:48:22.745] iteration 3326 : loss : 0.098033, loss_ce: 0.036946
[23:48:23.057] iteration 3327 : loss : 0.237205, loss_ce: 0.020731
[23:48:23.343] iteration 3328 : loss : 0.102217, loss_ce: 0.025791
[23:48:23.633] iteration 3329 : loss : 0.097900, loss_ce: 0.028945
[23:48:23.929] iteration 3330 : loss : 0.132199, loss_ce: 0.026505
[23:48:24.250] iteration 3331 : loss : 0.113325, loss_ce: 0.028319
[23:48:24.582] iteration 3332 : loss : 0.088258, loss_ce: 0.030976
[23:48:24.911] iteration 3333 : loss : 0.153185, loss_ce: 0.028582
[23:48:25.228] iteration 3334 : loss : 0.103258, loss_ce: 0.034835
[23:48:25.544] iteration 3335 : loss : 0.103716, loss_ce: 0.030625
[23:48:25.620] iteration 3336 : loss : 0.124990, loss_ce: 0.037225
[23:48:45.117] iteration 3337 : loss : 0.105524, loss_ce: 0.029909
[23:48:45.444] iteration 3338 : loss : 0.123791, loss_ce: 0.028635
[23:48:45.761] iteration 3339 : loss : 0.110480, loss_ce: 0.029291
[23:48:46.064] iteration 3340 : loss : 0.144763, loss_ce: 0.021793
[23:48:46.382] iteration 3341 : loss : 0.090438, loss_ce: 0.017342
[23:48:46.727] iteration 3342 : loss : 0.116642, loss_ce: 0.037517
[23:48:47.023] iteration 3343 : loss : 0.086949, loss_ce: 0.022192
[23:48:47.304] iteration 3344 : loss : 0.186381, loss_ce: 0.023388
[23:48:47.585] iteration 3345 : loss : 0.087089, loss_ce: 0.020178
[23:48:47.865] iteration 3346 : loss : 0.078903, loss_ce: 0.020416
[23:48:48.143] iteration 3347 : loss : 0.087329, loss_ce: 0.027650
[23:48:48.425] iteration 3348 : loss : 0.159865, loss_ce: 0.047450
[23:48:48.722] iteration 3349 : loss : 0.101314, loss_ce: 0.037517
[23:48:49.044] iteration 3350 : loss : 0.112721, loss_ce: 0.018477
[23:48:49.374] iteration 3351 : loss : 0.071031, loss_ce: 0.026578
[23:48:49.699] iteration 3352 : loss : 0.134558, loss_ce: 0.022821
[23:48:50.026] iteration 3353 : loss : 0.114840, loss_ce: 0.019822
[23:48:50.333] iteration 3354 : loss : 0.086537, loss_ce: 0.021683
[23:48:50.648] iteration 3355 : loss : 0.073574, loss_ce: 0.016112
[23:48:50.954] iteration 3356 : loss : 0.082286, loss_ce: 0.018831
[23:48:51.255] iteration 3357 : loss : 0.135495, loss_ce: 0.017919
[23:48:51.550] iteration 3358 : loss : 0.081260, loss_ce: 0.027258
[23:48:51.862] iteration 3359 : loss : 0.151613, loss_ce: 0.036337
[23:48:52.162] iteration 3360 : loss : 0.099433, loss_ce: 0.031613
[23:48:52.484] iteration 3361 : loss : 0.147125, loss_ce: 0.025070
[23:48:52.823] iteration 3362 : loss : 0.114408, loss_ce: 0.037970
[23:48:53.144] iteration 3363 : loss : 0.099818, loss_ce: 0.019529
[23:48:53.480] iteration 3364 : loss : 0.104611, loss_ce: 0.029877
[23:48:53.800] iteration 3365 : loss : 0.060921, loss_ce: 0.016989
[23:48:54.126] iteration 3366 : loss : 0.081594, loss_ce: 0.031453
[23:48:54.435] iteration 3367 : loss : 0.078318, loss_ce: 0.028583
[23:48:54.724] iteration 3368 : loss : 0.091114, loss_ce: 0.037562
[23:48:55.004] iteration 3369 : loss : 0.106152, loss_ce: 0.025601
[23:48:55.284] iteration 3370 : loss : 0.246515, loss_ce: 0.006408
[23:48:55.564] iteration 3371 : loss : 0.125337, loss_ce: 0.047800
[23:48:55.872] iteration 3372 : loss : 0.185332, loss_ce: 0.023519
[23:48:56.200] iteration 3373 : loss : 0.064525, loss_ce: 0.022236
[23:48:56.484] iteration 3374 : loss : 0.090028, loss_ce: 0.024821
[23:48:56.763] iteration 3375 : loss : 0.148470, loss_ce: 0.017611
[23:48:57.046] iteration 3376 : loss : 0.088582, loss_ce: 0.029143
[23:48:57.341] iteration 3377 : loss : 0.087986, loss_ce: 0.040591
[23:48:57.670] iteration 3378 : loss : 0.165999, loss_ce: 0.027549
[23:48:57.992] iteration 3379 : loss : 0.191393, loss_ce: 0.024330
[23:48:58.316] iteration 3380 : loss : 0.186338, loss_ce: 0.024904
[23:48:58.653] iteration 3381 : loss : 0.071372, loss_ce: 0.033500
[23:48:58.967] iteration 3382 : loss : 0.136678, loss_ce: 0.017638
[23:48:59.266] iteration 3383 : loss : 0.141430, loss_ce: 0.023771
[23:48:59.585] iteration 3384 : loss : 0.159720, loss_ce: 0.013420
[23:48:59.910] iteration 3385 : loss : 0.359125, loss_ce: 0.005394
[23:49:00.216] iteration 3386 : loss : 0.088279, loss_ce: 0.015315
[23:49:00.523] iteration 3387 : loss : 0.096975, loss_ce: 0.027403
[23:49:00.844] iteration 3388 : loss : 0.140455, loss_ce: 0.024208
[23:49:01.143] iteration 3389 : loss : 0.149934, loss_ce: 0.025564
[23:49:01.438] iteration 3390 : loss : 0.102862, loss_ce: 0.039203
[23:49:01.728] iteration 3391 : loss : 0.106087, loss_ce: 0.019916
[23:49:02.022] iteration 3392 : loss : 0.144547, loss_ce: 0.026963
[23:49:02.322] iteration 3393 : loss : 0.095457, loss_ce: 0.032718
[23:49:02.645] iteration 3394 : loss : 0.120012, loss_ce: 0.034370
[23:49:02.946] iteration 3395 : loss : 0.118580, loss_ce: 0.018993
[23:49:03.262] iteration 3396 : loss : 0.129262, loss_ce: 0.029806
[23:49:03.558] iteration 3397 : loss : 0.135960, loss_ce: 0.017786
[23:49:03.852] iteration 3398 : loss : 0.105630, loss_ce: 0.035888
[23:49:04.150] iteration 3399 : loss : 0.086017, loss_ce: 0.042698
[23:49:04.463] iteration 3400 : loss : 0.097177, loss_ce: 0.019365
[23:49:04.773] iteration 3401 : loss : 0.107943, loss_ce: 0.030926
[23:49:05.075] iteration 3402 : loss : 0.129395, loss_ce: 0.023456
[23:49:05.369] iteration 3403 : loss : 0.098255, loss_ce: 0.016050
[23:49:05.668] iteration 3404 : loss : 0.102316, loss_ce: 0.026451
[23:49:05.973] iteration 3405 : loss : 0.094137, loss_ce: 0.033984
[23:49:06.303] iteration 3406 : loss : 0.209006, loss_ce: 0.022097
[23:49:06.630] iteration 3407 : loss : 0.085435, loss_ce: 0.033895
[23:49:06.952] iteration 3408 : loss : 0.087833, loss_ce: 0.031967
[23:49:07.245] iteration 3409 : loss : 0.146613, loss_ce: 0.038854
[23:49:07.565] iteration 3410 : loss : 0.096320, loss_ce: 0.033974
[23:49:07.879] iteration 3411 : loss : 0.100203, loss_ce: 0.037112
[23:49:08.290] iteration 3412 : loss : 0.105575, loss_ce: 0.028248
[23:49:08.604] iteration 3413 : loss : 0.143038, loss_ce: 0.024631
[23:49:08.916] iteration 3414 : loss : 0.199835, loss_ce: 0.020352
[23:49:09.242] iteration 3415 : loss : 0.114057, loss_ce: 0.025065
[23:49:09.556] iteration 3416 : loss : 0.104032, loss_ce: 0.022697
[23:49:09.876] iteration 3417 : loss : 0.081990, loss_ce: 0.012167
[23:49:10.175] iteration 3418 : loss : 0.088437, loss_ce: 0.022566
[23:49:10.500] iteration 3419 : loss : 0.092567, loss_ce: 0.031727
[23:49:10.795] iteration 3420 : loss : 0.100442, loss_ce: 0.020363
[23:49:11.105] iteration 3421 : loss : 0.079811, loss_ce: 0.024320
[23:49:11.404] iteration 3422 : loss : 0.176968, loss_ce: 0.020338
[23:49:11.706] iteration 3423 : loss : 0.083660, loss_ce: 0.020798
[23:49:12.007] iteration 3424 : loss : 0.150227, loss_ce: 0.031579
[23:49:12.300] iteration 3425 : loss : 0.078839, loss_ce: 0.034758
[23:49:12.656] iteration 3426 : loss : 0.138822, loss_ce: 0.023580
[23:49:12.965] iteration 3427 : loss : 0.083318, loss_ce: 0.036978
[23:49:13.255] iteration 3428 : loss : 0.100382, loss_ce: 0.047419
[23:49:13.543] iteration 3429 : loss : 0.162746, loss_ce: 0.030921
[23:49:13.840] iteration 3430 : loss : 0.108541, loss_ce: 0.028738
[23:49:14.135] iteration 3431 : loss : 0.158425, loss_ce: 0.014719
[23:49:14.431] iteration 3432 : loss : 0.077767, loss_ce: 0.022708
[23:49:14.728] iteration 3433 : loss : 0.084844, loss_ce: 0.020348
[23:49:15.027] iteration 3434 : loss : 0.093497, loss_ce: 0.034012
[23:49:15.316] iteration 3435 : loss : 0.131104, loss_ce: 0.031593
[23:49:15.609] iteration 3436 : loss : 0.088218, loss_ce: 0.028135
[23:49:15.902] iteration 3437 : loss : 0.165283, loss_ce: 0.051039
[23:49:16.193] iteration 3438 : loss : 0.090721, loss_ce: 0.032425
[23:49:16.489] iteration 3439 : loss : 0.144254, loss_ce: 0.019726
[23:49:16.791] iteration 3440 : loss : 0.129362, loss_ce: 0.038843
[23:49:17.102] iteration 3441 : loss : 0.096835, loss_ce: 0.031287
[23:49:17.403] iteration 3442 : loss : 0.121565, loss_ce: 0.036421
[23:49:17.775] iteration 3443 : loss : 0.115299, loss_ce: 0.025194
[23:49:18.072] iteration 3444 : loss : 0.150899, loss_ce: 0.017487
[23:49:18.370] iteration 3445 : loss : 0.113948, loss_ce: 0.048601
[23:49:18.667] iteration 3446 : loss : 0.085964, loss_ce: 0.022857
[23:49:18.961] iteration 3447 : loss : 0.083521, loss_ce: 0.022466
[23:49:19.258] iteration 3448 : loss : 0.121453, loss_ce: 0.021382
[23:49:19.550] iteration 3449 : loss : 0.131437, loss_ce: 0.034917
[23:49:19.850] iteration 3450 : loss : 0.135708, loss_ce: 0.012683
[23:49:20.149] iteration 3451 : loss : 0.077327, loss_ce: 0.033244
[23:49:20.443] iteration 3452 : loss : 0.085432, loss_ce: 0.027320
[23:49:20.735] iteration 3453 : loss : 0.140683, loss_ce: 0.025930
[23:49:21.027] iteration 3454 : loss : 0.107783, loss_ce: 0.044387
[23:49:21.328] iteration 3455 : loss : 0.143747, loss_ce: 0.024975
[23:49:21.629] iteration 3456 : loss : 0.083401, loss_ce: 0.036940
[23:49:21.930] iteration 3457 : loss : 0.089148, loss_ce: 0.024780
[23:49:22.225] iteration 3458 : loss : 0.218476, loss_ce: 0.011744
[23:49:22.563] iteration 3459 : loss : 0.094509, loss_ce: 0.023948
[23:49:22.910] iteration 3460 : loss : 0.150719, loss_ce: 0.010222
[23:49:23.259] iteration 3461 : loss : 0.077731, loss_ce: 0.033989
[23:49:23.558] iteration 3462 : loss : 0.086486, loss_ce: 0.029910
[23:49:23.860] iteration 3463 : loss : 0.204412, loss_ce: 0.010399
[23:49:24.166] iteration 3464 : loss : 0.077994, loss_ce: 0.030133
[23:49:24.470] iteration 3465 : loss : 0.100985, loss_ce: 0.042390
[23:49:24.782] iteration 3466 : loss : 0.098237, loss_ce: 0.038946
[23:49:25.086] iteration 3467 : loss : 0.089830, loss_ce: 0.041606
[23:49:25.394] iteration 3468 : loss : 0.102032, loss_ce: 0.017054
[23:49:25.726] iteration 3469 : loss : 0.087391, loss_ce: 0.014783
[23:49:26.033] iteration 3470 : loss : 0.101545, loss_ce: 0.037577
[23:49:26.328] iteration 3471 : loss : 0.091627, loss_ce: 0.029366
[23:49:26.626] iteration 3472 : loss : 0.132903, loss_ce: 0.027612
[23:49:26.960] iteration 3473 : loss : 0.138333, loss_ce: 0.038295
[23:49:27.307] iteration 3474 : loss : 0.144708, loss_ce: 0.038830
[23:49:27.381] iteration 3475 : loss : 0.295425, loss_ce: 0.055990
[23:49:49.741] iteration 3476 : loss : 0.066471, loss_ce: 0.020034
[23:49:50.043] iteration 3477 : loss : 0.121917, loss_ce: 0.010281
[23:49:50.342] iteration 3478 : loss : 0.093651, loss_ce: 0.014588
[23:49:50.645] iteration 3479 : loss : 0.108687, loss_ce: 0.027190
[23:49:50.955] iteration 3480 : loss : 0.136165, loss_ce: 0.044407
[23:49:51.292] iteration 3481 : loss : 0.102004, loss_ce: 0.035400
[23:49:51.598] iteration 3482 : loss : 0.093707, loss_ce: 0.023745
[23:49:51.891] iteration 3483 : loss : 0.100827, loss_ce: 0.027431
[23:49:52.175] iteration 3484 : loss : 0.142534, loss_ce: 0.043965
[23:49:52.456] iteration 3485 : loss : 0.096674, loss_ce: 0.029446
[23:49:52.731] iteration 3486 : loss : 0.080280, loss_ce: 0.019893
[23:49:53.010] iteration 3487 : loss : 0.108119, loss_ce: 0.036031
[23:49:53.290] iteration 3488 : loss : 0.136996, loss_ce: 0.016068
[23:49:53.567] iteration 3489 : loss : 0.072201, loss_ce: 0.032202
[23:49:53.842] iteration 3490 : loss : 0.137090, loss_ce: 0.019645
[23:49:54.118] iteration 3491 : loss : 0.091622, loss_ce: 0.027243
[23:49:54.395] iteration 3492 : loss : 0.087347, loss_ce: 0.046438
[23:49:54.672] iteration 3493 : loss : 0.091695, loss_ce: 0.028338
[23:49:54.954] iteration 3494 : loss : 0.092323, loss_ce: 0.027811
[23:49:55.228] iteration 3495 : loss : 0.101673, loss_ce: 0.030355
[23:49:55.504] iteration 3496 : loss : 0.106127, loss_ce: 0.020518
[23:49:55.782] iteration 3497 : loss : 0.087247, loss_ce: 0.032820
[23:49:56.059] iteration 3498 : loss : 0.072910, loss_ce: 0.017332
[23:49:56.338] iteration 3499 : loss : 0.103670, loss_ce: 0.029110
[23:49:56.616] iteration 3500 : loss : 0.121455, loss_ce: 0.028834
[23:49:56.935] iteration 3501 : loss : 0.159150, loss_ce: 0.013933
[23:49:57.255] iteration 3502 : loss : 0.116862, loss_ce: 0.033813
[23:49:57.548] iteration 3503 : loss : 0.090060, loss_ce: 0.019801
[23:49:57.855] iteration 3504 : loss : 0.128715, loss_ce: 0.018932
[23:49:58.169] iteration 3505 : loss : 0.139844, loss_ce: 0.012468
[23:49:58.445] iteration 3506 : loss : 0.167460, loss_ce: 0.015740
[23:49:58.724] iteration 3507 : loss : 0.103484, loss_ce: 0.047398
[23:49:59.005] iteration 3508 : loss : 0.102781, loss_ce: 0.025420
[23:49:59.282] iteration 3509 : loss : 0.127268, loss_ce: 0.015068
[23:49:59.563] iteration 3510 : loss : 0.097504, loss_ce: 0.038791
[23:49:59.845] iteration 3511 : loss : 0.087125, loss_ce: 0.027358
[23:50:00.121] iteration 3512 : loss : 0.115545, loss_ce: 0.049918
[23:50:00.404] iteration 3513 : loss : 0.106072, loss_ce: 0.030035
[23:50:00.680] iteration 3514 : loss : 0.072348, loss_ce: 0.019937
[23:50:00.958] iteration 3515 : loss : 0.158545, loss_ce: 0.010913
[23:50:01.232] iteration 3516 : loss : 0.130198, loss_ce: 0.042510
[23:50:01.511] iteration 3517 : loss : 0.104115, loss_ce: 0.045308
[23:50:01.790] iteration 3518 : loss : 0.071216, loss_ce: 0.023253
[23:50:02.067] iteration 3519 : loss : 0.272597, loss_ce: 0.012043
[23:50:02.344] iteration 3520 : loss : 0.130038, loss_ce: 0.040733
[23:50:02.635] iteration 3521 : loss : 0.094669, loss_ce: 0.017270
[23:50:02.912] iteration 3522 : loss : 0.119484, loss_ce: 0.027147
[23:50:03.189] iteration 3523 : loss : 0.076231, loss_ce: 0.021021
[23:50:03.468] iteration 3524 : loss : 0.128720, loss_ce: 0.012890
[23:50:03.744] iteration 3525 : loss : 0.103954, loss_ce: 0.059842
[23:50:04.019] iteration 3526 : loss : 0.180691, loss_ce: 0.011119
[23:50:04.298] iteration 3527 : loss : 0.107135, loss_ce: 0.022249
[23:50:04.573] iteration 3528 : loss : 0.146129, loss_ce: 0.027369
[23:50:04.853] iteration 3529 : loss : 0.119161, loss_ce: 0.016707
[23:50:05.131] iteration 3530 : loss : 0.086871, loss_ce: 0.022647
[23:50:05.409] iteration 3531 : loss : 0.148021, loss_ce: 0.031291
[23:50:05.690] iteration 3532 : loss : 0.157607, loss_ce: 0.028268
[23:50:05.965] iteration 3533 : loss : 0.080333, loss_ce: 0.023204
[23:50:06.243] iteration 3534 : loss : 0.084288, loss_ce: 0.021700
[23:50:06.519] iteration 3535 : loss : 0.129934, loss_ce: 0.025079
[23:50:06.795] iteration 3536 : loss : 0.084057, loss_ce: 0.023091
[23:50:07.071] iteration 3537 : loss : 0.144888, loss_ce: 0.033192
[23:50:07.350] iteration 3538 : loss : 0.097493, loss_ce: 0.050577
[23:50:07.630] iteration 3539 : loss : 0.129108, loss_ce: 0.027481
[23:50:07.909] iteration 3540 : loss : 0.112376, loss_ce: 0.030413
[23:50:08.205] iteration 3541 : loss : 0.078038, loss_ce: 0.019406
[23:50:08.486] iteration 3542 : loss : 0.132343, loss_ce: 0.022911
[23:50:08.766] iteration 3543 : loss : 0.148506, loss_ce: 0.018077
[23:50:09.044] iteration 3544 : loss : 0.078490, loss_ce: 0.026780
[23:50:09.325] iteration 3545 : loss : 0.134137, loss_ce: 0.027346
[23:50:09.600] iteration 3546 : loss : 0.102158, loss_ce: 0.032916
[23:50:09.876] iteration 3547 : loss : 0.087526, loss_ce: 0.029072
[23:50:10.153] iteration 3548 : loss : 0.081082, loss_ce: 0.028805
[23:50:10.429] iteration 3549 : loss : 0.120455, loss_ce: 0.046498
[23:50:10.705] iteration 3550 : loss : 0.122058, loss_ce: 0.025704
[23:50:10.982] iteration 3551 : loss : 0.105879, loss_ce: 0.027814
[23:50:11.263] iteration 3552 : loss : 0.105013, loss_ce: 0.029614
[23:50:11.537] iteration 3553 : loss : 0.086783, loss_ce: 0.022345
[23:50:11.816] iteration 3554 : loss : 0.077557, loss_ce: 0.024297
[23:50:12.093] iteration 3555 : loss : 0.164522, loss_ce: 0.028313
[23:50:12.371] iteration 3556 : loss : 0.136713, loss_ce: 0.025702
[23:50:12.648] iteration 3557 : loss : 0.113685, loss_ce: 0.034497
[23:50:12.926] iteration 3558 : loss : 0.086437, loss_ce: 0.030238
[23:50:13.205] iteration 3559 : loss : 0.138745, loss_ce: 0.018760
[23:50:13.480] iteration 3560 : loss : 0.141456, loss_ce: 0.010124
[23:50:13.782] iteration 3561 : loss : 0.088253, loss_ce: 0.032448
[23:50:14.058] iteration 3562 : loss : 0.085299, loss_ce: 0.024148
[23:50:14.336] iteration 3563 : loss : 0.072045, loss_ce: 0.021977
[23:50:14.616] iteration 3564 : loss : 0.091582, loss_ce: 0.028713
[23:50:14.896] iteration 3565 : loss : 0.158667, loss_ce: 0.025453
[23:50:15.172] iteration 3566 : loss : 0.085648, loss_ce: 0.017616
[23:50:15.451] iteration 3567 : loss : 0.102505, loss_ce: 0.040050
[23:50:15.726] iteration 3568 : loss : 0.144774, loss_ce: 0.022342
[23:50:16.003] iteration 3569 : loss : 0.121482, loss_ce: 0.034023
[23:50:16.280] iteration 3570 : loss : 0.092570, loss_ce: 0.023973
[23:50:16.556] iteration 3571 : loss : 0.063178, loss_ce: 0.016592
[23:50:16.834] iteration 3572 : loss : 0.105060, loss_ce: 0.025197
[23:50:17.109] iteration 3573 : loss : 0.088623, loss_ce: 0.033864
[23:50:17.387] iteration 3574 : loss : 0.166417, loss_ce: 0.030170
[23:50:17.664] iteration 3575 : loss : 0.413742, loss_ce: 0.003081
[23:50:17.939] iteration 3576 : loss : 0.084874, loss_ce: 0.030675
[23:50:18.216] iteration 3577 : loss : 0.201661, loss_ce: 0.020570
[23:50:18.491] iteration 3578 : loss : 0.069778, loss_ce: 0.012892
[23:50:18.768] iteration 3579 : loss : 0.087692, loss_ce: 0.036024
[23:50:19.048] iteration 3580 : loss : 0.135488, loss_ce: 0.023356
[23:50:19.342] iteration 3581 : loss : 0.146953, loss_ce: 0.015566
[23:50:19.618] iteration 3582 : loss : 0.080578, loss_ce: 0.020176
[23:50:19.895] iteration 3583 : loss : 0.062735, loss_ce: 0.014456
[23:50:20.177] iteration 3584 : loss : 0.072656, loss_ce: 0.030815
[23:50:20.453] iteration 3585 : loss : 0.074919, loss_ce: 0.021942
[23:50:20.730] iteration 3586 : loss : 0.118721, loss_ce: 0.047170
[23:50:21.005] iteration 3587 : loss : 0.073268, loss_ce: 0.024176
[23:50:21.284] iteration 3588 : loss : 0.060288, loss_ce: 0.015361
[23:50:21.561] iteration 3589 : loss : 0.132746, loss_ce: 0.019408
[23:50:21.835] iteration 3590 : loss : 0.092767, loss_ce: 0.030189
[23:50:22.112] iteration 3591 : loss : 0.138477, loss_ce: 0.010838
[23:50:22.390] iteration 3592 : loss : 0.073031, loss_ce: 0.028358
[23:50:22.667] iteration 3593 : loss : 0.073805, loss_ce: 0.022470
[23:50:22.945] iteration 3594 : loss : 0.152272, loss_ce: 0.034783
[23:50:23.223] iteration 3595 : loss : 0.134442, loss_ce: 0.030997
[23:50:23.503] iteration 3596 : loss : 0.137198, loss_ce: 0.020854
[23:50:23.780] iteration 3597 : loss : 0.091779, loss_ce: 0.031300
[23:50:24.058] iteration 3598 : loss : 0.087838, loss_ce: 0.027119
[23:50:24.342] iteration 3599 : loss : 0.131497, loss_ce: 0.025522
[23:50:24.621] iteration 3600 : loss : 0.158623, loss_ce: 0.017066
[23:50:24.931] iteration 3601 : loss : 0.129241, loss_ce: 0.043401
[23:50:25.213] iteration 3602 : loss : 0.127808, loss_ce: 0.028775
[23:50:25.498] iteration 3603 : loss : 0.145770, loss_ce: 0.016515
[23:50:25.781] iteration 3604 : loss : 0.059237, loss_ce: 0.014959
[23:50:26.062] iteration 3605 : loss : 0.136696, loss_ce: 0.039705
[23:50:26.346] iteration 3606 : loss : 0.096273, loss_ce: 0.032732
[23:50:26.628] iteration 3607 : loss : 0.101584, loss_ce: 0.021815
[23:50:26.909] iteration 3608 : loss : 0.095432, loss_ce: 0.038686
[23:50:27.192] iteration 3609 : loss : 0.087940, loss_ce: 0.026642
[23:50:27.472] iteration 3610 : loss : 0.074269, loss_ce: 0.028701
[23:50:27.754] iteration 3611 : loss : 0.199713, loss_ce: 0.019101
[23:50:28.033] iteration 3612 : loss : 0.092290, loss_ce: 0.029798
[23:50:28.312] iteration 3613 : loss : 0.079630, loss_ce: 0.034973
[23:50:28.393] iteration 3614 : loss : 0.410060, loss_ce: 0.003991
[23:50:47.699] iteration 3615 : loss : 0.087331, loss_ce: 0.024060
[23:50:47.977] iteration 3616 : loss : 0.187295, loss_ce: 0.020530
[23:50:48.256] iteration 3617 : loss : 0.093871, loss_ce: 0.035363
[23:50:48.535] iteration 3618 : loss : 0.144074, loss_ce: 0.023398
[23:50:48.815] iteration 3619 : loss : 0.104250, loss_ce: 0.035207
[23:50:49.090] iteration 3620 : loss : 0.131589, loss_ce: 0.022499
[23:50:49.388] iteration 3621 : loss : 0.069926, loss_ce: 0.027706
[23:50:49.664] iteration 3622 : loss : 0.059378, loss_ce: 0.015696
[23:50:49.943] iteration 3623 : loss : 0.113215, loss_ce: 0.027869
[23:50:50.219] iteration 3624 : loss : 0.144965, loss_ce: 0.015620
[23:50:50.496] iteration 3625 : loss : 0.084742, loss_ce: 0.016686
[23:50:50.770] iteration 3626 : loss : 0.135581, loss_ce: 0.015435
[23:50:51.047] iteration 3627 : loss : 0.086204, loss_ce: 0.022440
[23:50:51.328] iteration 3628 : loss : 0.118938, loss_ce: 0.019502
[23:50:51.604] iteration 3629 : loss : 0.077526, loss_ce: 0.027542
[23:50:51.881] iteration 3630 : loss : 0.102510, loss_ce: 0.027343
[23:50:52.158] iteration 3631 : loss : 0.106473, loss_ce: 0.029429
[23:50:52.434] iteration 3632 : loss : 0.090927, loss_ce: 0.031880
[23:50:52.709] iteration 3633 : loss : 0.073479, loss_ce: 0.029015
[23:50:52.985] iteration 3634 : loss : 0.103040, loss_ce: 0.022100
[23:50:53.260] iteration 3635 : loss : 0.080799, loss_ce: 0.019834
[23:50:53.538] iteration 3636 : loss : 0.080332, loss_ce: 0.027192
[23:50:53.818] iteration 3637 : loss : 0.076814, loss_ce: 0.020694
[23:50:54.096] iteration 3638 : loss : 0.095369, loss_ce: 0.016117
[23:50:54.370] iteration 3639 : loss : 0.065793, loss_ce: 0.020324
[23:50:54.647] iteration 3640 : loss : 0.174562, loss_ce: 0.023003
[23:50:54.940] iteration 3641 : loss : 0.073642, loss_ce: 0.025493
[23:50:55.217] iteration 3642 : loss : 0.136477, loss_ce: 0.016992
[23:50:55.493] iteration 3643 : loss : 0.180171, loss_ce: 0.013571
[23:50:55.771] iteration 3644 : loss : 0.085257, loss_ce: 0.020868
[23:50:56.049] iteration 3645 : loss : 0.095979, loss_ce: 0.029579
[23:50:56.329] iteration 3646 : loss : 0.153937, loss_ce: 0.024406
[23:50:56.632] iteration 3647 : loss : 0.075757, loss_ce: 0.018044
[23:50:56.926] iteration 3648 : loss : 0.094998, loss_ce: 0.037313
[23:50:57.220] iteration 3649 : loss : 0.097864, loss_ce: 0.025874
[23:50:57.525] iteration 3650 : loss : 0.094816, loss_ce: 0.038465
[23:50:57.806] iteration 3651 : loss : 0.086127, loss_ce: 0.022522
[23:50:58.085] iteration 3652 : loss : 0.134344, loss_ce: 0.034165
[23:50:58.367] iteration 3653 : loss : 0.197165, loss_ce: 0.022611
[23:50:58.648] iteration 3654 : loss : 0.118974, loss_ce: 0.054031
[23:50:58.927] iteration 3655 : loss : 0.139161, loss_ce: 0.015229
[23:50:59.205] iteration 3656 : loss : 0.085029, loss_ce: 0.033292
[23:50:59.488] iteration 3657 : loss : 0.092049, loss_ce: 0.035246
[23:50:59.777] iteration 3658 : loss : 0.104731, loss_ce: 0.040338
[23:51:00.061] iteration 3659 : loss : 0.095455, loss_ce: 0.036574
[23:51:00.365] iteration 3660 : loss : 0.107589, loss_ce: 0.032183
[23:51:00.682] iteration 3661 : loss : 0.130501, loss_ce: 0.035995
[23:51:00.986] iteration 3662 : loss : 0.080129, loss_ce: 0.024323
[23:51:01.293] iteration 3663 : loss : 0.209405, loss_ce: 0.013132
[23:51:01.582] iteration 3664 : loss : 0.132496, loss_ce: 0.014518
[23:51:01.872] iteration 3665 : loss : 0.170353, loss_ce: 0.011681
[23:51:02.156] iteration 3666 : loss : 0.111690, loss_ce: 0.026939
[23:51:02.440] iteration 3667 : loss : 0.094595, loss_ce: 0.023382
[23:51:02.722] iteration 3668 : loss : 0.079773, loss_ce: 0.026954
[23:51:03.001] iteration 3669 : loss : 0.257894, loss_ce: 0.032851
[23:51:03.278] iteration 3670 : loss : 0.102893, loss_ce: 0.044339
[23:51:03.560] iteration 3671 : loss : 0.099445, loss_ce: 0.033057
[23:51:03.851] iteration 3672 : loss : 0.138912, loss_ce: 0.038711
[23:51:04.130] iteration 3673 : loss : 0.080736, loss_ce: 0.037210
[23:51:04.422] iteration 3674 : loss : 0.088608, loss_ce: 0.025213
[23:51:04.706] iteration 3675 : loss : 0.108642, loss_ce: 0.020321
[23:51:04.992] iteration 3676 : loss : 0.138385, loss_ce: 0.031744
[23:51:05.283] iteration 3677 : loss : 0.099305, loss_ce: 0.021889
[23:51:05.584] iteration 3678 : loss : 0.087167, loss_ce: 0.039228
[23:51:05.868] iteration 3679 : loss : 0.078055, loss_ce: 0.023968
[23:51:06.161] iteration 3680 : loss : 0.075096, loss_ce: 0.022635
[23:51:06.455] iteration 3681 : loss : 0.097105, loss_ce: 0.044727
[23:51:06.736] iteration 3682 : loss : 0.072480, loss_ce: 0.022638
[23:51:07.020] iteration 3683 : loss : 0.064944, loss_ce: 0.010596
[23:51:07.299] iteration 3684 : loss : 0.281638, loss_ce: 0.012950
[23:51:07.577] iteration 3685 : loss : 0.133554, loss_ce: 0.028973
[23:51:07.854] iteration 3686 : loss : 0.081831, loss_ce: 0.021729
[23:51:08.133] iteration 3687 : loss : 0.071984, loss_ce: 0.019438
[23:51:08.415] iteration 3688 : loss : 0.092617, loss_ce: 0.037846
[23:51:08.691] iteration 3689 : loss : 0.090133, loss_ce: 0.030027
[23:51:08.977] iteration 3690 : loss : 0.105698, loss_ce: 0.029107
[23:51:09.259] iteration 3691 : loss : 0.138036, loss_ce: 0.036138
[23:51:09.539] iteration 3692 : loss : 0.136650, loss_ce: 0.036222
[23:51:09.823] iteration 3693 : loss : 0.087524, loss_ce: 0.015542
[23:51:10.105] iteration 3694 : loss : 0.105210, loss_ce: 0.019197
[23:51:10.386] iteration 3695 : loss : 0.096746, loss_ce: 0.021191
[23:51:10.665] iteration 3696 : loss : 0.124785, loss_ce: 0.023973
[23:51:10.947] iteration 3697 : loss : 0.121227, loss_ce: 0.019631
[23:51:11.228] iteration 3698 : loss : 0.084290, loss_ce: 0.033583
[23:51:11.511] iteration 3699 : loss : 0.107356, loss_ce: 0.029543
[23:51:11.804] iteration 3700 : loss : 0.183955, loss_ce: 0.017693
[23:51:12.117] iteration 3701 : loss : 0.163127, loss_ce: 0.025777
[23:51:12.419] iteration 3702 : loss : 0.160550, loss_ce: 0.027799
[23:51:12.721] iteration 3703 : loss : 0.128682, loss_ce: 0.020605
[23:51:13.049] iteration 3704 : loss : 0.151839, loss_ce: 0.021890
[23:51:13.368] iteration 3705 : loss : 0.098689, loss_ce: 0.043243
[23:51:13.711] iteration 3706 : loss : 0.148807, loss_ce: 0.013619
[23:51:14.039] iteration 3707 : loss : 0.120111, loss_ce: 0.016525
[23:51:14.393] iteration 3708 : loss : 0.138715, loss_ce: 0.021378
[23:51:14.687] iteration 3709 : loss : 0.107603, loss_ce: 0.025994
[23:51:14.978] iteration 3710 : loss : 0.148142, loss_ce: 0.027055
[23:51:15.282] iteration 3711 : loss : 0.138821, loss_ce: 0.028753
[23:51:15.580] iteration 3712 : loss : 0.297296, loss_ce: 0.009926
[23:51:15.888] iteration 3713 : loss : 0.075915, loss_ce: 0.031471
[23:51:16.193] iteration 3714 : loss : 0.082476, loss_ce: 0.027407
[23:51:16.524] iteration 3715 : loss : 0.134898, loss_ce: 0.031480
[23:51:16.819] iteration 3716 : loss : 0.090411, loss_ce: 0.039669
[23:51:17.103] iteration 3717 : loss : 0.154711, loss_ce: 0.040301
[23:51:17.395] iteration 3718 : loss : 0.282604, loss_ce: 0.006075
[23:51:17.724] iteration 3719 : loss : 0.098020, loss_ce: 0.028093
[23:51:18.061] iteration 3720 : loss : 0.127009, loss_ce: 0.019423
[23:51:18.368] iteration 3721 : loss : 0.100276, loss_ce: 0.036338
[23:51:18.670] iteration 3722 : loss : 0.113016, loss_ce: 0.023256
[23:51:18.999] iteration 3723 : loss : 0.125462, loss_ce: 0.026580
[23:51:19.293] iteration 3724 : loss : 0.146978, loss_ce: 0.017440
[23:51:19.573] iteration 3725 : loss : 0.191891, loss_ce: 0.010060
[23:51:19.850] iteration 3726 : loss : 0.140949, loss_ce: 0.022765
[23:51:20.153] iteration 3727 : loss : 0.102121, loss_ce: 0.036380
[23:51:20.436] iteration 3728 : loss : 0.098809, loss_ce: 0.035039
[23:51:20.732] iteration 3729 : loss : 0.083772, loss_ce: 0.036569
[23:51:21.029] iteration 3730 : loss : 0.121871, loss_ce: 0.007018
[23:51:21.364] iteration 3731 : loss : 0.155738, loss_ce: 0.024533
[23:51:21.661] iteration 3732 : loss : 0.085152, loss_ce: 0.014180
[23:51:21.939] iteration 3733 : loss : 0.103603, loss_ce: 0.047555
[23:51:22.217] iteration 3734 : loss : 0.174166, loss_ce: 0.014013
[23:51:22.506] iteration 3735 : loss : 0.129788, loss_ce: 0.023820
[23:51:22.815] iteration 3736 : loss : 0.093065, loss_ce: 0.041030
[23:51:23.151] iteration 3737 : loss : 0.092931, loss_ce: 0.024458
[23:51:23.448] iteration 3738 : loss : 0.137624, loss_ce: 0.021671
[23:51:23.772] iteration 3739 : loss : 0.080211, loss_ce: 0.023758
[23:51:24.065] iteration 3740 : loss : 0.088079, loss_ce: 0.021015
[23:51:24.401] iteration 3741 : loss : 0.112728, loss_ce: 0.053809
[23:51:24.709] iteration 3742 : loss : 0.088785, loss_ce: 0.017693
[23:51:24.989] iteration 3743 : loss : 0.099149, loss_ce: 0.050220
[23:51:25.276] iteration 3744 : loss : 0.110589, loss_ce: 0.043867
[23:51:25.557] iteration 3745 : loss : 0.114080, loss_ce: 0.017097
[23:51:25.843] iteration 3746 : loss : 0.084981, loss_ce: 0.025623
[23:51:26.128] iteration 3747 : loss : 0.092848, loss_ce: 0.038240
[23:51:26.406] iteration 3748 : loss : 0.130311, loss_ce: 0.035859
[23:51:26.690] iteration 3749 : loss : 0.073432, loss_ce: 0.029198
[23:51:26.970] iteration 3750 : loss : 0.202637, loss_ce: 0.022078
[23:51:27.247] iteration 3751 : loss : 0.085966, loss_ce: 0.027937
[23:51:27.535] iteration 3752 : loss : 0.128464, loss_ce: 0.021842
[23:51:27.609] iteration 3753 : loss : 0.297136, loss_ce: 0.018729
[23:51:47.222] iteration 3754 : loss : 0.094172, loss_ce: 0.040673
[23:51:47.549] iteration 3755 : loss : 0.213865, loss_ce: 0.028371
[23:51:47.849] iteration 3756 : loss : 0.144335, loss_ce: 0.036505
[23:51:48.160] iteration 3757 : loss : 0.160990, loss_ce: 0.041224
[23:51:48.478] iteration 3758 : loss : 0.183699, loss_ce: 0.023802
[23:51:48.763] iteration 3759 : loss : 0.106250, loss_ce: 0.024673
[23:51:49.070] iteration 3760 : loss : 0.082603, loss_ce: 0.025562
[23:51:49.402] iteration 3761 : loss : 0.081585, loss_ce: 0.030598
[23:51:49.689] iteration 3762 : loss : 0.083218, loss_ce: 0.033791
[23:51:49.997] iteration 3763 : loss : 0.081170, loss_ce: 0.020962
[23:51:50.306] iteration 3764 : loss : 0.106057, loss_ce: 0.038114
[23:51:50.600] iteration 3765 : loss : 0.086263, loss_ce: 0.034635
[23:51:50.903] iteration 3766 : loss : 0.085694, loss_ce: 0.018977
[23:51:51.181] iteration 3767 : loss : 0.107658, loss_ce: 0.039601
[23:51:51.460] iteration 3768 : loss : 0.137195, loss_ce: 0.013168
[23:51:51.737] iteration 3769 : loss : 0.069093, loss_ce: 0.016854
[23:51:52.013] iteration 3770 : loss : 0.081437, loss_ce: 0.025459
[23:51:52.289] iteration 3771 : loss : 0.078003, loss_ce: 0.026977
[23:51:52.567] iteration 3772 : loss : 0.132198, loss_ce: 0.038275
[23:51:52.844] iteration 3773 : loss : 0.140373, loss_ce: 0.021983
[23:51:53.119] iteration 3774 : loss : 0.090540, loss_ce: 0.039942
[23:51:53.396] iteration 3775 : loss : 0.125387, loss_ce: 0.011751
[23:51:53.684] iteration 3776 : loss : 0.140525, loss_ce: 0.024407
[23:51:53.965] iteration 3777 : loss : 0.166355, loss_ce: 0.036939
[23:51:54.247] iteration 3778 : loss : 0.091564, loss_ce: 0.037137
[23:51:54.554] iteration 3779 : loss : 0.072244, loss_ce: 0.017309
[23:51:54.842] iteration 3780 : loss : 0.086032, loss_ce: 0.036916
[23:51:55.185] iteration 3781 : loss : 0.085112, loss_ce: 0.030208
[23:51:55.494] iteration 3782 : loss : 0.090767, loss_ce: 0.024362
[23:51:55.782] iteration 3783 : loss : 0.083170, loss_ce: 0.031267
[23:51:56.095] iteration 3784 : loss : 0.104970, loss_ce: 0.017116
[23:51:56.396] iteration 3785 : loss : 0.078921, loss_ce: 0.022807
[23:51:56.704] iteration 3786 : loss : 0.087360, loss_ce: 0.034702
[23:51:56.986] iteration 3787 : loss : 0.234704, loss_ce: 0.017163
[23:51:57.267] iteration 3788 : loss : 0.157805, loss_ce: 0.020672
[23:51:57.545] iteration 3789 : loss : 0.174050, loss_ce: 0.015452
[23:51:57.821] iteration 3790 : loss : 0.083611, loss_ce: 0.022013
[23:51:58.096] iteration 3791 : loss : 0.074039, loss_ce: 0.023692
[23:51:58.374] iteration 3792 : loss : 0.083832, loss_ce: 0.032679
[23:51:58.676] iteration 3793 : loss : 0.072788, loss_ce: 0.014026
[23:51:58.981] iteration 3794 : loss : 0.109671, loss_ce: 0.036417
[23:51:59.261] iteration 3795 : loss : 0.086982, loss_ce: 0.027170
[23:51:59.565] iteration 3796 : loss : 0.080652, loss_ce: 0.022339
[23:51:59.887] iteration 3797 : loss : 0.088978, loss_ce: 0.024071
[23:52:00.170] iteration 3798 : loss : 0.093691, loss_ce: 0.027709
[23:52:00.455] iteration 3799 : loss : 0.136158, loss_ce: 0.014851
[23:52:00.731] iteration 3800 : loss : 0.103610, loss_ce: 0.012989
[23:52:01.054] iteration 3801 : loss : 0.108429, loss_ce: 0.040778
[23:52:01.377] iteration 3802 : loss : 0.132554, loss_ce: 0.012395
[23:52:01.684] iteration 3803 : loss : 0.096501, loss_ce: 0.025646
[23:52:01.962] iteration 3804 : loss : 0.078711, loss_ce: 0.021873
[23:52:02.238] iteration 3805 : loss : 0.115369, loss_ce: 0.020873
[23:52:02.513] iteration 3806 : loss : 0.119879, loss_ce: 0.013264
[23:52:02.790] iteration 3807 : loss : 0.075106, loss_ce: 0.027996
[23:52:03.065] iteration 3808 : loss : 0.070127, loss_ce: 0.033995
[23:52:03.343] iteration 3809 : loss : 0.137887, loss_ce: 0.022064
[23:52:03.617] iteration 3810 : loss : 0.113155, loss_ce: 0.046217
[23:52:03.893] iteration 3811 : loss : 0.095327, loss_ce: 0.046614
[23:52:04.171] iteration 3812 : loss : 0.108674, loss_ce: 0.031858
[23:52:04.455] iteration 3813 : loss : 0.141552, loss_ce: 0.019879
[23:52:04.774] iteration 3814 : loss : 0.090330, loss_ce: 0.018738
[23:52:05.073] iteration 3815 : loss : 0.075248, loss_ce: 0.019637
[23:52:05.377] iteration 3816 : loss : 0.110415, loss_ce: 0.011314
[23:52:05.692] iteration 3817 : loss : 0.060329, loss_ce: 0.025257
[23:52:06.007] iteration 3818 : loss : 0.059310, loss_ce: 0.011378
[23:52:06.284] iteration 3819 : loss : 0.146716, loss_ce: 0.020684
[23:52:06.560] iteration 3820 : loss : 0.165189, loss_ce: 0.015940
[23:52:06.873] iteration 3821 : loss : 0.077277, loss_ce: 0.035587
[23:52:07.192] iteration 3822 : loss : 0.071033, loss_ce: 0.017229
[23:52:07.498] iteration 3823 : loss : 0.102523, loss_ce: 0.021150
[23:52:07.801] iteration 3824 : loss : 0.097097, loss_ce: 0.032163
[23:52:08.099] iteration 3825 : loss : 0.108903, loss_ce: 0.017526
[23:52:08.404] iteration 3826 : loss : 0.169852, loss_ce: 0.024153
[23:52:08.725] iteration 3827 : loss : 0.098713, loss_ce: 0.027600
[23:52:09.032] iteration 3828 : loss : 0.076022, loss_ce: 0.023875
[23:52:09.321] iteration 3829 : loss : 0.108130, loss_ce: 0.039504
[23:52:09.638] iteration 3830 : loss : 0.083155, loss_ce: 0.030619
[23:52:09.959] iteration 3831 : loss : 0.130365, loss_ce: 0.013135
[23:52:10.280] iteration 3832 : loss : 0.137241, loss_ce: 0.027595
[23:52:10.566] iteration 3833 : loss : 0.131229, loss_ce: 0.019979
[23:52:10.851] iteration 3834 : loss : 0.092842, loss_ce: 0.030610
[23:52:11.161] iteration 3835 : loss : 0.132816, loss_ce: 0.026544
[23:52:11.438] iteration 3836 : loss : 0.095662, loss_ce: 0.032225
[23:52:11.713] iteration 3837 : loss : 0.092304, loss_ce: 0.019879
[23:52:11.990] iteration 3838 : loss : 0.147567, loss_ce: 0.024019
[23:52:12.265] iteration 3839 : loss : 0.120316, loss_ce: 0.022129
[23:52:12.541] iteration 3840 : loss : 0.076491, loss_ce: 0.022598
[23:52:12.833] iteration 3841 : loss : 0.123015, loss_ce: 0.034101
[23:52:13.109] iteration 3842 : loss : 0.076439, loss_ce: 0.034214
[23:52:13.385] iteration 3843 : loss : 0.127043, loss_ce: 0.025374
[23:52:13.662] iteration 3844 : loss : 0.096799, loss_ce: 0.045262
[23:52:13.938] iteration 3845 : loss : 0.074893, loss_ce: 0.016820
[23:52:14.214] iteration 3846 : loss : 0.113248, loss_ce: 0.026132
[23:52:14.490] iteration 3847 : loss : 0.080110, loss_ce: 0.025657
[23:52:14.794] iteration 3848 : loss : 0.077990, loss_ce: 0.020344
[23:52:15.100] iteration 3849 : loss : 0.087306, loss_ce: 0.025480
[23:52:15.403] iteration 3850 : loss : 0.079713, loss_ce: 0.028511
[23:52:15.681] iteration 3851 : loss : 0.117458, loss_ce: 0.007759
[23:52:15.958] iteration 3852 : loss : 0.077801, loss_ce: 0.023232
[23:52:16.235] iteration 3853 : loss : 0.093778, loss_ce: 0.029000
[23:52:16.512] iteration 3854 : loss : 0.068890, loss_ce: 0.028603
[23:52:16.812] iteration 3855 : loss : 0.225898, loss_ce: 0.005542
[23:52:17.119] iteration 3856 : loss : 0.124156, loss_ce: 0.019413
[23:52:17.395] iteration 3857 : loss : 0.136271, loss_ce: 0.026437
[23:52:17.696] iteration 3858 : loss : 0.083816, loss_ce: 0.030702
[23:52:17.985] iteration 3859 : loss : 0.094433, loss_ce: 0.017682
[23:52:18.261] iteration 3860 : loss : 0.134493, loss_ce: 0.024727
[23:52:18.594] iteration 3861 : loss : 0.115821, loss_ce: 0.038494
[23:52:18.869] iteration 3862 : loss : 0.074918, loss_ce: 0.025993
[23:52:19.149] iteration 3863 : loss : 0.083998, loss_ce: 0.032599
[23:52:19.424] iteration 3864 : loss : 0.071292, loss_ce: 0.015499
[23:52:19.704] iteration 3865 : loss : 0.109127, loss_ce: 0.024389
[23:52:19.983] iteration 3866 : loss : 0.097220, loss_ce: 0.019095
[23:52:20.264] iteration 3867 : loss : 0.091794, loss_ce: 0.022771
[23:52:20.542] iteration 3868 : loss : 0.074438, loss_ce: 0.020287
[23:52:20.847] iteration 3869 : loss : 0.138800, loss_ce: 0.006846
[23:52:21.149] iteration 3870 : loss : 0.082994, loss_ce: 0.028403
[23:52:21.454] iteration 3871 : loss : 0.078996, loss_ce: 0.024436
[23:52:21.780] iteration 3872 : loss : 0.090297, loss_ce: 0.018185
[23:52:22.086] iteration 3873 : loss : 0.075693, loss_ce: 0.028902
[23:52:22.381] iteration 3874 : loss : 0.095312, loss_ce: 0.023829
[23:52:22.711] iteration 3875 : loss : 0.150483, loss_ce: 0.026796
[23:52:23.044] iteration 3876 : loss : 0.130465, loss_ce: 0.036224
[23:52:23.331] iteration 3877 : loss : 0.137966, loss_ce: 0.029229
[23:52:23.654] iteration 3878 : loss : 0.115864, loss_ce: 0.043419
[23:52:23.997] iteration 3879 : loss : 0.071270, loss_ce: 0.025151
[23:52:24.302] iteration 3880 : loss : 0.149568, loss_ce: 0.027631
[23:52:24.638] iteration 3881 : loss : 0.072459, loss_ce: 0.017641
[23:52:24.947] iteration 3882 : loss : 0.117272, loss_ce: 0.021475
[23:52:25.228] iteration 3883 : loss : 0.116759, loss_ce: 0.023818
[23:52:25.517] iteration 3884 : loss : 0.086074, loss_ce: 0.026025
[23:52:25.800] iteration 3885 : loss : 0.087953, loss_ce: 0.034740
[23:52:26.082] iteration 3886 : loss : 0.088220, loss_ce: 0.032629
[23:52:26.382] iteration 3887 : loss : 0.096385, loss_ce: 0.020178
[23:52:26.674] iteration 3888 : loss : 0.088058, loss_ce: 0.021329
[23:52:26.965] iteration 3889 : loss : 0.108518, loss_ce: 0.025408
[23:52:27.251] iteration 3890 : loss : 0.078323, loss_ce: 0.035016
[23:52:27.533] iteration 3891 : loss : 0.110211, loss_ce: 0.018091
[23:52:27.608] iteration 3892 : loss : 0.308673, loss_ce: 0.022195
[23:52:45.603] iteration 3893 : loss : 0.076047, loss_ce: 0.023446
[23:52:45.882] iteration 3894 : loss : 0.099670, loss_ce: 0.028071
[23:52:46.161] iteration 3895 : loss : 0.147539, loss_ce: 0.017844
[23:52:46.442] iteration 3896 : loss : 0.075524, loss_ce: 0.029626
[23:52:46.718] iteration 3897 : loss : 0.107475, loss_ce: 0.029444
[23:52:46.994] iteration 3898 : loss : 0.087675, loss_ce: 0.025895
[23:52:47.268] iteration 3899 : loss : 0.070410, loss_ce: 0.027887
[23:52:47.543] iteration 3900 : loss : 0.091847, loss_ce: 0.024139
[23:52:47.834] iteration 3901 : loss : 0.087744, loss_ce: 0.026577
[23:52:48.109] iteration 3902 : loss : 0.087650, loss_ce: 0.021878
[23:52:48.382] iteration 3903 : loss : 0.096108, loss_ce: 0.023290
[23:52:48.660] iteration 3904 : loss : 0.068335, loss_ce: 0.019045
[23:52:48.932] iteration 3905 : loss : 0.067981, loss_ce: 0.022207
[23:52:49.211] iteration 3906 : loss : 0.154299, loss_ce: 0.035761
[23:52:49.487] iteration 3907 : loss : 0.084606, loss_ce: 0.023750
[23:52:49.763] iteration 3908 : loss : 0.097085, loss_ce: 0.032144
[23:52:50.040] iteration 3909 : loss : 0.074703, loss_ce: 0.023213
[23:52:50.319] iteration 3910 : loss : 0.113897, loss_ce: 0.031049
[23:52:50.596] iteration 3911 : loss : 0.088982, loss_ce: 0.038266
[23:52:50.873] iteration 3912 : loss : 0.074494, loss_ce: 0.014889
[23:52:51.148] iteration 3913 : loss : 0.077533, loss_ce: 0.019032
[23:52:51.425] iteration 3914 : loss : 0.089960, loss_ce: 0.027786
[23:52:51.700] iteration 3915 : loss : 0.145311, loss_ce: 0.015738
[23:52:51.993] iteration 3916 : loss : 0.064600, loss_ce: 0.021319
[23:52:52.283] iteration 3917 : loss : 0.073093, loss_ce: 0.024407
[23:52:52.580] iteration 3918 : loss : 0.082295, loss_ce: 0.030134
[23:52:52.876] iteration 3919 : loss : 0.068110, loss_ce: 0.018989
[23:52:53.155] iteration 3920 : loss : 0.061174, loss_ce: 0.027466
[23:52:53.454] iteration 3921 : loss : 0.097411, loss_ce: 0.025464
[23:52:53.733] iteration 3922 : loss : 0.067387, loss_ce: 0.021598
[23:52:54.011] iteration 3923 : loss : 0.143487, loss_ce: 0.014370
[23:52:54.292] iteration 3924 : loss : 0.142551, loss_ce: 0.015638
[23:52:54.577] iteration 3925 : loss : 0.075852, loss_ce: 0.026127
[23:52:54.854] iteration 3926 : loss : 0.130118, loss_ce: 0.017608
[23:52:55.132] iteration 3927 : loss : 0.069176, loss_ce: 0.022494
[23:52:55.412] iteration 3928 : loss : 0.168496, loss_ce: 0.021496
[23:52:55.688] iteration 3929 : loss : 0.126225, loss_ce: 0.020561
[23:52:55.967] iteration 3930 : loss : 0.128020, loss_ce: 0.017475
[23:52:56.245] iteration 3931 : loss : 0.146847, loss_ce: 0.016243
[23:52:56.524] iteration 3932 : loss : 0.100131, loss_ce: 0.014572
[23:52:56.804] iteration 3933 : loss : 0.130638, loss_ce: 0.027304
[23:52:57.085] iteration 3934 : loss : 0.076492, loss_ce: 0.020007
[23:52:57.364] iteration 3935 : loss : 0.123226, loss_ce: 0.015120
[23:52:57.642] iteration 3936 : loss : 0.079587, loss_ce: 0.017136
[23:52:57.921] iteration 3937 : loss : 0.139526, loss_ce: 0.020383
[23:52:58.198] iteration 3938 : loss : 0.136111, loss_ce: 0.016959
[23:52:58.473] iteration 3939 : loss : 0.082995, loss_ce: 0.029231
[23:52:58.753] iteration 3940 : loss : 0.099659, loss_ce: 0.030663
[23:52:59.053] iteration 3941 : loss : 0.067007, loss_ce: 0.018705
[23:52:59.329] iteration 3942 : loss : 0.137507, loss_ce: 0.033661
[23:52:59.609] iteration 3943 : loss : 0.164917, loss_ce: 0.024333
[23:52:59.890] iteration 3944 : loss : 0.078947, loss_ce: 0.027601
[23:53:00.169] iteration 3945 : loss : 0.096279, loss_ce: 0.030216
[23:53:00.453] iteration 3946 : loss : 0.090677, loss_ce: 0.041400
[23:53:00.730] iteration 3947 : loss : 0.071176, loss_ce: 0.023747
[23:53:01.015] iteration 3948 : loss : 0.078069, loss_ce: 0.022177
[23:53:01.295] iteration 3949 : loss : 0.190894, loss_ce: 0.018726
[23:53:01.574] iteration 3950 : loss : 0.070407, loss_ce: 0.021500
[23:53:01.854] iteration 3951 : loss : 0.077371, loss_ce: 0.018251
[23:53:02.136] iteration 3952 : loss : 0.078538, loss_ce: 0.014140
[23:53:02.414] iteration 3953 : loss : 0.081123, loss_ce: 0.027402
[23:53:02.695] iteration 3954 : loss : 0.064820, loss_ce: 0.011628
[23:53:02.975] iteration 3955 : loss : 0.203663, loss_ce: 0.015054
[23:53:03.292] iteration 3956 : loss : 0.071890, loss_ce: 0.020747
[23:53:03.602] iteration 3957 : loss : 0.064277, loss_ce: 0.019475
[23:53:03.960] iteration 3958 : loss : 0.115486, loss_ce: 0.024533
[23:53:04.278] iteration 3959 : loss : 0.083671, loss_ce: 0.013249
[23:53:04.554] iteration 3960 : loss : 0.131110, loss_ce: 0.016969
[23:53:04.889] iteration 3961 : loss : 0.079342, loss_ce: 0.012303
[23:53:05.200] iteration 3962 : loss : 0.098968, loss_ce: 0.022337
[23:53:05.481] iteration 3963 : loss : 0.071432, loss_ce: 0.026226
[23:53:05.764] iteration 3964 : loss : 0.084656, loss_ce: 0.020660
[23:53:06.058] iteration 3965 : loss : 0.168011, loss_ce: 0.032710
[23:53:06.367] iteration 3966 : loss : 0.094607, loss_ce: 0.036817
[23:53:06.685] iteration 3967 : loss : 0.078047, loss_ce: 0.032182
[23:53:07.006] iteration 3968 : loss : 0.084733, loss_ce: 0.026744
[23:53:07.321] iteration 3969 : loss : 0.129948, loss_ce: 0.016759
[23:53:07.602] iteration 3970 : loss : 0.102428, loss_ce: 0.027415
[23:53:07.939] iteration 3971 : loss : 0.090462, loss_ce: 0.042963
[23:53:08.258] iteration 3972 : loss : 0.113600, loss_ce: 0.033652
[23:53:08.533] iteration 3973 : loss : 0.079759, loss_ce: 0.022301
[23:53:08.812] iteration 3974 : loss : 0.090673, loss_ce: 0.028874
[23:53:09.128] iteration 3975 : loss : 0.081949, loss_ce: 0.016846
[23:53:09.447] iteration 3976 : loss : 0.064485, loss_ce: 0.011673
[23:53:09.743] iteration 3977 : loss : 0.098604, loss_ce: 0.018129
[23:53:10.065] iteration 3978 : loss : 0.073788, loss_ce: 0.019128
[23:53:10.363] iteration 3979 : loss : 0.084410, loss_ce: 0.022698
[23:53:10.659] iteration 3980 : loss : 0.106147, loss_ce: 0.032988
[23:53:10.956] iteration 3981 : loss : 0.088385, loss_ce: 0.029155
[23:53:11.249] iteration 3982 : loss : 0.208395, loss_ce: 0.011759
[23:53:11.526] iteration 3983 : loss : 0.141588, loss_ce: 0.011881
[23:53:11.820] iteration 3984 : loss : 0.156362, loss_ce: 0.023441
[23:53:12.115] iteration 3985 : loss : 0.117055, loss_ce: 0.047992
[23:53:12.414] iteration 3986 : loss : 0.075315, loss_ce: 0.029393
[23:53:12.718] iteration 3987 : loss : 0.080003, loss_ce: 0.032476
[23:53:13.017] iteration 3988 : loss : 0.145443, loss_ce: 0.027079
[23:53:13.295] iteration 3989 : loss : 0.097744, loss_ce: 0.024869
[23:53:13.609] iteration 3990 : loss : 0.085383, loss_ce: 0.017944
[23:53:13.887] iteration 3991 : loss : 0.147992, loss_ce: 0.025430
[23:53:14.166] iteration 3992 : loss : 0.078624, loss_ce: 0.020023
[23:53:14.449] iteration 3993 : loss : 0.117996, loss_ce: 0.034646
[23:53:14.730] iteration 3994 : loss : 0.113279, loss_ce: 0.044092
[23:53:15.008] iteration 3995 : loss : 0.105336, loss_ce: 0.027526
[23:53:15.288] iteration 3996 : loss : 0.092236, loss_ce: 0.029980
[23:53:15.566] iteration 3997 : loss : 0.070052, loss_ce: 0.025146
[23:53:15.852] iteration 3998 : loss : 0.105049, loss_ce: 0.043176
[23:53:16.135] iteration 3999 : loss : 0.172879, loss_ce: 0.016516
[23:53:16.417] iteration 4000 : loss : 0.098662, loss_ce: 0.036324
[23:53:16.723] iteration 4001 : loss : 0.162423, loss_ce: 0.046596
[23:53:17.021] iteration 4002 : loss : 0.149996, loss_ce: 0.008778
[23:53:17.314] iteration 4003 : loss : 0.125149, loss_ce: 0.033104
[23:53:17.593] iteration 4004 : loss : 0.136874, loss_ce: 0.017626
[23:53:17.874] iteration 4005 : loss : 0.111653, loss_ce: 0.035633
[23:53:18.154] iteration 4006 : loss : 0.081713, loss_ce: 0.020673
[23:53:18.447] iteration 4007 : loss : 0.125247, loss_ce: 0.036258
[23:53:18.735] iteration 4008 : loss : 0.091513, loss_ce: 0.026391
[23:53:19.050] iteration 4009 : loss : 0.101244, loss_ce: 0.037367
[23:53:19.349] iteration 4010 : loss : 0.129342, loss_ce: 0.030681
[23:53:19.629] iteration 4011 : loss : 0.198902, loss_ce: 0.011586
[23:53:19.906] iteration 4012 : loss : 0.092883, loss_ce: 0.018627
[23:53:20.186] iteration 4013 : loss : 0.080183, loss_ce: 0.039534
[23:53:20.466] iteration 4014 : loss : 0.085730, loss_ce: 0.043050
[23:53:20.748] iteration 4015 : loss : 0.154743, loss_ce: 0.026600
[23:53:21.032] iteration 4016 : loss : 0.081335, loss_ce: 0.032512
[23:53:21.314] iteration 4017 : loss : 0.152048, loss_ce: 0.014610
[23:53:21.611] iteration 4018 : loss : 0.078640, loss_ce: 0.023367
[23:53:21.907] iteration 4019 : loss : 0.088102, loss_ce: 0.028923
[23:53:22.191] iteration 4020 : loss : 0.061157, loss_ce: 0.015222
[23:53:22.510] iteration 4021 : loss : 0.077611, loss_ce: 0.015538
[23:53:22.790] iteration 4022 : loss : 0.143124, loss_ce: 0.023096
[23:53:23.078] iteration 4023 : loss : 0.086951, loss_ce: 0.018411
[23:53:23.382] iteration 4024 : loss : 0.095164, loss_ce: 0.028561
[23:53:23.687] iteration 4025 : loss : 0.090799, loss_ce: 0.030694
[23:53:23.989] iteration 4026 : loss : 0.075821, loss_ce: 0.025682
[23:53:24.289] iteration 4027 : loss : 0.090899, loss_ce: 0.027477
[23:53:24.588] iteration 4028 : loss : 0.120816, loss_ce: 0.012944
[23:53:24.868] iteration 4029 : loss : 0.146515, loss_ce: 0.016362
[23:53:25.174] iteration 4030 : loss : 0.090390, loss_ce: 0.025630
[23:53:25.258] iteration 4031 : loss : 0.505271, loss_ce: 0.005446
[23:53:45.324] iteration 4032 : loss : 0.148574, loss_ce: 0.019881
[23:53:45.604] iteration 4033 : loss : 0.098744, loss_ce: 0.035313
[23:53:45.883] iteration 4034 : loss : 0.123193, loss_ce: 0.035720
[23:53:46.162] iteration 4035 : loss : 0.143885, loss_ce: 0.028286
[23:53:46.440] iteration 4036 : loss : 0.082326, loss_ce: 0.024539
[23:53:46.716] iteration 4037 : loss : 0.079598, loss_ce: 0.027873
[23:53:46.995] iteration 4038 : loss : 0.111916, loss_ce: 0.023394
[23:53:47.272] iteration 4039 : loss : 0.118259, loss_ce: 0.028004
[23:53:47.548] iteration 4040 : loss : 0.076011, loss_ce: 0.018448
[23:53:47.846] iteration 4041 : loss : 0.178413, loss_ce: 0.023517
[23:53:48.124] iteration 4042 : loss : 0.126222, loss_ce: 0.012140
[23:53:48.398] iteration 4043 : loss : 0.088172, loss_ce: 0.035357
[23:53:48.715] iteration 4044 : loss : 0.096338, loss_ce: 0.027827
[23:53:49.017] iteration 4045 : loss : 0.078208, loss_ce: 0.017836
[23:53:49.321] iteration 4046 : loss : 0.086502, loss_ce: 0.022250
[23:53:49.610] iteration 4047 : loss : 0.080332, loss_ce: 0.042091
[23:53:49.926] iteration 4048 : loss : 0.144929, loss_ce: 0.034140
[23:53:50.239] iteration 4049 : loss : 0.141125, loss_ce: 0.022810
[23:53:50.532] iteration 4050 : loss : 0.109467, loss_ce: 0.026991
[23:53:50.813] iteration 4051 : loss : 0.089880, loss_ce: 0.024807
[23:53:51.102] iteration 4052 : loss : 0.078975, loss_ce: 0.029111
[23:53:51.385] iteration 4053 : loss : 0.084173, loss_ce: 0.009705
[23:53:51.665] iteration 4054 : loss : 0.079694, loss_ce: 0.020549
[23:53:51.944] iteration 4055 : loss : 0.085681, loss_ce: 0.021442
[23:53:52.224] iteration 4056 : loss : 0.122691, loss_ce: 0.021076
[23:53:52.506] iteration 4057 : loss : 0.096591, loss_ce: 0.023747
[23:53:52.785] iteration 4058 : loss : 0.082757, loss_ce: 0.030220
[23:53:53.070] iteration 4059 : loss : 0.079071, loss_ce: 0.017566
[23:53:53.348] iteration 4060 : loss : 0.083011, loss_ce: 0.032897
[23:53:53.646] iteration 4061 : loss : 0.127325, loss_ce: 0.029280
[23:53:53.928] iteration 4062 : loss : 0.075064, loss_ce: 0.030250
[23:53:54.205] iteration 4063 : loss : 0.094013, loss_ce: 0.033491
[23:53:54.487] iteration 4064 : loss : 0.088350, loss_ce: 0.014741
[23:53:54.766] iteration 4065 : loss : 0.073807, loss_ce: 0.021972
[23:53:55.046] iteration 4066 : loss : 0.060859, loss_ce: 0.013073
[23:53:55.328] iteration 4067 : loss : 0.134195, loss_ce: 0.022064
[23:53:55.608] iteration 4068 : loss : 0.082985, loss_ce: 0.028363
[23:53:55.887] iteration 4069 : loss : 0.083146, loss_ce: 0.025608
[23:53:56.170] iteration 4070 : loss : 0.074721, loss_ce: 0.023458
[23:53:56.450] iteration 4071 : loss : 0.103840, loss_ce: 0.027864
[23:53:56.729] iteration 4072 : loss : 0.151947, loss_ce: 0.038343
[23:53:57.012] iteration 4073 : loss : 0.082034, loss_ce: 0.022313
[23:53:57.292] iteration 4074 : loss : 0.085279, loss_ce: 0.018501
[23:53:57.575] iteration 4075 : loss : 0.133066, loss_ce: 0.019601
[23:53:57.854] iteration 4076 : loss : 0.076737, loss_ce: 0.025293
[23:53:58.138] iteration 4077 : loss : 0.125652, loss_ce: 0.012687
[23:53:58.472] iteration 4078 : loss : 0.167681, loss_ce: 0.008756
[23:53:58.803] iteration 4079 : loss : 0.099081, loss_ce: 0.037240
[23:53:59.085] iteration 4080 : loss : 0.058035, loss_ce: 0.021251
[23:53:59.381] iteration 4081 : loss : 0.071451, loss_ce: 0.027027
[23:53:59.657] iteration 4082 : loss : 0.087275, loss_ce: 0.026314
[23:53:59.933] iteration 4083 : loss : 0.082631, loss_ce: 0.025314
[23:54:00.217] iteration 4084 : loss : 0.120029, loss_ce: 0.016745
[23:54:00.499] iteration 4085 : loss : 0.082059, loss_ce: 0.026542
[23:54:00.776] iteration 4086 : loss : 0.084079, loss_ce: 0.023339
[23:54:01.057] iteration 4087 : loss : 0.085067, loss_ce: 0.027319
[23:54:01.377] iteration 4088 : loss : 0.122691, loss_ce: 0.026331
[23:54:01.696] iteration 4089 : loss : 0.064800, loss_ce: 0.008295
[23:54:02.010] iteration 4090 : loss : 0.081222, loss_ce: 0.043967
[23:54:02.319] iteration 4091 : loss : 0.144311, loss_ce: 0.034081
[23:54:02.638] iteration 4092 : loss : 0.102308, loss_ce: 0.021350
[23:54:02.949] iteration 4093 : loss : 0.141148, loss_ce: 0.016441
[23:54:03.246] iteration 4094 : loss : 0.084755, loss_ce: 0.028880
[23:54:03.543] iteration 4095 : loss : 0.092831, loss_ce: 0.023031
[23:54:03.852] iteration 4096 : loss : 0.155382, loss_ce: 0.023632
[23:54:04.179] iteration 4097 : loss : 0.089557, loss_ce: 0.025656
[23:54:04.457] iteration 4098 : loss : 0.065024, loss_ce: 0.015563
[23:54:04.736] iteration 4099 : loss : 0.062153, loss_ce: 0.025733
[23:54:05.014] iteration 4100 : loss : 0.073451, loss_ce: 0.026869
[23:54:05.315] iteration 4101 : loss : 0.118819, loss_ce: 0.024670
[23:54:05.600] iteration 4102 : loss : 0.117791, loss_ce: 0.024792
[23:54:05.887] iteration 4103 : loss : 0.094197, loss_ce: 0.035875
[23:54:06.170] iteration 4104 : loss : 0.124260, loss_ce: 0.025269
[23:54:06.460] iteration 4105 : loss : 0.171149, loss_ce: 0.018712
[23:54:06.742] iteration 4106 : loss : 0.079521, loss_ce: 0.020090
[23:54:07.036] iteration 4107 : loss : 0.087784, loss_ce: 0.030813
[23:54:07.311] iteration 4108 : loss : 0.090480, loss_ce: 0.040688
[23:54:07.588] iteration 4109 : loss : 0.086722, loss_ce: 0.018059
[23:54:07.864] iteration 4110 : loss : 0.082675, loss_ce: 0.025676
[23:54:08.160] iteration 4111 : loss : 0.106191, loss_ce: 0.015716
[23:54:08.450] iteration 4112 : loss : 0.251732, loss_ce: 0.005251
[23:54:08.727] iteration 4113 : loss : 0.072828, loss_ce: 0.021720
[23:54:09.027] iteration 4114 : loss : 0.058635, loss_ce: 0.013364
[23:54:09.307] iteration 4115 : loss : 0.092079, loss_ce: 0.036395
[23:54:09.595] iteration 4116 : loss : 0.091802, loss_ce: 0.009896
[23:54:09.876] iteration 4117 : loss : 0.064190, loss_ce: 0.022880
[23:54:10.171] iteration 4118 : loss : 0.068188, loss_ce: 0.023576
[23:54:10.457] iteration 4119 : loss : 0.142075, loss_ce: 0.017831
[23:54:10.739] iteration 4120 : loss : 0.139187, loss_ce: 0.013617
[23:54:11.057] iteration 4121 : loss : 0.062484, loss_ce: 0.011808
[23:54:11.339] iteration 4122 : loss : 0.092185, loss_ce: 0.034355
[23:54:11.619] iteration 4123 : loss : 0.072185, loss_ce: 0.026760
[23:54:11.901] iteration 4124 : loss : 0.068546, loss_ce: 0.022781
[23:54:12.191] iteration 4125 : loss : 0.077247, loss_ce: 0.025950
[23:54:12.488] iteration 4126 : loss : 0.077515, loss_ce: 0.015833
[23:54:12.768] iteration 4127 : loss : 0.152841, loss_ce: 0.016049
[23:54:13.055] iteration 4128 : loss : 0.077733, loss_ce: 0.028082
[23:54:13.345] iteration 4129 : loss : 0.228099, loss_ce: 0.018147
[23:54:13.628] iteration 4130 : loss : 0.072825, loss_ce: 0.015697
[23:54:13.910] iteration 4131 : loss : 0.068901, loss_ce: 0.022510
[23:54:14.207] iteration 4132 : loss : 0.076416, loss_ce: 0.035052
[23:54:14.484] iteration 4133 : loss : 0.117932, loss_ce: 0.030332
[23:54:14.772] iteration 4134 : loss : 0.130657, loss_ce: 0.023286
[23:54:15.051] iteration 4135 : loss : 0.072321, loss_ce: 0.012474
[23:54:15.333] iteration 4136 : loss : 0.098882, loss_ce: 0.019495
[23:54:15.611] iteration 4137 : loss : 0.071195, loss_ce: 0.016966
[23:54:15.888] iteration 4138 : loss : 0.082470, loss_ce: 0.043256
[23:54:16.171] iteration 4139 : loss : 0.138902, loss_ce: 0.029943
[23:54:16.467] iteration 4140 : loss : 0.123253, loss_ce: 0.027906
[23:54:16.761] iteration 4141 : loss : 0.146755, loss_ce: 0.014453
[23:54:17.039] iteration 4142 : loss : 0.089398, loss_ce: 0.026041
[23:54:17.322] iteration 4143 : loss : 0.086170, loss_ce: 0.029229
[23:54:17.610] iteration 4144 : loss : 0.063475, loss_ce: 0.017113
[23:54:17.891] iteration 4145 : loss : 0.080697, loss_ce: 0.015885
[23:54:18.176] iteration 4146 : loss : 0.131900, loss_ce: 0.022918
[23:54:18.458] iteration 4147 : loss : 0.091648, loss_ce: 0.039868
[23:54:18.735] iteration 4148 : loss : 0.096803, loss_ce: 0.021436
[23:54:19.012] iteration 4149 : loss : 0.111646, loss_ce: 0.024823
[23:54:19.294] iteration 4150 : loss : 0.087788, loss_ce: 0.031156
[23:54:19.574] iteration 4151 : loss : 0.087021, loss_ce: 0.027760
[23:54:19.852] iteration 4152 : loss : 0.064615, loss_ce: 0.021649
[23:54:20.139] iteration 4153 : loss : 0.095622, loss_ce: 0.018331
[23:54:20.422] iteration 4154 : loss : 0.075412, loss_ce: 0.016135
[23:54:20.707] iteration 4155 : loss : 0.075823, loss_ce: 0.029699
[23:54:20.989] iteration 4156 : loss : 0.081496, loss_ce: 0.040655
[23:54:21.275] iteration 4157 : loss : 0.098695, loss_ce: 0.031191
[23:54:21.563] iteration 4158 : loss : 0.105006, loss_ce: 0.028838
[23:54:21.849] iteration 4159 : loss : 0.101521, loss_ce: 0.018247
[23:54:22.130] iteration 4160 : loss : 0.132026, loss_ce: 0.026991
[23:54:22.428] iteration 4161 : loss : 0.097870, loss_ce: 0.020954
[23:54:22.711] iteration 4162 : loss : 0.081175, loss_ce: 0.016344
[23:54:22.997] iteration 4163 : loss : 0.083147, loss_ce: 0.029187
[23:54:23.281] iteration 4164 : loss : 0.088795, loss_ce: 0.028607
[23:54:23.563] iteration 4165 : loss : 0.177764, loss_ce: 0.016562
[23:54:23.853] iteration 4166 : loss : 0.118460, loss_ce: 0.020732
[23:54:24.155] iteration 4167 : loss : 0.221081, loss_ce: 0.008710
[23:54:24.441] iteration 4168 : loss : 0.088860, loss_ce: 0.021734
[23:54:24.735] iteration 4169 : loss : 0.074574, loss_ce: 0.019127
[23:54:24.809] iteration 4170 : loss : 0.346666, loss_ce: 0.013370
[23:54:43.459] iteration 4171 : loss : 0.140416, loss_ce: 0.020938
[23:54:43.739] iteration 4172 : loss : 0.183872, loss_ce: 0.016459
[23:54:44.020] iteration 4173 : loss : 0.067477, loss_ce: 0.024653
[23:54:44.300] iteration 4174 : loss : 0.143442, loss_ce: 0.023933
[23:54:44.581] iteration 4175 : loss : 0.120732, loss_ce: 0.015113
[23:54:44.861] iteration 4176 : loss : 0.075771, loss_ce: 0.014271
[23:54:45.136] iteration 4177 : loss : 0.091881, loss_ce: 0.035842
[23:54:45.411] iteration 4178 : loss : 0.088018, loss_ce: 0.023882
[23:54:45.687] iteration 4179 : loss : 0.100311, loss_ce: 0.022312
[23:54:45.963] iteration 4180 : loss : 0.092917, loss_ce: 0.024292
[23:54:46.252] iteration 4181 : loss : 0.077903, loss_ce: 0.018386
[23:54:46.529] iteration 4182 : loss : 0.076738, loss_ce: 0.025645
[23:54:46.805] iteration 4183 : loss : 0.163649, loss_ce: 0.021146
[23:54:47.083] iteration 4184 : loss : 0.167457, loss_ce: 0.019209
[23:54:47.363] iteration 4185 : loss : 0.082623, loss_ce: 0.028339
[23:54:47.639] iteration 4186 : loss : 0.067739, loss_ce: 0.031290
[23:54:47.916] iteration 4187 : loss : 0.075606, loss_ce: 0.025600
[23:54:48.196] iteration 4188 : loss : 0.193834, loss_ce: 0.005029
[23:54:48.474] iteration 4189 : loss : 0.106717, loss_ce: 0.024517
[23:54:48.754] iteration 4190 : loss : 0.131162, loss_ce: 0.022345
[23:54:49.030] iteration 4191 : loss : 0.078538, loss_ce: 0.031450
[23:54:49.308] iteration 4192 : loss : 0.125303, loss_ce: 0.010705
[23:54:49.589] iteration 4193 : loss : 0.071655, loss_ce: 0.026176
[23:54:49.867] iteration 4194 : loss : 0.133835, loss_ce: 0.017079
[23:54:50.142] iteration 4195 : loss : 0.123334, loss_ce: 0.024139
[23:54:50.421] iteration 4196 : loss : 0.091006, loss_ce: 0.010258
[23:54:50.698] iteration 4197 : loss : 0.066483, loss_ce: 0.020600
[23:54:50.982] iteration 4198 : loss : 0.147325, loss_ce: 0.016954
[23:54:51.257] iteration 4199 : loss : 0.073988, loss_ce: 0.021626
[23:54:51.542] iteration 4200 : loss : 0.070650, loss_ce: 0.017866
[23:54:51.836] iteration 4201 : loss : 0.071935, loss_ce: 0.037244
[23:54:52.114] iteration 4202 : loss : 0.092375, loss_ce: 0.022962
[23:54:52.393] iteration 4203 : loss : 0.081935, loss_ce: 0.023537
[23:54:52.670] iteration 4204 : loss : 0.120670, loss_ce: 0.017359
[23:54:52.947] iteration 4205 : loss : 0.126363, loss_ce: 0.021950
[23:54:53.228] iteration 4206 : loss : 0.079656, loss_ce: 0.018760
[23:54:53.503] iteration 4207 : loss : 0.164852, loss_ce: 0.014518
[23:54:53.782] iteration 4208 : loss : 0.127314, loss_ce: 0.024212
[23:54:54.063] iteration 4209 : loss : 0.088959, loss_ce: 0.021594
[23:54:54.340] iteration 4210 : loss : 0.088500, loss_ce: 0.024082
[23:54:54.617] iteration 4211 : loss : 0.067909, loss_ce: 0.023709
[23:54:54.896] iteration 4212 : loss : 0.081938, loss_ce: 0.020886
[23:54:55.177] iteration 4213 : loss : 0.143065, loss_ce: 0.024537
[23:54:55.459] iteration 4214 : loss : 0.104918, loss_ce: 0.031594
[23:54:55.738] iteration 4215 : loss : 0.104761, loss_ce: 0.015768
[23:54:56.019] iteration 4216 : loss : 0.070478, loss_ce: 0.011754
[23:54:56.295] iteration 4217 : loss : 0.094380, loss_ce: 0.015585
[23:54:56.579] iteration 4218 : loss : 0.097481, loss_ce: 0.029189
[23:54:56.870] iteration 4219 : loss : 0.074456, loss_ce: 0.021820
[23:54:57.148] iteration 4220 : loss : 0.085114, loss_ce: 0.029561
[23:54:57.441] iteration 4221 : loss : 0.061372, loss_ce: 0.014373
[23:54:57.721] iteration 4222 : loss : 0.100168, loss_ce: 0.026226
[23:54:58.000] iteration 4223 : loss : 0.209230, loss_ce: 0.010267
[23:54:58.281] iteration 4224 : loss : 0.070259, loss_ce: 0.026676
[23:54:58.564] iteration 4225 : loss : 0.142147, loss_ce: 0.010186
[23:54:58.841] iteration 4226 : loss : 0.122020, loss_ce: 0.017841
[23:54:59.126] iteration 4227 : loss : 0.107034, loss_ce: 0.036175
[23:54:59.406] iteration 4228 : loss : 0.083386, loss_ce: 0.022785
[23:54:59.692] iteration 4229 : loss : 0.079748, loss_ce: 0.010013
[23:54:59.971] iteration 4230 : loss : 0.096048, loss_ce: 0.038039
[23:55:00.259] iteration 4231 : loss : 0.110587, loss_ce: 0.021783
[23:55:00.548] iteration 4232 : loss : 0.085425, loss_ce: 0.039556
[23:55:00.829] iteration 4233 : loss : 0.050992, loss_ce: 0.010631
[23:55:01.114] iteration 4234 : loss : 0.125616, loss_ce: 0.030147
[23:55:01.395] iteration 4235 : loss : 0.085958, loss_ce: 0.041509
[23:55:01.675] iteration 4236 : loss : 0.122251, loss_ce: 0.016521
[23:55:01.958] iteration 4237 : loss : 0.089672, loss_ce: 0.024259
[23:55:02.243] iteration 4238 : loss : 0.076273, loss_ce: 0.029626
[23:55:02.519] iteration 4239 : loss : 0.088917, loss_ce: 0.029487
[23:55:02.802] iteration 4240 : loss : 0.088860, loss_ce: 0.039875
[23:55:03.110] iteration 4241 : loss : 0.072173, loss_ce: 0.017368
[23:55:03.391] iteration 4242 : loss : 0.072983, loss_ce: 0.014271
[23:55:03.672] iteration 4243 : loss : 0.128892, loss_ce: 0.028950
[23:55:03.951] iteration 4244 : loss : 0.080028, loss_ce: 0.024314
[23:55:04.235] iteration 4245 : loss : 0.095702, loss_ce: 0.029079
[23:55:04.519] iteration 4246 : loss : 0.086947, loss_ce: 0.029339
[23:55:04.800] iteration 4247 : loss : 0.072411, loss_ce: 0.029929
[23:55:05.083] iteration 4248 : loss : 0.076598, loss_ce: 0.024946
[23:55:05.360] iteration 4249 : loss : 0.068919, loss_ce: 0.024505
[23:55:05.644] iteration 4250 : loss : 0.171927, loss_ce: 0.006227
[23:55:05.923] iteration 4251 : loss : 0.152321, loss_ce: 0.023951
[23:55:06.207] iteration 4252 : loss : 0.120717, loss_ce: 0.018454
[23:55:06.485] iteration 4253 : loss : 0.229084, loss_ce: 0.006650
[23:55:06.769] iteration 4254 : loss : 0.114778, loss_ce: 0.025190
[23:55:07.047] iteration 4255 : loss : 0.102425, loss_ce: 0.024182
[23:55:07.331] iteration 4256 : loss : 0.142929, loss_ce: 0.020209
[23:55:07.611] iteration 4257 : loss : 0.086929, loss_ce: 0.021128
[23:55:07.892] iteration 4258 : loss : 0.097739, loss_ce: 0.029039
[23:55:08.172] iteration 4259 : loss : 0.088954, loss_ce: 0.023086
[23:55:08.460] iteration 4260 : loss : 0.086754, loss_ce: 0.040253
[23:55:08.764] iteration 4261 : loss : 0.136299, loss_ce: 0.025461
[23:55:09.044] iteration 4262 : loss : 0.093187, loss_ce: 0.027671
[23:55:09.324] iteration 4263 : loss : 0.073556, loss_ce: 0.032796
[23:55:09.607] iteration 4264 : loss : 0.173722, loss_ce: 0.017469
[23:55:09.901] iteration 4265 : loss : 0.167897, loss_ce: 0.024950
[23:55:10.198] iteration 4266 : loss : 0.079358, loss_ce: 0.037383
[23:55:10.487] iteration 4267 : loss : 0.073094, loss_ce: 0.025007
[23:55:10.791] iteration 4268 : loss : 0.110173, loss_ce: 0.027559
[23:55:11.096] iteration 4269 : loss : 0.101392, loss_ce: 0.030921
[23:55:11.378] iteration 4270 : loss : 0.087343, loss_ce: 0.032621
[23:55:11.663] iteration 4271 : loss : 0.081810, loss_ce: 0.024023
[23:55:11.957] iteration 4272 : loss : 0.096973, loss_ce: 0.027226
[23:55:12.242] iteration 4273 : loss : 0.180573, loss_ce: 0.013275
[23:55:12.524] iteration 4274 : loss : 0.120917, loss_ce: 0.018386
[23:55:12.805] iteration 4275 : loss : 0.114406, loss_ce: 0.020993
[23:55:13.085] iteration 4276 : loss : 0.083088, loss_ce: 0.030615
[23:55:13.366] iteration 4277 : loss : 0.105978, loss_ce: 0.024976
[23:55:13.649] iteration 4278 : loss : 0.069959, loss_ce: 0.023187
[23:55:13.927] iteration 4279 : loss : 0.100740, loss_ce: 0.041044
[23:55:14.206] iteration 4280 : loss : 0.120497, loss_ce: 0.030383
[23:55:14.508] iteration 4281 : loss : 0.112852, loss_ce: 0.005678
[23:55:14.795] iteration 4282 : loss : 0.091486, loss_ce: 0.024629
[23:55:15.071] iteration 4283 : loss : 0.121990, loss_ce: 0.019208
[23:55:15.351] iteration 4284 : loss : 0.178293, loss_ce: 0.024291
[23:55:15.632] iteration 4285 : loss : 0.122098, loss_ce: 0.031938
[23:55:15.927] iteration 4286 : loss : 0.146136, loss_ce: 0.025903
[23:55:16.205] iteration 4287 : loss : 0.096277, loss_ce: 0.019610
[23:55:16.487] iteration 4288 : loss : 0.130401, loss_ce: 0.014498
[23:55:16.778] iteration 4289 : loss : 0.077395, loss_ce: 0.025044
[23:55:17.056] iteration 4290 : loss : 0.080303, loss_ce: 0.036403
[23:55:17.348] iteration 4291 : loss : 0.070976, loss_ce: 0.020758
[23:55:17.632] iteration 4292 : loss : 0.069141, loss_ce: 0.019659
[23:55:17.917] iteration 4293 : loss : 0.074677, loss_ce: 0.024468
[23:55:18.202] iteration 4294 : loss : 0.079803, loss_ce: 0.027677
[23:55:18.486] iteration 4295 : loss : 0.129378, loss_ce: 0.018332
[23:55:18.772] iteration 4296 : loss : 0.078667, loss_ce: 0.024024
[23:55:19.069] iteration 4297 : loss : 0.089319, loss_ce: 0.033593
[23:55:19.336] iteration 4298 : loss : 0.069309, loss_ce: 0.016224
[23:55:19.608] iteration 4299 : loss : 0.085625, loss_ce: 0.027250
[23:55:19.875] iteration 4300 : loss : 0.139201, loss_ce: 0.030830
[23:55:20.187] iteration 4301 : loss : 0.129034, loss_ce: 0.024072
[23:55:20.491] iteration 4302 : loss : 0.117802, loss_ce: 0.017788
[23:55:20.799] iteration 4303 : loss : 0.124897, loss_ce: 0.020618
[23:55:21.097] iteration 4304 : loss : 0.095642, loss_ce: 0.015389
[23:55:21.396] iteration 4305 : loss : 0.081535, loss_ce: 0.026723
[23:55:21.696] iteration 4306 : loss : 0.163416, loss_ce: 0.022081
[23:55:21.999] iteration 4307 : loss : 0.072710, loss_ce: 0.019175
[23:55:22.301] iteration 4308 : loss : 0.068292, loss_ce: 0.012483
[23:55:22.377] iteration 4309 : loss : 0.310330, loss_ce: 0.036836
[23:55:41.157] iteration 4310 : loss : 0.142544, loss_ce: 0.010543
[23:55:41.453] iteration 4311 : loss : 0.077124, loss_ce: 0.021299
[23:55:41.747] iteration 4312 : loss : 0.105378, loss_ce: 0.028510
[23:55:42.041] iteration 4313 : loss : 0.066999, loss_ce: 0.022621
[23:55:42.339] iteration 4314 : loss : 0.067403, loss_ce: 0.019987
[23:55:42.636] iteration 4315 : loss : 0.140595, loss_ce: 0.018855
[23:55:42.935] iteration 4316 : loss : 0.083654, loss_ce: 0.031467
[23:55:43.230] iteration 4317 : loss : 0.096192, loss_ce: 0.034058
[23:55:43.527] iteration 4318 : loss : 0.110328, loss_ce: 0.012376
[23:55:43.825] iteration 4319 : loss : 0.088884, loss_ce: 0.024360
[23:55:44.122] iteration 4320 : loss : 0.129517, loss_ce: 0.016917
[23:55:44.432] iteration 4321 : loss : 0.134981, loss_ce: 0.016927
[23:55:44.737] iteration 4322 : loss : 0.092505, loss_ce: 0.020300
[23:55:45.038] iteration 4323 : loss : 0.083941, loss_ce: 0.036601
[23:55:45.335] iteration 4324 : loss : 0.141167, loss_ce: 0.015271
[23:55:45.631] iteration 4325 : loss : 0.133715, loss_ce: 0.023296
[23:55:45.928] iteration 4326 : loss : 0.074763, loss_ce: 0.027631
[23:55:46.224] iteration 4327 : loss : 0.069598, loss_ce: 0.020565
[23:55:46.519] iteration 4328 : loss : 0.082494, loss_ce: 0.023426
[23:55:46.815] iteration 4329 : loss : 0.094267, loss_ce: 0.026597
[23:55:47.119] iteration 4330 : loss : 0.143446, loss_ce: 0.077215
[23:55:47.419] iteration 4331 : loss : 0.081133, loss_ce: 0.018495
[23:55:47.721] iteration 4332 : loss : 0.074559, loss_ce: 0.034540
[23:55:48.020] iteration 4333 : loss : 0.135224, loss_ce: 0.018022
[23:55:48.316] iteration 4334 : loss : 0.075145, loss_ce: 0.020033
[23:55:48.614] iteration 4335 : loss : 0.097913, loss_ce: 0.036274
[23:55:48.917] iteration 4336 : loss : 0.086610, loss_ce: 0.030829
[23:55:49.214] iteration 4337 : loss : 0.067736, loss_ce: 0.018567
[23:55:49.515] iteration 4338 : loss : 0.104236, loss_ce: 0.025568
[23:55:49.814] iteration 4339 : loss : 0.137572, loss_ce: 0.031875
[23:55:50.113] iteration 4340 : loss : 0.140535, loss_ce: 0.013536
[23:55:50.432] iteration 4341 : loss : 0.125168, loss_ce: 0.016988
[23:55:50.733] iteration 4342 : loss : 0.107204, loss_ce: 0.031116
[23:55:51.032] iteration 4343 : loss : 0.083968, loss_ce: 0.016518
[23:55:51.328] iteration 4344 : loss : 0.146936, loss_ce: 0.023539
[23:55:51.626] iteration 4345 : loss : 0.075770, loss_ce: 0.021690
[23:55:51.925] iteration 4346 : loss : 0.067629, loss_ce: 0.011879
[23:55:52.225] iteration 4347 : loss : 0.117386, loss_ce: 0.022738
[23:55:52.525] iteration 4348 : loss : 0.082961, loss_ce: 0.024035
[23:55:52.821] iteration 4349 : loss : 0.063940, loss_ce: 0.019981
[23:55:53.121] iteration 4350 : loss : 0.090621, loss_ce: 0.020245
[23:55:53.422] iteration 4351 : loss : 0.109631, loss_ce: 0.021689
[23:55:53.719] iteration 4352 : loss : 0.117674, loss_ce: 0.031476
[23:55:54.016] iteration 4353 : loss : 0.074137, loss_ce: 0.009829
[23:55:54.318] iteration 4354 : loss : 0.083875, loss_ce: 0.035783
[23:55:54.615] iteration 4355 : loss : 0.101010, loss_ce: 0.027215
[23:55:54.915] iteration 4356 : loss : 0.075625, loss_ce: 0.016330
[23:55:55.213] iteration 4357 : loss : 0.081540, loss_ce: 0.026765
[23:55:55.512] iteration 4358 : loss : 0.086011, loss_ce: 0.011278
[23:55:55.813] iteration 4359 : loss : 0.106553, loss_ce: 0.032569
[23:55:56.111] iteration 4360 : loss : 0.064876, loss_ce: 0.015794
[23:55:56.422] iteration 4361 : loss : 0.167777, loss_ce: 0.012078
[23:55:56.721] iteration 4362 : loss : 0.079608, loss_ce: 0.019432
[23:55:57.020] iteration 4363 : loss : 0.119409, loss_ce: 0.021489
[23:55:57.317] iteration 4364 : loss : 0.128594, loss_ce: 0.019427
[23:55:57.618] iteration 4365 : loss : 0.127844, loss_ce: 0.030957
[23:55:57.914] iteration 4366 : loss : 0.093297, loss_ce: 0.025091
[23:55:58.213] iteration 4367 : loss : 0.086305, loss_ce: 0.024663
[23:55:58.510] iteration 4368 : loss : 0.090577, loss_ce: 0.026093
[23:55:58.807] iteration 4369 : loss : 0.109813, loss_ce: 0.007726
[23:55:59.110] iteration 4370 : loss : 0.093535, loss_ce: 0.031735
[23:55:59.410] iteration 4371 : loss : 0.088900, loss_ce: 0.031120
[23:55:59.710] iteration 4372 : loss : 0.097161, loss_ce: 0.030130
[23:56:00.014] iteration 4373 : loss : 0.061087, loss_ce: 0.012952
[23:56:00.311] iteration 4374 : loss : 0.075203, loss_ce: 0.021510
[23:56:00.619] iteration 4375 : loss : 0.062837, loss_ce: 0.015512
[23:56:00.921] iteration 4376 : loss : 0.097524, loss_ce: 0.019095
[23:56:01.219] iteration 4377 : loss : 0.071098, loss_ce: 0.017064
[23:56:01.517] iteration 4378 : loss : 0.121334, loss_ce: 0.013349
[23:56:01.817] iteration 4379 : loss : 0.064145, loss_ce: 0.027285
[23:56:02.114] iteration 4380 : loss : 0.109258, loss_ce: 0.035624
[23:56:02.427] iteration 4381 : loss : 0.132591, loss_ce: 0.020228
[23:56:02.728] iteration 4382 : loss : 0.089178, loss_ce: 0.034282
[23:56:03.028] iteration 4383 : loss : 0.076237, loss_ce: 0.026514
[23:56:03.324] iteration 4384 : loss : 0.139239, loss_ce: 0.024131
[23:56:03.623] iteration 4385 : loss : 0.136997, loss_ce: 0.034040
[23:56:03.921] iteration 4386 : loss : 0.132539, loss_ce: 0.014361
[23:56:04.219] iteration 4387 : loss : 0.065218, loss_ce: 0.017071
[23:56:04.519] iteration 4388 : loss : 0.254987, loss_ce: 0.020643
[23:56:04.819] iteration 4389 : loss : 0.076881, loss_ce: 0.012707
[23:56:05.120] iteration 4390 : loss : 0.145535, loss_ce: 0.025612
[23:56:05.422] iteration 4391 : loss : 0.078744, loss_ce: 0.026456
[23:56:05.720] iteration 4392 : loss : 0.072666, loss_ce: 0.010125
[23:56:06.017] iteration 4393 : loss : 0.090756, loss_ce: 0.031454
[23:56:06.317] iteration 4394 : loss : 0.117981, loss_ce: 0.024946
[23:56:06.617] iteration 4395 : loss : 0.095757, loss_ce: 0.024404
[23:56:06.914] iteration 4396 : loss : 0.188953, loss_ce: 0.013800
[23:56:07.212] iteration 4397 : loss : 0.100529, loss_ce: 0.022903
[23:56:07.515] iteration 4398 : loss : 0.052649, loss_ce: 0.023042
[23:56:07.814] iteration 4399 : loss : 0.064522, loss_ce: 0.016765
[23:56:08.112] iteration 4400 : loss : 0.123768, loss_ce: 0.017981
[23:56:08.434] iteration 4401 : loss : 0.088281, loss_ce: 0.021189
[23:56:08.729] iteration 4402 : loss : 0.218914, loss_ce: 0.018333
[23:56:09.028] iteration 4403 : loss : 0.071933, loss_ce: 0.024985
[23:56:09.329] iteration 4404 : loss : 0.067621, loss_ce: 0.027974
[23:56:09.627] iteration 4405 : loss : 0.157459, loss_ce: 0.029535
[23:56:09.924] iteration 4406 : loss : 0.058139, loss_ce: 0.015743
[23:56:10.224] iteration 4407 : loss : 0.100139, loss_ce: 0.021140
[23:56:10.522] iteration 4408 : loss : 0.083485, loss_ce: 0.028288
[23:56:10.822] iteration 4409 : loss : 0.113928, loss_ce: 0.017804
[23:56:11.123] iteration 4410 : loss : 0.078626, loss_ce: 0.029074
[23:56:11.423] iteration 4411 : loss : 0.153785, loss_ce: 0.016537
[23:56:11.723] iteration 4412 : loss : 0.105144, loss_ce: 0.029238
[23:56:12.025] iteration 4413 : loss : 0.077537, loss_ce: 0.015139
[23:56:12.324] iteration 4414 : loss : 0.174058, loss_ce: 0.023547
[23:56:12.622] iteration 4415 : loss : 0.151608, loss_ce: 0.021773
[23:56:12.923] iteration 4416 : loss : 0.103449, loss_ce: 0.025830
[23:56:13.220] iteration 4417 : loss : 0.078040, loss_ce: 0.018043
[23:56:13.519] iteration 4418 : loss : 0.108609, loss_ce: 0.034610
[23:56:13.818] iteration 4419 : loss : 0.144673, loss_ce: 0.031909
[23:56:14.115] iteration 4420 : loss : 0.109874, loss_ce: 0.017508
[23:56:14.432] iteration 4421 : loss : 0.073093, loss_ce: 0.031961
[23:56:14.732] iteration 4422 : loss : 0.107722, loss_ce: 0.023307
[23:56:15.030] iteration 4423 : loss : 0.070443, loss_ce: 0.018369
[23:56:15.329] iteration 4424 : loss : 0.236572, loss_ce: 0.018436
[23:56:15.627] iteration 4425 : loss : 0.084987, loss_ce: 0.028571
[23:56:15.931] iteration 4426 : loss : 0.103377, loss_ce: 0.022079
[23:56:16.232] iteration 4427 : loss : 0.081050, loss_ce: 0.026339
[23:56:16.532] iteration 4428 : loss : 0.083371, loss_ce: 0.018010
[23:56:16.833] iteration 4429 : loss : 0.081501, loss_ce: 0.022491
[23:56:17.133] iteration 4430 : loss : 0.112407, loss_ce: 0.020513
[23:56:17.433] iteration 4431 : loss : 0.073265, loss_ce: 0.026162
[23:56:17.738] iteration 4432 : loss : 0.090813, loss_ce: 0.044691
[23:56:18.042] iteration 4433 : loss : 0.079717, loss_ce: 0.020553
[23:56:18.353] iteration 4434 : loss : 0.088662, loss_ce: 0.025954
[23:56:18.661] iteration 4435 : loss : 0.123168, loss_ce: 0.015210
[23:56:18.967] iteration 4436 : loss : 0.131735, loss_ce: 0.023929
[23:56:19.267] iteration 4437 : loss : 0.195678, loss_ce: 0.007990
[23:56:19.570] iteration 4438 : loss : 0.117319, loss_ce: 0.023975
[23:56:19.874] iteration 4439 : loss : 0.067786, loss_ce: 0.025220
[23:56:20.178] iteration 4440 : loss : 0.086176, loss_ce: 0.021038
[23:56:20.496] iteration 4441 : loss : 0.114018, loss_ce: 0.027622
[23:56:20.799] iteration 4442 : loss : 0.073994, loss_ce: 0.026032
[23:56:21.099] iteration 4443 : loss : 0.138096, loss_ce: 0.016314
[23:56:21.403] iteration 4444 : loss : 0.116260, loss_ce: 0.022211
[23:56:21.712] iteration 4445 : loss : 0.076018, loss_ce: 0.043101
[23:56:22.024] iteration 4446 : loss : 0.152929, loss_ce: 0.020302
[23:56:22.323] iteration 4447 : loss : 0.083634, loss_ce: 0.022631
[23:56:22.399] iteration 4448 : loss : 0.514716, loss_ce: 0.000237
[23:56:40.854] iteration 4449 : loss : 0.140171, loss_ce: 0.019870
[23:56:41.153] iteration 4450 : loss : 0.059425, loss_ce: 0.009571
[23:56:41.446] iteration 4451 : loss : 0.145300, loss_ce: 0.010317
[23:56:41.743] iteration 4452 : loss : 0.109177, loss_ce: 0.031191
[23:56:42.041] iteration 4453 : loss : 0.095652, loss_ce: 0.037394
[23:56:42.338] iteration 4454 : loss : 0.144048, loss_ce: 0.022128
[23:56:42.636] iteration 4455 : loss : 0.102995, loss_ce: 0.022667
[23:56:42.937] iteration 4456 : loss : 0.085808, loss_ce: 0.029334
[23:56:43.234] iteration 4457 : loss : 0.131077, loss_ce: 0.016070
[23:56:43.532] iteration 4458 : loss : 0.147540, loss_ce: 0.012505
[23:56:43.830] iteration 4459 : loss : 0.072437, loss_ce: 0.014740
[23:56:44.129] iteration 4460 : loss : 0.114792, loss_ce: 0.024972
[23:56:44.444] iteration 4461 : loss : 0.099143, loss_ce: 0.031395
[23:56:44.744] iteration 4462 : loss : 0.149936, loss_ce: 0.024326
[23:56:45.041] iteration 4463 : loss : 0.129685, loss_ce: 0.023537
[23:56:45.339] iteration 4464 : loss : 0.130390, loss_ce: 0.043309
[23:56:45.637] iteration 4465 : loss : 0.088125, loss_ce: 0.029857
[23:56:45.937] iteration 4466 : loss : 0.181011, loss_ce: 0.020186
[23:56:46.239] iteration 4467 : loss : 0.240004, loss_ce: 0.007439
[23:56:46.538] iteration 4468 : loss : 0.095020, loss_ce: 0.032269
[23:56:46.836] iteration 4469 : loss : 0.088816, loss_ce: 0.026734
[23:56:47.136] iteration 4470 : loss : 0.089929, loss_ce: 0.031956
[23:56:47.437] iteration 4471 : loss : 0.087513, loss_ce: 0.037658
[23:56:47.735] iteration 4472 : loss : 0.236408, loss_ce: 0.009760
[23:56:48.036] iteration 4473 : loss : 0.075204, loss_ce: 0.027500
[23:56:48.336] iteration 4474 : loss : 0.085272, loss_ce: 0.021854
[23:56:48.635] iteration 4475 : loss : 0.129817, loss_ce: 0.011217
[23:56:48.933] iteration 4476 : loss : 0.080718, loss_ce: 0.026104
[23:56:49.232] iteration 4477 : loss : 0.062636, loss_ce: 0.014096
[23:56:49.531] iteration 4478 : loss : 0.091483, loss_ce: 0.031538
[23:56:49.834] iteration 4479 : loss : 0.086778, loss_ce: 0.039055
[23:56:50.135] iteration 4480 : loss : 0.141340, loss_ce: 0.023970
[23:56:50.451] iteration 4481 : loss : 0.079092, loss_ce: 0.019627
[23:56:50.750] iteration 4482 : loss : 0.130052, loss_ce: 0.020839
[23:56:51.052] iteration 4483 : loss : 0.071601, loss_ce: 0.024712
[23:56:51.350] iteration 4484 : loss : 0.090310, loss_ce: 0.030009
[23:56:51.651] iteration 4485 : loss : 0.081737, loss_ce: 0.027236
[23:56:51.953] iteration 4486 : loss : 0.072842, loss_ce: 0.020603
[23:56:52.252] iteration 4487 : loss : 0.067031, loss_ce: 0.017888
[23:56:52.558] iteration 4488 : loss : 0.065984, loss_ce: 0.015193
[23:56:52.861] iteration 4489 : loss : 0.160773, loss_ce: 0.015655
[23:56:53.159] iteration 4490 : loss : 0.054970, loss_ce: 0.022100
[23:56:53.463] iteration 4491 : loss : 0.082684, loss_ce: 0.030660
[23:56:53.767] iteration 4492 : loss : 0.084387, loss_ce: 0.022944
[23:56:54.066] iteration 4493 : loss : 0.068460, loss_ce: 0.009723
[23:56:54.364] iteration 4494 : loss : 0.068834, loss_ce: 0.024081
[23:56:54.665] iteration 4495 : loss : 0.077598, loss_ce: 0.034721
[23:56:54.966] iteration 4496 : loss : 0.077670, loss_ce: 0.026651
[23:56:55.270] iteration 4497 : loss : 0.085475, loss_ce: 0.015980
[23:56:55.572] iteration 4498 : loss : 0.091826, loss_ce: 0.041378
[23:56:55.874] iteration 4499 : loss : 0.140506, loss_ce: 0.015042
[23:56:56.179] iteration 4500 : loss : 0.068440, loss_ce: 0.026159
[23:56:56.499] iteration 4501 : loss : 0.072389, loss_ce: 0.042851
[23:56:56.803] iteration 4502 : loss : 0.076210, loss_ce: 0.038155
[23:56:57.108] iteration 4503 : loss : 0.077578, loss_ce: 0.027771
[23:56:57.412] iteration 4504 : loss : 0.176524, loss_ce: 0.010303
[23:56:57.715] iteration 4505 : loss : 0.066721, loss_ce: 0.019188
[23:56:58.015] iteration 4506 : loss : 0.129341, loss_ce: 0.028141
[23:56:58.317] iteration 4507 : loss : 0.077630, loss_ce: 0.031643
[23:56:58.619] iteration 4508 : loss : 0.057005, loss_ce: 0.013506
[23:56:58.921] iteration 4509 : loss : 0.121438, loss_ce: 0.012030
[23:56:59.226] iteration 4510 : loss : 0.111576, loss_ce: 0.045322
[23:56:59.525] iteration 4511 : loss : 0.085492, loss_ce: 0.033999
[23:56:59.830] iteration 4512 : loss : 0.222995, loss_ce: 0.011650
[23:57:00.128] iteration 4513 : loss : 0.130851, loss_ce: 0.030766
[23:57:00.434] iteration 4514 : loss : 0.166867, loss_ce: 0.015472
[23:57:00.739] iteration 4515 : loss : 0.083459, loss_ce: 0.024258
[23:57:01.041] iteration 4516 : loss : 0.071211, loss_ce: 0.026907
[23:57:01.340] iteration 4517 : loss : 0.069532, loss_ce: 0.017127
[23:57:01.643] iteration 4518 : loss : 0.057525, loss_ce: 0.014152
[23:57:01.943] iteration 4519 : loss : 0.083804, loss_ce: 0.022958
[23:57:02.243] iteration 4520 : loss : 0.170915, loss_ce: 0.009142
[23:57:02.560] iteration 4521 : loss : 0.196536, loss_ce: 0.009387
[23:57:02.861] iteration 4522 : loss : 0.130258, loss_ce: 0.012400
[23:57:03.161] iteration 4523 : loss : 0.070728, loss_ce: 0.023965
[23:57:03.467] iteration 4524 : loss : 0.083402, loss_ce: 0.028241
[23:57:03.767] iteration 4525 : loss : 0.075583, loss_ce: 0.028290
[23:57:04.070] iteration 4526 : loss : 0.135153, loss_ce: 0.023347
[23:57:04.373] iteration 4527 : loss : 0.068366, loss_ce: 0.027956
[23:57:04.677] iteration 4528 : loss : 0.078882, loss_ce: 0.015878
[23:57:04.981] iteration 4529 : loss : 0.065051, loss_ce: 0.030920
[23:57:05.285] iteration 4530 : loss : 0.131472, loss_ce: 0.047844
[23:57:05.583] iteration 4531 : loss : 0.222949, loss_ce: 0.009972
[23:57:05.881] iteration 4532 : loss : 0.084941, loss_ce: 0.017964
[23:57:06.182] iteration 4533 : loss : 0.089310, loss_ce: 0.030130
[23:57:06.482] iteration 4534 : loss : 0.121397, loss_ce: 0.008706
[23:57:06.788] iteration 4535 : loss : 0.127477, loss_ce: 0.037488
[23:57:07.086] iteration 4536 : loss : 0.138452, loss_ce: 0.014760
[23:57:07.385] iteration 4537 : loss : 0.088639, loss_ce: 0.017552
[23:57:07.688] iteration 4538 : loss : 0.082452, loss_ce: 0.020033
[23:57:07.990] iteration 4539 : loss : 0.203112, loss_ce: 0.008084
[23:57:08.292] iteration 4540 : loss : 0.103592, loss_ce: 0.024204
[23:57:08.612] iteration 4541 : loss : 0.073904, loss_ce: 0.026302
[23:57:08.914] iteration 4542 : loss : 0.096129, loss_ce: 0.024599
[23:57:09.216] iteration 4543 : loss : 0.141364, loss_ce: 0.014212
[23:57:09.516] iteration 4544 : loss : 0.081205, loss_ce: 0.024385
[23:57:09.818] iteration 4545 : loss : 0.073589, loss_ce: 0.019721
[23:57:10.120] iteration 4546 : loss : 0.078118, loss_ce: 0.017708
[23:57:10.422] iteration 4547 : loss : 0.083894, loss_ce: 0.022632
[23:57:10.725] iteration 4548 : loss : 0.083186, loss_ce: 0.036138
[23:57:11.023] iteration 4549 : loss : 0.075864, loss_ce: 0.016062
[23:57:11.325] iteration 4550 : loss : 0.076562, loss_ce: 0.018363
[23:57:11.632] iteration 4551 : loss : 0.077496, loss_ce: 0.020337
[23:57:11.941] iteration 4552 : loss : 0.089580, loss_ce: 0.025640
[23:57:12.243] iteration 4553 : loss : 0.120959, loss_ce: 0.020122
[23:57:12.543] iteration 4554 : loss : 0.090457, loss_ce: 0.018070
[23:57:12.842] iteration 4555 : loss : 0.087158, loss_ce: 0.036149
[23:57:13.143] iteration 4556 : loss : 0.102377, loss_ce: 0.036940
[23:57:13.443] iteration 4557 : loss : 0.149535, loss_ce: 0.013536
[23:57:13.742] iteration 4558 : loss : 0.073897, loss_ce: 0.018706
[23:57:14.044] iteration 4559 : loss : 0.067170, loss_ce: 0.024127
[23:57:14.345] iteration 4560 : loss : 0.085813, loss_ce: 0.016023
[23:57:14.672] iteration 4561 : loss : 0.092391, loss_ce: 0.024123
[23:57:14.974] iteration 4562 : loss : 0.135131, loss_ce: 0.024818
[23:57:15.276] iteration 4563 : loss : 0.070242, loss_ce: 0.021152
[23:57:15.579] iteration 4564 : loss : 0.081400, loss_ce: 0.015122
[23:57:15.879] iteration 4565 : loss : 0.163145, loss_ce: 0.012667
[23:57:16.180] iteration 4566 : loss : 0.166980, loss_ce: 0.030028
[23:57:16.479] iteration 4567 : loss : 0.155832, loss_ce: 0.015109
[23:57:16.781] iteration 4568 : loss : 0.076467, loss_ce: 0.017481
[23:57:17.086] iteration 4569 : loss : 0.093014, loss_ce: 0.025396
[23:57:17.385] iteration 4570 : loss : 0.084037, loss_ce: 0.037619
[23:57:17.689] iteration 4571 : loss : 0.084398, loss_ce: 0.028525
[23:57:17.996] iteration 4572 : loss : 0.068437, loss_ce: 0.019551
[23:57:18.304] iteration 4573 : loss : 0.085958, loss_ce: 0.029990
[23:57:18.611] iteration 4574 : loss : 0.066184, loss_ce: 0.028994
[23:57:18.912] iteration 4575 : loss : 0.090182, loss_ce: 0.039296
[23:57:19.218] iteration 4576 : loss : 0.134659, loss_ce: 0.022823
[23:57:19.521] iteration 4577 : loss : 0.102687, loss_ce: 0.025706
[23:57:19.822] iteration 4578 : loss : 0.073792, loss_ce: 0.029454
[23:57:20.131] iteration 4579 : loss : 0.088242, loss_ce: 0.027274
[23:57:20.435] iteration 4580 : loss : 0.119994, loss_ce: 0.015600
[23:57:20.773] iteration 4581 : loss : 0.104392, loss_ce: 0.019618
[23:57:21.076] iteration 4582 : loss : 0.096364, loss_ce: 0.022665
[23:57:21.381] iteration 4583 : loss : 0.092172, loss_ce: 0.030103
[23:57:21.686] iteration 4584 : loss : 0.104976, loss_ce: 0.027033
[23:57:21.992] iteration 4585 : loss : 0.066433, loss_ce: 0.018931
[23:57:22.299] iteration 4586 : loss : 0.087482, loss_ce: 0.027965
[23:57:22.375] iteration 4587 : loss : 0.127699, loss_ce: 0.017277
[23:57:41.566] iteration 4588 : loss : 0.067311, loss_ce: 0.023803
[23:57:41.861] iteration 4589 : loss : 0.144061, loss_ce: 0.018105
[23:57:42.157] iteration 4590 : loss : 0.197463, loss_ce: 0.036959
[23:57:42.460] iteration 4591 : loss : 0.066958, loss_ce: 0.028203
[23:57:42.760] iteration 4592 : loss : 0.082568, loss_ce: 0.023249
[23:57:43.057] iteration 4593 : loss : 0.232670, loss_ce: 0.010886
[23:57:43.361] iteration 4594 : loss : 0.080174, loss_ce: 0.031280
[23:57:43.663] iteration 4595 : loss : 0.122750, loss_ce: 0.020158
[23:57:43.960] iteration 4596 : loss : 0.083196, loss_ce: 0.032625
[23:57:44.262] iteration 4597 : loss : 0.136965, loss_ce: 0.016161
[23:57:44.563] iteration 4598 : loss : 0.078539, loss_ce: 0.022341
[23:57:44.861] iteration 4599 : loss : 0.090887, loss_ce: 0.045290
[23:57:45.162] iteration 4600 : loss : 0.086749, loss_ce: 0.020398
[23:57:45.479] iteration 4601 : loss : 0.153469, loss_ce: 0.022844
[23:57:45.778] iteration 4602 : loss : 0.085656, loss_ce: 0.013932
[23:57:46.079] iteration 4603 : loss : 0.069787, loss_ce: 0.023678
[23:57:46.383] iteration 4604 : loss : 0.137767, loss_ce: 0.022330
[23:57:46.681] iteration 4605 : loss : 0.077209, loss_ce: 0.021068
[23:57:46.982] iteration 4606 : loss : 0.092321, loss_ce: 0.023921
[23:57:47.280] iteration 4607 : loss : 0.059883, loss_ce: 0.019019
[23:57:47.577] iteration 4608 : loss : 0.068697, loss_ce: 0.018680
[23:57:47.877] iteration 4609 : loss : 0.068627, loss_ce: 0.026214
[23:57:48.177] iteration 4610 : loss : 0.082252, loss_ce: 0.023455
[23:57:48.478] iteration 4611 : loss : 0.065810, loss_ce: 0.024092
[23:57:48.779] iteration 4612 : loss : 0.129565, loss_ce: 0.017566
[23:57:49.076] iteration 4613 : loss : 0.101322, loss_ce: 0.038364
[23:57:49.377] iteration 4614 : loss : 0.163309, loss_ce: 0.012778
[23:57:49.676] iteration 4615 : loss : 0.156147, loss_ce: 0.044735
[23:57:49.978] iteration 4616 : loss : 0.075580, loss_ce: 0.032638
[23:57:50.279] iteration 4617 : loss : 0.097757, loss_ce: 0.021259
[23:57:50.585] iteration 4618 : loss : 0.135774, loss_ce: 0.017729
[23:57:50.887] iteration 4619 : loss : 0.077634, loss_ce: 0.019618
[23:57:51.188] iteration 4620 : loss : 0.062993, loss_ce: 0.023702
[23:57:51.503] iteration 4621 : loss : 0.105499, loss_ce: 0.018576
[23:57:51.805] iteration 4622 : loss : 0.097659, loss_ce: 0.014977
[23:57:52.109] iteration 4623 : loss : 0.080583, loss_ce: 0.021177
[23:57:52.410] iteration 4624 : loss : 0.134574, loss_ce: 0.017834
[23:57:52.710] iteration 4625 : loss : 0.085497, loss_ce: 0.024686
[23:57:53.010] iteration 4626 : loss : 0.078850, loss_ce: 0.016662
[23:57:53.309] iteration 4627 : loss : 0.096457, loss_ce: 0.011877
[23:57:53.612] iteration 4628 : loss : 0.082460, loss_ce: 0.028768
[23:57:53.909] iteration 4629 : loss : 0.079773, loss_ce: 0.012351
[23:57:54.207] iteration 4630 : loss : 0.109800, loss_ce: 0.025469
[23:57:54.507] iteration 4631 : loss : 0.097837, loss_ce: 0.011792
[23:57:54.805] iteration 4632 : loss : 0.074615, loss_ce: 0.030822
[23:57:55.107] iteration 4633 : loss : 0.121969, loss_ce: 0.024906
[23:57:55.406] iteration 4634 : loss : 0.093840, loss_ce: 0.020806
[23:57:55.705] iteration 4635 : loss : 0.065340, loss_ce: 0.020729
[23:57:56.005] iteration 4636 : loss : 0.112565, loss_ce: 0.023163
[23:57:56.307] iteration 4637 : loss : 0.062150, loss_ce: 0.022612
[23:57:56.607] iteration 4638 : loss : 0.076410, loss_ce: 0.019005
[23:57:56.906] iteration 4639 : loss : 0.067871, loss_ce: 0.021348
[23:57:57.206] iteration 4640 : loss : 0.168128, loss_ce: 0.020344
[23:57:57.516] iteration 4641 : loss : 0.214387, loss_ce: 0.016294
[23:57:57.817] iteration 4642 : loss : 0.103973, loss_ce: 0.035914
[23:57:58.122] iteration 4643 : loss : 0.093351, loss_ce: 0.038226
[23:57:58.425] iteration 4644 : loss : 0.181291, loss_ce: 0.010261
[23:57:58.726] iteration 4645 : loss : 0.137135, loss_ce: 0.031819
[23:57:59.028] iteration 4646 : loss : 0.167985, loss_ce: 0.003865
[23:57:59.327] iteration 4647 : loss : 0.096518, loss_ce: 0.027256
[23:57:59.628] iteration 4648 : loss : 0.075173, loss_ce: 0.026206
[23:57:59.932] iteration 4649 : loss : 0.098857, loss_ce: 0.029789
[23:58:00.232] iteration 4650 : loss : 0.077596, loss_ce: 0.026813
[23:58:00.540] iteration 4651 : loss : 0.077717, loss_ce: 0.018699
[23:58:00.843] iteration 4652 : loss : 0.073113, loss_ce: 0.017682
[23:58:01.142] iteration 4653 : loss : 0.135141, loss_ce: 0.019194
[23:58:01.445] iteration 4654 : loss : 0.082278, loss_ce: 0.028699
[23:58:01.744] iteration 4655 : loss : 0.078822, loss_ce: 0.023484
[23:58:02.042] iteration 4656 : loss : 0.087639, loss_ce: 0.026905
[23:58:02.342] iteration 4657 : loss : 0.058033, loss_ce: 0.023303
[23:58:02.644] iteration 4658 : loss : 0.081219, loss_ce: 0.019098
[23:58:02.943] iteration 4659 : loss : 0.120892, loss_ce: 0.020318
[23:58:03.242] iteration 4660 : loss : 0.090719, loss_ce: 0.038818
[23:58:03.557] iteration 4661 : loss : 0.075896, loss_ce: 0.023417
[23:58:03.856] iteration 4662 : loss : 0.073894, loss_ce: 0.030974
[23:58:04.158] iteration 4663 : loss : 0.066811, loss_ce: 0.024540
[23:58:04.458] iteration 4664 : loss : 0.072722, loss_ce: 0.021329
[23:58:04.756] iteration 4665 : loss : 0.130452, loss_ce: 0.020381
[23:58:05.062] iteration 4666 : loss : 0.069770, loss_ce: 0.027221
[23:58:05.361] iteration 4667 : loss : 0.078814, loss_ce: 0.018366
[23:58:05.667] iteration 4668 : loss : 0.101991, loss_ce: 0.027568
[23:58:05.968] iteration 4669 : loss : 0.078869, loss_ce: 0.011222
[23:58:06.270] iteration 4670 : loss : 0.147203, loss_ce: 0.009375
[23:58:06.570] iteration 4671 : loss : 0.122780, loss_ce: 0.013711
[23:58:06.868] iteration 4672 : loss : 0.075068, loss_ce: 0.022266
[23:58:07.167] iteration 4673 : loss : 0.068606, loss_ce: 0.019019
[23:58:07.469] iteration 4674 : loss : 0.074318, loss_ce: 0.025900
[23:58:07.767] iteration 4675 : loss : 0.075001, loss_ce: 0.015143
[23:58:08.067] iteration 4676 : loss : 0.070313, loss_ce: 0.018041
[23:58:08.371] iteration 4677 : loss : 0.057577, loss_ce: 0.011275
[23:58:08.672] iteration 4678 : loss : 0.086621, loss_ce: 0.013091
[23:58:08.972] iteration 4679 : loss : 0.143779, loss_ce: 0.021749
[23:58:09.270] iteration 4680 : loss : 0.091506, loss_ce: 0.014206
[23:58:09.588] iteration 4681 : loss : 0.080782, loss_ce: 0.023586
[23:58:09.894] iteration 4682 : loss : 0.127258, loss_ce: 0.010121
[23:58:10.195] iteration 4683 : loss : 0.079599, loss_ce: 0.029803
[23:58:10.495] iteration 4684 : loss : 0.065796, loss_ce: 0.016025
[23:58:10.795] iteration 4685 : loss : 0.122002, loss_ce: 0.013665
[23:58:11.096] iteration 4686 : loss : 0.080605, loss_ce: 0.031289
[23:58:11.396] iteration 4687 : loss : 0.088886, loss_ce: 0.034580
[23:58:11.698] iteration 4688 : loss : 0.074637, loss_ce: 0.030351
[23:58:11.997] iteration 4689 : loss : 0.085360, loss_ce: 0.021673
[23:58:12.301] iteration 4690 : loss : 0.132578, loss_ce: 0.016338
[23:58:12.602] iteration 4691 : loss : 0.088289, loss_ce: 0.026242
[23:58:12.902] iteration 4692 : loss : 0.080882, loss_ce: 0.033226
[23:58:13.203] iteration 4693 : loss : 0.112483, loss_ce: 0.018038
[23:58:13.504] iteration 4694 : loss : 0.061776, loss_ce: 0.017263
[23:58:13.804] iteration 4695 : loss : 0.157918, loss_ce: 0.012884
[23:58:14.104] iteration 4696 : loss : 0.061895, loss_ce: 0.014456
[23:58:14.411] iteration 4697 : loss : 0.067102, loss_ce: 0.019251
[23:58:14.712] iteration 4698 : loss : 0.189696, loss_ce: 0.019993
[23:58:15.017] iteration 4699 : loss : 0.112914, loss_ce: 0.015084
[23:58:15.321] iteration 4700 : loss : 0.174212, loss_ce: 0.014652
[23:58:15.632] iteration 4701 : loss : 0.073925, loss_ce: 0.029686
[23:58:15.934] iteration 4702 : loss : 0.070752, loss_ce: 0.022006
[23:58:16.235] iteration 4703 : loss : 0.082387, loss_ce: 0.038532
[23:58:16.535] iteration 4704 : loss : 0.087546, loss_ce: 0.030265
[23:58:16.836] iteration 4705 : loss : 0.092235, loss_ce: 0.048949
[23:58:17.137] iteration 4706 : loss : 0.084244, loss_ce: 0.032741
[23:58:17.439] iteration 4707 : loss : 0.078925, loss_ce: 0.027034
[23:58:17.740] iteration 4708 : loss : 0.097595, loss_ce: 0.034834
[23:58:18.039] iteration 4709 : loss : 0.082446, loss_ce: 0.020915
[23:58:18.343] iteration 4710 : loss : 0.084721, loss_ce: 0.018829
[23:58:18.650] iteration 4711 : loss : 0.100668, loss_ce: 0.017473
[23:58:18.961] iteration 4712 : loss : 0.063562, loss_ce: 0.027968
[23:58:19.265] iteration 4713 : loss : 0.102383, loss_ce: 0.023178
[23:58:19.572] iteration 4714 : loss : 0.055097, loss_ce: 0.020402
[23:58:19.879] iteration 4715 : loss : 0.082132, loss_ce: 0.042182
[23:58:20.181] iteration 4716 : loss : 0.151609, loss_ce: 0.026261
[23:58:20.491] iteration 4717 : loss : 0.113872, loss_ce: 0.025739
[23:58:20.795] iteration 4718 : loss : 0.085876, loss_ce: 0.033701
[23:58:21.102] iteration 4719 : loss : 0.076070, loss_ce: 0.012794
[23:58:21.409] iteration 4720 : loss : 0.081489, loss_ce: 0.027628
[23:58:21.730] iteration 4721 : loss : 0.132506, loss_ce: 0.021660
[23:58:22.028] iteration 4722 : loss : 0.089974, loss_ce: 0.034789
[23:58:22.336] iteration 4723 : loss : 0.126658, loss_ce: 0.014819
[23:58:22.642] iteration 4724 : loss : 0.085140, loss_ce: 0.021878
[23:58:22.943] iteration 4725 : loss : 0.134700, loss_ce: 0.010612
[23:58:23.022] iteration 4726 : loss : 0.160378, loss_ce: 0.049380
[23:58:41.603] iteration 4727 : loss : 0.118384, loss_ce: 0.013522
[23:58:41.902] iteration 4728 : loss : 0.079907, loss_ce: 0.022279
[23:58:42.202] iteration 4729 : loss : 0.100749, loss_ce: 0.021555
[23:58:42.501] iteration 4730 : loss : 0.130434, loss_ce: 0.009860
[23:58:42.798] iteration 4731 : loss : 0.068321, loss_ce: 0.012482
[23:58:43.097] iteration 4732 : loss : 0.082438, loss_ce: 0.010987
[23:58:43.393] iteration 4733 : loss : 0.079617, loss_ce: 0.033055
[23:58:43.692] iteration 4734 : loss : 0.067798, loss_ce: 0.011289
[23:58:43.992] iteration 4735 : loss : 0.092949, loss_ce: 0.014263
[23:58:44.292] iteration 4736 : loss : 0.079997, loss_ce: 0.021623
[23:58:44.592] iteration 4737 : loss : 0.077005, loss_ce: 0.022572
[23:58:44.890] iteration 4738 : loss : 0.071893, loss_ce: 0.029248
[23:58:45.189] iteration 4739 : loss : 0.065787, loss_ce: 0.025648
[23:58:45.488] iteration 4740 : loss : 0.109268, loss_ce: 0.023436
[23:58:45.803] iteration 4741 : loss : 0.081986, loss_ce: 0.023549
[23:58:46.101] iteration 4742 : loss : 0.076978, loss_ce: 0.032852
[23:58:46.402] iteration 4743 : loss : 0.072112, loss_ce: 0.018874
[23:58:46.705] iteration 4744 : loss : 0.089656, loss_ce: 0.031070
[23:58:47.004] iteration 4745 : loss : 0.103538, loss_ce: 0.035542
[23:58:47.308] iteration 4746 : loss : 0.077883, loss_ce: 0.032113
[23:58:47.608] iteration 4747 : loss : 0.170665, loss_ce: 0.016957
[23:58:47.906] iteration 4748 : loss : 0.068047, loss_ce: 0.026454
[23:58:48.208] iteration 4749 : loss : 0.081590, loss_ce: 0.020953
[23:58:48.508] iteration 4750 : loss : 0.132410, loss_ce: 0.026375
[23:58:48.809] iteration 4751 : loss : 0.115007, loss_ce: 0.010205
[23:58:49.109] iteration 4752 : loss : 0.122366, loss_ce: 0.017132
[23:58:49.410] iteration 4753 : loss : 0.110924, loss_ce: 0.029704
[23:58:49.708] iteration 4754 : loss : 0.133294, loss_ce: 0.018647
[23:58:50.008] iteration 4755 : loss : 0.087944, loss_ce: 0.019445
[23:58:50.306] iteration 4756 : loss : 0.063520, loss_ce: 0.019094
[23:58:50.605] iteration 4757 : loss : 0.059773, loss_ce: 0.020910
[23:58:50.907] iteration 4758 : loss : 0.101642, loss_ce: 0.029833
[23:58:51.209] iteration 4759 : loss : 0.054358, loss_ce: 0.014571
[23:58:51.506] iteration 4760 : loss : 0.135704, loss_ce: 0.034191
[23:58:51.822] iteration 4761 : loss : 0.086996, loss_ce: 0.030288
[23:58:52.123] iteration 4762 : loss : 0.108416, loss_ce: 0.027971
[23:58:52.426] iteration 4763 : loss : 0.096254, loss_ce: 0.020334
[23:58:52.729] iteration 4764 : loss : 0.116792, loss_ce: 0.026149
[23:58:53.028] iteration 4765 : loss : 0.077944, loss_ce: 0.018708
[23:58:53.327] iteration 4766 : loss : 0.077776, loss_ce: 0.027850
[23:58:53.630] iteration 4767 : loss : 0.147232, loss_ce: 0.018493
[23:58:53.932] iteration 4768 : loss : 0.127648, loss_ce: 0.015278
[23:58:54.232] iteration 4769 : loss : 0.093800, loss_ce: 0.014370
[23:58:54.538] iteration 4770 : loss : 0.101108, loss_ce: 0.035524
[23:58:54.841] iteration 4771 : loss : 0.078844, loss_ce: 0.026644
[23:58:55.143] iteration 4772 : loss : 0.176895, loss_ce: 0.014518
[23:58:55.443] iteration 4773 : loss : 0.084666, loss_ce: 0.024161
[23:58:55.741] iteration 4774 : loss : 0.188719, loss_ce: 0.017156
[23:58:56.040] iteration 4775 : loss : 0.072906, loss_ce: 0.024481
[23:58:56.346] iteration 4776 : loss : 0.137899, loss_ce: 0.020895
[23:58:56.651] iteration 4777 : loss : 0.096165, loss_ce: 0.023895
[23:58:56.953] iteration 4778 : loss : 0.082639, loss_ce: 0.029186
[23:58:57.277] iteration 4779 : loss : 0.084116, loss_ce: 0.026953
[23:58:57.599] iteration 4780 : loss : 0.125095, loss_ce: 0.012541
[23:58:57.935] iteration 4781 : loss : 0.190158, loss_ce: 0.026305
[23:58:58.240] iteration 4782 : loss : 0.097367, loss_ce: 0.028186
[23:58:58.563] iteration 4783 : loss : 0.081848, loss_ce: 0.033715
[23:58:58.878] iteration 4784 : loss : 0.070281, loss_ce: 0.030900
[23:58:59.193] iteration 4785 : loss : 0.121817, loss_ce: 0.023177
[23:58:59.524] iteration 4786 : loss : 0.119036, loss_ce: 0.021484
[23:58:59.830] iteration 4787 : loss : 0.086076, loss_ce: 0.038194
[23:59:00.132] iteration 4788 : loss : 0.077558, loss_ce: 0.022913
[23:59:00.476] iteration 4789 : loss : 0.075424, loss_ce: 0.006374
[23:59:00.802] iteration 4790 : loss : 0.161716, loss_ce: 0.022120
[23:59:01.112] iteration 4791 : loss : 0.098294, loss_ce: 0.046334
[23:59:01.444] iteration 4792 : loss : 0.082810, loss_ce: 0.027130
[23:59:01.778] iteration 4793 : loss : 0.080650, loss_ce: 0.030850
[23:59:02.129] iteration 4794 : loss : 0.094892, loss_ce: 0.022920
[23:59:02.444] iteration 4795 : loss : 0.089740, loss_ce: 0.018447
[23:59:02.746] iteration 4796 : loss : 0.093652, loss_ce: 0.034304
[23:59:03.047] iteration 4797 : loss : 0.071083, loss_ce: 0.021351
[23:59:03.349] iteration 4798 : loss : 0.081599, loss_ce: 0.017129
[23:59:03.651] iteration 4799 : loss : 0.109091, loss_ce: 0.027989
[23:59:03.954] iteration 4800 : loss : 0.087213, loss_ce: 0.026326
[23:59:04.267] iteration 4801 : loss : 0.137741, loss_ce: 0.009773
[23:59:04.567] iteration 4802 : loss : 0.066448, loss_ce: 0.024899
[23:59:04.873] iteration 4803 : loss : 0.238428, loss_ce: 0.016821
[23:59:05.183] iteration 4804 : loss : 0.181995, loss_ce: 0.011310
[23:59:05.484] iteration 4805 : loss : 0.094592, loss_ce: 0.036809
[23:59:05.790] iteration 4806 : loss : 0.095216, loss_ce: 0.026133
[23:59:06.104] iteration 4807 : loss : 0.103818, loss_ce: 0.041770
[23:59:06.416] iteration 4808 : loss : 0.275716, loss_ce: 0.010987
[23:59:06.721] iteration 4809 : loss : 0.144117, loss_ce: 0.019149
[23:59:07.034] iteration 4810 : loss : 0.053443, loss_ce: 0.020256
[23:59:07.350] iteration 4811 : loss : 0.130186, loss_ce: 0.023182
[23:59:07.653] iteration 4812 : loss : 0.144257, loss_ce: 0.020305
[23:59:07.955] iteration 4813 : loss : 0.118991, loss_ce: 0.014305
[23:59:08.266] iteration 4814 : loss : 0.080456, loss_ce: 0.032674
[23:59:08.577] iteration 4815 : loss : 0.120632, loss_ce: 0.024245
[23:59:08.880] iteration 4816 : loss : 0.084371, loss_ce: 0.024410
[23:59:09.202] iteration 4817 : loss : 0.070908, loss_ce: 0.015207
[23:59:09.499] iteration 4818 : loss : 0.072402, loss_ce: 0.025043
[23:59:09.809] iteration 4819 : loss : 0.068105, loss_ce: 0.016393
[23:59:10.112] iteration 4820 : loss : 0.115968, loss_ce: 0.014331
[23:59:10.429] iteration 4821 : loss : 0.091849, loss_ce: 0.032037
[23:59:10.729] iteration 4822 : loss : 0.298069, loss_ce: 0.018655
[23:59:11.037] iteration 4823 : loss : 0.124992, loss_ce: 0.010971
[23:59:11.408] iteration 4824 : loss : 0.091736, loss_ce: 0.025208
[23:59:11.725] iteration 4825 : loss : 0.083024, loss_ce: 0.036263
[23:59:12.065] iteration 4826 : loss : 0.091512, loss_ce: 0.019099
[23:59:12.380] iteration 4827 : loss : 0.112561, loss_ce: 0.022544
[23:59:12.726] iteration 4828 : loss : 0.122421, loss_ce: 0.034992
[23:59:13.050] iteration 4829 : loss : 0.195065, loss_ce: 0.025813
[23:59:13.383] iteration 4830 : loss : 0.082016, loss_ce: 0.014163
[23:59:13.713] iteration 4831 : loss : 0.066929, loss_ce: 0.015079
[23:59:14.026] iteration 4832 : loss : 0.065411, loss_ce: 0.024514
[23:59:14.329] iteration 4833 : loss : 0.061408, loss_ce: 0.012451
[23:59:14.631] iteration 4834 : loss : 0.162501, loss_ce: 0.025234
[23:59:14.938] iteration 4835 : loss : 0.056759, loss_ce: 0.024228
[23:59:15.244] iteration 4836 : loss : 0.077321, loss_ce: 0.026502
[23:59:15.598] iteration 4837 : loss : 0.068032, loss_ce: 0.018958
[23:59:15.945] iteration 4838 : loss : 0.062749, loss_ce: 0.033431
[23:59:16.258] iteration 4839 : loss : 0.132784, loss_ce: 0.010347
[23:59:16.569] iteration 4840 : loss : 0.070121, loss_ce: 0.020790
[23:59:16.894] iteration 4841 : loss : 0.096027, loss_ce: 0.021735
[23:59:17.197] iteration 4842 : loss : 0.140384, loss_ce: 0.008168
[23:59:17.507] iteration 4843 : loss : 0.059333, loss_ce: 0.016866
[23:59:17.849] iteration 4844 : loss : 0.091396, loss_ce: 0.014153
[23:59:18.182] iteration 4845 : loss : 0.073223, loss_ce: 0.035375
[23:59:18.512] iteration 4846 : loss : 0.071440, loss_ce: 0.030675
[23:59:18.854] iteration 4847 : loss : 0.146701, loss_ce: 0.017595
[23:59:19.182] iteration 4848 : loss : 0.081801, loss_ce: 0.014547
[23:59:19.523] iteration 4849 : loss : 0.065956, loss_ce: 0.008221
[23:59:19.838] iteration 4850 : loss : 0.071274, loss_ce: 0.024041
[23:59:20.143] iteration 4851 : loss : 0.077170, loss_ce: 0.019077
[23:59:20.460] iteration 4852 : loss : 0.136663, loss_ce: 0.011287
[23:59:20.766] iteration 4853 : loss : 0.083568, loss_ce: 0.031031
[23:59:21.102] iteration 4854 : loss : 0.059317, loss_ce: 0.017797
[23:59:21.461] iteration 4855 : loss : 0.140615, loss_ce: 0.015353
[23:59:21.769] iteration 4856 : loss : 0.076154, loss_ce: 0.025720
[23:59:22.074] iteration 4857 : loss : 0.079096, loss_ce: 0.019318
[23:59:22.379] iteration 4858 : loss : 0.129668, loss_ce: 0.026436
[23:59:22.691] iteration 4859 : loss : 0.069380, loss_ce: 0.026716
[23:59:23.006] iteration 4860 : loss : 0.051636, loss_ce: 0.010558
[23:59:23.349] iteration 4861 : loss : 0.073327, loss_ce: 0.018454
[23:59:23.654] iteration 4862 : loss : 0.133385, loss_ce: 0.035934
[23:59:23.960] iteration 4863 : loss : 0.089267, loss_ce: 0.032963
[23:59:24.261] iteration 4864 : loss : 0.085851, loss_ce: 0.022999
[23:59:24.338] iteration 4865 : loss : 0.279923, loss_ce: 0.012871
[23:59:50.554] iteration 4866 : loss : 0.085823, loss_ce: 0.042972
[23:59:50.935] iteration 4867 : loss : 0.092389, loss_ce: 0.021178
[23:59:51.302] iteration 4868 : loss : 0.102530, loss_ce: 0.021324
[23:59:51.615] iteration 4869 : loss : 0.077304, loss_ce: 0.032682
[23:59:51.925] iteration 4870 : loss : 0.124402, loss_ce: 0.019833
[23:59:52.229] iteration 4871 : loss : 0.115257, loss_ce: 0.029383
[23:59:52.555] iteration 4872 : loss : 0.087127, loss_ce: 0.030657
[23:59:52.877] iteration 4873 : loss : 0.096427, loss_ce: 0.028060
[23:59:53.196] iteration 4874 : loss : 0.146407, loss_ce: 0.022301
[23:59:53.519] iteration 4875 : loss : 0.067473, loss_ce: 0.021731
[23:59:53.864] iteration 4876 : loss : 0.087868, loss_ce: 0.020648
[23:59:54.201] iteration 4877 : loss : 0.077705, loss_ce: 0.016777
[23:59:54.527] iteration 4878 : loss : 0.083006, loss_ce: 0.035310
[23:59:54.850] iteration 4879 : loss : 0.118219, loss_ce: 0.017390
[23:59:55.167] iteration 4880 : loss : 0.132023, loss_ce: 0.026868
[23:59:55.504] iteration 4881 : loss : 0.125211, loss_ce: 0.032333
[23:59:55.818] iteration 4882 : loss : 0.125531, loss_ce: 0.015014
[23:59:56.140] iteration 4883 : loss : 0.121072, loss_ce: 0.023774
[23:59:56.467] iteration 4884 : loss : 0.075587, loss_ce: 0.012364
[23:59:56.789] iteration 4885 : loss : 0.086330, loss_ce: 0.020487
[23:59:57.107] iteration 4886 : loss : 0.128088, loss_ce: 0.020722
[23:59:57.431] iteration 4887 : loss : 0.060275, loss_ce: 0.019237
[23:59:57.763] iteration 4888 : loss : 0.067056, loss_ce: 0.020897
[23:59:58.099] iteration 4889 : loss : 0.084040, loss_ce: 0.022241
[23:59:58.425] iteration 4890 : loss : 0.093540, loss_ce: 0.037985
[23:59:58.736] iteration 4891 : loss : 0.190116, loss_ce: 0.009122
[23:59:59.053] iteration 4892 : loss : 0.076543, loss_ce: 0.017831
[23:59:59.390] iteration 4893 : loss : 0.123351, loss_ce: 0.023124
[23:59:59.712] iteration 4894 : loss : 0.108154, loss_ce: 0.024117
[00:00:00.041] iteration 4895 : loss : 0.058576, loss_ce: 0.010387
[00:00:00.363] iteration 4896 : loss : 0.082502, loss_ce: 0.028688
[00:00:00.697] iteration 4897 : loss : 0.116650, loss_ce: 0.032311
[00:00:01.024] iteration 4898 : loss : 0.066311, loss_ce: 0.025024
[00:00:01.345] iteration 4899 : loss : 0.076398, loss_ce: 0.022276
[00:00:01.666] iteration 4900 : loss : 0.066307, loss_ce: 0.023418
[00:00:02.009] iteration 4901 : loss : 0.093689, loss_ce: 0.041697
[00:00:02.329] iteration 4902 : loss : 0.091109, loss_ce: 0.024241
[00:00:02.668] iteration 4903 : loss : 0.172708, loss_ce: 0.026216
[00:00:02.992] iteration 4904 : loss : 0.118436, loss_ce: 0.016278
[00:00:03.323] iteration 4905 : loss : 0.130354, loss_ce: 0.018485
[00:00:03.649] iteration 4906 : loss : 0.088232, loss_ce: 0.009071
[00:00:03.984] iteration 4907 : loss : 0.053541, loss_ce: 0.012599
[00:00:04.307] iteration 4908 : loss : 0.063425, loss_ce: 0.025169
[00:00:04.636] iteration 4909 : loss : 0.091820, loss_ce: 0.026817
[00:00:04.963] iteration 4910 : loss : 0.171836, loss_ce: 0.009366
[00:00:05.287] iteration 4911 : loss : 0.067209, loss_ce: 0.021600
[00:00:05.617] iteration 4912 : loss : 0.057993, loss_ce: 0.008231
[00:00:05.948] iteration 4913 : loss : 0.068885, loss_ce: 0.013485
[00:00:06.279] iteration 4914 : loss : 0.064404, loss_ce: 0.021609
[00:00:06.600] iteration 4915 : loss : 0.069852, loss_ce: 0.019535
[00:00:06.926] iteration 4916 : loss : 0.089106, loss_ce: 0.022542
[00:00:07.250] iteration 4917 : loss : 0.114816, loss_ce: 0.013494
[00:00:07.571] iteration 4918 : loss : 0.128854, loss_ce: 0.022938
[00:00:07.899] iteration 4919 : loss : 0.076147, loss_ce: 0.014306
[00:00:08.228] iteration 4920 : loss : 0.171256, loss_ce: 0.013530
[00:00:08.571] iteration 4921 : loss : 0.111924, loss_ce: 0.014090
[00:00:08.907] iteration 4922 : loss : 0.081880, loss_ce: 0.025882
[00:00:09.242] iteration 4923 : loss : 0.059396, loss_ce: 0.014989
[00:00:09.568] iteration 4924 : loss : 0.077384, loss_ce: 0.033939
[00:00:09.894] iteration 4925 : loss : 0.086399, loss_ce: 0.020877
[00:00:10.225] iteration 4926 : loss : 0.086134, loss_ce: 0.014502
[00:00:10.559] iteration 4927 : loss : 0.077221, loss_ce: 0.028111
[00:00:10.894] iteration 4928 : loss : 0.079977, loss_ce: 0.027929
[00:00:11.216] iteration 4929 : loss : 0.084353, loss_ce: 0.015064
[00:00:11.544] iteration 4930 : loss : 0.118689, loss_ce: 0.015320
[00:00:11.866] iteration 4931 : loss : 0.112833, loss_ce: 0.016442
[00:00:12.184] iteration 4932 : loss : 0.080624, loss_ce: 0.017751
[00:00:12.507] iteration 4933 : loss : 0.059465, loss_ce: 0.016998
[00:00:12.827] iteration 4934 : loss : 0.086420, loss_ce: 0.034057
[00:00:13.143] iteration 4935 : loss : 0.158436, loss_ce: 0.018329
[00:00:13.463] iteration 4936 : loss : 0.072955, loss_ce: 0.025673
[00:00:13.786] iteration 4937 : loss : 0.121175, loss_ce: 0.016894
[00:00:14.105] iteration 4938 : loss : 0.116522, loss_ce: 0.024809
[00:00:14.425] iteration 4939 : loss : 0.071836, loss_ce: 0.022912
[00:00:14.746] iteration 4940 : loss : 0.130723, loss_ce: 0.023098
[00:00:15.082] iteration 4941 : loss : 0.071246, loss_ce: 0.029882
[00:00:15.406] iteration 4942 : loss : 0.164458, loss_ce: 0.012989
[00:00:15.728] iteration 4943 : loss : 0.090570, loss_ce: 0.018834
[00:00:16.050] iteration 4944 : loss : 0.127210, loss_ce: 0.009854
[00:00:16.377] iteration 4945 : loss : 0.075276, loss_ce: 0.042700
[00:00:16.702] iteration 4946 : loss : 0.069961, loss_ce: 0.024849
[00:00:17.032] iteration 4947 : loss : 0.074810, loss_ce: 0.025259
[00:00:17.361] iteration 4948 : loss : 0.069178, loss_ce: 0.026199
[00:00:17.685] iteration 4949 : loss : 0.078244, loss_ce: 0.023751
[00:00:18.010] iteration 4950 : loss : 0.082966, loss_ce: 0.020825
[00:00:18.332] iteration 4951 : loss : 0.114533, loss_ce: 0.018938
[00:00:18.658] iteration 4952 : loss : 0.060591, loss_ce: 0.023493
[00:00:18.990] iteration 4953 : loss : 0.072907, loss_ce: 0.024225
[00:00:19.330] iteration 4954 : loss : 0.076763, loss_ce: 0.034055
[00:00:19.651] iteration 4955 : loss : 0.067401, loss_ce: 0.025934
[00:00:19.979] iteration 4956 : loss : 0.078164, loss_ce: 0.019933
[00:00:20.308] iteration 4957 : loss : 0.124485, loss_ce: 0.019957
[00:00:20.638] iteration 4958 : loss : 0.080597, loss_ce: 0.028844
[00:00:20.967] iteration 4959 : loss : 0.076234, loss_ce: 0.026189
[00:00:21.289] iteration 4960 : loss : 0.083464, loss_ce: 0.017227
[00:00:21.632] iteration 4961 : loss : 0.117582, loss_ce: 0.017690
[00:00:21.948] iteration 4962 : loss : 0.085742, loss_ce: 0.008868
[00:00:22.284] iteration 4963 : loss : 0.057300, loss_ce: 0.029574
[00:00:22.606] iteration 4964 : loss : 0.088082, loss_ce: 0.027753
[00:00:22.932] iteration 4965 : loss : 0.292892, loss_ce: 0.013995
[00:00:23.253] iteration 4966 : loss : 0.073455, loss_ce: 0.018391
[00:00:23.579] iteration 4967 : loss : 0.115532, loss_ce: 0.032211
[00:00:23.898] iteration 4968 : loss : 0.089788, loss_ce: 0.023242
[00:00:24.229] iteration 4969 : loss : 0.064022, loss_ce: 0.026750
[00:00:24.546] iteration 4970 : loss : 0.093145, loss_ce: 0.010321
[00:00:24.863] iteration 4971 : loss : 0.116417, loss_ce: 0.032666
[00:00:25.188] iteration 4972 : loss : 0.071419, loss_ce: 0.032828
[00:00:25.510] iteration 4973 : loss : 0.062003, loss_ce: 0.016528
[00:00:25.831] iteration 4974 : loss : 0.095293, loss_ce: 0.036277
[00:00:26.157] iteration 4975 : loss : 0.078801, loss_ce: 0.022208
[00:00:26.481] iteration 4976 : loss : 0.070783, loss_ce: 0.025982
[00:00:26.800] iteration 4977 : loss : 0.146411, loss_ce: 0.017994
[00:00:27.118] iteration 4978 : loss : 0.092656, loss_ce: 0.023869
[00:00:27.442] iteration 4979 : loss : 0.077027, loss_ce: 0.018156
[00:00:27.759] iteration 4980 : loss : 0.138933, loss_ce: 0.006376
[00:00:28.096] iteration 4981 : loss : 0.070630, loss_ce: 0.027881
[00:00:28.415] iteration 4982 : loss : 0.103977, loss_ce: 0.026607
[00:00:28.745] iteration 4983 : loss : 0.128110, loss_ce: 0.015472
[00:00:29.063] iteration 4984 : loss : 0.167551, loss_ce: 0.014608
[00:00:29.381] iteration 4985 : loss : 0.088575, loss_ce: 0.033504
[00:00:29.703] iteration 4986 : loss : 0.070002, loss_ce: 0.008389
[00:00:30.022] iteration 4987 : loss : 0.077331, loss_ce: 0.028814
[00:00:30.348] iteration 4988 : loss : 0.077225, loss_ce: 0.031393
[00:00:30.673] iteration 4989 : loss : 0.080205, loss_ce: 0.008711
[00:00:30.995] iteration 4990 : loss : 0.129569, loss_ce: 0.013192
[00:00:31.330] iteration 4991 : loss : 0.084079, loss_ce: 0.024738
[00:00:31.656] iteration 4992 : loss : 0.175621, loss_ce: 0.014942
[00:00:31.979] iteration 4993 : loss : 0.061326, loss_ce: 0.016983
[00:00:32.315] iteration 4994 : loss : 0.068407, loss_ce: 0.017876
[00:00:32.641] iteration 4995 : loss : 0.068407, loss_ce: 0.020122
[00:00:32.962] iteration 4996 : loss : 0.072119, loss_ce: 0.020793
[00:00:33.297] iteration 4997 : loss : 0.122967, loss_ce: 0.018550
[00:00:33.622] iteration 4998 : loss : 0.127593, loss_ce: 0.011525
[00:00:33.945] iteration 4999 : loss : 0.090492, loss_ce: 0.019831
[00:00:34.274] iteration 5000 : loss : 0.060779, loss_ce: 0.011751
[00:00:34.644] iteration 5001 : loss : 0.057670, loss_ce: 0.019682
[00:00:34.969] iteration 5002 : loss : 0.104270, loss_ce: 0.020836
[00:00:35.301] iteration 5003 : loss : 0.069760, loss_ce: 0.028089
[00:00:35.382] iteration 5004 : loss : 0.236334, loss_ce: 0.014221
[00:00:54.772] iteration 5005 : loss : 0.057705, loss_ce: 0.023955
[00:00:55.094] iteration 5006 : loss : 0.071985, loss_ce: 0.022713
[00:00:55.410] iteration 5007 : loss : 0.065581, loss_ce: 0.021467
[00:00:55.735] iteration 5008 : loss : 0.097598, loss_ce: 0.034112
[00:00:56.061] iteration 5009 : loss : 0.163810, loss_ce: 0.020506
[00:00:56.381] iteration 5010 : loss : 0.136836, loss_ce: 0.018812
[00:00:56.700] iteration 5011 : loss : 0.083007, loss_ce: 0.027460
[00:00:57.020] iteration 5012 : loss : 0.088133, loss_ce: 0.026579
[00:00:57.336] iteration 5013 : loss : 0.076793, loss_ce: 0.015205
[00:00:57.654] iteration 5014 : loss : 0.098254, loss_ce: 0.028129
[00:00:57.973] iteration 5015 : loss : 0.079701, loss_ce: 0.021554
[00:00:58.298] iteration 5016 : loss : 0.081207, loss_ce: 0.018601
[00:00:58.620] iteration 5017 : loss : 0.073397, loss_ce: 0.016359
[00:00:58.945] iteration 5018 : loss : 0.086773, loss_ce: 0.041615
[00:00:59.267] iteration 5019 : loss : 0.086681, loss_ce: 0.017110
[00:00:59.586] iteration 5020 : loss : 0.090636, loss_ce: 0.023582
[00:00:59.968] iteration 5021 : loss : 0.133705, loss_ce: 0.014031
[00:01:00.297] iteration 5022 : loss : 0.084029, loss_ce: 0.027762
[00:01:00.633] iteration 5023 : loss : 0.076051, loss_ce: 0.026492
[00:01:00.957] iteration 5024 : loss : 0.070888, loss_ce: 0.017160
[00:01:01.284] iteration 5025 : loss : 0.067674, loss_ce: 0.015256
[00:01:01.608] iteration 5026 : loss : 0.119278, loss_ce: 0.020833
[00:01:01.936] iteration 5027 : loss : 0.071333, loss_ce: 0.025610
[00:01:02.275] iteration 5028 : loss : 0.090808, loss_ce: 0.023904
[00:01:02.598] iteration 5029 : loss : 0.116537, loss_ce: 0.013362
[00:01:02.954] iteration 5030 : loss : 0.092814, loss_ce: 0.030697
[00:01:03.279] iteration 5031 : loss : 0.067087, loss_ce: 0.020297
[00:01:03.597] iteration 5032 : loss : 0.080587, loss_ce: 0.017740
[00:01:03.923] iteration 5033 : loss : 0.115493, loss_ce: 0.021199
[00:01:04.248] iteration 5034 : loss : 0.050525, loss_ce: 0.013254
[00:01:04.570] iteration 5035 : loss : 0.130904, loss_ce: 0.037749
[00:01:04.906] iteration 5036 : loss : 0.083923, loss_ce: 0.019887
[00:01:05.240] iteration 5037 : loss : 0.093883, loss_ce: 0.020603
[00:01:05.571] iteration 5038 : loss : 0.072946, loss_ce: 0.022643
[00:01:05.891] iteration 5039 : loss : 0.072666, loss_ce: 0.026923
[00:01:06.218] iteration 5040 : loss : 0.074222, loss_ce: 0.016495
[00:01:06.569] iteration 5041 : loss : 0.054639, loss_ce: 0.014670
[00:01:06.890] iteration 5042 : loss : 0.077008, loss_ce: 0.019151
[00:01:07.214] iteration 5043 : loss : 0.118171, loss_ce: 0.021569
[00:01:07.528] iteration 5044 : loss : 0.127957, loss_ce: 0.014418
[00:01:07.849] iteration 5045 : loss : 0.073705, loss_ce: 0.025711
[00:01:08.174] iteration 5046 : loss : 0.078639, loss_ce: 0.023897
[00:01:08.496] iteration 5047 : loss : 0.077525, loss_ce: 0.014680
[00:01:08.819] iteration 5048 : loss : 0.090545, loss_ce: 0.008057
[00:01:09.143] iteration 5049 : loss : 0.062984, loss_ce: 0.028040
[00:01:09.460] iteration 5050 : loss : 0.130760, loss_ce: 0.006609
[00:01:09.780] iteration 5051 : loss : 0.070475, loss_ce: 0.025780
[00:01:10.101] iteration 5052 : loss : 0.107117, loss_ce: 0.041180
[00:01:10.427] iteration 5053 : loss : 0.055224, loss_ce: 0.014239
[00:01:10.747] iteration 5054 : loss : 0.114083, loss_ce: 0.008441
[00:01:11.065] iteration 5055 : loss : 0.129486, loss_ce: 0.028997
[00:01:11.388] iteration 5056 : loss : 0.065963, loss_ce: 0.024187
[00:01:11.708] iteration 5057 : loss : 0.074625, loss_ce: 0.014844
[00:01:12.022] iteration 5058 : loss : 0.076478, loss_ce: 0.032595
[00:01:12.344] iteration 5059 : loss : 0.075472, loss_ce: 0.022241
[00:01:12.675] iteration 5060 : loss : 0.091696, loss_ce: 0.026584
[00:01:13.017] iteration 5061 : loss : 0.084498, loss_ce: 0.022887
[00:01:13.336] iteration 5062 : loss : 0.053233, loss_ce: 0.016070
[00:01:13.663] iteration 5063 : loss : 0.075939, loss_ce: 0.026798
[00:01:13.978] iteration 5064 : loss : 0.138323, loss_ce: 0.007467
[00:01:14.299] iteration 5065 : loss : 0.113606, loss_ce: 0.018210
[00:01:14.622] iteration 5066 : loss : 0.100782, loss_ce: 0.013665
[00:01:14.940] iteration 5067 : loss : 0.082450, loss_ce: 0.022990
[00:01:15.265] iteration 5068 : loss : 0.075757, loss_ce: 0.009675
[00:01:15.592] iteration 5069 : loss : 0.075226, loss_ce: 0.025925
[00:01:15.910] iteration 5070 : loss : 0.078598, loss_ce: 0.017981
[00:01:16.232] iteration 5071 : loss : 0.138988, loss_ce: 0.022787
[00:01:16.556] iteration 5072 : loss : 0.083455, loss_ce: 0.019867
[00:01:16.878] iteration 5073 : loss : 0.065817, loss_ce: 0.028974
[00:01:17.198] iteration 5074 : loss : 0.076876, loss_ce: 0.019362
[00:01:17.522] iteration 5075 : loss : 0.075746, loss_ce: 0.038439
[00:01:17.840] iteration 5076 : loss : 0.072137, loss_ce: 0.019804
[00:01:18.168] iteration 5077 : loss : 0.094878, loss_ce: 0.035162
[00:01:18.489] iteration 5078 : loss : 0.079017, loss_ce: 0.024094
[00:01:18.808] iteration 5079 : loss : 0.135974, loss_ce: 0.030204
[00:01:19.129] iteration 5080 : loss : 0.119185, loss_ce: 0.014280
[00:01:19.466] iteration 5081 : loss : 0.111819, loss_ce: 0.026888
[00:01:19.793] iteration 5082 : loss : 0.079968, loss_ce: 0.029791
[00:01:20.120] iteration 5083 : loss : 0.082587, loss_ce: 0.027396
[00:01:20.452] iteration 5084 : loss : 0.059032, loss_ce: 0.017139
[00:01:20.775] iteration 5085 : loss : 0.073262, loss_ce: 0.011472
[00:01:21.093] iteration 5086 : loss : 0.085299, loss_ce: 0.030566
[00:01:21.435] iteration 5087 : loss : 0.071782, loss_ce: 0.012904
[00:01:21.768] iteration 5088 : loss : 0.136127, loss_ce: 0.021991
[00:01:22.099] iteration 5089 : loss : 0.073063, loss_ce: 0.026561
[00:01:22.466] iteration 5090 : loss : 0.092506, loss_ce: 0.017857
[00:01:22.816] iteration 5091 : loss : 0.069420, loss_ce: 0.026830
[00:01:23.152] iteration 5092 : loss : 0.238117, loss_ce: 0.010279
[00:01:23.498] iteration 5093 : loss : 0.149162, loss_ce: 0.019477
[00:01:23.828] iteration 5094 : loss : 0.100890, loss_ce: 0.042119
[00:01:24.153] iteration 5095 : loss : 0.117313, loss_ce: 0.015513
[00:01:24.490] iteration 5096 : loss : 0.074983, loss_ce: 0.020384
[00:01:24.806] iteration 5097 : loss : 0.060619, loss_ce: 0.022285
[00:01:25.124] iteration 5098 : loss : 0.059475, loss_ce: 0.024485
[00:01:25.452] iteration 5099 : loss : 0.079037, loss_ce: 0.028451
[00:01:25.791] iteration 5100 : loss : 0.096369, loss_ce: 0.023499
[00:01:26.153] iteration 5101 : loss : 0.070135, loss_ce: 0.033537
[00:01:26.467] iteration 5102 : loss : 0.063625, loss_ce: 0.013927
[00:01:26.797] iteration 5103 : loss : 0.122797, loss_ce: 0.013198
[00:01:27.116] iteration 5104 : loss : 0.083940, loss_ce: 0.020566
[00:01:27.457] iteration 5105 : loss : 0.067541, loss_ce: 0.017111
[00:01:27.780] iteration 5106 : loss : 0.141337, loss_ce: 0.017701
[00:01:28.097] iteration 5107 : loss : 0.073833, loss_ce: 0.022353
[00:01:28.423] iteration 5108 : loss : 0.051651, loss_ce: 0.012498
[00:01:28.742] iteration 5109 : loss : 0.070959, loss_ce: 0.026761
[00:01:29.076] iteration 5110 : loss : 0.095139, loss_ce: 0.030890
[00:01:29.415] iteration 5111 : loss : 0.069378, loss_ce: 0.021130
[00:01:29.765] iteration 5112 : loss : 0.070511, loss_ce: 0.022591
[00:01:30.108] iteration 5113 : loss : 0.088333, loss_ce: 0.038751
[00:01:30.453] iteration 5114 : loss : 0.124570, loss_ce: 0.013834
[00:01:30.772] iteration 5115 : loss : 0.065505, loss_ce: 0.022334
[00:01:31.084] iteration 5116 : loss : 0.127260, loss_ce: 0.007937
[00:01:31.416] iteration 5117 : loss : 0.104208, loss_ce: 0.018163
[00:01:31.767] iteration 5118 : loss : 0.117650, loss_ce: 0.019421
[00:01:32.111] iteration 5119 : loss : 0.064820, loss_ce: 0.013629
[00:01:32.493] iteration 5120 : loss : 0.073115, loss_ce: 0.014431
[00:01:32.920] iteration 5121 : loss : 0.093466, loss_ce: 0.032980
[00:01:33.257] iteration 5122 : loss : 0.057226, loss_ce: 0.006856
[00:01:33.607] iteration 5123 : loss : 0.068879, loss_ce: 0.029301
[00:01:33.949] iteration 5124 : loss : 0.173553, loss_ce: 0.014856
[00:01:34.280] iteration 5125 : loss : 0.078585, loss_ce: 0.020035
[00:01:34.621] iteration 5126 : loss : 0.076416, loss_ce: 0.019648
[00:01:34.949] iteration 5127 : loss : 0.076076, loss_ce: 0.021882
[00:01:35.275] iteration 5128 : loss : 0.064317, loss_ce: 0.019678
[00:01:35.597] iteration 5129 : loss : 0.077787, loss_ce: 0.028071
[00:01:35.925] iteration 5130 : loss : 0.094267, loss_ce: 0.019937
[00:01:36.256] iteration 5131 : loss : 0.095080, loss_ce: 0.017207
[00:01:36.575] iteration 5132 : loss : 0.140972, loss_ce: 0.016541
[00:01:36.897] iteration 5133 : loss : 0.079134, loss_ce: 0.020973
[00:01:37.228] iteration 5134 : loss : 0.065350, loss_ce: 0.024003
[00:01:37.546] iteration 5135 : loss : 0.090242, loss_ce: 0.017640
[00:01:37.872] iteration 5136 : loss : 0.095291, loss_ce: 0.011344
[00:01:38.200] iteration 5137 : loss : 0.225494, loss_ce: 0.018969
[00:01:38.531] iteration 5138 : loss : 0.085224, loss_ce: 0.016850
[00:01:38.860] iteration 5139 : loss : 0.102871, loss_ce: 0.035563
[00:01:39.180] iteration 5140 : loss : 0.222739, loss_ce: 0.004574
[00:01:39.525] iteration 5141 : loss : 0.071823, loss_ce: 0.028668
[00:01:39.852] iteration 5142 : loss : 0.074559, loss_ce: 0.017820
[00:01:39.935] iteration 5143 : loss : 0.099413, loss_ce: 0.039429
[00:01:59.739] iteration 5144 : loss : 0.104697, loss_ce: 0.019842
[00:02:00.055] iteration 5145 : loss : 0.078331, loss_ce: 0.020853
[00:02:00.375] iteration 5146 : loss : 0.098511, loss_ce: 0.017915
[00:02:00.703] iteration 5147 : loss : 0.090080, loss_ce: 0.016644
[00:02:01.022] iteration 5148 : loss : 0.073259, loss_ce: 0.017053
[00:02:01.336] iteration 5149 : loss : 0.088441, loss_ce: 0.015778
[00:02:01.661] iteration 5150 : loss : 0.186730, loss_ce: 0.013036
[00:02:01.983] iteration 5151 : loss : 0.076247, loss_ce: 0.024622
[00:02:02.300] iteration 5152 : loss : 0.122534, loss_ce: 0.017047
[00:02:02.625] iteration 5153 : loss : 0.188244, loss_ce: 0.011588
[00:02:02.945] iteration 5154 : loss : 0.141263, loss_ce: 0.031458
[00:02:03.261] iteration 5155 : loss : 0.110013, loss_ce: 0.031785
[00:02:03.582] iteration 5156 : loss : 0.074385, loss_ce: 0.024824
[00:02:03.901] iteration 5157 : loss : 0.103489, loss_ce: 0.026688
[00:02:04.225] iteration 5158 : loss : 0.072104, loss_ce: 0.010246
[00:02:04.541] iteration 5159 : loss : 0.127395, loss_ce: 0.023150
[00:02:04.869] iteration 5160 : loss : 0.080372, loss_ce: 0.018476
[00:02:05.215] iteration 5161 : loss : 0.071018, loss_ce: 0.025163
[00:02:05.531] iteration 5162 : loss : 0.093120, loss_ce: 0.034736
[00:02:05.855] iteration 5163 : loss : 0.104275, loss_ce: 0.020173
[00:02:06.180] iteration 5164 : loss : 0.068847, loss_ce: 0.017590
[00:02:06.507] iteration 5165 : loss : 0.073068, loss_ce: 0.026534
[00:02:06.834] iteration 5166 : loss : 0.118003, loss_ce: 0.016364
[00:02:07.161] iteration 5167 : loss : 0.060943, loss_ce: 0.022295
[00:02:07.488] iteration 5168 : loss : 0.183387, loss_ce: 0.018587
[00:02:07.804] iteration 5169 : loss : 0.072308, loss_ce: 0.021471
[00:02:08.142] iteration 5170 : loss : 0.063241, loss_ce: 0.018054
[00:02:08.474] iteration 5171 : loss : 0.074730, loss_ce: 0.021063
[00:02:08.794] iteration 5172 : loss : 0.064192, loss_ce: 0.018838
[00:02:09.140] iteration 5173 : loss : 0.118169, loss_ce: 0.013512
[00:02:09.506] iteration 5174 : loss : 0.074020, loss_ce: 0.030702
[00:02:09.856] iteration 5175 : loss : 0.082133, loss_ce: 0.026939
[00:02:10.200] iteration 5176 : loss : 0.073233, loss_ce: 0.022813
[00:02:10.512] iteration 5177 : loss : 0.061901, loss_ce: 0.019346
[00:02:10.819] iteration 5178 : loss : 0.063204, loss_ce: 0.020386
[00:02:11.148] iteration 5179 : loss : 0.122341, loss_ce: 0.019508
[00:02:11.476] iteration 5180 : loss : 0.083961, loss_ce: 0.025231
[00:02:11.806] iteration 5181 : loss : 0.133919, loss_ce: 0.020435
[00:02:12.132] iteration 5182 : loss : 0.083497, loss_ce: 0.021723
[00:02:12.764] iteration 5183 : loss : 0.055698, loss_ce: 0.020036
[00:02:13.297] iteration 5184 : loss : 0.081660, loss_ce: 0.030855
[00:02:14.715] iteration 5185 : loss : 0.067352, loss_ce: 0.017886
[00:02:15.275] iteration 5186 : loss : 0.064446, loss_ce: 0.019309
[00:02:15.604] iteration 5187 : loss : 0.096723, loss_ce: 0.032382
[00:02:15.937] iteration 5188 : loss : 0.065549, loss_ce: 0.028146
[00:02:16.263] iteration 5189 : loss : 0.109090, loss_ce: 0.015818
[00:02:16.567] iteration 5190 : loss : 0.072768, loss_ce: 0.026314
[00:02:16.942] iteration 5191 : loss : 0.116264, loss_ce: 0.013150
[00:02:17.291] iteration 5192 : loss : 0.225576, loss_ce: 0.009078
[00:02:17.619] iteration 5193 : loss : 0.073744, loss_ce: 0.023942
[00:02:17.939] iteration 5194 : loss : 0.057113, loss_ce: 0.015116
[00:02:18.283] iteration 5195 : loss : 0.070439, loss_ce: 0.011716
[00:02:18.603] iteration 5196 : loss : 0.081864, loss_ce: 0.023272
[00:02:18.935] iteration 5197 : loss : 0.140901, loss_ce: 0.022884
[00:02:19.270] iteration 5198 : loss : 0.078076, loss_ce: 0.027462
[00:02:19.631] iteration 5199 : loss : 0.060037, loss_ce: 0.020940
[00:02:19.977] iteration 5200 : loss : 0.104191, loss_ce: 0.031702
[00:02:20.311] iteration 5201 : loss : 0.079508, loss_ce: 0.027378
[00:02:20.618] iteration 5202 : loss : 0.066870, loss_ce: 0.020326
[00:09:40.763] Namespace(root_path='D:\\data/Synapse/train', dataset='Synapse', list_dir='./lists/lists_Synapse', num_classes=9, output_dir='D:\\data/output', max_iterations=30000, max_epochs=150, batch_size=16, n_gpu=1, deterministic=1, base_lr=0.01, img_size=224, seed=1234, cfg='configs/swin_tiny_patch4_window7_224_lite.yaml', opts=None, zip=False, cache_mode='part', resume=None, accumulation_steps=None, use_checkpoint=False, amp_opt_level='O1', tag=None, eval=False, throughput=False)
[00:09:40.768] 139 iterations per epoch. 20850 max iterations 
[00:10:03.184] iteration 1 : loss : 1.463958, loss_ce: 2.234431
[00:10:03.789] iteration 2 : loss : 1.362587, loss_ce: 2.026518
[00:10:04.062] iteration 3 : loss : 1.207965, loss_ce: 1.637840
[00:10:04.335] iteration 4 : loss : 1.056116, loss_ce: 1.305276
[00:10:04.613] iteration 5 : loss : 0.845675, loss_ce: 0.801525
[00:10:04.889] iteration 6 : loss : 0.746403, loss_ce: 0.569570
[00:10:05.162] iteration 7 : loss : 0.703337, loss_ce: 0.463305
[00:10:05.439] iteration 8 : loss : 0.698379, loss_ce: 0.445791
[00:10:05.724] iteration 9 : loss : 0.649538, loss_ce: 0.313923
[00:10:06.021] iteration 10 : loss : 0.640000, loss_ce: 0.277069
[00:10:06.322] iteration 11 : loss : 0.647168, loss_ce: 0.293086
[00:10:06.611] iteration 12 : loss : 0.651027, loss_ce: 0.299663
[00:10:06.933] iteration 13 : loss : 0.632551, loss_ce: 0.252080
[00:10:07.271] iteration 14 : loss : 0.625255, loss_ce: 0.232934
[00:10:07.560] iteration 15 : loss : 0.627184, loss_ce: 0.236640
[00:10:07.847] iteration 16 : loss : 0.671620, loss_ce: 0.345951
[00:10:08.123] iteration 17 : loss : 0.585180, loss_ce: 0.132364
[00:10:08.404] iteration 18 : loss : 0.667238, loss_ce: 0.334600
[00:10:08.682] iteration 19 : loss : 0.691185, loss_ce: 0.393568
[00:10:08.959] iteration 20 : loss : 0.737733, loss_ce: 0.508338
[00:10:09.270] iteration 21 : loss : 0.648666, loss_ce: 0.288800
[00:10:09.554] iteration 22 : loss : 0.634671, loss_ce: 0.254611
[00:10:09.832] iteration 23 : loss : 0.708587, loss_ce: 0.437456
[00:10:10.114] iteration 24 : loss : 0.611421, loss_ce: 0.197628
[00:10:10.402] iteration 25 : loss : 0.691902, loss_ce: 0.397463
[00:10:10.681] iteration 26 : loss : 0.625170, loss_ce: 0.233867
[00:10:10.971] iteration 27 : loss : 0.668765, loss_ce: 0.343233
[00:10:11.247] iteration 28 : loss : 0.651139, loss_ce: 0.301936
[00:10:11.522] iteration 29 : loss : 0.627878, loss_ce: 0.247455
[00:10:11.828] iteration 30 : loss : 0.606536, loss_ce: 0.198083
[00:10:12.143] iteration 31 : loss : 0.597331, loss_ce: 0.192767
[00:10:12.419] iteration 32 : loss : 0.611812, loss_ce: 0.221483
[00:10:12.723] iteration 33 : loss : 0.654702, loss_ce: 0.343687
[00:10:13.018] iteration 34 : loss : 0.605163, loss_ce: 0.231836
[00:10:13.301] iteration 35 : loss : 0.638844, loss_ce: 0.307441
[00:10:13.612] iteration 36 : loss : 0.648503, loss_ce: 0.336910
[00:10:13.934] iteration 37 : loss : 0.635265, loss_ce: 0.307442
[00:10:14.327] iteration 38 : loss : 0.632995, loss_ce: 0.320540
[00:10:14.647] iteration 39 : loss : 0.579874, loss_ce: 0.184163
[00:10:14.931] iteration 40 : loss : 0.607006, loss_ce: 0.284664
[00:10:15.259] iteration 41 : loss : 0.641639, loss_ce: 0.359823
[00:10:15.558] iteration 42 : loss : 0.589657, loss_ce: 0.241367
[00:10:15.844] iteration 43 : loss : 0.573051, loss_ce: 0.216197
[00:10:16.138] iteration 44 : loss : 0.581050, loss_ce: 0.193696
[00:10:16.423] iteration 45 : loss : 0.586582, loss_ce: 0.199200
[00:10:16.719] iteration 46 : loss : 0.564574, loss_ce: 0.122219
[00:10:17.020] iteration 47 : loss : 0.581776, loss_ce: 0.178824
[00:10:17.321] iteration 48 : loss : 0.580879, loss_ce: 0.223508
[00:10:17.608] iteration 49 : loss : 0.579625, loss_ce: 0.219467
[00:10:17.895] iteration 50 : loss : 0.569268, loss_ce: 0.176484
[00:10:18.174] iteration 51 : loss : 0.602778, loss_ce: 0.282271
[00:10:18.452] iteration 52 : loss : 0.579921, loss_ce: 0.217490
[00:10:18.728] iteration 53 : loss : 0.559823, loss_ce: 0.165776
[00:10:19.008] iteration 54 : loss : 0.573677, loss_ce: 0.188881
[00:10:19.287] iteration 55 : loss : 0.562016, loss_ce: 0.173500
[00:10:19.568] iteration 56 : loss : 0.562084, loss_ce: 0.180559
[00:10:19.862] iteration 57 : loss : 0.564162, loss_ce: 0.139455
[00:10:20.199] iteration 58 : loss : 0.552901, loss_ce: 0.126733
[00:10:20.536] iteration 59 : loss : 0.549418, loss_ce: 0.141934
[00:10:20.842] iteration 60 : loss : 0.580367, loss_ce: 0.202071
[00:10:21.165] iteration 61 : loss : 0.588353, loss_ce: 0.202220
[00:10:21.452] iteration 62 : loss : 0.567914, loss_ce: 0.162546
[00:10:21.753] iteration 63 : loss : 0.591278, loss_ce: 0.264510
[00:10:22.069] iteration 64 : loss : 0.572738, loss_ce: 0.200188
[00:10:22.393] iteration 65 : loss : 0.567481, loss_ce: 0.193800
[00:10:22.688] iteration 66 : loss : 0.571640, loss_ce: 0.195996
[00:10:22.990] iteration 67 : loss : 0.559889, loss_ce: 0.158492
[00:10:23.266] iteration 68 : loss : 0.560371, loss_ce: 0.151213
[00:10:23.555] iteration 69 : loss : 0.588096, loss_ce: 0.217063
[00:10:23.851] iteration 70 : loss : 0.564510, loss_ce: 0.151472
[00:10:24.157] iteration 71 : loss : 0.560092, loss_ce: 0.162318
[00:10:24.471] iteration 72 : loss : 0.570533, loss_ce: 0.201379
[00:10:24.758] iteration 73 : loss : 0.581310, loss_ce: 0.237166
[00:10:25.070] iteration 74 : loss : 0.563106, loss_ce: 0.188789
[00:10:25.354] iteration 75 : loss : 0.556645, loss_ce: 0.181938
[00:10:25.666] iteration 76 : loss : 0.555855, loss_ce: 0.198353
[00:10:25.949] iteration 77 : loss : 0.551091, loss_ce: 0.132894
[00:10:26.254] iteration 78 : loss : 0.555725, loss_ce: 0.163820
[00:10:26.542] iteration 79 : loss : 0.563963, loss_ce: 0.154362
[00:10:26.855] iteration 80 : loss : 0.539982, loss_ce: 0.148032
[00:10:27.180] iteration 81 : loss : 0.541317, loss_ce: 0.148877
[00:10:27.460] iteration 82 : loss : 0.569418, loss_ce: 0.211314
[00:10:27.775] iteration 83 : loss : 0.578086, loss_ce: 0.198829
[00:10:28.098] iteration 84 : loss : 0.564605, loss_ce: 0.194586
[00:10:28.379] iteration 85 : loss : 0.564097, loss_ce: 0.190747
[00:10:28.708] iteration 86 : loss : 0.556343, loss_ce: 0.179120
[00:10:28.986] iteration 87 : loss : 0.569517, loss_ce: 0.205773
[00:10:29.264] iteration 88 : loss : 0.554096, loss_ce: 0.150855
[00:10:29.543] iteration 89 : loss : 0.578922, loss_ce: 0.211140
[00:10:29.833] iteration 90 : loss : 0.550226, loss_ce: 0.131443
[00:10:30.122] iteration 91 : loss : 0.588697, loss_ce: 0.243887
[00:10:30.401] iteration 92 : loss : 0.568296, loss_ce: 0.212048
[00:10:30.678] iteration 93 : loss : 0.544131, loss_ce: 0.166399
[00:10:30.969] iteration 94 : loss : 0.549765, loss_ce: 0.175324
[00:10:31.250] iteration 95 : loss : 0.530327, loss_ce: 0.106178
[00:10:31.528] iteration 96 : loss : 0.566567, loss_ce: 0.144061
[00:10:31.824] iteration 97 : loss : 0.550174, loss_ce: 0.143650
[00:10:32.131] iteration 98 : loss : 0.559710, loss_ce: 0.168630
[00:10:32.410] iteration 99 : loss : 0.558768, loss_ce: 0.198590
[00:10:32.694] iteration 100 : loss : 0.564096, loss_ce: 0.249145
[00:10:32.985] iteration 101 : loss : 0.579532, loss_ce: 0.265283
[00:10:33.266] iteration 102 : loss : 0.561266, loss_ce: 0.228468
[00:10:33.545] iteration 103 : loss : 0.544898, loss_ce: 0.153794
[00:10:33.827] iteration 104 : loss : 0.567579, loss_ce: 0.181216
[00:10:34.109] iteration 105 : loss : 0.560783, loss_ce: 0.134331
[00:10:34.389] iteration 106 : loss : 0.579971, loss_ce: 0.208285
[00:10:34.673] iteration 107 : loss : 0.559117, loss_ce: 0.165989
[00:10:34.952] iteration 108 : loss : 0.546548, loss_ce: 0.188109
[00:10:35.232] iteration 109 : loss : 0.561708, loss_ce: 0.185925
[00:10:35.511] iteration 110 : loss : 0.554799, loss_ce: 0.214870
[00:10:35.793] iteration 111 : loss : 0.555516, loss_ce: 0.206036
[00:10:36.080] iteration 112 : loss : 0.559461, loss_ce: 0.205851
[00:10:36.363] iteration 113 : loss : 0.547860, loss_ce: 0.134178
[00:10:36.641] iteration 114 : loss : 0.573065, loss_ce: 0.153832
[00:10:36.973] iteration 115 : loss : 0.576159, loss_ce: 0.195848
[00:10:37.321] iteration 116 : loss : 0.542486, loss_ce: 0.121735
[00:10:37.631] iteration 117 : loss : 0.557137, loss_ce: 0.201206
[00:10:37.914] iteration 118 : loss : 0.543947, loss_ce: 0.167893
[00:10:38.194] iteration 119 : loss : 0.557026, loss_ce: 0.221740
[00:10:38.478] iteration 120 : loss : 0.552010, loss_ce: 0.203063
[00:10:38.795] iteration 121 : loss : 0.537632, loss_ce: 0.148484
[00:10:39.074] iteration 122 : loss : 0.549326, loss_ce: 0.141445
[00:10:39.357] iteration 123 : loss : 0.600902, loss_ce: 0.247641
[00:10:39.638] iteration 124 : loss : 0.554901, loss_ce: 0.174684
[00:10:39.919] iteration 125 : loss : 0.539229, loss_ce: 0.176804
[00:10:40.207] iteration 126 : loss : 0.547471, loss_ce: 0.196593
[00:10:40.487] iteration 127 : loss : 0.563967, loss_ce: 0.203540
[00:10:40.763] iteration 128 : loss : 0.554003, loss_ce: 0.209760
[00:10:41.049] iteration 129 : loss : 0.541855, loss_ce: 0.157431
[00:10:41.336] iteration 130 : loss : 0.553956, loss_ce: 0.167509
[00:10:41.620] iteration 131 : loss : 0.571342, loss_ce: 0.235527
[00:10:41.933] iteration 132 : loss : 0.538581, loss_ce: 0.154098
[00:10:42.242] iteration 133 : loss : 0.524625, loss_ce: 0.138659
[00:10:42.523] iteration 134 : loss : 0.523074, loss_ce: 0.134470
[00:10:42.809] iteration 135 : loss : 0.528824, loss_ce: 0.116179
[00:10:43.086] iteration 136 : loss : 0.554399, loss_ce: 0.205957
[00:10:43.403] iteration 137 : loss : 0.563856, loss_ce: 0.181810
[00:10:43.712] iteration 138 : loss : 0.518570, loss_ce: 0.130090
[00:10:43.805] iteration 139 : loss : 0.517769, loss_ce: 0.157201
[00:11:02.525] iteration 140 : loss : 0.541158, loss_ce: 0.198491
[00:11:02.824] iteration 141 : loss : 0.531142, loss_ce: 0.169068
[00:11:03.113] iteration 142 : loss : 0.527159, loss_ce: 0.153046
[00:11:03.401] iteration 143 : loss : 0.524373, loss_ce: 0.132997
[00:11:03.681] iteration 144 : loss : 0.531914, loss_ce: 0.159220
[00:11:03.976] iteration 145 : loss : 0.508788, loss_ce: 0.130987
[00:11:04.255] iteration 146 : loss : 0.525316, loss_ce: 0.152663
[00:11:04.541] iteration 147 : loss : 0.498455, loss_ce: 0.084460
[00:11:04.828] iteration 148 : loss : 0.552354, loss_ce: 0.240407
[00:11:05.124] iteration 149 : loss : 0.522992, loss_ce: 0.173707
[00:11:05.419] iteration 150 : loss : 0.517648, loss_ce: 0.103578
[00:11:05.736] iteration 151 : loss : 0.544543, loss_ce: 0.151744
[00:11:06.028] iteration 152 : loss : 0.508039, loss_ce: 0.127851
[00:11:06.312] iteration 153 : loss : 0.538643, loss_ce: 0.175406
[00:11:06.595] iteration 154 : loss : 0.551911, loss_ce: 0.194065
[00:11:06.905] iteration 155 : loss : 0.535330, loss_ce: 0.207807
[00:11:07.216] iteration 156 : loss : 0.533738, loss_ce: 0.201429
[00:11:07.502] iteration 157 : loss : 0.518206, loss_ce: 0.137265
[00:11:07.796] iteration 158 : loss : 0.515552, loss_ce: 0.102589
[00:11:08.082] iteration 159 : loss : 0.542862, loss_ce: 0.135484
[00:11:08.358] iteration 160 : loss : 0.509241, loss_ce: 0.138975
[00:11:08.654] iteration 161 : loss : 0.517155, loss_ce: 0.126072
[00:11:08.932] iteration 162 : loss : 0.526598, loss_ce: 0.143490
[00:11:09.211] iteration 163 : loss : 0.509337, loss_ce: 0.120805
[00:11:09.494] iteration 164 : loss : 0.520610, loss_ce: 0.157170
[00:11:09.771] iteration 165 : loss : 0.524298, loss_ce: 0.182873
[00:11:10.054] iteration 166 : loss : 0.497088, loss_ce: 0.108030
[00:11:10.334] iteration 167 : loss : 0.519055, loss_ce: 0.104485
[00:11:10.616] iteration 168 : loss : 0.502980, loss_ce: 0.087909
[00:11:10.894] iteration 169 : loss : 0.548029, loss_ce: 0.178869
[00:11:11.174] iteration 170 : loss : 0.557714, loss_ce: 0.276812
[00:11:11.452] iteration 171 : loss : 0.537840, loss_ce: 0.212024
[00:11:11.734] iteration 172 : loss : 0.532839, loss_ce: 0.184562
[00:11:12.050] iteration 173 : loss : 0.552013, loss_ce: 0.236132
[00:11:12.332] iteration 174 : loss : 0.552760, loss_ce: 0.214476
[00:11:12.611] iteration 175 : loss : 0.502505, loss_ce: 0.105955
[00:11:12.889] iteration 176 : loss : 0.521307, loss_ce: 0.164991
[00:11:13.170] iteration 177 : loss : 0.516416, loss_ce: 0.124105
[00:11:13.447] iteration 178 : loss : 0.545045, loss_ce: 0.191534
[00:11:13.725] iteration 179 : loss : 0.538828, loss_ce: 0.227804
[00:11:14.032] iteration 180 : loss : 0.522908, loss_ce: 0.182877
[00:11:14.335] iteration 181 : loss : 0.527647, loss_ce: 0.123068
[00:11:14.613] iteration 182 : loss : 0.497905, loss_ce: 0.073401
[00:11:14.891] iteration 183 : loss : 0.539369, loss_ce: 0.154232
[00:11:15.179] iteration 184 : loss : 0.505891, loss_ce: 0.124434
[00:11:15.473] iteration 185 : loss : 0.514696, loss_ce: 0.163566
[00:11:15.758] iteration 186 : loss : 0.547509, loss_ce: 0.218195
[00:11:16.037] iteration 187 : loss : 0.517704, loss_ce: 0.166138
[00:11:16.316] iteration 188 : loss : 0.524765, loss_ce: 0.168329
[00:11:16.606] iteration 189 : loss : 0.511183, loss_ce: 0.106170
[00:11:16.919] iteration 190 : loss : 0.528156, loss_ce: 0.115619
[00:11:17.241] iteration 191 : loss : 0.505883, loss_ce: 0.116124
[00:11:17.545] iteration 192 : loss : 0.538600, loss_ce: 0.152248
[00:11:17.846] iteration 193 : loss : 0.502427, loss_ce: 0.111848
[00:11:18.132] iteration 194 : loss : 0.534408, loss_ce: 0.172483
[00:11:18.411] iteration 195 : loss : 0.523625, loss_ce: 0.184821
[00:11:18.690] iteration 196 : loss : 0.530280, loss_ce: 0.184986
[00:11:18.976] iteration 197 : loss : 0.504227, loss_ce: 0.112617
[00:11:19.259] iteration 198 : loss : 0.540445, loss_ce: 0.150380
[00:11:19.552] iteration 199 : loss : 0.522594, loss_ce: 0.123342
[00:11:19.853] iteration 200 : loss : 0.500230, loss_ce: 0.086612
[00:11:20.153] iteration 201 : loss : 0.496677, loss_ce: 0.108501
[00:11:20.441] iteration 202 : loss : 0.499741, loss_ce: 0.108399
[00:11:20.723] iteration 203 : loss : 0.500360, loss_ce: 0.131312
[00:11:21.004] iteration 204 : loss : 0.513713, loss_ce: 0.155715
[00:11:21.290] iteration 205 : loss : 0.517234, loss_ce: 0.150461
[00:11:21.614] iteration 206 : loss : 0.520333, loss_ce: 0.177357
[00:11:21.934] iteration 207 : loss : 0.530258, loss_ce: 0.172146
[00:11:22.248] iteration 208 : loss : 0.511811, loss_ce: 0.144273
[00:11:22.542] iteration 209 : loss : 0.520632, loss_ce: 0.177313
[00:11:22.852] iteration 210 : loss : 0.529325, loss_ce: 0.191049
[00:11:23.167] iteration 211 : loss : 0.538240, loss_ce: 0.220472
[00:11:23.449] iteration 212 : loss : 0.536973, loss_ce: 0.196304
[00:11:23.730] iteration 213 : loss : 0.508919, loss_ce: 0.144269
[00:11:24.020] iteration 214 : loss : 0.524879, loss_ce: 0.137349
[00:11:24.325] iteration 215 : loss : 0.539223, loss_ce: 0.175584
[00:11:24.606] iteration 216 : loss : 0.482232, loss_ce: 0.060086
[00:11:24.886] iteration 217 : loss : 0.504237, loss_ce: 0.137619
[00:11:25.166] iteration 218 : loss : 0.487778, loss_ce: 0.101329
[00:11:25.450] iteration 219 : loss : 0.497882, loss_ce: 0.134679
[00:11:25.730] iteration 220 : loss : 0.482579, loss_ce: 0.087832
[00:11:26.026] iteration 221 : loss : 0.496678, loss_ce: 0.087367
[00:11:26.313] iteration 222 : loss : 0.498126, loss_ce: 0.131050
[00:11:26.623] iteration 223 : loss : 0.491049, loss_ce: 0.108777
[00:11:26.933] iteration 224 : loss : 0.491904, loss_ce: 0.088821
[00:11:27.234] iteration 225 : loss : 0.538641, loss_ce: 0.209247
[00:11:27.555] iteration 226 : loss : 0.507968, loss_ce: 0.124461
[00:11:27.859] iteration 227 : loss : 0.510699, loss_ce: 0.163503
[00:11:28.169] iteration 228 : loss : 0.511941, loss_ce: 0.167884
[00:11:28.452] iteration 229 : loss : 0.494183, loss_ce: 0.092191
[00:11:28.747] iteration 230 : loss : 0.517062, loss_ce: 0.175385
[00:11:29.055] iteration 231 : loss : 0.494624, loss_ce: 0.109555
[00:11:29.341] iteration 232 : loss : 0.521606, loss_ce: 0.112241
[00:11:29.626] iteration 233 : loss : 0.498891, loss_ce: 0.104960
[00:11:29.911] iteration 234 : loss : 0.472162, loss_ce: 0.083731
[00:11:30.206] iteration 235 : loss : 0.494186, loss_ce: 0.132140
[00:11:30.487] iteration 236 : loss : 0.491978, loss_ce: 0.117690
[00:11:30.771] iteration 237 : loss : 0.548381, loss_ce: 0.255372
[00:11:31.051] iteration 238 : loss : 0.514133, loss_ce: 0.167591
[00:11:31.337] iteration 239 : loss : 0.500346, loss_ce: 0.159102
[00:11:31.623] iteration 240 : loss : 0.520900, loss_ce: 0.150727
[00:11:31.940] iteration 241 : loss : 0.499499, loss_ce: 0.139045
[00:11:32.243] iteration 242 : loss : 0.502089, loss_ce: 0.097685
[00:11:32.532] iteration 243 : loss : 0.494319, loss_ce: 0.119462
[00:11:32.819] iteration 244 : loss : 0.507491, loss_ce: 0.130430
[00:11:33.130] iteration 245 : loss : 0.495418, loss_ce: 0.152107
[00:11:33.444] iteration 246 : loss : 0.495262, loss_ce: 0.096590
[00:11:33.757] iteration 247 : loss : 0.490091, loss_ce: 0.067554
[00:11:34.064] iteration 248 : loss : 0.535275, loss_ce: 0.186791
[00:11:34.343] iteration 249 : loss : 0.530268, loss_ce: 0.090360
[00:11:34.623] iteration 250 : loss : 0.505593, loss_ce: 0.156917
[00:11:34.904] iteration 251 : loss : 0.531995, loss_ce: 0.217872
[00:11:35.184] iteration 252 : loss : 0.505645, loss_ce: 0.161033
[00:11:35.483] iteration 253 : loss : 0.492607, loss_ce: 0.146099
[00:11:35.774] iteration 254 : loss : 0.489448, loss_ce: 0.139779
[00:11:36.056] iteration 255 : loss : 0.507466, loss_ce: 0.183483
[00:11:36.337] iteration 256 : loss : 0.493113, loss_ce: 0.118708
[00:11:36.627] iteration 257 : loss : 0.516189, loss_ce: 0.181487
[00:11:36.940] iteration 258 : loss : 0.504020, loss_ce: 0.150556
[00:11:37.259] iteration 259 : loss : 0.489882, loss_ce: 0.109441
[00:11:37.563] iteration 260 : loss : 0.487834, loss_ce: 0.134983
[00:11:37.862] iteration 261 : loss : 0.486444, loss_ce: 0.064523
[00:11:38.147] iteration 262 : loss : 0.502940, loss_ce: 0.127903
[00:11:38.452] iteration 263 : loss : 0.502912, loss_ce: 0.136973
[00:11:38.736] iteration 264 : loss : 0.513961, loss_ce: 0.115221
[00:11:39.023] iteration 265 : loss : 0.505811, loss_ce: 0.142522
[00:11:39.308] iteration 266 : loss : 0.484261, loss_ce: 0.108702
[00:11:39.611] iteration 267 : loss : 0.502115, loss_ce: 0.139273
[00:11:39.904] iteration 268 : loss : 0.504705, loss_ce: 0.184788
[00:11:40.189] iteration 269 : loss : 0.481954, loss_ce: 0.137316
[00:11:40.474] iteration 270 : loss : 0.486169, loss_ce: 0.124911
[00:11:40.754] iteration 271 : loss : 0.512049, loss_ce: 0.157606
[00:11:41.038] iteration 272 : loss : 0.499418, loss_ce: 0.130214
[00:11:41.322] iteration 273 : loss : 0.484841, loss_ce: 0.123388
[00:11:41.605] iteration 274 : loss : 0.490344, loss_ce: 0.135651
[00:11:41.906] iteration 275 : loss : 0.510157, loss_ce: 0.181259
[00:11:42.206] iteration 276 : loss : 0.484827, loss_ce: 0.074689
[00:11:42.488] iteration 277 : loss : 0.491734, loss_ce: 0.114197
[00:11:42.577] iteration 278 : loss : 0.522263, loss_ce: 0.171290
[00:12:01.003] iteration 279 : loss : 0.499387, loss_ce: 0.108498
[00:12:01.289] iteration 280 : loss : 0.482880, loss_ce: 0.151405
[00:12:01.584] iteration 281 : loss : 0.488650, loss_ce: 0.150460
[00:12:01.885] iteration 282 : loss : 0.506918, loss_ce: 0.169118
[00:12:02.183] iteration 283 : loss : 0.477350, loss_ce: 0.108962
[00:12:02.464] iteration 284 : loss : 0.495478, loss_ce: 0.125747
[00:12:02.738] iteration 285 : loss : 0.495558, loss_ce: 0.116425
[00:12:03.017] iteration 286 : loss : 0.496131, loss_ce: 0.152259
[00:12:03.293] iteration 287 : loss : 0.481993, loss_ce: 0.135510
[00:12:03.570] iteration 288 : loss : 0.501502, loss_ce: 0.145181
[00:12:03.845] iteration 289 : loss : 0.495256, loss_ce: 0.112305
[00:12:04.120] iteration 290 : loss : 0.480355, loss_ce: 0.121008
[00:12:04.400] iteration 291 : loss : 0.456805, loss_ce: 0.071780
[00:12:04.679] iteration 292 : loss : 0.487093, loss_ce: 0.130827
[00:12:04.955] iteration 293 : loss : 0.483881, loss_ce: 0.131856
[00:12:05.235] iteration 294 : loss : 0.502224, loss_ce: 0.173974
[00:12:05.514] iteration 295 : loss : 0.490905, loss_ce: 0.116716
[00:12:05.793] iteration 296 : loss : 0.483086, loss_ce: 0.115796
[00:12:06.070] iteration 297 : loss : 0.482735, loss_ce: 0.142918
[00:12:06.346] iteration 298 : loss : 0.472385, loss_ce: 0.116740
[00:12:06.624] iteration 299 : loss : 0.525511, loss_ce: 0.233027
[00:12:06.921] iteration 300 : loss : 0.504935, loss_ce: 0.179468
[00:12:07.226] iteration 301 : loss : 0.474473, loss_ce: 0.113322
[00:12:07.503] iteration 302 : loss : 0.494168, loss_ce: 0.148464
[00:12:07.777] iteration 303 : loss : 0.476234, loss_ce: 0.093380
[00:12:08.057] iteration 304 : loss : 0.527861, loss_ce: 0.226846
[00:12:08.337] iteration 305 : loss : 0.488260, loss_ce: 0.147595
[00:12:08.615] iteration 306 : loss : 0.479250, loss_ce: 0.126242
[00:12:08.892] iteration 307 : loss : 0.509269, loss_ce: 0.218136
[00:12:09.172] iteration 308 : loss : 0.480074, loss_ce: 0.122268
[00:12:09.450] iteration 309 : loss : 0.451072, loss_ce: 0.097565
[00:12:09.727] iteration 310 : loss : 0.469043, loss_ce: 0.152388
[00:12:10.004] iteration 311 : loss : 0.476797, loss_ce: 0.108316
[00:12:10.284] iteration 312 : loss : 0.475202, loss_ce: 0.094999
[00:12:10.564] iteration 313 : loss : 0.469262, loss_ce: 0.111232
[00:12:10.842] iteration 314 : loss : 0.471832, loss_ce: 0.129926
[00:12:11.120] iteration 315 : loss : 0.463723, loss_ce: 0.108771
[00:12:11.398] iteration 316 : loss : 0.460375, loss_ce: 0.137761
[00:12:11.677] iteration 317 : loss : 0.474723, loss_ce: 0.161609
[00:12:11.981] iteration 318 : loss : 0.462881, loss_ce: 0.071705
[00:12:12.268] iteration 319 : loss : 0.489363, loss_ce: 0.168150
[00:12:12.547] iteration 320 : loss : 0.455857, loss_ce: 0.110448
[00:12:12.844] iteration 321 : loss : 0.483507, loss_ce: 0.142713
[00:12:13.122] iteration 322 : loss : 0.486873, loss_ce: 0.106691
[00:12:13.400] iteration 323 : loss : 0.498165, loss_ce: 0.167402
[00:12:13.678] iteration 324 : loss : 0.465399, loss_ce: 0.123219
[00:12:13.957] iteration 325 : loss : 0.456434, loss_ce: 0.077093
[00:12:14.235] iteration 326 : loss : 0.477482, loss_ce: 0.120140
[00:12:14.514] iteration 327 : loss : 0.485454, loss_ce: 0.146344
[00:12:14.792] iteration 328 : loss : 0.529859, loss_ce: 0.208214
[00:12:15.068] iteration 329 : loss : 0.471420, loss_ce: 0.132562
[00:12:15.347] iteration 330 : loss : 0.489779, loss_ce: 0.148689
[00:12:15.625] iteration 331 : loss : 0.472244, loss_ce: 0.150582
[00:12:15.901] iteration 332 : loss : 0.507443, loss_ce: 0.154865
[00:12:16.179] iteration 333 : loss : 0.500146, loss_ce: 0.180663
[00:12:16.464] iteration 334 : loss : 0.484805, loss_ce: 0.118735
[00:12:16.742] iteration 335 : loss : 0.490360, loss_ce: 0.181640
[00:12:17.051] iteration 336 : loss : 0.482770, loss_ce: 0.105001
[00:12:17.331] iteration 337 : loss : 0.477804, loss_ce: 0.152362
[00:12:17.611] iteration 338 : loss : 0.472500, loss_ce: 0.126501
[00:12:17.890] iteration 339 : loss : 0.498381, loss_ce: 0.137476
[00:12:18.167] iteration 340 : loss : 0.480541, loss_ce: 0.119209
[00:12:18.458] iteration 341 : loss : 0.484035, loss_ce: 0.151333
[00:12:18.737] iteration 342 : loss : 0.469172, loss_ce: 0.156140
[00:12:19.012] iteration 343 : loss : 0.507219, loss_ce: 0.230585
[00:12:19.294] iteration 344 : loss : 0.490853, loss_ce: 0.092047
[00:12:19.571] iteration 345 : loss : 0.506203, loss_ce: 0.207751
[00:12:19.848] iteration 346 : loss : 0.468921, loss_ce: 0.104096
[00:12:20.127] iteration 347 : loss : 0.473035, loss_ce: 0.121359
[00:12:20.407] iteration 348 : loss : 0.475732, loss_ce: 0.092947
[00:12:20.729] iteration 349 : loss : 0.480962, loss_ce: 0.088246
[00:12:21.020] iteration 350 : loss : 0.454942, loss_ce: 0.088682
[00:12:21.299] iteration 351 : loss : 0.468329, loss_ce: 0.139992
[00:12:21.578] iteration 352 : loss : 0.461157, loss_ce: 0.124579
[00:12:21.903] iteration 353 : loss : 0.474074, loss_ce: 0.133076
[00:12:22.213] iteration 354 : loss : 0.476374, loss_ce: 0.104726
[00:12:22.593] iteration 355 : loss : 0.453938, loss_ce: 0.119530
[00:12:22.924] iteration 356 : loss : 0.476334, loss_ce: 0.138201
[00:12:23.257] iteration 357 : loss : 0.449943, loss_ce: 0.104116
[00:12:23.566] iteration 358 : loss : 0.474680, loss_ce: 0.092813
[00:12:23.850] iteration 359 : loss : 0.461395, loss_ce: 0.133055
[00:12:24.147] iteration 360 : loss : 0.454000, loss_ce: 0.120431
[00:12:24.507] iteration 361 : loss : 0.459853, loss_ce: 0.101165
[00:12:24.850] iteration 362 : loss : 0.447644, loss_ce: 0.101734
[00:12:25.130] iteration 363 : loss : 0.450860, loss_ce: 0.084096
[00:12:25.409] iteration 364 : loss : 0.445390, loss_ce: 0.126759
[00:12:25.694] iteration 365 : loss : 0.466905, loss_ce: 0.145188
[00:12:25.973] iteration 366 : loss : 0.484769, loss_ce: 0.136833
[00:12:26.281] iteration 367 : loss : 0.467108, loss_ce: 0.152734
[00:12:26.578] iteration 368 : loss : 0.506335, loss_ce: 0.237349
[00:12:26.876] iteration 369 : loss : 0.461230, loss_ce: 0.147473
[00:12:27.172] iteration 370 : loss : 0.501539, loss_ce: 0.172075
[00:12:27.459] iteration 371 : loss : 0.488346, loss_ce: 0.066105
[00:12:27.742] iteration 372 : loss : 0.452342, loss_ce: 0.105460
[00:12:28.042] iteration 373 : loss : 0.472592, loss_ce: 0.107693
[00:12:28.355] iteration 374 : loss : 0.467970, loss_ce: 0.164990
[00:12:28.655] iteration 375 : loss : 0.495727, loss_ce: 0.204887
[00:12:28.975] iteration 376 : loss : 0.451767, loss_ce: 0.123469
[00:12:29.292] iteration 377 : loss : 0.474435, loss_ce: 0.056542
[00:12:29.608] iteration 378 : loss : 0.456551, loss_ce: 0.129859
[00:12:29.921] iteration 379 : loss : 0.456479, loss_ce: 0.135901
[00:12:30.246] iteration 380 : loss : 0.498038, loss_ce: 0.123728
[00:12:30.576] iteration 381 : loss : 0.454124, loss_ce: 0.133462
[00:12:30.880] iteration 382 : loss : 0.466411, loss_ce: 0.126817
[00:12:31.201] iteration 383 : loss : 0.499718, loss_ce: 0.157791
[00:12:31.705] iteration 384 : loss : 0.456398, loss_ce: 0.129807
[00:12:31.986] iteration 385 : loss : 0.439729, loss_ce: 0.108827
[00:12:32.264] iteration 386 : loss : 0.439207, loss_ce: 0.074424
[00:12:32.548] iteration 387 : loss : 0.505817, loss_ce: 0.196708
[00:12:32.830] iteration 388 : loss : 0.518615, loss_ce: 0.042303
[00:12:33.110] iteration 389 : loss : 0.488536, loss_ce: 0.153108
[00:12:33.390] iteration 390 : loss : 0.439319, loss_ce: 0.096213
[00:12:33.683] iteration 391 : loss : 0.494828, loss_ce: 0.236753
[00:12:33.963] iteration 392 : loss : 0.461073, loss_ce: 0.148584
[00:12:34.245] iteration 393 : loss : 0.451293, loss_ce: 0.117111
[00:12:34.529] iteration 394 : loss : 0.456552, loss_ce: 0.086274
[00:12:34.813] iteration 395 : loss : 0.459183, loss_ce: 0.091481
[00:12:35.096] iteration 396 : loss : 0.455642, loss_ce: 0.081424
[00:12:35.377] iteration 397 : loss : 0.476632, loss_ce: 0.169269
[00:12:35.658] iteration 398 : loss : 0.478678, loss_ce: 0.189912
[00:12:35.938] iteration 399 : loss : 0.455930, loss_ce: 0.145231
[00:12:36.216] iteration 400 : loss : 0.481635, loss_ce: 0.156712
[00:12:36.518] iteration 401 : loss : 0.439933, loss_ce: 0.102488
[00:12:36.803] iteration 402 : loss : 0.483248, loss_ce: 0.179045
[00:12:37.093] iteration 403 : loss : 0.449385, loss_ce: 0.100606
[00:12:37.372] iteration 404 : loss : 0.463203, loss_ce: 0.128262
[00:12:37.661] iteration 405 : loss : 0.488272, loss_ce: 0.103705
[00:12:37.949] iteration 406 : loss : 0.426263, loss_ce: 0.055142
[00:12:38.235] iteration 407 : loss : 0.461732, loss_ce: 0.120716
[00:12:38.520] iteration 408 : loss : 0.448210, loss_ce: 0.077505
[00:12:38.804] iteration 409 : loss : 0.435271, loss_ce: 0.109004
[00:12:39.089] iteration 410 : loss : 0.456449, loss_ce: 0.172365
[00:12:39.375] iteration 411 : loss : 0.459182, loss_ce: 0.130589
[00:12:39.663] iteration 412 : loss : 0.469844, loss_ce: 0.140676
[00:12:39.947] iteration 413 : loss : 0.424848, loss_ce: 0.062560
[00:12:40.236] iteration 414 : loss : 0.429168, loss_ce: 0.140309
[00:12:40.516] iteration 415 : loss : 0.453277, loss_ce: 0.092018
[00:12:40.802] iteration 416 : loss : 0.455388, loss_ce: 0.176192
[00:12:40.878] iteration 417 : loss : 0.462147, loss_ce: 0.090152
[00:13:01.042] iteration 418 : loss : 0.464809, loss_ce: 0.146862
[00:13:01.328] iteration 419 : loss : 0.456858, loss_ce: 0.096803
[00:13:01.619] iteration 420 : loss : 0.443889, loss_ce: 0.106904
[00:13:01.933] iteration 421 : loss : 0.467850, loss_ce: 0.166708
[00:13:02.255] iteration 422 : loss : 0.464512, loss_ce: 0.088287
[00:13:02.560] iteration 423 : loss : 0.442567, loss_ce: 0.126299
[00:13:02.889] iteration 424 : loss : 0.445318, loss_ce: 0.128798
[00:13:03.200] iteration 425 : loss : 0.464866, loss_ce: 0.182200
[00:13:03.512] iteration 426 : loss : 0.452483, loss_ce: 0.118458
[00:13:03.794] iteration 427 : loss : 0.459493, loss_ce: 0.119045
[00:13:04.088] iteration 428 : loss : 0.444377, loss_ce: 0.151075
[00:13:04.400] iteration 429 : loss : 0.451324, loss_ce: 0.077976
[00:13:04.694] iteration 430 : loss : 0.473347, loss_ce: 0.135961
[00:13:04.980] iteration 431 : loss : 0.453325, loss_ce: 0.162579
[00:13:05.259] iteration 432 : loss : 0.485865, loss_ce: 0.159241
[00:13:05.538] iteration 433 : loss : 0.491708, loss_ce: 0.145044
[00:13:05.846] iteration 434 : loss : 0.454707, loss_ce: 0.142694
[00:13:06.133] iteration 435 : loss : 0.462202, loss_ce: 0.174782
[00:13:06.410] iteration 436 : loss : 0.453944, loss_ce: 0.128480
[00:13:06.686] iteration 437 : loss : 0.452730, loss_ce: 0.122009
[00:13:06.993] iteration 438 : loss : 0.423317, loss_ce: 0.117130
[00:13:07.278] iteration 439 : loss : 0.441148, loss_ce: 0.170203
[00:13:07.555] iteration 440 : loss : 0.453117, loss_ce: 0.132784
[00:13:07.852] iteration 441 : loss : 0.447405, loss_ce: 0.064180
[00:13:08.135] iteration 442 : loss : 0.417439, loss_ce: 0.096147
[00:13:08.416] iteration 443 : loss : 0.413637, loss_ce: 0.073499
[00:13:08.733] iteration 444 : loss : 0.457564, loss_ce: 0.140842
[00:13:09.042] iteration 445 : loss : 0.415572, loss_ce: 0.117212
[00:13:09.362] iteration 446 : loss : 0.451743, loss_ce: 0.135992
[00:13:09.648] iteration 447 : loss : 0.448179, loss_ce: 0.117714
[00:13:09.960] iteration 448 : loss : 0.435513, loss_ce: 0.099834
[00:13:10.269] iteration 449 : loss : 0.418475, loss_ce: 0.111399
[00:13:10.570] iteration 450 : loss : 0.437178, loss_ce: 0.118038
[00:13:10.873] iteration 451 : loss : 0.429332, loss_ce: 0.095785
[00:13:11.182] iteration 452 : loss : 0.443655, loss_ce: 0.103201
[00:13:11.484] iteration 453 : loss : 0.424697, loss_ce: 0.070706
[00:13:11.797] iteration 454 : loss : 0.419762, loss_ce: 0.119204
[00:13:12.088] iteration 455 : loss : 0.441127, loss_ce: 0.100083
[00:13:12.398] iteration 456 : loss : 0.401266, loss_ce: 0.056229
[00:13:12.690] iteration 457 : loss : 0.449245, loss_ce: 0.114895
[00:13:12.991] iteration 458 : loss : 0.440000, loss_ce: 0.109031
[00:13:13.314] iteration 459 : loss : 0.437615, loss_ce: 0.130172
[00:13:13.611] iteration 460 : loss : 0.460183, loss_ce: 0.151180
[00:13:13.927] iteration 461 : loss : 0.411679, loss_ce: 0.094906
[00:13:14.241] iteration 462 : loss : 0.429568, loss_ce: 0.137219
[00:13:14.528] iteration 463 : loss : 0.439721, loss_ce: 0.093194
[00:13:14.835] iteration 464 : loss : 0.430516, loss_ce: 0.127380
[00:13:15.128] iteration 465 : loss : 0.397592, loss_ce: 0.111846
[00:13:15.409] iteration 466 : loss : 0.426631, loss_ce: 0.113520
[00:13:15.688] iteration 467 : loss : 0.417665, loss_ce: 0.097983
[00:13:16.007] iteration 468 : loss : 0.407853, loss_ce: 0.112163
[00:13:16.289] iteration 469 : loss : 0.472893, loss_ce: 0.190498
[00:13:16.587] iteration 470 : loss : 0.415389, loss_ce: 0.159884
[00:13:16.892] iteration 471 : loss : 0.447359, loss_ce: 0.138371
[00:13:17.215] iteration 472 : loss : 0.433037, loss_ce: 0.106592
[00:13:17.523] iteration 473 : loss : 0.421724, loss_ce: 0.117081
[00:13:17.873] iteration 474 : loss : 0.430883, loss_ce: 0.121471
[00:13:18.199] iteration 475 : loss : 0.401154, loss_ce: 0.126149
[00:13:18.507] iteration 476 : loss : 0.451850, loss_ce: 0.165468
[00:13:18.803] iteration 477 : loss : 0.415318, loss_ce: 0.078322
[00:13:19.122] iteration 478 : loss : 0.431987, loss_ce: 0.092467
[00:13:19.423] iteration 479 : loss : 0.422503, loss_ce: 0.098828
[00:13:19.740] iteration 480 : loss : 0.461375, loss_ce: 0.109715
[00:13:20.062] iteration 481 : loss : 0.428975, loss_ce: 0.107933
[00:13:20.374] iteration 482 : loss : 0.424977, loss_ce: 0.114234
[00:13:20.661] iteration 483 : loss : 0.436137, loss_ce: 0.158694
[00:13:20.946] iteration 484 : loss : 0.443247, loss_ce: 0.080543
[00:13:21.261] iteration 485 : loss : 0.401895, loss_ce: 0.107127
[00:13:21.576] iteration 486 : loss : 0.394969, loss_ce: 0.083178
[00:13:21.883] iteration 487 : loss : 0.425204, loss_ce: 0.092011
[00:13:22.172] iteration 488 : loss : 0.434364, loss_ce: 0.065733
[00:13:22.449] iteration 489 : loss : 0.420110, loss_ce: 0.106575
[00:13:22.753] iteration 490 : loss : 0.437549, loss_ce: 0.153988
[00:13:23.063] iteration 491 : loss : 0.432635, loss_ce: 0.117258
[00:13:23.345] iteration 492 : loss : 0.405280, loss_ce: 0.082088
[00:13:23.627] iteration 493 : loss : 0.434064, loss_ce: 0.132540
[00:13:23.909] iteration 494 : loss : 0.399958, loss_ce: 0.087487
[00:13:24.189] iteration 495 : loss : 0.468991, loss_ce: 0.102757
[00:13:24.487] iteration 496 : loss : 0.444021, loss_ce: 0.095005
[00:13:24.800] iteration 497 : loss : 0.433347, loss_ce: 0.074705
[00:13:25.081] iteration 498 : loss : 0.451567, loss_ce: 0.154783
[00:13:25.391] iteration 499 : loss : 0.404316, loss_ce: 0.078325
[00:13:25.675] iteration 500 : loss : 0.429697, loss_ce: 0.058573
[00:13:25.974] iteration 501 : loss : 0.426580, loss_ce: 0.125551
[00:13:26.259] iteration 502 : loss : 0.449511, loss_ce: 0.091097
[00:13:26.536] iteration 503 : loss : 0.432835, loss_ce: 0.109466
[00:13:26.822] iteration 504 : loss : 0.467240, loss_ce: 0.188221
[00:13:27.114] iteration 505 : loss : 0.481897, loss_ce: 0.170794
[00:13:27.396] iteration 506 : loss : 0.435447, loss_ce: 0.145931
[00:13:27.678] iteration 507 : loss : 0.424504, loss_ce: 0.094345
[00:13:27.961] iteration 508 : loss : 0.456070, loss_ce: 0.137334
[00:13:28.242] iteration 509 : loss : 0.452233, loss_ce: 0.078745
[00:13:28.524] iteration 510 : loss : 0.466543, loss_ce: 0.134390
[00:13:28.806] iteration 511 : loss : 0.430328, loss_ce: 0.130566
[00:13:29.089] iteration 512 : loss : 0.462896, loss_ce: 0.204949
[00:13:29.370] iteration 513 : loss : 0.462685, loss_ce: 0.129128
[00:13:29.650] iteration 514 : loss : 0.411213, loss_ce: 0.085724
[00:13:29.933] iteration 515 : loss : 0.412725, loss_ce: 0.080530
[00:13:30.240] iteration 516 : loss : 0.447805, loss_ce: 0.112533
[00:13:30.557] iteration 517 : loss : 0.457092, loss_ce: 0.101664
[00:13:30.857] iteration 518 : loss : 0.451481, loss_ce: 0.112049
[00:13:31.181] iteration 519 : loss : 0.522214, loss_ce: 0.050088
[00:13:31.501] iteration 520 : loss : 0.448047, loss_ce: 0.134631
[00:13:31.837] iteration 521 : loss : 0.471764, loss_ce: 0.112461
[00:13:32.127] iteration 522 : loss : 0.435039, loss_ce: 0.145684
[00:13:32.416] iteration 523 : loss : 0.436862, loss_ce: 0.137218
[00:13:32.723] iteration 524 : loss : 0.430481, loss_ce: 0.140053
[00:13:33.053] iteration 525 : loss : 0.425024, loss_ce: 0.044029
[00:13:33.350] iteration 526 : loss : 0.437497, loss_ce: 0.058429
[00:13:33.659] iteration 527 : loss : 0.405825, loss_ce: 0.101798
[00:13:33.961] iteration 528 : loss : 0.384557, loss_ce: 0.082973
[00:13:34.263] iteration 529 : loss : 0.434374, loss_ce: 0.135063
[00:13:34.579] iteration 530 : loss : 0.431041, loss_ce: 0.129555
[00:13:34.886] iteration 531 : loss : 0.434945, loss_ce: 0.110358
[00:13:35.167] iteration 532 : loss : 0.423468, loss_ce: 0.118893
[00:13:35.457] iteration 533 : loss : 0.408750, loss_ce: 0.128014
[00:13:35.738] iteration 534 : loss : 0.440648, loss_ce: 0.094759
[00:13:36.045] iteration 535 : loss : 0.439930, loss_ce: 0.102798
[00:13:36.333] iteration 536 : loss : 0.449125, loss_ce: 0.135937
[00:13:36.617] iteration 537 : loss : 0.417465, loss_ce: 0.074051
[00:13:36.897] iteration 538 : loss : 0.416027, loss_ce: 0.114859
[00:13:37.184] iteration 539 : loss : 0.416672, loss_ce: 0.121988
[00:13:37.470] iteration 540 : loss : 0.470454, loss_ce: 0.182686
[00:13:37.790] iteration 541 : loss : 0.499499, loss_ce: 0.150219
[00:13:38.102] iteration 542 : loss : 0.412459, loss_ce: 0.096414
[00:13:38.393] iteration 543 : loss : 0.451370, loss_ce: 0.191153
[00:13:38.686] iteration 544 : loss : 0.424138, loss_ce: 0.090209
[00:13:38.972] iteration 545 : loss : 0.424240, loss_ce: 0.074688
[00:13:39.257] iteration 546 : loss : 0.418323, loss_ce: 0.100972
[00:13:39.586] iteration 547 : loss : 0.405531, loss_ce: 0.107376
[00:13:39.908] iteration 548 : loss : 0.407436, loss_ce: 0.098378
[00:13:40.238] iteration 549 : loss : 0.413706, loss_ce: 0.104701
[00:13:40.564] iteration 550 : loss : 0.431358, loss_ce: 0.080401
[00:13:40.873] iteration 551 : loss : 0.402210, loss_ce: 0.041875
[00:13:41.177] iteration 552 : loss : 0.444059, loss_ce: 0.176110
[00:13:41.498] iteration 553 : loss : 0.462951, loss_ce: 0.140122
[00:13:41.791] iteration 554 : loss : 0.456627, loss_ce: 0.132497
[00:13:42.104] iteration 555 : loss : 0.416506, loss_ce: 0.124583
[00:13:42.200] iteration 556 : loss : 0.456654, loss_ce: 0.106649
[00:14:00.977] iteration 557 : loss : 0.448013, loss_ce: 0.137748
[00:14:01.265] iteration 558 : loss : 0.380543, loss_ce: 0.102116
[00:14:01.550] iteration 559 : loss : 0.407482, loss_ce: 0.084233
[00:14:01.832] iteration 560 : loss : 0.427307, loss_ce: 0.156636
[00:14:02.131] iteration 561 : loss : 0.407259, loss_ce: 0.125707
[00:14:02.408] iteration 562 : loss : 0.400633, loss_ce: 0.110296
[00:14:02.684] iteration 563 : loss : 0.385661, loss_ce: 0.092012
[00:14:02.962] iteration 564 : loss : 0.398666, loss_ce: 0.094018
[00:14:03.238] iteration 565 : loss : 0.400550, loss_ce: 0.096571
[00:14:03.519] iteration 566 : loss : 0.395345, loss_ce: 0.086875
[00:14:03.797] iteration 567 : loss : 0.377124, loss_ce: 0.080822
[00:14:04.080] iteration 568 : loss : 0.411488, loss_ce: 0.127297
[00:14:04.364] iteration 569 : loss : 0.431177, loss_ce: 0.145684
[00:14:04.641] iteration 570 : loss : 0.424690, loss_ce: 0.144276
[00:14:04.921] iteration 571 : loss : 0.362830, loss_ce: 0.083444
[00:14:05.198] iteration 572 : loss : 0.416682, loss_ce: 0.140412
[00:14:05.476] iteration 573 : loss : 0.403956, loss_ce: 0.136185
[00:14:05.754] iteration 574 : loss : 0.382546, loss_ce: 0.109975
[00:14:06.035] iteration 575 : loss : 0.403897, loss_ce: 0.131782
[00:14:06.316] iteration 576 : loss : 0.400286, loss_ce: 0.121503
[00:14:06.594] iteration 577 : loss : 0.407573, loss_ce: 0.089038
[00:14:06.872] iteration 578 : loss : 0.383005, loss_ce: 0.075868
[00:14:07.152] iteration 579 : loss : 0.377210, loss_ce: 0.066905
[00:14:07.431] iteration 580 : loss : 0.394260, loss_ce: 0.104524
[00:14:07.727] iteration 581 : loss : 0.438313, loss_ce: 0.103694
[00:14:08.010] iteration 582 : loss : 0.455782, loss_ce: 0.113264
[00:14:08.288] iteration 583 : loss : 0.418524, loss_ce: 0.032480
[00:14:08.570] iteration 584 : loss : 0.403986, loss_ce: 0.096414
[00:14:08.850] iteration 585 : loss : 0.418767, loss_ce: 0.115487
[00:14:09.130] iteration 586 : loss : 0.414607, loss_ce: 0.080886
[00:14:09.409] iteration 587 : loss : 0.374710, loss_ce: 0.091865
[00:14:09.693] iteration 588 : loss : 0.434832, loss_ce: 0.114669
[00:14:09.975] iteration 589 : loss : 0.398517, loss_ce: 0.077441
[00:14:10.270] iteration 590 : loss : 0.347132, loss_ce: 0.110677
[00:14:10.558] iteration 591 : loss : 0.344867, loss_ce: 0.089880
[00:14:10.839] iteration 592 : loss : 0.387842, loss_ce: 0.117919
[00:14:11.119] iteration 593 : loss : 0.401669, loss_ce: 0.143663
[00:14:11.400] iteration 594 : loss : 0.368050, loss_ce: 0.091611
[00:14:11.680] iteration 595 : loss : 0.379636, loss_ce: 0.054459
[00:14:11.959] iteration 596 : loss : 0.406603, loss_ce: 0.091784
[00:14:12.246] iteration 597 : loss : 0.424781, loss_ce: 0.078263
[00:14:12.530] iteration 598 : loss : 0.411558, loss_ce: 0.067173
[00:14:12.809] iteration 599 : loss : 0.361639, loss_ce: 0.096796
[00:14:13.092] iteration 600 : loss : 0.409730, loss_ce: 0.139353
[00:14:13.392] iteration 601 : loss : 0.402550, loss_ce: 0.132886
[00:14:13.669] iteration 602 : loss : 0.429465, loss_ce: 0.069212
[00:14:13.950] iteration 603 : loss : 0.421764, loss_ce: 0.178211
[00:14:14.232] iteration 604 : loss : 0.385460, loss_ce: 0.075192
[00:14:14.511] iteration 605 : loss : 0.383720, loss_ce: 0.044872
[00:14:14.792] iteration 606 : loss : 0.365359, loss_ce: 0.033150
[00:14:15.068] iteration 607 : loss : 0.388651, loss_ce: 0.145632
[00:14:15.350] iteration 608 : loss : 0.411140, loss_ce: 0.121925
[00:14:15.629] iteration 609 : loss : 0.386747, loss_ce: 0.103725
[00:14:15.910] iteration 610 : loss : 0.379005, loss_ce: 0.113313
[00:14:16.187] iteration 611 : loss : 0.382810, loss_ce: 0.104174
[00:14:16.465] iteration 612 : loss : 0.400650, loss_ce: 0.120990
[00:14:16.748] iteration 613 : loss : 0.438634, loss_ce: 0.128931
[00:14:17.027] iteration 614 : loss : 0.391768, loss_ce: 0.105114
[00:14:17.309] iteration 615 : loss : 0.416361, loss_ce: 0.109829
[00:14:17.590] iteration 616 : loss : 0.364392, loss_ce: 0.064610
[00:14:17.869] iteration 617 : loss : 0.434003, loss_ce: 0.089798
[00:14:18.145] iteration 618 : loss : 0.380214, loss_ce: 0.136719
[00:14:18.426] iteration 619 : loss : 0.336503, loss_ce: 0.050239
[00:14:18.704] iteration 620 : loss : 0.440189, loss_ce: 0.087452
[00:14:19.002] iteration 621 : loss : 0.369668, loss_ce: 0.102721
[00:14:19.278] iteration 622 : loss : 0.377445, loss_ce: 0.094207
[00:14:19.556] iteration 623 : loss : 0.406385, loss_ce: 0.142783
[00:14:19.838] iteration 624 : loss : 0.379818, loss_ce: 0.067099
[00:14:20.116] iteration 625 : loss : 0.356453, loss_ce: 0.105635
[00:14:20.398] iteration 626 : loss : 0.339706, loss_ce: 0.054161
[00:14:20.678] iteration 627 : loss : 0.354684, loss_ce: 0.072195
[00:14:20.966] iteration 628 : loss : 0.414707, loss_ce: 0.069827
[00:14:21.257] iteration 629 : loss : 0.404959, loss_ce: 0.119489
[00:14:21.544] iteration 630 : loss : 0.450468, loss_ce: 0.060467
[00:14:21.833] iteration 631 : loss : 0.420666, loss_ce: 0.136458
[00:14:22.117] iteration 632 : loss : 0.369953, loss_ce: 0.125047
[00:14:22.403] iteration 633 : loss : 0.388781, loss_ce: 0.086248
[00:14:22.688] iteration 634 : loss : 0.441216, loss_ce: 0.122386
[00:14:22.968] iteration 635 : loss : 0.429466, loss_ce: 0.152223
[00:14:23.245] iteration 636 : loss : 0.391547, loss_ce: 0.135685
[00:14:23.525] iteration 637 : loss : 0.406116, loss_ce: 0.094978
[00:14:23.807] iteration 638 : loss : 0.372984, loss_ce: 0.081205
[00:14:24.085] iteration 639 : loss : 0.388375, loss_ce: 0.075358
[00:14:24.363] iteration 640 : loss : 0.357099, loss_ce: 0.059127
[00:14:24.657] iteration 641 : loss : 0.368377, loss_ce: 0.099928
[00:14:24.938] iteration 642 : loss : 0.406825, loss_ce: 0.111033
[00:14:25.216] iteration 643 : loss : 0.413194, loss_ce: 0.086816
[00:14:25.496] iteration 644 : loss : 0.421471, loss_ce: 0.110879
[00:14:25.777] iteration 645 : loss : 0.379300, loss_ce: 0.066630
[00:14:26.054] iteration 646 : loss : 0.397845, loss_ce: 0.123100
[00:14:26.338] iteration 647 : loss : 0.406856, loss_ce: 0.140189
[00:14:26.619] iteration 648 : loss : 0.412928, loss_ce: 0.154025
[00:14:26.896] iteration 649 : loss : 0.395015, loss_ce: 0.114821
[00:14:27.175] iteration 650 : loss : 0.429774, loss_ce: 0.182402
[00:14:27.489] iteration 651 : loss : 0.406930, loss_ce: 0.138838
[00:14:27.806] iteration 652 : loss : 0.414953, loss_ce: 0.132975
[00:14:28.101] iteration 653 : loss : 0.434373, loss_ce: 0.164263
[00:14:28.398] iteration 654 : loss : 0.360158, loss_ce: 0.107671
[00:14:28.723] iteration 655 : loss : 0.338564, loss_ce: 0.071100
[00:14:29.047] iteration 656 : loss : 0.377079, loss_ce: 0.096498
[00:14:29.347] iteration 657 : loss : 0.379122, loss_ce: 0.088040
[00:14:29.635] iteration 658 : loss : 0.377986, loss_ce: 0.090581
[00:14:29.921] iteration 659 : loss : 0.437239, loss_ce: 0.068204
[00:14:30.209] iteration 660 : loss : 0.376400, loss_ce: 0.099575
[00:14:30.514] iteration 661 : loss : 0.385415, loss_ce: 0.079802
[00:14:30.805] iteration 662 : loss : 0.376591, loss_ce: 0.127974
[00:14:31.092] iteration 663 : loss : 0.361972, loss_ce: 0.096080
[00:14:31.380] iteration 664 : loss : 0.339718, loss_ce: 0.064966
[00:14:31.675] iteration 665 : loss : 0.387263, loss_ce: 0.108845
[00:14:31.965] iteration 666 : loss : 0.376228, loss_ce: 0.152776
[00:14:32.266] iteration 667 : loss : 0.380072, loss_ce: 0.128237
[00:14:32.559] iteration 668 : loss : 0.352954, loss_ce: 0.130421
[00:14:32.856] iteration 669 : loss : 0.354690, loss_ce: 0.115079
[00:14:33.149] iteration 670 : loss : 0.377453, loss_ce: 0.112360
[00:14:33.440] iteration 671 : loss : 0.410083, loss_ce: 0.131681
[00:14:33.741] iteration 672 : loss : 0.388806, loss_ce: 0.116161
[00:14:34.034] iteration 673 : loss : 0.342824, loss_ce: 0.080036
[00:14:34.325] iteration 674 : loss : 0.345553, loss_ce: 0.062947
[00:14:34.620] iteration 675 : loss : 0.439862, loss_ce: 0.122711
[00:14:34.907] iteration 676 : loss : 0.419357, loss_ce: 0.113399
[00:14:35.198] iteration 677 : loss : 0.346004, loss_ce: 0.108850
[00:14:35.487] iteration 678 : loss : 0.360280, loss_ce: 0.098990
[00:14:35.777] iteration 679 : loss : 0.374388, loss_ce: 0.122325
[00:14:36.069] iteration 680 : loss : 0.405850, loss_ce: 0.066930
[00:14:36.399] iteration 681 : loss : 0.376159, loss_ce: 0.104290
[00:14:36.696] iteration 682 : loss : 0.335251, loss_ce: 0.093196
[00:14:36.988] iteration 683 : loss : 0.344789, loss_ce: 0.097773
[00:14:37.282] iteration 684 : loss : 0.355295, loss_ce: 0.084188
[00:14:37.580] iteration 685 : loss : 0.378717, loss_ce: 0.103087
[00:14:37.879] iteration 686 : loss : 0.343423, loss_ce: 0.131032
[00:14:38.177] iteration 687 : loss : 0.323089, loss_ce: 0.069761
[00:14:38.469] iteration 688 : loss : 0.362958, loss_ce: 0.094444
[00:14:38.763] iteration 689 : loss : 0.375955, loss_ce: 0.109090
[00:14:39.058] iteration 690 : loss : 0.390462, loss_ce: 0.098386
[00:14:39.358] iteration 691 : loss : 0.361774, loss_ce: 0.115695
[00:14:39.656] iteration 692 : loss : 0.333738, loss_ce: 0.052043
[00:14:39.947] iteration 693 : loss : 0.353693, loss_ce: 0.052850
[00:14:40.243] iteration 694 : loss : 0.354632, loss_ce: 0.106209
[00:14:40.333] iteration 695 : loss : 0.501893, loss_ce: 0.044125
[00:14:59.055] iteration 696 : loss : 0.343168, loss_ce: 0.084003
[00:14:59.352] iteration 697 : loss : 0.373030, loss_ce: 0.125537
[00:14:59.661] iteration 698 : loss : 0.369412, loss_ce: 0.114210
[00:14:59.981] iteration 699 : loss : 0.428299, loss_ce: 0.070636
[00:15:00.329] iteration 700 : loss : 0.357017, loss_ce: 0.057511
[00:15:00.671] iteration 701 : loss : 0.351527, loss_ce: 0.049978
[00:15:00.980] iteration 702 : loss : 0.460569, loss_ce: 0.111291
[00:15:01.267] iteration 703 : loss : 0.386644, loss_ce: 0.065885
[00:15:01.560] iteration 704 : loss : 0.374454, loss_ce: 0.081383
[00:15:01.881] iteration 705 : loss : 0.414950, loss_ce: 0.129656
[00:15:02.187] iteration 706 : loss : 0.425457, loss_ce: 0.174381
[00:15:02.507] iteration 707 : loss : 0.364328, loss_ce: 0.094237
[00:15:02.845] iteration 708 : loss : 0.384472, loss_ce: 0.107418
[00:15:03.168] iteration 709 : loss : 0.414679, loss_ce: 0.137516
[00:15:03.491] iteration 710 : loss : 0.363197, loss_ce: 0.109352
[00:15:03.852] iteration 711 : loss : 0.314040, loss_ce: 0.099253
[00:15:04.145] iteration 712 : loss : 0.334365, loss_ce: 0.072453
[00:15:04.461] iteration 713 : loss : 0.389362, loss_ce: 0.135750
[00:15:04.777] iteration 714 : loss : 0.359893, loss_ce: 0.085146
[00:15:05.075] iteration 715 : loss : 0.363224, loss_ce: 0.109709
[00:15:05.379] iteration 716 : loss : 0.346839, loss_ce: 0.106813
[00:15:05.662] iteration 717 : loss : 0.326552, loss_ce: 0.083122
[00:15:05.973] iteration 718 : loss : 0.380269, loss_ce: 0.109778
[00:15:06.292] iteration 719 : loss : 0.351277, loss_ce: 0.090995
[00:15:06.600] iteration 720 : loss : 0.333433, loss_ce: 0.128153
[00:15:06.923] iteration 721 : loss : 0.363981, loss_ce: 0.077114
[00:15:07.224] iteration 722 : loss : 0.311970, loss_ce: 0.057404
[00:15:07.513] iteration 723 : loss : 0.372751, loss_ce: 0.104814
[00:15:07.795] iteration 724 : loss : 0.352034, loss_ce: 0.079356
[00:15:08.081] iteration 725 : loss : 0.290458, loss_ce: 0.083041
[00:15:08.369] iteration 726 : loss : 0.345965, loss_ce: 0.084011
[00:15:08.645] iteration 727 : loss : 0.337399, loss_ce: 0.097111
[00:15:08.972] iteration 728 : loss : 0.368367, loss_ce: 0.091321
[00:15:09.290] iteration 729 : loss : 0.306515, loss_ce: 0.073569
[00:15:09.609] iteration 730 : loss : 0.389948, loss_ce: 0.112821
[00:15:09.910] iteration 731 : loss : 0.321207, loss_ce: 0.097289
[00:15:10.211] iteration 732 : loss : 0.345321, loss_ce: 0.106804
[00:15:10.523] iteration 733 : loss : 0.374086, loss_ce: 0.043015
[00:15:10.825] iteration 734 : loss : 0.329177, loss_ce: 0.076501
[00:15:11.116] iteration 735 : loss : 0.354871, loss_ce: 0.109666
[00:15:11.397] iteration 736 : loss : 0.354236, loss_ce: 0.084524
[00:15:11.705] iteration 737 : loss : 0.362464, loss_ce: 0.136573
[00:15:12.021] iteration 738 : loss : 0.323053, loss_ce: 0.094479
[00:15:12.321] iteration 739 : loss : 0.344784, loss_ce: 0.073244
[00:15:12.629] iteration 740 : loss : 0.307694, loss_ce: 0.073469
[00:15:12.963] iteration 741 : loss : 0.326654, loss_ce: 0.111702
[00:15:13.257] iteration 742 : loss : 0.366963, loss_ce: 0.083333
[00:15:13.545] iteration 743 : loss : 0.378110, loss_ce: 0.167762
[00:15:13.837] iteration 744 : loss : 0.321327, loss_ce: 0.151560
[00:15:14.126] iteration 745 : loss : 0.327790, loss_ce: 0.073184
[00:15:14.412] iteration 746 : loss : 0.370874, loss_ce: 0.098674
[00:15:14.693] iteration 747 : loss : 0.387473, loss_ce: 0.100384
[00:15:14.970] iteration 748 : loss : 0.335779, loss_ce: 0.097872
[00:15:15.249] iteration 749 : loss : 0.344828, loss_ce: 0.114599
[00:15:15.530] iteration 750 : loss : 0.311389, loss_ce: 0.097777
[00:15:15.811] iteration 751 : loss : 0.336038, loss_ce: 0.075681
[00:15:16.097] iteration 752 : loss : 0.332630, loss_ce: 0.084712
[00:15:16.378] iteration 753 : loss : 0.354607, loss_ce: 0.085128
[00:15:16.663] iteration 754 : loss : 0.340923, loss_ce: 0.059379
[00:15:16.946] iteration 755 : loss : 0.325243, loss_ce: 0.092006
[00:15:17.228] iteration 756 : loss : 0.292621, loss_ce: 0.105781
[00:15:17.507] iteration 757 : loss : 0.337279, loss_ce: 0.116915
[00:15:17.791] iteration 758 : loss : 0.336707, loss_ce: 0.054925
[00:15:18.091] iteration 759 : loss : 0.265775, loss_ce: 0.055662
[00:15:18.372] iteration 760 : loss : 0.328929, loss_ce: 0.067411
[00:15:18.667] iteration 761 : loss : 0.277778, loss_ce: 0.065327
[00:15:18.962] iteration 762 : loss : 0.306699, loss_ce: 0.058398
[00:15:19.271] iteration 763 : loss : 0.329246, loss_ce: 0.071053
[00:15:19.583] iteration 764 : loss : 0.291837, loss_ce: 0.086398
[00:15:19.881] iteration 765 : loss : 0.356564, loss_ce: 0.088576
[00:15:20.191] iteration 766 : loss : 0.322422, loss_ce: 0.097861
[00:15:20.477] iteration 767 : loss : 0.354605, loss_ce: 0.073421
[00:15:20.770] iteration 768 : loss : 0.357111, loss_ce: 0.086660
[00:15:21.070] iteration 769 : loss : 0.323729, loss_ce: 0.097684
[00:15:21.372] iteration 770 : loss : 0.375301, loss_ce: 0.082691
[00:15:21.656] iteration 771 : loss : 0.280617, loss_ce: 0.083090
[00:15:21.956] iteration 772 : loss : 0.335891, loss_ce: 0.138717
[00:15:22.274] iteration 773 : loss : 0.313896, loss_ce: 0.085585
[00:15:22.579] iteration 774 : loss : 0.302667, loss_ce: 0.086324
[00:15:22.905] iteration 775 : loss : 0.334955, loss_ce: 0.064488
[00:15:23.235] iteration 776 : loss : 0.303316, loss_ce: 0.078183
[00:15:23.527] iteration 777 : loss : 0.289296, loss_ce: 0.047678
[00:15:23.832] iteration 778 : loss : 0.316999, loss_ce: 0.071767
[00:15:24.120] iteration 779 : loss : 0.282955, loss_ce: 0.043241
[00:15:24.420] iteration 780 : loss : 0.298129, loss_ce: 0.088334
[00:15:24.746] iteration 781 : loss : 0.341776, loss_ce: 0.057179
[00:15:25.083] iteration 782 : loss : 0.307181, loss_ce: 0.043299
[00:15:25.391] iteration 783 : loss : 0.302092, loss_ce: 0.084410
[00:15:25.693] iteration 784 : loss : 0.291459, loss_ce: 0.080856
[00:15:25.984] iteration 785 : loss : 0.316199, loss_ce: 0.078711
[00:15:26.264] iteration 786 : loss : 0.287111, loss_ce: 0.082909
[00:15:26.549] iteration 787 : loss : 0.299573, loss_ce: 0.088282
[00:15:26.838] iteration 788 : loss : 0.329038, loss_ce: 0.061368
[00:15:27.125] iteration 789 : loss : 0.334613, loss_ce: 0.086620
[00:15:27.407] iteration 790 : loss : 0.319125, loss_ce: 0.094209
[00:15:27.687] iteration 791 : loss : 0.303392, loss_ce: 0.084570
[00:15:27.999] iteration 792 : loss : 0.273379, loss_ce: 0.086180
[00:15:28.292] iteration 793 : loss : 0.349549, loss_ce: 0.097672
[00:15:28.579] iteration 794 : loss : 0.264194, loss_ce: 0.066776
[00:15:28.895] iteration 795 : loss : 0.321976, loss_ce: 0.086800
[00:15:29.206] iteration 796 : loss : 0.348130, loss_ce: 0.125930
[00:15:29.488] iteration 797 : loss : 0.260204, loss_ce: 0.075742
[00:15:29.772] iteration 798 : loss : 0.338213, loss_ce: 0.031695
[00:15:30.052] iteration 799 : loss : 0.308782, loss_ce: 0.060267
[00:15:30.334] iteration 800 : loss : 0.311322, loss_ce: 0.095306
[00:15:30.631] iteration 801 : loss : 0.305451, loss_ce: 0.050255
[00:15:30.909] iteration 802 : loss : 0.323228, loss_ce: 0.034717
[00:15:31.191] iteration 803 : loss : 0.260882, loss_ce: 0.056130
[00:15:31.475] iteration 804 : loss : 0.349802, loss_ce: 0.091861
[00:15:31.755] iteration 805 : loss : 0.286388, loss_ce: 0.075687
[00:15:32.039] iteration 806 : loss : 0.291298, loss_ce: 0.052203
[00:15:32.323] iteration 807 : loss : 0.316231, loss_ce: 0.076834
[00:15:32.603] iteration 808 : loss : 0.329175, loss_ce: 0.116422
[00:15:32.903] iteration 809 : loss : 0.282237, loss_ce: 0.063349
[00:15:33.207] iteration 810 : loss : 0.315290, loss_ce: 0.035590
[00:15:33.488] iteration 811 : loss : 0.280642, loss_ce: 0.070718
[00:15:33.769] iteration 812 : loss : 0.335699, loss_ce: 0.096681
[00:15:34.050] iteration 813 : loss : 0.325018, loss_ce: 0.103161
[00:15:34.330] iteration 814 : loss : 0.311422, loss_ce: 0.063032
[00:15:34.613] iteration 815 : loss : 0.323681, loss_ce: 0.106534
[00:15:34.894] iteration 816 : loss : 0.259901, loss_ce: 0.054435
[00:15:35.174] iteration 817 : loss : 0.281392, loss_ce: 0.064175
[00:15:35.459] iteration 818 : loss : 0.293499, loss_ce: 0.073276
[00:15:35.745] iteration 819 : loss : 0.298475, loss_ce: 0.102536
[00:15:36.032] iteration 820 : loss : 0.390673, loss_ce: 0.087896
[00:15:36.336] iteration 821 : loss : 0.352906, loss_ce: 0.162454
[00:15:36.619] iteration 822 : loss : 0.338203, loss_ce: 0.125468
[00:15:36.902] iteration 823 : loss : 0.343714, loss_ce: 0.088171
[00:15:37.185] iteration 824 : loss : 0.352272, loss_ce: 0.097963
[00:15:37.472] iteration 825 : loss : 0.290503, loss_ce: 0.100749
[00:15:37.758] iteration 826 : loss : 0.285503, loss_ce: 0.119526
[00:15:38.074] iteration 827 : loss : 0.325841, loss_ce: 0.074250
[00:15:38.366] iteration 828 : loss : 0.312831, loss_ce: 0.072260
[00:15:38.653] iteration 829 : loss : 0.328142, loss_ce: 0.069606
[00:15:38.936] iteration 830 : loss : 0.354729, loss_ce: 0.081316
[00:15:39.226] iteration 831 : loss : 0.305701, loss_ce: 0.116659
[00:15:39.512] iteration 832 : loss : 0.304673, loss_ce: 0.087414
[00:15:39.795] iteration 833 : loss : 0.301717, loss_ce: 0.096662
[00:15:39.877] iteration 834 : loss : 0.522561, loss_ce: 0.026580
[00:15:59.023] iteration 835 : loss : 0.322165, loss_ce: 0.111163
[00:15:59.336] iteration 836 : loss : 0.295352, loss_ce: 0.091060
[00:15:59.640] iteration 837 : loss : 0.315378, loss_ce: 0.044563
[00:15:59.947] iteration 838 : loss : 0.352893, loss_ce: 0.143837
[00:16:00.253] iteration 839 : loss : 0.319036, loss_ce: 0.074447
[00:16:00.559] iteration 840 : loss : 0.286229, loss_ce: 0.059422
[00:16:00.883] iteration 841 : loss : 0.295625, loss_ce: 0.060799
[00:16:01.184] iteration 842 : loss : 0.317424, loss_ce: 0.093681
[00:16:01.487] iteration 843 : loss : 0.306301, loss_ce: 0.048452
[00:16:01.792] iteration 844 : loss : 0.293543, loss_ce: 0.044360
[00:16:02.093] iteration 845 : loss : 0.304873, loss_ce: 0.136660
[00:16:02.392] iteration 846 : loss : 0.295262, loss_ce: 0.067694
[00:16:02.694] iteration 847 : loss : 0.278085, loss_ce: 0.098346
[00:16:03.001] iteration 848 : loss : 0.394334, loss_ce: 0.105646
[00:16:03.300] iteration 849 : loss : 0.298419, loss_ce: 0.075394
[00:16:03.608] iteration 850 : loss : 0.313633, loss_ce: 0.081787
[00:16:03.911] iteration 851 : loss : 0.281494, loss_ce: 0.099834
[00:16:04.217] iteration 852 : loss : 0.328548, loss_ce: 0.040210
[00:16:04.519] iteration 853 : loss : 0.286247, loss_ce: 0.080526
[00:16:04.821] iteration 854 : loss : 0.262857, loss_ce: 0.063611
[00:16:05.123] iteration 855 : loss : 0.319757, loss_ce: 0.089065
[00:16:05.426] iteration 856 : loss : 0.267738, loss_ce: 0.100253
[00:16:05.726] iteration 857 : loss : 0.287572, loss_ce: 0.079005
[00:16:06.034] iteration 858 : loss : 0.251760, loss_ce: 0.079576
[00:16:06.336] iteration 859 : loss : 0.250154, loss_ce: 0.091157
[00:16:06.639] iteration 860 : loss : 0.260255, loss_ce: 0.109720
[00:16:06.966] iteration 861 : loss : 0.248377, loss_ce: 0.075787
[00:16:07.267] iteration 862 : loss : 0.234783, loss_ce: 0.062864
[00:16:07.572] iteration 863 : loss : 0.350803, loss_ce: 0.134492
[00:16:07.886] iteration 864 : loss : 0.317232, loss_ce: 0.067320
[00:16:08.192] iteration 865 : loss : 0.301460, loss_ce: 0.074798
[00:16:08.494] iteration 866 : loss : 0.320693, loss_ce: 0.080602
[00:16:08.796] iteration 867 : loss : 0.332894, loss_ce: 0.163525
[00:16:09.101] iteration 868 : loss : 0.322498, loss_ce: 0.130551
[00:16:09.399] iteration 869 : loss : 0.325252, loss_ce: 0.049880
[00:16:09.702] iteration 870 : loss : 0.367808, loss_ce: 0.103131
[00:16:10.010] iteration 871 : loss : 0.357288, loss_ce: 0.115208
[00:16:10.314] iteration 872 : loss : 0.263824, loss_ce: 0.055862
[00:16:10.624] iteration 873 : loss : 0.266998, loss_ce: 0.066896
[00:16:10.931] iteration 874 : loss : 0.341352, loss_ce: 0.113110
[00:16:11.238] iteration 875 : loss : 0.352581, loss_ce: 0.139658
[00:16:11.545] iteration 876 : loss : 0.325099, loss_ce: 0.090946
[00:16:11.854] iteration 877 : loss : 0.348847, loss_ce: 0.059857
[00:16:12.162] iteration 878 : loss : 0.306155, loss_ce: 0.092649
[00:16:12.468] iteration 879 : loss : 0.344092, loss_ce: 0.066514
[00:16:12.776] iteration 880 : loss : 0.302553, loss_ce: 0.095379
[00:16:13.109] iteration 881 : loss : 0.346659, loss_ce: 0.101115
[00:16:13.412] iteration 882 : loss : 0.264807, loss_ce: 0.053234
[00:16:13.723] iteration 883 : loss : 0.240615, loss_ce: 0.073741
[00:16:14.029] iteration 884 : loss : 0.293830, loss_ce: 0.097820
[00:16:14.336] iteration 885 : loss : 0.329051, loss_ce: 0.110188
[00:16:14.644] iteration 886 : loss : 0.267107, loss_ce: 0.123477
[00:16:14.949] iteration 887 : loss : 0.308719, loss_ce: 0.043184
[00:16:15.254] iteration 888 : loss : 0.240109, loss_ce: 0.053167
[00:16:15.561] iteration 889 : loss : 0.254353, loss_ce: 0.059519
[00:16:15.861] iteration 890 : loss : 0.265082, loss_ce: 0.075762
[00:16:16.163] iteration 891 : loss : 0.231214, loss_ce: 0.052221
[00:16:16.469] iteration 892 : loss : 0.299952, loss_ce: 0.130519
[00:16:16.775] iteration 893 : loss : 0.323808, loss_ce: 0.041605
[00:16:17.079] iteration 894 : loss : 0.326311, loss_ce: 0.038028
[00:16:17.381] iteration 895 : loss : 0.293287, loss_ce: 0.099403
[00:16:17.698] iteration 896 : loss : 0.227816, loss_ce: 0.050577
[00:16:18.012] iteration 897 : loss : 0.253119, loss_ce: 0.092320
[00:16:18.316] iteration 898 : loss : 0.254948, loss_ce: 0.033928
[00:16:18.615] iteration 899 : loss : 0.218528, loss_ce: 0.032144
[00:16:18.922] iteration 900 : loss : 0.326427, loss_ce: 0.101081
[00:16:19.255] iteration 901 : loss : 0.287199, loss_ce: 0.040859
[00:16:19.557] iteration 902 : loss : 0.264808, loss_ce: 0.076609
[00:16:19.864] iteration 903 : loss : 0.249149, loss_ce: 0.064174
[00:16:20.166] iteration 904 : loss : 0.281493, loss_ce: 0.118025
[00:16:20.467] iteration 905 : loss : 0.261940, loss_ce: 0.104201
[00:16:20.769] iteration 906 : loss : 0.279957, loss_ce: 0.072967
[00:16:21.076] iteration 907 : loss : 0.313859, loss_ce: 0.030502
[00:16:21.380] iteration 908 : loss : 0.290788, loss_ce: 0.071492
[00:16:21.690] iteration 909 : loss : 0.270217, loss_ce: 0.054268
[00:16:21.999] iteration 910 : loss : 0.317855, loss_ce: 0.084804
[00:16:22.301] iteration 911 : loss : 0.331098, loss_ce: 0.123864
[00:16:22.608] iteration 912 : loss : 0.288996, loss_ce: 0.064856
[00:16:22.917] iteration 913 : loss : 0.311020, loss_ce: 0.080393
[00:16:23.223] iteration 914 : loss : 0.292687, loss_ce: 0.082371
[00:16:23.534] iteration 915 : loss : 0.288271, loss_ce: 0.095316
[00:16:23.841] iteration 916 : loss : 0.232064, loss_ce: 0.049205
[00:16:24.151] iteration 917 : loss : 0.281336, loss_ce: 0.049381
[00:16:24.462] iteration 918 : loss : 0.294600, loss_ce: 0.095669
[00:16:24.771] iteration 919 : loss : 0.266640, loss_ce: 0.065790
[00:16:25.079] iteration 920 : loss : 0.248956, loss_ce: 0.062998
[00:16:25.407] iteration 921 : loss : 0.228898, loss_ce: 0.091704
[00:16:25.710] iteration 922 : loss : 0.264742, loss_ce: 0.062335
[00:16:26.010] iteration 923 : loss : 0.352501, loss_ce: 0.090539
[00:16:26.320] iteration 924 : loss : 0.327844, loss_ce: 0.056141
[00:16:26.625] iteration 925 : loss : 0.265912, loss_ce: 0.063315
[00:16:26.932] iteration 926 : loss : 0.281781, loss_ce: 0.044972
[00:16:27.245] iteration 927 : loss : 0.253057, loss_ce: 0.062140
[00:16:27.552] iteration 928 : loss : 0.257136, loss_ce: 0.065957
[00:16:27.855] iteration 929 : loss : 0.255999, loss_ce: 0.062583
[00:16:28.171] iteration 930 : loss : 0.234851, loss_ce: 0.050532
[00:16:28.480] iteration 931 : loss : 0.370694, loss_ce: 0.076915
[00:16:28.781] iteration 932 : loss : 0.286169, loss_ce: 0.055262
[00:16:29.095] iteration 933 : loss : 0.278591, loss_ce: 0.044573
[00:16:29.401] iteration 934 : loss : 0.216768, loss_ce: 0.087925
[00:16:29.704] iteration 935 : loss : 0.276252, loss_ce: 0.114294
[00:16:30.015] iteration 936 : loss : 0.278820, loss_ce: 0.060435
[00:16:30.324] iteration 937 : loss : 0.247179, loss_ce: 0.073028
[00:16:30.630] iteration 938 : loss : 0.250369, loss_ce: 0.078819
[00:16:30.932] iteration 939 : loss : 0.259525, loss_ce: 0.060455
[00:16:31.236] iteration 940 : loss : 0.279521, loss_ce: 0.090109
[00:16:31.564] iteration 941 : loss : 0.288215, loss_ce: 0.098707
[00:16:31.869] iteration 942 : loss : 0.249558, loss_ce: 0.068180
[00:16:32.176] iteration 943 : loss : 0.303611, loss_ce: 0.049040
[00:16:32.482] iteration 944 : loss : 0.261656, loss_ce: 0.102788
[00:16:32.796] iteration 945 : loss : 0.271326, loss_ce: 0.041896
[00:16:33.107] iteration 946 : loss : 0.290791, loss_ce: 0.092501
[00:16:33.409] iteration 947 : loss : 0.265911, loss_ce: 0.083925
[00:16:33.717] iteration 948 : loss : 0.324576, loss_ce: 0.049349
[00:16:34.021] iteration 949 : loss : 0.292546, loss_ce: 0.097595
[00:16:34.332] iteration 950 : loss : 0.292350, loss_ce: 0.057229
[00:16:34.637] iteration 951 : loss : 0.236975, loss_ce: 0.065147
[00:16:34.943] iteration 952 : loss : 0.260150, loss_ce: 0.047426
[00:16:35.256] iteration 953 : loss : 0.283560, loss_ce: 0.102324
[00:16:35.558] iteration 954 : loss : 0.330571, loss_ce: 0.104674
[00:16:35.870] iteration 955 : loss : 0.321820, loss_ce: 0.087363
[00:16:36.177] iteration 956 : loss : 0.295958, loss_ce: 0.066791
[00:16:36.488] iteration 957 : loss : 0.257555, loss_ce: 0.135106
[00:16:36.797] iteration 958 : loss : 0.259987, loss_ce: 0.053117
[00:16:37.115] iteration 959 : loss : 0.271237, loss_ce: 0.088840
[00:16:37.420] iteration 960 : loss : 0.347897, loss_ce: 0.059214
[00:16:37.753] iteration 961 : loss : 0.250052, loss_ce: 0.074921
[00:16:38.061] iteration 962 : loss : 0.237807, loss_ce: 0.064171
[00:16:38.368] iteration 963 : loss : 0.299584, loss_ce: 0.072577
[00:16:38.684] iteration 964 : loss : 0.360303, loss_ce: 0.073777
[00:16:38.992] iteration 965 : loss : 0.310531, loss_ce: 0.036649
[00:16:39.299] iteration 966 : loss : 0.264046, loss_ce: 0.086017
[00:16:39.618] iteration 967 : loss : 0.261222, loss_ce: 0.088717
[00:16:39.923] iteration 968 : loss : 0.362097, loss_ce: 0.101997
[00:16:40.232] iteration 969 : loss : 0.324470, loss_ce: 0.062746
[00:16:40.539] iteration 970 : loss : 0.337261, loss_ce: 0.079234
[00:16:40.841] iteration 971 : loss : 0.282008, loss_ce: 0.070219
[00:16:41.152] iteration 972 : loss : 0.307473, loss_ce: 0.079980
[00:16:41.234] iteration 973 : loss : 0.312060, loss_ce: 0.041580
[00:16:59.700] iteration 974 : loss : 0.269500, loss_ce: 0.053309
[00:17:00.005] iteration 975 : loss : 0.333164, loss_ce: 0.072719
[00:17:00.309] iteration 976 : loss : 0.379151, loss_ce: 0.015761
[00:17:00.620] iteration 977 : loss : 0.286561, loss_ce: 0.095394
[00:17:00.925] iteration 978 : loss : 0.285460, loss_ce: 0.131694
[00:17:01.235] iteration 979 : loss : 0.309014, loss_ce: 0.038913
[00:17:01.535] iteration 980 : loss : 0.279692, loss_ce: 0.119841
[00:17:01.856] iteration 981 : loss : 0.388051, loss_ce: 0.038402
[00:17:02.157] iteration 982 : loss : 0.317632, loss_ce: 0.060313
[00:17:02.463] iteration 983 : loss : 0.273220, loss_ce: 0.048516
[00:17:02.775] iteration 984 : loss : 0.330385, loss_ce: 0.053831
[00:17:03.078] iteration 985 : loss : 0.327771, loss_ce: 0.074685
[00:17:03.380] iteration 986 : loss : 0.242731, loss_ce: 0.057554
[00:17:03.690] iteration 987 : loss : 0.260294, loss_ce: 0.064871
[00:17:03.988] iteration 988 : loss : 0.242916, loss_ce: 0.055200
[00:17:04.287] iteration 989 : loss : 0.269705, loss_ce: 0.063536
[00:17:04.587] iteration 990 : loss : 0.222005, loss_ce: 0.086648
[00:17:04.894] iteration 991 : loss : 0.266161, loss_ce: 0.113607
[00:17:05.193] iteration 992 : loss : 0.161681, loss_ce: 0.029883
[00:17:05.494] iteration 993 : loss : 0.248830, loss_ce: 0.072948
[00:17:05.801] iteration 994 : loss : 0.250729, loss_ce: 0.070447
[00:17:06.107] iteration 995 : loss : 0.280839, loss_ce: 0.133210
[00:17:06.409] iteration 996 : loss : 0.297219, loss_ce: 0.072366
[00:17:06.710] iteration 997 : loss : 0.183596, loss_ce: 0.046491
[00:17:07.013] iteration 998 : loss : 0.360312, loss_ce: 0.048603
[00:17:07.313] iteration 999 : loss : 0.255006, loss_ce: 0.086819
[00:17:07.623] iteration 1000 : loss : 0.274525, loss_ce: 0.066596
[00:17:07.951] iteration 1001 : loss : 0.214928, loss_ce: 0.053361
[00:17:08.257] iteration 1002 : loss : 0.259555, loss_ce: 0.065297
[00:17:08.566] iteration 1003 : loss : 0.232533, loss_ce: 0.090043
[00:17:08.868] iteration 1004 : loss : 0.283807, loss_ce: 0.075251
[00:17:09.176] iteration 1005 : loss : 0.227611, loss_ce: 0.094132
[00:17:09.481] iteration 1006 : loss : 0.239696, loss_ce: 0.074152
[00:17:09.786] iteration 1007 : loss : 0.282975, loss_ce: 0.064301
[00:17:10.086] iteration 1008 : loss : 0.254280, loss_ce: 0.038966
[00:17:10.394] iteration 1009 : loss : 0.285994, loss_ce: 0.101777
[00:17:10.701] iteration 1010 : loss : 0.198220, loss_ce: 0.060935
[00:17:11.000] iteration 1011 : loss : 0.296850, loss_ce: 0.064541
[00:17:11.306] iteration 1012 : loss : 0.246970, loss_ce: 0.068683
[00:17:11.615] iteration 1013 : loss : 0.261080, loss_ce: 0.071846
[00:17:11.920] iteration 1014 : loss : 0.271442, loss_ce: 0.093500
[00:17:12.224] iteration 1015 : loss : 0.250139, loss_ce: 0.063168
[00:17:12.531] iteration 1016 : loss : 0.211930, loss_ce: 0.067737
[00:17:12.838] iteration 1017 : loss : 0.255462, loss_ce: 0.066938
[00:17:13.144] iteration 1018 : loss : 0.274830, loss_ce: 0.063647
[00:17:13.453] iteration 1019 : loss : 0.346116, loss_ce: 0.060036
[00:17:13.759] iteration 1020 : loss : 0.268842, loss_ce: 0.111414
[00:17:14.085] iteration 1021 : loss : 0.314619, loss_ce: 0.063290
[00:17:14.387] iteration 1022 : loss : 0.246933, loss_ce: 0.046511
[00:17:14.696] iteration 1023 : loss : 0.212301, loss_ce: 0.055947
[00:17:15.003] iteration 1024 : loss : 0.302689, loss_ce: 0.092548
[00:17:15.317] iteration 1025 : loss : 0.288999, loss_ce: 0.078781
[00:17:15.619] iteration 1026 : loss : 0.235807, loss_ce: 0.069436
[00:17:15.925] iteration 1027 : loss : 0.291268, loss_ce: 0.041650
[00:17:16.230] iteration 1028 : loss : 0.272326, loss_ce: 0.083510
[00:17:16.538] iteration 1029 : loss : 0.254029, loss_ce: 0.105622
[00:17:16.846] iteration 1030 : loss : 0.268585, loss_ce: 0.141041
[00:17:17.150] iteration 1031 : loss : 0.273555, loss_ce: 0.080474
[00:17:17.458] iteration 1032 : loss : 0.218713, loss_ce: 0.065455
[00:17:17.761] iteration 1033 : loss : 0.240429, loss_ce: 0.060584
[00:17:18.067] iteration 1034 : loss : 0.226539, loss_ce: 0.089871
[00:17:18.373] iteration 1035 : loss : 0.248448, loss_ce: 0.063225
[00:17:18.685] iteration 1036 : loss : 0.267019, loss_ce: 0.113079
[00:17:19.000] iteration 1037 : loss : 0.196690, loss_ce: 0.093797
[00:17:19.300] iteration 1038 : loss : 0.216761, loss_ce: 0.055219
[00:17:19.612] iteration 1039 : loss : 0.245790, loss_ce: 0.069144
[00:17:19.919] iteration 1040 : loss : 0.233434, loss_ce: 0.050990
[00:17:20.248] iteration 1041 : loss : 0.214960, loss_ce: 0.033484
[00:17:20.552] iteration 1042 : loss : 0.253621, loss_ce: 0.048044
[00:17:20.857] iteration 1043 : loss : 0.231649, loss_ce: 0.082405
[00:17:21.165] iteration 1044 : loss : 0.265581, loss_ce: 0.078859
[00:17:21.470] iteration 1045 : loss : 0.216093, loss_ce: 0.051114
[00:17:21.777] iteration 1046 : loss : 0.288476, loss_ce: 0.108446
[00:17:22.082] iteration 1047 : loss : 0.218111, loss_ce: 0.041198
[00:17:22.396] iteration 1048 : loss : 0.171841, loss_ce: 0.036981
[00:17:22.701] iteration 1049 : loss : 0.297621, loss_ce: 0.070111
[00:17:23.004] iteration 1050 : loss : 0.252676, loss_ce: 0.024900
[00:17:23.311] iteration 1051 : loss : 0.175260, loss_ce: 0.043868
[00:17:23.614] iteration 1052 : loss : 0.230870, loss_ce: 0.056608
[00:17:23.921] iteration 1053 : loss : 0.260053, loss_ce: 0.074928
[00:17:24.227] iteration 1054 : loss : 0.303516, loss_ce: 0.079746
[00:17:24.538] iteration 1055 : loss : 0.240460, loss_ce: 0.069409
[00:17:24.844] iteration 1056 : loss : 0.302359, loss_ce: 0.080678
[00:17:25.149] iteration 1057 : loss : 0.216940, loss_ce: 0.072233
[00:17:25.452] iteration 1058 : loss : 0.243619, loss_ce: 0.058489
[00:17:25.757] iteration 1059 : loss : 0.253665, loss_ce: 0.076363
[00:17:26.056] iteration 1060 : loss : 0.291891, loss_ce: 0.056700
[00:17:26.380] iteration 1061 : loss : 0.321315, loss_ce: 0.058672
[00:17:26.679] iteration 1062 : loss : 0.236678, loss_ce: 0.108730
[00:17:26.987] iteration 1063 : loss : 0.165683, loss_ce: 0.039108
[00:17:27.292] iteration 1064 : loss : 0.336545, loss_ce: 0.034662
[00:17:27.601] iteration 1065 : loss : 0.283412, loss_ce: 0.070238
[00:17:27.909] iteration 1066 : loss : 0.264069, loss_ce: 0.057447
[00:17:28.215] iteration 1067 : loss : 0.240389, loss_ce: 0.055951
[00:17:28.525] iteration 1068 : loss : 0.299658, loss_ce: 0.047556
[00:17:28.835] iteration 1069 : loss : 0.237934, loss_ce: 0.083809
[00:17:29.133] iteration 1070 : loss : 0.257924, loss_ce: 0.058491
[00:17:29.437] iteration 1071 : loss : 0.216739, loss_ce: 0.107846
[00:17:29.753] iteration 1072 : loss : 0.406149, loss_ce: 0.016900
[00:17:30.056] iteration 1073 : loss : 0.309266, loss_ce: 0.102160
[00:17:30.370] iteration 1074 : loss : 0.266358, loss_ce: 0.078871
[00:17:30.674] iteration 1075 : loss : 0.264101, loss_ce: 0.080085
[00:17:30.979] iteration 1076 : loss : 0.229372, loss_ce: 0.050982
[00:17:31.283] iteration 1077 : loss : 0.184956, loss_ce: 0.058000
[00:17:31.602] iteration 1078 : loss : 0.245788, loss_ce: 0.053936
[00:17:31.909] iteration 1079 : loss : 0.276904, loss_ce: 0.121617
[00:17:32.217] iteration 1080 : loss : 0.219415, loss_ce: 0.045658
[00:17:32.557] iteration 1081 : loss : 0.194197, loss_ce: 0.062386
[00:17:32.867] iteration 1082 : loss : 0.244551, loss_ce: 0.049656
[00:17:33.179] iteration 1083 : loss : 0.218358, loss_ce: 0.063002
[00:17:33.482] iteration 1084 : loss : 0.323315, loss_ce: 0.072521
[00:17:33.790] iteration 1085 : loss : 0.246973, loss_ce: 0.044729
[00:17:34.092] iteration 1086 : loss : 0.252550, loss_ce: 0.062834
[00:17:34.395] iteration 1087 : loss : 0.271010, loss_ce: 0.102550
[00:17:34.704] iteration 1088 : loss : 0.264542, loss_ce: 0.066352
[00:17:35.012] iteration 1089 : loss : 0.286699, loss_ce: 0.067608
[00:17:35.322] iteration 1090 : loss : 0.193294, loss_ce: 0.046103
[00:17:35.623] iteration 1091 : loss : 0.263562, loss_ce: 0.065600
[00:17:35.936] iteration 1092 : loss : 0.304384, loss_ce: 0.044767
[00:17:36.239] iteration 1093 : loss : 0.168529, loss_ce: 0.040591
[00:17:36.544] iteration 1094 : loss : 0.244084, loss_ce: 0.074435
[00:17:36.854] iteration 1095 : loss : 0.288252, loss_ce: 0.053632
[00:17:37.162] iteration 1096 : loss : 0.232895, loss_ce: 0.041982
[00:17:37.481] iteration 1097 : loss : 0.269019, loss_ce: 0.060721
[00:17:37.788] iteration 1098 : loss : 0.180443, loss_ce: 0.036717
[00:17:38.101] iteration 1099 : loss : 0.255730, loss_ce: 0.049704
[00:17:38.409] iteration 1100 : loss : 0.205858, loss_ce: 0.055284
[00:17:38.766] iteration 1101 : loss : 0.251002, loss_ce: 0.062780
[00:17:39.073] iteration 1102 : loss : 0.238636, loss_ce: 0.057871
[00:17:39.393] iteration 1103 : loss : 0.216601, loss_ce: 0.063071
[00:17:39.712] iteration 1104 : loss : 0.217381, loss_ce: 0.051143
[00:17:40.023] iteration 1105 : loss : 0.276055, loss_ce: 0.040461
[00:17:40.331] iteration 1106 : loss : 0.255722, loss_ce: 0.048959
[00:17:40.639] iteration 1107 : loss : 0.178616, loss_ce: 0.037177
[00:17:40.950] iteration 1108 : loss : 0.279283, loss_ce: 0.066579
[00:17:41.268] iteration 1109 : loss : 0.232845, loss_ce: 0.078719
[00:17:41.580] iteration 1110 : loss : 0.231054, loss_ce: 0.086675
[00:17:41.888] iteration 1111 : loss : 0.217096, loss_ce: 0.089691
[00:17:41.966] iteration 1112 : loss : 0.249349, loss_ce: 0.075205
[00:18:00.198] iteration 1113 : loss : 0.265542, loss_ce: 0.057194
[00:18:00.502] iteration 1114 : loss : 0.192200, loss_ce: 0.051023
[00:18:00.820] iteration 1115 : loss : 0.212464, loss_ce: 0.077376
[00:18:01.127] iteration 1116 : loss : 0.178569, loss_ce: 0.049691
[00:18:01.435] iteration 1117 : loss : 0.209407, loss_ce: 0.044422
[00:18:01.736] iteration 1118 : loss : 0.295065, loss_ce: 0.051218
[00:18:02.043] iteration 1119 : loss : 0.190889, loss_ce: 0.059536
[00:18:02.347] iteration 1120 : loss : 0.236137, loss_ce: 0.103036
[00:18:02.666] iteration 1121 : loss : 0.242126, loss_ce: 0.066772
[00:18:02.970] iteration 1122 : loss : 0.242523, loss_ce: 0.043329
[00:18:03.273] iteration 1123 : loss : 0.294686, loss_ce: 0.077674
[00:18:03.574] iteration 1124 : loss : 0.197017, loss_ce: 0.052173
[00:18:03.881] iteration 1125 : loss : 0.132983, loss_ce: 0.024669
[00:18:04.185] iteration 1126 : loss : 0.313634, loss_ce: 0.062654
[00:18:04.502] iteration 1127 : loss : 0.270346, loss_ce: 0.042377
[00:18:04.809] iteration 1128 : loss : 0.227253, loss_ce: 0.050353
[00:18:05.115] iteration 1129 : loss : 0.206092, loss_ce: 0.047180
[00:18:05.421] iteration 1130 : loss : 0.272540, loss_ce: 0.071966
[00:18:05.729] iteration 1131 : loss : 0.226704, loss_ce: 0.021061
[00:18:06.033] iteration 1132 : loss : 0.265183, loss_ce: 0.076990
[00:18:06.332] iteration 1133 : loss : 0.225730, loss_ce: 0.065630
[00:18:06.633] iteration 1134 : loss : 0.216500, loss_ce: 0.056431
[00:18:06.937] iteration 1135 : loss : 0.222117, loss_ce: 0.057445
[00:18:07.244] iteration 1136 : loss : 0.246481, loss_ce: 0.040549
[00:18:07.553] iteration 1137 : loss : 0.227335, loss_ce: 0.091656
[00:18:07.856] iteration 1138 : loss : 0.285983, loss_ce: 0.059645
[00:18:08.153] iteration 1139 : loss : 0.269091, loss_ce: 0.072076
[00:18:08.462] iteration 1140 : loss : 0.210847, loss_ce: 0.045447
[00:18:08.785] iteration 1141 : loss : 0.306835, loss_ce: 0.093339
[00:18:09.079] iteration 1142 : loss : 0.182998, loss_ce: 0.074074
[00:18:09.380] iteration 1143 : loss : 0.313923, loss_ce: 0.087577
[00:18:09.687] iteration 1144 : loss : 0.219316, loss_ce: 0.064580
[00:18:09.987] iteration 1145 : loss : 0.181486, loss_ce: 0.076250
[00:18:10.292] iteration 1146 : loss : 0.213005, loss_ce: 0.082180
[00:18:10.595] iteration 1147 : loss : 0.261924, loss_ce: 0.046209
[00:18:10.892] iteration 1148 : loss : 0.294115, loss_ce: 0.112234
[00:18:11.197] iteration 1149 : loss : 0.207759, loss_ce: 0.062230
[00:18:11.496] iteration 1150 : loss : 0.195755, loss_ce: 0.056060
[00:18:11.800] iteration 1151 : loss : 0.330732, loss_ce: 0.068189
[00:18:12.101] iteration 1152 : loss : 0.251770, loss_ce: 0.062666
[00:18:12.406] iteration 1153 : loss : 0.219586, loss_ce: 0.067540
[00:18:12.706] iteration 1154 : loss : 0.269696, loss_ce: 0.046856
[00:18:13.009] iteration 1155 : loss : 0.189958, loss_ce: 0.090372
[00:18:13.319] iteration 1156 : loss : 0.181098, loss_ce: 0.054565
[00:18:13.616] iteration 1157 : loss : 0.188596, loss_ce: 0.055772
[00:18:13.918] iteration 1158 : loss : 0.188573, loss_ce: 0.055560
[00:18:14.227] iteration 1159 : loss : 0.188229, loss_ce: 0.049881
[00:18:14.529] iteration 1160 : loss : 0.175514, loss_ce: 0.052058
[00:18:14.860] iteration 1161 : loss : 0.186843, loss_ce: 0.062926
[00:18:15.162] iteration 1162 : loss : 0.207156, loss_ce: 0.059016
[00:18:15.470] iteration 1163 : loss : 0.180649, loss_ce: 0.049121
[00:18:15.769] iteration 1164 : loss : 0.217591, loss_ce: 0.031219
[00:18:16.080] iteration 1165 : loss : 0.260751, loss_ce: 0.071998
[00:18:16.388] iteration 1166 : loss : 0.214948, loss_ce: 0.074613
[00:18:16.692] iteration 1167 : loss : 0.165725, loss_ce: 0.062269
[00:18:16.992] iteration 1168 : loss : 0.211718, loss_ce: 0.068053
[00:18:17.292] iteration 1169 : loss : 0.254155, loss_ce: 0.043350
[00:18:17.596] iteration 1170 : loss : 0.161675, loss_ce: 0.051893
[00:18:17.899] iteration 1171 : loss : 0.250013, loss_ce: 0.024221
[00:18:18.204] iteration 1172 : loss : 0.200837, loss_ce: 0.044088
[00:18:18.505] iteration 1173 : loss : 0.247173, loss_ce: 0.023505
[00:18:18.812] iteration 1174 : loss : 0.216292, loss_ce: 0.039105
[00:18:19.118] iteration 1175 : loss : 0.180378, loss_ce: 0.064377
[00:18:19.413] iteration 1176 : loss : 0.213024, loss_ce: 0.054922
[00:18:19.722] iteration 1177 : loss : 0.223570, loss_ce: 0.039224
[00:18:20.029] iteration 1178 : loss : 0.223210, loss_ce: 0.067686
[00:18:20.330] iteration 1179 : loss : 0.201301, loss_ce: 0.099270
[00:18:20.634] iteration 1180 : loss : 0.257358, loss_ce: 0.096298
[00:18:20.956] iteration 1181 : loss : 0.191076, loss_ce: 0.065791
[00:18:21.254] iteration 1182 : loss : 0.208915, loss_ce: 0.064643
[00:18:21.563] iteration 1183 : loss : 0.221693, loss_ce: 0.094748
[00:18:21.870] iteration 1184 : loss : 0.270126, loss_ce: 0.033759
[00:18:22.171] iteration 1185 : loss : 0.244277, loss_ce: 0.030662
[00:18:22.481] iteration 1186 : loss : 0.186874, loss_ce: 0.044368
[00:18:22.793] iteration 1187 : loss : 0.171102, loss_ce: 0.034748
[00:18:23.101] iteration 1188 : loss : 0.186803, loss_ce: 0.061291
[00:18:23.408] iteration 1189 : loss : 0.251874, loss_ce: 0.061581
[00:18:23.718] iteration 1190 : loss : 0.275971, loss_ce: 0.109147
[00:18:24.018] iteration 1191 : loss : 0.225973, loss_ce: 0.059619
[00:18:24.325] iteration 1192 : loss : 0.190224, loss_ce: 0.024321
[00:18:24.628] iteration 1193 : loss : 0.397173, loss_ce: 0.029378
[00:18:24.939] iteration 1194 : loss : 0.261574, loss_ce: 0.098209
[00:18:25.242] iteration 1195 : loss : 0.313930, loss_ce: 0.070419
[00:18:25.545] iteration 1196 : loss : 0.272389, loss_ce: 0.045509
[00:18:25.850] iteration 1197 : loss : 0.213653, loss_ce: 0.068371
[00:18:26.152] iteration 1198 : loss : 0.305178, loss_ce: 0.031584
[00:18:26.464] iteration 1199 : loss : 0.247114, loss_ce: 0.063094
[00:18:26.768] iteration 1200 : loss : 0.211352, loss_ce: 0.083405
[00:18:27.085] iteration 1201 : loss : 0.246078, loss_ce: 0.028662
[00:18:27.392] iteration 1202 : loss : 0.209420, loss_ce: 0.043236
[00:18:27.703] iteration 1203 : loss : 0.213102, loss_ce: 0.060776
[00:18:28.006] iteration 1204 : loss : 0.246435, loss_ce: 0.077285
[00:18:28.316] iteration 1205 : loss : 0.217615, loss_ce: 0.078002
[00:18:28.622] iteration 1206 : loss : 0.258263, loss_ce: 0.078582
[00:18:28.929] iteration 1207 : loss : 0.317665, loss_ce: 0.089942
[00:18:29.232] iteration 1208 : loss : 0.329616, loss_ce: 0.063139
[00:18:29.541] iteration 1209 : loss : 0.209158, loss_ce: 0.034622
[00:18:29.843] iteration 1210 : loss : 0.213503, loss_ce: 0.074754
[00:18:30.150] iteration 1211 : loss : 0.215645, loss_ce: 0.098653
[00:18:30.452] iteration 1212 : loss : 0.217717, loss_ce: 0.106033
[00:18:30.758] iteration 1213 : loss : 0.261949, loss_ce: 0.103306
[00:18:31.064] iteration 1214 : loss : 0.243580, loss_ce: 0.069112
[00:18:31.373] iteration 1215 : loss : 0.231056, loss_ce: 0.024614
[00:18:31.678] iteration 1216 : loss : 0.205075, loss_ce: 0.049999
[00:18:31.991] iteration 1217 : loss : 0.187965, loss_ce: 0.066797
[00:18:32.293] iteration 1218 : loss : 0.223710, loss_ce: 0.036662
[00:18:32.602] iteration 1219 : loss : 0.325919, loss_ce: 0.112818
[00:18:32.910] iteration 1220 : loss : 0.219960, loss_ce: 0.095261
[00:18:33.233] iteration 1221 : loss : 0.225696, loss_ce: 0.069476
[00:18:33.533] iteration 1222 : loss : 0.176356, loss_ce: 0.039123
[00:18:33.839] iteration 1223 : loss : 0.188884, loss_ce: 0.079593
[00:18:34.147] iteration 1224 : loss : 0.233836, loss_ce: 0.064605
[00:18:34.451] iteration 1225 : loss : 0.188446, loss_ce: 0.061447
[00:18:34.766] iteration 1226 : loss : 0.287931, loss_ce: 0.073179
[00:18:35.068] iteration 1227 : loss : 0.209011, loss_ce: 0.069072
[00:18:35.371] iteration 1228 : loss : 0.254995, loss_ce: 0.013790
[00:18:35.678] iteration 1229 : loss : 0.236840, loss_ce: 0.053047
[00:18:35.978] iteration 1230 : loss : 0.224408, loss_ce: 0.070575
[00:18:36.289] iteration 1231 : loss : 0.342052, loss_ce: 0.082433
[00:18:36.595] iteration 1232 : loss : 0.173266, loss_ce: 0.041916
[00:18:36.900] iteration 1233 : loss : 0.258232, loss_ce: 0.059944
[00:18:37.204] iteration 1234 : loss : 0.266581, loss_ce: 0.092116
[00:18:37.515] iteration 1235 : loss : 0.231563, loss_ce: 0.056898
[00:18:37.818] iteration 1236 : loss : 0.256884, loss_ce: 0.067314
[00:18:38.142] iteration 1237 : loss : 0.204488, loss_ce: 0.039832
[00:18:38.458] iteration 1238 : loss : 0.213759, loss_ce: 0.057837
[00:18:38.758] iteration 1239 : loss : 0.319275, loss_ce: 0.045896
[00:18:39.068] iteration 1240 : loss : 0.267926, loss_ce: 0.080861
[00:18:39.408] iteration 1241 : loss : 0.295802, loss_ce: 0.021385
[00:18:39.717] iteration 1242 : loss : 0.269112, loss_ce: 0.057386
[00:18:40.031] iteration 1243 : loss : 0.217208, loss_ce: 0.050505
[00:18:40.341] iteration 1244 : loss : 0.180803, loss_ce: 0.064092
[00:18:40.645] iteration 1245 : loss : 0.206476, loss_ce: 0.089930
[00:18:40.957] iteration 1246 : loss : 0.206121, loss_ce: 0.055905
[00:18:41.267] iteration 1247 : loss : 0.246551, loss_ce: 0.052505
[00:18:41.583] iteration 1248 : loss : 0.274994, loss_ce: 0.077972
[00:18:41.891] iteration 1249 : loss : 0.235870, loss_ce: 0.101161
[00:18:42.210] iteration 1250 : loss : 0.182134, loss_ce: 0.040186
[00:18:42.299] iteration 1251 : loss : 0.279137, loss_ce: 0.060490
[00:19:01.011] iteration 1252 : loss : 0.244451, loss_ce: 0.083158
[00:19:01.321] iteration 1253 : loss : 0.317710, loss_ce: 0.016286
[00:19:01.633] iteration 1254 : loss : 0.300652, loss_ce: 0.051637
[00:19:01.955] iteration 1255 : loss : 0.222167, loss_ce: 0.059568
[00:19:02.259] iteration 1256 : loss : 0.216970, loss_ce: 0.066380
[00:19:02.569] iteration 1257 : loss : 0.203912, loss_ce: 0.063467
[00:19:02.868] iteration 1258 : loss : 0.163649, loss_ce: 0.059981
[00:19:03.175] iteration 1259 : loss : 0.181690, loss_ce: 0.061233
[00:19:03.473] iteration 1260 : loss : 0.306033, loss_ce: 0.016463
[00:19:03.797] iteration 1261 : loss : 0.200680, loss_ce: 0.076698
[00:19:04.104] iteration 1262 : loss : 0.284627, loss_ce: 0.035287
[00:19:04.414] iteration 1263 : loss : 0.192299, loss_ce: 0.048809
[00:19:04.715] iteration 1264 : loss : 0.176254, loss_ce: 0.045926
[00:19:05.024] iteration 1265 : loss : 0.146098, loss_ce: 0.039699
[00:19:05.326] iteration 1266 : loss : 0.239954, loss_ce: 0.067405
[00:19:05.635] iteration 1267 : loss : 0.293920, loss_ce: 0.066056
[00:19:05.934] iteration 1268 : loss : 0.178942, loss_ce: 0.061595
[00:19:06.241] iteration 1269 : loss : 0.210524, loss_ce: 0.079908
[00:19:06.546] iteration 1270 : loss : 0.233243, loss_ce: 0.066886
[00:19:06.850] iteration 1271 : loss : 0.195796, loss_ce: 0.034655
[00:19:07.153] iteration 1272 : loss : 0.217730, loss_ce: 0.035195
[00:19:07.456] iteration 1273 : loss : 0.173277, loss_ce: 0.059103
[00:19:07.761] iteration 1274 : loss : 0.283107, loss_ce: 0.048747
[00:19:08.063] iteration 1275 : loss : 0.147174, loss_ce: 0.045420
[00:19:08.372] iteration 1276 : loss : 0.173919, loss_ce: 0.043293
[00:19:08.671] iteration 1277 : loss : 0.205033, loss_ce: 0.045761
[00:19:08.979] iteration 1278 : loss : 0.240076, loss_ce: 0.029637
[00:19:09.284] iteration 1279 : loss : 0.186821, loss_ce: 0.033418
[00:19:09.590] iteration 1280 : loss : 0.209776, loss_ce: 0.041528
[00:19:09.916] iteration 1281 : loss : 0.163502, loss_ce: 0.053616
[00:19:10.216] iteration 1282 : loss : 0.165927, loss_ce: 0.067161
[00:19:10.525] iteration 1283 : loss : 0.125247, loss_ce: 0.041015
[00:19:10.833] iteration 1284 : loss : 0.254357, loss_ce: 0.054323
[00:19:11.136] iteration 1285 : loss : 0.149363, loss_ce: 0.055190
[00:19:11.437] iteration 1286 : loss : 0.154046, loss_ce: 0.054080
[00:19:11.738] iteration 1287 : loss : 0.224289, loss_ce: 0.028280
[00:19:12.048] iteration 1288 : loss : 0.196970, loss_ce: 0.074276
[00:19:12.349] iteration 1289 : loss : 0.235973, loss_ce: 0.045397
[00:19:12.656] iteration 1290 : loss : 0.221777, loss_ce: 0.054437
[00:19:12.971] iteration 1291 : loss : 0.234265, loss_ce: 0.034524
[00:19:13.275] iteration 1292 : loss : 0.183115, loss_ce: 0.065400
[00:19:13.572] iteration 1293 : loss : 0.179259, loss_ce: 0.050030
[00:19:13.876] iteration 1294 : loss : 0.210934, loss_ce: 0.036924
[00:19:14.188] iteration 1295 : loss : 0.166393, loss_ce: 0.051273
[00:19:14.493] iteration 1296 : loss : 0.234879, loss_ce: 0.078251
[00:19:14.792] iteration 1297 : loss : 0.366124, loss_ce: 0.016003
[00:19:15.099] iteration 1298 : loss : 0.257269, loss_ce: 0.067160
[00:19:15.407] iteration 1299 : loss : 0.162077, loss_ce: 0.062461
[00:19:15.723] iteration 1300 : loss : 0.177797, loss_ce: 0.045608
[00:19:16.056] iteration 1301 : loss : 0.179003, loss_ce: 0.054576
[00:19:16.364] iteration 1302 : loss : 0.229173, loss_ce: 0.039811
[00:19:16.671] iteration 1303 : loss : 0.256610, loss_ce: 0.051272
[00:19:16.977] iteration 1304 : loss : 0.222376, loss_ce: 0.039295
[00:19:17.284] iteration 1305 : loss : 0.303875, loss_ce: 0.050413
[00:19:17.590] iteration 1306 : loss : 0.223578, loss_ce: 0.081883
[00:19:17.900] iteration 1307 : loss : 0.223723, loss_ce: 0.081934
[00:19:18.209] iteration 1308 : loss : 0.168997, loss_ce: 0.079514
[00:19:18.514] iteration 1309 : loss : 0.248959, loss_ce: 0.060183
[00:19:18.827] iteration 1310 : loss : 0.255455, loss_ce: 0.018840
[00:19:19.133] iteration 1311 : loss : 0.182018, loss_ce: 0.053759
[00:19:19.441] iteration 1312 : loss : 0.199928, loss_ce: 0.079420
[00:19:19.744] iteration 1313 : loss : 0.190735, loss_ce: 0.056730
[00:19:20.059] iteration 1314 : loss : 0.157134, loss_ce: 0.034203
[00:19:20.364] iteration 1315 : loss : 0.240423, loss_ce: 0.056090
[00:19:20.673] iteration 1316 : loss : 0.220804, loss_ce: 0.043806
[00:19:20.980] iteration 1317 : loss : 0.183702, loss_ce: 0.062283
[00:19:21.285] iteration 1318 : loss : 0.209457, loss_ce: 0.046082
[00:19:21.601] iteration 1319 : loss : 0.251039, loss_ce: 0.031466
[00:19:21.906] iteration 1320 : loss : 0.227978, loss_ce: 0.034639
[00:19:22.234] iteration 1321 : loss : 0.214678, loss_ce: 0.031907
[00:19:22.538] iteration 1322 : loss : 0.210307, loss_ce: 0.064159
[00:19:22.848] iteration 1323 : loss : 0.155622, loss_ce: 0.060544
[00:19:23.155] iteration 1324 : loss : 0.188630, loss_ce: 0.056274
[00:19:23.465] iteration 1325 : loss : 0.325847, loss_ce: 0.022897
[00:19:23.769] iteration 1326 : loss : 0.181142, loss_ce: 0.067214
[00:19:24.073] iteration 1327 : loss : 0.250863, loss_ce: 0.060596
[00:19:24.381] iteration 1328 : loss : 0.340746, loss_ce: 0.069363
[00:19:24.683] iteration 1329 : loss : 0.151937, loss_ce: 0.058504
[00:19:24.998] iteration 1330 : loss : 0.164738, loss_ce: 0.043992
[00:19:25.305] iteration 1331 : loss : 0.231848, loss_ce: 0.021797
[00:19:25.616] iteration 1332 : loss : 0.181613, loss_ce: 0.064527
[00:19:25.921] iteration 1333 : loss : 0.161684, loss_ce: 0.050545
[00:19:26.225] iteration 1334 : loss : 0.135583, loss_ce: 0.046685
[00:19:26.536] iteration 1335 : loss : 0.178457, loss_ce: 0.030429
[00:19:26.845] iteration 1336 : loss : 0.231162, loss_ce: 0.033578
[00:19:27.154] iteration 1337 : loss : 0.239697, loss_ce: 0.061113
[00:19:27.460] iteration 1338 : loss : 0.184784, loss_ce: 0.070557
[00:19:27.768] iteration 1339 : loss : 0.192209, loss_ce: 0.066018
[00:19:28.076] iteration 1340 : loss : 0.182538, loss_ce: 0.041597
[00:19:28.410] iteration 1341 : loss : 0.200992, loss_ce: 0.053857
[00:19:28.720] iteration 1342 : loss : 0.210201, loss_ce: 0.037498
[00:19:29.028] iteration 1343 : loss : 0.289104, loss_ce: 0.058360
[00:19:29.337] iteration 1344 : loss : 0.238650, loss_ce: 0.058196
[00:19:29.645] iteration 1345 : loss : 0.174534, loss_ce: 0.043702
[00:19:29.951] iteration 1346 : loss : 0.215212, loss_ce: 0.063038
[00:19:30.266] iteration 1347 : loss : 0.201794, loss_ce: 0.053304
[00:19:30.576] iteration 1348 : loss : 0.217269, loss_ce: 0.051886
[00:19:30.880] iteration 1349 : loss : 0.157874, loss_ce: 0.049770
[00:19:31.188] iteration 1350 : loss : 0.214705, loss_ce: 0.049656
[00:19:31.498] iteration 1351 : loss : 0.186760, loss_ce: 0.068898
[00:19:31.809] iteration 1352 : loss : 0.242047, loss_ce: 0.084768
[00:19:32.122] iteration 1353 : loss : 0.178599, loss_ce: 0.054817
[00:19:32.427] iteration 1354 : loss : 0.141771, loss_ce: 0.032004
[00:19:32.742] iteration 1355 : loss : 0.178743, loss_ce: 0.039536
[00:19:33.047] iteration 1356 : loss : 0.236633, loss_ce: 0.043003
[00:19:33.359] iteration 1357 : loss : 0.240232, loss_ce: 0.033661
[00:19:33.672] iteration 1358 : loss : 0.272967, loss_ce: 0.019017
[00:19:33.977] iteration 1359 : loss : 0.217325, loss_ce: 0.055007
[00:19:34.294] iteration 1360 : loss : 0.233370, loss_ce: 0.060481
[00:19:34.622] iteration 1361 : loss : 0.201556, loss_ce: 0.030679
[00:19:34.925] iteration 1362 : loss : 0.153784, loss_ce: 0.049548
[00:19:35.230] iteration 1363 : loss : 0.161675, loss_ce: 0.045523
[00:19:35.542] iteration 1364 : loss : 0.249926, loss_ce: 0.041164
[00:19:35.849] iteration 1365 : loss : 0.176385, loss_ce: 0.046165
[00:19:36.159] iteration 1366 : loss : 0.263115, loss_ce: 0.035918
[00:19:36.465] iteration 1367 : loss : 0.202151, loss_ce: 0.098004
[00:19:36.774] iteration 1368 : loss : 0.223885, loss_ce: 0.077852
[00:19:37.085] iteration 1369 : loss : 0.287663, loss_ce: 0.072435
[00:19:37.391] iteration 1370 : loss : 0.220478, loss_ce: 0.094216
[00:19:37.700] iteration 1371 : loss : 0.201974, loss_ce: 0.076061
[00:19:38.006] iteration 1372 : loss : 0.210636, loss_ce: 0.053096
[00:19:38.316] iteration 1373 : loss : 0.141955, loss_ce: 0.029405
[00:19:38.619] iteration 1374 : loss : 0.170557, loss_ce: 0.052906
[00:19:38.930] iteration 1375 : loss : 0.230824, loss_ce: 0.041548
[00:19:39.242] iteration 1376 : loss : 0.195742, loss_ce: 0.061885
[00:19:39.551] iteration 1377 : loss : 0.187393, loss_ce: 0.035674
[00:19:39.860] iteration 1378 : loss : 0.237654, loss_ce: 0.094638
[00:19:40.180] iteration 1379 : loss : 0.180750, loss_ce: 0.073262
[00:19:40.493] iteration 1380 : loss : 0.194768, loss_ce: 0.042813
[00:19:40.844] iteration 1381 : loss : 0.253940, loss_ce: 0.067603
[00:19:41.155] iteration 1382 : loss : 0.179760, loss_ce: 0.065837
[00:19:41.478] iteration 1383 : loss : 0.178869, loss_ce: 0.081546
[00:19:41.789] iteration 1384 : loss : 0.130458, loss_ce: 0.037495
[00:19:42.097] iteration 1385 : loss : 0.181502, loss_ce: 0.045252
[00:19:42.415] iteration 1386 : loss : 0.237368, loss_ce: 0.076965
[00:19:42.723] iteration 1387 : loss : 0.217807, loss_ce: 0.086972
[00:19:43.037] iteration 1388 : loss : 0.142634, loss_ce: 0.028508
[00:19:43.341] iteration 1389 : loss : 0.194445, loss_ce: 0.056569
[00:19:43.439] iteration 1390 : loss : 0.281450, loss_ce: 0.042670
[00:20:02.380] iteration 1391 : loss : 0.160801, loss_ce: 0.040630
[00:20:02.686] iteration 1392 : loss : 0.153676, loss_ce: 0.052986
[00:20:02.997] iteration 1393 : loss : 0.186223, loss_ce: 0.046786
[00:20:03.309] iteration 1394 : loss : 0.164850, loss_ce: 0.059810
[00:20:03.615] iteration 1395 : loss : 0.204671, loss_ce: 0.039919
[00:20:03.921] iteration 1396 : loss : 0.201774, loss_ce: 0.043219
[00:20:04.228] iteration 1397 : loss : 0.270492, loss_ce: 0.027861
[00:20:04.531] iteration 1398 : loss : 0.175294, loss_ce: 0.060491
[00:20:04.834] iteration 1399 : loss : 0.179252, loss_ce: 0.059266
[00:20:05.138] iteration 1400 : loss : 0.144535, loss_ce: 0.052653
[00:20:05.460] iteration 1401 : loss : 0.212592, loss_ce: 0.034001
[00:20:05.756] iteration 1402 : loss : 0.230318, loss_ce: 0.039640
[00:20:06.060] iteration 1403 : loss : 0.217648, loss_ce: 0.050763
[00:20:06.363] iteration 1404 : loss : 0.209446, loss_ce: 0.044432
[00:20:06.669] iteration 1405 : loss : 0.224323, loss_ce: 0.044203
[00:20:06.976] iteration 1406 : loss : 0.205244, loss_ce: 0.034433
[00:20:07.289] iteration 1407 : loss : 0.156480, loss_ce: 0.078740
[00:20:07.592] iteration 1408 : loss : 0.184825, loss_ce: 0.061861
[00:20:07.894] iteration 1409 : loss : 0.178474, loss_ce: 0.034623
[00:20:08.214] iteration 1410 : loss : 0.258155, loss_ce: 0.033604
[00:20:08.514] iteration 1411 : loss : 0.137624, loss_ce: 0.023515
[00:20:08.819] iteration 1412 : loss : 0.126932, loss_ce: 0.019096
[00:20:09.136] iteration 1413 : loss : 0.170681, loss_ce: 0.051935
[00:20:09.442] iteration 1414 : loss : 0.240332, loss_ce: 0.038640
[00:20:09.752] iteration 1415 : loss : 0.243296, loss_ce: 0.035491
[00:20:10.057] iteration 1416 : loss : 0.193775, loss_ce: 0.053831
[00:20:10.365] iteration 1417 : loss : 0.222908, loss_ce: 0.027474
[00:20:10.668] iteration 1418 : loss : 0.150843, loss_ce: 0.046199
[00:20:10.975] iteration 1419 : loss : 0.133568, loss_ce: 0.055095
[00:20:11.282] iteration 1420 : loss : 0.184249, loss_ce: 0.041171
[00:20:11.604] iteration 1421 : loss : 0.190684, loss_ce: 0.091046
[00:20:11.904] iteration 1422 : loss : 0.165184, loss_ce: 0.065522
[00:20:12.216] iteration 1423 : loss : 0.171926, loss_ce: 0.065771
[00:20:12.519] iteration 1424 : loss : 0.206637, loss_ce: 0.044431
[00:20:12.824] iteration 1425 : loss : 0.149231, loss_ce: 0.053575
[00:20:13.137] iteration 1426 : loss : 0.319063, loss_ce: 0.046783
[00:20:13.438] iteration 1427 : loss : 0.173316, loss_ce: 0.035850
[00:20:13.742] iteration 1428 : loss : 0.159307, loss_ce: 0.057606
[00:20:14.054] iteration 1429 : loss : 0.159720, loss_ce: 0.021367
[00:20:14.358] iteration 1430 : loss : 0.123757, loss_ce: 0.022719
[00:20:14.659] iteration 1431 : loss : 0.150264, loss_ce: 0.036799
[00:20:14.962] iteration 1432 : loss : 0.234024, loss_ce: 0.058561
[00:20:15.278] iteration 1433 : loss : 0.226299, loss_ce: 0.019736
[00:20:15.585] iteration 1434 : loss : 0.250983, loss_ce: 0.041688
[00:20:15.894] iteration 1435 : loss : 0.170358, loss_ce: 0.038025
[00:20:16.201] iteration 1436 : loss : 0.206973, loss_ce: 0.049158
[00:20:16.502] iteration 1437 : loss : 0.273745, loss_ce: 0.043750
[00:20:16.805] iteration 1438 : loss : 0.177689, loss_ce: 0.048245
[00:20:17.112] iteration 1439 : loss : 0.239152, loss_ce: 0.028851
[00:20:17.411] iteration 1440 : loss : 0.193188, loss_ce: 0.069944
[00:20:17.737] iteration 1441 : loss : 0.186753, loss_ce: 0.049083
[00:20:18.042] iteration 1442 : loss : 0.169449, loss_ce: 0.061612
[00:20:18.349] iteration 1443 : loss : 0.327444, loss_ce: 0.024052
[00:20:18.655] iteration 1444 : loss : 0.205780, loss_ce: 0.049826
[00:20:18.956] iteration 1445 : loss : 0.185814, loss_ce: 0.041202
[00:20:19.258] iteration 1446 : loss : 0.175905, loss_ce: 0.059412
[00:20:19.564] iteration 1447 : loss : 0.179448, loss_ce: 0.049147
[00:20:19.873] iteration 1448 : loss : 0.237710, loss_ce: 0.048200
[00:20:20.180] iteration 1449 : loss : 0.177559, loss_ce: 0.046491
[00:20:20.487] iteration 1450 : loss : 0.144843, loss_ce: 0.024534
[00:20:20.791] iteration 1451 : loss : 0.208569, loss_ce: 0.042001
[00:20:21.097] iteration 1452 : loss : 0.205690, loss_ce: 0.041974
[00:20:21.404] iteration 1453 : loss : 0.213715, loss_ce: 0.020681
[00:20:21.721] iteration 1454 : loss : 0.166173, loss_ce: 0.035423
[00:20:22.031] iteration 1455 : loss : 0.131503, loss_ce: 0.050818
[00:20:22.342] iteration 1456 : loss : 0.182506, loss_ce: 0.011933
[00:20:22.645] iteration 1457 : loss : 0.201346, loss_ce: 0.035239
[00:20:22.959] iteration 1458 : loss : 0.186944, loss_ce: 0.045078
[00:20:23.276] iteration 1459 : loss : 0.175168, loss_ce: 0.025667
[00:20:23.578] iteration 1460 : loss : 0.173852, loss_ce: 0.049915
[00:20:23.897] iteration 1461 : loss : 0.200019, loss_ce: 0.047117
[00:20:24.195] iteration 1462 : loss : 0.198144, loss_ce: 0.046826
[00:20:24.502] iteration 1463 : loss : 0.155058, loss_ce: 0.049466
[00:20:24.807] iteration 1464 : loss : 0.191364, loss_ce: 0.058915
[00:20:25.113] iteration 1465 : loss : 0.173745, loss_ce: 0.042042
[00:20:25.420] iteration 1466 : loss : 0.145780, loss_ce: 0.052546
[00:20:25.733] iteration 1467 : loss : 0.156321, loss_ce: 0.065247
[00:20:26.038] iteration 1468 : loss : 0.215997, loss_ce: 0.044912
[00:20:26.355] iteration 1469 : loss : 0.157909, loss_ce: 0.050375
[00:20:26.668] iteration 1470 : loss : 0.169981, loss_ce: 0.057043
[00:20:26.970] iteration 1471 : loss : 0.166882, loss_ce: 0.058951
[00:20:27.277] iteration 1472 : loss : 0.222449, loss_ce: 0.054744
[00:20:27.582] iteration 1473 : loss : 0.183837, loss_ce: 0.056025
[00:20:27.887] iteration 1474 : loss : 0.140174, loss_ce: 0.047437
[00:20:28.196] iteration 1475 : loss : 0.211273, loss_ce: 0.056776
[00:20:28.504] iteration 1476 : loss : 0.200324, loss_ce: 0.042281
[00:20:28.804] iteration 1477 : loss : 0.154950, loss_ce: 0.043391
[00:20:29.118] iteration 1478 : loss : 0.218935, loss_ce: 0.044713
[00:20:29.426] iteration 1479 : loss : 0.181285, loss_ce: 0.068094
[00:20:29.729] iteration 1480 : loss : 0.152898, loss_ce: 0.050507
[00:20:30.054] iteration 1481 : loss : 0.185882, loss_ce: 0.076534
[00:20:30.355] iteration 1482 : loss : 0.164846, loss_ce: 0.049603
[00:20:30.665] iteration 1483 : loss : 0.243067, loss_ce: 0.048137
[00:20:30.968] iteration 1484 : loss : 0.167928, loss_ce: 0.040048
[00:20:31.270] iteration 1485 : loss : 0.162430, loss_ce: 0.043259
[00:20:31.571] iteration 1486 : loss : 0.219242, loss_ce: 0.080661
[00:20:31.876] iteration 1487 : loss : 0.185570, loss_ce: 0.042253
[00:20:32.185] iteration 1488 : loss : 0.163140, loss_ce: 0.055793
[00:20:32.494] iteration 1489 : loss : 0.212861, loss_ce: 0.043944
[00:20:32.802] iteration 1490 : loss : 0.167600, loss_ce: 0.028661
[00:20:33.117] iteration 1491 : loss : 0.196334, loss_ce: 0.039358
[00:20:33.420] iteration 1492 : loss : 0.180757, loss_ce: 0.043760
[00:20:33.732] iteration 1493 : loss : 0.202428, loss_ce: 0.064829
[00:20:34.036] iteration 1494 : loss : 0.210113, loss_ce: 0.027499
[00:20:34.348] iteration 1495 : loss : 0.168695, loss_ce: 0.037300
[00:20:34.665] iteration 1496 : loss : 0.222070, loss_ce: 0.092747
[00:20:34.973] iteration 1497 : loss : 0.176610, loss_ce: 0.043358
[00:20:35.276] iteration 1498 : loss : 0.200085, loss_ce: 0.041761
[00:20:35.585] iteration 1499 : loss : 0.169444, loss_ce: 0.035040
[00:20:35.887] iteration 1500 : loss : 0.154367, loss_ce: 0.026770
[00:20:36.214] iteration 1501 : loss : 0.190800, loss_ce: 0.046354
[00:20:36.520] iteration 1502 : loss : 0.200016, loss_ce: 0.055558
[00:20:36.824] iteration 1503 : loss : 0.166921, loss_ce: 0.059140
[00:20:37.131] iteration 1504 : loss : 0.201703, loss_ce: 0.071617
[00:20:37.430] iteration 1505 : loss : 0.213501, loss_ce: 0.097129
[00:20:37.741] iteration 1506 : loss : 0.153052, loss_ce: 0.044839
[00:20:38.049] iteration 1507 : loss : 0.158373, loss_ce: 0.040036
[00:20:38.351] iteration 1508 : loss : 0.248234, loss_ce: 0.047234
[00:20:38.655] iteration 1509 : loss : 0.152282, loss_ce: 0.048088
[00:20:38.958] iteration 1510 : loss : 0.207040, loss_ce: 0.113361
[00:20:39.261] iteration 1511 : loss : 0.174090, loss_ce: 0.067627
[00:20:39.578] iteration 1512 : loss : 0.156115, loss_ce: 0.056622
[00:20:39.880] iteration 1513 : loss : 0.215882, loss_ce: 0.042295
[00:20:40.191] iteration 1514 : loss : 0.173230, loss_ce: 0.045421
[00:20:40.502] iteration 1515 : loss : 0.180444, loss_ce: 0.067019
[00:20:40.813] iteration 1516 : loss : 0.192071, loss_ce: 0.063360
[00:20:41.123] iteration 1517 : loss : 0.192302, loss_ce: 0.064831
[00:20:41.434] iteration 1518 : loss : 0.165471, loss_ce: 0.022955
[00:20:41.748] iteration 1519 : loss : 0.175349, loss_ce: 0.080978
[00:20:42.054] iteration 1520 : loss : 0.239405, loss_ce: 0.035524
[00:20:42.390] iteration 1521 : loss : 0.178317, loss_ce: 0.022681
[00:20:42.697] iteration 1522 : loss : 0.203334, loss_ce: 0.041859
[00:20:43.009] iteration 1523 : loss : 0.215461, loss_ce: 0.043992
[00:20:43.328] iteration 1524 : loss : 0.154331, loss_ce: 0.031384
[00:20:43.637] iteration 1525 : loss : 0.202331, loss_ce: 0.040397
[00:20:43.941] iteration 1526 : loss : 0.341608, loss_ce: 0.033740
[00:20:44.259] iteration 1527 : loss : 0.192300, loss_ce: 0.039358
[00:20:44.558] iteration 1528 : loss : 0.209675, loss_ce: 0.062429
[00:20:44.635] iteration 1529 : loss : 0.224366, loss_ce: 0.049368
[00:21:03.329] iteration 1530 : loss : 0.190757, loss_ce: 0.051556
[00:21:03.639] iteration 1531 : loss : 0.209265, loss_ce: 0.056054
[00:21:03.951] iteration 1532 : loss : 0.242522, loss_ce: 0.021487
[00:21:04.263] iteration 1533 : loss : 0.226133, loss_ce: 0.069719
[00:21:04.574] iteration 1534 : loss : 0.222745, loss_ce: 0.063375
[00:21:04.881] iteration 1535 : loss : 0.206405, loss_ce: 0.079185
[00:21:05.191] iteration 1536 : loss : 0.197612, loss_ce: 0.059971
[00:21:05.491] iteration 1537 : loss : 0.164656, loss_ce: 0.033303
[00:21:05.790] iteration 1538 : loss : 0.125400, loss_ce: 0.027717
[00:21:06.097] iteration 1539 : loss : 0.147458, loss_ce: 0.048614
[00:21:06.396] iteration 1540 : loss : 0.165260, loss_ce: 0.068072
[00:21:06.728] iteration 1541 : loss : 0.199118, loss_ce: 0.085228
[00:21:07.035] iteration 1542 : loss : 0.143153, loss_ce: 0.027660
[00:21:07.341] iteration 1543 : loss : 0.174414, loss_ce: 0.048338
[00:21:07.656] iteration 1544 : loss : 0.191815, loss_ce: 0.078571
[00:21:07.966] iteration 1545 : loss : 0.162719, loss_ce: 0.053626
[00:21:08.270] iteration 1546 : loss : 0.210854, loss_ce: 0.037301
[00:21:08.573] iteration 1547 : loss : 0.223108, loss_ce: 0.055559
[00:21:08.884] iteration 1548 : loss : 0.183866, loss_ce: 0.029168
[00:21:09.188] iteration 1549 : loss : 0.135059, loss_ce: 0.052840
[00:21:09.494] iteration 1550 : loss : 0.140520, loss_ce: 0.035350
[00:21:09.801] iteration 1551 : loss : 0.216422, loss_ce: 0.026502
[00:21:10.101] iteration 1552 : loss : 0.282722, loss_ce: 0.065909
[00:21:10.412] iteration 1553 : loss : 0.145801, loss_ce: 0.057520
[00:21:10.717] iteration 1554 : loss : 0.210746, loss_ce: 0.059585
[00:21:11.021] iteration 1555 : loss : 0.166156, loss_ce: 0.054955
[00:21:11.325] iteration 1556 : loss : 0.199676, loss_ce: 0.041493
[00:21:11.641] iteration 1557 : loss : 0.172909, loss_ce: 0.067529
[00:21:11.944] iteration 1558 : loss : 0.182863, loss_ce: 0.037910
[00:21:12.245] iteration 1559 : loss : 0.128346, loss_ce: 0.040620
[00:21:12.548] iteration 1560 : loss : 0.242659, loss_ce: 0.039535
[00:21:12.883] iteration 1561 : loss : 0.198566, loss_ce: 0.033696
[00:21:13.187] iteration 1562 : loss : 0.180592, loss_ce: 0.041556
[00:21:13.492] iteration 1563 : loss : 0.120185, loss_ce: 0.042164
[00:21:13.795] iteration 1564 : loss : 0.161415, loss_ce: 0.068103
[00:21:14.098] iteration 1565 : loss : 0.158119, loss_ce: 0.063522
[00:21:14.411] iteration 1566 : loss : 0.150495, loss_ce: 0.036383
[00:21:14.721] iteration 1567 : loss : 0.228351, loss_ce: 0.049985
[00:21:15.026] iteration 1568 : loss : 0.116223, loss_ce: 0.045527
[00:21:15.327] iteration 1569 : loss : 0.157532, loss_ce: 0.060015
[00:21:15.634] iteration 1570 : loss : 0.171551, loss_ce: 0.032988
[00:21:15.947] iteration 1571 : loss : 0.149007, loss_ce: 0.053318
[00:21:16.255] iteration 1572 : loss : 0.176355, loss_ce: 0.036751
[00:21:16.565] iteration 1573 : loss : 0.177160, loss_ce: 0.044659
[00:21:16.868] iteration 1574 : loss : 0.189273, loss_ce: 0.043826
[00:21:17.176] iteration 1575 : loss : 0.165148, loss_ce: 0.035702
[00:21:17.484] iteration 1576 : loss : 0.131276, loss_ce: 0.026021
[00:21:17.787] iteration 1577 : loss : 0.167728, loss_ce: 0.043842
[00:21:18.088] iteration 1578 : loss : 0.160352, loss_ce: 0.051278
[00:21:18.399] iteration 1579 : loss : 0.118512, loss_ce: 0.032502
[00:21:18.707] iteration 1580 : loss : 0.139137, loss_ce: 0.040955
[00:21:19.041] iteration 1581 : loss : 0.136603, loss_ce: 0.038505
[00:21:19.347] iteration 1582 : loss : 0.135544, loss_ce: 0.038206
[00:21:19.654] iteration 1583 : loss : 0.161690, loss_ce: 0.053850
[00:21:19.960] iteration 1584 : loss : 0.205840, loss_ce: 0.022980
[00:21:20.266] iteration 1585 : loss : 0.145045, loss_ce: 0.039972
[00:21:20.574] iteration 1586 : loss : 0.221521, loss_ce: 0.040941
[00:21:20.880] iteration 1587 : loss : 0.167956, loss_ce: 0.035861
[00:21:21.192] iteration 1588 : loss : 0.152694, loss_ce: 0.046791
[00:21:21.500] iteration 1589 : loss : 0.153108, loss_ce: 0.064631
[00:21:21.806] iteration 1590 : loss : 0.215697, loss_ce: 0.046907
[00:21:22.117] iteration 1591 : loss : 0.235729, loss_ce: 0.033377
[00:21:22.418] iteration 1592 : loss : 0.110659, loss_ce: 0.042281
[00:21:22.724] iteration 1593 : loss : 0.304764, loss_ce: 0.003736
[00:21:23.034] iteration 1594 : loss : 0.154896, loss_ce: 0.026024
[00:21:23.335] iteration 1595 : loss : 0.138922, loss_ce: 0.022630
[00:21:23.644] iteration 1596 : loss : 0.186765, loss_ce: 0.057684
[00:21:23.950] iteration 1597 : loss : 0.152824, loss_ce: 0.049661
[00:21:24.269] iteration 1598 : loss : 0.189213, loss_ce: 0.028830
[00:21:24.568] iteration 1599 : loss : 0.144680, loss_ce: 0.033488
[00:21:24.870] iteration 1600 : loss : 0.156576, loss_ce: 0.050743
[00:21:25.200] iteration 1601 : loss : 0.218167, loss_ce: 0.070404
[00:21:25.504] iteration 1602 : loss : 0.175405, loss_ce: 0.044432
[00:21:25.810] iteration 1603 : loss : 0.169152, loss_ce: 0.081519
[00:21:26.123] iteration 1604 : loss : 0.181707, loss_ce: 0.020415
[00:21:26.429] iteration 1605 : loss : 0.194815, loss_ce: 0.044366
[00:21:26.728] iteration 1606 : loss : 0.164630, loss_ce: 0.055610
[00:21:27.041] iteration 1607 : loss : 0.191847, loss_ce: 0.050906
[00:21:27.351] iteration 1608 : loss : 0.209036, loss_ce: 0.020658
[00:21:27.655] iteration 1609 : loss : 0.148242, loss_ce: 0.041776
[00:21:27.974] iteration 1610 : loss : 0.204505, loss_ce: 0.049101
[00:21:28.278] iteration 1611 : loss : 0.257848, loss_ce: 0.042026
[00:21:28.579] iteration 1612 : loss : 0.139733, loss_ce: 0.053148
[00:21:28.894] iteration 1613 : loss : 0.123474, loss_ce: 0.049382
[00:21:29.200] iteration 1614 : loss : 0.198792, loss_ce: 0.029953
[00:21:29.505] iteration 1615 : loss : 0.226495, loss_ce: 0.042674
[00:21:29.815] iteration 1616 : loss : 0.235419, loss_ce: 0.036669
[00:21:30.120] iteration 1617 : loss : 0.220862, loss_ce: 0.014607
[00:21:30.426] iteration 1618 : loss : 0.167464, loss_ce: 0.032391
[00:21:30.731] iteration 1619 : loss : 0.246297, loss_ce: 0.010627
[00:21:31.048] iteration 1620 : loss : 0.179748, loss_ce: 0.060639
[00:21:31.383] iteration 1621 : loss : 0.264079, loss_ce: 0.031818
[00:21:31.691] iteration 1622 : loss : 0.167542, loss_ce: 0.014978
[00:21:31.997] iteration 1623 : loss : 0.164329, loss_ce: 0.038803
[00:21:32.303] iteration 1624 : loss : 0.210287, loss_ce: 0.067755
[00:21:32.607] iteration 1625 : loss : 0.216483, loss_ce: 0.044400
[00:21:32.917] iteration 1626 : loss : 0.144143, loss_ce: 0.027785
[00:21:33.227] iteration 1627 : loss : 0.186151, loss_ce: 0.056952
[00:21:33.538] iteration 1628 : loss : 0.221366, loss_ce: 0.037302
[00:21:33.842] iteration 1629 : loss : 0.153910, loss_ce: 0.048691
[00:21:34.151] iteration 1630 : loss : 0.285731, loss_ce: 0.045856
[00:21:34.457] iteration 1631 : loss : 0.197316, loss_ce: 0.050564
[00:21:34.766] iteration 1632 : loss : 0.139481, loss_ce: 0.021574
[00:21:35.072] iteration 1633 : loss : 0.150508, loss_ce: 0.048318
[00:21:35.382] iteration 1634 : loss : 0.166328, loss_ce: 0.054852
[00:21:35.685] iteration 1635 : loss : 0.157937, loss_ce: 0.036672
[00:21:35.992] iteration 1636 : loss : 0.161405, loss_ce: 0.064319
[00:21:36.300] iteration 1637 : loss : 0.198953, loss_ce: 0.047481
[00:21:36.606] iteration 1638 : loss : 0.160339, loss_ce: 0.046421
[00:21:36.922] iteration 1639 : loss : 0.169357, loss_ce: 0.037174
[00:21:37.231] iteration 1640 : loss : 0.216095, loss_ce: 0.046029
[00:21:37.548] iteration 1641 : loss : 0.127269, loss_ce: 0.032494
[00:21:37.858] iteration 1642 : loss : 0.130850, loss_ce: 0.032149
[00:21:38.165] iteration 1643 : loss : 0.183408, loss_ce: 0.020407
[00:21:38.474] iteration 1644 : loss : 0.157423, loss_ce: 0.046864
[00:21:38.789] iteration 1645 : loss : 0.167721, loss_ce: 0.040950
[00:21:39.099] iteration 1646 : loss : 0.134621, loss_ce: 0.045211
[00:21:39.401] iteration 1647 : loss : 0.174094, loss_ce: 0.054205
[00:21:39.710] iteration 1648 : loss : 0.170899, loss_ce: 0.053883
[00:21:40.016] iteration 1649 : loss : 0.160555, loss_ce: 0.058896
[00:21:40.330] iteration 1650 : loss : 0.193924, loss_ce: 0.038266
[00:21:40.634] iteration 1651 : loss : 0.131947, loss_ce: 0.046742
[00:21:40.951] iteration 1652 : loss : 0.151029, loss_ce: 0.065105
[00:21:41.268] iteration 1653 : loss : 0.164634, loss_ce: 0.067017
[00:21:41.574] iteration 1654 : loss : 0.140429, loss_ce: 0.036926
[00:21:41.886] iteration 1655 : loss : 0.215885, loss_ce: 0.041165
[00:21:42.208] iteration 1656 : loss : 0.161206, loss_ce: 0.035481
[00:21:42.523] iteration 1657 : loss : 0.167513, loss_ce: 0.027908
[00:21:42.832] iteration 1658 : loss : 0.195990, loss_ce: 0.048501
[00:21:43.141] iteration 1659 : loss : 0.126664, loss_ce: 0.042923
[00:21:43.447] iteration 1660 : loss : 0.166173, loss_ce: 0.037198
[00:21:43.791] iteration 1661 : loss : 0.166904, loss_ce: 0.031988
[00:21:44.096] iteration 1662 : loss : 0.161014, loss_ce: 0.051692
[00:21:44.415] iteration 1663 : loss : 0.118124, loss_ce: 0.045715
[00:21:44.731] iteration 1664 : loss : 0.149807, loss_ce: 0.040605
[00:21:45.041] iteration 1665 : loss : 0.144350, loss_ce: 0.041431
[00:21:45.349] iteration 1666 : loss : 0.145673, loss_ce: 0.044286
[00:21:45.664] iteration 1667 : loss : 0.177723, loss_ce: 0.080778
[00:21:45.748] iteration 1668 : loss : 0.394275, loss_ce: 0.028690
[00:22:04.600] iteration 1669 : loss : 0.163583, loss_ce: 0.028789
[00:22:04.909] iteration 1670 : loss : 0.203871, loss_ce: 0.028631
[00:22:05.213] iteration 1671 : loss : 0.273641, loss_ce: 0.014569
[00:22:05.520] iteration 1672 : loss : 0.113924, loss_ce: 0.027691
[00:22:05.828] iteration 1673 : loss : 0.191200, loss_ce: 0.027258
[00:22:06.129] iteration 1674 : loss : 0.185784, loss_ce: 0.088433
[00:22:06.441] iteration 1675 : loss : 0.150650, loss_ce: 0.037429
[00:22:06.745] iteration 1676 : loss : 0.198737, loss_ce: 0.082851
[00:22:07.047] iteration 1677 : loss : 0.171379, loss_ce: 0.073059
[00:22:07.352] iteration 1678 : loss : 0.205506, loss_ce: 0.023858
[00:22:07.658] iteration 1679 : loss : 0.280235, loss_ce: 0.038495
[00:22:07.966] iteration 1680 : loss : 0.227301, loss_ce: 0.044992
[00:22:08.298] iteration 1681 : loss : 0.242478, loss_ce: 0.043096
[00:22:08.600] iteration 1682 : loss : 0.204639, loss_ce: 0.056430
[00:22:08.919] iteration 1683 : loss : 0.179901, loss_ce: 0.037106
[00:22:09.218] iteration 1684 : loss : 0.202317, loss_ce: 0.035061
[00:22:09.522] iteration 1685 : loss : 0.193235, loss_ce: 0.036843
[00:22:09.838] iteration 1686 : loss : 0.164311, loss_ce: 0.048193
[00:22:10.139] iteration 1687 : loss : 0.158688, loss_ce: 0.048014
[00:22:10.439] iteration 1688 : loss : 0.168171, loss_ce: 0.031234
[00:22:10.752] iteration 1689 : loss : 0.168820, loss_ce: 0.043367
[00:22:11.060] iteration 1690 : loss : 0.172132, loss_ce: 0.042009
[00:22:11.367] iteration 1691 : loss : 0.207837, loss_ce: 0.025800
[00:22:11.676] iteration 1692 : loss : 0.141796, loss_ce: 0.064713
[00:22:11.980] iteration 1693 : loss : 0.166706, loss_ce: 0.048074
[00:22:12.283] iteration 1694 : loss : 0.155302, loss_ce: 0.058985
[00:22:12.591] iteration 1695 : loss : 0.149996, loss_ce: 0.077424
[00:22:12.894] iteration 1696 : loss : 0.131850, loss_ce: 0.023322
[00:22:13.201] iteration 1697 : loss : 0.114767, loss_ce: 0.029300
[00:22:13.504] iteration 1698 : loss : 0.176758, loss_ce: 0.048367
[00:22:13.811] iteration 1699 : loss : 0.135192, loss_ce: 0.044191
[00:22:14.114] iteration 1700 : loss : 0.126533, loss_ce: 0.037977
[00:22:14.431] iteration 1701 : loss : 0.193586, loss_ce: 0.040535
[00:22:14.739] iteration 1702 : loss : 0.168727, loss_ce: 0.028352
[00:22:15.053] iteration 1703 : loss : 0.204840, loss_ce: 0.077376
[00:22:15.356] iteration 1704 : loss : 0.200552, loss_ce: 0.050480
[00:22:15.663] iteration 1705 : loss : 0.201266, loss_ce: 0.069768
[00:22:15.965] iteration 1706 : loss : 0.173907, loss_ce: 0.042173
[00:22:16.271] iteration 1707 : loss : 0.137628, loss_ce: 0.045775
[00:22:16.577] iteration 1708 : loss : 0.128194, loss_ce: 0.027500
[00:22:16.881] iteration 1709 : loss : 0.201499, loss_ce: 0.046575
[00:22:17.183] iteration 1710 : loss : 0.141262, loss_ce: 0.037900
[00:22:17.495] iteration 1711 : loss : 0.146396, loss_ce: 0.046199
[00:22:17.802] iteration 1712 : loss : 0.220028, loss_ce: 0.077012
[00:22:18.106] iteration 1713 : loss : 0.156078, loss_ce: 0.013351
[00:22:18.412] iteration 1714 : loss : 0.178456, loss_ce: 0.046474
[00:22:18.713] iteration 1715 : loss : 0.189746, loss_ce: 0.045833
[00:22:19.019] iteration 1716 : loss : 0.135601, loss_ce: 0.044709
[00:22:19.330] iteration 1717 : loss : 0.142079, loss_ce: 0.038585
[00:22:19.636] iteration 1718 : loss : 0.140185, loss_ce: 0.060368
[00:22:19.938] iteration 1719 : loss : 0.218768, loss_ce: 0.048191
[00:22:20.244] iteration 1720 : loss : 0.194107, loss_ce: 0.067521
[00:22:20.568] iteration 1721 : loss : 0.180656, loss_ce: 0.036279
[00:22:20.871] iteration 1722 : loss : 0.183548, loss_ce: 0.060239
[00:22:21.176] iteration 1723 : loss : 0.207474, loss_ce: 0.034002
[00:22:21.480] iteration 1724 : loss : 0.174724, loss_ce: 0.020759
[00:22:21.783] iteration 1725 : loss : 0.187137, loss_ce: 0.043938
[00:22:22.092] iteration 1726 : loss : 0.128213, loss_ce: 0.038161
[00:22:22.394] iteration 1727 : loss : 0.119246, loss_ce: 0.029189
[00:22:22.696] iteration 1728 : loss : 0.143419, loss_ce: 0.021778
[00:22:23.000] iteration 1729 : loss : 0.136080, loss_ce: 0.046684
[00:22:23.300] iteration 1730 : loss : 0.170180, loss_ce: 0.023385
[00:22:23.607] iteration 1731 : loss : 0.143024, loss_ce: 0.058138
[00:22:23.909] iteration 1732 : loss : 0.139740, loss_ce: 0.041928
[00:22:24.214] iteration 1733 : loss : 0.123360, loss_ce: 0.037273
[00:22:24.520] iteration 1734 : loss : 0.220624, loss_ce: 0.040680
[00:22:24.822] iteration 1735 : loss : 0.156843, loss_ce: 0.034393
[00:22:25.128] iteration 1736 : loss : 0.124511, loss_ce: 0.039024
[00:22:25.435] iteration 1737 : loss : 0.110669, loss_ce: 0.032620
[00:22:25.738] iteration 1738 : loss : 0.173507, loss_ce: 0.045744
[00:22:26.048] iteration 1739 : loss : 0.127590, loss_ce: 0.037532
[00:22:26.349] iteration 1740 : loss : 0.120289, loss_ce: 0.033285
[00:22:26.673] iteration 1741 : loss : 0.122186, loss_ce: 0.042974
[00:22:26.984] iteration 1742 : loss : 0.144912, loss_ce: 0.039250
[00:22:27.294] iteration 1743 : loss : 0.135564, loss_ce: 0.043298
[00:22:27.596] iteration 1744 : loss : 0.140101, loss_ce: 0.039334
[00:22:27.901] iteration 1745 : loss : 0.123094, loss_ce: 0.035467
[00:22:28.205] iteration 1746 : loss : 0.150185, loss_ce: 0.052005
[00:22:28.510] iteration 1747 : loss : 0.224287, loss_ce: 0.031871
[00:22:28.818] iteration 1748 : loss : 0.236173, loss_ce: 0.064300
[00:22:29.123] iteration 1749 : loss : 0.182155, loss_ce: 0.041605
[00:22:29.427] iteration 1750 : loss : 0.138985, loss_ce: 0.046075
[00:22:29.736] iteration 1751 : loss : 0.158031, loss_ce: 0.049513
[00:22:30.042] iteration 1752 : loss : 0.217183, loss_ce: 0.027150
[00:22:30.346] iteration 1753 : loss : 0.175023, loss_ce: 0.042690
[00:22:30.653] iteration 1754 : loss : 0.107466, loss_ce: 0.033668
[00:22:30.959] iteration 1755 : loss : 0.135498, loss_ce: 0.055221
[00:22:31.265] iteration 1756 : loss : 0.158535, loss_ce: 0.049260
[00:22:31.569] iteration 1757 : loss : 0.165979, loss_ce: 0.048012
[00:22:31.876] iteration 1758 : loss : 0.158518, loss_ce: 0.028118
[00:22:32.177] iteration 1759 : loss : 0.128385, loss_ce: 0.034192
[00:22:32.486] iteration 1760 : loss : 0.289236, loss_ce: 0.039713
[00:22:32.806] iteration 1761 : loss : 0.176635, loss_ce: 0.047667
[00:22:33.113] iteration 1762 : loss : 0.188290, loss_ce: 0.037388
[00:22:33.416] iteration 1763 : loss : 0.209314, loss_ce: 0.044133
[00:22:33.727] iteration 1764 : loss : 0.190253, loss_ce: 0.039100
[00:22:34.036] iteration 1765 : loss : 0.141616, loss_ce: 0.067252
[00:22:34.338] iteration 1766 : loss : 0.201155, loss_ce: 0.042571
[00:22:34.650] iteration 1767 : loss : 0.194539, loss_ce: 0.055592
[00:22:34.955] iteration 1768 : loss : 0.144123, loss_ce: 0.041956
[00:22:35.269] iteration 1769 : loss : 0.165757, loss_ce: 0.048164
[00:22:35.567] iteration 1770 : loss : 0.232828, loss_ce: 0.029849
[00:22:35.873] iteration 1771 : loss : 0.237228, loss_ce: 0.038371
[00:22:36.180] iteration 1772 : loss : 0.191136, loss_ce: 0.031063
[00:22:36.481] iteration 1773 : loss : 0.180102, loss_ce: 0.032410
[00:22:36.789] iteration 1774 : loss : 0.125986, loss_ce: 0.032200
[00:22:37.099] iteration 1775 : loss : 0.142182, loss_ce: 0.058944
[00:22:37.404] iteration 1776 : loss : 0.158724, loss_ce: 0.041693
[00:22:37.709] iteration 1777 : loss : 0.178221, loss_ce: 0.068040
[00:22:38.020] iteration 1778 : loss : 0.220217, loss_ce: 0.068078
[00:22:38.330] iteration 1779 : loss : 0.191447, loss_ce: 0.029266
[00:22:38.635] iteration 1780 : loss : 0.139869, loss_ce: 0.050506
[00:22:38.961] iteration 1781 : loss : 0.224047, loss_ce: 0.021321
[00:22:39.270] iteration 1782 : loss : 0.171618, loss_ce: 0.050338
[00:22:39.574] iteration 1783 : loss : 0.253120, loss_ce: 0.024309
[00:22:39.879] iteration 1784 : loss : 0.174375, loss_ce: 0.028298
[00:22:40.186] iteration 1785 : loss : 0.173368, loss_ce: 0.043511
[00:22:40.488] iteration 1786 : loss : 0.244453, loss_ce: 0.048337
[00:22:40.788] iteration 1787 : loss : 0.222423, loss_ce: 0.071271
[00:22:41.097] iteration 1788 : loss : 0.158892, loss_ce: 0.070243
[00:22:41.400] iteration 1789 : loss : 0.139628, loss_ce: 0.046045
[00:22:41.711] iteration 1790 : loss : 0.218286, loss_ce: 0.057544
[00:22:42.017] iteration 1791 : loss : 0.141940, loss_ce: 0.048493
[00:22:42.326] iteration 1792 : loss : 0.247100, loss_ce: 0.039078
[00:22:42.636] iteration 1793 : loss : 0.182715, loss_ce: 0.022982
[00:22:42.947] iteration 1794 : loss : 0.199383, loss_ce: 0.036670
[00:22:43.259] iteration 1795 : loss : 0.230786, loss_ce: 0.059263
[00:22:43.564] iteration 1796 : loss : 0.141387, loss_ce: 0.049353
[00:22:43.875] iteration 1797 : loss : 0.159910, loss_ce: 0.065039
[00:22:44.188] iteration 1798 : loss : 0.165201, loss_ce: 0.029200
[00:22:44.491] iteration 1799 : loss : 0.180032, loss_ce: 0.033910
[00:22:44.797] iteration 1800 : loss : 0.171599, loss_ce: 0.063811
[00:22:45.135] iteration 1801 : loss : 0.156655, loss_ce: 0.044324
[00:22:45.444] iteration 1802 : loss : 0.146994, loss_ce: 0.041877
[00:22:45.748] iteration 1803 : loss : 0.125441, loss_ce: 0.019275
[00:22:46.059] iteration 1804 : loss : 0.174261, loss_ce: 0.044385
[00:22:46.365] iteration 1805 : loss : 0.195496, loss_ce: 0.048967
[00:22:46.669] iteration 1806 : loss : 0.098863, loss_ce: 0.026010
[00:22:46.747] iteration 1807 : loss : 0.313626, loss_ce: 0.027995
[00:23:05.494] iteration 1808 : loss : 0.209252, loss_ce: 0.026560
[00:23:05.803] iteration 1809 : loss : 0.170543, loss_ce: 0.058093
[00:23:06.108] iteration 1810 : loss : 0.180311, loss_ce: 0.040423
[00:23:06.416] iteration 1811 : loss : 0.192822, loss_ce: 0.039099
[00:23:06.728] iteration 1812 : loss : 0.201232, loss_ce: 0.044985
[00:23:07.027] iteration 1813 : loss : 0.140834, loss_ce: 0.047166
[00:23:07.326] iteration 1814 : loss : 0.138229, loss_ce: 0.038424
[00:23:07.635] iteration 1815 : loss : 0.146030, loss_ce: 0.035486
[00:23:07.939] iteration 1816 : loss : 0.182833, loss_ce: 0.018201
[00:23:08.243] iteration 1817 : loss : 0.195707, loss_ce: 0.038058
[00:23:08.550] iteration 1818 : loss : 0.138266, loss_ce: 0.038852
[00:23:08.853] iteration 1819 : loss : 0.167342, loss_ce: 0.072204
[00:23:09.162] iteration 1820 : loss : 0.211143, loss_ce: 0.043021
[00:23:09.484] iteration 1821 : loss : 0.283801, loss_ce: 0.083832
[00:23:09.788] iteration 1822 : loss : 0.148872, loss_ce: 0.039512
[00:23:10.094] iteration 1823 : loss : 0.161632, loss_ce: 0.065483
[00:23:10.394] iteration 1824 : loss : 0.212990, loss_ce: 0.055126
[00:23:10.699] iteration 1825 : loss : 0.129951, loss_ce: 0.042270
[00:23:11.005] iteration 1826 : loss : 0.163494, loss_ce: 0.033774
[00:23:11.307] iteration 1827 : loss : 0.151832, loss_ce: 0.050230
[00:23:11.612] iteration 1828 : loss : 0.157060, loss_ce: 0.038500
[00:23:11.917] iteration 1829 : loss : 0.134217, loss_ce: 0.053986
[00:23:12.225] iteration 1830 : loss : 0.137203, loss_ce: 0.034941
[00:23:12.533] iteration 1831 : loss : 0.122378, loss_ce: 0.023628
[00:23:12.833] iteration 1832 : loss : 0.187291, loss_ce: 0.055203
[00:23:13.141] iteration 1833 : loss : 0.190379, loss_ce: 0.037321
[00:23:13.443] iteration 1834 : loss : 0.120328, loss_ce: 0.061160
[00:23:13.754] iteration 1835 : loss : 0.102831, loss_ce: 0.012783
[00:23:14.062] iteration 1836 : loss : 0.175060, loss_ce: 0.035103
[00:23:14.372] iteration 1837 : loss : 0.128981, loss_ce: 0.024411
[00:23:14.687] iteration 1838 : loss : 0.167266, loss_ce: 0.022215
[00:23:14.992] iteration 1839 : loss : 0.132309, loss_ce: 0.051698
[00:23:15.298] iteration 1840 : loss : 0.130828, loss_ce: 0.033115
[00:23:15.622] iteration 1841 : loss : 0.151449, loss_ce: 0.048455
[00:23:15.928] iteration 1842 : loss : 0.160822, loss_ce: 0.044346
[00:23:16.240] iteration 1843 : loss : 0.164444, loss_ce: 0.021120
[00:23:16.550] iteration 1844 : loss : 0.296277, loss_ce: 0.039614
[00:23:16.862] iteration 1845 : loss : 0.198515, loss_ce: 0.034915
[00:23:17.166] iteration 1846 : loss : 0.291774, loss_ce: 0.025131
[00:23:17.471] iteration 1847 : loss : 0.138342, loss_ce: 0.039338
[00:23:17.773] iteration 1848 : loss : 0.153566, loss_ce: 0.036447
[00:23:18.078] iteration 1849 : loss : 0.190853, loss_ce: 0.041295
[00:23:18.387] iteration 1850 : loss : 0.140053, loss_ce: 0.047570
[00:23:18.693] iteration 1851 : loss : 0.125928, loss_ce: 0.052176
[00:23:19.003] iteration 1852 : loss : 0.131978, loss_ce: 0.028310
[00:23:19.314] iteration 1853 : loss : 0.164228, loss_ce: 0.045206
[00:23:19.625] iteration 1854 : loss : 0.186274, loss_ce: 0.040919
[00:23:19.929] iteration 1855 : loss : 0.129497, loss_ce: 0.042495
[00:23:20.231] iteration 1856 : loss : 0.090735, loss_ce: 0.024061
[00:23:20.540] iteration 1857 : loss : 0.139843, loss_ce: 0.040156
[00:23:20.842] iteration 1858 : loss : 0.141048, loss_ce: 0.038490
[00:23:21.147] iteration 1859 : loss : 0.155545, loss_ce: 0.035335
[00:23:21.458] iteration 1860 : loss : 0.138026, loss_ce: 0.063277
[00:23:21.782] iteration 1861 : loss : 0.156630, loss_ce: 0.051761
[00:23:22.084] iteration 1862 : loss : 0.170183, loss_ce: 0.050497
[00:23:22.399] iteration 1863 : loss : 0.182465, loss_ce: 0.025921
[00:23:22.703] iteration 1864 : loss : 0.139711, loss_ce: 0.047841
[00:23:23.017] iteration 1865 : loss : 0.212431, loss_ce: 0.036554
[00:23:23.323] iteration 1866 : loss : 0.163685, loss_ce: 0.050235
[00:23:23.637] iteration 1867 : loss : 0.109963, loss_ce: 0.031165
[00:23:23.949] iteration 1868 : loss : 0.124232, loss_ce: 0.047583
[00:23:24.255] iteration 1869 : loss : 0.123327, loss_ce: 0.028884
[00:23:24.560] iteration 1870 : loss : 0.134807, loss_ce: 0.051680
[00:23:24.866] iteration 1871 : loss : 0.176944, loss_ce: 0.035028
[00:23:25.179] iteration 1872 : loss : 0.169212, loss_ce: 0.038880
[00:23:25.489] iteration 1873 : loss : 0.165833, loss_ce: 0.035912
[00:23:25.804] iteration 1874 : loss : 0.212757, loss_ce: 0.029807
[00:23:26.113] iteration 1875 : loss : 0.141362, loss_ce: 0.047273
[00:23:26.425] iteration 1876 : loss : 0.143738, loss_ce: 0.029629
[00:23:26.725] iteration 1877 : loss : 0.127064, loss_ce: 0.026488
[00:23:27.022] iteration 1878 : loss : 0.161621, loss_ce: 0.038049
[00:23:27.331] iteration 1879 : loss : 0.152470, loss_ce: 0.062868
[00:23:27.630] iteration 1880 : loss : 0.168408, loss_ce: 0.057504
[00:23:27.953] iteration 1881 : loss : 0.201212, loss_ce: 0.038807
[00:23:28.262] iteration 1882 : loss : 0.174882, loss_ce: 0.059770
[00:23:28.570] iteration 1883 : loss : 0.178946, loss_ce: 0.035149
[00:23:28.872] iteration 1884 : loss : 0.150135, loss_ce: 0.040707
[00:23:29.183] iteration 1885 : loss : 0.225717, loss_ce: 0.054663
[00:23:29.483] iteration 1886 : loss : 0.157612, loss_ce: 0.040496
[00:23:29.788] iteration 1887 : loss : 0.200720, loss_ce: 0.051276
[00:23:30.094] iteration 1888 : loss : 0.171207, loss_ce: 0.057080
[00:23:30.398] iteration 1889 : loss : 0.179025, loss_ce: 0.065057
[00:23:30.701] iteration 1890 : loss : 0.156166, loss_ce: 0.068625
[00:23:31.007] iteration 1891 : loss : 0.136899, loss_ce: 0.041907
[00:23:31.315] iteration 1892 : loss : 0.141921, loss_ce: 0.031336
[00:23:31.619] iteration 1893 : loss : 0.120406, loss_ce: 0.032249
[00:23:31.926] iteration 1894 : loss : 0.150036, loss_ce: 0.044585
[00:23:32.227] iteration 1895 : loss : 0.147766, loss_ce: 0.057571
[00:23:32.542] iteration 1896 : loss : 0.207322, loss_ce: 0.053608
[00:23:32.851] iteration 1897 : loss : 0.137441, loss_ce: 0.032167
[00:23:33.160] iteration 1898 : loss : 0.144904, loss_ce: 0.052292
[00:23:33.468] iteration 1899 : loss : 0.114964, loss_ce: 0.041459
[00:23:33.772] iteration 1900 : loss : 0.153962, loss_ce: 0.036578
[00:23:34.102] iteration 1901 : loss : 0.140459, loss_ce: 0.042809
[00:23:34.409] iteration 1902 : loss : 0.195423, loss_ce: 0.051030
[00:23:34.720] iteration 1903 : loss : 0.134218, loss_ce: 0.052049
[00:23:35.034] iteration 1904 : loss : 0.192729, loss_ce: 0.035667
[00:23:35.344] iteration 1905 : loss : 0.160084, loss_ce: 0.052828
[00:23:35.648] iteration 1906 : loss : 0.167359, loss_ce: 0.035748
[00:23:35.961] iteration 1907 : loss : 0.154402, loss_ce: 0.043938
[00:23:36.269] iteration 1908 : loss : 0.175847, loss_ce: 0.041206
[00:23:36.574] iteration 1909 : loss : 0.152140, loss_ce: 0.021094
[00:23:36.889] iteration 1910 : loss : 0.157230, loss_ce: 0.048888
[00:23:37.203] iteration 1911 : loss : 0.178070, loss_ce: 0.064956
[00:23:37.515] iteration 1912 : loss : 0.234022, loss_ce: 0.034855
[00:23:37.827] iteration 1913 : loss : 0.126763, loss_ce: 0.035636
[00:23:38.139] iteration 1914 : loss : 0.156696, loss_ce: 0.052431
[00:23:38.445] iteration 1915 : loss : 0.168825, loss_ce: 0.028588
[00:23:38.757] iteration 1916 : loss : 0.155148, loss_ce: 0.017653
[00:23:39.064] iteration 1917 : loss : 0.142371, loss_ce: 0.025403
[00:23:39.374] iteration 1918 : loss : 0.105400, loss_ce: 0.012926
[00:23:39.681] iteration 1919 : loss : 0.189611, loss_ce: 0.041175
[00:23:39.989] iteration 1920 : loss : 0.188389, loss_ce: 0.046892
[00:23:40.316] iteration 1921 : loss : 0.159549, loss_ce: 0.026139
[00:23:40.622] iteration 1922 : loss : 0.191390, loss_ce: 0.085435
[00:23:40.936] iteration 1923 : loss : 0.174172, loss_ce: 0.035107
[00:23:41.245] iteration 1924 : loss : 0.149024, loss_ce: 0.043002
[00:23:41.553] iteration 1925 : loss : 0.160681, loss_ce: 0.014568
[00:23:41.861] iteration 1926 : loss : 0.119696, loss_ce: 0.024706
[00:23:42.165] iteration 1927 : loss : 0.156659, loss_ce: 0.036306
[00:23:42.474] iteration 1928 : loss : 0.191883, loss_ce: 0.018935
[00:23:42.790] iteration 1929 : loss : 0.156585, loss_ce: 0.050702
[00:23:43.109] iteration 1930 : loss : 0.131809, loss_ce: 0.052454
[00:23:43.422] iteration 1931 : loss : 0.169546, loss_ce: 0.036138
[00:23:43.736] iteration 1932 : loss : 0.123098, loss_ce: 0.033598
[00:23:44.041] iteration 1933 : loss : 0.095319, loss_ce: 0.029278
[00:23:44.352] iteration 1934 : loss : 0.139415, loss_ce: 0.037724
[00:23:44.658] iteration 1935 : loss : 0.230825, loss_ce: 0.075830
[00:23:44.968] iteration 1936 : loss : 0.222120, loss_ce: 0.023774
[00:23:45.277] iteration 1937 : loss : 0.161551, loss_ce: 0.020237
[00:23:45.585] iteration 1938 : loss : 0.134049, loss_ce: 0.031487
[00:23:45.894] iteration 1939 : loss : 0.149135, loss_ce: 0.033590
[00:23:46.202] iteration 1940 : loss : 0.165398, loss_ce: 0.037809
[00:23:46.550] iteration 1941 : loss : 0.121339, loss_ce: 0.040088
[00:23:46.858] iteration 1942 : loss : 0.180855, loss_ce: 0.052784
[00:23:47.172] iteration 1943 : loss : 0.216928, loss_ce: 0.037642
[00:23:47.474] iteration 1944 : loss : 0.141363, loss_ce: 0.035336
[00:23:47.791] iteration 1945 : loss : 0.167939, loss_ce: 0.019888
[00:23:47.876] iteration 1946 : loss : 0.313271, loss_ce: 0.071561
[00:24:06.703] iteration 1947 : loss : 0.141633, loss_ce: 0.028707
[00:24:07.010] iteration 1948 : loss : 0.130982, loss_ce: 0.028221
[00:24:07.319] iteration 1949 : loss : 0.182952, loss_ce: 0.016840
[00:24:07.628] iteration 1950 : loss : 0.179113, loss_ce: 0.028145
[00:24:07.940] iteration 1951 : loss : 0.132241, loss_ce: 0.050964
[00:24:08.244] iteration 1952 : loss : 0.190283, loss_ce: 0.057699
[00:24:08.547] iteration 1953 : loss : 0.204474, loss_ce: 0.079389
[00:24:08.851] iteration 1954 : loss : 0.177850, loss_ce: 0.045956
[00:24:09.159] iteration 1955 : loss : 0.219591, loss_ce: 0.023439
[00:24:09.465] iteration 1956 : loss : 0.131273, loss_ce: 0.061714
[00:24:09.776] iteration 1957 : loss : 0.120794, loss_ce: 0.029311
[00:24:10.082] iteration 1958 : loss : 0.176187, loss_ce: 0.035571
[00:24:10.380] iteration 1959 : loss : 0.147879, loss_ce: 0.017681
[00:24:10.685] iteration 1960 : loss : 0.120094, loss_ce: 0.028802
[00:24:11.014] iteration 1961 : loss : 0.176674, loss_ce: 0.025188
[00:24:11.315] iteration 1962 : loss : 0.163534, loss_ce: 0.026508
[00:24:11.623] iteration 1963 : loss : 0.302455, loss_ce: 0.022066
[00:24:11.925] iteration 1964 : loss : 0.101572, loss_ce: 0.033697
[00:24:12.232] iteration 1965 : loss : 0.177443, loss_ce: 0.024779
[00:24:12.540] iteration 1966 : loss : 0.191848, loss_ce: 0.047864
[00:24:12.848] iteration 1967 : loss : 0.206280, loss_ce: 0.057702
[00:24:13.163] iteration 1968 : loss : 0.110154, loss_ce: 0.047891
[00:24:13.476] iteration 1969 : loss : 0.118775, loss_ce: 0.038662
[00:24:13.778] iteration 1970 : loss : 0.224817, loss_ce: 0.040563
[00:24:14.090] iteration 1971 : loss : 0.205885, loss_ce: 0.043247
[00:24:14.398] iteration 1972 : loss : 0.181207, loss_ce: 0.054466
[00:24:14.711] iteration 1973 : loss : 0.133793, loss_ce: 0.058747
[00:24:15.022] iteration 1974 : loss : 0.191825, loss_ce: 0.037837
[00:24:15.328] iteration 1975 : loss : 0.178607, loss_ce: 0.025106
[00:24:15.630] iteration 1976 : loss : 0.156006, loss_ce: 0.063763
[00:24:15.940] iteration 1977 : loss : 0.220288, loss_ce: 0.049428
[00:24:16.243] iteration 1978 : loss : 0.153858, loss_ce: 0.037001
[00:24:16.550] iteration 1979 : loss : 0.182964, loss_ce: 0.032470
[00:24:16.857] iteration 1980 : loss : 0.195506, loss_ce: 0.041567
[00:24:17.183] iteration 1981 : loss : 0.124874, loss_ce: 0.058550
[00:24:17.492] iteration 1982 : loss : 0.129801, loss_ce: 0.060023
[00:24:17.795] iteration 1983 : loss : 0.221350, loss_ce: 0.052301
[00:24:18.111] iteration 1984 : loss : 0.170423, loss_ce: 0.035781
[00:24:18.418] iteration 1985 : loss : 0.187958, loss_ce: 0.024125
[00:24:18.721] iteration 1986 : loss : 0.194271, loss_ce: 0.040487
[00:24:19.036] iteration 1987 : loss : 0.143336, loss_ce: 0.017374
[00:24:19.341] iteration 1988 : loss : 0.117150, loss_ce: 0.055046
[00:24:19.645] iteration 1989 : loss : 0.191810, loss_ce: 0.035829
[00:24:19.947] iteration 1990 : loss : 0.193299, loss_ce: 0.104269
[00:24:20.249] iteration 1991 : loss : 0.140671, loss_ce: 0.048066
[00:24:20.553] iteration 1992 : loss : 0.224303, loss_ce: 0.034086
[00:24:20.862] iteration 1993 : loss : 0.140826, loss_ce: 0.051670
[00:24:21.162] iteration 1994 : loss : 0.105117, loss_ce: 0.026007
[00:24:21.475] iteration 1995 : loss : 0.210261, loss_ce: 0.043776
[00:24:21.779] iteration 1996 : loss : 0.170172, loss_ce: 0.075260
[00:24:22.093] iteration 1997 : loss : 0.243639, loss_ce: 0.101093
[00:24:22.397] iteration 1998 : loss : 0.203722, loss_ce: 0.013438
[00:24:22.705] iteration 1999 : loss : 0.194619, loss_ce: 0.023296
[00:24:23.013] iteration 2000 : loss : 0.199677, loss_ce: 0.019117
[00:24:23.330] iteration 2001 : loss : 0.168958, loss_ce: 0.023719
[00:24:23.630] iteration 2002 : loss : 0.115818, loss_ce: 0.035025
[00:24:23.937] iteration 2003 : loss : 0.222521, loss_ce: 0.047555
[00:24:24.239] iteration 2004 : loss : 0.146320, loss_ce: 0.055923
[00:24:24.552] iteration 2005 : loss : 0.198765, loss_ce: 0.034910
[00:24:24.858] iteration 2006 : loss : 0.152347, loss_ce: 0.040911
[00:24:25.162] iteration 2007 : loss : 0.145999, loss_ce: 0.032553
[00:24:25.470] iteration 2008 : loss : 0.184584, loss_ce: 0.036572
[00:24:25.773] iteration 2009 : loss : 0.148407, loss_ce: 0.042793
[00:24:26.083] iteration 2010 : loss : 0.211534, loss_ce: 0.053831
[00:24:26.387] iteration 2011 : loss : 0.103232, loss_ce: 0.019061
[00:24:26.688] iteration 2012 : loss : 0.152948, loss_ce: 0.038049
[00:24:26.999] iteration 2013 : loss : 0.121195, loss_ce: 0.049886
[00:24:27.307] iteration 2014 : loss : 0.193023, loss_ce: 0.019002
[00:24:27.612] iteration 2015 : loss : 0.156130, loss_ce: 0.049973
[00:24:27.914] iteration 2016 : loss : 0.143052, loss_ce: 0.045836
[00:24:28.224] iteration 2017 : loss : 0.121750, loss_ce: 0.038865
[00:24:28.530] iteration 2018 : loss : 0.158418, loss_ce: 0.036482
[00:24:28.841] iteration 2019 : loss : 0.115861, loss_ce: 0.036257
[00:24:29.143] iteration 2020 : loss : 0.098392, loss_ce: 0.022108
[00:24:29.470] iteration 2021 : loss : 0.142047, loss_ce: 0.034702
[00:24:29.772] iteration 2022 : loss : 0.248398, loss_ce: 0.026841
[00:24:30.076] iteration 2023 : loss : 0.216676, loss_ce: 0.026045
[00:24:30.384] iteration 2024 : loss : 0.195109, loss_ce: 0.022882
[00:24:30.687] iteration 2025 : loss : 0.198111, loss_ce: 0.033195
[00:24:30.993] iteration 2026 : loss : 0.116694, loss_ce: 0.029634
[00:24:31.296] iteration 2027 : loss : 0.112409, loss_ce: 0.045305
[00:24:31.602] iteration 2028 : loss : 0.122241, loss_ce: 0.069223
[00:24:31.903] iteration 2029 : loss : 0.231488, loss_ce: 0.030058
[00:24:32.213] iteration 2030 : loss : 0.117485, loss_ce: 0.044354
[00:24:32.515] iteration 2031 : loss : 0.110148, loss_ce: 0.034892
[00:24:32.832] iteration 2032 : loss : 0.131406, loss_ce: 0.038164
[00:24:33.139] iteration 2033 : loss : 0.162197, loss_ce: 0.055682
[00:24:33.450] iteration 2034 : loss : 0.107069, loss_ce: 0.039819
[00:24:33.751] iteration 2035 : loss : 0.145444, loss_ce: 0.058180
[00:24:34.056] iteration 2036 : loss : 0.120603, loss_ce: 0.036174
[00:24:34.360] iteration 2037 : loss : 0.125878, loss_ce: 0.038640
[00:24:34.668] iteration 2038 : loss : 0.189560, loss_ce: 0.024298
[00:24:34.971] iteration 2039 : loss : 0.197813, loss_ce: 0.026147
[00:24:35.276] iteration 2040 : loss : 0.155772, loss_ce: 0.039472
[00:24:35.594] iteration 2041 : loss : 0.106140, loss_ce: 0.025774
[00:24:35.901] iteration 2042 : loss : 0.156303, loss_ce: 0.044270
[00:24:36.211] iteration 2043 : loss : 0.188737, loss_ce: 0.050124
[00:24:36.515] iteration 2044 : loss : 0.142084, loss_ce: 0.028375
[00:24:36.832] iteration 2045 : loss : 0.205848, loss_ce: 0.017124
[00:24:37.136] iteration 2046 : loss : 0.166250, loss_ce: 0.046321
[00:24:37.448] iteration 2047 : loss : 0.131857, loss_ce: 0.069880
[00:24:37.750] iteration 2048 : loss : 0.162774, loss_ce: 0.047883
[00:24:38.055] iteration 2049 : loss : 0.144345, loss_ce: 0.032123
[00:24:38.356] iteration 2050 : loss : 0.174328, loss_ce: 0.051856
[00:24:38.665] iteration 2051 : loss : 0.200169, loss_ce: 0.045693
[00:24:38.972] iteration 2052 : loss : 0.133596, loss_ce: 0.058847
[00:24:39.278] iteration 2053 : loss : 0.181916, loss_ce: 0.040718
[00:24:39.575] iteration 2054 : loss : 0.160970, loss_ce: 0.039077
[00:24:39.879] iteration 2055 : loss : 0.180092, loss_ce: 0.020658
[00:24:40.181] iteration 2056 : loss : 0.165489, loss_ce: 0.038448
[00:24:40.488] iteration 2057 : loss : 0.116628, loss_ce: 0.030172
[00:24:40.790] iteration 2058 : loss : 0.160121, loss_ce: 0.039756
[00:24:41.095] iteration 2059 : loss : 0.147427, loss_ce: 0.052836
[00:24:41.399] iteration 2060 : loss : 0.104097, loss_ce: 0.027558
[00:24:41.717] iteration 2061 : loss : 0.144953, loss_ce: 0.036835
[00:24:42.016] iteration 2062 : loss : 0.110395, loss_ce: 0.038992
[00:24:42.321] iteration 2063 : loss : 0.147733, loss_ce: 0.072952
[00:24:42.631] iteration 2064 : loss : 0.169802, loss_ce: 0.052270
[00:24:42.934] iteration 2065 : loss : 0.118944, loss_ce: 0.039855
[00:24:43.247] iteration 2066 : loss : 0.187210, loss_ce: 0.033169
[00:24:43.555] iteration 2067 : loss : 0.111995, loss_ce: 0.033567
[00:24:43.862] iteration 2068 : loss : 0.131359, loss_ce: 0.059549
[00:24:44.175] iteration 2069 : loss : 0.119260, loss_ce: 0.033404
[00:24:44.488] iteration 2070 : loss : 0.132337, loss_ce: 0.056078
[00:24:44.804] iteration 2071 : loss : 0.102403, loss_ce: 0.029261
[00:24:45.114] iteration 2072 : loss : 0.211784, loss_ce: 0.019957
[00:24:45.420] iteration 2073 : loss : 0.126397, loss_ce: 0.037446
[00:24:45.729] iteration 2074 : loss : 0.169316, loss_ce: 0.034329
[00:24:46.034] iteration 2075 : loss : 0.194170, loss_ce: 0.035035
[00:24:46.346] iteration 2076 : loss : 0.146635, loss_ce: 0.030940
[00:24:46.657] iteration 2077 : loss : 0.090226, loss_ce: 0.030681
[00:24:46.966] iteration 2078 : loss : 0.130992, loss_ce: 0.043735
[00:24:47.274] iteration 2079 : loss : 0.116270, loss_ce: 0.033767
[00:24:47.582] iteration 2080 : loss : 0.206551, loss_ce: 0.055527
[00:24:47.928] iteration 2081 : loss : 0.097435, loss_ce: 0.039073
[00:24:48.227] iteration 2082 : loss : 0.174455, loss_ce: 0.049940
[00:24:48.535] iteration 2083 : loss : 0.173118, loss_ce: 0.028212
[00:24:48.847] iteration 2084 : loss : 0.349803, loss_ce: 0.033199
[00:24:48.929] iteration 2085 : loss : 0.345401, loss_ce: 0.098983
[00:25:07.684] iteration 2086 : loss : 0.111952, loss_ce: 0.043865
[00:25:07.992] iteration 2087 : loss : 0.140785, loss_ce: 0.033153
[00:25:08.302] iteration 2088 : loss : 0.152354, loss_ce: 0.063785
[00:25:08.610] iteration 2089 : loss : 0.141777, loss_ce: 0.033839
[00:25:08.910] iteration 2090 : loss : 0.170689, loss_ce: 0.033965
[00:25:09.213] iteration 2091 : loss : 0.099908, loss_ce: 0.024154
[00:25:09.516] iteration 2092 : loss : 0.112893, loss_ce: 0.040956
[00:25:09.821] iteration 2093 : loss : 0.120003, loss_ce: 0.025346
[00:25:10.133] iteration 2094 : loss : 0.187433, loss_ce: 0.044997
[00:25:10.440] iteration 2095 : loss : 0.127782, loss_ce: 0.062982
[00:25:10.742] iteration 2096 : loss : 0.124485, loss_ce: 0.042228
[00:25:11.051] iteration 2097 : loss : 0.121216, loss_ce: 0.024725
[00:25:11.358] iteration 2098 : loss : 0.139479, loss_ce: 0.040694
[00:25:11.661] iteration 2099 : loss : 0.118213, loss_ce: 0.037227
[00:25:11.965] iteration 2100 : loss : 0.167019, loss_ce: 0.031551
[00:25:12.287] iteration 2101 : loss : 0.129979, loss_ce: 0.035718
[00:25:12.588] iteration 2102 : loss : 0.098306, loss_ce: 0.033020
[00:25:12.894] iteration 2103 : loss : 0.176495, loss_ce: 0.040975
[00:25:13.203] iteration 2104 : loss : 0.127164, loss_ce: 0.040489
[00:25:13.507] iteration 2105 : loss : 0.093794, loss_ce: 0.044376
[00:25:13.812] iteration 2106 : loss : 0.140679, loss_ce: 0.032121
[00:25:14.112] iteration 2107 : loss : 0.138128, loss_ce: 0.030068
[00:25:14.414] iteration 2108 : loss : 0.156629, loss_ce: 0.025565
[00:25:14.720] iteration 2109 : loss : 0.205911, loss_ce: 0.027796
[00:25:15.022] iteration 2110 : loss : 0.098646, loss_ce: 0.038839
[00:25:15.331] iteration 2111 : loss : 0.141850, loss_ce: 0.028569
[00:25:15.632] iteration 2112 : loss : 0.104239, loss_ce: 0.034025
[00:25:15.938] iteration 2113 : loss : 0.166330, loss_ce: 0.030321
[00:25:16.248] iteration 2114 : loss : 0.114858, loss_ce: 0.048418
[00:25:16.552] iteration 2115 : loss : 0.110662, loss_ce: 0.040092
[00:25:16.857] iteration 2116 : loss : 0.267588, loss_ce: 0.018736
[00:25:17.167] iteration 2117 : loss : 0.170155, loss_ce: 0.027165
[00:25:17.469] iteration 2118 : loss : 0.150936, loss_ce: 0.037560
[00:25:17.774] iteration 2119 : loss : 0.160032, loss_ce: 0.039572
[00:25:18.079] iteration 2120 : loss : 0.104222, loss_ce: 0.034932
[00:25:18.405] iteration 2121 : loss : 0.147983, loss_ce: 0.041142
[00:25:18.708] iteration 2122 : loss : 0.137753, loss_ce: 0.030484
[00:25:19.014] iteration 2123 : loss : 0.088206, loss_ce: 0.030287
[00:25:19.327] iteration 2124 : loss : 0.105181, loss_ce: 0.038069
[00:25:19.630] iteration 2125 : loss : 0.156066, loss_ce: 0.055280
[00:25:19.932] iteration 2126 : loss : 0.202175, loss_ce: 0.015013
[00:25:20.241] iteration 2127 : loss : 0.111752, loss_ce: 0.049503
[00:25:20.548] iteration 2128 : loss : 0.155363, loss_ce: 0.033982
[00:25:20.851] iteration 2129 : loss : 0.106198, loss_ce: 0.029070
[00:25:21.162] iteration 2130 : loss : 0.081801, loss_ce: 0.021256
[00:25:21.469] iteration 2131 : loss : 0.194578, loss_ce: 0.017985
[00:25:21.771] iteration 2132 : loss : 0.150872, loss_ce: 0.056145
[00:25:22.083] iteration 2133 : loss : 0.146961, loss_ce: 0.024908
[00:25:22.390] iteration 2134 : loss : 0.127470, loss_ce: 0.015439
[00:25:22.691] iteration 2135 : loss : 0.182163, loss_ce: 0.023300
[00:25:23.004] iteration 2136 : loss : 0.137314, loss_ce: 0.034689
[00:25:23.309] iteration 2137 : loss : 0.146631, loss_ce: 0.048460
[00:25:23.614] iteration 2138 : loss : 0.236643, loss_ce: 0.053789
[00:25:23.920] iteration 2139 : loss : 0.113101, loss_ce: 0.037604
[00:25:24.224] iteration 2140 : loss : 0.110650, loss_ce: 0.036601
[00:25:24.542] iteration 2141 : loss : 0.150695, loss_ce: 0.039022
[00:25:24.848] iteration 2142 : loss : 0.167288, loss_ce: 0.022757
[00:25:25.162] iteration 2143 : loss : 0.140893, loss_ce: 0.039104
[00:25:25.466] iteration 2144 : loss : 0.143598, loss_ce: 0.026977
[00:25:25.773] iteration 2145 : loss : 0.129312, loss_ce: 0.028427
[00:25:26.080] iteration 2146 : loss : 0.119098, loss_ce: 0.045888
[00:25:26.386] iteration 2147 : loss : 0.146888, loss_ce: 0.033847
[00:25:26.688] iteration 2148 : loss : 0.107125, loss_ce: 0.023179
[00:25:26.995] iteration 2149 : loss : 0.124966, loss_ce: 0.036088
[00:25:27.304] iteration 2150 : loss : 0.094503, loss_ce: 0.033429
[00:25:27.614] iteration 2151 : loss : 0.183655, loss_ce: 0.013053
[00:25:27.918] iteration 2152 : loss : 0.195331, loss_ce: 0.029434
[00:25:28.234] iteration 2153 : loss : 0.176854, loss_ce: 0.029966
[00:25:28.541] iteration 2154 : loss : 0.098832, loss_ce: 0.034131
[00:25:28.843] iteration 2155 : loss : 0.118535, loss_ce: 0.045883
[00:25:29.152] iteration 2156 : loss : 0.090963, loss_ce: 0.028413
[00:25:29.459] iteration 2157 : loss : 0.093667, loss_ce: 0.033837
[00:25:29.762] iteration 2158 : loss : 0.205237, loss_ce: 0.049079
[00:25:30.068] iteration 2159 : loss : 0.129695, loss_ce: 0.031845
[00:25:30.376] iteration 2160 : loss : 0.132312, loss_ce: 0.050001
[00:25:30.705] iteration 2161 : loss : 0.126901, loss_ce: 0.050677
[00:25:31.012] iteration 2162 : loss : 0.152064, loss_ce: 0.024943
[00:25:31.320] iteration 2163 : loss : 0.077735, loss_ce: 0.023602
[00:25:31.625] iteration 2164 : loss : 0.107399, loss_ce: 0.030973
[00:25:31.941] iteration 2165 : loss : 0.152005, loss_ce: 0.048817
[00:25:32.245] iteration 2166 : loss : 0.181712, loss_ce: 0.031785
[00:25:32.553] iteration 2167 : loss : 0.264887, loss_ce: 0.006033
[00:25:32.858] iteration 2168 : loss : 0.142786, loss_ce: 0.035626
[00:25:33.170] iteration 2169 : loss : 0.108580, loss_ce: 0.044467
[00:25:33.476] iteration 2170 : loss : 0.116733, loss_ce: 0.023185
[00:25:33.785] iteration 2171 : loss : 0.134698, loss_ce: 0.029658
[00:25:34.094] iteration 2172 : loss : 0.107960, loss_ce: 0.050102
[00:25:34.401] iteration 2173 : loss : 0.194372, loss_ce: 0.049454
[00:25:34.709] iteration 2174 : loss : 0.102706, loss_ce: 0.024340
[00:25:35.023] iteration 2175 : loss : 0.104822, loss_ce: 0.068708
[00:25:35.327] iteration 2176 : loss : 0.109377, loss_ce: 0.028368
[00:25:35.634] iteration 2177 : loss : 0.144703, loss_ce: 0.049076
[00:25:35.940] iteration 2178 : loss : 0.146177, loss_ce: 0.042208
[00:25:36.245] iteration 2179 : loss : 0.162794, loss_ce: 0.045807
[00:25:36.550] iteration 2180 : loss : 0.189211, loss_ce: 0.028169
[00:25:36.879] iteration 2181 : loss : 0.133158, loss_ce: 0.044747
[00:25:37.182] iteration 2182 : loss : 0.198592, loss_ce: 0.027289
[00:25:37.492] iteration 2183 : loss : 0.168438, loss_ce: 0.048010
[00:25:37.806] iteration 2184 : loss : 0.154341, loss_ce: 0.045159
[00:25:38.115] iteration 2185 : loss : 0.114311, loss_ce: 0.037251
[00:25:38.419] iteration 2186 : loss : 0.120030, loss_ce: 0.036765
[00:25:38.734] iteration 2187 : loss : 0.186834, loss_ce: 0.048014
[00:25:39.041] iteration 2188 : loss : 0.118129, loss_ce: 0.037200
[00:25:39.342] iteration 2189 : loss : 0.146819, loss_ce: 0.041364
[00:25:39.650] iteration 2190 : loss : 0.130929, loss_ce: 0.052669
[00:25:39.953] iteration 2191 : loss : 0.179520, loss_ce: 0.052697
[00:25:40.267] iteration 2192 : loss : 0.101988, loss_ce: 0.024741
[00:25:40.570] iteration 2193 : loss : 0.154464, loss_ce: 0.037969
[00:25:40.873] iteration 2194 : loss : 0.114990, loss_ce: 0.043117
[00:25:41.181] iteration 2195 : loss : 0.272838, loss_ce: 0.012549
[00:25:41.484] iteration 2196 : loss : 0.121492, loss_ce: 0.030863
[00:25:41.791] iteration 2197 : loss : 0.093318, loss_ce: 0.028220
[00:25:42.099] iteration 2198 : loss : 0.133208, loss_ce: 0.026372
[00:25:42.402] iteration 2199 : loss : 0.142095, loss_ce: 0.039225
[00:25:42.712] iteration 2200 : loss : 0.198774, loss_ce: 0.022395
[00:25:43.041] iteration 2201 : loss : 0.448221, loss_ce: 0.009286
[00:25:43.349] iteration 2202 : loss : 0.196320, loss_ce: 0.023877
[00:25:43.656] iteration 2203 : loss : 0.135110, loss_ce: 0.040341
[00:25:43.962] iteration 2204 : loss : 0.151072, loss_ce: 0.041431
[00:25:44.275] iteration 2205 : loss : 0.151924, loss_ce: 0.048366
[00:25:44.581] iteration 2206 : loss : 0.196205, loss_ce: 0.022400
[00:25:44.893] iteration 2207 : loss : 0.138970, loss_ce: 0.028486
[00:25:45.209] iteration 2208 : loss : 0.202569, loss_ce: 0.058933
[00:25:45.511] iteration 2209 : loss : 0.135602, loss_ce: 0.034172
[00:25:45.817] iteration 2210 : loss : 0.201316, loss_ce: 0.045432
[00:25:46.128] iteration 2211 : loss : 0.130260, loss_ce: 0.036178
[00:25:46.441] iteration 2212 : loss : 0.160889, loss_ce: 0.027012
[00:25:46.752] iteration 2213 : loss : 0.174906, loss_ce: 0.027095
[00:25:47.059] iteration 2214 : loss : 0.181063, loss_ce: 0.037746
[00:25:47.371] iteration 2215 : loss : 0.123280, loss_ce: 0.026998
[00:25:47.682] iteration 2216 : loss : 0.131278, loss_ce: 0.042128
[00:25:47.994] iteration 2217 : loss : 0.132968, loss_ce: 0.040445
[00:25:48.300] iteration 2218 : loss : 0.225856, loss_ce: 0.024491
[00:25:48.607] iteration 2219 : loss : 0.219893, loss_ce: 0.056527
[00:25:48.918] iteration 2220 : loss : 0.102704, loss_ce: 0.037954
[00:25:49.243] iteration 2221 : loss : 0.131431, loss_ce: 0.039665
[00:25:49.553] iteration 2222 : loss : 0.126698, loss_ce: 0.045256
[00:25:49.852] iteration 2223 : loss : 0.215710, loss_ce: 0.030799
[00:25:49.933] iteration 2224 : loss : 0.339319, loss_ce: 0.034525
[00:26:09.254] iteration 2225 : loss : 0.184349, loss_ce: 0.064094
[00:26:09.557] iteration 2226 : loss : 0.208888, loss_ce: 0.043221
[00:26:09.862] iteration 2227 : loss : 0.131214, loss_ce: 0.031201
[00:26:10.167] iteration 2228 : loss : 0.172608, loss_ce: 0.041222
[00:26:10.477] iteration 2229 : loss : 0.187515, loss_ce: 0.025779
[00:26:10.784] iteration 2230 : loss : 0.126861, loss_ce: 0.023203
[00:26:11.089] iteration 2231 : loss : 0.114578, loss_ce: 0.022225
[00:26:11.392] iteration 2232 : loss : 0.184846, loss_ce: 0.022440
[00:26:11.696] iteration 2233 : loss : 0.085721, loss_ce: 0.026000
[00:26:12.002] iteration 2234 : loss : 0.170201, loss_ce: 0.050179
[00:26:12.306] iteration 2235 : loss : 0.120894, loss_ce: 0.049875
[00:26:12.615] iteration 2236 : loss : 0.161668, loss_ce: 0.030307
[00:26:12.916] iteration 2237 : loss : 0.115594, loss_ce: 0.034925
[00:26:13.222] iteration 2238 : loss : 0.132190, loss_ce: 0.035559
[00:26:13.524] iteration 2239 : loss : 0.120145, loss_ce: 0.022449
[00:26:13.829] iteration 2240 : loss : 0.093277, loss_ce: 0.026659
[00:26:14.153] iteration 2241 : loss : 0.110866, loss_ce: 0.028170
[00:26:14.455] iteration 2242 : loss : 0.100972, loss_ce: 0.020964
[00:26:14.766] iteration 2243 : loss : 0.139572, loss_ce: 0.036503
[00:26:15.073] iteration 2244 : loss : 0.121677, loss_ce: 0.025314
[00:26:15.375] iteration 2245 : loss : 0.175573, loss_ce: 0.041125
[00:26:15.678] iteration 2246 : loss : 0.145503, loss_ce: 0.041113
[00:26:15.980] iteration 2247 : loss : 0.111954, loss_ce: 0.032785
[00:26:16.287] iteration 2248 : loss : 0.117717, loss_ce: 0.034462
[00:26:16.594] iteration 2249 : loss : 0.135189, loss_ce: 0.020749
[00:26:16.899] iteration 2250 : loss : 0.206668, loss_ce: 0.046914
[00:26:17.201] iteration 2251 : loss : 0.153684, loss_ce: 0.058267
[00:26:17.500] iteration 2252 : loss : 0.099578, loss_ce: 0.026706
[00:26:17.803] iteration 2253 : loss : 0.133036, loss_ce: 0.042468
[00:26:18.121] iteration 2254 : loss : 0.148046, loss_ce: 0.044929
[00:26:18.424] iteration 2255 : loss : 0.183919, loss_ce: 0.029753
[00:26:18.728] iteration 2256 : loss : 0.127627, loss_ce: 0.056524
[00:26:19.042] iteration 2257 : loss : 0.159388, loss_ce: 0.028282
[00:26:19.346] iteration 2258 : loss : 0.164175, loss_ce: 0.032454
[00:26:19.653] iteration 2259 : loss : 0.194155, loss_ce: 0.052659
[00:26:19.955] iteration 2260 : loss : 0.126315, loss_ce: 0.049559
[00:26:20.274] iteration 2261 : loss : 0.166330, loss_ce: 0.037632
[00:26:20.572] iteration 2262 : loss : 0.154504, loss_ce: 0.042002
[00:26:20.875] iteration 2263 : loss : 0.104225, loss_ce: 0.025569
[00:26:21.180] iteration 2264 : loss : 0.139647, loss_ce: 0.022523
[00:26:21.490] iteration 2265 : loss : 0.131585, loss_ce: 0.045502
[00:26:21.793] iteration 2266 : loss : 0.158120, loss_ce: 0.028173
[00:26:22.102] iteration 2267 : loss : 0.134019, loss_ce: 0.043058
[00:26:22.412] iteration 2268 : loss : 0.125728, loss_ce: 0.052967
[00:26:22.716] iteration 2269 : loss : 0.108543, loss_ce: 0.031396
[00:26:23.021] iteration 2270 : loss : 0.156828, loss_ce: 0.043148
[00:26:23.325] iteration 2271 : loss : 0.155031, loss_ce: 0.030272
[00:26:23.627] iteration 2272 : loss : 0.292242, loss_ce: 0.030819
[00:26:23.929] iteration 2273 : loss : 0.161532, loss_ce: 0.029210
[00:26:24.238] iteration 2274 : loss : 0.123937, loss_ce: 0.018165
[00:26:24.548] iteration 2275 : loss : 0.189746, loss_ce: 0.025752
[00:26:24.850] iteration 2276 : loss : 0.081846, loss_ce: 0.010770
[00:26:25.153] iteration 2277 : loss : 0.130590, loss_ce: 0.045478
[00:26:25.463] iteration 2278 : loss : 0.207711, loss_ce: 0.022168
[00:26:25.764] iteration 2279 : loss : 0.150949, loss_ce: 0.021085
[00:26:26.070] iteration 2280 : loss : 0.126337, loss_ce: 0.035662
[00:26:26.397] iteration 2281 : loss : 0.155360, loss_ce: 0.038616
[00:26:26.696] iteration 2282 : loss : 0.165962, loss_ce: 0.037025
[00:26:26.999] iteration 2283 : loss : 0.186613, loss_ce: 0.026118
[00:26:27.302] iteration 2284 : loss : 0.144491, loss_ce: 0.055376
[00:26:27.609] iteration 2285 : loss : 0.085268, loss_ce: 0.035954
[00:26:27.912] iteration 2286 : loss : 0.156103, loss_ce: 0.046462
[00:26:28.222] iteration 2287 : loss : 0.135983, loss_ce: 0.014059
[00:26:28.525] iteration 2288 : loss : 0.157291, loss_ce: 0.014704
[00:26:28.827] iteration 2289 : loss : 0.161848, loss_ce: 0.034999
[00:26:29.132] iteration 2290 : loss : 0.183424, loss_ce: 0.038868
[00:26:29.437] iteration 2291 : loss : 0.223352, loss_ce: 0.042284
[00:26:29.735] iteration 2292 : loss : 0.192898, loss_ce: 0.041782
[00:26:30.045] iteration 2293 : loss : 0.114192, loss_ce: 0.044969
[00:26:30.350] iteration 2294 : loss : 0.208658, loss_ce: 0.039815
[00:26:30.654] iteration 2295 : loss : 0.085049, loss_ce: 0.031275
[00:26:30.959] iteration 2296 : loss : 0.125942, loss_ce: 0.053874
[00:26:31.279] iteration 2297 : loss : 0.131071, loss_ce: 0.045229
[00:26:31.582] iteration 2298 : loss : 0.169684, loss_ce: 0.071635
[00:26:31.884] iteration 2299 : loss : 0.309837, loss_ce: 0.016206
[00:26:32.190] iteration 2300 : loss : 0.157120, loss_ce: 0.035244
[00:26:32.511] iteration 2301 : loss : 0.198301, loss_ce: 0.018282
[00:26:32.812] iteration 2302 : loss : 0.164797, loss_ce: 0.031607
[00:26:33.116] iteration 2303 : loss : 0.157429, loss_ce: 0.026880
[00:26:33.421] iteration 2304 : loss : 0.146179, loss_ce: 0.049103
[00:26:33.727] iteration 2305 : loss : 0.136641, loss_ce: 0.034678
[00:26:34.036] iteration 2306 : loss : 0.172704, loss_ce: 0.037318
[00:26:34.345] iteration 2307 : loss : 0.135051, loss_ce: 0.050786
[00:26:34.655] iteration 2308 : loss : 0.126050, loss_ce: 0.032134
[00:26:34.953] iteration 2309 : loss : 0.107265, loss_ce: 0.019864
[00:26:35.258] iteration 2310 : loss : 0.123897, loss_ce: 0.056053
[00:26:35.565] iteration 2311 : loss : 0.134337, loss_ce: 0.054068
[00:26:35.868] iteration 2312 : loss : 0.179515, loss_ce: 0.045111
[00:26:36.163] iteration 2313 : loss : 0.103050, loss_ce: 0.022300
[00:26:36.470] iteration 2314 : loss : 0.119482, loss_ce: 0.029603
[00:26:36.773] iteration 2315 : loss : 0.161504, loss_ce: 0.041454
[00:26:37.082] iteration 2316 : loss : 0.102571, loss_ce: 0.048147
[00:26:37.393] iteration 2317 : loss : 0.118446, loss_ce: 0.031498
[00:26:37.700] iteration 2318 : loss : 0.088400, loss_ce: 0.028781
[00:26:38.006] iteration 2319 : loss : 0.157939, loss_ce: 0.049928
[00:26:38.312] iteration 2320 : loss : 0.143448, loss_ce: 0.021813
[00:26:38.640] iteration 2321 : loss : 0.099294, loss_ce: 0.026618
[00:26:38.943] iteration 2322 : loss : 0.093143, loss_ce: 0.014591
[00:26:39.245] iteration 2323 : loss : 0.158290, loss_ce: 0.042717
[00:26:39.549] iteration 2324 : loss : 0.099944, loss_ce: 0.020413
[00:26:39.849] iteration 2325 : loss : 0.143418, loss_ce: 0.023268
[00:26:40.152] iteration 2326 : loss : 0.143046, loss_ce: 0.016179
[00:26:40.462] iteration 2327 : loss : 0.170547, loss_ce: 0.026870
[00:26:40.764] iteration 2328 : loss : 0.118587, loss_ce: 0.044528
[00:26:41.070] iteration 2329 : loss : 0.114551, loss_ce: 0.027970
[00:26:41.370] iteration 2330 : loss : 0.099658, loss_ce: 0.028497
[00:26:41.672] iteration 2331 : loss : 0.165460, loss_ce: 0.044664
[00:26:41.972] iteration 2332 : loss : 0.125343, loss_ce: 0.026969
[00:26:42.277] iteration 2333 : loss : 0.150443, loss_ce: 0.036386
[00:26:42.588] iteration 2334 : loss : 0.102324, loss_ce: 0.021272
[00:26:42.889] iteration 2335 : loss : 0.094754, loss_ce: 0.034960
[00:26:43.202] iteration 2336 : loss : 0.130554, loss_ce: 0.050534
[00:26:43.506] iteration 2337 : loss : 0.098282, loss_ce: 0.032648
[00:26:43.814] iteration 2338 : loss : 0.086622, loss_ce: 0.032978
[00:26:44.122] iteration 2339 : loss : 0.139161, loss_ce: 0.025052
[00:26:44.424] iteration 2340 : loss : 0.115719, loss_ce: 0.022090
[00:26:44.740] iteration 2341 : loss : 0.089438, loss_ce: 0.016253
[00:26:45.044] iteration 2342 : loss : 0.114785, loss_ce: 0.049592
[00:26:45.351] iteration 2343 : loss : 0.098865, loss_ce: 0.046805
[00:26:45.654] iteration 2344 : loss : 0.145540, loss_ce: 0.019689
[00:26:45.958] iteration 2345 : loss : 0.116195, loss_ce: 0.032172
[00:26:46.267] iteration 2346 : loss : 0.169865, loss_ce: 0.032205
[00:26:46.570] iteration 2347 : loss : 0.092015, loss_ce: 0.038738
[00:26:46.876] iteration 2348 : loss : 0.142243, loss_ce: 0.046563
[00:26:47.181] iteration 2349 : loss : 0.116516, loss_ce: 0.035643
[00:26:47.490] iteration 2350 : loss : 0.126271, loss_ce: 0.043550
[00:26:47.805] iteration 2351 : loss : 0.095330, loss_ce: 0.046240
[00:26:48.107] iteration 2352 : loss : 0.114841, loss_ce: 0.047250
[00:26:48.412] iteration 2353 : loss : 0.089544, loss_ce: 0.028032
[00:26:48.730] iteration 2354 : loss : 0.082540, loss_ce: 0.031088
[00:26:49.039] iteration 2355 : loss : 0.153402, loss_ce: 0.038153
[00:26:49.351] iteration 2356 : loss : 0.109806, loss_ce: 0.017625
[00:26:49.657] iteration 2357 : loss : 0.258399, loss_ce: 0.031721
[00:26:49.968] iteration 2358 : loss : 0.250490, loss_ce: 0.018632
[00:26:50.285] iteration 2359 : loss : 0.104508, loss_ce: 0.014580
[00:26:50.584] iteration 2360 : loss : 0.136597, loss_ce: 0.039437
[00:26:50.909] iteration 2361 : loss : 0.136532, loss_ce: 0.024059
[00:26:51.214] iteration 2362 : loss : 0.142427, loss_ce: 0.074257
[00:26:51.296] iteration 2363 : loss : 0.506004, loss_ce: 0.000394
[00:27:10.493] iteration 2364 : loss : 0.081566, loss_ce: 0.021375
[00:27:10.804] iteration 2365 : loss : 0.143385, loss_ce: 0.039140
[00:27:11.111] iteration 2366 : loss : 0.157660, loss_ce: 0.029062
[00:27:11.407] iteration 2367 : loss : 0.111071, loss_ce: 0.039485
[00:27:11.712] iteration 2368 : loss : 0.140114, loss_ce: 0.042811
[00:27:12.016] iteration 2369 : loss : 0.117706, loss_ce: 0.059615
[00:27:12.321] iteration 2370 : loss : 0.108163, loss_ce: 0.029771
[00:27:12.630] iteration 2371 : loss : 0.198940, loss_ce: 0.031182
[00:27:12.929] iteration 2372 : loss : 0.150657, loss_ce: 0.019345
[00:27:13.243] iteration 2373 : loss : 0.129169, loss_ce: 0.049214
[00:27:13.546] iteration 2374 : loss : 0.165392, loss_ce: 0.036426
[00:27:13.852] iteration 2375 : loss : 0.120109, loss_ce: 0.034738
[00:27:14.165] iteration 2376 : loss : 0.168487, loss_ce: 0.019297
[00:27:14.466] iteration 2377 : loss : 0.085718, loss_ce: 0.019589
[00:27:14.774] iteration 2378 : loss : 0.127253, loss_ce: 0.040211
[00:27:15.076] iteration 2379 : loss : 0.098416, loss_ce: 0.043227
[00:27:15.389] iteration 2380 : loss : 0.124324, loss_ce: 0.045583
[00:27:15.713] iteration 2381 : loss : 0.140044, loss_ce: 0.054914
[00:27:16.021] iteration 2382 : loss : 0.141291, loss_ce: 0.049187
[00:27:16.334] iteration 2383 : loss : 0.141881, loss_ce: 0.034604
[00:27:16.638] iteration 2384 : loss : 0.130260, loss_ce: 0.025628
[00:27:16.945] iteration 2385 : loss : 0.144943, loss_ce: 0.037229
[00:27:17.254] iteration 2386 : loss : 0.180682, loss_ce: 0.020961
[00:27:17.567] iteration 2387 : loss : 0.102783, loss_ce: 0.026002
[00:27:17.871] iteration 2388 : loss : 0.107970, loss_ce: 0.057316
[00:27:18.184] iteration 2389 : loss : 0.107120, loss_ce: 0.036804
[00:27:18.490] iteration 2390 : loss : 0.172084, loss_ce: 0.012631
[00:27:18.808] iteration 2391 : loss : 0.106914, loss_ce: 0.029322
[00:27:19.117] iteration 2392 : loss : 0.172116, loss_ce: 0.027007
[00:27:19.420] iteration 2393 : loss : 0.150015, loss_ce: 0.032736
[00:27:19.719] iteration 2394 : loss : 0.124654, loss_ce: 0.052271
[00:27:20.023] iteration 2395 : loss : 0.096100, loss_ce: 0.028385
[00:27:20.332] iteration 2396 : loss : 0.136158, loss_ce: 0.028936
[00:27:20.641] iteration 2397 : loss : 0.108774, loss_ce: 0.019136
[00:27:20.953] iteration 2398 : loss : 0.095832, loss_ce: 0.033683
[00:27:21.254] iteration 2399 : loss : 0.099229, loss_ce: 0.021549
[00:27:21.561] iteration 2400 : loss : 0.104151, loss_ce: 0.028514
[00:27:21.894] iteration 2401 : loss : 0.152629, loss_ce: 0.029546
[00:27:22.196] iteration 2402 : loss : 0.121769, loss_ce: 0.052869
[00:27:22.511] iteration 2403 : loss : 0.166326, loss_ce: 0.035014
[00:27:22.818] iteration 2404 : loss : 0.118260, loss_ce: 0.037439
[00:27:23.127] iteration 2405 : loss : 0.089281, loss_ce: 0.036075
[00:27:23.437] iteration 2406 : loss : 0.101061, loss_ce: 0.026925
[00:27:23.745] iteration 2407 : loss : 0.095204, loss_ce: 0.023159
[00:27:24.048] iteration 2408 : loss : 0.140754, loss_ce: 0.025806
[00:27:24.364] iteration 2409 : loss : 0.126022, loss_ce: 0.038941
[00:27:24.664] iteration 2410 : loss : 0.098396, loss_ce: 0.024535
[00:27:24.974] iteration 2411 : loss : 0.184208, loss_ce: 0.033317
[00:27:25.282] iteration 2412 : loss : 0.116332, loss_ce: 0.041932
[00:27:25.592] iteration 2413 : loss : 0.190152, loss_ce: 0.027458
[00:27:25.905] iteration 2414 : loss : 0.171314, loss_ce: 0.022165
[00:27:26.208] iteration 2415 : loss : 0.154267, loss_ce: 0.035246
[00:27:26.513] iteration 2416 : loss : 0.126533, loss_ce: 0.044108
[00:27:26.813] iteration 2417 : loss : 0.117735, loss_ce: 0.078653
[00:27:27.121] iteration 2418 : loss : 0.078823, loss_ce: 0.018981
[00:27:27.427] iteration 2419 : loss : 0.102150, loss_ce: 0.040627
[00:27:27.736] iteration 2420 : loss : 0.100036, loss_ce: 0.043984
[00:27:28.056] iteration 2421 : loss : 0.114374, loss_ce: 0.045080
[00:27:28.367] iteration 2422 : loss : 0.145795, loss_ce: 0.029871
[00:27:28.676] iteration 2423 : loss : 0.114596, loss_ce: 0.029604
[00:27:28.976] iteration 2424 : loss : 0.144695, loss_ce: 0.042818
[00:27:29.290] iteration 2425 : loss : 0.135070, loss_ce: 0.016518
[00:27:29.591] iteration 2426 : loss : 0.092553, loss_ce: 0.043288
[00:27:29.892] iteration 2427 : loss : 0.122606, loss_ce: 0.022796
[00:27:30.201] iteration 2428 : loss : 0.119749, loss_ce: 0.036748
[00:27:30.507] iteration 2429 : loss : 0.167284, loss_ce: 0.037245
[00:27:30.813] iteration 2430 : loss : 0.213825, loss_ce: 0.026243
[00:27:31.117] iteration 2431 : loss : 0.230850, loss_ce: 0.018456
[00:27:31.431] iteration 2432 : loss : 0.090829, loss_ce: 0.014187
[00:27:31.735] iteration 2433 : loss : 0.158582, loss_ce: 0.010601
[00:27:32.041] iteration 2434 : loss : 0.101208, loss_ce: 0.009159
[00:27:32.354] iteration 2435 : loss : 0.156158, loss_ce: 0.014904
[00:27:32.660] iteration 2436 : loss : 0.164530, loss_ce: 0.027988
[00:27:32.964] iteration 2437 : loss : 0.211843, loss_ce: 0.029352
[00:27:33.276] iteration 2438 : loss : 0.102574, loss_ce: 0.033365
[00:27:33.579] iteration 2439 : loss : 0.172073, loss_ce: 0.031886
[00:27:33.887] iteration 2440 : loss : 0.118549, loss_ce: 0.029823
[00:27:34.213] iteration 2441 : loss : 0.172525, loss_ce: 0.026616
[00:27:34.519] iteration 2442 : loss : 0.103422, loss_ce: 0.023606
[00:27:34.823] iteration 2443 : loss : 0.103422, loss_ce: 0.022172
[00:27:35.131] iteration 2444 : loss : 0.173924, loss_ce: 0.032768
[00:27:35.438] iteration 2445 : loss : 0.105401, loss_ce: 0.044877
[00:27:35.745] iteration 2446 : loss : 0.161013, loss_ce: 0.027265
[00:27:36.054] iteration 2447 : loss : 0.168349, loss_ce: 0.018128
[00:27:36.359] iteration 2448 : loss : 0.142415, loss_ce: 0.042036
[00:27:36.666] iteration 2449 : loss : 0.130375, loss_ce: 0.038898
[00:27:36.980] iteration 2450 : loss : 0.111743, loss_ce: 0.035260
[00:27:37.295] iteration 2451 : loss : 0.115627, loss_ce: 0.049014
[00:27:37.594] iteration 2452 : loss : 0.153237, loss_ce: 0.018689
[00:27:37.907] iteration 2453 : loss : 0.156769, loss_ce: 0.030965
[00:27:38.218] iteration 2454 : loss : 0.151178, loss_ce: 0.022984
[00:27:38.523] iteration 2455 : loss : 0.105124, loss_ce: 0.031917
[00:27:38.831] iteration 2456 : loss : 0.107474, loss_ce: 0.037223
[00:27:39.136] iteration 2457 : loss : 0.143577, loss_ce: 0.022144
[00:27:39.451] iteration 2458 : loss : 0.116395, loss_ce: 0.018865
[00:27:39.758] iteration 2459 : loss : 0.121609, loss_ce: 0.030329
[00:27:40.063] iteration 2460 : loss : 0.118827, loss_ce: 0.037810
[00:27:40.389] iteration 2461 : loss : 0.181677, loss_ce: 0.042042
[00:27:40.701] iteration 2462 : loss : 0.096286, loss_ce: 0.032962
[00:27:41.009] iteration 2463 : loss : 0.116345, loss_ce: 0.055878
[00:27:41.311] iteration 2464 : loss : 0.155637, loss_ce: 0.030779
[00:27:41.627] iteration 2465 : loss : 0.156725, loss_ce: 0.058365
[00:27:41.930] iteration 2466 : loss : 0.177532, loss_ce: 0.060694
[00:27:42.236] iteration 2467 : loss : 0.115151, loss_ce: 0.049165
[00:27:42.550] iteration 2468 : loss : 0.145261, loss_ce: 0.031062
[00:27:42.851] iteration 2469 : loss : 0.145171, loss_ce: 0.031230
[00:27:43.163] iteration 2470 : loss : 0.108833, loss_ce: 0.037730
[00:27:43.473] iteration 2471 : loss : 0.134202, loss_ce: 0.058154
[00:27:43.784] iteration 2472 : loss : 0.101846, loss_ce: 0.020567
[00:27:44.087] iteration 2473 : loss : 0.159447, loss_ce: 0.040424
[00:27:44.396] iteration 2474 : loss : 0.101468, loss_ce: 0.033153
[00:27:44.704] iteration 2475 : loss : 0.161534, loss_ce: 0.031490
[00:27:45.013] iteration 2476 : loss : 0.122385, loss_ce: 0.036310
[00:27:45.320] iteration 2477 : loss : 0.094945, loss_ce: 0.021225
[00:27:45.621] iteration 2478 : loss : 0.114832, loss_ce: 0.023597
[00:27:45.929] iteration 2479 : loss : 0.119336, loss_ce: 0.032172
[00:27:46.227] iteration 2480 : loss : 0.114602, loss_ce: 0.034313
[00:27:46.551] iteration 2481 : loss : 0.099256, loss_ce: 0.035971
[00:27:46.854] iteration 2482 : loss : 0.134342, loss_ce: 0.037075
[00:27:47.162] iteration 2483 : loss : 0.189021, loss_ce: 0.029812
[00:27:47.462] iteration 2484 : loss : 0.116927, loss_ce: 0.049138
[00:27:47.777] iteration 2485 : loss : 0.134787, loss_ce: 0.043017
[00:27:48.078] iteration 2486 : loss : 0.159040, loss_ce: 0.020147
[00:27:48.383] iteration 2487 : loss : 0.148872, loss_ce: 0.047316
[00:27:48.700] iteration 2488 : loss : 0.120500, loss_ce: 0.049175
[00:27:49.005] iteration 2489 : loss : 0.094821, loss_ce: 0.017826
[00:27:49.318] iteration 2490 : loss : 0.109481, loss_ce: 0.043608
[00:27:49.620] iteration 2491 : loss : 0.137503, loss_ce: 0.019355
[00:27:49.932] iteration 2492 : loss : 0.160636, loss_ce: 0.030430
[00:27:50.240] iteration 2493 : loss : 0.141781, loss_ce: 0.037556
[00:27:50.543] iteration 2494 : loss : 0.109016, loss_ce: 0.045993
[00:27:50.850] iteration 2495 : loss : 0.250936, loss_ce: 0.016809
[00:27:51.166] iteration 2496 : loss : 0.128989, loss_ce: 0.024889
[00:27:51.477] iteration 2497 : loss : 0.103834, loss_ce: 0.034357
[00:27:51.787] iteration 2498 : loss : 0.111293, loss_ce: 0.033104
[00:27:52.099] iteration 2499 : loss : 0.122129, loss_ce: 0.036521
[00:27:52.418] iteration 2500 : loss : 0.088431, loss_ce: 0.034534
[00:27:52.761] iteration 2501 : loss : 0.154409, loss_ce: 0.037142
[00:27:52.845] iteration 2502 : loss : 0.359322, loss_ce: 0.012078
[00:28:12.099] iteration 2503 : loss : 0.126503, loss_ce: 0.048803
[00:28:12.402] iteration 2504 : loss : 0.100104, loss_ce: 0.036172
[00:28:12.715] iteration 2505 : loss : 0.142450, loss_ce: 0.021045
[00:28:13.014] iteration 2506 : loss : 0.204929, loss_ce: 0.031268
[00:28:13.327] iteration 2507 : loss : 0.169117, loss_ce: 0.057016
[00:28:13.632] iteration 2508 : loss : 0.256996, loss_ce: 0.023653
[00:28:13.939] iteration 2509 : loss : 0.114822, loss_ce: 0.039743
[00:28:14.246] iteration 2510 : loss : 0.141745, loss_ce: 0.044835
[00:28:14.546] iteration 2511 : loss : 0.129671, loss_ce: 0.043664
[00:28:14.844] iteration 2512 : loss : 0.169181, loss_ce: 0.012959
[00:28:15.152] iteration 2513 : loss : 0.114252, loss_ce: 0.028553
[00:28:15.451] iteration 2514 : loss : 0.130803, loss_ce: 0.022435
[00:28:15.752] iteration 2515 : loss : 0.126315, loss_ce: 0.043749
[00:28:16.053] iteration 2516 : loss : 0.100595, loss_ce: 0.022540
[00:28:16.356] iteration 2517 : loss : 0.131283, loss_ce: 0.016403
[00:28:16.669] iteration 2518 : loss : 0.179807, loss_ce: 0.025884
[00:28:16.977] iteration 2519 : loss : 0.069756, loss_ce: 0.031076
[00:28:17.275] iteration 2520 : loss : 0.122984, loss_ce: 0.051995
[00:28:17.589] iteration 2521 : loss : 0.152630, loss_ce: 0.030291
[00:28:17.898] iteration 2522 : loss : 0.104495, loss_ce: 0.022480
[00:28:18.203] iteration 2523 : loss : 0.100041, loss_ce: 0.033597
[00:28:18.518] iteration 2524 : loss : 0.129027, loss_ce: 0.026487
[00:28:18.830] iteration 2525 : loss : 0.126092, loss_ce: 0.057142
[00:28:19.133] iteration 2526 : loss : 0.100799, loss_ce: 0.045808
[00:28:19.438] iteration 2527 : loss : 0.139524, loss_ce: 0.034743
[00:28:19.743] iteration 2528 : loss : 0.141294, loss_ce: 0.031606
[00:28:20.049] iteration 2529 : loss : 0.076933, loss_ce: 0.032192
[00:28:20.361] iteration 2530 : loss : 0.096161, loss_ce: 0.046072
[00:28:20.663] iteration 2531 : loss : 0.108469, loss_ce: 0.041774
[00:28:20.960] iteration 2532 : loss : 0.110560, loss_ce: 0.038703
[00:28:21.264] iteration 2533 : loss : 0.093416, loss_ce: 0.025070
[00:28:21.566] iteration 2534 : loss : 0.140604, loss_ce: 0.024606
[00:28:21.880] iteration 2535 : loss : 0.133560, loss_ce: 0.038343
[00:28:22.181] iteration 2536 : loss : 0.091830, loss_ce: 0.033007
[00:28:22.487] iteration 2537 : loss : 0.088152, loss_ce: 0.022117
[00:28:22.788] iteration 2538 : loss : 0.173672, loss_ce: 0.032080
[00:28:23.106] iteration 2539 : loss : 0.102190, loss_ce: 0.047667
[00:28:23.409] iteration 2540 : loss : 0.143515, loss_ce: 0.031014
[00:28:23.739] iteration 2541 : loss : 0.101290, loss_ce: 0.035600
[00:28:24.045] iteration 2542 : loss : 0.132893, loss_ce: 0.044515
[00:28:24.348] iteration 2543 : loss : 0.124937, loss_ce: 0.024450
[00:28:24.654] iteration 2544 : loss : 0.127494, loss_ce: 0.032056
[00:28:24.955] iteration 2545 : loss : 0.131201, loss_ce: 0.037215
[00:28:25.259] iteration 2546 : loss : 0.180865, loss_ce: 0.030501
[00:28:25.563] iteration 2547 : loss : 0.142961, loss_ce: 0.056185
[00:28:25.870] iteration 2548 : loss : 0.101335, loss_ce: 0.054529
[00:28:26.178] iteration 2549 : loss : 0.136819, loss_ce: 0.022624
[00:28:26.491] iteration 2550 : loss : 0.081874, loss_ce: 0.028722
[00:28:26.792] iteration 2551 : loss : 0.174531, loss_ce: 0.033010
[00:28:27.099] iteration 2552 : loss : 0.114385, loss_ce: 0.052289
[00:28:27.399] iteration 2553 : loss : 0.084688, loss_ce: 0.019086
[00:28:27.703] iteration 2554 : loss : 0.143264, loss_ce: 0.019202
[00:28:28.018] iteration 2555 : loss : 0.134351, loss_ce: 0.022106
[00:28:28.332] iteration 2556 : loss : 0.184391, loss_ce: 0.030581
[00:28:28.635] iteration 2557 : loss : 0.092708, loss_ce: 0.016368
[00:28:28.944] iteration 2558 : loss : 0.249436, loss_ce: 0.011134
[00:28:29.248] iteration 2559 : loss : 0.208477, loss_ce: 0.025251
[00:28:29.553] iteration 2560 : loss : 0.101953, loss_ce: 0.027246
[00:28:29.878] iteration 2561 : loss : 0.140895, loss_ce: 0.018687
[00:28:30.179] iteration 2562 : loss : 0.082649, loss_ce: 0.022985
[00:28:30.483] iteration 2563 : loss : 0.110048, loss_ce: 0.047759
[00:28:30.789] iteration 2564 : loss : 0.157620, loss_ce: 0.028348
[00:28:31.093] iteration 2565 : loss : 0.168500, loss_ce: 0.022648
[00:28:31.399] iteration 2566 : loss : 0.100647, loss_ce: 0.022382
[00:28:31.702] iteration 2567 : loss : 0.116303, loss_ce: 0.046562
[00:28:32.008] iteration 2568 : loss : 0.097844, loss_ce: 0.024415
[00:28:32.313] iteration 2569 : loss : 0.084642, loss_ce: 0.021852
[00:28:32.611] iteration 2570 : loss : 0.159388, loss_ce: 0.026720
[00:28:32.911] iteration 2571 : loss : 0.285752, loss_ce: 0.031036
[00:28:33.218] iteration 2572 : loss : 0.127410, loss_ce: 0.037228
[00:28:33.526] iteration 2573 : loss : 0.094328, loss_ce: 0.039070
[00:28:33.832] iteration 2574 : loss : 0.238130, loss_ce: 0.028078
[00:28:34.138] iteration 2575 : loss : 0.165785, loss_ce: 0.030347
[00:28:34.443] iteration 2576 : loss : 0.126743, loss_ce: 0.047384
[00:28:34.747] iteration 2577 : loss : 0.099490, loss_ce: 0.027177
[00:28:35.051] iteration 2578 : loss : 0.084714, loss_ce: 0.024768
[00:28:35.353] iteration 2579 : loss : 0.107808, loss_ce: 0.032045
[00:28:35.655] iteration 2580 : loss : 0.166984, loss_ce: 0.032412
[00:28:35.981] iteration 2581 : loss : 0.091095, loss_ce: 0.023209
[00:28:36.284] iteration 2582 : loss : 0.178189, loss_ce: 0.023264
[00:28:36.591] iteration 2583 : loss : 0.120597, loss_ce: 0.047148
[00:28:36.893] iteration 2584 : loss : 0.094853, loss_ce: 0.048095
[00:28:37.202] iteration 2585 : loss : 0.092650, loss_ce: 0.024241
[00:28:37.506] iteration 2586 : loss : 0.118307, loss_ce: 0.042498
[00:28:37.809] iteration 2587 : loss : 0.074118, loss_ce: 0.029485
[00:28:38.112] iteration 2588 : loss : 0.141418, loss_ce: 0.065266
[00:28:38.417] iteration 2589 : loss : 0.100088, loss_ce: 0.040523
[00:28:38.730] iteration 2590 : loss : 0.192993, loss_ce: 0.024399
[00:28:39.030] iteration 2591 : loss : 0.195582, loss_ce: 0.026085
[00:28:39.340] iteration 2592 : loss : 0.133564, loss_ce: 0.032753
[00:28:39.641] iteration 2593 : loss : 0.120781, loss_ce: 0.037540
[00:28:39.944] iteration 2594 : loss : 0.149922, loss_ce: 0.020585
[00:28:40.252] iteration 2595 : loss : 0.095996, loss_ce: 0.016277
[00:28:40.558] iteration 2596 : loss : 0.113890, loss_ce: 0.032112
[00:28:40.863] iteration 2597 : loss : 0.146319, loss_ce: 0.030898
[00:28:41.169] iteration 2598 : loss : 0.154860, loss_ce: 0.030288
[00:28:41.471] iteration 2599 : loss : 0.168102, loss_ce: 0.011175
[00:28:41.780] iteration 2600 : loss : 0.079807, loss_ce: 0.025550
[00:28:42.109] iteration 2601 : loss : 0.166925, loss_ce: 0.027131
[00:28:42.410] iteration 2602 : loss : 0.119629, loss_ce: 0.021828
[00:28:42.715] iteration 2603 : loss : 0.104109, loss_ce: 0.026041
[00:28:43.025] iteration 2604 : loss : 0.098249, loss_ce: 0.034323
[00:28:43.342] iteration 2605 : loss : 0.123204, loss_ce: 0.026510
[00:28:43.643] iteration 2606 : loss : 0.137170, loss_ce: 0.025348
[00:28:43.956] iteration 2607 : loss : 0.130440, loss_ce: 0.029177
[00:28:44.257] iteration 2608 : loss : 0.091414, loss_ce: 0.025136
[00:28:44.570] iteration 2609 : loss : 0.091524, loss_ce: 0.034619
[00:28:44.877] iteration 2610 : loss : 0.177721, loss_ce: 0.013690
[00:28:45.185] iteration 2611 : loss : 0.098781, loss_ce: 0.016927
[00:28:45.493] iteration 2612 : loss : 0.110591, loss_ce: 0.028943
[00:28:45.796] iteration 2613 : loss : 0.092813, loss_ce: 0.022553
[00:28:46.099] iteration 2614 : loss : 0.123109, loss_ce: 0.036176
[00:28:46.408] iteration 2615 : loss : 0.116398, loss_ce: 0.045590
[00:28:46.707] iteration 2616 : loss : 0.107427, loss_ce: 0.021896
[00:28:47.014] iteration 2617 : loss : 0.193360, loss_ce: 0.012086
[00:28:47.326] iteration 2618 : loss : 0.143746, loss_ce: 0.013287
[00:28:47.634] iteration 2619 : loss : 0.106268, loss_ce: 0.031919
[00:28:47.950] iteration 2620 : loss : 0.100048, loss_ce: 0.029173
[00:28:48.273] iteration 2621 : loss : 0.076886, loss_ce: 0.020998
[00:28:48.571] iteration 2622 : loss : 0.146927, loss_ce: 0.026505
[00:28:48.878] iteration 2623 : loss : 0.094544, loss_ce: 0.017704
[00:28:49.180] iteration 2624 : loss : 0.223553, loss_ce: 0.016404
[00:28:49.495] iteration 2625 : loss : 0.103160, loss_ce: 0.043108
[00:28:49.800] iteration 2626 : loss : 0.149426, loss_ce: 0.061646
[00:28:50.104] iteration 2627 : loss : 0.138127, loss_ce: 0.043181
[00:28:50.424] iteration 2628 : loss : 0.101578, loss_ce: 0.038762
[00:28:50.731] iteration 2629 : loss : 0.154738, loss_ce: 0.028983
[00:28:51.035] iteration 2630 : loss : 0.171043, loss_ce: 0.024523
[00:28:51.347] iteration 2631 : loss : 0.136402, loss_ce: 0.031432
[00:28:51.662] iteration 2632 : loss : 0.140587, loss_ce: 0.027926
[00:28:51.967] iteration 2633 : loss : 0.145141, loss_ce: 0.040724
[00:28:52.273] iteration 2634 : loss : 0.191428, loss_ce: 0.049675
[00:28:52.585] iteration 2635 : loss : 0.135792, loss_ce: 0.035994
[00:28:52.890] iteration 2636 : loss : 0.156739, loss_ce: 0.025707
[00:28:53.209] iteration 2637 : loss : 0.141563, loss_ce: 0.034841
[00:28:53.521] iteration 2638 : loss : 0.146286, loss_ce: 0.024434
[00:28:53.834] iteration 2639 : loss : 0.166372, loss_ce: 0.022918
[00:28:54.141] iteration 2640 : loss : 0.174546, loss_ce: 0.046644
[00:28:54.273] iteration 2641 : loss : 0.518821, loss_ce: 0.026623
[00:29:13.141] iteration 2642 : loss : 0.116735, loss_ce: 0.032531
[00:29:13.451] iteration 2643 : loss : 0.103922, loss_ce: 0.037656
[00:29:13.763] iteration 2644 : loss : 0.108524, loss_ce: 0.028223
[00:29:14.063] iteration 2645 : loss : 0.143754, loss_ce: 0.021444
[00:29:14.375] iteration 2646 : loss : 0.148378, loss_ce: 0.040313
[00:29:14.676] iteration 2647 : loss : 0.092357, loss_ce: 0.022793
[00:29:14.982] iteration 2648 : loss : 0.120152, loss_ce: 0.037784
[00:29:15.289] iteration 2649 : loss : 0.105332, loss_ce: 0.038341
[00:29:15.596] iteration 2650 : loss : 0.073597, loss_ce: 0.023651
[00:29:15.897] iteration 2651 : loss : 0.164188, loss_ce: 0.016498
[00:29:16.206] iteration 2652 : loss : 0.101679, loss_ce: 0.036694
[00:29:16.513] iteration 2653 : loss : 0.128543, loss_ce: 0.025023
[00:29:16.815] iteration 2654 : loss : 0.174023, loss_ce: 0.020190
[00:29:17.113] iteration 2655 : loss : 0.188164, loss_ce: 0.009614
[00:29:17.419] iteration 2656 : loss : 0.152725, loss_ce: 0.034443
[00:29:17.733] iteration 2657 : loss : 0.106231, loss_ce: 0.034399
[00:29:18.031] iteration 2658 : loss : 0.090077, loss_ce: 0.020204
[00:29:18.342] iteration 2659 : loss : 0.154092, loss_ce: 0.022327
[00:29:18.650] iteration 2660 : loss : 0.148546, loss_ce: 0.034889
[00:29:18.994] iteration 2661 : loss : 0.111490, loss_ce: 0.036248
[00:29:19.300] iteration 2662 : loss : 0.188550, loss_ce: 0.039540
[00:29:19.617] iteration 2663 : loss : 0.098560, loss_ce: 0.036211
[00:29:19.917] iteration 2664 : loss : 0.110305, loss_ce: 0.033638
[00:29:20.224] iteration 2665 : loss : 0.163129, loss_ce: 0.051925
[00:29:20.525] iteration 2666 : loss : 0.137437, loss_ce: 0.048970
[00:29:20.837] iteration 2667 : loss : 0.138438, loss_ce: 0.032852
[00:29:21.142] iteration 2668 : loss : 0.134020, loss_ce: 0.020250
[00:29:21.452] iteration 2669 : loss : 0.108674, loss_ce: 0.032440
[00:29:21.762] iteration 2670 : loss : 0.135193, loss_ce: 0.018689
[00:29:22.075] iteration 2671 : loss : 0.177839, loss_ce: 0.023193
[00:29:22.380] iteration 2672 : loss : 0.090869, loss_ce: 0.031349
[00:29:22.690] iteration 2673 : loss : 0.187802, loss_ce: 0.022198
[00:29:22.997] iteration 2674 : loss : 0.081300, loss_ce: 0.019986
[00:29:23.309] iteration 2675 : loss : 0.128755, loss_ce: 0.022436
[00:29:23.620] iteration 2676 : loss : 0.131805, loss_ce: 0.058254
[00:29:23.925] iteration 2677 : loss : 0.117856, loss_ce: 0.029670
[00:29:24.230] iteration 2678 : loss : 0.114652, loss_ce: 0.030133
[00:29:24.534] iteration 2679 : loss : 0.139814, loss_ce: 0.023165
[00:29:24.838] iteration 2680 : loss : 0.140263, loss_ce: 0.017361
[00:29:25.167] iteration 2681 : loss : 0.116685, loss_ce: 0.035551
[00:29:25.472] iteration 2682 : loss : 0.200166, loss_ce: 0.016386
[00:29:25.780] iteration 2683 : loss : 0.122724, loss_ce: 0.055221
[00:29:26.086] iteration 2684 : loss : 0.097989, loss_ce: 0.024964
[00:29:26.394] iteration 2685 : loss : 0.118779, loss_ce: 0.045782
[00:29:26.702] iteration 2686 : loss : 0.199433, loss_ce: 0.013538
[00:29:27.007] iteration 2687 : loss : 0.126494, loss_ce: 0.030242
[00:29:27.308] iteration 2688 : loss : 0.129119, loss_ce: 0.021066
[00:29:27.614] iteration 2689 : loss : 0.132332, loss_ce: 0.029856
[00:29:27.912] iteration 2690 : loss : 0.097332, loss_ce: 0.022254
[00:29:28.217] iteration 2691 : loss : 0.103004, loss_ce: 0.031397
[00:29:28.520] iteration 2692 : loss : 0.167273, loss_ce: 0.031170
[00:29:28.831] iteration 2693 : loss : 0.089569, loss_ce: 0.029455
[00:29:29.134] iteration 2694 : loss : 0.157135, loss_ce: 0.047461
[00:29:29.442] iteration 2695 : loss : 0.115023, loss_ce: 0.040487
[00:29:29.746] iteration 2696 : loss : 0.112253, loss_ce: 0.024653
[00:29:30.051] iteration 2697 : loss : 0.082741, loss_ce: 0.030262
[00:29:30.358] iteration 2698 : loss : 0.206823, loss_ce: 0.050686
[00:29:30.663] iteration 2699 : loss : 0.158908, loss_ce: 0.028845
[00:29:30.967] iteration 2700 : loss : 0.121354, loss_ce: 0.039861
[00:29:31.299] iteration 2701 : loss : 0.112116, loss_ce: 0.035880
[00:29:31.602] iteration 2702 : loss : 0.106212, loss_ce: 0.034688
[00:29:31.921] iteration 2703 : loss : 0.119654, loss_ce: 0.040447
[00:29:32.223] iteration 2704 : loss : 0.126049, loss_ce: 0.018524
[00:29:32.531] iteration 2705 : loss : 0.128352, loss_ce: 0.054358
[00:29:32.843] iteration 2706 : loss : 0.170174, loss_ce: 0.040513
[00:29:33.149] iteration 2707 : loss : 0.090561, loss_ce: 0.021753
[00:29:33.454] iteration 2708 : loss : 0.144499, loss_ce: 0.031220
[00:29:33.770] iteration 2709 : loss : 0.094439, loss_ce: 0.041907
[00:29:34.077] iteration 2710 : loss : 0.138590, loss_ce: 0.016868
[00:29:34.379] iteration 2711 : loss : 0.084159, loss_ce: 0.026834
[00:29:34.686] iteration 2712 : loss : 0.104683, loss_ce: 0.043806
[00:29:34.992] iteration 2713 : loss : 0.108435, loss_ce: 0.023457
[00:29:35.296] iteration 2714 : loss : 0.157543, loss_ce: 0.024784
[00:29:35.606] iteration 2715 : loss : 0.086821, loss_ce: 0.034994
[00:29:35.915] iteration 2716 : loss : 0.106812, loss_ce: 0.033055
[00:29:36.221] iteration 2717 : loss : 0.095010, loss_ce: 0.028633
[00:29:36.533] iteration 2718 : loss : 0.106306, loss_ce: 0.037850
[00:29:36.842] iteration 2719 : loss : 0.162281, loss_ce: 0.038573
[00:29:37.150] iteration 2720 : loss : 0.106928, loss_ce: 0.033059
[00:29:37.482] iteration 2721 : loss : 0.135699, loss_ce: 0.019617
[00:29:37.787] iteration 2722 : loss : 0.109792, loss_ce: 0.019574
[00:29:38.090] iteration 2723 : loss : 0.108461, loss_ce: 0.032788
[00:29:38.403] iteration 2724 : loss : 0.108084, loss_ce: 0.021136
[00:29:38.711] iteration 2725 : loss : 0.130008, loss_ce: 0.023754
[00:29:39.013] iteration 2726 : loss : 0.103285, loss_ce: 0.029915
[00:29:39.322] iteration 2727 : loss : 0.080858, loss_ce: 0.029351
[00:29:39.633] iteration 2728 : loss : 0.082988, loss_ce: 0.016750
[00:29:39.936] iteration 2729 : loss : 0.152811, loss_ce: 0.018961
[00:29:40.249] iteration 2730 : loss : 0.117002, loss_ce: 0.012175
[00:29:40.555] iteration 2731 : loss : 0.108714, loss_ce: 0.033126
[00:29:40.863] iteration 2732 : loss : 0.116943, loss_ce: 0.039967
[00:29:41.165] iteration 2733 : loss : 0.106522, loss_ce: 0.029677
[00:29:41.473] iteration 2734 : loss : 0.116402, loss_ce: 0.023377
[00:29:41.770] iteration 2735 : loss : 0.086526, loss_ce: 0.038698
[00:29:42.080] iteration 2736 : loss : 0.145795, loss_ce: 0.018025
[00:29:42.389] iteration 2737 : loss : 0.098496, loss_ce: 0.038759
[00:29:42.695] iteration 2738 : loss : 0.101076, loss_ce: 0.036101
[00:29:42.999] iteration 2739 : loss : 0.086016, loss_ce: 0.037446
[00:29:43.317] iteration 2740 : loss : 0.215277, loss_ce: 0.020078
[00:29:43.664] iteration 2741 : loss : 0.092218, loss_ce: 0.042903
[00:29:43.978] iteration 2742 : loss : 0.157474, loss_ce: 0.029291
[00:29:44.281] iteration 2743 : loss : 0.123310, loss_ce: 0.032986
[00:29:44.587] iteration 2744 : loss : 0.187676, loss_ce: 0.032801
[00:29:44.900] iteration 2745 : loss : 0.077940, loss_ce: 0.024975
[00:29:45.203] iteration 2746 : loss : 0.101470, loss_ce: 0.020633
[00:29:45.509] iteration 2747 : loss : 0.104740, loss_ce: 0.025891
[00:29:45.821] iteration 2748 : loss : 0.138602, loss_ce: 0.017817
[00:29:46.127] iteration 2749 : loss : 0.096058, loss_ce: 0.022303
[00:29:46.434] iteration 2750 : loss : 0.162149, loss_ce: 0.030674
[00:29:46.740] iteration 2751 : loss : 0.163710, loss_ce: 0.035537
[00:29:47.049] iteration 2752 : loss : 0.130146, loss_ce: 0.026385
[00:29:47.350] iteration 2753 : loss : 0.155387, loss_ce: 0.022129
[00:29:47.654] iteration 2754 : loss : 0.126372, loss_ce: 0.020230
[00:29:47.959] iteration 2755 : loss : 0.210045, loss_ce: 0.015483
[00:29:48.266] iteration 2756 : loss : 0.078157, loss_ce: 0.018995
[00:29:48.582] iteration 2757 : loss : 0.094658, loss_ce: 0.033845
[00:29:48.885] iteration 2758 : loss : 0.160759, loss_ce: 0.016317
[00:29:49.191] iteration 2759 : loss : 0.074391, loss_ce: 0.028585
[00:29:49.488] iteration 2760 : loss : 0.111625, loss_ce: 0.044141
[00:29:49.805] iteration 2761 : loss : 0.158416, loss_ce: 0.027521
[00:29:50.108] iteration 2762 : loss : 0.212563, loss_ce: 0.026254
[00:29:50.414] iteration 2763 : loss : 0.113440, loss_ce: 0.027898
[00:29:50.717] iteration 2764 : loss : 0.101202, loss_ce: 0.039767
[00:29:51.030] iteration 2765 : loss : 0.102354, loss_ce: 0.024225
[00:29:51.367] iteration 2766 : loss : 0.119204, loss_ce: 0.040164
[00:29:51.666] iteration 2767 : loss : 0.098568, loss_ce: 0.024973
[00:29:51.980] iteration 2768 : loss : 0.204722, loss_ce: 0.028988
[00:29:52.290] iteration 2769 : loss : 0.092039, loss_ce: 0.030766
[00:29:52.591] iteration 2770 : loss : 0.108798, loss_ce: 0.027560
[00:29:52.904] iteration 2771 : loss : 0.095190, loss_ce: 0.032317
[00:29:53.216] iteration 2772 : loss : 0.084516, loss_ce: 0.022562
[00:29:53.524] iteration 2773 : loss : 0.109434, loss_ce: 0.038632
[00:29:53.836] iteration 2774 : loss : 0.090829, loss_ce: 0.034704
[00:29:54.173] iteration 2775 : loss : 0.137607, loss_ce: 0.028953
[00:29:54.527] iteration 2776 : loss : 0.109040, loss_ce: 0.039356
[00:29:54.891] iteration 2777 : loss : 0.083940, loss_ce: 0.030890
[00:29:55.245] iteration 2778 : loss : 0.181942, loss_ce: 0.012035
[00:29:55.605] iteration 2779 : loss : 0.128187, loss_ce: 0.036758
[00:29:55.684] iteration 2780 : loss : 0.420488, loss_ce: 0.009914
[00:30:14.679] iteration 2781 : loss : 0.169232, loss_ce: 0.027600
[00:30:14.982] iteration 2782 : loss : 0.097103, loss_ce: 0.039169
[00:30:15.293] iteration 2783 : loss : 0.080889, loss_ce: 0.022129
[00:30:15.594] iteration 2784 : loss : 0.092665, loss_ce: 0.032474
[00:30:15.902] iteration 2785 : loss : 0.147986, loss_ce: 0.029460
[00:30:16.209] iteration 2786 : loss : 0.099702, loss_ce: 0.026970
[00:30:16.511] iteration 2787 : loss : 0.162603, loss_ce: 0.027629
[00:30:16.818] iteration 2788 : loss : 0.187258, loss_ce: 0.017226
[00:30:17.122] iteration 2789 : loss : 0.132989, loss_ce: 0.010328
[00:30:17.424] iteration 2790 : loss : 0.106025, loss_ce: 0.033384
[00:30:17.733] iteration 2791 : loss : 0.106577, loss_ce: 0.047850
[00:30:18.039] iteration 2792 : loss : 0.155575, loss_ce: 0.021240
[00:30:18.350] iteration 2793 : loss : 0.230169, loss_ce: 0.019936
[00:30:18.650] iteration 2794 : loss : 0.367552, loss_ce: 0.010015
[00:30:18.964] iteration 2795 : loss : 0.118167, loss_ce: 0.043637
[00:30:19.270] iteration 2796 : loss : 0.292610, loss_ce: 0.008790
[00:30:19.569] iteration 2797 : loss : 0.102183, loss_ce: 0.035182
[00:30:19.876] iteration 2798 : loss : 0.100875, loss_ce: 0.050282
[00:30:20.185] iteration 2799 : loss : 0.129470, loss_ce: 0.049311
[00:30:20.491] iteration 2800 : loss : 0.239571, loss_ce: 0.012804
[00:30:20.807] iteration 2801 : loss : 0.195387, loss_ce: 0.017031
[00:30:21.113] iteration 2802 : loss : 0.183949, loss_ce: 0.034657
[00:30:21.426] iteration 2803 : loss : 0.163874, loss_ce: 0.020450
[00:30:21.728] iteration 2804 : loss : 0.126595, loss_ce: 0.058453
[00:30:22.031] iteration 2805 : loss : 0.134987, loss_ce: 0.017715
[00:30:22.333] iteration 2806 : loss : 0.110181, loss_ce: 0.051774
[00:30:22.636] iteration 2807 : loss : 0.118581, loss_ce: 0.024536
[00:30:22.938] iteration 2808 : loss : 0.097784, loss_ce: 0.048819
[00:30:23.243] iteration 2809 : loss : 0.084504, loss_ce: 0.016101
[00:30:23.546] iteration 2810 : loss : 0.107537, loss_ce: 0.024009
[00:30:23.849] iteration 2811 : loss : 0.120532, loss_ce: 0.022453
[00:30:24.155] iteration 2812 : loss : 0.158001, loss_ce: 0.019989
[00:30:24.459] iteration 2813 : loss : 0.111760, loss_ce: 0.024632
[00:30:24.767] iteration 2814 : loss : 0.086561, loss_ce: 0.024510
[00:30:25.068] iteration 2815 : loss : 0.108097, loss_ce: 0.039378
[00:30:25.376] iteration 2816 : loss : 0.160659, loss_ce: 0.027610
[00:30:25.681] iteration 2817 : loss : 0.078378, loss_ce: 0.024489
[00:30:25.981] iteration 2818 : loss : 0.174593, loss_ce: 0.012420
[00:30:26.284] iteration 2819 : loss : 0.236529, loss_ce: 0.018501
[00:30:26.592] iteration 2820 : loss : 0.146833, loss_ce: 0.024069
[00:30:26.905] iteration 2821 : loss : 0.100790, loss_ce: 0.037485
[00:30:27.206] iteration 2822 : loss : 0.084072, loss_ce: 0.031830
[00:30:27.513] iteration 2823 : loss : 0.147110, loss_ce: 0.026378
[00:30:27.818] iteration 2824 : loss : 0.125655, loss_ce: 0.022601
[00:30:28.132] iteration 2825 : loss : 0.096912, loss_ce: 0.033999
[00:30:28.436] iteration 2826 : loss : 0.113440, loss_ce: 0.041651
[00:30:28.744] iteration 2827 : loss : 0.120490, loss_ce: 0.016399
[00:30:29.052] iteration 2828 : loss : 0.186755, loss_ce: 0.010569
[00:30:29.361] iteration 2829 : loss : 0.089344, loss_ce: 0.020345
[00:30:29.664] iteration 2830 : loss : 0.098198, loss_ce: 0.032834
[00:30:29.979] iteration 2831 : loss : 0.108341, loss_ce: 0.045033
[00:30:30.283] iteration 2832 : loss : 0.139262, loss_ce: 0.016602
[00:30:30.590] iteration 2833 : loss : 0.110719, loss_ce: 0.026864
[00:30:30.897] iteration 2834 : loss : 0.106505, loss_ce: 0.038643
[00:30:31.204] iteration 2835 : loss : 0.111657, loss_ce: 0.034612
[00:30:31.503] iteration 2836 : loss : 0.102600, loss_ce: 0.018594
[00:30:31.806] iteration 2837 : loss : 0.115519, loss_ce: 0.026978
[00:30:32.110] iteration 2838 : loss : 0.103135, loss_ce: 0.030791
[00:30:32.414] iteration 2839 : loss : 0.096382, loss_ce: 0.035221
[00:30:32.721] iteration 2840 : loss : 0.168955, loss_ce: 0.030623
[00:30:33.046] iteration 2841 : loss : 0.156775, loss_ce: 0.038044
[00:30:33.349] iteration 2842 : loss : 0.080498, loss_ce: 0.023142
[00:30:33.651] iteration 2843 : loss : 0.148325, loss_ce: 0.041699
[00:30:33.955] iteration 2844 : loss : 0.136388, loss_ce: 0.024082
[00:30:34.264] iteration 2845 : loss : 0.089453, loss_ce: 0.026879
[00:30:34.579] iteration 2846 : loss : 0.173047, loss_ce: 0.020425
[00:30:34.885] iteration 2847 : loss : 0.110568, loss_ce: 0.042242
[00:30:35.185] iteration 2848 : loss : 0.135226, loss_ce: 0.043960
[00:30:35.498] iteration 2849 : loss : 0.080511, loss_ce: 0.022300
[00:30:35.802] iteration 2850 : loss : 0.104528, loss_ce: 0.031264
[00:30:36.109] iteration 2851 : loss : 0.088772, loss_ce: 0.035614
[00:30:36.420] iteration 2852 : loss : 0.160300, loss_ce: 0.019874
[00:30:36.724] iteration 2853 : loss : 0.106743, loss_ce: 0.039575
[00:30:37.032] iteration 2854 : loss : 0.143443, loss_ce: 0.011071
[00:30:37.341] iteration 2855 : loss : 0.154447, loss_ce: 0.027254
[00:30:37.647] iteration 2856 : loss : 0.098288, loss_ce: 0.038905
[00:30:37.952] iteration 2857 : loss : 0.111152, loss_ce: 0.047664
[00:30:38.257] iteration 2858 : loss : 0.120488, loss_ce: 0.035697
[00:30:38.567] iteration 2859 : loss : 0.094250, loss_ce: 0.038967
[00:30:38.871] iteration 2860 : loss : 0.173575, loss_ce: 0.031631
[00:30:39.203] iteration 2861 : loss : 0.119804, loss_ce: 0.029886
[00:30:39.507] iteration 2862 : loss : 0.144256, loss_ce: 0.029027
[00:30:39.815] iteration 2863 : loss : 0.083283, loss_ce: 0.041482
[00:30:40.122] iteration 2864 : loss : 0.085879, loss_ce: 0.025650
[00:30:40.428] iteration 2865 : loss : 0.145982, loss_ce: 0.024759
[00:30:40.743] iteration 2866 : loss : 0.153374, loss_ce: 0.028674
[00:30:41.056] iteration 2867 : loss : 0.154908, loss_ce: 0.014893
[00:30:41.360] iteration 2868 : loss : 0.092627, loss_ce: 0.025283
[00:30:41.670] iteration 2869 : loss : 0.147306, loss_ce: 0.009588
[00:30:41.969] iteration 2870 : loss : 0.088506, loss_ce: 0.038057
[00:30:42.276] iteration 2871 : loss : 0.120858, loss_ce: 0.036627
[00:30:42.585] iteration 2872 : loss : 0.111051, loss_ce: 0.034190
[00:30:42.888] iteration 2873 : loss : 0.169754, loss_ce: 0.039030
[00:30:43.199] iteration 2874 : loss : 0.080052, loss_ce: 0.032618
[00:30:43.510] iteration 2875 : loss : 0.204420, loss_ce: 0.026616
[00:30:43.814] iteration 2876 : loss : 0.118920, loss_ce: 0.039913
[00:30:44.116] iteration 2877 : loss : 0.164025, loss_ce: 0.043222
[00:30:44.419] iteration 2878 : loss : 0.111777, loss_ce: 0.049000
[00:30:44.729] iteration 2879 : loss : 0.152705, loss_ce: 0.019913
[00:30:45.031] iteration 2880 : loss : 0.093276, loss_ce: 0.038173
[00:30:45.359] iteration 2881 : loss : 0.093389, loss_ce: 0.038030
[00:30:45.659] iteration 2882 : loss : 0.166190, loss_ce: 0.021255
[00:30:45.962] iteration 2883 : loss : 0.103130, loss_ce: 0.033329
[00:30:46.271] iteration 2884 : loss : 0.151130, loss_ce: 0.047881
[00:30:46.582] iteration 2885 : loss : 0.143697, loss_ce: 0.034937
[00:30:46.894] iteration 2886 : loss : 0.123187, loss_ce: 0.034272
[00:30:47.199] iteration 2887 : loss : 0.099354, loss_ce: 0.023041
[00:30:47.507] iteration 2888 : loss : 0.098373, loss_ce: 0.018567
[00:30:47.804] iteration 2889 : loss : 0.101442, loss_ce: 0.034292
[00:30:48.107] iteration 2890 : loss : 0.084219, loss_ce: 0.032674
[00:30:48.420] iteration 2891 : loss : 0.106360, loss_ce: 0.025298
[00:30:48.724] iteration 2892 : loss : 0.097473, loss_ce: 0.032566
[00:30:49.034] iteration 2893 : loss : 0.114539, loss_ce: 0.040091
[00:30:49.340] iteration 2894 : loss : 0.094694, loss_ce: 0.034997
[00:30:49.647] iteration 2895 : loss : 0.187770, loss_ce: 0.013488
[00:30:49.952] iteration 2896 : loss : 0.162720, loss_ce: 0.044027
[00:30:50.268] iteration 2897 : loss : 0.124488, loss_ce: 0.020119
[00:30:50.573] iteration 2898 : loss : 0.099861, loss_ce: 0.020238
[00:30:50.879] iteration 2899 : loss : 0.107335, loss_ce: 0.033444
[00:30:51.191] iteration 2900 : loss : 0.080243, loss_ce: 0.023631
[00:30:51.519] iteration 2901 : loss : 0.097970, loss_ce: 0.029850
[00:30:51.825] iteration 2902 : loss : 0.081257, loss_ce: 0.024258
[00:30:52.131] iteration 2903 : loss : 0.122402, loss_ce: 0.028753
[00:30:52.440] iteration 2904 : loss : 0.074082, loss_ce: 0.017182
[00:30:52.746] iteration 2905 : loss : 0.091005, loss_ce: 0.022794
[00:30:53.050] iteration 2906 : loss : 0.107956, loss_ce: 0.026571
[00:30:53.362] iteration 2907 : loss : 0.120672, loss_ce: 0.021001
[00:30:53.678] iteration 2908 : loss : 0.128095, loss_ce: 0.024995
[00:30:53.986] iteration 2909 : loss : 0.170702, loss_ce: 0.031967
[00:30:54.299] iteration 2910 : loss : 0.132289, loss_ce: 0.021088
[00:30:54.611] iteration 2911 : loss : 0.166959, loss_ce: 0.026683
[00:30:54.923] iteration 2912 : loss : 0.161401, loss_ce: 0.019755
[00:30:55.231] iteration 2913 : loss : 0.103047, loss_ce: 0.032332
[00:30:55.544] iteration 2914 : loss : 0.137157, loss_ce: 0.028240
[00:30:55.849] iteration 2915 : loss : 0.112746, loss_ce: 0.038248
[00:30:56.157] iteration 2916 : loss : 0.174410, loss_ce: 0.023014
[00:30:56.463] iteration 2917 : loss : 0.097375, loss_ce: 0.026969
[00:30:56.776] iteration 2918 : loss : 0.109127, loss_ce: 0.044029
[00:30:56.853] iteration 2919 : loss : 0.141845, loss_ce: 0.040849
[00:31:16.048] iteration 2920 : loss : 0.120283, loss_ce: 0.035623
[00:31:16.379] iteration 2921 : loss : 0.119981, loss_ce: 0.034837
[00:31:16.685] iteration 2922 : loss : 0.161663, loss_ce: 0.021076
[00:31:16.989] iteration 2923 : loss : 0.100719, loss_ce: 0.028920
[00:31:17.307] iteration 2924 : loss : 0.078906, loss_ce: 0.031086
[00:31:17.616] iteration 2925 : loss : 0.101575, loss_ce: 0.029535
[00:31:17.923] iteration 2926 : loss : 0.118575, loss_ce: 0.047855
[00:31:18.227] iteration 2927 : loss : 0.094788, loss_ce: 0.035547
[00:31:18.536] iteration 2928 : loss : 0.146899, loss_ce: 0.038770
[00:31:18.840] iteration 2929 : loss : 0.072633, loss_ce: 0.025807
[00:31:19.147] iteration 2930 : loss : 0.147950, loss_ce: 0.024952
[00:31:19.452] iteration 2931 : loss : 0.125735, loss_ce: 0.028031
[00:31:19.764] iteration 2932 : loss : 0.145729, loss_ce: 0.046928
[00:31:20.070] iteration 2933 : loss : 0.096051, loss_ce: 0.039605
[00:31:20.380] iteration 2934 : loss : 0.126485, loss_ce: 0.025329
[00:31:20.688] iteration 2935 : loss : 0.092872, loss_ce: 0.032657
[00:31:20.996] iteration 2936 : loss : 0.098147, loss_ce: 0.029425
[00:31:21.297] iteration 2937 : loss : 0.096145, loss_ce: 0.019441
[00:31:21.608] iteration 2938 : loss : 0.105762, loss_ce: 0.037258
[00:31:21.912] iteration 2939 : loss : 0.150053, loss_ce: 0.032832
[00:31:22.215] iteration 2940 : loss : 0.132546, loss_ce: 0.033352
[00:31:22.543] iteration 2941 : loss : 0.105375, loss_ce: 0.035837
[00:31:22.851] iteration 2942 : loss : 0.089810, loss_ce: 0.025545
[00:31:23.164] iteration 2943 : loss : 0.153565, loss_ce: 0.018961
[00:31:23.468] iteration 2944 : loss : 0.093274, loss_ce: 0.020108
[00:31:23.776] iteration 2945 : loss : 0.091674, loss_ce: 0.024100
[00:31:24.080] iteration 2946 : loss : 0.140029, loss_ce: 0.044197
[00:31:24.389] iteration 2947 : loss : 0.104545, loss_ce: 0.047532
[00:31:24.703] iteration 2948 : loss : 0.103189, loss_ce: 0.038428
[00:31:25.011] iteration 2949 : loss : 0.102190, loss_ce: 0.037181
[00:31:25.318] iteration 2950 : loss : 0.078852, loss_ce: 0.019304
[00:31:25.628] iteration 2951 : loss : 0.088564, loss_ce: 0.026735
[00:31:25.928] iteration 2952 : loss : 0.099791, loss_ce: 0.035681
[00:31:26.234] iteration 2953 : loss : 0.073202, loss_ce: 0.026386
[00:31:26.539] iteration 2954 : loss : 0.123911, loss_ce: 0.025354
[00:31:26.842] iteration 2955 : loss : 0.107822, loss_ce: 0.012848
[00:31:27.148] iteration 2956 : loss : 0.125601, loss_ce: 0.022790
[00:31:27.455] iteration 2957 : loss : 0.154557, loss_ce: 0.019872
[00:31:27.769] iteration 2958 : loss : 0.138444, loss_ce: 0.025520
[00:31:28.077] iteration 2959 : loss : 0.159526, loss_ce: 0.032281
[00:31:28.394] iteration 2960 : loss : 0.137037, loss_ce: 0.026502
[00:31:28.726] iteration 2961 : loss : 0.094762, loss_ce: 0.025588
[00:31:29.030] iteration 2962 : loss : 0.176603, loss_ce: 0.020479
[00:31:29.337] iteration 2963 : loss : 0.307308, loss_ce: 0.021827
[00:31:29.644] iteration 2964 : loss : 0.106536, loss_ce: 0.013397
[00:31:29.949] iteration 2965 : loss : 0.123394, loss_ce: 0.047189
[00:31:30.255] iteration 2966 : loss : 0.141649, loss_ce: 0.072012
[00:31:30.561] iteration 2967 : loss : 0.106697, loss_ce: 0.032513
[00:31:30.867] iteration 2968 : loss : 0.097496, loss_ce: 0.029493
[00:31:31.176] iteration 2969 : loss : 0.115953, loss_ce: 0.013877
[00:31:31.481] iteration 2970 : loss : 0.169651, loss_ce: 0.028239
[00:31:31.788] iteration 2971 : loss : 0.147065, loss_ce: 0.027981
[00:31:32.098] iteration 2972 : loss : 0.146394, loss_ce: 0.026405
[00:31:32.404] iteration 2973 : loss : 0.147262, loss_ce: 0.014486
[00:31:32.711] iteration 2974 : loss : 0.095152, loss_ce: 0.026743
[00:31:33.014] iteration 2975 : loss : 0.073566, loss_ce: 0.015643
[00:31:33.328] iteration 2976 : loss : 0.148586, loss_ce: 0.018537
[00:31:33.632] iteration 2977 : loss : 0.132370, loss_ce: 0.029423
[00:31:33.940] iteration 2978 : loss : 0.079111, loss_ce: 0.014292
[00:31:34.244] iteration 2979 : loss : 0.109742, loss_ce: 0.040469
[00:31:34.559] iteration 2980 : loss : 0.292945, loss_ce: 0.009706
[00:31:34.886] iteration 2981 : loss : 0.096871, loss_ce: 0.031332
[00:31:35.189] iteration 2982 : loss : 0.129022, loss_ce: 0.036801
[00:31:35.505] iteration 2983 : loss : 0.082936, loss_ce: 0.020689
[00:31:35.811] iteration 2984 : loss : 0.082206, loss_ce: 0.033010
[00:31:36.118] iteration 2985 : loss : 0.088278, loss_ce: 0.033593
[00:31:36.432] iteration 2986 : loss : 0.138223, loss_ce: 0.021855
[00:31:36.739] iteration 2987 : loss : 0.134755, loss_ce: 0.035187
[00:31:37.049] iteration 2988 : loss : 0.073414, loss_ce: 0.026547
[00:31:37.353] iteration 2989 : loss : 0.135555, loss_ce: 0.015584
[00:31:37.665] iteration 2990 : loss : 0.107039, loss_ce: 0.034031
[00:31:37.974] iteration 2991 : loss : 0.138823, loss_ce: 0.018589
[00:31:38.280] iteration 2992 : loss : 0.124216, loss_ce: 0.023383
[00:31:38.594] iteration 2993 : loss : 0.097483, loss_ce: 0.025184
[00:31:38.899] iteration 2994 : loss : 0.088206, loss_ce: 0.035582
[00:31:39.210] iteration 2995 : loss : 0.075021, loss_ce: 0.023471
[00:31:39.518] iteration 2996 : loss : 0.138807, loss_ce: 0.021999
[00:31:39.824] iteration 2997 : loss : 0.096012, loss_ce: 0.031534
[00:31:40.135] iteration 2998 : loss : 0.069671, loss_ce: 0.025795
[00:31:40.436] iteration 2999 : loss : 0.104747, loss_ce: 0.027766
[00:31:40.745] iteration 3000 : loss : 0.102744, loss_ce: 0.026364
[00:31:41.065] iteration 3001 : loss : 0.094701, loss_ce: 0.024775
[00:31:41.370] iteration 3002 : loss : 0.115040, loss_ce: 0.022775
[00:31:41.680] iteration 3003 : loss : 0.161106, loss_ce: 0.013427
[00:31:41.982] iteration 3004 : loss : 0.114645, loss_ce: 0.020711
[00:31:42.295] iteration 3005 : loss : 0.116998, loss_ce: 0.014670
[00:31:42.596] iteration 3006 : loss : 0.257750, loss_ce: 0.010312
[00:31:42.905] iteration 3007 : loss : 0.103295, loss_ce: 0.039091
[00:31:43.213] iteration 3008 : loss : 0.111883, loss_ce: 0.045804
[00:31:43.519] iteration 3009 : loss : 0.150413, loss_ce: 0.029104
[00:31:43.822] iteration 3010 : loss : 0.121254, loss_ce: 0.037319
[00:31:44.133] iteration 3011 : loss : 0.103901, loss_ce: 0.034001
[00:31:44.442] iteration 3012 : loss : 0.121760, loss_ce: 0.037839
[00:31:44.750] iteration 3013 : loss : 0.121183, loss_ce: 0.042110
[00:31:45.061] iteration 3014 : loss : 0.145617, loss_ce: 0.020924
[00:31:45.367] iteration 3015 : loss : 0.112330, loss_ce: 0.027839
[00:31:45.677] iteration 3016 : loss : 0.170872, loss_ce: 0.021780
[00:31:45.979] iteration 3017 : loss : 0.109399, loss_ce: 0.015373
[00:31:46.288] iteration 3018 : loss : 0.123555, loss_ce: 0.032833
[00:31:46.596] iteration 3019 : loss : 0.203327, loss_ce: 0.027294
[00:31:46.902] iteration 3020 : loss : 0.175786, loss_ce: 0.029443
[00:31:47.232] iteration 3021 : loss : 0.118321, loss_ce: 0.036553
[00:31:47.537] iteration 3022 : loss : 0.125880, loss_ce: 0.028617
[00:31:47.842] iteration 3023 : loss : 0.120162, loss_ce: 0.015200
[00:31:48.148] iteration 3024 : loss : 0.149437, loss_ce: 0.033261
[00:31:48.462] iteration 3025 : loss : 0.144735, loss_ce: 0.034768
[00:31:48.767] iteration 3026 : loss : 0.127678, loss_ce: 0.050353
[00:31:49.074] iteration 3027 : loss : 0.126310, loss_ce: 0.052712
[00:31:49.386] iteration 3028 : loss : 0.179299, loss_ce: 0.011550
[00:31:49.689] iteration 3029 : loss : 0.071498, loss_ce: 0.025379
[00:31:49.994] iteration 3030 : loss : 0.123160, loss_ce: 0.022475
[00:31:50.302] iteration 3031 : loss : 0.102136, loss_ce: 0.028114
[00:31:50.616] iteration 3032 : loss : 0.134676, loss_ce: 0.016860
[00:31:50.922] iteration 3033 : loss : 0.111592, loss_ce: 0.030525
[00:31:51.232] iteration 3034 : loss : 0.150492, loss_ce: 0.029122
[00:31:51.532] iteration 3035 : loss : 0.099371, loss_ce: 0.016586
[00:31:51.842] iteration 3036 : loss : 0.207690, loss_ce: 0.013949
[00:31:52.143] iteration 3037 : loss : 0.180589, loss_ce: 0.042126
[00:31:52.451] iteration 3038 : loss : 0.092916, loss_ce: 0.029035
[00:31:52.763] iteration 3039 : loss : 0.110550, loss_ce: 0.033892
[00:31:53.063] iteration 3040 : loss : 0.101144, loss_ce: 0.026603
[00:31:53.387] iteration 3041 : loss : 0.087553, loss_ce: 0.040856
[00:31:53.695] iteration 3042 : loss : 0.110456, loss_ce: 0.026923
[00:31:54.011] iteration 3043 : loss : 0.087717, loss_ce: 0.031926
[00:31:54.317] iteration 3044 : loss : 0.082364, loss_ce: 0.028066
[00:31:54.631] iteration 3045 : loss : 0.096736, loss_ce: 0.023105
[00:31:54.941] iteration 3046 : loss : 0.160287, loss_ce: 0.009363
[00:31:55.252] iteration 3047 : loss : 0.119605, loss_ce: 0.025910
[00:31:55.567] iteration 3048 : loss : 0.200268, loss_ce: 0.029635
[00:31:55.875] iteration 3049 : loss : 0.161664, loss_ce: 0.050490
[00:31:56.188] iteration 3050 : loss : 0.169231, loss_ce: 0.037083
[00:31:56.513] iteration 3051 : loss : 0.302528, loss_ce: 0.015587
[00:31:56.810] iteration 3052 : loss : 0.109761, loss_ce: 0.030603
[00:31:57.112] iteration 3053 : loss : 0.081548, loss_ce: 0.029674
[00:31:57.430] iteration 3054 : loss : 0.147465, loss_ce: 0.024534
[00:31:57.746] iteration 3055 : loss : 0.196635, loss_ce: 0.029645
[00:31:58.046] iteration 3056 : loss : 0.122099, loss_ce: 0.056423
[00:31:58.365] iteration 3057 : loss : 0.141311, loss_ce: 0.021320
[00:31:58.441] iteration 3058 : loss : 0.192169, loss_ce: 0.022108
[00:32:17.237] iteration 3059 : loss : 0.115219, loss_ce: 0.044041
[00:32:17.545] iteration 3060 : loss : 0.107924, loss_ce: 0.022980
[00:32:17.877] iteration 3061 : loss : 0.157826, loss_ce: 0.018024
[00:32:18.196] iteration 3062 : loss : 0.139596, loss_ce: 0.022808
[00:32:18.501] iteration 3063 : loss : 0.132851, loss_ce: 0.046219
[00:32:18.809] iteration 3064 : loss : 0.105939, loss_ce: 0.025028
[00:32:19.115] iteration 3065 : loss : 0.192891, loss_ce: 0.060116
[00:32:19.421] iteration 3066 : loss : 0.090739, loss_ce: 0.030971
[00:32:19.728] iteration 3067 : loss : 0.102667, loss_ce: 0.032454
[00:32:20.027] iteration 3068 : loss : 0.232027, loss_ce: 0.015669
[00:32:20.336] iteration 3069 : loss : 0.061085, loss_ce: 0.009423
[00:32:20.642] iteration 3070 : loss : 0.152793, loss_ce: 0.047996
[00:32:20.945] iteration 3071 : loss : 0.090145, loss_ce: 0.019804
[00:32:21.249] iteration 3072 : loss : 0.133026, loss_ce: 0.047726
[00:32:21.561] iteration 3073 : loss : 0.175187, loss_ce: 0.024595
[00:32:21.865] iteration 3074 : loss : 0.158792, loss_ce: 0.029123
[00:32:22.163] iteration 3075 : loss : 0.096700, loss_ce: 0.032698
[00:32:22.470] iteration 3076 : loss : 0.129624, loss_ce: 0.040975
[00:32:22.770] iteration 3077 : loss : 0.099063, loss_ce: 0.017737
[00:32:23.075] iteration 3078 : loss : 0.099499, loss_ce: 0.040723
[00:32:23.384] iteration 3079 : loss : 0.105596, loss_ce: 0.027248
[00:32:23.685] iteration 3080 : loss : 0.118697, loss_ce: 0.017890
[00:32:24.007] iteration 3081 : loss : 0.112600, loss_ce: 0.044685
[00:32:24.308] iteration 3082 : loss : 0.107963, loss_ce: 0.025770
[00:32:24.612] iteration 3083 : loss : 0.098044, loss_ce: 0.032628
[00:32:24.920] iteration 3084 : loss : 0.105491, loss_ce: 0.038956
[00:32:25.223] iteration 3085 : loss : 0.117565, loss_ce: 0.025476
[00:32:25.528] iteration 3086 : loss : 0.154192, loss_ce: 0.025131
[00:32:25.836] iteration 3087 : loss : 0.121503, loss_ce: 0.050902
[00:32:26.138] iteration 3088 : loss : 0.195738, loss_ce: 0.024151
[00:32:26.444] iteration 3089 : loss : 0.155581, loss_ce: 0.028621
[00:32:26.747] iteration 3090 : loss : 0.128880, loss_ce: 0.040629
[00:32:27.053] iteration 3091 : loss : 0.138086, loss_ce: 0.042645
[00:32:27.358] iteration 3092 : loss : 0.080592, loss_ce: 0.020692
[00:32:27.665] iteration 3093 : loss : 0.087087, loss_ce: 0.029371
[00:32:27.969] iteration 3094 : loss : 0.134091, loss_ce: 0.047229
[00:32:28.276] iteration 3095 : loss : 0.093661, loss_ce: 0.043646
[00:32:28.580] iteration 3096 : loss : 0.125020, loss_ce: 0.058640
[00:32:28.878] iteration 3097 : loss : 0.145430, loss_ce: 0.027950
[00:32:29.186] iteration 3098 : loss : 0.273685, loss_ce: 0.014225
[00:32:29.486] iteration 3099 : loss : 0.074514, loss_ce: 0.014077
[00:32:29.788] iteration 3100 : loss : 0.117572, loss_ce: 0.021551
[00:32:30.119] iteration 3101 : loss : 0.158089, loss_ce: 0.028401
[00:32:30.421] iteration 3102 : loss : 0.124443, loss_ce: 0.031753
[00:32:30.726] iteration 3103 : loss : 0.110817, loss_ce: 0.041526
[00:32:31.036] iteration 3104 : loss : 0.087195, loss_ce: 0.013713
[00:32:31.343] iteration 3105 : loss : 0.087925, loss_ce: 0.017932
[00:32:31.647] iteration 3106 : loss : 0.099059, loss_ce: 0.038355
[00:32:31.954] iteration 3107 : loss : 0.076223, loss_ce: 0.027131
[00:32:32.263] iteration 3108 : loss : 0.092722, loss_ce: 0.029062
[00:32:32.567] iteration 3109 : loss : 0.136445, loss_ce: 0.033064
[00:32:32.870] iteration 3110 : loss : 0.099082, loss_ce: 0.037651
[00:32:33.188] iteration 3111 : loss : 0.092185, loss_ce: 0.019161
[00:32:33.494] iteration 3112 : loss : 0.132817, loss_ce: 0.045324
[00:32:33.803] iteration 3113 : loss : 0.158526, loss_ce: 0.018402
[00:32:34.106] iteration 3114 : loss : 0.129035, loss_ce: 0.036518
[00:32:34.416] iteration 3115 : loss : 0.106738, loss_ce: 0.039524
[00:32:34.720] iteration 3116 : loss : 0.144275, loss_ce: 0.025326
[00:32:35.030] iteration 3117 : loss : 0.105695, loss_ce: 0.022841
[00:32:35.336] iteration 3118 : loss : 0.139187, loss_ce: 0.031499
[00:32:35.635] iteration 3119 : loss : 0.141138, loss_ce: 0.015152
[00:32:35.945] iteration 3120 : loss : 0.143570, loss_ce: 0.027237
[00:32:36.264] iteration 3121 : loss : 0.179411, loss_ce: 0.016866
[00:32:36.565] iteration 3122 : loss : 0.107766, loss_ce: 0.032765
[00:32:36.873] iteration 3123 : loss : 0.123393, loss_ce: 0.025430
[00:32:37.185] iteration 3124 : loss : 0.160560, loss_ce: 0.021927
[00:32:37.487] iteration 3125 : loss : 0.098271, loss_ce: 0.024189
[00:32:37.793] iteration 3126 : loss : 0.108531, loss_ce: 0.052934
[00:32:38.093] iteration 3127 : loss : 0.098216, loss_ce: 0.040264
[00:32:38.408] iteration 3128 : loss : 0.119461, loss_ce: 0.034156
[00:32:38.710] iteration 3129 : loss : 0.093365, loss_ce: 0.033780
[00:32:39.019] iteration 3130 : loss : 0.091313, loss_ce: 0.023334
[00:32:39.325] iteration 3131 : loss : 0.101766, loss_ce: 0.025284
[00:32:39.634] iteration 3132 : loss : 0.161321, loss_ce: 0.034137
[00:32:39.947] iteration 3133 : loss : 0.106446, loss_ce: 0.037474
[00:32:40.259] iteration 3134 : loss : 0.110378, loss_ce: 0.025479
[00:32:40.566] iteration 3135 : loss : 0.088275, loss_ce: 0.019032
[00:32:40.865] iteration 3136 : loss : 0.141592, loss_ce: 0.024512
[00:32:41.182] iteration 3137 : loss : 0.122910, loss_ce: 0.024821
[00:32:41.491] iteration 3138 : loss : 0.148254, loss_ce: 0.013143
[00:32:41.804] iteration 3139 : loss : 0.154883, loss_ce: 0.031715
[00:32:42.104] iteration 3140 : loss : 0.133129, loss_ce: 0.028992
[00:32:42.435] iteration 3141 : loss : 0.187493, loss_ce: 0.023247
[00:32:42.739] iteration 3142 : loss : 0.078357, loss_ce: 0.023359
[00:32:43.042] iteration 3143 : loss : 0.078827, loss_ce: 0.031754
[00:32:43.353] iteration 3144 : loss : 0.132646, loss_ce: 0.023924
[00:32:43.659] iteration 3145 : loss : 0.099346, loss_ce: 0.039044
[00:32:43.967] iteration 3146 : loss : 0.082779, loss_ce: 0.013339
[00:32:44.271] iteration 3147 : loss : 0.139051, loss_ce: 0.020923
[00:32:44.578] iteration 3148 : loss : 0.118843, loss_ce: 0.039674
[00:32:44.879] iteration 3149 : loss : 0.152397, loss_ce: 0.022506
[00:32:45.184] iteration 3150 : loss : 0.127180, loss_ce: 0.020007
[00:32:45.488] iteration 3151 : loss : 0.070946, loss_ce: 0.021045
[00:32:45.791] iteration 3152 : loss : 0.093049, loss_ce: 0.026304
[00:32:46.103] iteration 3153 : loss : 0.152646, loss_ce: 0.017666
[00:32:46.405] iteration 3154 : loss : 0.138257, loss_ce: 0.038459
[00:32:46.708] iteration 3155 : loss : 0.099675, loss_ce: 0.039596
[00:32:47.014] iteration 3156 : loss : 0.128274, loss_ce: 0.028131
[00:32:47.315] iteration 3157 : loss : 0.151783, loss_ce: 0.022530
[00:32:47.622] iteration 3158 : loss : 0.086414, loss_ce: 0.030619
[00:32:47.933] iteration 3159 : loss : 0.140572, loss_ce: 0.039815
[00:32:48.240] iteration 3160 : loss : 0.103507, loss_ce: 0.025452
[00:32:48.565] iteration 3161 : loss : 0.179166, loss_ce: 0.034540
[00:32:48.865] iteration 3162 : loss : 0.117401, loss_ce: 0.030114
[00:32:49.174] iteration 3163 : loss : 0.124614, loss_ce: 0.027040
[00:32:49.479] iteration 3164 : loss : 0.103268, loss_ce: 0.033434
[00:32:49.785] iteration 3165 : loss : 0.130525, loss_ce: 0.026357
[00:32:50.084] iteration 3166 : loss : 0.161783, loss_ce: 0.028556
[00:32:50.392] iteration 3167 : loss : 0.091342, loss_ce: 0.020948
[00:32:50.699] iteration 3168 : loss : 0.166781, loss_ce: 0.028195
[00:32:51.009] iteration 3169 : loss : 0.126971, loss_ce: 0.041560
[00:32:51.320] iteration 3170 : loss : 0.188801, loss_ce: 0.009453
[00:32:51.628] iteration 3171 : loss : 0.090219, loss_ce: 0.024815
[00:32:51.935] iteration 3172 : loss : 0.228254, loss_ce: 0.007657
[00:32:52.235] iteration 3173 : loss : 0.117416, loss_ce: 0.042623
[00:32:52.540] iteration 3174 : loss : 0.087020, loss_ce: 0.025686
[00:32:52.847] iteration 3175 : loss : 0.126351, loss_ce: 0.033103
[00:32:53.159] iteration 3176 : loss : 0.152354, loss_ce: 0.036792
[00:32:53.467] iteration 3177 : loss : 0.082222, loss_ce: 0.016448
[00:32:53.771] iteration 3178 : loss : 0.147359, loss_ce: 0.028409
[00:32:54.080] iteration 3179 : loss : 0.069893, loss_ce: 0.013674
[00:32:54.385] iteration 3180 : loss : 0.079081, loss_ce: 0.020846
[00:32:54.707] iteration 3181 : loss : 0.107019, loss_ce: 0.024209
[00:32:55.010] iteration 3182 : loss : 0.108599, loss_ce: 0.033348
[00:32:55.316] iteration 3183 : loss : 0.071878, loss_ce: 0.021568
[00:32:55.629] iteration 3184 : loss : 0.142215, loss_ce: 0.037756
[00:32:55.936] iteration 3185 : loss : 0.145071, loss_ce: 0.028614
[00:32:56.243] iteration 3186 : loss : 0.154009, loss_ce: 0.012575
[00:32:56.552] iteration 3187 : loss : 0.099906, loss_ce: 0.031351
[00:32:56.867] iteration 3188 : loss : 0.128187, loss_ce: 0.037264
[00:32:57.176] iteration 3189 : loss : 0.125429, loss_ce: 0.036995
[00:32:57.484] iteration 3190 : loss : 0.086588, loss_ce: 0.019105
[00:32:57.797] iteration 3191 : loss : 0.244525, loss_ce: 0.007169
[00:32:58.113] iteration 3192 : loss : 0.137327, loss_ce: 0.020013
[00:32:58.425] iteration 3193 : loss : 0.113577, loss_ce: 0.017709
[00:32:58.736] iteration 3194 : loss : 0.150305, loss_ce: 0.044894
[00:32:59.046] iteration 3195 : loss : 0.144884, loss_ce: 0.027697
[00:32:59.366] iteration 3196 : loss : 0.219605, loss_ce: 0.031893
[00:32:59.448] iteration 3197 : loss : 0.374362, loss_ce: 0.030622
[00:33:17.862] iteration 3198 : loss : 0.183743, loss_ce: 0.007976
[00:33:18.171] iteration 3199 : loss : 0.298754, loss_ce: 0.008925
[00:33:18.474] iteration 3200 : loss : 0.086970, loss_ce: 0.041113
[00:33:18.805] iteration 3201 : loss : 0.078925, loss_ce: 0.039140
[00:33:19.118] iteration 3202 : loss : 0.175543, loss_ce: 0.028915
[00:33:19.429] iteration 3203 : loss : 0.076931, loss_ce: 0.028364
[00:33:19.735] iteration 3204 : loss : 0.099804, loss_ce: 0.043117
[00:33:20.037] iteration 3205 : loss : 0.081205, loss_ce: 0.018853
[00:33:20.345] iteration 3206 : loss : 0.164032, loss_ce: 0.021726
[00:33:20.653] iteration 3207 : loss : 0.090159, loss_ce: 0.038547
[00:33:20.957] iteration 3208 : loss : 0.155645, loss_ce: 0.023226
[00:33:21.257] iteration 3209 : loss : 0.092505, loss_ce: 0.026207
[00:33:21.570] iteration 3210 : loss : 0.147328, loss_ce: 0.023368
[00:33:21.876] iteration 3211 : loss : 0.099559, loss_ce: 0.036321
[00:33:22.184] iteration 3212 : loss : 0.104870, loss_ce: 0.050906
[00:33:22.496] iteration 3213 : loss : 0.087717, loss_ce: 0.022570
[00:33:22.805] iteration 3214 : loss : 0.088726, loss_ce: 0.013762
[00:33:23.108] iteration 3215 : loss : 0.116427, loss_ce: 0.036105
[00:33:23.416] iteration 3216 : loss : 0.096964, loss_ce: 0.019463
[00:33:23.725] iteration 3217 : loss : 0.126393, loss_ce: 0.031246
[00:33:24.034] iteration 3218 : loss : 0.149135, loss_ce: 0.033429
[00:33:24.340] iteration 3219 : loss : 0.147641, loss_ce: 0.018253
[00:33:24.643] iteration 3220 : loss : 0.106928, loss_ce: 0.046121
[00:33:24.971] iteration 3221 : loss : 0.087822, loss_ce: 0.020132
[00:33:25.270] iteration 3222 : loss : 0.088860, loss_ce: 0.025745
[00:33:25.584] iteration 3223 : loss : 0.087704, loss_ce: 0.025676
[00:33:25.889] iteration 3224 : loss : 0.074951, loss_ce: 0.022392
[00:33:26.205] iteration 3225 : loss : 0.083611, loss_ce: 0.033862
[00:33:26.512] iteration 3226 : loss : 0.101722, loss_ce: 0.019692
[00:33:26.827] iteration 3227 : loss : 0.091384, loss_ce: 0.025069
[00:33:27.129] iteration 3228 : loss : 0.101060, loss_ce: 0.045878
[00:33:27.443] iteration 3229 : loss : 0.084875, loss_ce: 0.018699
[00:33:27.749] iteration 3230 : loss : 0.115594, loss_ce: 0.036626
[00:33:28.050] iteration 3231 : loss : 0.098653, loss_ce: 0.028593
[00:33:28.362] iteration 3232 : loss : 0.069635, loss_ce: 0.021139
[00:33:28.670] iteration 3233 : loss : 0.154068, loss_ce: 0.036340
[00:33:28.975] iteration 3234 : loss : 0.102667, loss_ce: 0.024721
[00:33:29.281] iteration 3235 : loss : 0.119389, loss_ce: 0.038155
[00:33:29.587] iteration 3236 : loss : 0.104169, loss_ce: 0.024889
[00:33:29.893] iteration 3237 : loss : 0.081681, loss_ce: 0.030365
[00:33:30.194] iteration 3238 : loss : 0.116614, loss_ce: 0.036647
[00:33:30.500] iteration 3239 : loss : 0.141560, loss_ce: 0.030431
[00:33:30.807] iteration 3240 : loss : 0.087363, loss_ce: 0.026852
[00:33:31.142] iteration 3241 : loss : 0.144837, loss_ce: 0.015186
[00:33:31.449] iteration 3242 : loss : 0.075110, loss_ce: 0.018072
[00:33:31.749] iteration 3243 : loss : 0.098551, loss_ce: 0.015784
[00:33:32.056] iteration 3244 : loss : 0.080436, loss_ce: 0.023199
[00:33:32.362] iteration 3245 : loss : 0.113078, loss_ce: 0.027677
[00:33:32.665] iteration 3246 : loss : 0.088181, loss_ce: 0.015549
[00:33:32.962] iteration 3247 : loss : 0.105253, loss_ce: 0.028691
[00:33:33.273] iteration 3248 : loss : 0.182236, loss_ce: 0.052591
[00:33:33.582] iteration 3249 : loss : 0.095703, loss_ce: 0.032715
[00:33:33.888] iteration 3250 : loss : 0.093671, loss_ce: 0.034360
[00:33:34.193] iteration 3251 : loss : 0.091667, loss_ce: 0.027218
[00:33:34.498] iteration 3252 : loss : 0.136296, loss_ce: 0.019605
[00:33:34.802] iteration 3253 : loss : 0.073105, loss_ce: 0.022288
[00:33:35.115] iteration 3254 : loss : 0.108602, loss_ce: 0.044923
[00:33:35.420] iteration 3255 : loss : 0.102037, loss_ce: 0.015946
[00:33:35.722] iteration 3256 : loss : 0.134864, loss_ce: 0.021622
[00:33:36.041] iteration 3257 : loss : 0.147694, loss_ce: 0.024621
[00:33:36.341] iteration 3258 : loss : 0.166246, loss_ce: 0.008199
[00:33:36.648] iteration 3259 : loss : 0.154172, loss_ce: 0.041853
[00:33:36.953] iteration 3260 : loss : 0.149992, loss_ce: 0.018476
[00:33:37.280] iteration 3261 : loss : 0.150106, loss_ce: 0.035433
[00:33:37.587] iteration 3262 : loss : 0.089383, loss_ce: 0.037160
[00:33:37.894] iteration 3263 : loss : 0.295034, loss_ce: 0.014338
[00:33:38.205] iteration 3264 : loss : 0.082559, loss_ce: 0.030641
[00:33:38.507] iteration 3265 : loss : 0.090676, loss_ce: 0.023031
[00:33:38.816] iteration 3266 : loss : 0.114249, loss_ce: 0.031590
[00:33:39.130] iteration 3267 : loss : 0.121392, loss_ce: 0.041042
[00:33:39.439] iteration 3268 : loss : 0.143637, loss_ce: 0.014917
[00:33:39.742] iteration 3269 : loss : 0.103697, loss_ce: 0.021073
[00:33:40.051] iteration 3270 : loss : 0.125179, loss_ce: 0.040216
[00:33:40.354] iteration 3271 : loss : 0.187361, loss_ce: 0.034353
[00:33:40.663] iteration 3272 : loss : 0.188435, loss_ce: 0.015836
[00:33:40.972] iteration 3273 : loss : 0.108101, loss_ce: 0.034858
[00:33:41.274] iteration 3274 : loss : 0.114214, loss_ce: 0.045389
[00:33:41.579] iteration 3275 : loss : 0.105038, loss_ce: 0.042371
[00:33:41.892] iteration 3276 : loss : 0.098425, loss_ce: 0.039051
[00:33:42.197] iteration 3277 : loss : 0.102376, loss_ce: 0.031413
[00:33:42.504] iteration 3278 : loss : 0.103992, loss_ce: 0.018516
[00:33:42.808] iteration 3279 : loss : 0.140494, loss_ce: 0.022504
[00:33:43.114] iteration 3280 : loss : 0.237386, loss_ce: 0.018948
[00:33:43.450] iteration 3281 : loss : 0.156055, loss_ce: 0.017873
[00:33:43.756] iteration 3282 : loss : 0.108557, loss_ce: 0.016682
[00:33:44.066] iteration 3283 : loss : 0.418786, loss_ce: 0.006144
[00:33:44.369] iteration 3284 : loss : 0.127870, loss_ce: 0.022428
[00:33:44.676] iteration 3285 : loss : 0.097043, loss_ce: 0.025646
[00:33:44.992] iteration 3286 : loss : 0.096823, loss_ce: 0.035786
[00:33:45.298] iteration 3287 : loss : 0.085066, loss_ce: 0.030767
[00:33:45.607] iteration 3288 : loss : 0.112115, loss_ce: 0.015406
[00:33:45.914] iteration 3289 : loss : 0.101962, loss_ce: 0.023380
[00:33:46.216] iteration 3290 : loss : 0.087074, loss_ce: 0.035128
[00:33:46.519] iteration 3291 : loss : 0.086739, loss_ce: 0.023648
[00:33:46.822] iteration 3292 : loss : 0.187289, loss_ce: 0.019582
[00:33:47.126] iteration 3293 : loss : 0.252888, loss_ce: 0.024133
[00:33:47.434] iteration 3294 : loss : 0.111935, loss_ce: 0.045487
[00:33:47.745] iteration 3295 : loss : 0.094949, loss_ce: 0.019043
[00:33:48.053] iteration 3296 : loss : 0.111645, loss_ce: 0.031899
[00:33:48.358] iteration 3297 : loss : 0.164790, loss_ce: 0.019226
[00:33:48.665] iteration 3298 : loss : 0.120228, loss_ce: 0.026570
[00:33:48.972] iteration 3299 : loss : 0.127206, loss_ce: 0.012747
[00:33:49.285] iteration 3300 : loss : 0.135393, loss_ce: 0.038268
[00:33:49.611] iteration 3301 : loss : 0.163809, loss_ce: 0.018635
[00:33:49.911] iteration 3302 : loss : 0.113169, loss_ce: 0.051994
[00:33:50.221] iteration 3303 : loss : 0.113722, loss_ce: 0.037252
[00:33:50.531] iteration 3304 : loss : 0.130565, loss_ce: 0.031230
[00:33:50.840] iteration 3305 : loss : 0.101938, loss_ce: 0.038147
[00:33:51.147] iteration 3306 : loss : 0.099234, loss_ce: 0.034233
[00:33:51.457] iteration 3307 : loss : 0.096175, loss_ce: 0.029198
[00:33:51.761] iteration 3308 : loss : 0.090513, loss_ce: 0.023802
[00:33:52.068] iteration 3309 : loss : 0.097006, loss_ce: 0.042305
[00:33:52.374] iteration 3310 : loss : 0.088848, loss_ce: 0.043033
[00:33:52.676] iteration 3311 : loss : 0.123564, loss_ce: 0.033606
[00:33:52.984] iteration 3312 : loss : 0.084833, loss_ce: 0.019792
[00:33:53.295] iteration 3313 : loss : 0.115701, loss_ce: 0.030475
[00:33:53.598] iteration 3314 : loss : 0.105559, loss_ce: 0.043474
[00:33:53.906] iteration 3315 : loss : 0.097451, loss_ce: 0.030391
[00:33:54.210] iteration 3316 : loss : 0.097343, loss_ce: 0.020596
[00:33:54.517] iteration 3317 : loss : 0.118771, loss_ce: 0.027576
[00:33:54.818] iteration 3318 : loss : 0.135001, loss_ce: 0.025124
[00:33:55.127] iteration 3319 : loss : 0.235772, loss_ce: 0.018632
[00:33:55.436] iteration 3320 : loss : 0.083020, loss_ce: 0.024379
[00:33:55.770] iteration 3321 : loss : 0.155077, loss_ce: 0.013469
[00:33:56.079] iteration 3322 : loss : 0.067961, loss_ce: 0.016224
[00:33:56.392] iteration 3323 : loss : 0.115835, loss_ce: 0.042445
[00:33:56.702] iteration 3324 : loss : 0.123384, loss_ce: 0.041152
[00:33:57.008] iteration 3325 : loss : 0.097522, loss_ce: 0.021865
[00:33:57.313] iteration 3326 : loss : 0.098033, loss_ce: 0.036946
[00:33:57.625] iteration 3327 : loss : 0.237205, loss_ce: 0.020731
[00:33:57.931] iteration 3328 : loss : 0.102217, loss_ce: 0.025791
[00:33:58.242] iteration 3329 : loss : 0.097900, loss_ce: 0.028945
[00:33:58.550] iteration 3330 : loss : 0.132199, loss_ce: 0.026505
[00:33:58.866] iteration 3331 : loss : 0.113325, loss_ce: 0.028319
[00:33:59.182] iteration 3332 : loss : 0.088258, loss_ce: 0.030976
[00:33:59.490] iteration 3333 : loss : 0.153185, loss_ce: 0.028582
[00:33:59.806] iteration 3334 : loss : 0.103258, loss_ce: 0.034835
[00:34:00.119] iteration 3335 : loss : 0.103716, loss_ce: 0.030625
[00:34:00.207] iteration 3336 : loss : 0.124990, loss_ce: 0.037225
[00:34:19.185] iteration 3337 : loss : 0.105524, loss_ce: 0.029909
[00:34:19.494] iteration 3338 : loss : 0.123791, loss_ce: 0.028635
[00:34:19.805] iteration 3339 : loss : 0.110480, loss_ce: 0.029291
[00:34:20.106] iteration 3340 : loss : 0.144763, loss_ce: 0.021793
[00:34:20.429] iteration 3341 : loss : 0.090438, loss_ce: 0.017342
[00:34:20.738] iteration 3342 : loss : 0.116642, loss_ce: 0.037517
[00:34:21.036] iteration 3343 : loss : 0.086949, loss_ce: 0.022192
[00:34:21.347] iteration 3344 : loss : 0.186381, loss_ce: 0.023388
[00:34:21.656] iteration 3345 : loss : 0.087089, loss_ce: 0.020178
[00:34:21.962] iteration 3346 : loss : 0.078903, loss_ce: 0.020416
[00:34:22.268] iteration 3347 : loss : 0.087329, loss_ce: 0.027650
[00:34:22.569] iteration 3348 : loss : 0.159865, loss_ce: 0.047450
[00:34:22.875] iteration 3349 : loss : 0.101314, loss_ce: 0.037517
[00:34:23.178] iteration 3350 : loss : 0.112721, loss_ce: 0.018477
[00:34:23.479] iteration 3351 : loss : 0.071031, loss_ce: 0.026578
[00:34:23.785] iteration 3352 : loss : 0.134558, loss_ce: 0.022821
[00:34:24.092] iteration 3353 : loss : 0.114840, loss_ce: 0.019822
[00:34:24.392] iteration 3354 : loss : 0.086537, loss_ce: 0.021683
[00:34:24.692] iteration 3355 : loss : 0.073574, loss_ce: 0.016112
[00:34:24.993] iteration 3356 : loss : 0.082286, loss_ce: 0.018831
[00:34:25.302] iteration 3357 : loss : 0.135495, loss_ce: 0.017919
[00:34:25.602] iteration 3358 : loss : 0.081260, loss_ce: 0.027258
[00:34:25.903] iteration 3359 : loss : 0.151613, loss_ce: 0.036337
[00:34:26.211] iteration 3360 : loss : 0.099433, loss_ce: 0.031613
[00:34:26.519] iteration 3361 : loss : 0.147125, loss_ce: 0.025070
[00:34:26.823] iteration 3362 : loss : 0.114408, loss_ce: 0.037970
[00:34:27.130] iteration 3363 : loss : 0.099818, loss_ce: 0.019529
[00:34:27.438] iteration 3364 : loss : 0.104611, loss_ce: 0.029877
[00:34:27.735] iteration 3365 : loss : 0.060921, loss_ce: 0.016989
[00:34:28.039] iteration 3366 : loss : 0.081594, loss_ce: 0.031453
[00:34:28.351] iteration 3367 : loss : 0.078318, loss_ce: 0.028583
[00:34:28.655] iteration 3368 : loss : 0.091114, loss_ce: 0.037562
[00:34:28.962] iteration 3369 : loss : 0.106152, loss_ce: 0.025601
[00:34:29.268] iteration 3370 : loss : 0.246515, loss_ce: 0.006408
[00:34:29.571] iteration 3371 : loss : 0.125337, loss_ce: 0.047800
[00:34:29.872] iteration 3372 : loss : 0.185332, loss_ce: 0.023519
[00:34:30.178] iteration 3373 : loss : 0.064525, loss_ce: 0.022236
[00:34:30.476] iteration 3374 : loss : 0.090028, loss_ce: 0.024821
[00:34:30.776] iteration 3375 : loss : 0.148470, loss_ce: 0.017611
[00:34:31.083] iteration 3376 : loss : 0.088582, loss_ce: 0.029143
[00:34:31.390] iteration 3377 : loss : 0.087986, loss_ce: 0.040591
[00:34:31.700] iteration 3378 : loss : 0.165999, loss_ce: 0.027549
[00:34:32.008] iteration 3379 : loss : 0.191393, loss_ce: 0.024330
[00:34:32.310] iteration 3380 : loss : 0.186338, loss_ce: 0.024904
[00:34:32.637] iteration 3381 : loss : 0.071372, loss_ce: 0.033500
[00:34:32.940] iteration 3382 : loss : 0.136678, loss_ce: 0.017638
[00:34:33.245] iteration 3383 : loss : 0.141430, loss_ce: 0.023771
[00:34:33.547] iteration 3384 : loss : 0.159720, loss_ce: 0.013420
[00:34:33.857] iteration 3385 : loss : 0.359125, loss_ce: 0.005394
[00:34:34.166] iteration 3386 : loss : 0.088279, loss_ce: 0.015315
[00:34:34.464] iteration 3387 : loss : 0.096975, loss_ce: 0.027403
[00:34:34.768] iteration 3388 : loss : 0.140455, loss_ce: 0.024208
[00:34:35.068] iteration 3389 : loss : 0.149934, loss_ce: 0.025564
[00:34:35.374] iteration 3390 : loss : 0.102862, loss_ce: 0.039203
[00:34:35.677] iteration 3391 : loss : 0.106087, loss_ce: 0.019916
[00:34:35.984] iteration 3392 : loss : 0.144547, loss_ce: 0.026963
[00:34:36.292] iteration 3393 : loss : 0.095457, loss_ce: 0.032718
[00:34:36.595] iteration 3394 : loss : 0.120012, loss_ce: 0.034370
[00:34:36.896] iteration 3395 : loss : 0.118580, loss_ce: 0.018993
[00:34:37.207] iteration 3396 : loss : 0.129262, loss_ce: 0.029806
[00:34:37.509] iteration 3397 : loss : 0.135960, loss_ce: 0.017786
[00:34:37.817] iteration 3398 : loss : 0.105630, loss_ce: 0.035888
[00:34:38.120] iteration 3399 : loss : 0.086017, loss_ce: 0.042698
[00:34:38.427] iteration 3400 : loss : 0.097177, loss_ce: 0.019365
[00:34:38.745] iteration 3401 : loss : 0.107943, loss_ce: 0.030926
[00:34:39.052] iteration 3402 : loss : 0.129395, loss_ce: 0.023456
[00:34:39.359] iteration 3403 : loss : 0.098255, loss_ce: 0.016050
[00:34:39.661] iteration 3404 : loss : 0.102316, loss_ce: 0.026451
[00:34:39.967] iteration 3405 : loss : 0.094137, loss_ce: 0.033984
[00:34:40.277] iteration 3406 : loss : 0.209006, loss_ce: 0.022097
[00:34:40.583] iteration 3407 : loss : 0.085435, loss_ce: 0.033895
[00:34:40.893] iteration 3408 : loss : 0.087833, loss_ce: 0.031967
[00:34:41.196] iteration 3409 : loss : 0.146613, loss_ce: 0.038854
[00:34:41.500] iteration 3410 : loss : 0.096320, loss_ce: 0.033974
[00:34:41.810] iteration 3411 : loss : 0.100203, loss_ce: 0.037112
[00:34:42.115] iteration 3412 : loss : 0.105575, loss_ce: 0.028248
[00:34:42.419] iteration 3413 : loss : 0.143038, loss_ce: 0.024631
[00:34:42.727] iteration 3414 : loss : 0.199835, loss_ce: 0.020352
[00:34:43.031] iteration 3415 : loss : 0.114057, loss_ce: 0.025065
[00:34:43.337] iteration 3416 : loss : 0.104032, loss_ce: 0.022697
[00:34:43.639] iteration 3417 : loss : 0.081990, loss_ce: 0.012167
[00:34:43.949] iteration 3418 : loss : 0.088437, loss_ce: 0.022566
[00:34:44.253] iteration 3419 : loss : 0.092567, loss_ce: 0.031727
[00:34:44.560] iteration 3420 : loss : 0.100442, loss_ce: 0.020363
[00:34:44.882] iteration 3421 : loss : 0.079811, loss_ce: 0.024320
[00:34:45.183] iteration 3422 : loss : 0.176968, loss_ce: 0.020338
[00:34:45.489] iteration 3423 : loss : 0.083660, loss_ce: 0.020798
[00:34:45.795] iteration 3424 : loss : 0.150227, loss_ce: 0.031579
[00:34:46.106] iteration 3425 : loss : 0.078839, loss_ce: 0.034758
[00:34:46.407] iteration 3426 : loss : 0.138822, loss_ce: 0.023580
[00:34:46.714] iteration 3427 : loss : 0.083318, loss_ce: 0.036978
[00:34:47.025] iteration 3428 : loss : 0.100382, loss_ce: 0.047419
[00:34:47.331] iteration 3429 : loss : 0.162746, loss_ce: 0.030921
[00:34:47.631] iteration 3430 : loss : 0.108541, loss_ce: 0.028738
[00:34:47.937] iteration 3431 : loss : 0.158425, loss_ce: 0.014719
[00:34:48.245] iteration 3432 : loss : 0.077767, loss_ce: 0.022708
[00:34:48.545] iteration 3433 : loss : 0.084844, loss_ce: 0.020348
[00:34:48.850] iteration 3434 : loss : 0.093497, loss_ce: 0.034012
[00:34:49.148] iteration 3435 : loss : 0.131104, loss_ce: 0.031593
[00:34:49.450] iteration 3436 : loss : 0.088218, loss_ce: 0.028135
[00:34:49.754] iteration 3437 : loss : 0.165283, loss_ce: 0.051039
[00:34:50.055] iteration 3438 : loss : 0.090721, loss_ce: 0.032425
[00:34:50.360] iteration 3439 : loss : 0.144254, loss_ce: 0.019726
[00:34:50.669] iteration 3440 : loss : 0.129362, loss_ce: 0.038843
[00:34:50.990] iteration 3441 : loss : 0.096835, loss_ce: 0.031287
[00:34:51.301] iteration 3442 : loss : 0.121565, loss_ce: 0.036421
[00:34:51.604] iteration 3443 : loss : 0.115299, loss_ce: 0.025194
[00:34:51.907] iteration 3444 : loss : 0.150899, loss_ce: 0.017487
[00:34:52.217] iteration 3445 : loss : 0.113948, loss_ce: 0.048601
[00:34:52.529] iteration 3446 : loss : 0.085964, loss_ce: 0.022857
[00:34:52.835] iteration 3447 : loss : 0.083521, loss_ce: 0.022466
[00:34:53.144] iteration 3448 : loss : 0.121453, loss_ce: 0.021382
[00:34:53.444] iteration 3449 : loss : 0.131437, loss_ce: 0.034917
[00:34:53.746] iteration 3450 : loss : 0.135708, loss_ce: 0.012683
[00:34:54.054] iteration 3451 : loss : 0.077327, loss_ce: 0.033244
[00:34:54.356] iteration 3452 : loss : 0.085432, loss_ce: 0.027320
[00:34:54.660] iteration 3453 : loss : 0.140683, loss_ce: 0.025930
[00:34:54.961] iteration 3454 : loss : 0.107783, loss_ce: 0.044387
[00:34:55.274] iteration 3455 : loss : 0.143747, loss_ce: 0.024975
[00:34:55.577] iteration 3456 : loss : 0.083401, loss_ce: 0.036940
[00:34:55.886] iteration 3457 : loss : 0.089148, loss_ce: 0.024780
[00:34:56.192] iteration 3458 : loss : 0.218476, loss_ce: 0.011744
[00:34:56.502] iteration 3459 : loss : 0.094509, loss_ce: 0.023948
[00:34:56.814] iteration 3460 : loss : 0.150719, loss_ce: 0.010222
[00:34:57.152] iteration 3461 : loss : 0.077731, loss_ce: 0.033989
[00:34:57.459] iteration 3462 : loss : 0.086486, loss_ce: 0.029910
[00:34:57.774] iteration 3463 : loss : 0.204412, loss_ce: 0.010399
[00:34:58.083] iteration 3464 : loss : 0.077994, loss_ce: 0.030133
[00:34:58.392] iteration 3465 : loss : 0.100985, loss_ce: 0.042390
[00:34:58.705] iteration 3466 : loss : 0.098237, loss_ce: 0.038946
[00:34:59.014] iteration 3467 : loss : 0.089830, loss_ce: 0.041606
[00:34:59.326] iteration 3468 : loss : 0.102032, loss_ce: 0.017054
[00:34:59.639] iteration 3469 : loss : 0.087391, loss_ce: 0.014783
[00:34:59.946] iteration 3470 : loss : 0.101545, loss_ce: 0.037577
[00:35:00.247] iteration 3471 : loss : 0.091627, loss_ce: 0.029366
[00:35:00.567] iteration 3472 : loss : 0.132903, loss_ce: 0.027612
[00:35:00.881] iteration 3473 : loss : 0.138333, loss_ce: 0.038295
[00:35:01.192] iteration 3474 : loss : 0.144708, loss_ce: 0.038830
[00:35:01.288] iteration 3475 : loss : 0.295425, loss_ce: 0.055990
[00:35:19.850] iteration 3476 : loss : 0.066471, loss_ce: 0.020034
[00:35:20.160] iteration 3477 : loss : 0.121917, loss_ce: 0.010281
[00:35:20.475] iteration 3478 : loss : 0.093651, loss_ce: 0.014588
[00:35:20.784] iteration 3479 : loss : 0.108687, loss_ce: 0.027190
[00:35:21.097] iteration 3480 : loss : 0.136165, loss_ce: 0.044407
[00:35:21.424] iteration 3481 : loss : 0.102004, loss_ce: 0.035400
[00:35:21.726] iteration 3482 : loss : 0.093707, loss_ce: 0.023745
[00:35:22.031] iteration 3483 : loss : 0.100827, loss_ce: 0.027431
[00:35:22.344] iteration 3484 : loss : 0.142534, loss_ce: 0.043965
[00:35:22.661] iteration 3485 : loss : 0.096674, loss_ce: 0.029446
[00:35:22.963] iteration 3486 : loss : 0.080280, loss_ce: 0.019893
[00:35:23.273] iteration 3487 : loss : 0.108119, loss_ce: 0.036031
[00:35:23.578] iteration 3488 : loss : 0.136996, loss_ce: 0.016068
[00:35:23.896] iteration 3489 : loss : 0.072201, loss_ce: 0.032202
[00:35:24.201] iteration 3490 : loss : 0.137090, loss_ce: 0.019645
[00:35:24.518] iteration 3491 : loss : 0.091622, loss_ce: 0.027243
[00:35:24.828] iteration 3492 : loss : 0.087347, loss_ce: 0.046438
[00:35:25.139] iteration 3493 : loss : 0.091695, loss_ce: 0.028338
[00:35:25.445] iteration 3494 : loss : 0.092323, loss_ce: 0.027811
[00:35:25.757] iteration 3495 : loss : 0.101673, loss_ce: 0.030355
[00:35:26.060] iteration 3496 : loss : 0.106127, loss_ce: 0.020518
[00:35:26.375] iteration 3497 : loss : 0.087247, loss_ce: 0.032820
[00:35:26.681] iteration 3498 : loss : 0.072910, loss_ce: 0.017332
[00:35:26.989] iteration 3499 : loss : 0.103670, loss_ce: 0.029110
[00:35:27.296] iteration 3500 : loss : 0.121455, loss_ce: 0.028834
[00:35:27.637] iteration 3501 : loss : 0.159150, loss_ce: 0.013933
[00:35:27.943] iteration 3502 : loss : 0.116862, loss_ce: 0.033813
[00:35:28.248] iteration 3503 : loss : 0.090060, loss_ce: 0.019801
[00:35:28.558] iteration 3504 : loss : 0.128715, loss_ce: 0.018932
[00:35:28.872] iteration 3505 : loss : 0.139844, loss_ce: 0.012468
[00:35:29.184] iteration 3506 : loss : 0.167460, loss_ce: 0.015740
[00:35:29.489] iteration 3507 : loss : 0.103484, loss_ce: 0.047398
[00:35:29.799] iteration 3508 : loss : 0.102781, loss_ce: 0.025420
[00:35:30.104] iteration 3509 : loss : 0.127268, loss_ce: 0.015068
[00:35:30.410] iteration 3510 : loss : 0.097504, loss_ce: 0.038791
[00:35:30.714] iteration 3511 : loss : 0.087125, loss_ce: 0.027358
[00:35:31.029] iteration 3512 : loss : 0.115545, loss_ce: 0.049918
[00:35:31.333] iteration 3513 : loss : 0.106072, loss_ce: 0.030035
[00:35:31.637] iteration 3514 : loss : 0.072348, loss_ce: 0.019937
[00:35:31.947] iteration 3515 : loss : 0.158545, loss_ce: 0.010913
[00:35:32.262] iteration 3516 : loss : 0.130198, loss_ce: 0.042510
[00:35:32.564] iteration 3517 : loss : 0.104115, loss_ce: 0.045308
[00:35:32.873] iteration 3518 : loss : 0.071216, loss_ce: 0.023253
[00:35:33.178] iteration 3519 : loss : 0.272597, loss_ce: 0.012043
[00:35:33.487] iteration 3520 : loss : 0.130038, loss_ce: 0.040733
[00:35:33.826] iteration 3521 : loss : 0.094669, loss_ce: 0.017270
[00:35:34.135] iteration 3522 : loss : 0.119484, loss_ce: 0.027147
[00:35:34.438] iteration 3523 : loss : 0.076231, loss_ce: 0.021021
[00:35:34.743] iteration 3524 : loss : 0.128720, loss_ce: 0.012890
[00:35:35.051] iteration 3525 : loss : 0.103954, loss_ce: 0.059842
[00:35:35.359] iteration 3526 : loss : 0.180691, loss_ce: 0.011119
[00:35:35.667] iteration 3527 : loss : 0.107135, loss_ce: 0.022249
[00:35:35.977] iteration 3528 : loss : 0.146129, loss_ce: 0.027369
[00:35:36.282] iteration 3529 : loss : 0.119161, loss_ce: 0.016707
[00:35:36.596] iteration 3530 : loss : 0.086871, loss_ce: 0.022647
[00:35:36.899] iteration 3531 : loss : 0.148021, loss_ce: 0.031291
[00:35:37.210] iteration 3532 : loss : 0.157607, loss_ce: 0.028268
[00:35:37.517] iteration 3533 : loss : 0.080333, loss_ce: 0.023204
[00:35:37.822] iteration 3534 : loss : 0.084288, loss_ce: 0.021700
[00:35:38.139] iteration 3535 : loss : 0.129934, loss_ce: 0.025079
[00:35:38.447] iteration 3536 : loss : 0.084057, loss_ce: 0.023091
[00:35:38.754] iteration 3537 : loss : 0.144888, loss_ce: 0.033192
[00:35:39.068] iteration 3538 : loss : 0.097493, loss_ce: 0.050577
[00:35:39.371] iteration 3539 : loss : 0.129108, loss_ce: 0.027481
[00:35:39.680] iteration 3540 : loss : 0.112376, loss_ce: 0.030413
[00:35:40.010] iteration 3541 : loss : 0.078038, loss_ce: 0.019406
[00:35:40.313] iteration 3542 : loss : 0.132343, loss_ce: 0.022911
[00:35:40.617] iteration 3543 : loss : 0.148506, loss_ce: 0.018077
[00:35:40.922] iteration 3544 : loss : 0.078490, loss_ce: 0.026780
[00:35:41.234] iteration 3545 : loss : 0.134137, loss_ce: 0.027346
[00:35:41.534] iteration 3546 : loss : 0.102158, loss_ce: 0.032916
[00:35:41.839] iteration 3547 : loss : 0.087526, loss_ce: 0.029072
[00:35:42.142] iteration 3548 : loss : 0.081082, loss_ce: 0.028805
[00:35:42.453] iteration 3549 : loss : 0.120455, loss_ce: 0.046498
[00:35:42.756] iteration 3550 : loss : 0.122058, loss_ce: 0.025704
[00:35:43.071] iteration 3551 : loss : 0.105879, loss_ce: 0.027814
[00:35:43.391] iteration 3552 : loss : 0.105013, loss_ce: 0.029614
[00:35:43.693] iteration 3553 : loss : 0.086783, loss_ce: 0.022345
[00:35:44.006] iteration 3554 : loss : 0.077557, loss_ce: 0.024297
[00:35:44.326] iteration 3555 : loss : 0.164522, loss_ce: 0.028313
[00:35:44.630] iteration 3556 : loss : 0.136713, loss_ce: 0.025702
[00:35:44.936] iteration 3557 : loss : 0.113685, loss_ce: 0.034497
[00:35:45.239] iteration 3558 : loss : 0.086437, loss_ce: 0.030238
[00:35:45.546] iteration 3559 : loss : 0.138745, loss_ce: 0.018760
[00:35:45.845] iteration 3560 : loss : 0.141456, loss_ce: 0.010124
[00:35:46.179] iteration 3561 : loss : 0.088253, loss_ce: 0.032448
[00:35:46.492] iteration 3562 : loss : 0.085299, loss_ce: 0.024148
[00:35:46.798] iteration 3563 : loss : 0.072045, loss_ce: 0.021977
[00:35:47.104] iteration 3564 : loss : 0.091582, loss_ce: 0.028713
[00:35:47.407] iteration 3565 : loss : 0.158667, loss_ce: 0.025453
[00:35:47.710] iteration 3566 : loss : 0.085648, loss_ce: 0.017616
[00:35:48.016] iteration 3567 : loss : 0.102505, loss_ce: 0.040050
[00:35:48.328] iteration 3568 : loss : 0.144774, loss_ce: 0.022342
[00:35:48.633] iteration 3569 : loss : 0.121482, loss_ce: 0.034023
[00:35:48.938] iteration 3570 : loss : 0.092570, loss_ce: 0.023973
[00:35:49.243] iteration 3571 : loss : 0.063178, loss_ce: 0.016592
[00:35:49.560] iteration 3572 : loss : 0.105060, loss_ce: 0.025197
[00:35:49.863] iteration 3573 : loss : 0.088623, loss_ce: 0.033864
[00:35:50.165] iteration 3574 : loss : 0.166417, loss_ce: 0.030170
[00:35:50.476] iteration 3575 : loss : 0.413742, loss_ce: 0.003081
[00:35:50.780] iteration 3576 : loss : 0.084874, loss_ce: 0.030675
[00:35:51.085] iteration 3577 : loss : 0.201661, loss_ce: 0.020570
[00:35:51.396] iteration 3578 : loss : 0.069778, loss_ce: 0.012892
[00:35:51.704] iteration 3579 : loss : 0.087692, loss_ce: 0.036024
[00:35:52.007] iteration 3580 : loss : 0.135488, loss_ce: 0.023356
[00:35:52.330] iteration 3581 : loss : 0.146953, loss_ce: 0.015566
[00:35:52.631] iteration 3582 : loss : 0.080578, loss_ce: 0.020176
[00:35:52.941] iteration 3583 : loss : 0.062735, loss_ce: 0.014456
[00:35:53.244] iteration 3584 : loss : 0.072656, loss_ce: 0.030815
[00:35:53.550] iteration 3585 : loss : 0.074919, loss_ce: 0.021942
[00:35:53.855] iteration 3586 : loss : 0.118721, loss_ce: 0.047170
[00:35:54.161] iteration 3587 : loss : 0.073268, loss_ce: 0.024176
[00:35:54.469] iteration 3588 : loss : 0.060288, loss_ce: 0.015361
[00:35:54.779] iteration 3589 : loss : 0.132746, loss_ce: 0.019408
[00:35:55.086] iteration 3590 : loss : 0.092767, loss_ce: 0.030189
[00:35:55.391] iteration 3591 : loss : 0.138477, loss_ce: 0.010838
[00:35:55.698] iteration 3592 : loss : 0.073031, loss_ce: 0.028358
[00:35:56.003] iteration 3593 : loss : 0.073805, loss_ce: 0.022470
[00:35:56.305] iteration 3594 : loss : 0.152272, loss_ce: 0.034783
[00:35:56.611] iteration 3595 : loss : 0.134442, loss_ce: 0.030997
[00:35:56.914] iteration 3596 : loss : 0.137198, loss_ce: 0.020854
[00:35:57.226] iteration 3597 : loss : 0.091779, loss_ce: 0.031300
[00:35:57.530] iteration 3598 : loss : 0.087838, loss_ce: 0.027119
[00:35:57.847] iteration 3599 : loss : 0.131497, loss_ce: 0.025522
[00:35:58.151] iteration 3600 : loss : 0.158623, loss_ce: 0.017066
[00:35:58.483] iteration 3601 : loss : 0.129241, loss_ce: 0.043401
[00:35:58.792] iteration 3602 : loss : 0.127808, loss_ce: 0.028775
[00:35:59.095] iteration 3603 : loss : 0.145770, loss_ce: 0.016515
[00:35:59.408] iteration 3604 : loss : 0.059237, loss_ce: 0.014959
[00:35:59.715] iteration 3605 : loss : 0.136696, loss_ce: 0.039705
[00:36:00.022] iteration 3606 : loss : 0.096273, loss_ce: 0.032732
[00:36:00.325] iteration 3607 : loss : 0.101584, loss_ce: 0.021815
[00:36:00.638] iteration 3608 : loss : 0.095432, loss_ce: 0.038686
[00:36:00.944] iteration 3609 : loss : 0.087940, loss_ce: 0.026642
[00:36:01.250] iteration 3610 : loss : 0.074269, loss_ce: 0.028701
[00:36:01.565] iteration 3611 : loss : 0.199713, loss_ce: 0.019101
[00:36:01.882] iteration 3612 : loss : 0.092290, loss_ce: 0.029798
[00:36:02.185] iteration 3613 : loss : 0.079630, loss_ce: 0.034973
[00:36:02.272] iteration 3614 : loss : 0.410060, loss_ce: 0.003991
[00:36:21.567] iteration 3615 : loss : 0.087331, loss_ce: 0.024060
[00:36:21.874] iteration 3616 : loss : 0.187295, loss_ce: 0.020530
[00:36:22.185] iteration 3617 : loss : 0.093871, loss_ce: 0.035363
[00:36:22.498] iteration 3618 : loss : 0.144074, loss_ce: 0.023398
[00:36:22.804] iteration 3619 : loss : 0.104250, loss_ce: 0.035207
[00:36:23.104] iteration 3620 : loss : 0.131589, loss_ce: 0.022499
[00:36:23.428] iteration 3621 : loss : 0.069926, loss_ce: 0.027706
[00:36:23.727] iteration 3622 : loss : 0.059378, loss_ce: 0.015696
[00:36:24.028] iteration 3623 : loss : 0.113215, loss_ce: 0.027869
[00:36:24.331] iteration 3624 : loss : 0.144965, loss_ce: 0.015620
[00:36:24.632] iteration 3625 : loss : 0.084742, loss_ce: 0.016686
[00:36:24.937] iteration 3626 : loss : 0.135581, loss_ce: 0.015435
[00:36:25.237] iteration 3627 : loss : 0.086204, loss_ce: 0.022440
[00:36:25.546] iteration 3628 : loss : 0.118938, loss_ce: 0.019502
[00:36:25.846] iteration 3629 : loss : 0.077526, loss_ce: 0.027542
[00:36:26.155] iteration 3630 : loss : 0.102510, loss_ce: 0.027343
[00:36:26.459] iteration 3631 : loss : 0.106473, loss_ce: 0.029429
[00:36:26.762] iteration 3632 : loss : 0.090927, loss_ce: 0.031880
[00:36:27.070] iteration 3633 : loss : 0.073479, loss_ce: 0.029015
[00:36:27.376] iteration 3634 : loss : 0.103040, loss_ce: 0.022100
[00:36:27.683] iteration 3635 : loss : 0.080799, loss_ce: 0.019834
[00:36:27.994] iteration 3636 : loss : 0.080332, loss_ce: 0.027192
[00:36:28.310] iteration 3637 : loss : 0.076814, loss_ce: 0.020694
[00:36:28.616] iteration 3638 : loss : 0.095369, loss_ce: 0.016117
[00:36:28.923] iteration 3639 : loss : 0.065793, loss_ce: 0.020324
[00:36:29.239] iteration 3640 : loss : 0.174562, loss_ce: 0.023003
[00:36:29.570] iteration 3641 : loss : 0.073642, loss_ce: 0.025493
[00:36:29.880] iteration 3642 : loss : 0.136477, loss_ce: 0.016992
[00:36:30.195] iteration 3643 : loss : 0.180171, loss_ce: 0.013571
[00:36:30.496] iteration 3644 : loss : 0.085257, loss_ce: 0.020868
[00:36:30.803] iteration 3645 : loss : 0.095979, loss_ce: 0.029579
[00:36:31.100] iteration 3646 : loss : 0.153937, loss_ce: 0.024406
[00:36:31.409] iteration 3647 : loss : 0.075757, loss_ce: 0.018044
[00:36:31.713] iteration 3648 : loss : 0.094998, loss_ce: 0.037313
[00:36:32.023] iteration 3649 : loss : 0.097864, loss_ce: 0.025874
[00:36:32.325] iteration 3650 : loss : 0.094816, loss_ce: 0.038466
[00:36:32.629] iteration 3651 : loss : 0.086127, loss_ce: 0.022522
[00:36:32.934] iteration 3652 : loss : 0.134344, loss_ce: 0.034165
[00:36:33.243] iteration 3653 : loss : 0.197165, loss_ce: 0.022611
[00:36:33.546] iteration 3654 : loss : 0.118974, loss_ce: 0.054031
[00:36:33.852] iteration 3655 : loss : 0.139161, loss_ce: 0.015229
[00:36:34.160] iteration 3656 : loss : 0.085029, loss_ce: 0.033292
[00:36:34.461] iteration 3657 : loss : 0.092049, loss_ce: 0.035246
[00:36:34.763] iteration 3658 : loss : 0.104731, loss_ce: 0.040338
[00:36:35.067] iteration 3659 : loss : 0.095455, loss_ce: 0.036574
[00:36:35.370] iteration 3660 : loss : 0.107589, loss_ce: 0.032183
[00:36:35.693] iteration 3661 : loss : 0.130501, loss_ce: 0.035995
[00:36:36.000] iteration 3662 : loss : 0.080129, loss_ce: 0.024323
[00:36:36.299] iteration 3663 : loss : 0.209405, loss_ce: 0.013132
[00:36:36.603] iteration 3664 : loss : 0.132496, loss_ce: 0.014518
[00:36:36.910] iteration 3665 : loss : 0.170353, loss_ce: 0.011681
[00:36:37.220] iteration 3666 : loss : 0.111690, loss_ce: 0.026939
[00:36:37.524] iteration 3667 : loss : 0.094595, loss_ce: 0.023382
[00:36:37.830] iteration 3668 : loss : 0.079773, loss_ce: 0.026954
[00:36:38.139] iteration 3669 : loss : 0.257894, loss_ce: 0.032851
[00:36:38.449] iteration 3670 : loss : 0.102893, loss_ce: 0.044339
[00:36:38.757] iteration 3671 : loss : 0.099445, loss_ce: 0.033057
[00:36:39.062] iteration 3672 : loss : 0.138912, loss_ce: 0.038711
[00:36:39.366] iteration 3673 : loss : 0.080736, loss_ce: 0.037210
[00:36:39.666] iteration 3674 : loss : 0.088608, loss_ce: 0.025213
[00:36:39.973] iteration 3675 : loss : 0.108642, loss_ce: 0.020321
[00:36:40.274] iteration 3676 : loss : 0.138385, loss_ce: 0.031744
[00:36:40.582] iteration 3677 : loss : 0.099305, loss_ce: 0.021889
[00:36:40.887] iteration 3678 : loss : 0.087167, loss_ce: 0.039228
[00:36:41.193] iteration 3679 : loss : 0.078055, loss_ce: 0.023968
[00:36:41.498] iteration 3680 : loss : 0.075096, loss_ce: 0.022635
[00:36:41.814] iteration 3681 : loss : 0.097105, loss_ce: 0.044727
[00:36:42.116] iteration 3682 : loss : 0.072480, loss_ce: 0.022638
[00:36:42.422] iteration 3683 : loss : 0.064944, loss_ce: 0.010596
[00:36:42.730] iteration 3684 : loss : 0.281638, loss_ce: 0.012950
[00:36:43.034] iteration 3685 : loss : 0.133554, loss_ce: 0.028973
[00:36:43.355] iteration 3686 : loss : 0.081831, loss_ce: 0.021729
[00:36:43.663] iteration 3687 : loss : 0.071984, loss_ce: 0.019438
[00:36:43.962] iteration 3688 : loss : 0.092617, loss_ce: 0.037846
[00:36:44.267] iteration 3689 : loss : 0.090133, loss_ce: 0.030027
[00:36:44.573] iteration 3690 : loss : 0.105698, loss_ce: 0.029107
[00:36:44.879] iteration 3691 : loss : 0.138036, loss_ce: 0.036138
[00:36:45.177] iteration 3692 : loss : 0.136650, loss_ce: 0.036222
[00:36:45.486] iteration 3693 : loss : 0.087524, loss_ce: 0.015542
[00:36:45.791] iteration 3694 : loss : 0.105210, loss_ce: 0.019197
[00:36:46.097] iteration 3695 : loss : 0.096746, loss_ce: 0.021191
[00:36:46.401] iteration 3696 : loss : 0.124785, loss_ce: 0.023973
[00:36:46.706] iteration 3697 : loss : 0.121227, loss_ce: 0.019631
[00:36:47.010] iteration 3698 : loss : 0.084290, loss_ce: 0.033583
[00:36:47.312] iteration 3699 : loss : 0.107356, loss_ce: 0.029543
[00:36:47.616] iteration 3700 : loss : 0.183955, loss_ce: 0.017693
[00:36:47.933] iteration 3701 : loss : 0.163127, loss_ce: 0.025777
[00:36:48.246] iteration 3702 : loss : 0.160550, loss_ce: 0.027799
[00:36:48.551] iteration 3703 : loss : 0.128682, loss_ce: 0.020605
[00:36:48.854] iteration 3704 : loss : 0.151839, loss_ce: 0.021890
[00:36:49.160] iteration 3705 : loss : 0.098689, loss_ce: 0.043243
[00:36:49.464] iteration 3706 : loss : 0.148807, loss_ce: 0.013619
[00:36:49.771] iteration 3707 : loss : 0.120111, loss_ce: 0.016525
[00:36:50.078] iteration 3708 : loss : 0.138715, loss_ce: 0.021378
[00:36:50.384] iteration 3709 : loss : 0.107603, loss_ce: 0.025994
[00:36:50.692] iteration 3710 : loss : 0.148142, loss_ce: 0.027055
[00:36:50.998] iteration 3711 : loss : 0.138821, loss_ce: 0.028753
[00:36:51.302] iteration 3712 : loss : 0.297296, loss_ce: 0.009926
[00:36:51.605] iteration 3713 : loss : 0.075915, loss_ce: 0.031471
[00:36:51.907] iteration 3714 : loss : 0.082476, loss_ce: 0.027407
[00:36:52.212] iteration 3715 : loss : 0.134898, loss_ce: 0.031480
[00:36:52.510] iteration 3716 : loss : 0.090411, loss_ce: 0.039669
[00:36:52.830] iteration 3717 : loss : 0.154711, loss_ce: 0.040301
[00:36:53.138] iteration 3718 : loss : 0.282604, loss_ce: 0.006075
[00:36:53.442] iteration 3719 : loss : 0.098020, loss_ce: 0.028093
[00:36:53.751] iteration 3720 : loss : 0.127009, loss_ce: 0.019423
[00:36:54.081] iteration 3721 : loss : 0.100276, loss_ce: 0.036338
[00:36:54.384] iteration 3722 : loss : 0.113016, loss_ce: 0.023256
[00:36:54.695] iteration 3723 : loss : 0.125462, loss_ce: 0.026580
[00:36:55.001] iteration 3724 : loss : 0.146978, loss_ce: 0.017440
[00:36:55.313] iteration 3725 : loss : 0.191891, loss_ce: 0.010060
[00:36:55.615] iteration 3726 : loss : 0.140949, loss_ce: 0.022765
[00:36:55.922] iteration 3727 : loss : 0.102121, loss_ce: 0.036380
[00:36:56.220] iteration 3728 : loss : 0.098809, loss_ce: 0.035039
[00:36:56.526] iteration 3729 : loss : 0.083772, loss_ce: 0.036569
[00:36:56.837] iteration 3730 : loss : 0.121871, loss_ce: 0.007018
[00:36:57.140] iteration 3731 : loss : 0.155738, loss_ce: 0.024533
[00:36:57.443] iteration 3732 : loss : 0.085152, loss_ce: 0.014180
[00:36:57.746] iteration 3733 : loss : 0.103603, loss_ce: 0.047555
[00:36:58.052] iteration 3734 : loss : 0.174166, loss_ce: 0.014013
[00:36:58.360] iteration 3735 : loss : 0.129788, loss_ce: 0.023820
[00:36:58.659] iteration 3736 : loss : 0.093065, loss_ce: 0.041030
[00:36:58.972] iteration 3737 : loss : 0.092931, loss_ce: 0.024458
[00:36:59.287] iteration 3738 : loss : 0.137624, loss_ce: 0.021671
[00:36:59.597] iteration 3739 : loss : 0.080211, loss_ce: 0.023758
[00:36:59.902] iteration 3740 : loss : 0.088079, loss_ce: 0.021015
[00:37:00.236] iteration 3741 : loss : 0.112728, loss_ce: 0.053809
[00:37:00.543] iteration 3742 : loss : 0.088785, loss_ce: 0.017693
[00:37:00.860] iteration 3743 : loss : 0.099149, loss_ce: 0.050220
[00:37:01.167] iteration 3744 : loss : 0.110589, loss_ce: 0.043867
[00:37:01.472] iteration 3745 : loss : 0.114080, loss_ce: 0.017097
[00:37:01.787] iteration 3746 : loss : 0.084981, loss_ce: 0.025623
[00:37:02.095] iteration 3747 : loss : 0.092848, loss_ce: 0.038240
[00:37:02.411] iteration 3748 : loss : 0.130311, loss_ce: 0.035859
[00:37:02.726] iteration 3749 : loss : 0.073432, loss_ce: 0.029198
[00:37:03.035] iteration 3750 : loss : 0.202637, loss_ce: 0.022078
[00:37:03.361] iteration 3751 : loss : 0.085966, loss_ce: 0.027937
[00:37:03.666] iteration 3752 : loss : 0.128464, loss_ce: 0.021842
[00:37:03.743] iteration 3753 : loss : 0.297136, loss_ce: 0.018729
[00:37:21.526] iteration 3754 : loss : 0.094172, loss_ce: 0.040673
[00:37:21.833] iteration 3755 : loss : 0.213865, loss_ce: 0.028371
[00:37:22.136] iteration 3756 : loss : 0.144335, loss_ce: 0.036505
[00:37:22.448] iteration 3757 : loss : 0.160990, loss_ce: 0.041224
[00:37:22.765] iteration 3758 : loss : 0.183699, loss_ce: 0.023802
[00:37:23.071] iteration 3759 : loss : 0.106250, loss_ce: 0.024673
[00:37:23.374] iteration 3760 : loss : 0.082603, loss_ce: 0.025562
[00:37:23.695] iteration 3761 : loss : 0.081585, loss_ce: 0.030598
[00:37:23.993] iteration 3762 : loss : 0.083218, loss_ce: 0.033791
[00:37:24.304] iteration 3763 : loss : 0.081170, loss_ce: 0.020962
[00:37:24.609] iteration 3764 : loss : 0.106057, loss_ce: 0.038114
[00:37:24.917] iteration 3765 : loss : 0.086263, loss_ce: 0.034635
[00:37:25.221] iteration 3766 : loss : 0.085694, loss_ce: 0.018977
[00:37:25.532] iteration 3767 : loss : 0.107658, loss_ce: 0.039601
[00:37:25.849] iteration 3768 : loss : 0.137195, loss_ce: 0.013168
[00:37:26.150] iteration 3769 : loss : 0.069093, loss_ce: 0.016854
[00:37:26.459] iteration 3770 : loss : 0.081437, loss_ce: 0.025459
[00:37:26.764] iteration 3771 : loss : 0.078003, loss_ce: 0.026977
[00:37:27.064] iteration 3772 : loss : 0.132198, loss_ce: 0.038275
[00:37:27.370] iteration 3773 : loss : 0.140373, loss_ce: 0.021983
[00:37:27.671] iteration 3774 : loss : 0.090540, loss_ce: 0.039942
[00:37:27.978] iteration 3775 : loss : 0.125387, loss_ce: 0.011751
[00:37:28.292] iteration 3776 : loss : 0.140525, loss_ce: 0.024407
[00:37:28.594] iteration 3777 : loss : 0.166355, loss_ce: 0.036939
[00:37:28.905] iteration 3778 : loss : 0.091564, loss_ce: 0.037137
[00:37:29.214] iteration 3779 : loss : 0.072244, loss_ce: 0.017309
[00:37:29.524] iteration 3780 : loss : 0.086032, loss_ce: 0.036916
[00:37:29.858] iteration 3781 : loss : 0.085112, loss_ce: 0.030208
[00:37:30.161] iteration 3782 : loss : 0.090767, loss_ce: 0.024362
[00:37:30.469] iteration 3783 : loss : 0.083170, loss_ce: 0.031267
[00:37:30.777] iteration 3784 : loss : 0.104970, loss_ce: 0.017116
[00:37:31.079] iteration 3785 : loss : 0.078921, loss_ce: 0.022807
[00:37:31.384] iteration 3786 : loss : 0.087360, loss_ce: 0.034702
[00:37:31.686] iteration 3787 : loss : 0.234704, loss_ce: 0.017163
[00:37:31.988] iteration 3788 : loss : 0.157805, loss_ce: 0.020672
[00:37:32.293] iteration 3789 : loss : 0.174050, loss_ce: 0.015452
[00:37:32.611] iteration 3790 : loss : 0.083611, loss_ce: 0.022013
[00:37:32.923] iteration 3791 : loss : 0.074039, loss_ce: 0.023692
[00:37:33.229] iteration 3792 : loss : 0.083832, loss_ce: 0.032679
[00:37:33.546] iteration 3793 : loss : 0.072788, loss_ce: 0.014026
[00:37:33.852] iteration 3794 : loss : 0.109671, loss_ce: 0.036417
[00:37:34.153] iteration 3795 : loss : 0.086982, loss_ce: 0.027170
[00:37:34.457] iteration 3796 : loss : 0.080652, loss_ce: 0.022339
[00:37:34.764] iteration 3797 : loss : 0.088978, loss_ce: 0.024071
[00:37:35.068] iteration 3798 : loss : 0.093691, loss_ce: 0.027709
[00:37:35.381] iteration 3799 : loss : 0.136158, loss_ce: 0.014851
[00:37:35.685] iteration 3800 : loss : 0.103610, loss_ce: 0.012989
[00:37:36.011] iteration 3801 : loss : 0.108429, loss_ce: 0.040778
[00:37:36.318] iteration 3802 : loss : 0.132554, loss_ce: 0.012395
[00:37:36.622] iteration 3803 : loss : 0.096501, loss_ce: 0.025646
[00:37:36.933] iteration 3804 : loss : 0.078711, loss_ce: 0.021873
[00:37:37.241] iteration 3805 : loss : 0.115369, loss_ce: 0.020873
[00:37:37.543] iteration 3806 : loss : 0.119879, loss_ce: 0.013264
[00:37:37.854] iteration 3807 : loss : 0.075106, loss_ce: 0.027996
[00:37:38.160] iteration 3808 : loss : 0.070127, loss_ce: 0.033995
[00:37:38.469] iteration 3809 : loss : 0.137887, loss_ce: 0.022064
[00:37:38.779] iteration 3810 : loss : 0.113155, loss_ce: 0.046217
[00:37:39.087] iteration 3811 : loss : 0.095327, loss_ce: 0.046614
[00:37:39.394] iteration 3812 : loss : 0.108674, loss_ce: 0.031858
[00:37:39.703] iteration 3813 : loss : 0.141552, loss_ce: 0.019879
[00:37:40.005] iteration 3814 : loss : 0.090330, loss_ce: 0.018738
[00:37:40.317] iteration 3815 : loss : 0.075248, loss_ce: 0.019637
[00:37:40.626] iteration 3816 : loss : 0.110415, loss_ce: 0.011314
[00:37:40.934] iteration 3817 : loss : 0.060329, loss_ce: 0.025257
[00:37:41.241] iteration 3818 : loss : 0.059310, loss_ce: 0.011378
[00:37:41.547] iteration 3819 : loss : 0.146716, loss_ce: 0.020684
[00:37:41.856] iteration 3820 : loss : 0.165189, loss_ce: 0.015940
[00:37:42.191] iteration 3821 : loss : 0.077277, loss_ce: 0.035587
[00:37:42.493] iteration 3822 : loss : 0.071033, loss_ce: 0.017229
[00:37:42.808] iteration 3823 : loss : 0.102523, loss_ce: 0.021150
[00:37:43.115] iteration 3824 : loss : 0.097097, loss_ce: 0.032163
[00:37:43.425] iteration 3825 : loss : 0.108903, loss_ce: 0.017526
[00:37:43.725] iteration 3826 : loss : 0.169852, loss_ce: 0.024153
[00:37:44.030] iteration 3827 : loss : 0.098713, loss_ce: 0.027600
[00:37:44.337] iteration 3828 : loss : 0.076022, loss_ce: 0.023875
[00:37:44.648] iteration 3829 : loss : 0.108130, loss_ce: 0.039504
[00:37:44.955] iteration 3830 : loss : 0.083155, loss_ce: 0.030619
[00:37:45.261] iteration 3831 : loss : 0.130365, loss_ce: 0.013135
[00:37:45.565] iteration 3832 : loss : 0.137241, loss_ce: 0.027595
[00:37:45.863] iteration 3833 : loss : 0.131229, loss_ce: 0.019979
[00:37:46.162] iteration 3834 : loss : 0.092842, loss_ce: 0.030610
[00:37:46.464] iteration 3835 : loss : 0.132816, loss_ce: 0.026544
[00:37:46.769] iteration 3836 : loss : 0.095662, loss_ce: 0.032225
[00:37:47.074] iteration 3837 : loss : 0.092304, loss_ce: 0.019879
[00:37:47.380] iteration 3838 : loss : 0.147567, loss_ce: 0.024019
[00:37:47.689] iteration 3839 : loss : 0.120316, loss_ce: 0.022129
[00:37:47.991] iteration 3840 : loss : 0.076491, loss_ce: 0.022598
[00:37:48.313] iteration 3841 : loss : 0.123015, loss_ce: 0.034101
[00:37:48.617] iteration 3842 : loss : 0.076439, loss_ce: 0.034214
[00:37:48.925] iteration 3843 : loss : 0.127043, loss_ce: 0.025374
[00:37:49.230] iteration 3844 : loss : 0.096799, loss_ce: 0.045262
[00:37:49.536] iteration 3845 : loss : 0.074893, loss_ce: 0.016820
[00:37:49.837] iteration 3846 : loss : 0.113248, loss_ce: 0.026132
[00:37:50.141] iteration 3847 : loss : 0.080110, loss_ce: 0.025657
[00:37:50.450] iteration 3848 : loss : 0.077990, loss_ce: 0.020344
[00:37:50.766] iteration 3849 : loss : 0.087306, loss_ce: 0.025480
[00:37:51.069] iteration 3850 : loss : 0.079713, loss_ce: 0.028511
[00:37:51.369] iteration 3851 : loss : 0.117458, loss_ce: 0.007759
[00:37:51.672] iteration 3852 : loss : 0.077801, loss_ce: 0.023232
[00:37:51.976] iteration 3853 : loss : 0.093778, loss_ce: 0.029000
[00:37:52.284] iteration 3854 : loss : 0.068890, loss_ce: 0.028603
[00:37:52.586] iteration 3855 : loss : 0.225898, loss_ce: 0.005542
[00:37:52.889] iteration 3856 : loss : 0.124156, loss_ce: 0.019413
[00:37:53.200] iteration 3857 : loss : 0.136271, loss_ce: 0.026437
[00:37:53.507] iteration 3858 : loss : 0.083816, loss_ce: 0.030702
[00:37:53.813] iteration 3859 : loss : 0.094433, loss_ce: 0.017682
[00:37:54.122] iteration 3860 : loss : 0.134493, loss_ce: 0.024727
[00:37:54.444] iteration 3861 : loss : 0.115821, loss_ce: 0.038494
[00:37:54.743] iteration 3862 : loss : 0.074918, loss_ce: 0.025993
[00:37:55.053] iteration 3863 : loss : 0.083998, loss_ce: 0.032599
[00:37:55.360] iteration 3864 : loss : 0.071292, loss_ce: 0.015499
[00:37:55.663] iteration 3865 : loss : 0.109127, loss_ce: 0.024389
[00:37:55.972] iteration 3866 : loss : 0.097220, loss_ce: 0.019095
[00:37:56.276] iteration 3867 : loss : 0.091794, loss_ce: 0.022771
[00:37:56.577] iteration 3868 : loss : 0.074438, loss_ce: 0.020287
[00:37:56.878] iteration 3869 : loss : 0.138800, loss_ce: 0.006846
[00:37:57.184] iteration 3870 : loss : 0.082994, loss_ce: 0.028403
[00:37:57.492] iteration 3871 : loss : 0.078996, loss_ce: 0.024436
[00:37:57.799] iteration 3872 : loss : 0.090297, loss_ce: 0.018185
[00:37:58.117] iteration 3873 : loss : 0.075693, loss_ce: 0.028902
[00:37:58.417] iteration 3874 : loss : 0.095312, loss_ce: 0.023829
[00:37:58.728] iteration 3875 : loss : 0.150483, loss_ce: 0.026796
[00:37:59.036] iteration 3876 : loss : 0.130465, loss_ce: 0.036224
[00:37:59.346] iteration 3877 : loss : 0.137966, loss_ce: 0.029229
[00:37:59.656] iteration 3878 : loss : 0.115864, loss_ce: 0.043419
[00:37:59.961] iteration 3879 : loss : 0.071270, loss_ce: 0.025151
[00:38:00.280] iteration 3880 : loss : 0.149568, loss_ce: 0.027631
[00:38:00.626] iteration 3881 : loss : 0.072459, loss_ce: 0.017641
[00:38:00.944] iteration 3882 : loss : 0.117272, loss_ce: 0.021475
[00:38:01.247] iteration 3883 : loss : 0.116759, loss_ce: 0.023818
[00:38:01.563] iteration 3884 : loss : 0.086074, loss_ce: 0.026025
[00:38:01.870] iteration 3885 : loss : 0.087953, loss_ce: 0.034740
[00:38:02.181] iteration 3886 : loss : 0.088220, loss_ce: 0.032629
[00:38:02.484] iteration 3887 : loss : 0.096385, loss_ce: 0.020178
[00:38:02.802] iteration 3888 : loss : 0.088058, loss_ce: 0.021329
[00:38:03.112] iteration 3889 : loss : 0.108518, loss_ce: 0.025408
[00:38:03.427] iteration 3890 : loss : 0.078323, loss_ce: 0.035016
[00:38:03.728] iteration 3891 : loss : 0.110211, loss_ce: 0.018091
[00:38:03.808] iteration 3892 : loss : 0.308673, loss_ce: 0.022195
[00:38:22.546] iteration 3893 : loss : 0.076047, loss_ce: 0.023446
[00:38:22.856] iteration 3894 : loss : 0.099670, loss_ce: 0.028071
[00:38:23.167] iteration 3895 : loss : 0.147539, loss_ce: 0.017844
[00:38:23.480] iteration 3896 : loss : 0.075524, loss_ce: 0.029626
[00:38:23.783] iteration 3897 : loss : 0.107475, loss_ce: 0.029444
[00:38:24.084] iteration 3898 : loss : 0.087675, loss_ce: 0.025895
[00:38:24.395] iteration 3899 : loss : 0.070410, loss_ce: 0.027887
[00:38:24.699] iteration 3900 : loss : 0.091847, loss_ce: 0.024139
[00:38:25.023] iteration 3901 : loss : 0.087744, loss_ce: 0.026577
[00:38:25.324] iteration 3902 : loss : 0.087650, loss_ce: 0.021878
[00:38:25.628] iteration 3903 : loss : 0.096108, loss_ce: 0.023290
[00:38:25.929] iteration 3904 : loss : 0.068335, loss_ce: 0.019045
[00:38:26.243] iteration 3905 : loss : 0.067981, loss_ce: 0.022207
[00:38:26.540] iteration 3906 : loss : 0.154299, loss_ce: 0.035761
[00:38:26.843] iteration 3907 : loss : 0.084606, loss_ce: 0.023750
[00:38:27.153] iteration 3908 : loss : 0.097085, loss_ce: 0.032144
[00:38:27.450] iteration 3909 : loss : 0.074703, loss_ce: 0.023213
[00:38:27.751] iteration 3910 : loss : 0.113897, loss_ce: 0.031049
[00:38:28.056] iteration 3911 : loss : 0.088982, loss_ce: 0.038266
[00:38:28.361] iteration 3912 : loss : 0.074494, loss_ce: 0.014889
[00:38:28.672] iteration 3913 : loss : 0.077533, loss_ce: 0.019032
[00:38:28.973] iteration 3914 : loss : 0.089960, loss_ce: 0.027786
[00:38:29.278] iteration 3915 : loss : 0.145311, loss_ce: 0.015738
[00:38:29.581] iteration 3916 : loss : 0.064600, loss_ce: 0.021319
[00:38:29.893] iteration 3917 : loss : 0.073093, loss_ce: 0.024407
[00:38:30.197] iteration 3918 : loss : 0.082295, loss_ce: 0.030134
[00:38:30.504] iteration 3919 : loss : 0.068110, loss_ce: 0.018989
[00:38:30.806] iteration 3920 : loss : 0.061174, loss_ce: 0.027466
[00:38:31.129] iteration 3921 : loss : 0.097411, loss_ce: 0.025464
[00:38:31.432] iteration 3922 : loss : 0.067387, loss_ce: 0.021598
[00:38:31.741] iteration 3923 : loss : 0.143487, loss_ce: 0.014370
[00:38:32.044] iteration 3924 : loss : 0.142551, loss_ce: 0.015638
[00:38:32.344] iteration 3925 : loss : 0.075852, loss_ce: 0.026127
[00:38:32.649] iteration 3926 : loss : 0.130118, loss_ce: 0.017608
[00:38:32.949] iteration 3927 : loss : 0.069176, loss_ce: 0.022494
[00:38:33.257] iteration 3928 : loss : 0.168496, loss_ce: 0.021496
[00:38:33.559] iteration 3929 : loss : 0.126225, loss_ce: 0.020561
[00:38:33.872] iteration 3930 : loss : 0.128020, loss_ce: 0.017475
[00:38:34.180] iteration 3931 : loss : 0.146847, loss_ce: 0.016243
[00:38:34.486] iteration 3932 : loss : 0.100131, loss_ce: 0.014572
[00:38:34.789] iteration 3933 : loss : 0.130638, loss_ce: 0.027304
[00:38:35.100] iteration 3934 : loss : 0.076492, loss_ce: 0.020007
[00:38:35.409] iteration 3935 : loss : 0.123226, loss_ce: 0.015120
[00:38:35.710] iteration 3936 : loss : 0.079587, loss_ce: 0.017136
[00:38:36.019] iteration 3937 : loss : 0.139526, loss_ce: 0.020383
[00:38:36.324] iteration 3938 : loss : 0.136111, loss_ce: 0.016959
[00:38:36.631] iteration 3939 : loss : 0.082995, loss_ce: 0.029231
[00:38:36.933] iteration 3940 : loss : 0.099659, loss_ce: 0.030663
[00:38:37.264] iteration 3941 : loss : 0.067007, loss_ce: 0.018705
[00:38:37.566] iteration 3942 : loss : 0.137507, loss_ce: 0.033661
[00:38:37.873] iteration 3943 : loss : 0.164917, loss_ce: 0.024333
[00:38:38.176] iteration 3944 : loss : 0.078947, loss_ce: 0.027601
[00:38:38.480] iteration 3945 : loss : 0.096279, loss_ce: 0.030216
[00:38:38.788] iteration 3946 : loss : 0.090677, loss_ce: 0.041400
[00:38:39.092] iteration 3947 : loss : 0.071176, loss_ce: 0.023747
[00:38:39.392] iteration 3948 : loss : 0.078069, loss_ce: 0.022177
[00:38:39.695] iteration 3949 : loss : 0.190894, loss_ce: 0.018726
[00:38:39.998] iteration 3950 : loss : 0.070407, loss_ce: 0.021500
[00:38:40.305] iteration 3951 : loss : 0.077371, loss_ce: 0.018251
[00:38:40.606] iteration 3952 : loss : 0.078538, loss_ce: 0.014140
[00:38:40.908] iteration 3953 : loss : 0.081123, loss_ce: 0.027402
[00:38:41.208] iteration 3954 : loss : 0.064820, loss_ce: 0.011628
[00:38:41.512] iteration 3955 : loss : 0.203663, loss_ce: 0.015054
[00:38:41.817] iteration 3956 : loss : 0.071890, loss_ce: 0.020747
[00:38:42.117] iteration 3957 : loss : 0.064277, loss_ce: 0.019475
[00:38:42.419] iteration 3958 : loss : 0.115486, loss_ce: 0.024533
[00:38:42.720] iteration 3959 : loss : 0.083671, loss_ce: 0.013249
[00:38:43.025] iteration 3960 : loss : 0.131110, loss_ce: 0.016969
[00:38:43.350] iteration 3961 : loss : 0.079342, loss_ce: 0.012303
[00:38:43.653] iteration 3962 : loss : 0.098968, loss_ce: 0.022337
[00:38:43.956] iteration 3963 : loss : 0.071432, loss_ce: 0.026226
[00:38:44.267] iteration 3964 : loss : 0.084656, loss_ce: 0.020660
[00:38:44.569] iteration 3965 : loss : 0.168011, loss_ce: 0.032710
[00:38:44.884] iteration 3966 : loss : 0.094607, loss_ce: 0.036817
[00:38:45.191] iteration 3967 : loss : 0.078047, loss_ce: 0.032182
[00:38:45.491] iteration 3968 : loss : 0.084733, loss_ce: 0.026744
[00:38:45.798] iteration 3969 : loss : 0.129948, loss_ce: 0.016759
[00:38:46.100] iteration 3970 : loss : 0.102428, loss_ce: 0.027415
[00:38:46.418] iteration 3971 : loss : 0.090462, loss_ce: 0.042963
[00:38:46.724] iteration 3972 : loss : 0.113600, loss_ce: 0.033652
[00:38:47.026] iteration 3973 : loss : 0.079759, loss_ce: 0.022301
[00:38:47.338] iteration 3974 : loss : 0.090673, loss_ce: 0.028874
[00:38:47.644] iteration 3975 : loss : 0.081949, loss_ce: 0.016846
[00:38:47.950] iteration 3976 : loss : 0.064485, loss_ce: 0.011673
[00:38:48.258] iteration 3977 : loss : 0.098604, loss_ce: 0.018129
[00:38:48.568] iteration 3978 : loss : 0.073788, loss_ce: 0.019128
[00:38:48.881] iteration 3979 : loss : 0.084410, loss_ce: 0.022698
[00:38:49.183] iteration 3980 : loss : 0.106147, loss_ce: 0.032988
[00:38:49.505] iteration 3981 : loss : 0.088385, loss_ce: 0.029155
[00:38:49.804] iteration 3982 : loss : 0.208395, loss_ce: 0.011759
[00:38:50.112] iteration 3983 : loss : 0.141588, loss_ce: 0.011881
[00:38:50.418] iteration 3984 : loss : 0.156362, loss_ce: 0.023441
[00:38:50.722] iteration 3985 : loss : 0.117055, loss_ce: 0.047992
[00:38:51.023] iteration 3986 : loss : 0.075315, loss_ce: 0.029393
[00:38:51.333] iteration 3987 : loss : 0.080003, loss_ce: 0.032476
[00:38:51.634] iteration 3988 : loss : 0.145443, loss_ce: 0.027079
[00:38:51.941] iteration 3989 : loss : 0.097744, loss_ce: 0.024869
[00:38:52.246] iteration 3990 : loss : 0.085383, loss_ce: 0.017944
[00:38:52.557] iteration 3991 : loss : 0.147992, loss_ce: 0.025430
[00:38:52.858] iteration 3992 : loss : 0.078624, loss_ce: 0.020023
[00:38:53.161] iteration 3993 : loss : 0.117996, loss_ce: 0.034646
[00:38:53.471] iteration 3994 : loss : 0.113279, loss_ce: 0.044092
[00:38:53.781] iteration 3995 : loss : 0.105336, loss_ce: 0.027526
[00:38:54.084] iteration 3996 : loss : 0.092236, loss_ce: 0.029980
[00:38:54.387] iteration 3997 : loss : 0.070052, loss_ce: 0.025146
[00:38:54.691] iteration 3998 : loss : 0.105049, loss_ce: 0.043176
[00:38:54.991] iteration 3999 : loss : 0.172879, loss_ce: 0.016516
[00:38:55.304] iteration 4000 : loss : 0.098662, loss_ce: 0.036324
[00:38:55.655] iteration 4001 : loss : 0.162423, loss_ce: 0.046596
[00:38:55.959] iteration 4002 : loss : 0.149996, loss_ce: 0.008778
[00:38:56.268] iteration 4003 : loss : 0.125149, loss_ce: 0.033104
[00:38:56.570] iteration 4004 : loss : 0.136874, loss_ce: 0.017626
[00:38:56.872] iteration 4005 : loss : 0.111653, loss_ce: 0.035633
[00:38:57.176] iteration 4006 : loss : 0.081713, loss_ce: 0.020673
[00:38:57.476] iteration 4007 : loss : 0.125247, loss_ce: 0.036258
[00:38:57.790] iteration 4008 : loss : 0.091513, loss_ce: 0.026391
[00:38:58.088] iteration 4009 : loss : 0.101244, loss_ce: 0.037367
[00:38:58.397] iteration 4010 : loss : 0.129342, loss_ce: 0.030681
[00:38:58.706] iteration 4011 : loss : 0.198902, loss_ce: 0.011586
[00:38:59.010] iteration 4012 : loss : 0.092883, loss_ce: 0.018627
[00:38:59.308] iteration 4013 : loss : 0.080183, loss_ce: 0.039534
[00:38:59.613] iteration 4014 : loss : 0.085730, loss_ce: 0.043050
[00:38:59.923] iteration 4015 : loss : 0.154743, loss_ce: 0.026600
[00:39:00.240] iteration 4016 : loss : 0.081335, loss_ce: 0.032512
[00:39:00.557] iteration 4017 : loss : 0.152048, loss_ce: 0.014610
[00:39:00.864] iteration 4018 : loss : 0.078640, loss_ce: 0.023367
[00:39:01.179] iteration 4019 : loss : 0.088102, loss_ce: 0.028923
[00:39:01.482] iteration 4020 : loss : 0.061157, loss_ce: 0.015222
[00:39:01.820] iteration 4021 : loss : 0.077611, loss_ce: 0.015538
[00:39:02.125] iteration 4022 : loss : 0.143124, loss_ce: 0.023096
[00:39:02.435] iteration 4023 : loss : 0.086951, loss_ce: 0.018411
[00:39:02.742] iteration 4024 : loss : 0.095164, loss_ce: 0.028561
[00:39:03.050] iteration 4025 : loss : 0.090799, loss_ce: 0.030694
[00:39:03.364] iteration 4026 : loss : 0.075821, loss_ce: 0.025682
[00:39:03.671] iteration 4027 : loss : 0.090899, loss_ce: 0.027477
[00:39:03.985] iteration 4028 : loss : 0.120816, loss_ce: 0.012944
[00:39:04.288] iteration 4029 : loss : 0.146515, loss_ce: 0.016362
[00:39:04.590] iteration 4030 : loss : 0.090390, loss_ce: 0.025630
[00:39:04.675] iteration 4031 : loss : 0.505271, loss_ce: 0.005446
[00:39:22.081] iteration 4032 : loss : 0.148574, loss_ce: 0.019881
[00:39:22.393] iteration 4033 : loss : 0.098744, loss_ce: 0.035313
[00:39:22.699] iteration 4034 : loss : 0.123193, loss_ce: 0.035720
[00:39:23.006] iteration 4035 : loss : 0.143885, loss_ce: 0.028286
[00:39:23.320] iteration 4036 : loss : 0.082326, loss_ce: 0.024539
[00:39:23.625] iteration 4037 : loss : 0.079598, loss_ce: 0.027873
[00:39:23.931] iteration 4038 : loss : 0.111916, loss_ce: 0.023394
[00:39:24.237] iteration 4039 : loss : 0.118259, loss_ce: 0.028004
[00:39:24.553] iteration 4040 : loss : 0.076011, loss_ce: 0.018448
[00:39:24.878] iteration 4041 : loss : 0.178413, loss_ce: 0.023517
[00:39:25.183] iteration 4042 : loss : 0.126222, loss_ce: 0.012140
[00:39:25.490] iteration 4043 : loss : 0.088172, loss_ce: 0.035357
[00:39:25.799] iteration 4044 : loss : 0.096338, loss_ce: 0.027827
[00:39:26.106] iteration 4045 : loss : 0.078208, loss_ce: 0.017836
[00:39:26.411] iteration 4046 : loss : 0.086502, loss_ce: 0.022250
[00:39:26.714] iteration 4047 : loss : 0.080332, loss_ce: 0.042091
[00:39:27.029] iteration 4048 : loss : 0.144929, loss_ce: 0.034140
[00:39:27.337] iteration 4049 : loss : 0.141125, loss_ce: 0.022810
[00:39:27.648] iteration 4050 : loss : 0.109467, loss_ce: 0.026991
[00:39:27.952] iteration 4051 : loss : 0.089880, loss_ce: 0.024807
[00:39:28.256] iteration 4052 : loss : 0.078975, loss_ce: 0.029111
[00:39:28.567] iteration 4053 : loss : 0.084173, loss_ce: 0.009705
[00:39:28.873] iteration 4054 : loss : 0.079694, loss_ce: 0.020549
[00:39:29.189] iteration 4055 : loss : 0.085681, loss_ce: 0.021442
[00:39:29.491] iteration 4056 : loss : 0.122691, loss_ce: 0.021076
[00:39:29.806] iteration 4057 : loss : 0.096591, loss_ce: 0.023747
[00:39:30.112] iteration 4058 : loss : 0.082757, loss_ce: 0.030220
[00:39:30.421] iteration 4059 : loss : 0.079071, loss_ce: 0.017566
[00:39:30.728] iteration 4060 : loss : 0.083011, loss_ce: 0.032897
[00:39:31.059] iteration 4061 : loss : 0.127325, loss_ce: 0.029280
[00:39:31.360] iteration 4062 : loss : 0.075064, loss_ce: 0.030250
[00:39:31.668] iteration 4063 : loss : 0.094013, loss_ce: 0.033491
[00:39:31.970] iteration 4064 : loss : 0.088350, loss_ce: 0.014741
[00:39:32.286] iteration 4065 : loss : 0.073807, loss_ce: 0.021972
[00:39:32.591] iteration 4066 : loss : 0.060859, loss_ce: 0.013073
[00:39:32.896] iteration 4067 : loss : 0.134195, loss_ce: 0.022064
[00:39:33.206] iteration 4068 : loss : 0.082985, loss_ce: 0.028363
[00:39:33.519] iteration 4069 : loss : 0.083146, loss_ce: 0.025608
[00:39:33.824] iteration 4070 : loss : 0.074721, loss_ce: 0.023458
[00:39:34.133] iteration 4071 : loss : 0.103840, loss_ce: 0.027864
[00:39:34.441] iteration 4072 : loss : 0.151947, loss_ce: 0.038343
[00:39:34.743] iteration 4073 : loss : 0.082034, loss_ce: 0.022313
[00:39:35.057] iteration 4074 : loss : 0.085279, loss_ce: 0.018501
[00:39:35.361] iteration 4075 : loss : 0.133066, loss_ce: 0.019601
[00:39:35.662] iteration 4076 : loss : 0.076737, loss_ce: 0.025293
[00:39:35.971] iteration 4077 : loss : 0.125652, loss_ce: 0.012687
[00:39:36.275] iteration 4078 : loss : 0.167681, loss_ce: 0.008756
[00:39:36.582] iteration 4079 : loss : 0.099081, loss_ce: 0.037240
[00:39:36.888] iteration 4080 : loss : 0.058035, loss_ce: 0.021250
[00:39:37.220] iteration 4081 : loss : 0.071451, loss_ce: 0.027027
[00:39:37.525] iteration 4082 : loss : 0.087275, loss_ce: 0.026314
[00:39:37.842] iteration 4083 : loss : 0.082631, loss_ce: 0.025314
[00:39:38.139] iteration 4084 : loss : 0.120029, loss_ce: 0.016745
[00:39:38.457] iteration 4085 : loss : 0.082059, loss_ce: 0.026542
[00:39:38.768] iteration 4086 : loss : 0.084079, loss_ce: 0.023339
[00:39:39.074] iteration 4087 : loss : 0.085067, loss_ce: 0.027319
[00:39:39.375] iteration 4088 : loss : 0.122691, loss_ce: 0.026331
[00:39:39.684] iteration 4089 : loss : 0.064800, loss_ce: 0.008295
[00:39:39.994] iteration 4090 : loss : 0.081222, loss_ce: 0.043967
[00:39:40.302] iteration 4091 : loss : 0.144311, loss_ce: 0.034081
[00:39:40.612] iteration 4092 : loss : 0.102308, loss_ce: 0.021350
[00:39:40.914] iteration 4093 : loss : 0.141148, loss_ce: 0.016441
[00:39:41.233] iteration 4094 : loss : 0.084755, loss_ce: 0.028880
[00:39:41.532] iteration 4095 : loss : 0.092831, loss_ce: 0.023031
[00:39:41.838] iteration 4096 : loss : 0.155382, loss_ce: 0.023632
[00:39:42.147] iteration 4097 : loss : 0.089557, loss_ce: 0.025656
[00:39:42.462] iteration 4098 : loss : 0.065024, loss_ce: 0.015563
[00:39:42.778] iteration 4099 : loss : 0.062153, loss_ce: 0.025733
[00:39:43.085] iteration 4100 : loss : 0.073451, loss_ce: 0.026869
[00:39:43.420] iteration 4101 : loss : 0.118819, loss_ce: 0.024670
[00:39:43.727] iteration 4102 : loss : 0.117791, loss_ce: 0.024792
[00:39:44.029] iteration 4103 : loss : 0.094197, loss_ce: 0.035876
[00:39:44.340] iteration 4104 : loss : 0.124260, loss_ce: 0.025269
[00:39:44.648] iteration 4105 : loss : 0.171149, loss_ce: 0.018712
[00:39:44.952] iteration 4106 : loss : 0.079521, loss_ce: 0.020090
[00:39:45.260] iteration 4107 : loss : 0.087784, loss_ce: 0.030813
[00:39:45.564] iteration 4108 : loss : 0.090480, loss_ce: 0.040688
[00:39:45.872] iteration 4109 : loss : 0.086722, loss_ce: 0.018059
[00:39:46.177] iteration 4110 : loss : 0.082675, loss_ce: 0.025676
[00:39:46.479] iteration 4111 : loss : 0.106191, loss_ce: 0.015716
[00:39:46.785] iteration 4112 : loss : 0.251732, loss_ce: 0.005251
[00:39:47.091] iteration 4113 : loss : 0.072828, loss_ce: 0.021720
[00:39:47.402] iteration 4114 : loss : 0.058635, loss_ce: 0.013364
[00:39:47.709] iteration 4115 : loss : 0.092079, loss_ce: 0.036395
[00:39:48.013] iteration 4116 : loss : 0.091802, loss_ce: 0.009896
[00:39:48.316] iteration 4117 : loss : 0.064190, loss_ce: 0.022880
[00:39:48.625] iteration 4118 : loss : 0.068188, loss_ce: 0.023576
[00:39:48.928] iteration 4119 : loss : 0.142075, loss_ce: 0.017831
[00:39:49.236] iteration 4120 : loss : 0.139187, loss_ce: 0.013617
[00:39:49.558] iteration 4121 : loss : 0.062484, loss_ce: 0.011808
[00:39:49.868] iteration 4122 : loss : 0.092185, loss_ce: 0.034355
[00:39:50.175] iteration 4123 : loss : 0.072185, loss_ce: 0.026760
[00:39:50.480] iteration 4124 : loss : 0.068546, loss_ce: 0.022781
[00:39:50.792] iteration 4125 : loss : 0.077247, loss_ce: 0.025950
[00:39:51.096] iteration 4126 : loss : 0.077515, loss_ce: 0.015833
[00:39:51.402] iteration 4127 : loss : 0.152841, loss_ce: 0.016049
[00:39:51.708] iteration 4128 : loss : 0.077733, loss_ce: 0.028082
[00:39:52.012] iteration 4129 : loss : 0.228099, loss_ce: 0.018147
[00:39:52.316] iteration 4130 : loss : 0.072825, loss_ce: 0.015697
[00:39:52.623] iteration 4131 : loss : 0.068901, loss_ce: 0.022510
[00:39:52.932] iteration 4132 : loss : 0.076416, loss_ce: 0.035052
[00:39:53.234] iteration 4133 : loss : 0.117932, loss_ce: 0.030332
[00:39:53.536] iteration 4134 : loss : 0.130657, loss_ce: 0.023286
[00:39:53.843] iteration 4135 : loss : 0.072321, loss_ce: 0.012474
[00:39:54.152] iteration 4136 : loss : 0.098882, loss_ce: 0.019495
[00:39:54.464] iteration 4137 : loss : 0.071195, loss_ce: 0.016966
[00:39:54.771] iteration 4138 : loss : 0.082470, loss_ce: 0.043256
[00:39:55.084] iteration 4139 : loss : 0.138902, loss_ce: 0.029943
[00:39:55.384] iteration 4140 : loss : 0.123253, loss_ce: 0.027906
[00:39:55.698] iteration 4141 : loss : 0.146755, loss_ce: 0.014453
[00:39:55.999] iteration 4142 : loss : 0.089398, loss_ce: 0.026041
[00:39:56.303] iteration 4143 : loss : 0.086170, loss_ce: 0.029229
[00:39:56.605] iteration 4144 : loss : 0.063475, loss_ce: 0.017113
[00:39:56.918] iteration 4145 : loss : 0.080697, loss_ce: 0.015885
[00:39:57.225] iteration 4146 : loss : 0.131900, loss_ce: 0.022918
[00:39:57.536] iteration 4147 : loss : 0.091648, loss_ce: 0.039868
[00:39:57.846] iteration 4148 : loss : 0.096803, loss_ce: 0.021436
[00:39:58.150] iteration 4149 : loss : 0.111646, loss_ce: 0.024823
[00:39:58.453] iteration 4150 : loss : 0.087788, loss_ce: 0.031156
[00:39:58.756] iteration 4151 : loss : 0.087021, loss_ce: 0.027760
[00:39:59.064] iteration 4152 : loss : 0.064615, loss_ce: 0.021649
[00:39:59.373] iteration 4153 : loss : 0.095622, loss_ce: 0.018331
[00:39:59.687] iteration 4154 : loss : 0.075412, loss_ce: 0.016135
[00:39:59.987] iteration 4155 : loss : 0.075823, loss_ce: 0.029699
[00:40:00.310] iteration 4156 : loss : 0.081496, loss_ce: 0.040655
[00:40:00.632] iteration 4157 : loss : 0.098695, loss_ce: 0.031191
[00:40:00.939] iteration 4158 : loss : 0.105006, loss_ce: 0.028838
[00:40:01.259] iteration 4159 : loss : 0.101521, loss_ce: 0.018247
[00:40:01.566] iteration 4160 : loss : 0.132026, loss_ce: 0.026991
[00:40:01.894] iteration 4161 : loss : 0.097870, loss_ce: 0.020954
[00:40:02.209] iteration 4162 : loss : 0.081175, loss_ce: 0.016344
[00:40:02.515] iteration 4163 : loss : 0.083147, loss_ce: 0.029187
[00:40:02.822] iteration 4164 : loss : 0.088795, loss_ce: 0.028607
[00:40:03.131] iteration 4165 : loss : 0.177764, loss_ce: 0.016562
[00:40:03.449] iteration 4166 : loss : 0.118460, loss_ce: 0.020732
[00:40:03.759] iteration 4167 : loss : 0.221081, loss_ce: 0.008710
[00:40:04.072] iteration 4168 : loss : 0.088860, loss_ce: 0.021734
[00:40:04.378] iteration 4169 : loss : 0.074574, loss_ce: 0.019127
[00:40:04.458] iteration 4170 : loss : 0.346666, loss_ce: 0.013370
[00:40:23.555] iteration 4171 : loss : 0.140416, loss_ce: 0.020938
[00:40:23.860] iteration 4172 : loss : 0.183872, loss_ce: 0.016459
[00:40:24.174] iteration 4173 : loss : 0.067477, loss_ce: 0.024653
[00:40:24.479] iteration 4174 : loss : 0.143442, loss_ce: 0.023933
[00:40:24.785] iteration 4175 : loss : 0.120732, loss_ce: 0.015113
[00:40:25.087] iteration 4176 : loss : 0.075771, loss_ce: 0.014271
[00:40:25.393] iteration 4177 : loss : 0.091881, loss_ce: 0.035842
[00:40:25.700] iteration 4178 : loss : 0.088018, loss_ce: 0.023882
[00:40:26.003] iteration 4179 : loss : 0.100311, loss_ce: 0.022312
[00:40:26.311] iteration 4180 : loss : 0.092917, loss_ce: 0.024292
[00:40:26.636] iteration 4181 : loss : 0.077903, loss_ce: 0.018386
[00:40:26.935] iteration 4182 : loss : 0.076738, loss_ce: 0.025645
[00:40:27.234] iteration 4183 : loss : 0.163649, loss_ce: 0.021146
[00:40:27.532] iteration 4184 : loss : 0.167457, loss_ce: 0.019209
[00:40:27.834] iteration 4185 : loss : 0.082623, loss_ce: 0.028339
[00:40:28.139] iteration 4186 : loss : 0.067739, loss_ce: 0.031290
[00:40:28.446] iteration 4187 : loss : 0.075606, loss_ce: 0.025600
[00:40:28.749] iteration 4188 : loss : 0.193834, loss_ce: 0.005029
[00:40:29.054] iteration 4189 : loss : 0.106717, loss_ce: 0.024517
[00:40:29.353] iteration 4190 : loss : 0.131162, loss_ce: 0.022345
[00:40:29.653] iteration 4191 : loss : 0.078538, loss_ce: 0.031450
[00:40:29.959] iteration 4192 : loss : 0.125303, loss_ce: 0.010705
[00:40:30.267] iteration 4193 : loss : 0.071655, loss_ce: 0.026176
[00:40:30.575] iteration 4194 : loss : 0.133835, loss_ce: 0.017079
[00:40:30.882] iteration 4195 : loss : 0.123334, loss_ce: 0.024139
[00:40:31.183] iteration 4196 : loss : 0.091006, loss_ce: 0.010258
[00:40:31.492] iteration 4197 : loss : 0.066483, loss_ce: 0.020600
[00:40:31.796] iteration 4198 : loss : 0.147325, loss_ce: 0.016954
[00:40:32.112] iteration 4199 : loss : 0.073988, loss_ce: 0.021626
[00:40:32.414] iteration 4200 : loss : 0.070650, loss_ce: 0.017866
[00:40:32.739] iteration 4201 : loss : 0.071935, loss_ce: 0.037244
[00:40:33.038] iteration 4202 : loss : 0.092375, loss_ce: 0.022962
[00:40:33.346] iteration 4203 : loss : 0.081935, loss_ce: 0.023537
[00:40:33.645] iteration 4204 : loss : 0.120670, loss_ce: 0.017359
[00:40:33.952] iteration 4205 : loss : 0.126363, loss_ce: 0.021950
[00:40:34.260] iteration 4206 : loss : 0.079656, loss_ce: 0.018760
[00:40:34.565] iteration 4207 : loss : 0.164852, loss_ce: 0.014518
[00:40:34.867] iteration 4208 : loss : 0.127314, loss_ce: 0.024212
[00:40:35.163] iteration 4209 : loss : 0.088959, loss_ce: 0.021594
[00:40:35.463] iteration 4210 : loss : 0.088500, loss_ce: 0.024082
[00:40:35.766] iteration 4211 : loss : 0.067909, loss_ce: 0.023709
[00:40:36.070] iteration 4212 : loss : 0.081938, loss_ce: 0.020886
[00:40:36.382] iteration 4213 : loss : 0.143065, loss_ce: 0.024537
[00:40:36.681] iteration 4214 : loss : 0.104918, loss_ce: 0.031594
[00:40:36.993] iteration 4215 : loss : 0.104761, loss_ce: 0.015768
[00:40:37.294] iteration 4216 : loss : 0.070478, loss_ce: 0.011754
[00:40:37.608] iteration 4217 : loss : 0.094380, loss_ce: 0.015585
[00:40:37.912] iteration 4218 : loss : 0.097481, loss_ce: 0.029189
[00:40:38.230] iteration 4219 : loss : 0.074456, loss_ce: 0.021820
[00:40:38.532] iteration 4220 : loss : 0.085114, loss_ce: 0.029561
[00:40:38.850] iteration 4221 : loss : 0.061372, loss_ce: 0.014373
[00:40:39.151] iteration 4222 : loss : 0.100168, loss_ce: 0.026226
[00:40:39.455] iteration 4223 : loss : 0.209230, loss_ce: 0.010267
[00:40:39.754] iteration 4224 : loss : 0.070259, loss_ce: 0.026676
[00:40:40.059] iteration 4225 : loss : 0.142147, loss_ce: 0.010186
[00:40:40.360] iteration 4226 : loss : 0.122020, loss_ce: 0.017841
[00:40:40.664] iteration 4227 : loss : 0.107034, loss_ce: 0.036175
[00:40:40.969] iteration 4228 : loss : 0.083386, loss_ce: 0.022785
[00:40:41.277] iteration 4229 : loss : 0.079748, loss_ce: 0.010013
[00:40:41.581] iteration 4230 : loss : 0.096048, loss_ce: 0.038039
[00:40:41.894] iteration 4231 : loss : 0.110587, loss_ce: 0.021783
[00:40:42.199] iteration 4232 : loss : 0.085425, loss_ce: 0.039556
[00:40:42.504] iteration 4233 : loss : 0.050992, loss_ce: 0.010631
[00:40:42.809] iteration 4234 : loss : 0.125616, loss_ce: 0.030147
[00:40:43.113] iteration 4235 : loss : 0.085958, loss_ce: 0.041509
[00:40:43.419] iteration 4236 : loss : 0.122251, loss_ce: 0.016521
[00:40:43.726] iteration 4237 : loss : 0.089672, loss_ce: 0.024259
[00:40:44.027] iteration 4238 : loss : 0.076273, loss_ce: 0.029626
[00:40:44.331] iteration 4239 : loss : 0.088917, loss_ce: 0.029487
[00:40:44.631] iteration 4240 : loss : 0.088860, loss_ce: 0.039875
[00:40:44.947] iteration 4241 : loss : 0.072173, loss_ce: 0.017368
[00:40:45.254] iteration 4242 : loss : 0.072983, loss_ce: 0.014271
[00:40:45.553] iteration 4243 : loss : 0.128892, loss_ce: 0.028950
[00:40:45.854] iteration 4244 : loss : 0.080028, loss_ce: 0.024314
[00:40:46.159] iteration 4245 : loss : 0.095702, loss_ce: 0.029079
[00:40:46.464] iteration 4246 : loss : 0.086947, loss_ce: 0.029339
[00:40:46.772] iteration 4247 : loss : 0.072411, loss_ce: 0.029929
[00:40:47.080] iteration 4248 : loss : 0.076598, loss_ce: 0.024946
[00:40:47.384] iteration 4249 : loss : 0.068919, loss_ce: 0.024505
[00:40:47.694] iteration 4250 : loss : 0.171927, loss_ce: 0.006227
[00:40:47.996] iteration 4251 : loss : 0.152321, loss_ce: 0.023951
[00:40:48.309] iteration 4252 : loss : 0.120717, loss_ce: 0.018454
[00:40:48.609] iteration 4253 : loss : 0.229084, loss_ce: 0.006650
[00:40:48.925] iteration 4254 : loss : 0.114778, loss_ce: 0.025190
[00:40:49.229] iteration 4255 : loss : 0.102425, loss_ce: 0.024182
[00:40:49.541] iteration 4256 : loss : 0.142929, loss_ce: 0.020209
[00:40:49.847] iteration 4257 : loss : 0.086929, loss_ce: 0.021128
[00:40:50.163] iteration 4258 : loss : 0.097739, loss_ce: 0.029039
[00:40:50.466] iteration 4259 : loss : 0.088954, loss_ce: 0.023086
[00:40:50.782] iteration 4260 : loss : 0.086754, loss_ce: 0.040253
[00:40:51.109] iteration 4261 : loss : 0.136299, loss_ce: 0.025461
[00:40:51.413] iteration 4262 : loss : 0.093187, loss_ce: 0.027671
[00:40:51.719] iteration 4263 : loss : 0.073556, loss_ce: 0.032796
[00:40:52.025] iteration 4264 : loss : 0.173722, loss_ce: 0.017469
[00:40:52.339] iteration 4265 : loss : 0.167897, loss_ce: 0.024950
[00:40:52.645] iteration 4266 : loss : 0.079358, loss_ce: 0.037383
[00:40:52.950] iteration 4267 : loss : 0.073094, loss_ce: 0.025007
[00:40:53.256] iteration 4268 : loss : 0.110173, loss_ce: 0.027559
[00:40:53.569] iteration 4269 : loss : 0.101392, loss_ce: 0.030921
[00:40:53.875] iteration 4270 : loss : 0.087343, loss_ce: 0.032621
[00:40:54.176] iteration 4271 : loss : 0.081810, loss_ce: 0.024023
[00:40:54.496] iteration 4272 : loss : 0.096973, loss_ce: 0.027226
[00:40:54.809] iteration 4273 : loss : 0.180573, loss_ce: 0.013275
[00:40:55.114] iteration 4274 : loss : 0.120917, loss_ce: 0.018386
[00:40:55.419] iteration 4275 : loss : 0.114406, loss_ce: 0.020993
[00:40:55.727] iteration 4276 : loss : 0.083088, loss_ce: 0.030615
[00:40:56.037] iteration 4277 : loss : 0.105978, loss_ce: 0.024976
[00:40:56.347] iteration 4278 : loss : 0.069959, loss_ce: 0.023187
[00:40:56.646] iteration 4279 : loss : 0.100740, loss_ce: 0.041044
[00:40:56.956] iteration 4280 : loss : 0.120497, loss_ce: 0.030383
[00:40:57.290] iteration 4281 : loss : 0.112852, loss_ce: 0.005678
[00:40:57.588] iteration 4282 : loss : 0.091486, loss_ce: 0.024629
[00:40:57.898] iteration 4283 : loss : 0.121990, loss_ce: 0.019208
[00:40:58.204] iteration 4284 : loss : 0.178293, loss_ce: 0.024291
[00:40:58.505] iteration 4285 : loss : 0.122098, loss_ce: 0.031938
[00:40:58.812] iteration 4286 : loss : 0.146136, loss_ce: 0.025903
[00:40:59.112] iteration 4287 : loss : 0.096277, loss_ce: 0.019610
[00:40:59.415] iteration 4288 : loss : 0.130401, loss_ce: 0.014498
[00:40:59.731] iteration 4289 : loss : 0.077395, loss_ce: 0.025044
[00:41:00.037] iteration 4290 : loss : 0.080303, loss_ce: 0.036403
[00:41:00.336] iteration 4291 : loss : 0.070976, loss_ce: 0.020758
[00:41:00.641] iteration 4292 : loss : 0.069141, loss_ce: 0.019659
[00:41:00.956] iteration 4293 : loss : 0.074677, loss_ce: 0.024468
[00:41:01.262] iteration 4294 : loss : 0.079803, loss_ce: 0.027677
[00:41:01.573] iteration 4295 : loss : 0.129378, loss_ce: 0.018332
[00:41:01.883] iteration 4296 : loss : 0.078667, loss_ce: 0.024024
[00:41:02.193] iteration 4297 : loss : 0.089319, loss_ce: 0.033593
[00:41:02.509] iteration 4298 : loss : 0.069309, loss_ce: 0.016224
[00:41:02.809] iteration 4299 : loss : 0.085625, loss_ce: 0.027250
[00:41:03.126] iteration 4300 : loss : 0.139201, loss_ce: 0.030830
[00:41:03.466] iteration 4301 : loss : 0.129034, loss_ce: 0.024072
[00:41:03.780] iteration 4302 : loss : 0.117802, loss_ce: 0.017788
[00:41:04.091] iteration 4303 : loss : 0.124897, loss_ce: 0.020618
[00:41:04.405] iteration 4304 : loss : 0.095642, loss_ce: 0.015389
[00:41:04.722] iteration 4305 : loss : 0.081535, loss_ce: 0.026723
[00:41:05.029] iteration 4306 : loss : 0.163416, loss_ce: 0.022081
[00:41:05.331] iteration 4307 : loss : 0.072710, loss_ce: 0.019175
[00:41:05.648] iteration 4308 : loss : 0.068292, loss_ce: 0.012483
[00:41:05.728] iteration 4309 : loss : 0.310330, loss_ce: 0.036836
[00:41:23.353] iteration 4310 : loss : 0.142544, loss_ce: 0.010543
[00:41:23.658] iteration 4311 : loss : 0.077124, loss_ce: 0.021299
[00:41:23.973] iteration 4312 : loss : 0.105378, loss_ce: 0.028510
[00:41:24.276] iteration 4313 : loss : 0.066999, loss_ce: 0.022621
[00:41:24.580] iteration 4314 : loss : 0.067403, loss_ce: 0.019987
[00:41:24.895] iteration 4315 : loss : 0.140595, loss_ce: 0.018855
[00:41:25.193] iteration 4316 : loss : 0.083654, loss_ce: 0.031467
[00:41:25.499] iteration 4317 : loss : 0.096192, loss_ce: 0.034058
[00:41:25.805] iteration 4318 : loss : 0.110328, loss_ce: 0.012376
[00:41:26.115] iteration 4319 : loss : 0.088884, loss_ce: 0.024360
[00:41:26.414] iteration 4320 : loss : 0.129517, loss_ce: 0.016917
[00:41:26.742] iteration 4321 : loss : 0.134981, loss_ce: 0.016927
[00:41:27.045] iteration 4322 : loss : 0.092505, loss_ce: 0.020300
[00:41:27.359] iteration 4323 : loss : 0.083941, loss_ce: 0.036601
[00:41:27.668] iteration 4324 : loss : 0.141167, loss_ce: 0.015271
[00:41:27.972] iteration 4325 : loss : 0.133715, loss_ce: 0.023296
[00:41:28.280] iteration 4326 : loss : 0.074763, loss_ce: 0.027631
[00:41:28.582] iteration 4327 : loss : 0.069598, loss_ce: 0.020565
[00:41:28.895] iteration 4328 : loss : 0.082494, loss_ce: 0.023426
[00:41:29.202] iteration 4329 : loss : 0.094267, loss_ce: 0.026597
[00:41:29.503] iteration 4330 : loss : 0.143446, loss_ce: 0.077215
[00:41:29.808] iteration 4331 : loss : 0.081133, loss_ce: 0.018495
[00:41:30.125] iteration 4332 : loss : 0.074559, loss_ce: 0.034540
[00:41:30.439] iteration 4333 : loss : 0.135224, loss_ce: 0.018022
[00:41:30.753] iteration 4334 : loss : 0.075145, loss_ce: 0.020033
[00:41:31.053] iteration 4335 : loss : 0.097913, loss_ce: 0.036274
[00:41:31.364] iteration 4336 : loss : 0.086610, loss_ce: 0.030829
[00:41:31.675] iteration 4337 : loss : 0.067736, loss_ce: 0.018567
[00:41:31.990] iteration 4338 : loss : 0.104236, loss_ce: 0.025568
[00:41:32.296] iteration 4339 : loss : 0.137572, loss_ce: 0.031875
[00:41:32.613] iteration 4340 : loss : 0.140535, loss_ce: 0.013536
[00:41:32.932] iteration 4341 : loss : 0.125168, loss_ce: 0.016988
[00:41:33.231] iteration 4342 : loss : 0.107204, loss_ce: 0.031116
[00:41:33.547] iteration 4343 : loss : 0.083968, loss_ce: 0.016518
[00:41:33.849] iteration 4344 : loss : 0.146936, loss_ce: 0.023539
[00:41:34.153] iteration 4345 : loss : 0.075770, loss_ce: 0.021690
[00:41:34.461] iteration 4346 : loss : 0.067629, loss_ce: 0.011879
[00:41:34.768] iteration 4347 : loss : 0.117386, loss_ce: 0.022738
[00:41:35.081] iteration 4348 : loss : 0.082961, loss_ce: 0.024035
[00:41:35.386] iteration 4349 : loss : 0.063940, loss_ce: 0.019981
[00:41:35.698] iteration 4350 : loss : 0.090621, loss_ce: 0.020245
[00:41:36.007] iteration 4351 : loss : 0.109631, loss_ce: 0.021689
[00:41:36.323] iteration 4352 : loss : 0.117674, loss_ce: 0.031476
[00:41:36.635] iteration 4353 : loss : 0.074137, loss_ce: 0.009829
[00:41:36.935] iteration 4354 : loss : 0.083875, loss_ce: 0.035783
[00:41:37.245] iteration 4355 : loss : 0.101010, loss_ce: 0.027215
[00:41:37.548] iteration 4356 : loss : 0.075625, loss_ce: 0.016330
[00:41:37.862] iteration 4357 : loss : 0.081540, loss_ce: 0.026765
[00:41:38.169] iteration 4358 : loss : 0.086011, loss_ce: 0.011278
[00:41:38.472] iteration 4359 : loss : 0.106553, loss_ce: 0.032569
[00:41:38.780] iteration 4360 : loss : 0.064876, loss_ce: 0.015794
[00:41:39.096] iteration 4361 : loss : 0.167777, loss_ce: 0.012078
[00:41:39.398] iteration 4362 : loss : 0.079608, loss_ce: 0.019432
[00:41:39.706] iteration 4363 : loss : 0.119409, loss_ce: 0.021489
[00:41:40.009] iteration 4364 : loss : 0.128594, loss_ce: 0.019427
[00:41:40.318] iteration 4365 : loss : 0.127844, loss_ce: 0.030957
[00:41:40.622] iteration 4366 : loss : 0.093297, loss_ce: 0.025091
[00:41:40.933] iteration 4367 : loss : 0.086305, loss_ce: 0.024663
[00:41:41.235] iteration 4368 : loss : 0.090577, loss_ce: 0.026093
[00:41:41.546] iteration 4369 : loss : 0.109813, loss_ce: 0.007726
[00:41:41.851] iteration 4370 : loss : 0.093535, loss_ce: 0.031735
[00:41:42.159] iteration 4371 : loss : 0.088900, loss_ce: 0.031120
[00:41:42.465] iteration 4372 : loss : 0.097161, loss_ce: 0.030130
[00:41:42.773] iteration 4373 : loss : 0.061087, loss_ce: 0.012952
[00:41:43.086] iteration 4374 : loss : 0.075203, loss_ce: 0.021510
[00:41:43.401] iteration 4375 : loss : 0.062837, loss_ce: 0.015512
[00:41:43.708] iteration 4376 : loss : 0.097524, loss_ce: 0.019095
[00:41:44.012] iteration 4377 : loss : 0.071098, loss_ce: 0.017064
[00:41:44.320] iteration 4378 : loss : 0.121334, loss_ce: 0.013349
[00:41:44.625] iteration 4379 : loss : 0.064145, loss_ce: 0.027285
[00:41:44.933] iteration 4380 : loss : 0.109258, loss_ce: 0.035624
[00:41:45.268] iteration 4381 : loss : 0.132591, loss_ce: 0.020228
[00:41:45.570] iteration 4382 : loss : 0.089178, loss_ce: 0.034282
[00:41:45.869] iteration 4383 : loss : 0.076237, loss_ce: 0.026514
[00:41:46.173] iteration 4384 : loss : 0.139239, loss_ce: 0.024131
[00:41:46.480] iteration 4385 : loss : 0.136997, loss_ce: 0.034040
[00:41:46.782] iteration 4386 : loss : 0.132539, loss_ce: 0.014361
[00:41:47.098] iteration 4387 : loss : 0.065218, loss_ce: 0.017071
[00:41:47.394] iteration 4388 : loss : 0.254987, loss_ce: 0.020643
[00:41:47.702] iteration 4389 : loss : 0.076881, loss_ce: 0.012707
[00:41:48.002] iteration 4390 : loss : 0.145535, loss_ce: 0.025612
[00:41:48.306] iteration 4391 : loss : 0.078744, loss_ce: 0.026456
[00:41:48.611] iteration 4392 : loss : 0.072666, loss_ce: 0.010125
[00:41:48.909] iteration 4393 : loss : 0.090756, loss_ce: 0.031454
[00:41:49.209] iteration 4394 : loss : 0.117981, loss_ce: 0.024946
[00:41:49.516] iteration 4395 : loss : 0.095757, loss_ce: 0.024404
[00:41:49.820] iteration 4396 : loss : 0.188953, loss_ce: 0.013800
[00:41:50.125] iteration 4397 : loss : 0.100529, loss_ce: 0.022903
[00:41:50.425] iteration 4398 : loss : 0.052649, loss_ce: 0.023042
[00:41:50.736] iteration 4399 : loss : 0.064522, loss_ce: 0.016765
[00:41:51.047] iteration 4400 : loss : 0.123768, loss_ce: 0.017981
[00:41:51.377] iteration 4401 : loss : 0.088281, loss_ce: 0.021189
[00:41:51.686] iteration 4402 : loss : 0.218914, loss_ce: 0.018333
[00:41:51.989] iteration 4403 : loss : 0.071933, loss_ce: 0.024985
[00:41:52.295] iteration 4404 : loss : 0.067621, loss_ce: 0.027974
[00:41:52.602] iteration 4405 : loss : 0.157459, loss_ce: 0.029535
[00:41:52.907] iteration 4406 : loss : 0.058139, loss_ce: 0.015743
[00:41:53.211] iteration 4407 : loss : 0.100139, loss_ce: 0.021140
[00:41:53.522] iteration 4408 : loss : 0.083485, loss_ce: 0.028288
[00:41:53.824] iteration 4409 : loss : 0.113928, loss_ce: 0.017804
[00:41:54.131] iteration 4410 : loss : 0.078626, loss_ce: 0.029074
[00:41:54.441] iteration 4411 : loss : 0.153785, loss_ce: 0.016537
[00:41:54.742] iteration 4412 : loss : 0.105144, loss_ce: 0.029238
[00:41:55.057] iteration 4413 : loss : 0.077537, loss_ce: 0.015139
[00:41:55.359] iteration 4414 : loss : 0.174058, loss_ce: 0.023547
[00:41:55.662] iteration 4415 : loss : 0.151608, loss_ce: 0.021773
[00:41:55.963] iteration 4416 : loss : 0.103449, loss_ce: 0.025830
[00:41:56.273] iteration 4417 : loss : 0.078040, loss_ce: 0.018043
[00:41:56.576] iteration 4418 : loss : 0.108609, loss_ce: 0.034610
[00:41:56.895] iteration 4419 : loss : 0.144673, loss_ce: 0.031909
[00:41:57.204] iteration 4420 : loss : 0.109874, loss_ce: 0.017508
[00:41:57.530] iteration 4421 : loss : 0.073093, loss_ce: 0.031961
[00:41:57.828] iteration 4422 : loss : 0.107722, loss_ce: 0.023307
[00:41:58.135] iteration 4423 : loss : 0.070443, loss_ce: 0.018369
[00:41:58.445] iteration 4424 : loss : 0.236572, loss_ce: 0.018436
[00:41:58.746] iteration 4425 : loss : 0.084987, loss_ce: 0.028571
[00:41:59.050] iteration 4426 : loss : 0.103377, loss_ce: 0.022079
[00:41:59.359] iteration 4427 : loss : 0.081050, loss_ce: 0.026339
[00:41:59.665] iteration 4428 : loss : 0.083371, loss_ce: 0.018010
[00:41:59.978] iteration 4429 : loss : 0.081501, loss_ce: 0.022491
[00:42:00.290] iteration 4430 : loss : 0.112407, loss_ce: 0.020513
[00:42:00.593] iteration 4431 : loss : 0.073265, loss_ce: 0.026162
[00:42:00.906] iteration 4432 : loss : 0.090813, loss_ce: 0.044691
[00:42:01.216] iteration 4433 : loss : 0.079717, loss_ce: 0.020553
[00:42:01.536] iteration 4434 : loss : 0.088662, loss_ce: 0.025954
[00:42:01.842] iteration 4435 : loss : 0.123168, loss_ce: 0.015210
[00:42:02.146] iteration 4436 : loss : 0.131735, loss_ce: 0.023929
[00:42:02.451] iteration 4437 : loss : 0.195678, loss_ce: 0.007990
[00:42:02.763] iteration 4438 : loss : 0.117319, loss_ce: 0.023975
[00:42:03.079] iteration 4439 : loss : 0.067786, loss_ce: 0.025220
[00:42:03.387] iteration 4440 : loss : 0.086176, loss_ce: 0.021038
[00:42:03.705] iteration 4441 : loss : 0.114018, loss_ce: 0.027622
[00:42:04.020] iteration 4442 : loss : 0.073994, loss_ce: 0.026032
[00:42:04.340] iteration 4443 : loss : 0.138096, loss_ce: 0.016314
[00:42:04.650] iteration 4444 : loss : 0.116260, loss_ce: 0.022211
[00:42:04.965] iteration 4445 : loss : 0.076018, loss_ce: 0.043101
[00:42:05.267] iteration 4446 : loss : 0.152929, loss_ce: 0.020302
[00:42:05.581] iteration 4447 : loss : 0.083634, loss_ce: 0.022631
[00:42:05.660] iteration 4448 : loss : 0.514716, loss_ce: 0.000237
[00:42:24.702] iteration 4449 : loss : 0.140171, loss_ce: 0.019870
[00:42:25.007] iteration 4450 : loss : 0.059425, loss_ce: 0.009571
[00:42:25.320] iteration 4451 : loss : 0.145300, loss_ce: 0.010317
[00:42:25.641] iteration 4452 : loss : 0.109177, loss_ce: 0.031191
[00:42:25.944] iteration 4453 : loss : 0.095652, loss_ce: 0.037394
[00:42:26.247] iteration 4454 : loss : 0.144048, loss_ce: 0.022128
[00:42:26.549] iteration 4455 : loss : 0.102995, loss_ce: 0.022667
[00:42:26.861] iteration 4456 : loss : 0.085808, loss_ce: 0.029334
[00:42:27.163] iteration 4457 : loss : 0.131077, loss_ce: 0.016070
[00:42:27.465] iteration 4458 : loss : 0.147540, loss_ce: 0.012505
[00:42:27.768] iteration 4459 : loss : 0.072437, loss_ce: 0.014740
[00:42:28.072] iteration 4460 : loss : 0.114792, loss_ce: 0.024972
[00:42:28.394] iteration 4461 : loss : 0.099143, loss_ce: 0.031395
[00:42:28.694] iteration 4462 : loss : 0.149936, loss_ce: 0.024326
[00:42:28.998] iteration 4463 : loss : 0.129685, loss_ce: 0.023537
[00:42:29.307] iteration 4464 : loss : 0.130390, loss_ce: 0.043309
[00:42:29.618] iteration 4465 : loss : 0.088125, loss_ce: 0.029857
[00:42:29.924] iteration 4466 : loss : 0.181011, loss_ce: 0.020186
[00:42:30.240] iteration 4467 : loss : 0.240004, loss_ce: 0.007439
[00:42:30.540] iteration 4468 : loss : 0.095020, loss_ce: 0.032269
[00:42:30.848] iteration 4469 : loss : 0.088816, loss_ce: 0.026734
[00:42:31.153] iteration 4470 : loss : 0.089929, loss_ce: 0.031956
[00:42:31.456] iteration 4471 : loss : 0.087513, loss_ce: 0.037658
[00:42:31.761] iteration 4472 : loss : 0.236408, loss_ce: 0.009760
[00:42:32.066] iteration 4473 : loss : 0.075204, loss_ce: 0.027500
[00:42:32.364] iteration 4474 : loss : 0.085272, loss_ce: 0.021854
[00:42:32.678] iteration 4475 : loss : 0.129817, loss_ce: 0.011217
[00:42:32.977] iteration 4476 : loss : 0.080718, loss_ce: 0.026104
[00:42:33.281] iteration 4477 : loss : 0.062636, loss_ce: 0.014096
[00:42:33.597] iteration 4478 : loss : 0.091483, loss_ce: 0.031538
[00:42:33.907] iteration 4479 : loss : 0.086778, loss_ce: 0.039055
[00:42:34.210] iteration 4480 : loss : 0.141340, loss_ce: 0.023970
[00:42:34.527] iteration 4481 : loss : 0.079092, loss_ce: 0.019627
[00:42:34.833] iteration 4482 : loss : 0.130052, loss_ce: 0.020839
[00:42:35.149] iteration 4483 : loss : 0.071601, loss_ce: 0.024712
[00:42:35.452] iteration 4484 : loss : 0.090310, loss_ce: 0.030009
[00:42:35.754] iteration 4485 : loss : 0.081737, loss_ce: 0.027236
[00:42:36.062] iteration 4486 : loss : 0.072842, loss_ce: 0.020603
[00:42:36.361] iteration 4487 : loss : 0.067031, loss_ce: 0.017888
[00:42:36.662] iteration 4488 : loss : 0.065984, loss_ce: 0.015193
[00:42:36.966] iteration 4489 : loss : 0.160773, loss_ce: 0.015655
[00:42:37.267] iteration 4490 : loss : 0.054970, loss_ce: 0.022100
[00:42:37.570] iteration 4491 : loss : 0.082684, loss_ce: 0.030660
[00:42:37.875] iteration 4492 : loss : 0.084387, loss_ce: 0.022944
[00:42:38.174] iteration 4493 : loss : 0.068460, loss_ce: 0.009723
[00:42:38.485] iteration 4494 : loss : 0.068834, loss_ce: 0.024081
[00:42:38.785] iteration 4495 : loss : 0.077598, loss_ce: 0.034721
[00:42:39.088] iteration 4496 : loss : 0.077670, loss_ce: 0.026651
[00:42:39.401] iteration 4497 : loss : 0.085475, loss_ce: 0.015980
[00:42:39.700] iteration 4498 : loss : 0.091826, loss_ce: 0.041378
[00:42:40.007] iteration 4499 : loss : 0.140506, loss_ce: 0.015042
[00:42:40.310] iteration 4500 : loss : 0.068440, loss_ce: 0.026159
[00:42:40.637] iteration 4501 : loss : 0.072389, loss_ce: 0.042851
[00:42:40.940] iteration 4502 : loss : 0.076210, loss_ce: 0.038155
[00:42:41.248] iteration 4503 : loss : 0.077578, loss_ce: 0.027771
[00:42:41.549] iteration 4504 : loss : 0.176524, loss_ce: 0.010303
[00:42:41.858] iteration 4505 : loss : 0.066721, loss_ce: 0.019188
[00:42:42.167] iteration 4506 : loss : 0.129341, loss_ce: 0.028141
[00:42:42.469] iteration 4507 : loss : 0.077630, loss_ce: 0.031643
[00:42:42.774] iteration 4508 : loss : 0.057005, loss_ce: 0.013506
[00:42:43.078] iteration 4509 : loss : 0.121438, loss_ce: 0.012030
[00:42:43.384] iteration 4510 : loss : 0.111576, loss_ce: 0.045322
[00:42:43.694] iteration 4511 : loss : 0.085492, loss_ce: 0.033999
[00:42:43.997] iteration 4512 : loss : 0.222995, loss_ce: 0.011650
[00:42:44.303] iteration 4513 : loss : 0.130851, loss_ce: 0.030766
[00:42:44.611] iteration 4514 : loss : 0.166867, loss_ce: 0.015472
[00:42:44.921] iteration 4515 : loss : 0.083459, loss_ce: 0.024258
[00:42:45.221] iteration 4516 : loss : 0.071211, loss_ce: 0.026907
[00:42:45.526] iteration 4517 : loss : 0.069532, loss_ce: 0.017127
[00:42:45.827] iteration 4518 : loss : 0.057525, loss_ce: 0.014152
[00:42:46.130] iteration 4519 : loss : 0.083804, loss_ce: 0.022958
[00:42:46.440] iteration 4520 : loss : 0.170915, loss_ce: 0.009142
[00:42:46.758] iteration 4521 : loss : 0.196536, loss_ce: 0.009387
[00:42:47.057] iteration 4522 : loss : 0.130258, loss_ce: 0.012400
[00:42:47.358] iteration 4523 : loss : 0.070728, loss_ce: 0.023965
[00:42:47.673] iteration 4524 : loss : 0.083402, loss_ce: 0.028241
[00:42:47.973] iteration 4525 : loss : 0.075583, loss_ce: 0.028290
[00:42:48.277] iteration 4526 : loss : 0.135153, loss_ce: 0.023347
[00:42:48.590] iteration 4527 : loss : 0.068366, loss_ce: 0.027956
[00:42:48.896] iteration 4528 : loss : 0.078882, loss_ce: 0.015878
[00:42:49.199] iteration 4529 : loss : 0.065051, loss_ce: 0.030920
[00:42:49.507] iteration 4530 : loss : 0.131472, loss_ce: 0.047844
[00:42:49.817] iteration 4531 : loss : 0.222949, loss_ce: 0.009971
[00:42:50.120] iteration 4532 : loss : 0.084941, loss_ce: 0.017964
[00:42:50.427] iteration 4533 : loss : 0.089310, loss_ce: 0.030130
[00:42:50.736] iteration 4534 : loss : 0.121397, loss_ce: 0.008706
[00:42:51.038] iteration 4535 : loss : 0.127477, loss_ce: 0.037488
[00:42:51.348] iteration 4536 : loss : 0.138452, loss_ce: 0.014760
[00:42:51.654] iteration 4537 : loss : 0.088639, loss_ce: 0.017552
[00:42:51.957] iteration 4538 : loss : 0.082452, loss_ce: 0.020033
[00:42:52.261] iteration 4539 : loss : 0.203112, loss_ce: 0.008084
[00:42:52.564] iteration 4540 : loss : 0.103592, loss_ce: 0.024204
[00:42:52.897] iteration 4541 : loss : 0.073904, loss_ce: 0.026302
[00:42:53.199] iteration 4542 : loss : 0.096129, loss_ce: 0.024599
[00:42:53.511] iteration 4543 : loss : 0.141364, loss_ce: 0.014212
[00:42:53.818] iteration 4544 : loss : 0.081205, loss_ce: 0.024385
[00:42:54.121] iteration 4545 : loss : 0.073589, loss_ce: 0.019721
[00:42:54.428] iteration 4546 : loss : 0.078118, loss_ce: 0.017708
[00:42:54.727] iteration 4547 : loss : 0.083894, loss_ce: 0.022632
[00:42:55.041] iteration 4548 : loss : 0.083186, loss_ce: 0.036138
[00:42:55.349] iteration 4549 : loss : 0.075864, loss_ce: 0.016062
[00:42:55.651] iteration 4550 : loss : 0.076562, loss_ce: 0.018363
[00:42:55.963] iteration 4551 : loss : 0.077496, loss_ce: 0.020337
[00:42:56.261] iteration 4552 : loss : 0.089580, loss_ce: 0.025640
[00:42:56.565] iteration 4553 : loss : 0.120959, loss_ce: 0.020122
[00:42:56.868] iteration 4554 : loss : 0.090457, loss_ce: 0.018070
[00:42:57.176] iteration 4555 : loss : 0.087158, loss_ce: 0.036149
[00:42:57.481] iteration 4556 : loss : 0.102377, loss_ce: 0.036940
[00:42:57.787] iteration 4557 : loss : 0.149535, loss_ce: 0.013536
[00:42:58.086] iteration 4558 : loss : 0.073897, loss_ce: 0.018706
[00:42:58.395] iteration 4559 : loss : 0.067170, loss_ce: 0.024127
[00:42:58.701] iteration 4560 : loss : 0.085813, loss_ce: 0.016023
[00:42:59.030] iteration 4561 : loss : 0.092391, loss_ce: 0.024123
[00:42:59.334] iteration 4562 : loss : 0.135131, loss_ce: 0.024818
[00:42:59.639] iteration 4563 : loss : 0.070242, loss_ce: 0.021152
[00:42:59.944] iteration 4564 : loss : 0.081400, loss_ce: 0.015122
[00:43:00.258] iteration 4565 : loss : 0.163145, loss_ce: 0.012667
[00:43:00.557] iteration 4566 : loss : 0.166980, loss_ce: 0.030028
[00:43:00.873] iteration 4567 : loss : 0.155832, loss_ce: 0.015109
[00:43:01.184] iteration 4568 : loss : 0.076467, loss_ce: 0.017481
[00:43:01.489] iteration 4569 : loss : 0.093014, loss_ce: 0.025396
[00:43:01.792] iteration 4570 : loss : 0.084037, loss_ce: 0.037619
[00:43:02.110] iteration 4571 : loss : 0.084398, loss_ce: 0.028525
[00:43:02.427] iteration 4572 : loss : 0.068437, loss_ce: 0.019551
[00:43:02.734] iteration 4573 : loss : 0.085958, loss_ce: 0.029990
[00:43:03.052] iteration 4574 : loss : 0.066184, loss_ce: 0.028994
[00:43:03.365] iteration 4575 : loss : 0.090182, loss_ce: 0.039296
[00:43:03.668] iteration 4576 : loss : 0.134659, loss_ce: 0.022823
[00:43:03.989] iteration 4577 : loss : 0.102687, loss_ce: 0.025706
[00:43:04.299] iteration 4578 : loss : 0.073792, loss_ce: 0.029454
[00:43:04.606] iteration 4579 : loss : 0.088242, loss_ce: 0.027274
[00:43:04.911] iteration 4580 : loss : 0.119994, loss_ce: 0.015600
[00:43:05.251] iteration 4581 : loss : 0.104392, loss_ce: 0.019618
[00:43:05.560] iteration 4582 : loss : 0.096364, loss_ce: 0.022665
[00:43:05.873] iteration 4583 : loss : 0.092172, loss_ce: 0.030103
[00:43:06.179] iteration 4584 : loss : 0.104976, loss_ce: 0.027033
[00:43:06.497] iteration 4585 : loss : 0.066433, loss_ce: 0.018931
[00:43:06.806] iteration 4586 : loss : 0.087482, loss_ce: 0.027965
[00:43:06.891] iteration 4587 : loss : 0.127699, loss_ce: 0.017277
[00:43:24.486] iteration 4588 : loss : 0.067311, loss_ce: 0.023803
[00:43:24.793] iteration 4589 : loss : 0.144061, loss_ce: 0.018105
[00:43:25.106] iteration 4590 : loss : 0.197463, loss_ce: 0.036959
[00:43:25.425] iteration 4591 : loss : 0.066958, loss_ce: 0.028203
[00:43:25.744] iteration 4592 : loss : 0.082568, loss_ce: 0.023249
[00:43:26.056] iteration 4593 : loss : 0.232670, loss_ce: 0.010886
[00:43:26.372] iteration 4594 : loss : 0.080174, loss_ce: 0.031280
[00:43:26.686] iteration 4595 : loss : 0.122750, loss_ce: 0.020158
[00:43:26.993] iteration 4596 : loss : 0.083196, loss_ce: 0.032625
[00:43:27.296] iteration 4597 : loss : 0.136965, loss_ce: 0.016161
[00:43:27.607] iteration 4598 : loss : 0.078539, loss_ce: 0.022341
[00:43:27.919] iteration 4599 : loss : 0.090887, loss_ce: 0.045290
[00:43:28.222] iteration 4600 : loss : 0.086749, loss_ce: 0.020398
[00:43:28.549] iteration 4601 : loss : 0.153469, loss_ce: 0.022844
[00:43:28.865] iteration 4602 : loss : 0.085656, loss_ce: 0.013932
[00:43:29.172] iteration 4603 : loss : 0.069787, loss_ce: 0.023678
[00:43:29.474] iteration 4604 : loss : 0.137767, loss_ce: 0.022330
[00:43:29.783] iteration 4605 : loss : 0.077209, loss_ce: 0.021068
[00:43:30.089] iteration 4606 : loss : 0.092321, loss_ce: 0.023921
[00:43:30.400] iteration 4607 : loss : 0.059883, loss_ce: 0.019019
[00:43:30.700] iteration 4608 : loss : 0.068697, loss_ce: 0.018680
[00:43:31.008] iteration 4609 : loss : 0.068627, loss_ce: 0.026214
[00:43:31.313] iteration 4610 : loss : 0.082252, loss_ce: 0.023455
[00:43:31.622] iteration 4611 : loss : 0.065810, loss_ce: 0.024092
[00:43:31.935] iteration 4612 : loss : 0.129565, loss_ce: 0.017566
[00:43:32.243] iteration 4613 : loss : 0.101322, loss_ce: 0.038364
[00:43:32.544] iteration 4614 : loss : 0.163309, loss_ce: 0.012778
[00:43:32.854] iteration 4615 : loss : 0.156147, loss_ce: 0.044735
[00:43:33.159] iteration 4616 : loss : 0.075580, loss_ce: 0.032638
[00:43:33.466] iteration 4617 : loss : 0.097757, loss_ce: 0.021259
[00:43:33.774] iteration 4618 : loss : 0.135774, loss_ce: 0.017729
[00:43:34.079] iteration 4619 : loss : 0.077634, loss_ce: 0.019618
[00:43:34.385] iteration 4620 : loss : 0.062993, loss_ce: 0.023702
[00:43:34.708] iteration 4621 : loss : 0.105499, loss_ce: 0.018576
[00:43:35.007] iteration 4622 : loss : 0.097659, loss_ce: 0.014977
[00:43:35.325] iteration 4623 : loss : 0.080583, loss_ce: 0.021177
[00:43:35.632] iteration 4624 : loss : 0.134574, loss_ce: 0.017834
[00:43:35.932] iteration 4625 : loss : 0.085497, loss_ce: 0.024686
[00:43:36.239] iteration 4626 : loss : 0.078850, loss_ce: 0.016662
[00:43:36.556] iteration 4627 : loss : 0.096457, loss_ce: 0.011877
[00:43:36.869] iteration 4628 : loss : 0.082460, loss_ce: 0.028768
[00:43:37.175] iteration 4629 : loss : 0.079773, loss_ce: 0.012351
[00:43:37.480] iteration 4630 : loss : 0.109800, loss_ce: 0.025469
[00:43:37.793] iteration 4631 : loss : 0.097837, loss_ce: 0.011792
[00:43:38.100] iteration 4632 : loss : 0.074615, loss_ce: 0.030822
[00:43:38.407] iteration 4633 : loss : 0.121969, loss_ce: 0.024906
[00:43:38.713] iteration 4634 : loss : 0.093840, loss_ce: 0.020806
[00:43:39.015] iteration 4635 : loss : 0.065340, loss_ce: 0.020729
[00:43:39.327] iteration 4636 : loss : 0.112565, loss_ce: 0.023163
[00:43:39.634] iteration 4637 : loss : 0.062150, loss_ce: 0.022612
[00:43:39.944] iteration 4638 : loss : 0.076410, loss_ce: 0.019005
[00:43:40.252] iteration 4639 : loss : 0.067871, loss_ce: 0.021348
[00:43:40.560] iteration 4640 : loss : 0.168128, loss_ce: 0.020344
[00:43:40.889] iteration 4641 : loss : 0.214387, loss_ce: 0.016294
[00:43:41.196] iteration 4642 : loss : 0.103973, loss_ce: 0.035914
[00:43:41.512] iteration 4643 : loss : 0.093351, loss_ce: 0.038226
[00:43:41.823] iteration 4644 : loss : 0.181291, loss_ce: 0.010261
[00:43:42.129] iteration 4645 : loss : 0.137135, loss_ce: 0.031819
[00:43:42.436] iteration 4646 : loss : 0.167985, loss_ce: 0.003865
[00:43:42.742] iteration 4647 : loss : 0.096518, loss_ce: 0.027256
[00:43:43.051] iteration 4648 : loss : 0.075173, loss_ce: 0.026206
[00:43:43.362] iteration 4649 : loss : 0.098857, loss_ce: 0.029789
[00:43:43.669] iteration 4650 : loss : 0.077596, loss_ce: 0.026813
[00:43:43.974] iteration 4651 : loss : 0.077717, loss_ce: 0.018699
[00:43:44.281] iteration 4652 : loss : 0.073113, loss_ce: 0.017682
[00:43:44.590] iteration 4653 : loss : 0.135141, loss_ce: 0.019194
[00:43:44.898] iteration 4654 : loss : 0.082278, loss_ce: 0.028699
[00:43:45.213] iteration 4655 : loss : 0.078822, loss_ce: 0.023484
[00:43:45.513] iteration 4656 : loss : 0.087639, loss_ce: 0.026905
[00:43:45.827] iteration 4657 : loss : 0.058033, loss_ce: 0.023303
[00:43:46.135] iteration 4658 : loss : 0.081219, loss_ce: 0.019098
[00:43:46.437] iteration 4659 : loss : 0.120892, loss_ce: 0.020318
[00:43:46.744] iteration 4660 : loss : 0.090719, loss_ce: 0.038818
[00:43:47.071] iteration 4661 : loss : 0.075896, loss_ce: 0.023417
[00:43:47.372] iteration 4662 : loss : 0.073894, loss_ce: 0.030974
[00:43:47.675] iteration 4663 : loss : 0.066811, loss_ce: 0.024540
[00:43:47.985] iteration 4664 : loss : 0.072722, loss_ce: 0.021329
[00:43:48.288] iteration 4665 : loss : 0.130452, loss_ce: 0.020381
[00:43:48.599] iteration 4666 : loss : 0.069770, loss_ce: 0.027221
[00:43:48.904] iteration 4667 : loss : 0.078814, loss_ce: 0.018366
[00:43:49.216] iteration 4668 : loss : 0.101991, loss_ce: 0.027568
[00:43:49.517] iteration 4669 : loss : 0.078869, loss_ce: 0.011222
[00:43:49.823] iteration 4670 : loss : 0.147203, loss_ce: 0.009375
[00:43:50.125] iteration 4671 : loss : 0.122780, loss_ce: 0.013711
[00:43:50.431] iteration 4672 : loss : 0.075068, loss_ce: 0.022266
[00:43:50.738] iteration 4673 : loss : 0.068606, loss_ce: 0.019019
[00:43:51.044] iteration 4674 : loss : 0.074318, loss_ce: 0.025900
[00:43:51.356] iteration 4675 : loss : 0.075001, loss_ce: 0.015143
[00:43:51.659] iteration 4676 : loss : 0.070313, loss_ce: 0.018041
[00:43:51.962] iteration 4677 : loss : 0.057577, loss_ce: 0.011276
[00:43:52.274] iteration 4678 : loss : 0.086621, loss_ce: 0.013091
[00:43:52.574] iteration 4679 : loss : 0.143779, loss_ce: 0.021749
[00:43:52.882] iteration 4680 : loss : 0.091506, loss_ce: 0.014206
[00:43:53.205] iteration 4681 : loss : 0.080782, loss_ce: 0.023586
[00:43:53.505] iteration 4682 : loss : 0.127258, loss_ce: 0.010121
[00:43:53.812] iteration 4683 : loss : 0.079599, loss_ce: 0.029803
[00:43:54.121] iteration 4684 : loss : 0.065796, loss_ce: 0.016025
[00:43:54.425] iteration 4685 : loss : 0.122002, loss_ce: 0.013665
[00:43:54.741] iteration 4686 : loss : 0.080605, loss_ce: 0.031289
[00:43:55.053] iteration 4687 : loss : 0.088886, loss_ce: 0.034580
[00:43:55.357] iteration 4688 : loss : 0.074637, loss_ce: 0.030351
[00:43:55.669] iteration 4689 : loss : 0.085360, loss_ce: 0.021673
[00:43:55.971] iteration 4690 : loss : 0.132578, loss_ce: 0.016338
[00:43:56.272] iteration 4691 : loss : 0.088289, loss_ce: 0.026242
[00:43:56.581] iteration 4692 : loss : 0.080882, loss_ce: 0.033226
[00:43:56.882] iteration 4693 : loss : 0.112483, loss_ce: 0.018038
[00:43:57.183] iteration 4694 : loss : 0.061776, loss_ce: 0.017263
[00:43:57.496] iteration 4695 : loss : 0.157918, loss_ce: 0.012884
[00:43:57.803] iteration 4696 : loss : 0.061895, loss_ce: 0.014456
[00:43:58.101] iteration 4697 : loss : 0.067102, loss_ce: 0.019251
[00:43:58.409] iteration 4698 : loss : 0.189696, loss_ce: 0.019993
[00:43:58.722] iteration 4699 : loss : 0.112914, loss_ce: 0.015084
[00:43:59.033] iteration 4700 : loss : 0.174212, loss_ce: 0.014652
[00:43:59.351] iteration 4701 : loss : 0.073925, loss_ce: 0.029686
[00:43:59.654] iteration 4702 : loss : 0.070752, loss_ce: 0.022006
[00:43:59.956] iteration 4703 : loss : 0.082387, loss_ce: 0.038532
[00:44:00.261] iteration 4704 : loss : 0.087546, loss_ce: 0.030265
[00:44:00.561] iteration 4705 : loss : 0.092235, loss_ce: 0.048949
[00:44:00.867] iteration 4706 : loss : 0.084244, loss_ce: 0.032741
[00:44:01.170] iteration 4707 : loss : 0.078925, loss_ce: 0.027034
[00:44:01.481] iteration 4708 : loss : 0.097595, loss_ce: 0.034834
[00:44:01.784] iteration 4709 : loss : 0.082446, loss_ce: 0.020915
[00:44:02.092] iteration 4710 : loss : 0.084721, loss_ce: 0.018829
[00:44:02.410] iteration 4711 : loss : 0.100668, loss_ce: 0.017473
[00:44:02.716] iteration 4712 : loss : 0.063562, loss_ce: 0.027968
[00:44:03.020] iteration 4713 : loss : 0.102383, loss_ce: 0.023178
[00:44:03.336] iteration 4714 : loss : 0.055097, loss_ce: 0.020402
[00:44:03.647] iteration 4715 : loss : 0.082132, loss_ce: 0.042182
[00:44:03.950] iteration 4716 : loss : 0.151609, loss_ce: 0.026261
[00:44:04.264] iteration 4717 : loss : 0.113872, loss_ce: 0.025739
[00:44:04.572] iteration 4718 : loss : 0.085876, loss_ce: 0.033701
[00:44:04.875] iteration 4719 : loss : 0.076070, loss_ce: 0.012794
[00:44:05.192] iteration 4720 : loss : 0.081489, loss_ce: 0.027628
[00:44:05.516] iteration 4721 : loss : 0.132506, loss_ce: 0.021660
[00:44:05.821] iteration 4722 : loss : 0.089974, loss_ce: 0.034789
[00:44:06.121] iteration 4723 : loss : 0.126658, loss_ce: 0.014819
[00:44:06.439] iteration 4724 : loss : 0.085140, loss_ce: 0.021878
[00:44:06.745] iteration 4725 : loss : 0.134700, loss_ce: 0.010612
[00:44:06.827] iteration 4726 : loss : 0.160378, loss_ce: 0.049380
[00:44:26.044] iteration 4727 : loss : 0.118384, loss_ce: 0.013522
[00:44:26.352] iteration 4728 : loss : 0.079907, loss_ce: 0.022279
[00:44:26.664] iteration 4729 : loss : 0.100749, loss_ce: 0.021555
[00:44:26.974] iteration 4730 : loss : 0.130434, loss_ce: 0.009860
[00:44:27.277] iteration 4731 : loss : 0.068321, loss_ce: 0.012482
[00:44:27.577] iteration 4732 : loss : 0.082438, loss_ce: 0.010987
[00:44:27.887] iteration 4733 : loss : 0.079617, loss_ce: 0.033055
[00:44:28.184] iteration 4734 : loss : 0.067798, loss_ce: 0.011289
[00:44:28.488] iteration 4735 : loss : 0.092949, loss_ce: 0.014263
[00:44:28.792] iteration 4736 : loss : 0.079997, loss_ce: 0.021623
[00:44:29.103] iteration 4737 : loss : 0.077005, loss_ce: 0.022572
[00:44:29.413] iteration 4738 : loss : 0.071893, loss_ce: 0.029248
[00:44:29.720] iteration 4739 : loss : 0.065787, loss_ce: 0.025648
[00:44:30.022] iteration 4740 : loss : 0.109268, loss_ce: 0.023436
[00:44:30.348] iteration 4741 : loss : 0.081986, loss_ce: 0.023549
[00:44:30.653] iteration 4742 : loss : 0.076978, loss_ce: 0.032852
[00:44:30.956] iteration 4743 : loss : 0.072112, loss_ce: 0.018874
[00:44:31.263] iteration 4744 : loss : 0.089656, loss_ce: 0.031070
[00:44:31.580] iteration 4745 : loss : 0.103538, loss_ce: 0.035542
[00:44:31.887] iteration 4746 : loss : 0.077883, loss_ce: 0.032113
[00:44:32.193] iteration 4747 : loss : 0.170665, loss_ce: 0.016957
[00:44:32.495] iteration 4748 : loss : 0.068047, loss_ce: 0.026454
[00:44:32.802] iteration 4749 : loss : 0.081590, loss_ce: 0.020953
[00:44:33.114] iteration 4750 : loss : 0.132410, loss_ce: 0.026375
[00:44:33.418] iteration 4751 : loss : 0.115007, loss_ce: 0.010205
[00:44:33.722] iteration 4752 : loss : 0.122366, loss_ce: 0.017132
[00:44:34.026] iteration 4753 : loss : 0.110924, loss_ce: 0.029704
[00:44:34.327] iteration 4754 : loss : 0.133294, loss_ce: 0.018647
[00:44:34.632] iteration 4755 : loss : 0.087944, loss_ce: 0.019445
[00:44:34.937] iteration 4756 : loss : 0.063520, loss_ce: 0.019094
[00:44:35.254] iteration 4757 : loss : 0.059773, loss_ce: 0.020910
[00:44:35.552] iteration 4758 : loss : 0.101642, loss_ce: 0.029833
[00:44:35.856] iteration 4759 : loss : 0.054358, loss_ce: 0.014571
[00:44:36.161] iteration 4760 : loss : 0.135704, loss_ce: 0.034191
[00:44:36.494] iteration 4761 : loss : 0.086996, loss_ce: 0.030288
[00:44:36.799] iteration 4762 : loss : 0.108416, loss_ce: 0.027971
[00:44:37.100] iteration 4763 : loss : 0.096254, loss_ce: 0.020334
[00:44:37.409] iteration 4764 : loss : 0.116792, loss_ce: 0.026149
[00:44:37.716] iteration 4765 : loss : 0.077944, loss_ce: 0.018708
[00:44:38.017] iteration 4766 : loss : 0.077776, loss_ce: 0.027850
[00:44:38.329] iteration 4767 : loss : 0.147232, loss_ce: 0.018493
[00:44:38.636] iteration 4768 : loss : 0.127648, loss_ce: 0.015278
[00:44:38.942] iteration 4769 : loss : 0.093800, loss_ce: 0.014370
[00:44:39.244] iteration 4770 : loss : 0.101108, loss_ce: 0.035524
[00:44:39.548] iteration 4771 : loss : 0.078844, loss_ce: 0.026644
[00:44:39.855] iteration 4772 : loss : 0.176895, loss_ce: 0.014518
[00:44:40.166] iteration 4773 : loss : 0.084666, loss_ce: 0.024161
[00:44:40.468] iteration 4774 : loss : 0.188719, loss_ce: 0.017156
[00:44:40.783] iteration 4775 : loss : 0.072906, loss_ce: 0.024481
[00:44:41.087] iteration 4776 : loss : 0.137899, loss_ce: 0.020895
[00:44:41.395] iteration 4777 : loss : 0.096165, loss_ce: 0.023895
[00:44:41.701] iteration 4778 : loss : 0.082639, loss_ce: 0.029186
[00:44:42.003] iteration 4779 : loss : 0.084116, loss_ce: 0.026953
[00:44:42.309] iteration 4780 : loss : 0.125095, loss_ce: 0.012541
[00:44:42.634] iteration 4781 : loss : 0.190158, loss_ce: 0.026305
[00:44:42.936] iteration 4782 : loss : 0.097367, loss_ce: 0.028186
[00:44:43.243] iteration 4783 : loss : 0.081848, loss_ce: 0.033715
[00:44:43.562] iteration 4784 : loss : 0.070281, loss_ce: 0.030900
[00:44:43.865] iteration 4785 : loss : 0.121817, loss_ce: 0.023177
[00:44:44.173] iteration 4786 : loss : 0.119036, loss_ce: 0.021484
[00:44:44.480] iteration 4787 : loss : 0.086076, loss_ce: 0.038194
[00:44:44.784] iteration 4788 : loss : 0.077558, loss_ce: 0.022913
[00:44:45.089] iteration 4789 : loss : 0.075424, loss_ce: 0.006374
[00:44:45.392] iteration 4790 : loss : 0.161716, loss_ce: 0.022120
[00:44:45.699] iteration 4791 : loss : 0.098294, loss_ce: 0.046334
[00:44:46.012] iteration 4792 : loss : 0.082810, loss_ce: 0.027130
[00:44:46.315] iteration 4793 : loss : 0.080650, loss_ce: 0.030850
[00:44:46.614] iteration 4794 : loss : 0.094892, loss_ce: 0.022920
[00:44:46.915] iteration 4795 : loss : 0.089740, loss_ce: 0.018447
[00:44:47.223] iteration 4796 : loss : 0.093652, loss_ce: 0.034304
[00:44:47.536] iteration 4797 : loss : 0.071083, loss_ce: 0.021351
[00:44:47.848] iteration 4798 : loss : 0.081599, loss_ce: 0.017129
[00:44:48.162] iteration 4799 : loss : 0.109091, loss_ce: 0.027989
[00:44:48.467] iteration 4800 : loss : 0.087213, loss_ce: 0.026326
[00:44:48.794] iteration 4801 : loss : 0.137741, loss_ce: 0.009773
[00:44:49.095] iteration 4802 : loss : 0.066448, loss_ce: 0.024899
[00:44:49.395] iteration 4803 : loss : 0.238428, loss_ce: 0.016821
[00:44:49.698] iteration 4804 : loss : 0.181995, loss_ce: 0.011310
[00:44:50.008] iteration 4805 : loss : 0.094592, loss_ce: 0.036809
[00:44:50.311] iteration 4806 : loss : 0.095216, loss_ce: 0.026133
[00:44:50.619] iteration 4807 : loss : 0.103818, loss_ce: 0.041770
[00:44:50.930] iteration 4808 : loss : 0.275716, loss_ce: 0.010987
[00:44:51.230] iteration 4809 : loss : 0.144117, loss_ce: 0.019149
[00:44:51.543] iteration 4810 : loss : 0.053443, loss_ce: 0.020256
[00:44:51.852] iteration 4811 : loss : 0.130186, loss_ce: 0.023182
[00:44:52.155] iteration 4812 : loss : 0.144257, loss_ce: 0.020305
[00:44:52.469] iteration 4813 : loss : 0.118991, loss_ce: 0.014305
[00:44:52.773] iteration 4814 : loss : 0.080456, loss_ce: 0.032674
[00:44:53.082] iteration 4815 : loss : 0.120632, loss_ce: 0.024245
[00:44:53.395] iteration 4816 : loss : 0.084371, loss_ce: 0.024410
[00:44:53.700] iteration 4817 : loss : 0.070908, loss_ce: 0.015207
[00:44:54.018] iteration 4818 : loss : 0.072402, loss_ce: 0.025043
[00:44:54.317] iteration 4819 : loss : 0.068105, loss_ce: 0.016393
[00:44:54.623] iteration 4820 : loss : 0.115968, loss_ce: 0.014331
[00:44:54.941] iteration 4821 : loss : 0.091849, loss_ce: 0.032037
[00:44:55.242] iteration 4822 : loss : 0.298069, loss_ce: 0.018655
[00:44:55.546] iteration 4823 : loss : 0.124992, loss_ce: 0.010971
[00:44:55.853] iteration 4824 : loss : 0.091736, loss_ce: 0.025208
[00:44:56.153] iteration 4825 : loss : 0.083024, loss_ce: 0.036263
[00:44:56.457] iteration 4826 : loss : 0.091512, loss_ce: 0.019099
[00:44:56.766] iteration 4827 : loss : 0.112561, loss_ce: 0.022544
[00:44:57.073] iteration 4828 : loss : 0.122421, loss_ce: 0.034992
[00:44:57.375] iteration 4829 : loss : 0.195065, loss_ce: 0.025813
[00:44:57.679] iteration 4830 : loss : 0.082016, loss_ce: 0.014163
[00:44:57.987] iteration 4831 : loss : 0.066929, loss_ce: 0.015079
[00:44:58.301] iteration 4832 : loss : 0.065411, loss_ce: 0.024514
[00:44:58.604] iteration 4833 : loss : 0.061408, loss_ce: 0.012451
[00:44:58.916] iteration 4834 : loss : 0.162501, loss_ce: 0.025234
[00:44:59.220] iteration 4835 : loss : 0.056759, loss_ce: 0.024228
[00:44:59.528] iteration 4836 : loss : 0.077321, loss_ce: 0.026502
[00:44:59.842] iteration 4837 : loss : 0.068032, loss_ce: 0.018958
[00:45:00.152] iteration 4838 : loss : 0.062749, loss_ce: 0.033431
[00:45:00.455] iteration 4839 : loss : 0.132784, loss_ce: 0.010347
[00:45:00.756] iteration 4840 : loss : 0.070121, loss_ce: 0.020790
[00:45:01.082] iteration 4841 : loss : 0.096027, loss_ce: 0.021735
[00:45:01.390] iteration 4842 : loss : 0.140384, loss_ce: 0.008168
[00:45:01.704] iteration 4843 : loss : 0.059333, loss_ce: 0.016866
[00:45:02.006] iteration 4844 : loss : 0.091396, loss_ce: 0.014153
[00:45:02.314] iteration 4845 : loss : 0.073223, loss_ce: 0.035375
[00:45:02.618] iteration 4846 : loss : 0.071440, loss_ce: 0.030675
[00:45:02.924] iteration 4847 : loss : 0.146701, loss_ce: 0.017595
[00:45:03.228] iteration 4848 : loss : 0.081801, loss_ce: 0.014547
[00:45:03.543] iteration 4849 : loss : 0.065956, loss_ce: 0.008221
[00:45:03.847] iteration 4850 : loss : 0.071274, loss_ce: 0.024041
[00:45:04.160] iteration 4851 : loss : 0.077170, loss_ce: 0.019077
[00:45:04.482] iteration 4852 : loss : 0.136663, loss_ce: 0.011287
[00:45:04.796] iteration 4853 : loss : 0.083568, loss_ce: 0.031031
[00:45:05.103] iteration 4854 : loss : 0.059317, loss_ce: 0.017797
[00:45:05.416] iteration 4855 : loss : 0.140615, loss_ce: 0.015353
[00:45:05.735] iteration 4856 : loss : 0.076154, loss_ce: 0.025720
[00:45:06.048] iteration 4857 : loss : 0.079096, loss_ce: 0.019318
[00:45:06.363] iteration 4858 : loss : 0.129668, loss_ce: 0.026436
[00:45:06.676] iteration 4859 : loss : 0.069380, loss_ce: 0.026716
[00:45:06.983] iteration 4860 : loss : 0.051636, loss_ce: 0.010558
[00:45:07.332] iteration 4861 : loss : 0.073327, loss_ce: 0.018454
[00:45:07.634] iteration 4862 : loss : 0.133385, loss_ce: 0.035934
[00:45:07.952] iteration 4863 : loss : 0.089267, loss_ce: 0.032963
[00:45:08.275] iteration 4864 : loss : 0.085851, loss_ce: 0.022999
[00:45:08.364] iteration 4865 : loss : 0.279923, loss_ce: 0.012871
[00:45:25.687] iteration 4866 : loss : 0.085823, loss_ce: 0.042972
[00:45:25.994] iteration 4867 : loss : 0.092389, loss_ce: 0.021178
[00:45:26.302] iteration 4868 : loss : 0.102530, loss_ce: 0.021324
[00:45:26.614] iteration 4869 : loss : 0.077304, loss_ce: 0.032682
[00:45:26.912] iteration 4870 : loss : 0.124402, loss_ce: 0.019833
[00:45:27.217] iteration 4871 : loss : 0.115257, loss_ce: 0.029383
[00:45:27.518] iteration 4872 : loss : 0.087127, loss_ce: 0.030657
[00:45:27.816] iteration 4873 : loss : 0.096427, loss_ce: 0.028060
[00:45:28.123] iteration 4874 : loss : 0.146407, loss_ce: 0.022301
[00:45:28.432] iteration 4875 : loss : 0.067473, loss_ce: 0.021731
[00:45:28.732] iteration 4876 : loss : 0.087868, loss_ce: 0.020648
[00:45:29.034] iteration 4877 : loss : 0.077705, loss_ce: 0.016777
[00:45:29.344] iteration 4878 : loss : 0.083006, loss_ce: 0.035310
[00:45:29.656] iteration 4879 : loss : 0.118219, loss_ce: 0.017390
[00:45:29.959] iteration 4880 : loss : 0.132023, loss_ce: 0.026868
[00:45:30.285] iteration 4881 : loss : 0.125211, loss_ce: 0.032333
[00:45:30.589] iteration 4882 : loss : 0.125531, loss_ce: 0.015014
[00:45:30.892] iteration 4883 : loss : 0.121072, loss_ce: 0.023774
[00:45:31.204] iteration 4884 : loss : 0.075587, loss_ce: 0.012364
[00:45:31.512] iteration 4885 : loss : 0.086330, loss_ce: 0.020487
[00:45:31.821] iteration 4886 : loss : 0.128088, loss_ce: 0.020722
[00:45:32.124] iteration 4887 : loss : 0.060275, loss_ce: 0.019237
[00:45:32.423] iteration 4888 : loss : 0.067056, loss_ce: 0.020897
[00:45:32.729] iteration 4889 : loss : 0.084040, loss_ce: 0.022241
[00:45:33.035] iteration 4890 : loss : 0.093540, loss_ce: 0.037985
[00:45:33.340] iteration 4891 : loss : 0.190116, loss_ce: 0.009122
[00:45:33.645] iteration 4892 : loss : 0.076543, loss_ce: 0.017831
[00:45:33.948] iteration 4893 : loss : 0.123351, loss_ce: 0.023124
[00:45:34.249] iteration 4894 : loss : 0.108154, loss_ce: 0.024117
[00:45:34.560] iteration 4895 : loss : 0.058576, loss_ce: 0.010387
[00:45:34.869] iteration 4896 : loss : 0.082502, loss_ce: 0.028688
[00:45:35.174] iteration 4897 : loss : 0.116650, loss_ce: 0.032311
[00:45:35.488] iteration 4898 : loss : 0.066311, loss_ce: 0.025024
[00:45:35.798] iteration 4899 : loss : 0.076398, loss_ce: 0.022276
[00:45:36.105] iteration 4900 : loss : 0.066307, loss_ce: 0.023418
[00:45:36.421] iteration 4901 : loss : 0.093689, loss_ce: 0.041697
[00:45:36.726] iteration 4902 : loss : 0.091109, loss_ce: 0.024241
[00:45:37.034] iteration 4903 : loss : 0.172708, loss_ce: 0.026216
[00:45:37.342] iteration 4904 : loss : 0.118436, loss_ce: 0.016278
[00:45:37.651] iteration 4905 : loss : 0.130354, loss_ce: 0.018485
[00:45:37.948] iteration 4906 : loss : 0.088232, loss_ce: 0.009071
[00:45:38.256] iteration 4907 : loss : 0.053541, loss_ce: 0.012599
[00:45:38.564] iteration 4908 : loss : 0.063425, loss_ce: 0.025169
[00:45:38.862] iteration 4909 : loss : 0.091820, loss_ce: 0.026817
[00:45:39.164] iteration 4910 : loss : 0.171836, loss_ce: 0.009366
[00:45:39.472] iteration 4911 : loss : 0.067209, loss_ce: 0.021600
[00:45:39.784] iteration 4912 : loss : 0.057993, loss_ce: 0.008231
[00:45:40.080] iteration 4913 : loss : 0.068885, loss_ce: 0.013485
[00:45:40.386] iteration 4914 : loss : 0.064404, loss_ce: 0.021609
[00:45:40.687] iteration 4915 : loss : 0.069852, loss_ce: 0.019535
[00:45:40.994] iteration 4916 : loss : 0.089106, loss_ce: 0.022542
[00:45:41.302] iteration 4917 : loss : 0.114816, loss_ce: 0.013494
[00:45:41.611] iteration 4918 : loss : 0.128854, loss_ce: 0.022938
[00:45:41.919] iteration 4919 : loss : 0.076147, loss_ce: 0.014306
[00:45:42.228] iteration 4920 : loss : 0.171256, loss_ce: 0.013530
[00:45:42.553] iteration 4921 : loss : 0.111924, loss_ce: 0.014090
[00:45:42.856] iteration 4922 : loss : 0.081880, loss_ce: 0.025882
[00:45:43.161] iteration 4923 : loss : 0.059396, loss_ce: 0.014989
[00:45:43.468] iteration 4924 : loss : 0.077384, loss_ce: 0.033939
[00:45:43.771] iteration 4925 : loss : 0.086399, loss_ce: 0.020877
[00:45:44.079] iteration 4926 : loss : 0.086134, loss_ce: 0.014502
[00:45:44.382] iteration 4927 : loss : 0.077221, loss_ce: 0.028111
[00:45:44.686] iteration 4928 : loss : 0.079977, loss_ce: 0.027929
[00:45:44.998] iteration 4929 : loss : 0.084353, loss_ce: 0.015064
[00:45:45.302] iteration 4930 : loss : 0.118689, loss_ce: 0.015320
[00:45:45.603] iteration 4931 : loss : 0.112833, loss_ce: 0.016442
[00:45:45.911] iteration 4932 : loss : 0.080624, loss_ce: 0.017751
[00:45:46.222] iteration 4933 : loss : 0.059465, loss_ce: 0.016998
[00:45:46.530] iteration 4934 : loss : 0.086420, loss_ce: 0.034057
[00:45:46.834] iteration 4935 : loss : 0.158436, loss_ce: 0.018329
[00:45:47.146] iteration 4936 : loss : 0.072955, loss_ce: 0.025673
[00:45:47.449] iteration 4937 : loss : 0.121175, loss_ce: 0.016894
[00:45:47.758] iteration 4938 : loss : 0.116522, loss_ce: 0.024809
[00:45:48.066] iteration 4939 : loss : 0.071836, loss_ce: 0.022912
[00:45:48.376] iteration 4940 : loss : 0.130723, loss_ce: 0.023098
[00:45:48.697] iteration 4941 : loss : 0.071246, loss_ce: 0.029882
[00:45:49.003] iteration 4942 : loss : 0.164458, loss_ce: 0.012989
[00:45:49.310] iteration 4943 : loss : 0.090570, loss_ce: 0.018834
[00:45:49.616] iteration 4944 : loss : 0.127210, loss_ce: 0.009854
[00:45:49.924] iteration 4945 : loss : 0.075276, loss_ce: 0.042700
[00:45:50.230] iteration 4946 : loss : 0.069961, loss_ce: 0.024849
[00:45:50.533] iteration 4947 : loss : 0.074810, loss_ce: 0.025259
[00:45:50.834] iteration 4948 : loss : 0.069178, loss_ce: 0.026199
[00:45:51.145] iteration 4949 : loss : 0.078244, loss_ce: 0.023751
[00:45:51.451] iteration 4950 : loss : 0.082966, loss_ce: 0.020825
[00:45:51.754] iteration 4951 : loss : 0.114533, loss_ce: 0.018938
[00:45:52.056] iteration 4952 : loss : 0.060591, loss_ce: 0.023493
[00:45:52.364] iteration 4953 : loss : 0.072907, loss_ce: 0.024225
[00:45:52.668] iteration 4954 : loss : 0.076763, loss_ce: 0.034055
[00:45:52.974] iteration 4955 : loss : 0.067401, loss_ce: 0.025934
[00:45:53.278] iteration 4956 : loss : 0.078164, loss_ce: 0.019933
[00:45:53.589] iteration 4957 : loss : 0.124485, loss_ce: 0.019957
[00:45:53.888] iteration 4958 : loss : 0.080597, loss_ce: 0.028844
[00:45:54.190] iteration 4959 : loss : 0.076234, loss_ce: 0.026189
[00:45:54.496] iteration 4960 : loss : 0.083464, loss_ce: 0.017227
[00:45:54.825] iteration 4961 : loss : 0.117582, loss_ce: 0.017690
[00:45:55.126] iteration 4962 : loss : 0.085742, loss_ce: 0.008868
[00:45:55.442] iteration 4963 : loss : 0.057300, loss_ce: 0.029574
[00:45:55.739] iteration 4964 : loss : 0.088082, loss_ce: 0.027753
[00:45:56.052] iteration 4965 : loss : 0.292892, loss_ce: 0.013995
[00:45:56.353] iteration 4966 : loss : 0.073455, loss_ce: 0.018391
[00:45:56.655] iteration 4967 : loss : 0.115532, loss_ce: 0.032211
[00:45:56.963] iteration 4968 : loss : 0.089788, loss_ce: 0.023242
[00:45:57.272] iteration 4969 : loss : 0.064022, loss_ce: 0.026750
[00:45:57.577] iteration 4970 : loss : 0.093145, loss_ce: 0.010321
[00:45:57.883] iteration 4971 : loss : 0.116417, loss_ce: 0.032666
[00:45:58.189] iteration 4972 : loss : 0.071419, loss_ce: 0.032828
[00:45:58.496] iteration 4973 : loss : 0.062003, loss_ce: 0.016528
[00:45:58.803] iteration 4974 : loss : 0.095293, loss_ce: 0.036277
[00:45:59.114] iteration 4975 : loss : 0.078801, loss_ce: 0.022208
[00:45:59.421] iteration 4976 : loss : 0.070783, loss_ce: 0.025982
[00:45:59.729] iteration 4977 : loss : 0.146411, loss_ce: 0.017994
[00:46:00.030] iteration 4978 : loss : 0.092656, loss_ce: 0.023869
[00:46:00.340] iteration 4979 : loss : 0.077027, loss_ce: 0.018156
[00:46:00.644] iteration 4980 : loss : 0.138933, loss_ce: 0.006376
[00:46:00.969] iteration 4981 : loss : 0.070630, loss_ce: 0.027881
[00:46:01.271] iteration 4982 : loss : 0.103977, loss_ce: 0.026607
[00:46:01.575] iteration 4983 : loss : 0.128110, loss_ce: 0.015472
[00:46:01.881] iteration 4984 : loss : 0.167551, loss_ce: 0.014608
[00:46:02.195] iteration 4985 : loss : 0.088575, loss_ce: 0.033504
[00:46:02.507] iteration 4986 : loss : 0.070002, loss_ce: 0.008389
[00:46:02.810] iteration 4987 : loss : 0.077331, loss_ce: 0.028814
[00:46:03.124] iteration 4988 : loss : 0.077225, loss_ce: 0.031393
[00:46:03.434] iteration 4989 : loss : 0.080205, loss_ce: 0.008711
[00:46:03.744] iteration 4990 : loss : 0.129569, loss_ce: 0.013192
[00:46:04.066] iteration 4991 : loss : 0.084079, loss_ce: 0.024738
[00:46:04.374] iteration 4992 : loss : 0.175621, loss_ce: 0.014942
[00:46:04.677] iteration 4993 : loss : 0.061327, loss_ce: 0.016983
[00:46:04.990] iteration 4994 : loss : 0.068407, loss_ce: 0.017876
[00:46:05.303] iteration 4995 : loss : 0.068407, loss_ce: 0.020122
[00:46:05.608] iteration 4996 : loss : 0.072119, loss_ce: 0.020793
[00:46:05.923] iteration 4997 : loss : 0.122967, loss_ce: 0.018550
[00:46:06.234] iteration 4998 : loss : 0.127593, loss_ce: 0.011525
[00:46:06.554] iteration 4999 : loss : 0.090492, loss_ce: 0.019831
[00:46:06.863] iteration 5000 : loss : 0.060779, loss_ce: 0.011751
[00:46:07.209] iteration 5001 : loss : 0.057670, loss_ce: 0.019682
[00:46:07.523] iteration 5002 : loss : 0.104270, loss_ce: 0.020836
[00:46:07.833] iteration 5003 : loss : 0.069760, loss_ce: 0.028089
[00:46:07.917] iteration 5004 : loss : 0.236334, loss_ce: 0.014221
[00:46:27.203] iteration 5005 : loss : 0.057705, loss_ce: 0.023955
[00:46:27.509] iteration 5006 : loss : 0.071985, loss_ce: 0.022713
[00:46:27.822] iteration 5007 : loss : 0.065581, loss_ce: 0.021467
[00:46:28.127] iteration 5008 : loss : 0.097598, loss_ce: 0.034112
[00:46:28.443] iteration 5009 : loss : 0.163810, loss_ce: 0.020506
[00:46:28.750] iteration 5010 : loss : 0.136836, loss_ce: 0.018812
[00:46:29.054] iteration 5011 : loss : 0.083007, loss_ce: 0.027460
[00:46:29.360] iteration 5012 : loss : 0.088133, loss_ce: 0.026579
[00:46:29.662] iteration 5013 : loss : 0.076793, loss_ce: 0.015205
[00:46:29.974] iteration 5014 : loss : 0.098254, loss_ce: 0.028129
[00:46:30.277] iteration 5015 : loss : 0.079701, loss_ce: 0.021554
[00:46:30.586] iteration 5016 : loss : 0.081207, loss_ce: 0.018601
[00:46:30.895] iteration 5017 : loss : 0.073397, loss_ce: 0.016359
[00:46:31.197] iteration 5018 : loss : 0.086773, loss_ce: 0.041615
[00:46:31.501] iteration 5019 : loss : 0.086681, loss_ce: 0.017110
[00:46:31.805] iteration 5020 : loss : 0.090636, loss_ce: 0.023582
[00:46:32.132] iteration 5021 : loss : 0.133705, loss_ce: 0.014031
[00:46:32.436] iteration 5022 : loss : 0.084029, loss_ce: 0.027762
[00:46:32.738] iteration 5023 : loss : 0.076051, loss_ce: 0.026492
[00:46:33.046] iteration 5024 : loss : 0.070888, loss_ce: 0.017160
[00:46:33.362] iteration 5025 : loss : 0.067674, loss_ce: 0.015256
[00:46:33.665] iteration 5026 : loss : 0.119278, loss_ce: 0.020833
[00:46:33.965] iteration 5027 : loss : 0.071333, loss_ce: 0.025610
[00:46:34.273] iteration 5028 : loss : 0.090808, loss_ce: 0.023904
[00:46:34.580] iteration 5029 : loss : 0.116537, loss_ce: 0.013362
[00:46:34.882] iteration 5030 : loss : 0.092814, loss_ce: 0.030697
[00:46:35.191] iteration 5031 : loss : 0.067087, loss_ce: 0.020297
[00:46:35.493] iteration 5032 : loss : 0.080587, loss_ce: 0.017740
[00:46:35.803] iteration 5033 : loss : 0.115493, loss_ce: 0.021199
[00:46:36.113] iteration 5034 : loss : 0.050525, loss_ce: 0.013254
[00:46:36.414] iteration 5035 : loss : 0.130904, loss_ce: 0.037749
[00:46:36.720] iteration 5036 : loss : 0.083923, loss_ce: 0.019887
[00:46:37.029] iteration 5037 : loss : 0.093883, loss_ce: 0.020603
[00:46:37.335] iteration 5038 : loss : 0.072946, loss_ce: 0.022643
[00:46:37.634] iteration 5039 : loss : 0.072666, loss_ce: 0.026923
[00:46:37.942] iteration 5040 : loss : 0.074222, loss_ce: 0.016495
[00:46:38.264] iteration 5041 : loss : 0.054639, loss_ce: 0.014670
[00:46:38.574] iteration 5042 : loss : 0.077008, loss_ce: 0.019151
[00:46:38.878] iteration 5043 : loss : 0.118171, loss_ce: 0.021569
[00:46:39.180] iteration 5044 : loss : 0.127957, loss_ce: 0.014418
[00:46:39.491] iteration 5045 : loss : 0.073705, loss_ce: 0.025711
[00:46:39.797] iteration 5046 : loss : 0.078639, loss_ce: 0.023897
[00:46:40.106] iteration 5047 : loss : 0.077525, loss_ce: 0.014680
[00:46:40.402] iteration 5048 : loss : 0.090545, loss_ce: 0.008057
[00:46:40.702] iteration 5049 : loss : 0.062984, loss_ce: 0.028040
[00:46:41.008] iteration 5050 : loss : 0.130760, loss_ce: 0.006609
[00:46:41.315] iteration 5051 : loss : 0.070475, loss_ce: 0.025780
[00:46:41.623] iteration 5052 : loss : 0.107117, loss_ce: 0.041180
[00:46:41.934] iteration 5053 : loss : 0.055224, loss_ce: 0.014239
[00:46:42.237] iteration 5054 : loss : 0.114083, loss_ce: 0.008441
[00:46:42.542] iteration 5055 : loss : 0.129486, loss_ce: 0.028997
[00:46:42.846] iteration 5056 : loss : 0.065964, loss_ce: 0.024187
[00:46:43.157] iteration 5057 : loss : 0.074625, loss_ce: 0.014844
[00:46:43.467] iteration 5058 : loss : 0.076478, loss_ce: 0.032595
[00:46:43.769] iteration 5059 : loss : 0.075472, loss_ce: 0.022241
[00:46:44.075] iteration 5060 : loss : 0.091696, loss_ce: 0.026584
[00:46:44.409] iteration 5061 : loss : 0.084498, loss_ce: 0.022887
[00:46:44.715] iteration 5062 : loss : 0.053233, loss_ce: 0.016070
[00:46:45.016] iteration 5063 : loss : 0.075939, loss_ce: 0.026798
[00:46:45.331] iteration 5064 : loss : 0.138323, loss_ce: 0.007467
[00:46:45.633] iteration 5065 : loss : 0.113606, loss_ce: 0.018210
[00:46:45.935] iteration 5066 : loss : 0.100782, loss_ce: 0.013665
[00:46:46.245] iteration 5067 : loss : 0.082450, loss_ce: 0.022990
[00:46:46.550] iteration 5068 : loss : 0.075757, loss_ce: 0.009675
[00:46:46.858] iteration 5069 : loss : 0.075226, loss_ce: 0.025925
[00:46:47.169] iteration 5070 : loss : 0.078598, loss_ce: 0.017981
[00:46:47.471] iteration 5071 : loss : 0.138988, loss_ce: 0.022787
[00:46:47.774] iteration 5072 : loss : 0.083455, loss_ce: 0.019867
[00:46:48.088] iteration 5073 : loss : 0.065817, loss_ce: 0.028974
[00:46:48.393] iteration 5074 : loss : 0.076876, loss_ce: 0.019362
[00:46:48.692] iteration 5075 : loss : 0.075746, loss_ce: 0.038439
[00:46:48.996] iteration 5076 : loss : 0.072137, loss_ce: 0.019804
[00:46:49.302] iteration 5077 : loss : 0.094878, loss_ce: 0.035162
[00:46:49.607] iteration 5078 : loss : 0.079017, loss_ce: 0.024094
[00:46:49.908] iteration 5079 : loss : 0.135974, loss_ce: 0.030205
[00:46:50.227] iteration 5080 : loss : 0.119185, loss_ce: 0.014280
[00:46:50.548] iteration 5081 : loss : 0.111819, loss_ce: 0.026888
[00:46:50.855] iteration 5082 : loss : 0.079968, loss_ce: 0.029791
[00:46:51.163] iteration 5083 : loss : 0.082587, loss_ce: 0.027396
[00:46:51.473] iteration 5084 : loss : 0.059032, loss_ce: 0.017139
[00:46:51.772] iteration 5085 : loss : 0.073262, loss_ce: 0.011472
[00:46:52.080] iteration 5086 : loss : 0.085299, loss_ce: 0.030566
[00:46:52.390] iteration 5087 : loss : 0.071782, loss_ce: 0.012904
[00:46:52.693] iteration 5088 : loss : 0.136127, loss_ce: 0.021991
[00:46:52.997] iteration 5089 : loss : 0.073063, loss_ce: 0.026561
[00:46:53.322] iteration 5090 : loss : 0.092506, loss_ce: 0.017857
[00:46:53.625] iteration 5091 : loss : 0.069420, loss_ce: 0.026830
[00:46:53.933] iteration 5092 : loss : 0.238117, loss_ce: 0.010279
[00:46:54.239] iteration 5093 : loss : 0.149162, loss_ce: 0.019477
[00:46:54.544] iteration 5094 : loss : 0.100890, loss_ce: 0.042119
[00:46:54.846] iteration 5095 : loss : 0.117313, loss_ce: 0.015513
[00:46:55.150] iteration 5096 : loss : 0.074983, loss_ce: 0.020384
[00:46:55.461] iteration 5097 : loss : 0.060619, loss_ce: 0.022285
[00:46:55.766] iteration 5098 : loss : 0.059475, loss_ce: 0.024485
[00:46:56.068] iteration 5099 : loss : 0.079037, loss_ce: 0.028451
[00:46:56.371] iteration 5100 : loss : 0.096369, loss_ce: 0.023499
[00:46:56.705] iteration 5101 : loss : 0.070135, loss_ce: 0.033537
[00:46:57.001] iteration 5102 : loss : 0.063625, loss_ce: 0.013927
[00:46:57.307] iteration 5103 : loss : 0.122797, loss_ce: 0.013198
[00:46:57.623] iteration 5104 : loss : 0.083940, loss_ce: 0.020566
[00:46:57.925] iteration 5105 : loss : 0.067541, loss_ce: 0.017111
[00:46:58.235] iteration 5106 : loss : 0.141337, loss_ce: 0.017701
[00:46:58.537] iteration 5107 : loss : 0.073833, loss_ce: 0.022353
[00:46:58.845] iteration 5108 : loss : 0.051651, loss_ce: 0.012498
[00:46:59.154] iteration 5109 : loss : 0.070959, loss_ce: 0.026761
[00:46:59.462] iteration 5110 : loss : 0.095139, loss_ce: 0.030890
[00:46:59.765] iteration 5111 : loss : 0.069378, loss_ce: 0.021130
[00:47:00.077] iteration 5112 : loss : 0.070511, loss_ce: 0.022591
[00:47:00.385] iteration 5113 : loss : 0.088333, loss_ce: 0.038751
[00:47:00.688] iteration 5114 : loss : 0.124570, loss_ce: 0.013834
[00:47:00.995] iteration 5115 : loss : 0.065505, loss_ce: 0.022334
[00:47:01.310] iteration 5116 : loss : 0.127260, loss_ce: 0.007937
[00:47:01.616] iteration 5117 : loss : 0.104208, loss_ce: 0.018163
[00:47:01.923] iteration 5118 : loss : 0.117650, loss_ce: 0.019421
[00:47:02.231] iteration 5119 : loss : 0.064820, loss_ce: 0.013629
[00:47:02.541] iteration 5120 : loss : 0.073115, loss_ce: 0.014431
[00:47:02.873] iteration 5121 : loss : 0.093466, loss_ce: 0.032980
[00:47:03.182] iteration 5122 : loss : 0.057226, loss_ce: 0.006856
[00:47:03.486] iteration 5123 : loss : 0.068879, loss_ce: 0.029301
[00:47:03.790] iteration 5124 : loss : 0.173553, loss_ce: 0.014856
[00:47:04.098] iteration 5125 : loss : 0.078585, loss_ce: 0.020035
[00:47:04.407] iteration 5126 : loss : 0.076416, loss_ce: 0.019648
[00:47:04.713] iteration 5127 : loss : 0.076076, loss_ce: 0.021882
[00:47:05.020] iteration 5128 : loss : 0.064317, loss_ce: 0.019678
[00:47:05.331] iteration 5129 : loss : 0.077787, loss_ce: 0.028071
[00:47:05.644] iteration 5130 : loss : 0.094267, loss_ce: 0.019937
[00:47:05.959] iteration 5131 : loss : 0.095080, loss_ce: 0.017207
[00:47:06.270] iteration 5132 : loss : 0.140972, loss_ce: 0.016541
[00:47:06.579] iteration 5133 : loss : 0.079134, loss_ce: 0.020973
[00:47:06.889] iteration 5134 : loss : 0.065350, loss_ce: 0.024003
[00:47:07.199] iteration 5135 : loss : 0.090242, loss_ce: 0.017640
[00:47:07.509] iteration 5136 : loss : 0.095291, loss_ce: 0.011344
[00:47:07.817] iteration 5137 : loss : 0.225494, loss_ce: 0.018969
[00:47:08.128] iteration 5138 : loss : 0.085224, loss_ce: 0.016850
[00:47:08.435] iteration 5139 : loss : 0.102871, loss_ce: 0.035563
[00:47:08.745] iteration 5140 : loss : 0.222739, loss_ce: 0.004574
[00:47:09.085] iteration 5141 : loss : 0.071823, loss_ce: 0.028668
[00:47:09.394] iteration 5142 : loss : 0.074559, loss_ce: 0.017820
[00:47:09.471] iteration 5143 : loss : 0.099413, loss_ce: 0.039429
[00:47:26.523] iteration 5144 : loss : 0.104697, loss_ce: 0.019842
[00:47:26.828] iteration 5145 : loss : 0.078331, loss_ce: 0.020853
[00:47:27.133] iteration 5146 : loss : 0.098511, loss_ce: 0.017915
[00:47:27.446] iteration 5147 : loss : 0.090080, loss_ce: 0.016644
[00:47:27.754] iteration 5148 : loss : 0.073259, loss_ce: 0.017053
[00:47:28.056] iteration 5149 : loss : 0.088441, loss_ce: 0.015778
[00:47:28.358] iteration 5150 : loss : 0.186730, loss_ce: 0.013036
[00:47:28.669] iteration 5151 : loss : 0.076247, loss_ce: 0.024622
[00:47:28.976] iteration 5152 : loss : 0.122534, loss_ce: 0.017047
[00:47:29.277] iteration 5153 : loss : 0.188244, loss_ce: 0.011588
[00:47:29.583] iteration 5154 : loss : 0.141263, loss_ce: 0.031458
[00:47:29.893] iteration 5155 : loss : 0.110013, loss_ce: 0.031785
[00:47:30.193] iteration 5156 : loss : 0.074385, loss_ce: 0.024824
[00:47:30.506] iteration 5157 : loss : 0.103489, loss_ce: 0.026688
[00:47:30.813] iteration 5158 : loss : 0.072104, loss_ce: 0.010246
[00:47:31.123] iteration 5159 : loss : 0.127395, loss_ce: 0.023150
[00:47:31.428] iteration 5160 : loss : 0.080372, loss_ce: 0.018476
[00:47:31.763] iteration 5161 : loss : 0.071018, loss_ce: 0.025163
[00:47:32.072] iteration 5162 : loss : 0.093120, loss_ce: 0.034736
[00:47:32.379] iteration 5163 : loss : 0.104275, loss_ce: 0.020173
[00:47:32.687] iteration 5164 : loss : 0.068847, loss_ce: 0.017590
[00:47:32.999] iteration 5165 : loss : 0.073068, loss_ce: 0.026534
[00:47:33.307] iteration 5166 : loss : 0.118003, loss_ce: 0.016364
[00:47:33.616] iteration 5167 : loss : 0.060943, loss_ce: 0.022295
[00:47:33.921] iteration 5168 : loss : 0.183387, loss_ce: 0.018587
[00:47:34.228] iteration 5169 : loss : 0.072308, loss_ce: 0.021471
[00:47:34.539] iteration 5170 : loss : 0.063241, loss_ce: 0.018054
[00:47:34.846] iteration 5171 : loss : 0.074730, loss_ce: 0.021063
[00:47:35.156] iteration 5172 : loss : 0.064192, loss_ce: 0.018838
[00:47:35.463] iteration 5173 : loss : 0.118169, loss_ce: 0.013512
[00:47:35.770] iteration 5174 : loss : 0.074020, loss_ce: 0.030702
[00:47:36.077] iteration 5175 : loss : 0.082133, loss_ce: 0.026939
[00:47:36.382] iteration 5176 : loss : 0.073233, loss_ce: 0.022813
[00:47:36.692] iteration 5177 : loss : 0.061901, loss_ce: 0.019346
[00:47:37.003] iteration 5178 : loss : 0.063204, loss_ce: 0.020386
[00:47:37.315] iteration 5179 : loss : 0.122341, loss_ce: 0.019508
[00:47:37.623] iteration 5180 : loss : 0.083961, loss_ce: 0.025231
[00:47:37.942] iteration 5181 : loss : 0.133919, loss_ce: 0.020435
[00:47:38.253] iteration 5182 : loss : 0.083497, loss_ce: 0.021723
[00:47:38.556] iteration 5183 : loss : 0.055698, loss_ce: 0.020036
[00:47:38.863] iteration 5184 : loss : 0.081660, loss_ce: 0.030855
[00:47:39.170] iteration 5185 : loss : 0.067352, loss_ce: 0.017886
[00:47:39.477] iteration 5186 : loss : 0.064446, loss_ce: 0.019309
[00:47:39.785] iteration 5187 : loss : 0.096723, loss_ce: 0.032382
[00:47:40.093] iteration 5188 : loss : 0.065549, loss_ce: 0.028146
[00:47:40.403] iteration 5189 : loss : 0.109090, loss_ce: 0.015818
[00:47:40.715] iteration 5190 : loss : 0.072768, loss_ce: 0.026314
[00:47:41.023] iteration 5191 : loss : 0.116264, loss_ce: 0.013150
[00:47:41.334] iteration 5192 : loss : 0.225576, loss_ce: 0.009078
[00:47:41.642] iteration 5193 : loss : 0.073744, loss_ce: 0.023942
[00:47:41.947] iteration 5194 : loss : 0.057113, loss_ce: 0.015116
[00:47:42.249] iteration 5195 : loss : 0.070439, loss_ce: 0.011716
[00:47:42.554] iteration 5196 : loss : 0.081864, loss_ce: 0.023272
[00:47:42.868] iteration 5197 : loss : 0.140901, loss_ce: 0.022884
[00:47:43.176] iteration 5198 : loss : 0.078076, loss_ce: 0.027462
[00:47:43.482] iteration 5199 : loss : 0.060037, loss_ce: 0.020940
[00:47:43.784] iteration 5200 : loss : 0.104191, loss_ce: 0.031702
[00:47:44.101] iteration 5201 : loss : 0.079508, loss_ce: 0.027378
[00:47:44.414] iteration 5202 : loss : 0.066870, loss_ce: 0.020326
[00:47:44.717] iteration 5203 : loss : 0.059177, loss_ce: 0.011764
[00:47:45.028] iteration 5204 : loss : 0.066568, loss_ce: 0.011679
[00:47:45.336] iteration 5205 : loss : 0.109582, loss_ce: 0.021904
[00:47:45.651] iteration 5206 : loss : 0.086202, loss_ce: 0.020025
[00:47:45.948] iteration 5207 : loss : 0.183251, loss_ce: 0.024673
[00:47:46.252] iteration 5208 : loss : 0.070140, loss_ce: 0.032517
[00:47:46.555] iteration 5209 : loss : 0.128803, loss_ce: 0.021902
[00:47:46.870] iteration 5210 : loss : 0.054084, loss_ce: 0.012970
[00:47:47.175] iteration 5211 : loss : 0.087891, loss_ce: 0.030737
[00:47:47.485] iteration 5212 : loss : 0.167197, loss_ce: 0.020836
[00:47:47.788] iteration 5213 : loss : 0.084542, loss_ce: 0.028108
[00:47:48.091] iteration 5214 : loss : 0.081425, loss_ce: 0.037476
[00:47:48.395] iteration 5215 : loss : 0.129116, loss_ce: 0.023324
[00:47:48.697] iteration 5216 : loss : 0.136802, loss_ce: 0.012519
[00:47:49.012] iteration 5217 : loss : 0.071860, loss_ce: 0.010220
[00:47:49.316] iteration 5218 : loss : 0.128940, loss_ce: 0.015534
[00:47:49.624] iteration 5219 : loss : 0.134731, loss_ce: 0.035250
[00:47:49.934] iteration 5220 : loss : 0.065215, loss_ce: 0.019820
[00:47:50.258] iteration 5221 : loss : 0.054144, loss_ce: 0.017900
[00:47:50.564] iteration 5222 : loss : 0.067909, loss_ce: 0.016088
[00:47:50.881] iteration 5223 : loss : 0.096518, loss_ce: 0.022650
[00:47:51.186] iteration 5224 : loss : 0.085703, loss_ce: 0.028572
[00:47:51.494] iteration 5225 : loss : 0.077743, loss_ce: 0.039331
[00:47:51.802] iteration 5226 : loss : 0.081025, loss_ce: 0.023397
[00:47:52.105] iteration 5227 : loss : 0.052327, loss_ce: 0.015044
[00:47:52.418] iteration 5228 : loss : 0.064667, loss_ce: 0.017923
[00:47:52.722] iteration 5229 : loss : 0.052022, loss_ce: 0.022529
[00:47:53.025] iteration 5230 : loss : 0.079093, loss_ce: 0.026204
[00:47:53.329] iteration 5231 : loss : 0.096723, loss_ce: 0.011701
[00:47:53.631] iteration 5232 : loss : 0.077272, loss_ce: 0.033169
[00:47:53.940] iteration 5233 : loss : 0.083258, loss_ce: 0.035808
[00:47:54.245] iteration 5234 : loss : 0.086320, loss_ce: 0.019643
[00:47:54.554] iteration 5235 : loss : 0.102642, loss_ce: 0.019246
[00:47:54.863] iteration 5236 : loss : 0.132985, loss_ce: 0.010437
[00:47:55.169] iteration 5237 : loss : 0.055672, loss_ce: 0.014796
[00:47:55.471] iteration 5238 : loss : 0.072628, loss_ce: 0.025787
[00:47:55.776] iteration 5239 : loss : 0.119709, loss_ce: 0.015600
[00:47:56.084] iteration 5240 : loss : 0.127905, loss_ce: 0.025281
[00:47:56.413] iteration 5241 : loss : 0.102548, loss_ce: 0.016712
[00:47:56.713] iteration 5242 : loss : 0.072865, loss_ce: 0.027223
[00:47:57.019] iteration 5243 : loss : 0.082876, loss_ce: 0.022139
[00:47:57.327] iteration 5244 : loss : 0.076972, loss_ce: 0.011908
[00:47:57.633] iteration 5245 : loss : 0.118012, loss_ce: 0.009137
[00:47:57.937] iteration 5246 : loss : 0.066204, loss_ce: 0.025739
[00:47:58.246] iteration 5247 : loss : 0.081365, loss_ce: 0.025669
[00:47:58.553] iteration 5248 : loss : 0.105083, loss_ce: 0.027619
[00:47:58.859] iteration 5249 : loss : 0.065419, loss_ce: 0.014903
[00:47:59.165] iteration 5250 : loss : 0.060860, loss_ce: 0.026026
[00:47:59.464] iteration 5251 : loss : 0.100760, loss_ce: 0.015027
[00:47:59.780] iteration 5252 : loss : 0.072735, loss_ce: 0.014886
[00:48:00.083] iteration 5253 : loss : 0.066458, loss_ce: 0.023083
[00:48:00.393] iteration 5254 : loss : 0.082329, loss_ce: 0.024735
[00:48:00.700] iteration 5255 : loss : 0.114752, loss_ce: 0.030986
[00:48:01.011] iteration 5256 : loss : 0.087766, loss_ce: 0.023669
[00:48:01.317] iteration 5257 : loss : 0.065674, loss_ce: 0.026849
[00:48:01.629] iteration 5258 : loss : 0.105986, loss_ce: 0.022347
[00:48:01.930] iteration 5259 : loss : 0.091549, loss_ce: 0.015108
[00:48:02.228] iteration 5260 : loss : 0.067204, loss_ce: 0.019946
[00:48:02.558] iteration 5261 : loss : 0.088302, loss_ce: 0.013461
[00:48:02.860] iteration 5262 : loss : 0.085168, loss_ce: 0.032615
[00:48:03.164] iteration 5263 : loss : 0.078807, loss_ce: 0.023733
[00:48:03.469] iteration 5264 : loss : 0.072452, loss_ce: 0.028035
[00:48:03.769] iteration 5265 : loss : 0.156580, loss_ce: 0.018754
[00:48:04.075] iteration 5266 : loss : 0.091097, loss_ce: 0.028052
[00:48:04.381] iteration 5267 : loss : 0.067451, loss_ce: 0.013199
[00:48:04.692] iteration 5268 : loss : 0.065239, loss_ce: 0.018609
[00:48:05.001] iteration 5269 : loss : 0.069602, loss_ce: 0.026136
[00:48:05.308] iteration 5270 : loss : 0.130745, loss_ce: 0.021411
[00:48:05.611] iteration 5271 : loss : 0.064508, loss_ce: 0.016835
[00:48:05.928] iteration 5272 : loss : 0.079249, loss_ce: 0.022350
[00:48:06.233] iteration 5273 : loss : 0.111449, loss_ce: 0.017172
[00:48:06.550] iteration 5274 : loss : 0.242486, loss_ce: 0.007397
[00:48:06.860] iteration 5275 : loss : 0.137038, loss_ce: 0.014027
[00:48:07.167] iteration 5276 : loss : 0.073603, loss_ce: 0.025423
[00:48:07.484] iteration 5277 : loss : 0.095779, loss_ce: 0.015786
[00:48:07.789] iteration 5278 : loss : 0.146200, loss_ce: 0.013093
[00:48:08.091] iteration 5279 : loss : 0.085389, loss_ce: 0.023013
[00:48:08.400] iteration 5280 : loss : 0.084398, loss_ce: 0.023266
[00:48:08.729] iteration 5281 : loss : 0.085835, loss_ce: 0.017637
[00:48:08.810] iteration 5282 : loss : 0.292383, loss_ce: 0.014000
[00:48:27.815] iteration 5283 : loss : 0.077017, loss_ce: 0.026230
[00:48:28.118] iteration 5284 : loss : 0.207054, loss_ce: 0.019138
[00:48:28.438] iteration 5285 : loss : 0.060438, loss_ce: 0.018736
[00:48:28.744] iteration 5286 : loss : 0.059300, loss_ce: 0.025027
[00:48:29.047] iteration 5287 : loss : 0.141553, loss_ce: 0.014840
[00:48:29.348] iteration 5288 : loss : 0.060633, loss_ce: 0.018359
[00:48:29.653] iteration 5289 : loss : 0.078583, loss_ce: 0.031017
[00:48:29.957] iteration 5290 : loss : 0.086100, loss_ce: 0.023868
[00:48:30.265] iteration 5291 : loss : 0.085692, loss_ce: 0.030016
[00:48:30.571] iteration 5292 : loss : 0.074532, loss_ce: 0.026337
[00:48:30.873] iteration 5293 : loss : 0.132272, loss_ce: 0.011048
[00:48:31.177] iteration 5294 : loss : 0.080905, loss_ce: 0.023717
[00:48:31.487] iteration 5295 : loss : 0.052779, loss_ce: 0.012870
[00:48:31.794] iteration 5296 : loss : 0.072054, loss_ce: 0.019270
[00:48:32.095] iteration 5297 : loss : 0.074009, loss_ce: 0.014374
[00:48:32.393] iteration 5298 : loss : 0.071162, loss_ce: 0.017188
[00:48:32.700] iteration 5299 : loss : 0.114635, loss_ce: 0.010844
[00:48:33.003] iteration 5300 : loss : 0.064310, loss_ce: 0.016035
[00:48:33.345] iteration 5301 : loss : 0.065295, loss_ce: 0.018528
[00:48:33.648] iteration 5302 : loss : 0.060304, loss_ce: 0.019670
[00:48:33.961] iteration 5303 : loss : 0.069808, loss_ce: 0.017682
[00:48:34.265] iteration 5304 : loss : 0.072676, loss_ce: 0.021479
[00:48:34.573] iteration 5305 : loss : 0.100708, loss_ce: 0.026829
[00:48:34.874] iteration 5306 : loss : 0.064374, loss_ce: 0.023973
[00:48:35.187] iteration 5307 : loss : 0.056563, loss_ce: 0.014720
[00:48:35.493] iteration 5308 : loss : 0.095043, loss_ce: 0.034620
[00:48:35.812] iteration 5309 : loss : 0.059368, loss_ce: 0.019354
[00:48:36.112] iteration 5310 : loss : 0.058893, loss_ce: 0.021368
[00:48:36.420] iteration 5311 : loss : 0.084300, loss_ce: 0.034067
[00:48:36.730] iteration 5312 : loss : 0.064234, loss_ce: 0.016469
[00:48:37.032] iteration 5313 : loss : 0.052033, loss_ce: 0.009151
[00:48:37.336] iteration 5314 : loss : 0.069729, loss_ce: 0.014627
[00:48:37.648] iteration 5315 : loss : 0.094047, loss_ce: 0.025251
[00:48:37.948] iteration 5316 : loss : 0.117289, loss_ce: 0.012467
[00:48:38.254] iteration 5317 : loss : 0.050262, loss_ce: 0.014975
[00:48:38.562] iteration 5318 : loss : 0.076125, loss_ce: 0.023106
[00:48:38.864] iteration 5319 : loss : 0.144878, loss_ce: 0.018310
[00:48:39.167] iteration 5320 : loss : 0.111570, loss_ce: 0.015393
[00:48:39.488] iteration 5321 : loss : 0.083724, loss_ce: 0.023495
[00:48:39.790] iteration 5322 : loss : 0.097101, loss_ce: 0.022603
[00:48:40.102] iteration 5323 : loss : 0.074557, loss_ce: 0.018825
[00:48:40.405] iteration 5324 : loss : 0.062274, loss_ce: 0.024689
[00:48:40.716] iteration 5325 : loss : 0.100318, loss_ce: 0.026892
[00:48:41.023] iteration 5326 : loss : 0.125513, loss_ce: 0.020726
[00:48:41.333] iteration 5327 : loss : 0.083733, loss_ce: 0.022166
[00:48:41.643] iteration 5328 : loss : 0.076986, loss_ce: 0.010003
[00:48:41.955] iteration 5329 : loss : 0.062677, loss_ce: 0.026961
[00:48:42.267] iteration 5330 : loss : 0.131372, loss_ce: 0.020014
[00:48:42.570] iteration 5331 : loss : 0.110423, loss_ce: 0.015033
[00:48:42.876] iteration 5332 : loss : 0.097380, loss_ce: 0.035886
[00:48:43.179] iteration 5333 : loss : 0.098064, loss_ce: 0.034541
[00:48:43.489] iteration 5334 : loss : 0.142797, loss_ce: 0.017253
[00:48:43.791] iteration 5335 : loss : 0.083663, loss_ce: 0.017671
[00:48:44.099] iteration 5336 : loss : 0.173831, loss_ce: 0.005649
[00:48:44.406] iteration 5337 : loss : 0.097922, loss_ce: 0.024295
[00:48:44.710] iteration 5338 : loss : 0.091962, loss_ce: 0.030204
[00:48:45.014] iteration 5339 : loss : 0.097066, loss_ce: 0.020024
[00:48:45.324] iteration 5340 : loss : 0.070021, loss_ce: 0.030598
[00:48:45.649] iteration 5341 : loss : 0.088719, loss_ce: 0.017256
[00:48:45.950] iteration 5342 : loss : 0.077061, loss_ce: 0.024011
[00:48:46.261] iteration 5343 : loss : 0.074099, loss_ce: 0.026366
[00:48:46.568] iteration 5344 : loss : 0.120534, loss_ce: 0.023269
[00:48:46.881] iteration 5345 : loss : 0.068619, loss_ce: 0.016130
[00:48:47.185] iteration 5346 : loss : 0.065403, loss_ce: 0.023876
[00:48:47.487] iteration 5347 : loss : 0.070685, loss_ce: 0.018051
[00:48:47.790] iteration 5348 : loss : 0.156059, loss_ce: 0.005306
[00:48:48.100] iteration 5349 : loss : 0.074994, loss_ce: 0.021822
[00:48:48.407] iteration 5350 : loss : 0.048209, loss_ce: 0.012351
[00:48:48.718] iteration 5351 : loss : 0.123408, loss_ce: 0.005942
[00:48:49.027] iteration 5352 : loss : 0.083961, loss_ce: 0.023298
[00:48:49.331] iteration 5353 : loss : 0.078841, loss_ce: 0.025968
[00:48:49.637] iteration 5354 : loss : 0.070364, loss_ce: 0.015916
[00:48:49.943] iteration 5355 : loss : 0.106024, loss_ce: 0.023488
[00:48:50.256] iteration 5356 : loss : 0.108034, loss_ce: 0.013537
[00:48:50.568] iteration 5357 : loss : 0.091979, loss_ce: 0.036325
[00:48:50.878] iteration 5358 : loss : 0.075152, loss_ce: 0.015853
[00:48:51.190] iteration 5359 : loss : 0.119332, loss_ce: 0.014615
[00:48:51.494] iteration 5360 : loss : 0.120717, loss_ce: 0.006850
[00:48:51.818] iteration 5361 : loss : 0.111329, loss_ce: 0.024877
[00:48:52.123] iteration 5362 : loss : 0.077046, loss_ce: 0.025057
[00:48:52.434] iteration 5363 : loss : 0.064262, loss_ce: 0.021741
[00:48:52.739] iteration 5364 : loss : 0.116193, loss_ce: 0.011794
[00:48:53.041] iteration 5365 : loss : 0.075711, loss_ce: 0.021904
[00:48:53.348] iteration 5366 : loss : 0.082055, loss_ce: 0.028358
[00:48:53.664] iteration 5367 : loss : 0.062731, loss_ce: 0.023244
[00:48:53.970] iteration 5368 : loss : 0.095225, loss_ce: 0.024198
[00:48:54.281] iteration 5369 : loss : 0.065952, loss_ce: 0.023987
[00:48:54.588] iteration 5370 : loss : 0.183579, loss_ce: 0.014761
[00:48:54.893] iteration 5371 : loss : 0.071676, loss_ce: 0.018657
[00:48:55.197] iteration 5372 : loss : 0.146688, loss_ce: 0.022951
[00:48:55.509] iteration 5373 : loss : 0.129815, loss_ce: 0.012992
[00:48:55.815] iteration 5374 : loss : 0.073056, loss_ce: 0.015521
[00:48:56.120] iteration 5375 : loss : 0.095249, loss_ce: 0.023610
[00:48:56.428] iteration 5376 : loss : 0.082499, loss_ce: 0.039996
[00:48:56.731] iteration 5377 : loss : 0.091848, loss_ce: 0.027613
[00:48:57.032] iteration 5378 : loss : 0.124577, loss_ce: 0.024015
[00:48:57.344] iteration 5379 : loss : 0.117447, loss_ce: 0.017571
[00:48:57.648] iteration 5380 : loss : 0.072727, loss_ce: 0.010681
[00:48:57.974] iteration 5381 : loss : 0.066593, loss_ce: 0.020958
[00:48:58.276] iteration 5382 : loss : 0.059690, loss_ce: 0.029576
[00:48:58.587] iteration 5383 : loss : 0.093986, loss_ce: 0.033271
[00:48:58.889] iteration 5384 : loss : 0.127139, loss_ce: 0.014321
[00:48:59.201] iteration 5385 : loss : 0.062176, loss_ce: 0.027698
[00:48:59.507] iteration 5386 : loss : 0.113884, loss_ce: 0.015036
[00:48:59.810] iteration 5387 : loss : 0.086105, loss_ce: 0.020413
[00:49:00.117] iteration 5388 : loss : 0.089557, loss_ce: 0.019339
[00:49:00.431] iteration 5389 : loss : 0.080128, loss_ce: 0.030419
[00:49:00.735] iteration 5390 : loss : 0.071047, loss_ce: 0.019613
[00:49:01.050] iteration 5391 : loss : 0.059454, loss_ce: 0.019980
[00:49:01.352] iteration 5392 : loss : 0.072625, loss_ce: 0.015407
[00:49:01.655] iteration 5393 : loss : 0.074162, loss_ce: 0.016754
[00:49:01.965] iteration 5394 : loss : 0.077387, loss_ce: 0.025609
[00:49:02.267] iteration 5395 : loss : 0.063365, loss_ce: 0.027174
[00:49:02.574] iteration 5396 : loss : 0.061879, loss_ce: 0.025377
[00:49:02.891] iteration 5397 : loss : 0.075994, loss_ce: 0.026792
[00:49:03.197] iteration 5398 : loss : 0.143249, loss_ce: 0.014215
[00:49:03.505] iteration 5399 : loss : 0.123792, loss_ce: 0.020508
[00:49:03.806] iteration 5400 : loss : 0.063393, loss_ce: 0.025170
[00:49:04.132] iteration 5401 : loss : 0.087089, loss_ce: 0.022064
[00:49:04.433] iteration 5402 : loss : 0.071553, loss_ce: 0.014252
[00:49:04.738] iteration 5403 : loss : 0.126213, loss_ce: 0.017697
[00:49:05.042] iteration 5404 : loss : 0.094734, loss_ce: 0.030538
[00:49:05.351] iteration 5405 : loss : 0.121612, loss_ce: 0.017387
[00:49:05.659] iteration 5406 : loss : 0.117346, loss_ce: 0.012320
[00:49:05.968] iteration 5407 : loss : 0.108700, loss_ce: 0.011824
[00:49:06.287] iteration 5408 : loss : 0.082900, loss_ce: 0.023072
[00:49:06.595] iteration 5409 : loss : 0.098710, loss_ce: 0.018092
[00:49:06.904] iteration 5410 : loss : 0.064153, loss_ce: 0.021429
[00:49:07.221] iteration 5411 : loss : 0.067505, loss_ce: 0.026892
[00:49:07.522] iteration 5412 : loss : 0.090258, loss_ce: 0.031551
[00:49:07.836] iteration 5413 : loss : 0.075590, loss_ce: 0.018393
[00:49:08.153] iteration 5414 : loss : 0.072812, loss_ce: 0.034207
[00:49:08.474] iteration 5415 : loss : 0.062667, loss_ce: 0.017866
[00:49:08.775] iteration 5416 : loss : 0.104585, loss_ce: 0.008028
[00:49:09.088] iteration 5417 : loss : 0.084059, loss_ce: 0.031143
[00:49:09.404] iteration 5418 : loss : 0.076280, loss_ce: 0.012729
[00:49:09.720] iteration 5419 : loss : 0.119451, loss_ce: 0.007638
[00:49:10.033] iteration 5420 : loss : 0.077390, loss_ce: 0.014503
[00:49:10.142] iteration 5421 : loss : 0.350693, loss_ce: 0.009266
[00:49:27.282] iteration 5422 : loss : 0.147896, loss_ce: 0.011380
[00:49:27.591] iteration 5423 : loss : 0.088415, loss_ce: 0.022652
[00:49:27.906] iteration 5424 : loss : 0.062566, loss_ce: 0.025519
[00:49:28.217] iteration 5425 : loss : 0.070979, loss_ce: 0.024649
[00:49:28.529] iteration 5426 : loss : 0.096591, loss_ce: 0.044983
[00:49:28.835] iteration 5427 : loss : 0.155508, loss_ce: 0.009806
[00:49:29.141] iteration 5428 : loss : 0.071997, loss_ce: 0.026438
[00:49:29.444] iteration 5429 : loss : 0.067629, loss_ce: 0.027507
[00:49:29.752] iteration 5430 : loss : 0.079266, loss_ce: 0.014711
[00:49:30.055] iteration 5431 : loss : 0.123223, loss_ce: 0.023637
[00:49:30.361] iteration 5432 : loss : 0.120009, loss_ce: 0.017271
[00:49:30.666] iteration 5433 : loss : 0.082676, loss_ce: 0.020260
[00:49:30.981] iteration 5434 : loss : 0.088045, loss_ce: 0.026207
[00:49:31.282] iteration 5435 : loss : 0.108885, loss_ce: 0.033460
[00:49:31.590] iteration 5436 : loss : 0.064568, loss_ce: 0.019500
[00:49:31.903] iteration 5437 : loss : 0.131675, loss_ce: 0.004709
[00:49:32.208] iteration 5438 : loss : 0.086947, loss_ce: 0.009179
[00:49:32.509] iteration 5439 : loss : 0.069006, loss_ce: 0.033197
[00:49:32.812] iteration 5440 : loss : 0.090498, loss_ce: 0.016489
[00:49:33.135] iteration 5441 : loss : 0.082564, loss_ce: 0.036526
[00:49:33.445] iteration 5442 : loss : 0.129897, loss_ce: 0.017744
[00:49:33.750] iteration 5443 : loss : 0.113198, loss_ce: 0.019252
[00:49:34.065] iteration 5444 : loss : 0.125054, loss_ce: 0.023864
[00:49:34.375] iteration 5445 : loss : 0.137709, loss_ce: 0.020509
[00:49:34.682] iteration 5446 : loss : 0.097920, loss_ce: 0.029397
[00:49:34.986] iteration 5447 : loss : 0.060853, loss_ce: 0.019010
[00:49:35.294] iteration 5448 : loss : 0.057617, loss_ce: 0.015843
[00:49:35.603] iteration 5449 : loss : 0.142521, loss_ce: 0.020169
[00:49:35.908] iteration 5450 : loss : 0.156428, loss_ce: 0.020067
[00:49:36.216] iteration 5451 : loss : 0.073229, loss_ce: 0.028622
[00:49:36.526] iteration 5452 : loss : 0.082292, loss_ce: 0.018234
[00:49:36.835] iteration 5453 : loss : 0.072773, loss_ce: 0.017673
[00:49:37.137] iteration 5454 : loss : 0.086327, loss_ce: 0.027336
[00:49:37.447] iteration 5455 : loss : 0.133733, loss_ce: 0.009430
[00:49:37.752] iteration 5456 : loss : 0.082222, loss_ce: 0.030741
[00:49:38.063] iteration 5457 : loss : 0.075258, loss_ce: 0.017657
[00:49:38.371] iteration 5458 : loss : 0.058069, loss_ce: 0.026137
[00:49:38.683] iteration 5459 : loss : 0.078974, loss_ce: 0.021469
[00:49:38.994] iteration 5460 : loss : 0.085052, loss_ce: 0.014798
[00:49:39.321] iteration 5461 : loss : 0.073965, loss_ce: 0.019360
[00:49:39.626] iteration 5462 : loss : 0.069867, loss_ce: 0.019850
[00:49:39.935] iteration 5463 : loss : 0.057968, loss_ce: 0.021385
[00:49:40.245] iteration 5464 : loss : 0.076737, loss_ce: 0.014657
[00:49:40.547] iteration 5465 : loss : 0.077241, loss_ce: 0.032500
[00:49:40.852] iteration 5466 : loss : 0.082269, loss_ce: 0.014360
[00:49:41.159] iteration 5467 : loss : 0.079296, loss_ce: 0.022183
[00:49:41.469] iteration 5468 : loss : 0.072532, loss_ce: 0.030607
[00:49:41.772] iteration 5469 : loss : 0.221506, loss_ce: 0.019164
[00:49:42.084] iteration 5470 : loss : 0.071923, loss_ce: 0.017341
[00:49:42.387] iteration 5471 : loss : 0.060454, loss_ce: 0.017994
[00:49:42.693] iteration 5472 : loss : 0.066118, loss_ce: 0.025943
[00:49:42.993] iteration 5473 : loss : 0.083681, loss_ce: 0.033818
[00:49:43.300] iteration 5474 : loss : 0.138077, loss_ce: 0.008659
[00:49:43.606] iteration 5475 : loss : 0.081097, loss_ce: 0.018597
[00:49:43.919] iteration 5476 : loss : 0.122229, loss_ce: 0.028670
[00:49:44.230] iteration 5477 : loss : 0.062392, loss_ce: 0.015351
[00:49:44.541] iteration 5478 : loss : 0.063181, loss_ce: 0.026213
[00:49:44.847] iteration 5479 : loss : 0.074889, loss_ce: 0.017188
[00:49:45.151] iteration 5480 : loss : 0.058498, loss_ce: 0.018281
[00:49:45.473] iteration 5481 : loss : 0.140843, loss_ce: 0.017538
[00:49:45.774] iteration 5482 : loss : 0.078612, loss_ce: 0.024567
[00:49:46.077] iteration 5483 : loss : 0.100120, loss_ce: 0.022587
[00:49:46.379] iteration 5484 : loss : 0.119088, loss_ce: 0.018044
[00:49:46.692] iteration 5485 : loss : 0.111377, loss_ce: 0.011312
[00:49:46.999] iteration 5486 : loss : 0.078713, loss_ce: 0.017951
[00:49:47.307] iteration 5487 : loss : 0.058810, loss_ce: 0.024386
[00:49:47.616] iteration 5488 : loss : 0.055897, loss_ce: 0.021990
[00:49:47.918] iteration 5489 : loss : 0.053626, loss_ce: 0.012571
[00:49:48.221] iteration 5490 : loss : 0.248792, loss_ce: 0.010868
[00:49:48.536] iteration 5491 : loss : 0.115259, loss_ce: 0.022256
[00:49:48.831] iteration 5492 : loss : 0.078461, loss_ce: 0.022791
[00:49:49.137] iteration 5493 : loss : 0.074548, loss_ce: 0.021566
[00:49:49.444] iteration 5494 : loss : 0.070205, loss_ce: 0.019006
[00:49:49.748] iteration 5495 : loss : 0.083628, loss_ce: 0.031262
[00:49:50.053] iteration 5496 : loss : 0.124386, loss_ce: 0.015923
[00:49:50.359] iteration 5497 : loss : 0.056622, loss_ce: 0.014463
[00:49:50.667] iteration 5498 : loss : 0.057161, loss_ce: 0.014038
[00:49:50.965] iteration 5499 : loss : 0.181198, loss_ce: 0.010391
[00:49:51.265] iteration 5500 : loss : 0.060729, loss_ce: 0.015387
[00:49:51.601] iteration 5501 : loss : 0.113558, loss_ce: 0.031870
[00:49:51.898] iteration 5502 : loss : 0.071490, loss_ce: 0.019694
[00:49:52.202] iteration 5503 : loss : 0.248006, loss_ce: 0.013058
[00:49:52.507] iteration 5504 : loss : 0.079926, loss_ce: 0.024969
[00:49:52.809] iteration 5505 : loss : 0.073959, loss_ce: 0.032675
[00:49:53.114] iteration 5506 : loss : 0.099382, loss_ce: 0.015157
[00:49:53.420] iteration 5507 : loss : 0.081166, loss_ce: 0.029305
[00:49:53.733] iteration 5508 : loss : 0.077908, loss_ce: 0.038134
[00:49:54.037] iteration 5509 : loss : 0.148253, loss_ce: 0.012123
[00:49:54.339] iteration 5510 : loss : 0.067747, loss_ce: 0.016686
[00:49:54.647] iteration 5511 : loss : 0.120314, loss_ce: 0.008132
[00:49:54.960] iteration 5512 : loss : 0.073940, loss_ce: 0.020990
[00:49:55.257] iteration 5513 : loss : 0.071353, loss_ce: 0.036599
[00:49:55.564] iteration 5514 : loss : 0.056581, loss_ce: 0.012499
[00:49:55.876] iteration 5515 : loss : 0.053330, loss_ce: 0.015585
[00:49:56.182] iteration 5516 : loss : 0.144413, loss_ce: 0.016414
[00:49:56.484] iteration 5517 : loss : 0.062229, loss_ce: 0.020234
[00:49:56.791] iteration 5518 : loss : 0.065394, loss_ce: 0.016001
[00:49:57.101] iteration 5519 : loss : 0.068524, loss_ce: 0.028480
[00:49:57.397] iteration 5520 : loss : 0.092004, loss_ce: 0.021201
[00:49:57.715] iteration 5521 : loss : 0.090855, loss_ce: 0.009959
[00:49:58.020] iteration 5522 : loss : 0.142235, loss_ce: 0.016264
[00:49:58.329] iteration 5523 : loss : 0.127336, loss_ce: 0.010319
[00:49:58.636] iteration 5524 : loss : 0.077167, loss_ce: 0.029745
[00:49:58.947] iteration 5525 : loss : 0.073899, loss_ce: 0.021135
[00:49:59.251] iteration 5526 : loss : 0.065579, loss_ce: 0.017789
[00:49:59.558] iteration 5527 : loss : 0.071097, loss_ce: 0.022537
[00:49:59.867] iteration 5528 : loss : 0.123560, loss_ce: 0.017382
[00:50:00.178] iteration 5529 : loss : 0.073626, loss_ce: 0.023775
[00:50:00.483] iteration 5530 : loss : 0.085644, loss_ce: 0.020327
[00:50:00.786] iteration 5531 : loss : 0.228862, loss_ce: 0.009841
[00:50:01.099] iteration 5532 : loss : 0.071704, loss_ce: 0.029140
[00:50:01.413] iteration 5533 : loss : 0.134382, loss_ce: 0.014176
[00:50:01.728] iteration 5534 : loss : 0.133285, loss_ce: 0.024480
[00:50:02.027] iteration 5535 : loss : 0.124691, loss_ce: 0.020385
[00:50:02.333] iteration 5536 : loss : 0.059269, loss_ce: 0.025560
[00:50:02.639] iteration 5537 : loss : 0.075998, loss_ce: 0.021042
[00:50:02.959] iteration 5538 : loss : 0.063483, loss_ce: 0.025675
[00:50:03.263] iteration 5539 : loss : 0.077205, loss_ce: 0.024146
[00:50:03.570] iteration 5540 : loss : 0.115113, loss_ce: 0.017840
[00:50:03.894] iteration 5541 : loss : 0.059243, loss_ce: 0.022846
[00:50:04.196] iteration 5542 : loss : 0.065116, loss_ce: 0.019430
[00:50:04.501] iteration 5543 : loss : 0.085549, loss_ce: 0.044760
[00:50:04.815] iteration 5544 : loss : 0.082448, loss_ce: 0.025350
[00:50:05.130] iteration 5545 : loss : 0.126235, loss_ce: 0.018990
[00:50:05.438] iteration 5546 : loss : 0.074320, loss_ce: 0.016311
[00:50:05.743] iteration 5547 : loss : 0.099627, loss_ce: 0.020579
[00:50:06.051] iteration 5548 : loss : 0.087826, loss_ce: 0.015613
[00:50:06.367] iteration 5549 : loss : 0.068497, loss_ce: 0.017597
[00:50:06.666] iteration 5550 : loss : 0.077176, loss_ce: 0.025144
[00:50:06.984] iteration 5551 : loss : 0.058217, loss_ce: 0.018151
[00:50:07.296] iteration 5552 : loss : 0.111282, loss_ce: 0.012075
[00:50:07.608] iteration 5553 : loss : 0.068694, loss_ce: 0.019220
[00:50:07.923] iteration 5554 : loss : 0.092000, loss_ce: 0.021204
[00:50:08.231] iteration 5555 : loss : 0.084250, loss_ce: 0.023969
[00:50:08.545] iteration 5556 : loss : 0.070048, loss_ce: 0.029082
[00:50:08.856] iteration 5557 : loss : 0.091918, loss_ce: 0.020176
[00:50:09.166] iteration 5558 : loss : 0.132709, loss_ce: 0.019914
[00:50:09.481] iteration 5559 : loss : 0.078203, loss_ce: 0.023210
[00:50:09.558] iteration 5560 : loss : 0.136541, loss_ce: 0.029376
[00:50:28.632] iteration 5561 : loss : 0.071452, loss_ce: 0.028761
[00:50:28.939] iteration 5562 : loss : 0.071636, loss_ce: 0.034263
[00:50:29.250] iteration 5563 : loss : 0.066202, loss_ce: 0.019389
[00:50:29.556] iteration 5564 : loss : 0.073749, loss_ce: 0.026244
[00:50:29.858] iteration 5565 : loss : 0.067672, loss_ce: 0.028449
[00:50:30.165] iteration 5566 : loss : 0.078989, loss_ce: 0.018882
[00:50:30.461] iteration 5567 : loss : 0.066675, loss_ce: 0.016155
[00:50:30.768] iteration 5568 : loss : 0.059416, loss_ce: 0.013103
[00:50:31.072] iteration 5569 : loss : 0.088049, loss_ce: 0.015849
[00:50:31.375] iteration 5570 : loss : 0.118834, loss_ce: 0.023640
[00:50:31.682] iteration 5571 : loss : 0.081347, loss_ce: 0.019101
[00:50:31.983] iteration 5572 : loss : 0.071556, loss_ce: 0.027529
[00:50:32.293] iteration 5573 : loss : 0.065826, loss_ce: 0.035550
[00:50:32.597] iteration 5574 : loss : 0.063622, loss_ce: 0.019263
[00:50:32.897] iteration 5575 : loss : 0.145425, loss_ce: 0.023012
[00:50:33.204] iteration 5576 : loss : 0.065567, loss_ce: 0.027301
[00:50:33.508] iteration 5577 : loss : 0.066305, loss_ce: 0.021734
[00:50:33.811] iteration 5578 : loss : 0.202688, loss_ce: 0.008328
[00:50:34.111] iteration 5579 : loss : 0.070889, loss_ce: 0.026866
[00:50:34.413] iteration 5580 : loss : 0.080559, loss_ce: 0.022318
[00:50:34.729] iteration 5581 : loss : 0.080154, loss_ce: 0.017643
[00:50:35.036] iteration 5582 : loss : 0.118440, loss_ce: 0.021188
[00:50:35.337] iteration 5583 : loss : 0.138822, loss_ce: 0.014202
[00:50:35.642] iteration 5584 : loss : 0.075936, loss_ce: 0.021862
[00:50:35.943] iteration 5585 : loss : 0.095456, loss_ce: 0.023646
[00:50:36.250] iteration 5586 : loss : 0.073099, loss_ce: 0.016825
[00:50:36.560] iteration 5587 : loss : 0.064632, loss_ce: 0.027314
[00:50:36.864] iteration 5588 : loss : 0.069091, loss_ce: 0.023643
[00:50:37.167] iteration 5589 : loss : 0.311827, loss_ce: 0.005599
[00:50:37.482] iteration 5590 : loss : 0.065145, loss_ce: 0.021343
[00:50:37.785] iteration 5591 : loss : 0.074408, loss_ce: 0.020656
[00:50:38.099] iteration 5592 : loss : 0.071880, loss_ce: 0.016497
[00:50:38.395] iteration 5593 : loss : 0.097085, loss_ce: 0.012118
[00:50:38.701] iteration 5594 : loss : 0.113630, loss_ce: 0.021286
[00:50:39.017] iteration 5595 : loss : 0.162932, loss_ce: 0.015044
[00:50:39.325] iteration 5596 : loss : 0.079278, loss_ce: 0.027931
[00:50:39.628] iteration 5597 : loss : 0.126055, loss_ce: 0.027614
[00:50:39.929] iteration 5598 : loss : 0.084712, loss_ce: 0.023032
[00:50:40.231] iteration 5599 : loss : 0.083093, loss_ce: 0.019460
[00:50:40.542] iteration 5600 : loss : 0.075525, loss_ce: 0.014752
[00:50:40.862] iteration 5601 : loss : 0.118008, loss_ce: 0.038193
[00:50:41.166] iteration 5602 : loss : 0.109534, loss_ce: 0.018728
[00:50:41.470] iteration 5603 : loss : 0.108289, loss_ce: 0.017217
[00:50:41.779] iteration 5604 : loss : 0.080628, loss_ce: 0.028982
[00:50:42.078] iteration 5605 : loss : 0.097314, loss_ce: 0.023069
[00:50:42.385] iteration 5606 : loss : 0.142053, loss_ce: 0.023557
[00:50:42.688] iteration 5607 : loss : 0.072193, loss_ce: 0.022043
[00:50:42.999] iteration 5608 : loss : 0.096409, loss_ce: 0.032233
[00:50:43.302] iteration 5609 : loss : 0.054354, loss_ce: 0.013799
[00:50:43.611] iteration 5610 : loss : 0.178764, loss_ce: 0.020493
[00:50:43.915] iteration 5611 : loss : 0.116102, loss_ce: 0.014990
[00:50:44.221] iteration 5612 : loss : 0.078222, loss_ce: 0.032388
[00:50:44.529] iteration 5613 : loss : 0.082458, loss_ce: 0.031500
[00:50:44.831] iteration 5614 : loss : 0.077157, loss_ce: 0.025379
[00:50:45.138] iteration 5615 : loss : 0.081531, loss_ce: 0.022537
[00:50:45.447] iteration 5616 : loss : 0.064715, loss_ce: 0.025911
[00:50:45.751] iteration 5617 : loss : 0.098453, loss_ce: 0.015793
[00:50:46.053] iteration 5618 : loss : 0.078108, loss_ce: 0.021571
[00:50:46.363] iteration 5619 : loss : 0.074286, loss_ce: 0.017121
[00:50:46.671] iteration 5620 : loss : 0.073400, loss_ce: 0.036592
[00:50:47.012] iteration 5621 : loss : 0.099517, loss_ce: 0.029367
[00:50:47.317] iteration 5622 : loss : 0.078527, loss_ce: 0.034103
[00:50:47.626] iteration 5623 : loss : 0.177863, loss_ce: 0.010746
[00:50:47.926] iteration 5624 : loss : 0.082283, loss_ce: 0.032530
[00:50:48.230] iteration 5625 : loss : 0.061312, loss_ce: 0.020225
[00:50:48.538] iteration 5626 : loss : 0.143394, loss_ce: 0.026589
[00:50:48.847] iteration 5627 : loss : 0.108847, loss_ce: 0.021008
[00:50:49.149] iteration 5628 : loss : 0.074144, loss_ce: 0.023818
[00:50:49.452] iteration 5629 : loss : 0.048429, loss_ce: 0.013249
[00:50:49.758] iteration 5630 : loss : 0.065284, loss_ce: 0.015949
[00:50:50.067] iteration 5631 : loss : 0.096834, loss_ce: 0.025247
[00:50:50.373] iteration 5632 : loss : 0.079381, loss_ce: 0.034505
[00:50:50.678] iteration 5633 : loss : 0.088837, loss_ce: 0.016790
[00:50:50.989] iteration 5634 : loss : 0.075324, loss_ce: 0.030597
[00:50:51.296] iteration 5635 : loss : 0.091971, loss_ce: 0.042584
[00:50:51.602] iteration 5636 : loss : 0.046222, loss_ce: 0.017261
[00:50:51.904] iteration 5637 : loss : 0.063803, loss_ce: 0.019694
[00:50:52.211] iteration 5638 : loss : 0.092194, loss_ce: 0.024928
[00:50:52.508] iteration 5639 : loss : 0.075943, loss_ce: 0.033693
[00:50:52.812] iteration 5640 : loss : 0.062267, loss_ce: 0.021934
[00:50:53.133] iteration 5641 : loss : 0.097205, loss_ce: 0.020190
[00:50:53.440] iteration 5642 : loss : 0.072208, loss_ce: 0.023800
[00:50:53.748] iteration 5643 : loss : 0.092924, loss_ce: 0.026998
[00:50:54.054] iteration 5644 : loss : 0.074198, loss_ce: 0.018630
[00:50:54.359] iteration 5645 : loss : 0.065853, loss_ce: 0.016437
[00:50:54.662] iteration 5646 : loss : 0.056386, loss_ce: 0.019785
[00:50:54.966] iteration 5647 : loss : 0.065320, loss_ce: 0.015698
[00:50:55.275] iteration 5648 : loss : 0.133966, loss_ce: 0.027287
[00:50:55.581] iteration 5649 : loss : 0.068309, loss_ce: 0.012504
[00:50:55.890] iteration 5650 : loss : 0.063118, loss_ce: 0.025171
[00:50:56.189] iteration 5651 : loss : 0.069410, loss_ce: 0.014802
[00:50:56.496] iteration 5652 : loss : 0.138247, loss_ce: 0.014480
[00:50:56.802] iteration 5653 : loss : 0.065246, loss_ce: 0.014373
[00:50:57.108] iteration 5654 : loss : 0.136745, loss_ce: 0.012214
[00:50:57.415] iteration 5655 : loss : 0.087249, loss_ce: 0.023054
[00:50:57.722] iteration 5656 : loss : 0.154387, loss_ce: 0.027123
[00:50:58.027] iteration 5657 : loss : 0.065244, loss_ce: 0.023058
[00:50:58.335] iteration 5658 : loss : 0.083072, loss_ce: 0.014155
[00:50:58.639] iteration 5659 : loss : 0.099766, loss_ce: 0.018409
[00:50:58.945] iteration 5660 : loss : 0.069402, loss_ce: 0.014776
[00:50:59.277] iteration 5661 : loss : 0.088642, loss_ce: 0.017740
[00:50:59.581] iteration 5662 : loss : 0.066852, loss_ce: 0.021270
[00:50:59.879] iteration 5663 : loss : 0.083537, loss_ce: 0.017930
[00:51:00.192] iteration 5664 : loss : 0.069549, loss_ce: 0.027480
[00:51:00.498] iteration 5665 : loss : 0.090163, loss_ce: 0.022197
[00:51:00.809] iteration 5666 : loss : 0.103412, loss_ce: 0.015894
[00:51:01.121] iteration 5667 : loss : 0.135079, loss_ce: 0.021265
[00:51:01.424] iteration 5668 : loss : 0.157856, loss_ce: 0.024718
[00:51:01.725] iteration 5669 : loss : 0.083757, loss_ce: 0.012725
[00:51:02.033] iteration 5670 : loss : 0.180860, loss_ce: 0.010878
[00:51:02.335] iteration 5671 : loss : 0.069095, loss_ce: 0.023821
[00:51:02.644] iteration 5672 : loss : 0.049420, loss_ce: 0.009458
[00:51:02.949] iteration 5673 : loss : 0.235080, loss_ce: 0.014788
[00:51:03.251] iteration 5674 : loss : 0.064258, loss_ce: 0.029732
[00:51:03.557] iteration 5675 : loss : 0.075695, loss_ce: 0.029003
[00:51:03.862] iteration 5676 : loss : 0.095361, loss_ce: 0.022257
[00:51:04.170] iteration 5677 : loss : 0.137166, loss_ce: 0.023914
[00:51:04.469] iteration 5678 : loss : 0.105731, loss_ce: 0.019643
[00:51:04.784] iteration 5679 : loss : 0.141221, loss_ce: 0.009312
[00:51:05.099] iteration 5680 : loss : 0.123402, loss_ce: 0.019431
[00:51:05.438] iteration 5681 : loss : 0.098786, loss_ce: 0.018064
[00:51:05.744] iteration 5682 : loss : 0.063965, loss_ce: 0.030082
[00:51:06.051] iteration 5683 : loss : 0.291887, loss_ce: 0.015976
[00:51:06.355] iteration 5684 : loss : 0.095565, loss_ce: 0.031796
[00:51:06.668] iteration 5685 : loss : 0.085279, loss_ce: 0.028992
[00:51:06.982] iteration 5686 : loss : 0.080485, loss_ce: 0.038497
[00:51:07.301] iteration 5687 : loss : 0.187523, loss_ce: 0.015104
[00:51:07.607] iteration 5688 : loss : 0.078940, loss_ce: 0.015100
[00:51:07.919] iteration 5689 : loss : 0.084747, loss_ce: 0.022393
[00:51:08.233] iteration 5690 : loss : 0.133814, loss_ce: 0.012902
[00:51:08.540] iteration 5691 : loss : 0.125711, loss_ce: 0.014192
[00:51:08.858] iteration 5692 : loss : 0.094295, loss_ce: 0.027968
[00:51:09.161] iteration 5693 : loss : 0.066686, loss_ce: 0.015539
[00:51:09.464] iteration 5694 : loss : 0.132973, loss_ce: 0.022461
[00:51:09.783] iteration 5695 : loss : 0.099530, loss_ce: 0.033232
[00:51:10.090] iteration 5696 : loss : 0.130451, loss_ce: 0.017748
[00:51:10.397] iteration 5697 : loss : 0.087432, loss_ce: 0.017144
[00:51:10.708] iteration 5698 : loss : 0.128975, loss_ce: 0.030878
[00:51:10.792] iteration 5699 : loss : 0.312398, loss_ce: 0.024034
[00:51:27.350] iteration 5700 : loss : 0.098040, loss_ce: 0.025038
[00:51:27.689] iteration 5701 : loss : 0.086866, loss_ce: 0.014997
[00:51:27.997] iteration 5702 : loss : 0.077747, loss_ce: 0.032048
[00:51:28.306] iteration 5703 : loss : 0.071713, loss_ce: 0.015925
[00:51:28.625] iteration 5704 : loss : 0.075247, loss_ce: 0.029054
[00:51:28.927] iteration 5705 : loss : 0.093236, loss_ce: 0.009046
[00:51:29.243] iteration 5706 : loss : 0.080524, loss_ce: 0.013883
[00:51:29.550] iteration 5707 : loss : 0.068501, loss_ce: 0.024913
[00:51:29.855] iteration 5708 : loss : 0.106158, loss_ce: 0.029420
[00:51:30.162] iteration 5709 : loss : 0.121110, loss_ce: 0.016073
[00:51:30.474] iteration 5710 : loss : 0.068384, loss_ce: 0.014165
[00:51:30.778] iteration 5711 : loss : 0.086651, loss_ce: 0.027363
[00:51:31.090] iteration 5712 : loss : 0.129239, loss_ce: 0.013488
[00:51:31.392] iteration 5713 : loss : 0.098488, loss_ce: 0.022537
[00:51:31.704] iteration 5714 : loss : 0.133643, loss_ce: 0.015967
[00:51:32.009] iteration 5715 : loss : 0.122099, loss_ce: 0.022693
[00:51:32.318] iteration 5716 : loss : 0.091317, loss_ce: 0.031399
[00:51:32.618] iteration 5717 : loss : 0.130781, loss_ce: 0.026943
[00:51:32.930] iteration 5718 : loss : 0.071422, loss_ce: 0.015563
[00:51:33.249] iteration 5719 : loss : 0.072450, loss_ce: 0.019555
[00:51:33.553] iteration 5720 : loss : 0.078069, loss_ce: 0.018372
[00:51:33.879] iteration 5721 : loss : 0.063448, loss_ce: 0.016180
[00:51:34.189] iteration 5722 : loss : 0.076728, loss_ce: 0.019109
[00:51:34.501] iteration 5723 : loss : 0.071717, loss_ce: 0.014068
[00:51:34.810] iteration 5724 : loss : 0.297604, loss_ce: 0.011868
[00:51:35.119] iteration 5725 : loss : 0.094380, loss_ce: 0.026023
[00:51:35.428] iteration 5726 : loss : 0.077064, loss_ce: 0.034559
[00:51:35.736] iteration 5727 : loss : 0.061410, loss_ce: 0.018632
[00:51:36.047] iteration 5728 : loss : 0.060054, loss_ce: 0.020924
[00:51:36.355] iteration 5729 : loss : 0.104768, loss_ce: 0.013212
[00:51:36.661] iteration 5730 : loss : 0.112618, loss_ce: 0.029551
[00:51:36.963] iteration 5731 : loss : 0.075698, loss_ce: 0.036256
[00:51:37.275] iteration 5732 : loss : 0.118785, loss_ce: 0.018537
[00:51:37.578] iteration 5733 : loss : 0.102351, loss_ce: 0.015666
[00:51:37.891] iteration 5734 : loss : 0.079200, loss_ce: 0.015336
[00:51:38.205] iteration 5735 : loss : 0.087025, loss_ce: 0.032403
[00:51:38.514] iteration 5736 : loss : 0.079246, loss_ce: 0.027458
[00:51:38.825] iteration 5737 : loss : 0.065194, loss_ce: 0.025666
[00:51:39.132] iteration 5738 : loss : 0.074975, loss_ce: 0.029653
[00:51:39.441] iteration 5739 : loss : 0.112783, loss_ce: 0.026991
[00:51:39.745] iteration 5740 : loss : 0.178336, loss_ce: 0.016889
[00:51:40.072] iteration 5741 : loss : 0.061116, loss_ce: 0.013716
[00:51:40.382] iteration 5742 : loss : 0.093451, loss_ce: 0.028320
[00:51:40.688] iteration 5743 : loss : 0.092504, loss_ce: 0.026090
[00:51:40.994] iteration 5744 : loss : 0.131758, loss_ce: 0.007559
[00:51:41.303] iteration 5745 : loss : 0.238884, loss_ce: 0.005700
[00:51:41.627] iteration 5746 : loss : 0.085522, loss_ce: 0.029297
[00:51:41.933] iteration 5747 : loss : 0.083176, loss_ce: 0.019999
[00:51:42.237] iteration 5748 : loss : 0.073758, loss_ce: 0.014138
[00:51:42.550] iteration 5749 : loss : 0.078396, loss_ce: 0.026195
[00:51:42.864] iteration 5750 : loss : 0.076174, loss_ce: 0.017899
[00:51:43.166] iteration 5751 : loss : 0.060613, loss_ce: 0.012326
[00:51:43.474] iteration 5752 : loss : 0.082236, loss_ce: 0.024456
[00:51:43.791] iteration 5753 : loss : 0.124051, loss_ce: 0.010352
[00:51:44.098] iteration 5754 : loss : 0.060514, loss_ce: 0.019841
[00:51:44.404] iteration 5755 : loss : 0.067390, loss_ce: 0.018232
[00:51:44.710] iteration 5756 : loss : 0.294688, loss_ce: 0.017208
[00:51:45.014] iteration 5757 : loss : 0.085201, loss_ce: 0.037244
[00:51:45.322] iteration 5758 : loss : 0.126710, loss_ce: 0.023753
[00:51:45.629] iteration 5759 : loss : 0.060438, loss_ce: 0.020897
[00:51:45.932] iteration 5760 : loss : 0.173118, loss_ce: 0.006396
[00:51:46.259] iteration 5761 : loss : 0.088404, loss_ce: 0.028465
[00:51:46.565] iteration 5762 : loss : 0.055179, loss_ce: 0.016773
[00:51:46.870] iteration 5763 : loss : 0.065128, loss_ce: 0.018054
[00:51:47.178] iteration 5764 : loss : 0.075557, loss_ce: 0.009103
[00:51:47.478] iteration 5765 : loss : 0.093134, loss_ce: 0.027397
[00:51:47.785] iteration 5766 : loss : 0.057866, loss_ce: 0.016693
[00:51:48.101] iteration 5767 : loss : 0.061624, loss_ce: 0.021648
[00:51:48.404] iteration 5768 : loss : 0.114894, loss_ce: 0.021395
[00:51:48.715] iteration 5769 : loss : 0.064442, loss_ce: 0.026040
[00:51:49.018] iteration 5770 : loss : 0.077810, loss_ce: 0.023673
[00:51:49.329] iteration 5771 : loss : 0.091862, loss_ce: 0.031139
[00:51:49.636] iteration 5772 : loss : 0.134568, loss_ce: 0.021946
[00:51:49.938] iteration 5773 : loss : 0.131862, loss_ce: 0.008257
[00:51:50.240] iteration 5774 : loss : 0.079470, loss_ce: 0.021861
[00:51:50.552] iteration 5775 : loss : 0.071317, loss_ce: 0.027697
[00:51:50.858] iteration 5776 : loss : 0.060916, loss_ce: 0.020268
[00:51:51.169] iteration 5777 : loss : 0.075054, loss_ce: 0.030728
[00:51:51.473] iteration 5778 : loss : 0.078352, loss_ce: 0.025001
[00:51:51.786] iteration 5779 : loss : 0.101503, loss_ce: 0.024076
[00:51:52.096] iteration 5780 : loss : 0.084459, loss_ce: 0.017363
[00:51:52.420] iteration 5781 : loss : 0.064049, loss_ce: 0.025911
[00:51:52.723] iteration 5782 : loss : 0.060266, loss_ce: 0.016563
[00:51:53.036] iteration 5783 : loss : 0.107904, loss_ce: 0.018230
[00:51:53.341] iteration 5784 : loss : 0.066570, loss_ce: 0.016499
[00:51:53.652] iteration 5785 : loss : 0.061700, loss_ce: 0.029295
[00:51:53.955] iteration 5786 : loss : 0.112179, loss_ce: 0.014167
[00:51:54.260] iteration 5787 : loss : 0.085220, loss_ce: 0.024143
[00:51:54.564] iteration 5788 : loss : 0.082546, loss_ce: 0.030663
[00:51:54.871] iteration 5789 : loss : 0.059476, loss_ce: 0.022830
[00:51:55.177] iteration 5790 : loss : 0.077189, loss_ce: 0.028700
[00:51:55.493] iteration 5791 : loss : 0.177270, loss_ce: 0.025428
[00:51:55.803] iteration 5792 : loss : 0.053837, loss_ce: 0.016364
[00:51:56.106] iteration 5793 : loss : 0.059931, loss_ce: 0.016539
[00:51:56.419] iteration 5794 : loss : 0.148813, loss_ce: 0.028845
[00:51:56.729] iteration 5795 : loss : 0.137420, loss_ce: 0.015133
[00:51:57.032] iteration 5796 : loss : 0.112405, loss_ce: 0.014276
[00:51:57.349] iteration 5797 : loss : 0.055817, loss_ce: 0.015075
[00:51:57.664] iteration 5798 : loss : 0.091214, loss_ce: 0.014654
[00:51:57.969] iteration 5799 : loss : 0.073349, loss_ce: 0.014095
[00:51:58.275] iteration 5800 : loss : 0.082657, loss_ce: 0.015008
[00:51:58.609] iteration 5801 : loss : 0.129832, loss_ce: 0.025695
[00:51:58.909] iteration 5802 : loss : 0.055829, loss_ce: 0.016919
[00:51:59.220] iteration 5803 : loss : 0.081720, loss_ce: 0.032400
[00:51:59.527] iteration 5804 : loss : 0.196479, loss_ce: 0.014101
[00:51:59.830] iteration 5805 : loss : 0.084474, loss_ce: 0.013514
[00:52:00.137] iteration 5806 : loss : 0.130860, loss_ce: 0.028092
[00:52:00.444] iteration 5807 : loss : 0.077389, loss_ce: 0.022899
[00:52:00.749] iteration 5808 : loss : 0.063775, loss_ce: 0.019025
[00:52:01.064] iteration 5809 : loss : 0.123630, loss_ce: 0.012846
[00:52:01.372] iteration 5810 : loss : 0.050646, loss_ce: 0.017198
[00:52:01.680] iteration 5811 : loss : 0.128027, loss_ce: 0.017909
[00:52:01.985] iteration 5812 : loss : 0.074271, loss_ce: 0.018550
[00:52:02.289] iteration 5813 : loss : 0.088330, loss_ce: 0.019410
[00:52:02.595] iteration 5814 : loss : 0.183168, loss_ce: 0.009151
[00:52:02.906] iteration 5815 : loss : 0.123194, loss_ce: 0.019321
[00:52:03.216] iteration 5816 : loss : 0.088056, loss_ce: 0.017046
[00:52:03.525] iteration 5817 : loss : 0.119470, loss_ce: 0.013398
[00:52:03.828] iteration 5818 : loss : 0.066709, loss_ce: 0.013731
[00:52:04.143] iteration 5819 : loss : 0.063601, loss_ce: 0.014436
[00:52:04.455] iteration 5820 : loss : 0.086811, loss_ce: 0.016244
[00:52:04.782] iteration 5821 : loss : 0.101377, loss_ce: 0.023563
[00:52:05.093] iteration 5822 : loss : 0.113589, loss_ce: 0.027049
[00:52:05.394] iteration 5823 : loss : 0.064226, loss_ce: 0.017108
[00:52:05.710] iteration 5824 : loss : 0.080638, loss_ce: 0.031584
[00:52:06.019] iteration 5825 : loss : 0.093524, loss_ce: 0.028270
[00:52:06.330] iteration 5826 : loss : 0.100734, loss_ce: 0.031794
[00:52:06.631] iteration 5827 : loss : 0.075388, loss_ce: 0.036110
[00:52:06.947] iteration 5828 : loss : 0.070533, loss_ce: 0.015660
[00:52:07.263] iteration 5829 : loss : 0.066996, loss_ce: 0.016687
[00:52:07.569] iteration 5830 : loss : 0.123423, loss_ce: 0.014555
[00:52:07.881] iteration 5831 : loss : 0.066978, loss_ce: 0.028543
[00:52:08.189] iteration 5832 : loss : 0.063630, loss_ce: 0.028403
[00:52:08.502] iteration 5833 : loss : 0.090988, loss_ce: 0.018690
[00:52:08.816] iteration 5834 : loss : 0.079481, loss_ce: 0.023294
[00:52:09.123] iteration 5835 : loss : 0.059021, loss_ce: 0.014374
[00:52:09.441] iteration 5836 : loss : 0.085637, loss_ce: 0.049364
[00:52:09.742] iteration 5837 : loss : 0.092342, loss_ce: 0.019809
[00:52:09.822] iteration 5838 : loss : 0.305505, loss_ce: 0.022008
[00:52:29.254] iteration 5839 : loss : 0.070340, loss_ce: 0.019540
[00:52:29.558] iteration 5840 : loss : 0.137731, loss_ce: 0.018627
[00:52:29.888] iteration 5841 : loss : 0.062989, loss_ce: 0.028385
[00:52:30.186] iteration 5842 : loss : 0.077531, loss_ce: 0.023155
[00:52:30.493] iteration 5843 : loss : 0.077379, loss_ce: 0.025395
[00:52:30.797] iteration 5844 : loss : 0.086865, loss_ce: 0.031146
[00:52:31.112] iteration 5845 : loss : 0.068792, loss_ce: 0.018260
[00:52:31.422] iteration 5846 : loss : 0.064389, loss_ce: 0.016846
[00:52:31.727] iteration 5847 : loss : 0.117093, loss_ce: 0.007386
[00:52:32.032] iteration 5848 : loss : 0.075196, loss_ce: 0.031742
[00:52:32.343] iteration 5849 : loss : 0.093407, loss_ce: 0.010423
[00:52:32.643] iteration 5850 : loss : 0.114556, loss_ce: 0.014929
[00:52:32.950] iteration 5851 : loss : 0.071418, loss_ce: 0.028315
[00:52:33.251] iteration 5852 : loss : 0.073715, loss_ce: 0.023237
[00:52:33.563] iteration 5853 : loss : 0.124973, loss_ce: 0.012447
[00:52:33.865] iteration 5854 : loss : 0.062128, loss_ce: 0.011511
[00:52:34.166] iteration 5855 : loss : 0.226592, loss_ce: 0.019660
[00:52:34.469] iteration 5856 : loss : 0.066821, loss_ce: 0.027924
[00:52:34.774] iteration 5857 : loss : 0.071634, loss_ce: 0.029051
[00:52:35.074] iteration 5858 : loss : 0.062184, loss_ce: 0.011367
[00:52:35.381] iteration 5859 : loss : 0.115291, loss_ce: 0.020624
[00:52:35.688] iteration 5860 : loss : 0.070803, loss_ce: 0.020220
[00:52:36.017] iteration 5861 : loss : 0.105086, loss_ce: 0.013469
[00:52:36.318] iteration 5862 : loss : 0.078962, loss_ce: 0.010695
[00:52:36.627] iteration 5863 : loss : 0.063686, loss_ce: 0.020320
[00:52:36.933] iteration 5864 : loss : 0.064512, loss_ce: 0.027452
[00:52:37.242] iteration 5865 : loss : 0.053359, loss_ce: 0.018103
[00:52:37.551] iteration 5866 : loss : 0.178606, loss_ce: 0.011375
[00:52:37.853] iteration 5867 : loss : 0.063613, loss_ce: 0.030280
[00:52:38.162] iteration 5868 : loss : 0.078213, loss_ce: 0.024795
[00:52:38.471] iteration 5869 : loss : 0.066874, loss_ce: 0.025505
[00:52:38.774] iteration 5870 : loss : 0.079293, loss_ce: 0.030413
[00:52:39.075] iteration 5871 : loss : 0.073305, loss_ce: 0.021655
[00:52:39.383] iteration 5872 : loss : 0.089776, loss_ce: 0.030508
[00:52:39.696] iteration 5873 : loss : 0.113993, loss_ce: 0.008980
[00:52:40.010] iteration 5874 : loss : 0.051885, loss_ce: 0.017827
[00:52:40.317] iteration 5875 : loss : 0.050081, loss_ce: 0.024794
[00:52:40.617] iteration 5876 : loss : 0.057784, loss_ce: 0.016112
[00:52:40.930] iteration 5877 : loss : 0.064797, loss_ce: 0.021416
[00:52:41.236] iteration 5878 : loss : 0.084147, loss_ce: 0.015570
[00:52:41.539] iteration 5879 : loss : 0.128683, loss_ce: 0.033173
[00:52:41.851] iteration 5880 : loss : 0.096284, loss_ce: 0.020968
[00:52:42.181] iteration 5881 : loss : 0.086295, loss_ce: 0.027428
[00:52:42.482] iteration 5882 : loss : 0.068016, loss_ce: 0.008723
[00:52:42.790] iteration 5883 : loss : 0.050985, loss_ce: 0.012744
[00:52:43.097] iteration 5884 : loss : 0.087527, loss_ce: 0.017372
[00:52:43.402] iteration 5885 : loss : 0.059912, loss_ce: 0.018218
[00:52:43.720] iteration 5886 : loss : 0.068789, loss_ce: 0.029057
[00:52:44.024] iteration 5887 : loss : 0.061008, loss_ce: 0.022212
[00:52:44.325] iteration 5888 : loss : 0.091874, loss_ce: 0.023024
[00:52:44.634] iteration 5889 : loss : 0.074889, loss_ce: 0.015528
[00:52:44.935] iteration 5890 : loss : 0.171313, loss_ce: 0.013193
[00:52:45.243] iteration 5891 : loss : 0.175353, loss_ce: 0.015587
[00:52:45.546] iteration 5892 : loss : 0.113850, loss_ce: 0.005903
[00:52:45.858] iteration 5893 : loss : 0.112421, loss_ce: 0.016278
[00:52:46.168] iteration 5894 : loss : 0.064375, loss_ce: 0.012885
[00:52:46.470] iteration 5895 : loss : 0.116727, loss_ce: 0.020494
[00:52:46.772] iteration 5896 : loss : 0.121957, loss_ce: 0.009846
[00:52:47.076] iteration 5897 : loss : 0.066284, loss_ce: 0.017786
[00:52:47.378] iteration 5898 : loss : 0.112183, loss_ce: 0.019627
[00:52:47.686] iteration 5899 : loss : 0.097252, loss_ce: 0.010932
[00:52:47.991] iteration 5900 : loss : 0.055763, loss_ce: 0.013363
[00:52:48.307] iteration 5901 : loss : 0.136860, loss_ce: 0.020154
[00:52:48.623] iteration 5902 : loss : 0.115239, loss_ce: 0.005499
[00:52:48.925] iteration 5903 : loss : 0.067976, loss_ce: 0.023656
[00:52:49.237] iteration 5904 : loss : 0.096876, loss_ce: 0.007393
[00:52:49.550] iteration 5905 : loss : 0.064597, loss_ce: 0.017927
[00:52:49.850] iteration 5906 : loss : 0.075551, loss_ce: 0.035810
[00:52:50.154] iteration 5907 : loss : 0.055333, loss_ce: 0.016709
[00:52:50.461] iteration 5908 : loss : 0.077653, loss_ce: 0.029571
[00:52:50.763] iteration 5909 : loss : 0.057581, loss_ce: 0.015526
[00:52:51.072] iteration 5910 : loss : 0.127005, loss_ce: 0.009872
[00:52:51.376] iteration 5911 : loss : 0.056164, loss_ce: 0.014298
[00:52:51.686] iteration 5912 : loss : 0.069483, loss_ce: 0.017681
[00:52:51.993] iteration 5913 : loss : 0.073396, loss_ce: 0.015819
[00:52:52.301] iteration 5914 : loss : 0.052811, loss_ce: 0.010274
[00:52:52.604] iteration 5915 : loss : 0.058655, loss_ce: 0.025596
[00:52:52.912] iteration 5916 : loss : 0.096101, loss_ce: 0.014880
[00:52:53.231] iteration 5917 : loss : 0.056141, loss_ce: 0.024248
[00:52:53.541] iteration 5918 : loss : 0.115947, loss_ce: 0.020744
[00:52:53.836] iteration 5919 : loss : 0.061406, loss_ce: 0.022756
[00:52:54.148] iteration 5920 : loss : 0.052630, loss_ce: 0.013221
[00:52:54.481] iteration 5921 : loss : 0.130501, loss_ce: 0.017326
[00:52:54.780] iteration 5922 : loss : 0.061934, loss_ce: 0.031074
[00:52:55.091] iteration 5923 : loss : 0.110768, loss_ce: 0.009354
[00:52:55.395] iteration 5924 : loss : 0.087429, loss_ce: 0.015052
[00:52:55.697] iteration 5925 : loss : 0.059661, loss_ce: 0.017851
[00:52:56.002] iteration 5926 : loss : 0.120835, loss_ce: 0.024001
[00:52:56.307] iteration 5927 : loss : 0.061286, loss_ce: 0.018051
[00:52:56.614] iteration 5928 : loss : 0.084573, loss_ce: 0.025310
[00:52:56.919] iteration 5929 : loss : 0.119833, loss_ce: 0.016357
[00:52:57.225] iteration 5930 : loss : 0.087983, loss_ce: 0.020780
[00:52:57.538] iteration 5931 : loss : 0.187653, loss_ce: 0.008213
[00:52:57.844] iteration 5932 : loss : 0.047001, loss_ce: 0.008367
[00:52:58.153] iteration 5933 : loss : 0.073387, loss_ce: 0.017478
[00:52:58.474] iteration 5934 : loss : 0.100370, loss_ce: 0.027162
[00:52:58.778] iteration 5935 : loss : 0.072658, loss_ce: 0.035583
[00:52:59.082] iteration 5936 : loss : 0.115497, loss_ce: 0.018476
[00:52:59.391] iteration 5937 : loss : 0.147301, loss_ce: 0.017864
[00:52:59.691] iteration 5938 : loss : 0.071869, loss_ce: 0.022194
[00:53:00.001] iteration 5939 : loss : 0.075059, loss_ce: 0.021572
[00:53:00.310] iteration 5940 : loss : 0.119352, loss_ce: 0.032248
[00:53:00.648] iteration 5941 : loss : 0.079902, loss_ce: 0.012761
[00:53:00.950] iteration 5942 : loss : 0.077284, loss_ce: 0.020650
[00:53:01.267] iteration 5943 : loss : 0.062742, loss_ce: 0.016019
[00:53:01.573] iteration 5944 : loss : 0.081533, loss_ce: 0.022724
[00:53:01.880] iteration 5945 : loss : 0.068512, loss_ce: 0.025182
[00:53:02.189] iteration 5946 : loss : 0.075848, loss_ce: 0.013519
[00:53:02.487] iteration 5947 : loss : 0.076487, loss_ce: 0.016730
[00:53:02.801] iteration 5948 : loss : 0.167150, loss_ce: 0.022612
[00:53:03.108] iteration 5949 : loss : 0.058812, loss_ce: 0.020120
[00:53:03.417] iteration 5950 : loss : 0.117800, loss_ce: 0.018361
[00:53:03.730] iteration 5951 : loss : 0.072084, loss_ce: 0.021594
[00:53:04.044] iteration 5952 : loss : 0.068398, loss_ce: 0.016227
[00:53:04.342] iteration 5953 : loss : 0.124783, loss_ce: 0.014021
[00:53:04.659] iteration 5954 : loss : 0.057316, loss_ce: 0.015742
[00:53:04.963] iteration 5955 : loss : 0.077593, loss_ce: 0.016603
[00:53:05.265] iteration 5956 : loss : 0.067043, loss_ce: 0.032827
[00:53:05.570] iteration 5957 : loss : 0.076248, loss_ce: 0.023647
[00:53:05.876] iteration 5958 : loss : 0.075087, loss_ce: 0.021519
[00:53:06.180] iteration 5959 : loss : 0.076747, loss_ce: 0.023194
[00:53:06.484] iteration 5960 : loss : 0.124651, loss_ce: 0.024455
[00:53:06.816] iteration 5961 : loss : 0.067004, loss_ce: 0.041446
[00:53:07.128] iteration 5962 : loss : 0.091768, loss_ce: 0.021423
[00:53:07.443] iteration 5963 : loss : 0.090092, loss_ce: 0.023174
[00:53:07.755] iteration 5964 : loss : 0.072666, loss_ce: 0.023707
[00:53:08.062] iteration 5965 : loss : 0.087979, loss_ce: 0.020485
[00:53:08.367] iteration 5966 : loss : 0.107487, loss_ce: 0.017531
[00:53:08.691] iteration 5967 : loss : 0.064736, loss_ce: 0.015187
[00:53:09.003] iteration 5968 : loss : 0.075361, loss_ce: 0.025221
[00:53:09.306] iteration 5969 : loss : 0.062369, loss_ce: 0.030601
[00:53:09.616] iteration 5970 : loss : 0.064193, loss_ce: 0.019876
[00:53:09.926] iteration 5971 : loss : 0.134473, loss_ce: 0.015427
[00:53:10.236] iteration 5972 : loss : 0.113020, loss_ce: 0.011235
[00:53:10.540] iteration 5973 : loss : 0.073379, loss_ce: 0.022058
[00:53:10.847] iteration 5974 : loss : 0.083947, loss_ce: 0.020455
[00:53:11.158] iteration 5975 : loss : 0.081603, loss_ce: 0.015719
[00:53:11.467] iteration 5976 : loss : 0.079306, loss_ce: 0.036646
[00:53:11.548] iteration 5977 : loss : 0.341949, loss_ce: 0.014087
[00:53:28.162] iteration 5978 : loss : 0.061046, loss_ce: 0.023805
[00:53:28.470] iteration 5979 : loss : 0.084282, loss_ce: 0.029358
[00:53:28.783] iteration 5980 : loss : 0.069261, loss_ce: 0.007319
[00:53:29.126] iteration 5981 : loss : 0.065978, loss_ce: 0.015814
[00:53:29.433] iteration 5982 : loss : 0.117713, loss_ce: 0.026267
[00:53:29.737] iteration 5983 : loss : 0.069329, loss_ce: 0.024951
[00:53:30.047] iteration 5984 : loss : 0.128644, loss_ce: 0.022689
[00:53:30.351] iteration 5985 : loss : 0.068545, loss_ce: 0.025347
[00:53:30.654] iteration 5986 : loss : 0.138640, loss_ce: 0.020291
[00:53:30.968] iteration 5987 : loss : 0.105867, loss_ce: 0.018353
[00:53:31.270] iteration 5988 : loss : 0.073966, loss_ce: 0.018946
[00:53:31.576] iteration 5989 : loss : 0.145805, loss_ce: 0.009029
[00:53:31.882] iteration 5990 : loss : 0.080887, loss_ce: 0.032915
[00:53:32.192] iteration 5991 : loss : 0.070667, loss_ce: 0.020515
[00:53:32.505] iteration 5992 : loss : 0.074369, loss_ce: 0.017117
[00:53:32.818] iteration 5993 : loss : 0.173463, loss_ce: 0.019851
[00:53:33.123] iteration 5994 : loss : 0.075047, loss_ce: 0.018064
[00:53:33.425] iteration 5995 : loss : 0.082931, loss_ce: 0.016218
[00:53:33.733] iteration 5996 : loss : 0.095030, loss_ce: 0.021225
[00:53:34.041] iteration 5997 : loss : 0.111860, loss_ce: 0.014060
[00:53:34.345] iteration 5998 : loss : 0.350813, loss_ce: 0.002038
[00:53:34.653] iteration 5999 : loss : 0.070373, loss_ce: 0.022638
[00:53:34.965] iteration 6000 : loss : 0.067170, loss_ce: 0.023575
[00:53:35.299] iteration 6001 : loss : 0.067564, loss_ce: 0.013869
[00:53:35.615] iteration 6002 : loss : 0.068770, loss_ce: 0.016575
[00:53:35.925] iteration 6003 : loss : 0.087860, loss_ce: 0.016587
[00:53:36.232] iteration 6004 : loss : 0.055831, loss_ce: 0.021003
[00:53:36.538] iteration 6005 : loss : 0.069551, loss_ce: 0.019421
[00:53:36.846] iteration 6006 : loss : 0.092089, loss_ce: 0.022592
[00:53:37.156] iteration 6007 : loss : 0.063365, loss_ce: 0.018311
[00:53:37.466] iteration 6008 : loss : 0.068573, loss_ce: 0.028568
[00:53:37.774] iteration 6009 : loss : 0.068315, loss_ce: 0.019462
[00:53:38.078] iteration 6010 : loss : 0.083094, loss_ce: 0.015421
[00:53:38.391] iteration 6011 : loss : 0.058331, loss_ce: 0.016624
[00:53:38.698] iteration 6012 : loss : 0.067237, loss_ce: 0.008881
[00:53:39.009] iteration 6013 : loss : 0.065733, loss_ce: 0.014269
[00:53:39.316] iteration 6014 : loss : 0.115040, loss_ce: 0.013585
[00:53:39.624] iteration 6015 : loss : 0.077742, loss_ce: 0.032942
[00:53:39.929] iteration 6016 : loss : 0.050225, loss_ce: 0.017516
[00:53:40.241] iteration 6017 : loss : 0.074236, loss_ce: 0.024580
[00:53:40.552] iteration 6018 : loss : 0.071468, loss_ce: 0.025120
[00:53:40.868] iteration 6019 : loss : 0.061312, loss_ce: 0.017315
[00:53:41.174] iteration 6020 : loss : 0.070425, loss_ce: 0.012568
[00:53:41.503] iteration 6021 : loss : 0.118920, loss_ce: 0.014264
[00:53:41.818] iteration 6022 : loss : 0.067435, loss_ce: 0.035122
[00:53:42.128] iteration 6023 : loss : 0.171297, loss_ce: 0.013955
[00:53:42.433] iteration 6024 : loss : 0.095529, loss_ce: 0.017862
[00:53:42.747] iteration 6025 : loss : 0.064415, loss_ce: 0.025283
[00:53:43.054] iteration 6026 : loss : 0.112168, loss_ce: 0.022768
[00:53:43.360] iteration 6027 : loss : 0.079605, loss_ce: 0.018281
[00:53:43.670] iteration 6028 : loss : 0.072017, loss_ce: 0.026780
[00:53:43.974] iteration 6029 : loss : 0.058906, loss_ce: 0.027229
[00:53:44.283] iteration 6030 : loss : 0.057612, loss_ce: 0.024852
[00:53:44.584] iteration 6031 : loss : 0.074357, loss_ce: 0.020557
[00:53:44.893] iteration 6032 : loss : 0.200578, loss_ce: 0.014140
[00:53:45.204] iteration 6033 : loss : 0.081348, loss_ce: 0.018002
[00:53:45.503] iteration 6034 : loss : 0.097464, loss_ce: 0.039506
[00:53:45.819] iteration 6035 : loss : 0.062837, loss_ce: 0.019455
[00:53:46.121] iteration 6036 : loss : 0.076413, loss_ce: 0.013019
[00:53:46.426] iteration 6037 : loss : 0.068400, loss_ce: 0.035894
[00:53:46.725] iteration 6038 : loss : 0.141497, loss_ce: 0.011792
[00:53:47.037] iteration 6039 : loss : 0.125880, loss_ce: 0.006360
[00:53:47.338] iteration 6040 : loss : 0.079187, loss_ce: 0.020071
[00:53:47.661] iteration 6041 : loss : 0.052612, loss_ce: 0.016102
[00:53:47.961] iteration 6042 : loss : 0.060207, loss_ce: 0.022591
[00:53:48.265] iteration 6043 : loss : 0.050869, loss_ce: 0.014784
[00:53:48.572] iteration 6044 : loss : 0.075153, loss_ce: 0.028609
[00:53:48.883] iteration 6045 : loss : 0.122299, loss_ce: 0.018230
[00:53:49.182] iteration 6046 : loss : 0.063545, loss_ce: 0.014656
[00:53:49.501] iteration 6047 : loss : 0.071374, loss_ce: 0.020138
[00:53:49.804] iteration 6048 : loss : 0.063048, loss_ce: 0.014329
[00:53:50.108] iteration 6049 : loss : 0.059236, loss_ce: 0.030120
[00:53:50.421] iteration 6050 : loss : 0.066589, loss_ce: 0.020079
[00:53:50.737] iteration 6051 : loss : 0.059346, loss_ce: 0.026958
[00:53:51.039] iteration 6052 : loss : 0.065598, loss_ce: 0.014165
[00:53:51.345] iteration 6053 : loss : 0.067887, loss_ce: 0.015347
[00:53:51.660] iteration 6054 : loss : 0.079614, loss_ce: 0.025791
[00:53:51.960] iteration 6055 : loss : 0.052597, loss_ce: 0.009286
[00:53:52.266] iteration 6056 : loss : 0.058750, loss_ce: 0.022047
[00:53:52.576] iteration 6057 : loss : 0.057914, loss_ce: 0.015594
[00:53:52.882] iteration 6058 : loss : 0.060346, loss_ce: 0.027903
[00:53:53.182] iteration 6059 : loss : 0.130125, loss_ce: 0.009770
[00:53:53.489] iteration 6060 : loss : 0.068467, loss_ce: 0.024139
[00:53:53.811] iteration 6061 : loss : 0.056746, loss_ce: 0.012438
[00:53:54.115] iteration 6062 : loss : 0.091271, loss_ce: 0.027336
[00:53:54.423] iteration 6063 : loss : 0.074842, loss_ce: 0.019524
[00:53:54.733] iteration 6064 : loss : 0.065996, loss_ce: 0.017335
[00:53:55.044] iteration 6065 : loss : 0.101315, loss_ce: 0.019571
[00:53:55.349] iteration 6066 : loss : 0.081531, loss_ce: 0.017747
[00:53:55.667] iteration 6067 : loss : 0.161487, loss_ce: 0.019411
[00:53:55.970] iteration 6068 : loss : 0.058839, loss_ce: 0.021018
[00:53:56.285] iteration 6069 : loss : 0.129433, loss_ce: 0.017093
[00:53:56.592] iteration 6070 : loss : 0.056940, loss_ce: 0.026407
[00:53:56.900] iteration 6071 : loss : 0.144660, loss_ce: 0.018678
[00:53:57.204] iteration 6072 : loss : 0.077438, loss_ce: 0.034143
[00:53:57.507] iteration 6073 : loss : 0.062807, loss_ce: 0.024432
[00:53:57.810] iteration 6074 : loss : 0.067471, loss_ce: 0.024921
[00:53:58.113] iteration 6075 : loss : 0.182343, loss_ce: 0.015044
[00:53:58.421] iteration 6076 : loss : 0.060428, loss_ce: 0.024380
[00:53:58.727] iteration 6077 : loss : 0.068877, loss_ce: 0.013958
[00:53:59.033] iteration 6078 : loss : 0.064596, loss_ce: 0.019734
[00:53:59.340] iteration 6079 : loss : 0.066441, loss_ce: 0.022822
[00:53:59.653] iteration 6080 : loss : 0.065248, loss_ce: 0.015634
[00:53:59.990] iteration 6081 : loss : 0.125137, loss_ce: 0.035089
[00:54:00.303] iteration 6082 : loss : 0.061809, loss_ce: 0.021560
[00:54:00.608] iteration 6083 : loss : 0.065941, loss_ce: 0.017990
[00:54:00.915] iteration 6084 : loss : 0.125607, loss_ce: 0.008059
[00:54:01.219] iteration 6085 : loss : 0.073558, loss_ce: 0.027989
[00:54:01.532] iteration 6086 : loss : 0.084876, loss_ce: 0.016650
[00:54:01.836] iteration 6087 : loss : 0.052500, loss_ce: 0.014531
[00:54:02.137] iteration 6088 : loss : 0.070922, loss_ce: 0.016503
[00:54:02.443] iteration 6089 : loss : 0.062238, loss_ce: 0.018672
[00:54:02.749] iteration 6090 : loss : 0.086513, loss_ce: 0.010561
[00:54:03.051] iteration 6091 : loss : 0.069626, loss_ce: 0.023230
[00:54:03.362] iteration 6092 : loss : 0.124092, loss_ce: 0.017736
[00:54:03.671] iteration 6093 : loss : 0.089874, loss_ce: 0.031193
[00:54:03.975] iteration 6094 : loss : 0.169851, loss_ce: 0.017943
[00:54:04.285] iteration 6095 : loss : 0.067841, loss_ce: 0.020585
[00:54:04.589] iteration 6096 : loss : 0.124864, loss_ce: 0.015262
[00:54:04.896] iteration 6097 : loss : 0.069402, loss_ce: 0.027443
[00:54:05.201] iteration 6098 : loss : 0.116258, loss_ce: 0.018653
[00:54:05.510] iteration 6099 : loss : 0.101971, loss_ce: 0.022666
[00:54:05.816] iteration 6100 : loss : 0.111861, loss_ce: 0.018992
[00:54:06.140] iteration 6101 : loss : 0.053564, loss_ce: 0.014034
[00:54:06.447] iteration 6102 : loss : 0.140770, loss_ce: 0.010615
[00:54:06.756] iteration 6103 : loss : 0.124284, loss_ce: 0.022638
[00:54:07.076] iteration 6104 : loss : 0.063669, loss_ce: 0.021629
[00:54:07.388] iteration 6105 : loss : 0.069777, loss_ce: 0.020578
[00:54:07.696] iteration 6106 : loss : 0.069155, loss_ce: 0.013472
[00:54:08.005] iteration 6107 : loss : 0.073566, loss_ce: 0.025346
[00:54:08.315] iteration 6108 : loss : 0.059016, loss_ce: 0.008241
[00:54:08.634] iteration 6109 : loss : 0.075685, loss_ce: 0.019061
[00:54:08.939] iteration 6110 : loss : 0.076826, loss_ce: 0.022741
[00:54:09.243] iteration 6111 : loss : 0.106587, loss_ce: 0.013352
[00:54:09.560] iteration 6112 : loss : 0.124481, loss_ce: 0.023887
[00:54:09.868] iteration 6113 : loss : 0.108328, loss_ce: 0.012601
[00:54:10.178] iteration 6114 : loss : 0.066600, loss_ce: 0.017609
[00:54:10.484] iteration 6115 : loss : 0.082057, loss_ce: 0.022724
[00:54:10.563] iteration 6116 : loss : 0.075361, loss_ce: 0.045118
[00:54:29.726] iteration 6117 : loss : 0.130541, loss_ce: 0.016273
[00:54:30.029] iteration 6118 : loss : 0.067025, loss_ce: 0.028662
[00:54:30.341] iteration 6119 : loss : 0.079319, loss_ce: 0.022720
[00:54:30.651] iteration 6120 : loss : 0.072993, loss_ce: 0.015856
[00:54:30.977] iteration 6121 : loss : 0.052071, loss_ce: 0.018577
[00:54:31.275] iteration 6122 : loss : 0.126469, loss_ce: 0.029467
[00:54:31.572] iteration 6123 : loss : 0.081279, loss_ce: 0.016121
[00:54:31.882] iteration 6124 : loss : 0.069507, loss_ce: 0.018729
[00:54:32.179] iteration 6125 : loss : 0.060500, loss_ce: 0.023789
[00:54:32.484] iteration 6126 : loss : 0.073721, loss_ce: 0.020385
[00:54:32.786] iteration 6127 : loss : 0.048136, loss_ce: 0.018414
[00:54:33.091] iteration 6128 : loss : 0.066553, loss_ce: 0.031239
[00:54:33.397] iteration 6129 : loss : 0.058420, loss_ce: 0.022973
[00:54:33.700] iteration 6130 : loss : 0.081797, loss_ce: 0.026808
[00:54:34.007] iteration 6131 : loss : 0.077149, loss_ce: 0.031615
[00:54:34.321] iteration 6132 : loss : 0.174071, loss_ce: 0.010625
[00:54:34.620] iteration 6133 : loss : 0.087969, loss_ce: 0.029550
[00:54:34.919] iteration 6134 : loss : 0.070715, loss_ce: 0.022190
[00:54:35.231] iteration 6135 : loss : 0.070834, loss_ce: 0.017091
[00:54:35.541] iteration 6136 : loss : 0.102203, loss_ce: 0.019412
[00:54:35.836] iteration 6137 : loss : 0.292519, loss_ce: 0.020729
[00:54:36.147] iteration 6138 : loss : 0.069963, loss_ce: 0.019417
[00:54:36.457] iteration 6139 : loss : 0.059178, loss_ce: 0.014152
[00:54:36.765] iteration 6140 : loss : 0.060306, loss_ce: 0.026987
[00:54:37.087] iteration 6141 : loss : 0.080518, loss_ce: 0.016639
[00:54:37.385] iteration 6142 : loss : 0.061674, loss_ce: 0.017675
[00:54:37.690] iteration 6143 : loss : 0.071836, loss_ce: 0.015054
[00:54:38.002] iteration 6144 : loss : 0.078499, loss_ce: 0.009943
[00:54:38.311] iteration 6145 : loss : 0.090699, loss_ce: 0.019540
[00:54:38.619] iteration 6146 : loss : 0.049065, loss_ce: 0.019075
[00:54:38.919] iteration 6147 : loss : 0.064585, loss_ce: 0.012020
[00:54:39.225] iteration 6148 : loss : 0.123272, loss_ce: 0.010391
[00:54:39.529] iteration 6149 : loss : 0.119013, loss_ce: 0.014022
[00:54:39.838] iteration 6150 : loss : 0.069505, loss_ce: 0.017521
[00:54:40.144] iteration 6151 : loss : 0.064192, loss_ce: 0.017671
[00:54:40.457] iteration 6152 : loss : 0.112242, loss_ce: 0.019603
[00:54:40.756] iteration 6153 : loss : 0.071158, loss_ce: 0.028271
[00:54:41.064] iteration 6154 : loss : 0.077662, loss_ce: 0.019255
[00:54:41.366] iteration 6155 : loss : 0.059051, loss_ce: 0.027523
[00:54:41.677] iteration 6156 : loss : 0.125505, loss_ce: 0.016668
[00:54:41.984] iteration 6157 : loss : 0.118439, loss_ce: 0.015835
[00:54:42.290] iteration 6158 : loss : 0.075287, loss_ce: 0.020901
[00:54:42.599] iteration 6159 : loss : 0.083914, loss_ce: 0.013238
[00:54:42.902] iteration 6160 : loss : 0.070518, loss_ce: 0.026608
[00:54:43.233] iteration 6161 : loss : 0.043971, loss_ce: 0.012112
[00:54:43.540] iteration 6162 : loss : 0.063708, loss_ce: 0.025367
[00:54:43.851] iteration 6163 : loss : 0.072426, loss_ce: 0.022620
[00:54:44.158] iteration 6164 : loss : 0.126761, loss_ce: 0.015712
[00:54:44.461] iteration 6165 : loss : 0.075200, loss_ce: 0.028699
[00:54:44.762] iteration 6166 : loss : 0.049089, loss_ce: 0.018199
[00:54:45.072] iteration 6167 : loss : 0.063165, loss_ce: 0.012589
[00:54:45.378] iteration 6168 : loss : 0.047235, loss_ce: 0.014712
[00:54:45.684] iteration 6169 : loss : 0.067109, loss_ce: 0.009827
[00:54:45.998] iteration 6170 : loss : 0.126893, loss_ce: 0.020253
[00:54:46.306] iteration 6171 : loss : 0.081981, loss_ce: 0.023081
[00:54:46.612] iteration 6172 : loss : 0.059413, loss_ce: 0.024013
[00:54:46.919] iteration 6173 : loss : 0.088630, loss_ce: 0.041399
[00:54:47.221] iteration 6174 : loss : 0.082140, loss_ce: 0.037909
[00:54:47.528] iteration 6175 : loss : 0.075350, loss_ce: 0.013807
[00:54:47.832] iteration 6176 : loss : 0.112359, loss_ce: 0.014207
[00:54:48.134] iteration 6177 : loss : 0.112287, loss_ce: 0.026242
[00:54:48.441] iteration 6178 : loss : 0.077615, loss_ce: 0.018081
[00:54:48.747] iteration 6179 : loss : 0.075447, loss_ce: 0.015778
[00:54:49.059] iteration 6180 : loss : 0.050677, loss_ce: 0.010193
[00:54:49.389] iteration 6181 : loss : 0.141557, loss_ce: 0.011818
[00:54:49.691] iteration 6182 : loss : 0.059077, loss_ce: 0.018840
[00:54:49.999] iteration 6183 : loss : 0.073851, loss_ce: 0.026098
[00:54:50.306] iteration 6184 : loss : 0.069216, loss_ce: 0.020426
[00:54:50.611] iteration 6185 : loss : 0.056175, loss_ce: 0.014644
[00:54:50.909] iteration 6186 : loss : 0.143506, loss_ce: 0.014897
[00:54:51.215] iteration 6187 : loss : 0.169749, loss_ce: 0.021136
[00:54:51.522] iteration 6188 : loss : 0.059394, loss_ce: 0.021638
[00:54:51.828] iteration 6189 : loss : 0.081713, loss_ce: 0.018611
[00:54:52.132] iteration 6190 : loss : 0.075834, loss_ce: 0.016674
[00:54:52.442] iteration 6191 : loss : 0.070162, loss_ce: 0.014353
[00:54:52.745] iteration 6192 : loss : 0.060962, loss_ce: 0.017090
[00:54:53.051] iteration 6193 : loss : 0.063387, loss_ce: 0.030214
[00:54:53.357] iteration 6194 : loss : 0.083690, loss_ce: 0.026325
[00:54:53.664] iteration 6195 : loss : 0.125069, loss_ce: 0.018318
[00:54:53.968] iteration 6196 : loss : 0.100199, loss_ce: 0.019024
[00:54:54.279] iteration 6197 : loss : 0.198682, loss_ce: 0.009186
[00:54:54.585] iteration 6198 : loss : 0.133796, loss_ce: 0.031233
[00:54:54.889] iteration 6199 : loss : 0.099592, loss_ce: 0.030245
[00:54:55.190] iteration 6200 : loss : 0.080848, loss_ce: 0.030834
[00:54:55.515] iteration 6201 : loss : 0.067993, loss_ce: 0.022693
[00:54:55.817] iteration 6202 : loss : 0.078402, loss_ce: 0.034504
[00:54:56.124] iteration 6203 : loss : 0.061605, loss_ce: 0.014746
[00:54:56.433] iteration 6204 : loss : 0.081915, loss_ce: 0.031320
[00:54:56.736] iteration 6205 : loss : 0.071081, loss_ce: 0.026282
[00:54:57.044] iteration 6206 : loss : 0.116043, loss_ce: 0.012656
[00:54:57.347] iteration 6207 : loss : 0.078124, loss_ce: 0.026626
[00:54:57.658] iteration 6208 : loss : 0.077814, loss_ce: 0.018054
[00:54:57.965] iteration 6209 : loss : 0.065464, loss_ce: 0.024538
[00:54:58.271] iteration 6210 : loss : 0.056317, loss_ce: 0.014532
[00:54:58.579] iteration 6211 : loss : 0.178169, loss_ce: 0.014082
[00:54:58.887] iteration 6212 : loss : 0.108547, loss_ce: 0.007926
[00:54:59.193] iteration 6213 : loss : 0.121490, loss_ce: 0.011085
[00:54:59.509] iteration 6214 : loss : 0.115623, loss_ce: 0.028227
[00:54:59.812] iteration 6215 : loss : 0.098143, loss_ce: 0.029649
[00:55:00.122] iteration 6216 : loss : 0.063234, loss_ce: 0.022196
[00:55:00.435] iteration 6217 : loss : 0.062504, loss_ce: 0.025315
[00:55:00.743] iteration 6218 : loss : 0.055414, loss_ce: 0.014469
[00:55:01.050] iteration 6219 : loss : 0.084293, loss_ce: 0.012128
[00:55:01.358] iteration 6220 : loss : 0.075878, loss_ce: 0.017590
[00:55:01.679] iteration 6221 : loss : 0.142159, loss_ce: 0.009029
[00:55:01.987] iteration 6222 : loss : 0.106418, loss_ce: 0.031118
[00:55:02.290] iteration 6223 : loss : 0.093321, loss_ce: 0.028499
[00:55:02.594] iteration 6224 : loss : 0.064639, loss_ce: 0.016958
[00:55:02.897] iteration 6225 : loss : 0.074139, loss_ce: 0.020896
[00:55:03.204] iteration 6226 : loss : 0.130190, loss_ce: 0.020694
[00:55:03.507] iteration 6227 : loss : 0.079078, loss_ce: 0.016607
[00:55:03.824] iteration 6228 : loss : 0.088088, loss_ce: 0.024528
[00:55:04.131] iteration 6229 : loss : 0.164468, loss_ce: 0.007802
[00:55:04.436] iteration 6230 : loss : 0.063201, loss_ce: 0.026480
[00:55:04.746] iteration 6231 : loss : 0.085178, loss_ce: 0.015208
[00:55:05.051] iteration 6232 : loss : 0.073458, loss_ce: 0.016372
[00:55:05.355] iteration 6233 : loss : 0.066899, loss_ce: 0.017325
[00:55:05.659] iteration 6234 : loss : 0.071464, loss_ce: 0.023711
[00:55:05.972] iteration 6235 : loss : 0.079822, loss_ce: 0.014305
[00:55:06.278] iteration 6236 : loss : 0.073363, loss_ce: 0.009515
[00:55:06.581] iteration 6237 : loss : 0.068682, loss_ce: 0.017299
[00:55:06.887] iteration 6238 : loss : 0.124435, loss_ce: 0.018735
[00:55:07.194] iteration 6239 : loss : 0.073642, loss_ce: 0.016213
[00:55:07.505] iteration 6240 : loss : 0.078223, loss_ce: 0.031367
[00:55:07.837] iteration 6241 : loss : 0.051653, loss_ce: 0.014052
[00:55:08.143] iteration 6242 : loss : 0.067121, loss_ce: 0.030029
[00:55:08.462] iteration 6243 : loss : 0.064365, loss_ce: 0.019911
[00:55:08.781] iteration 6244 : loss : 0.057763, loss_ce: 0.017602
[00:55:09.093] iteration 6245 : loss : 0.081262, loss_ce: 0.019629
[00:55:09.408] iteration 6246 : loss : 0.099596, loss_ce: 0.036608
[00:55:09.715] iteration 6247 : loss : 0.077606, loss_ce: 0.019073
[00:55:10.017] iteration 6248 : loss : 0.063984, loss_ce: 0.025189
[00:55:10.336] iteration 6249 : loss : 0.129035, loss_ce: 0.013546
[00:55:10.648] iteration 6250 : loss : 0.062729, loss_ce: 0.020219
[00:55:10.955] iteration 6251 : loss : 0.074484, loss_ce: 0.012153
[00:55:11.273] iteration 6252 : loss : 0.066173, loss_ce: 0.015466
[00:55:11.585] iteration 6253 : loss : 0.103284, loss_ce: 0.010315
[00:55:11.892] iteration 6254 : loss : 0.077163, loss_ce: 0.021814
[00:55:11.970] iteration 6255 : loss : 0.138541, loss_ce: 0.028268
[00:55:28.389] iteration 6256 : loss : 0.050693, loss_ce: 0.018524
[00:55:28.702] iteration 6257 : loss : 0.067950, loss_ce: 0.019312
[00:55:29.020] iteration 6258 : loss : 0.054644, loss_ce: 0.016824
[00:55:29.325] iteration 6259 : loss : 0.083083, loss_ce: 0.015268
[00:55:29.643] iteration 6260 : loss : 0.143488, loss_ce: 0.011096
[00:55:29.964] iteration 6261 : loss : 0.074100, loss_ce: 0.022287
[00:55:30.269] iteration 6262 : loss : 0.082377, loss_ce: 0.015464
[00:55:30.578] iteration 6263 : loss : 0.055259, loss_ce: 0.015661
[00:55:30.883] iteration 6264 : loss : 0.066255, loss_ce: 0.016364
[00:55:31.193] iteration 6265 : loss : 0.066416, loss_ce: 0.018150
[00:55:31.500] iteration 6266 : loss : 0.061837, loss_ce: 0.013177
[00:55:31.804] iteration 6267 : loss : 0.094119, loss_ce: 0.023804
[00:55:32.118] iteration 6268 : loss : 0.084098, loss_ce: 0.018154
[00:55:32.416] iteration 6269 : loss : 0.075843, loss_ce: 0.019743
[00:55:32.724] iteration 6270 : loss : 0.051993, loss_ce: 0.020205
[00:55:33.040] iteration 6271 : loss : 0.159036, loss_ce: 0.012846
[00:55:33.345] iteration 6272 : loss : 0.095295, loss_ce: 0.025606
[00:55:33.658] iteration 6273 : loss : 0.076325, loss_ce: 0.018896
[00:55:33.969] iteration 6274 : loss : 0.075638, loss_ce: 0.016020
[00:55:34.275] iteration 6275 : loss : 0.066986, loss_ce: 0.032320
[00:55:34.578] iteration 6276 : loss : 0.065689, loss_ce: 0.028897
[00:55:34.882] iteration 6277 : loss : 0.123648, loss_ce: 0.013888
[00:55:35.188] iteration 6278 : loss : 0.147764, loss_ce: 0.018441
[00:55:35.497] iteration 6279 : loss : 0.065734, loss_ce: 0.020209
[00:55:35.804] iteration 6280 : loss : 0.079644, loss_ce: 0.015145
[00:55:36.122] iteration 6281 : loss : 0.111850, loss_ce: 0.020225
[00:55:36.427] iteration 6282 : loss : 0.066332, loss_ce: 0.025275
[00:55:36.743] iteration 6283 : loss : 0.054627, loss_ce: 0.016341
[00:55:37.048] iteration 6284 : loss : 0.051243, loss_ce: 0.020407
[00:55:37.361] iteration 6285 : loss : 0.055831, loss_ce: 0.016812
[00:55:37.663] iteration 6286 : loss : 0.069549, loss_ce: 0.025698
[00:55:37.964] iteration 6287 : loss : 0.103775, loss_ce: 0.007719
[00:55:38.269] iteration 6288 : loss : 0.081623, loss_ce: 0.021422
[00:55:38.581] iteration 6289 : loss : 0.071782, loss_ce: 0.027791
[00:55:38.885] iteration 6290 : loss : 0.169640, loss_ce: 0.010684
[00:55:39.191] iteration 6291 : loss : 0.074167, loss_ce: 0.029138
[00:55:39.495] iteration 6292 : loss : 0.073968, loss_ce: 0.011265
[00:55:39.805] iteration 6293 : loss : 0.117817, loss_ce: 0.022209
[00:55:40.108] iteration 6294 : loss : 0.065800, loss_ce: 0.017565
[00:55:40.423] iteration 6295 : loss : 0.071325, loss_ce: 0.022793
[00:55:40.731] iteration 6296 : loss : 0.065915, loss_ce: 0.020727
[00:55:41.035] iteration 6297 : loss : 0.075443, loss_ce: 0.016262
[00:55:41.346] iteration 6298 : loss : 0.058981, loss_ce: 0.015129
[00:55:41.658] iteration 6299 : loss : 0.076005, loss_ce: 0.013997
[00:55:41.967] iteration 6300 : loss : 0.090071, loss_ce: 0.020430
[00:55:42.304] iteration 6301 : loss : 0.056394, loss_ce: 0.014599
[00:55:42.615] iteration 6302 : loss : 0.110107, loss_ce: 0.017806
[00:55:42.919] iteration 6303 : loss : 0.077096, loss_ce: 0.018180
[00:55:43.231] iteration 6304 : loss : 0.073185, loss_ce: 0.019153
[00:55:43.536] iteration 6305 : loss : 0.069583, loss_ce: 0.015552
[00:55:43.845] iteration 6306 : loss : 0.167028, loss_ce: 0.011311
[00:55:44.159] iteration 6307 : loss : 0.086728, loss_ce: 0.025206
[00:55:44.462] iteration 6308 : loss : 0.115787, loss_ce: 0.014262
[00:55:44.768] iteration 6309 : loss : 0.076530, loss_ce: 0.029440
[00:55:45.069] iteration 6310 : loss : 0.064145, loss_ce: 0.015349
[00:55:45.372] iteration 6311 : loss : 0.079567, loss_ce: 0.025884
[00:55:45.685] iteration 6312 : loss : 0.072701, loss_ce: 0.025434
[00:55:45.989] iteration 6313 : loss : 0.058228, loss_ce: 0.018075
[00:55:46.294] iteration 6314 : loss : 0.066428, loss_ce: 0.033956
[00:55:46.607] iteration 6315 : loss : 0.144343, loss_ce: 0.010661
[00:55:46.916] iteration 6316 : loss : 0.067127, loss_ce: 0.021574
[00:55:47.223] iteration 6317 : loss : 0.062066, loss_ce: 0.020430
[00:55:47.521] iteration 6318 : loss : 0.065559, loss_ce: 0.011823
[00:55:47.835] iteration 6319 : loss : 0.062384, loss_ce: 0.012596
[00:55:48.144] iteration 6320 : loss : 0.069256, loss_ce: 0.026146
[00:55:48.468] iteration 6321 : loss : 0.067917, loss_ce: 0.030637
[00:55:48.773] iteration 6322 : loss : 0.072512, loss_ce: 0.023236
[00:55:49.084] iteration 6323 : loss : 0.110090, loss_ce: 0.013940
[00:55:49.382] iteration 6324 : loss : 0.050010, loss_ce: 0.017162
[00:55:49.684] iteration 6325 : loss : 0.169261, loss_ce: 0.017281
[00:55:49.994] iteration 6326 : loss : 0.060713, loss_ce: 0.018969
[00:55:50.300] iteration 6327 : loss : 0.056943, loss_ce: 0.020189
[00:55:50.610] iteration 6328 : loss : 0.167398, loss_ce: 0.010201
[00:55:50.915] iteration 6329 : loss : 0.063615, loss_ce: 0.020100
[00:55:51.224] iteration 6330 : loss : 0.065918, loss_ce: 0.024315
[00:55:51.530] iteration 6331 : loss : 0.122447, loss_ce: 0.014268
[00:55:51.831] iteration 6332 : loss : 0.073134, loss_ce: 0.022145
[00:55:52.140] iteration 6333 : loss : 0.195482, loss_ce: 0.006800
[00:55:52.442] iteration 6334 : loss : 0.091932, loss_ce: 0.026868
[00:55:52.744] iteration 6335 : loss : 0.136384, loss_ce: 0.013590
[00:55:53.058] iteration 6336 : loss : 0.078007, loss_ce: 0.021035
[00:55:53.358] iteration 6337 : loss : 0.123292, loss_ce: 0.007740
[00:55:53.671] iteration 6338 : loss : 0.098171, loss_ce: 0.019113
[00:55:53.978] iteration 6339 : loss : 0.060088, loss_ce: 0.018621
[00:55:54.283] iteration 6340 : loss : 0.047994, loss_ce: 0.011302
[00:55:54.607] iteration 6341 : loss : 0.055545, loss_ce: 0.022051
[00:55:54.914] iteration 6342 : loss : 0.105381, loss_ce: 0.014084
[00:55:55.215] iteration 6343 : loss : 0.078285, loss_ce: 0.017124
[00:55:55.525] iteration 6344 : loss : 0.055228, loss_ce: 0.012055
[00:55:55.828] iteration 6345 : loss : 0.053749, loss_ce: 0.029639
[00:55:56.130] iteration 6346 : loss : 0.079272, loss_ce: 0.037137
[00:55:56.437] iteration 6347 : loss : 0.048959, loss_ce: 0.019092
[00:55:56.748] iteration 6348 : loss : 0.068286, loss_ce: 0.013691
[00:55:57.051] iteration 6349 : loss : 0.070783, loss_ce: 0.023142
[00:55:57.355] iteration 6350 : loss : 0.247299, loss_ce: 0.004722
[00:55:57.667] iteration 6351 : loss : 0.053163, loss_ce: 0.011691
[00:55:57.974] iteration 6352 : loss : 0.143068, loss_ce: 0.017014
[00:55:58.277] iteration 6353 : loss : 0.082952, loss_ce: 0.025435
[00:55:58.592] iteration 6354 : loss : 0.061923, loss_ce: 0.017971
[00:55:58.893] iteration 6355 : loss : 0.100915, loss_ce: 0.021081
[00:55:59.206] iteration 6356 : loss : 0.063324, loss_ce: 0.017229
[00:55:59.510] iteration 6357 : loss : 0.080819, loss_ce: 0.027893
[00:55:59.816] iteration 6358 : loss : 0.050981, loss_ce: 0.025308
[00:56:00.125] iteration 6359 : loss : 0.067310, loss_ce: 0.013628
[00:56:00.435] iteration 6360 : loss : 0.152714, loss_ce: 0.015663
[00:56:00.753] iteration 6361 : loss : 0.077973, loss_ce: 0.030571
[00:56:01.064] iteration 6362 : loss : 0.049946, loss_ce: 0.016979
[00:56:01.367] iteration 6363 : loss : 0.068877, loss_ce: 0.027075
[00:56:01.672] iteration 6364 : loss : 0.122360, loss_ce: 0.011772
[00:56:01.977] iteration 6365 : loss : 0.076760, loss_ce: 0.023393
[00:56:02.282] iteration 6366 : loss : 0.064635, loss_ce: 0.012049
[00:56:02.581] iteration 6367 : loss : 0.079974, loss_ce: 0.021196
[00:56:02.892] iteration 6368 : loss : 0.168645, loss_ce: 0.020215
[00:56:03.196] iteration 6369 : loss : 0.060096, loss_ce: 0.029833
[00:56:03.505] iteration 6370 : loss : 0.051127, loss_ce: 0.019340
[00:56:03.811] iteration 6371 : loss : 0.057181, loss_ce: 0.017325
[00:56:04.118] iteration 6372 : loss : 0.054125, loss_ce: 0.026484
[00:56:04.425] iteration 6373 : loss : 0.079858, loss_ce: 0.025742
[00:56:04.726] iteration 6374 : loss : 0.061117, loss_ce: 0.020646
[00:56:05.036] iteration 6375 : loss : 0.105243, loss_ce: 0.016070
[00:56:05.342] iteration 6376 : loss : 0.086520, loss_ce: 0.020106
[00:56:05.651] iteration 6377 : loss : 0.062724, loss_ce: 0.021595
[00:56:05.961] iteration 6378 : loss : 0.116025, loss_ce: 0.022806
[00:56:06.278] iteration 6379 : loss : 0.139175, loss_ce: 0.012262
[00:56:06.586] iteration 6380 : loss : 0.070015, loss_ce: 0.021847
[00:56:06.930] iteration 6381 : loss : 0.169234, loss_ce: 0.009461
[00:56:07.252] iteration 6382 : loss : 0.119975, loss_ce: 0.026520
[00:56:07.567] iteration 6383 : loss : 0.074912, loss_ce: 0.017390
[00:56:07.869] iteration 6384 : loss : 0.075423, loss_ce: 0.015978
[00:56:08.174] iteration 6385 : loss : 0.102619, loss_ce: 0.018516
[00:56:08.483] iteration 6386 : loss : 0.087722, loss_ce: 0.022508
[00:56:08.788] iteration 6387 : loss : 0.121233, loss_ce: 0.020932
[00:56:09.099] iteration 6388 : loss : 0.069687, loss_ce: 0.029816
[00:56:09.411] iteration 6389 : loss : 0.072570, loss_ce: 0.020102
[00:56:09.715] iteration 6390 : loss : 0.072843, loss_ce: 0.018349
[00:56:10.022] iteration 6391 : loss : 0.076218, loss_ce: 0.019682
[00:56:10.330] iteration 6392 : loss : 0.157925, loss_ce: 0.019004
[00:56:10.649] iteration 6393 : loss : 0.146469, loss_ce: 0.012435
[00:56:10.736] iteration 6394 : loss : 0.452502, loss_ce: 0.000462
[00:56:29.865] iteration 6395 : loss : 0.112255, loss_ce: 0.016974
[00:56:30.171] iteration 6396 : loss : 0.310715, loss_ce: 0.002757
[00:56:30.478] iteration 6397 : loss : 0.080182, loss_ce: 0.022189
[00:56:30.789] iteration 6398 : loss : 0.067399, loss_ce: 0.025060
[00:56:31.106] iteration 6399 : loss : 0.106155, loss_ce: 0.019655
[00:56:31.414] iteration 6400 : loss : 0.066431, loss_ce: 0.009912
[00:56:31.742] iteration 6401 : loss : 0.065999, loss_ce: 0.021265
[00:56:32.050] iteration 6402 : loss : 0.083930, loss_ce: 0.021990
[00:56:32.355] iteration 6403 : loss : 0.063665, loss_ce: 0.017819
[00:56:32.659] iteration 6404 : loss : 0.131882, loss_ce: 0.012369
[00:56:32.968] iteration 6405 : loss : 0.077350, loss_ce: 0.024531
[00:56:33.270] iteration 6406 : loss : 0.058409, loss_ce: 0.028057
[00:56:33.576] iteration 6407 : loss : 0.068432, loss_ce: 0.030628
[00:56:33.876] iteration 6408 : loss : 0.085602, loss_ce: 0.031092
[00:56:34.176] iteration 6409 : loss : 0.123329, loss_ce: 0.013561
[00:56:34.478] iteration 6410 : loss : 0.065183, loss_ce: 0.020158
[00:56:34.784] iteration 6411 : loss : 0.090058, loss_ce: 0.028363
[00:56:35.092] iteration 6412 : loss : 0.054094, loss_ce: 0.016917
[00:56:35.392] iteration 6413 : loss : 0.089945, loss_ce: 0.016429
[00:56:35.696] iteration 6414 : loss : 0.097750, loss_ce: 0.021299
[00:56:36.001] iteration 6415 : loss : 0.069314, loss_ce: 0.021958
[00:56:36.312] iteration 6416 : loss : 0.045370, loss_ce: 0.015900
[00:56:36.617] iteration 6417 : loss : 0.065526, loss_ce: 0.016348
[00:56:36.921] iteration 6418 : loss : 0.069370, loss_ce: 0.018010
[00:56:37.220] iteration 6419 : loss : 0.066081, loss_ce: 0.021900
[00:56:37.524] iteration 6420 : loss : 0.107468, loss_ce: 0.021600
[00:56:37.848] iteration 6421 : loss : 0.060678, loss_ce: 0.020391
[00:56:38.153] iteration 6422 : loss : 0.108597, loss_ce: 0.012251
[00:56:38.456] iteration 6423 : loss : 0.061102, loss_ce: 0.021681
[00:56:38.761] iteration 6424 : loss : 0.079072, loss_ce: 0.023916
[00:56:39.065] iteration 6425 : loss : 0.091990, loss_ce: 0.022075
[00:56:39.365] iteration 6426 : loss : 0.063761, loss_ce: 0.026624
[00:56:39.674] iteration 6427 : loss : 0.060233, loss_ce: 0.029709
[00:56:39.976] iteration 6428 : loss : 0.111148, loss_ce: 0.011480
[00:56:40.284] iteration 6429 : loss : 0.119812, loss_ce: 0.018014
[00:56:40.587] iteration 6430 : loss : 0.110342, loss_ce: 0.011072
[00:56:40.896] iteration 6431 : loss : 0.060518, loss_ce: 0.020252
[00:56:41.198] iteration 6432 : loss : 0.064241, loss_ce: 0.021187
[00:56:41.505] iteration 6433 : loss : 0.184184, loss_ce: 0.015497
[00:56:41.809] iteration 6434 : loss : 0.069282, loss_ce: 0.016782
[00:56:42.115] iteration 6435 : loss : 0.056571, loss_ce: 0.017358
[00:56:42.418] iteration 6436 : loss : 0.069096, loss_ce: 0.031138
[00:56:42.725] iteration 6437 : loss : 0.077706, loss_ce: 0.014750
[00:56:43.025] iteration 6438 : loss : 0.124012, loss_ce: 0.017098
[00:56:43.330] iteration 6439 : loss : 0.117927, loss_ce: 0.012820
[00:56:43.637] iteration 6440 : loss : 0.183044, loss_ce: 0.013360
[00:56:43.962] iteration 6441 : loss : 0.086045, loss_ce: 0.021004
[00:56:44.267] iteration 6442 : loss : 0.052870, loss_ce: 0.011616
[00:56:44.573] iteration 6443 : loss : 0.051643, loss_ce: 0.011793
[00:56:44.876] iteration 6444 : loss : 0.075311, loss_ce: 0.018022
[00:56:45.178] iteration 6445 : loss : 0.120523, loss_ce: 0.029156
[00:56:45.486] iteration 6446 : loss : 0.070095, loss_ce: 0.019081
[00:56:45.807] iteration 6447 : loss : 0.087313, loss_ce: 0.011355
[00:56:46.113] iteration 6448 : loss : 0.067385, loss_ce: 0.017885
[00:56:46.413] iteration 6449 : loss : 0.052206, loss_ce: 0.016719
[00:56:46.721] iteration 6450 : loss : 0.128012, loss_ce: 0.019546
[00:56:47.034] iteration 6451 : loss : 0.063508, loss_ce: 0.024537
[00:56:47.344] iteration 6452 : loss : 0.085878, loss_ce: 0.014807
[00:56:47.652] iteration 6453 : loss : 0.101919, loss_ce: 0.018190
[00:56:47.954] iteration 6454 : loss : 0.067645, loss_ce: 0.019540
[00:56:48.254] iteration 6455 : loss : 0.098909, loss_ce: 0.025234
[00:56:48.562] iteration 6456 : loss : 0.095577, loss_ce: 0.019504
[00:56:48.874] iteration 6457 : loss : 0.078313, loss_ce: 0.027451
[00:56:49.177] iteration 6458 : loss : 0.098507, loss_ce: 0.012445
[00:56:49.481] iteration 6459 : loss : 0.127466, loss_ce: 0.016120
[00:56:49.784] iteration 6460 : loss : 0.104448, loss_ce: 0.017954
[00:56:50.108] iteration 6461 : loss : 0.071958, loss_ce: 0.017480
[00:56:50.413] iteration 6462 : loss : 0.065110, loss_ce: 0.014162
[00:56:50.727] iteration 6463 : loss : 0.123950, loss_ce: 0.019771
[00:56:51.031] iteration 6464 : loss : 0.107011, loss_ce: 0.008482
[00:56:51.348] iteration 6465 : loss : 0.125020, loss_ce: 0.020484
[00:56:51.651] iteration 6466 : loss : 0.119327, loss_ce: 0.012269
[00:56:51.955] iteration 6467 : loss : 0.117705, loss_ce: 0.023546
[00:56:52.269] iteration 6468 : loss : 0.109061, loss_ce: 0.043053
[00:56:52.575] iteration 6469 : loss : 0.062016, loss_ce: 0.024578
[00:56:52.877] iteration 6470 : loss : 0.082819, loss_ce: 0.014875
[00:56:53.186] iteration 6471 : loss : 0.073996, loss_ce: 0.017557
[00:56:53.489] iteration 6472 : loss : 0.102666, loss_ce: 0.027433
[00:56:53.799] iteration 6473 : loss : 0.057731, loss_ce: 0.010375
[00:56:54.107] iteration 6474 : loss : 0.085852, loss_ce: 0.030364
[00:56:54.418] iteration 6475 : loss : 0.068547, loss_ce: 0.020763
[00:56:54.720] iteration 6476 : loss : 0.069504, loss_ce: 0.024269
[00:56:55.030] iteration 6477 : loss : 0.070217, loss_ce: 0.024074
[00:56:55.327] iteration 6478 : loss : 0.054818, loss_ce: 0.011496
[00:56:55.630] iteration 6479 : loss : 0.065527, loss_ce: 0.022057
[00:56:55.932] iteration 6480 : loss : 0.070721, loss_ce: 0.015845
[00:56:56.251] iteration 6481 : loss : 0.072510, loss_ce: 0.012890
[00:56:56.550] iteration 6482 : loss : 0.062312, loss_ce: 0.016441
[00:56:56.861] iteration 6483 : loss : 0.053377, loss_ce: 0.017928
[00:56:57.175] iteration 6484 : loss : 0.068758, loss_ce: 0.013035
[00:56:57.478] iteration 6485 : loss : 0.074483, loss_ce: 0.023572
[00:56:57.784] iteration 6486 : loss : 0.039463, loss_ce: 0.012467
[00:56:58.097] iteration 6487 : loss : 0.098395, loss_ce: 0.010239
[00:56:58.401] iteration 6488 : loss : 0.061590, loss_ce: 0.022123
[00:56:58.703] iteration 6489 : loss : 0.074072, loss_ce: 0.018757
[00:56:59.016] iteration 6490 : loss : 0.111257, loss_ce: 0.012226
[00:56:59.325] iteration 6491 : loss : 0.276347, loss_ce: 0.012699
[00:56:59.628] iteration 6492 : loss : 0.095905, loss_ce: 0.029853
[00:56:59.946] iteration 6493 : loss : 0.060934, loss_ce: 0.012458
[00:57:00.247] iteration 6494 : loss : 0.081604, loss_ce: 0.033387
[00:57:00.556] iteration 6495 : loss : 0.169641, loss_ce: 0.005481
[00:57:00.871] iteration 6496 : loss : 0.058214, loss_ce: 0.016163
[00:57:01.177] iteration 6497 : loss : 0.071365, loss_ce: 0.013546
[00:57:01.482] iteration 6498 : loss : 0.078919, loss_ce: 0.016182
[00:57:01.786] iteration 6499 : loss : 0.075112, loss_ce: 0.029220
[00:57:02.099] iteration 6500 : loss : 0.076909, loss_ce: 0.024106
[00:57:02.422] iteration 6501 : loss : 0.067077, loss_ce: 0.018318
[00:57:02.718] iteration 6502 : loss : 0.084435, loss_ce: 0.029258
[00:57:03.022] iteration 6503 : loss : 0.057950, loss_ce: 0.017924
[00:57:03.324] iteration 6504 : loss : 0.135528, loss_ce: 0.017659
[00:57:03.632] iteration 6505 : loss : 0.091333, loss_ce: 0.029344
[00:57:03.942] iteration 6506 : loss : 0.055304, loss_ce: 0.024326
[00:57:04.250] iteration 6507 : loss : 0.056601, loss_ce: 0.022618
[00:57:04.556] iteration 6508 : loss : 0.143260, loss_ce: 0.011634
[00:57:04.868] iteration 6509 : loss : 0.089991, loss_ce: 0.011548
[00:57:05.174] iteration 6510 : loss : 0.067376, loss_ce: 0.031327
[00:57:05.484] iteration 6511 : loss : 0.067415, loss_ce: 0.027455
[00:57:05.794] iteration 6512 : loss : 0.056086, loss_ce: 0.020861
[00:57:06.094] iteration 6513 : loss : 0.075316, loss_ce: 0.028680
[00:57:06.401] iteration 6514 : loss : 0.070928, loss_ce: 0.024240
[00:57:06.707] iteration 6515 : loss : 0.076067, loss_ce: 0.022645
[00:57:07.014] iteration 6516 : loss : 0.075704, loss_ce: 0.021938
[00:57:07.326] iteration 6517 : loss : 0.115772, loss_ce: 0.016229
[00:57:07.642] iteration 6518 : loss : 0.075840, loss_ce: 0.008713
[00:57:07.954] iteration 6519 : loss : 0.086438, loss_ce: 0.034016
[00:57:08.262] iteration 6520 : loss : 0.138813, loss_ce: 0.010971
[00:57:08.605] iteration 6521 : loss : 0.078803, loss_ce: 0.027242
[00:57:08.917] iteration 6522 : loss : 0.053967, loss_ce: 0.011724
[00:57:09.227] iteration 6523 : loss : 0.130378, loss_ce: 0.011589
[00:57:09.535] iteration 6524 : loss : 0.083182, loss_ce: 0.035704
[00:57:09.853] iteration 6525 : loss : 0.110914, loss_ce: 0.019010
[00:57:10.163] iteration 6526 : loss : 0.073444, loss_ce: 0.016779
[00:57:10.474] iteration 6527 : loss : 0.117203, loss_ce: 0.021606
[00:57:10.781] iteration 6528 : loss : 0.079996, loss_ce: 0.024672
[00:57:11.088] iteration 6529 : loss : 0.073740, loss_ce: 0.025832
[00:57:11.389] iteration 6530 : loss : 0.058333, loss_ce: 0.026882
[00:57:11.698] iteration 6531 : loss : 0.056491, loss_ce: 0.014669
[00:57:12.000] iteration 6532 : loss : 0.063157, loss_ce: 0.039442
[00:57:12.082] iteration 6533 : loss : 0.182110, loss_ce: 0.009642
[00:57:29.097] iteration 6534 : loss : 0.052490, loss_ce: 0.013381
[00:57:29.400] iteration 6535 : loss : 0.056534, loss_ce: 0.013093
[00:57:29.707] iteration 6536 : loss : 0.080034, loss_ce: 0.018536
[00:57:30.015] iteration 6537 : loss : 0.061956, loss_ce: 0.027390
[00:57:30.323] iteration 6538 : loss : 0.047075, loss_ce: 0.014082
[00:57:30.630] iteration 6539 : loss : 0.068512, loss_ce: 0.018565
[00:57:30.935] iteration 6540 : loss : 0.068856, loss_ce: 0.013613
[00:57:31.265] iteration 6541 : loss : 0.064577, loss_ce: 0.021410
[00:57:31.564] iteration 6542 : loss : 0.057605, loss_ce: 0.015150
[00:57:31.870] iteration 6543 : loss : 0.114982, loss_ce: 0.024052
[00:57:32.174] iteration 6544 : loss : 0.120046, loss_ce: 0.025248
[00:57:32.478] iteration 6545 : loss : 0.077118, loss_ce: 0.020538
[00:57:32.793] iteration 6546 : loss : 0.093469, loss_ce: 0.017118
[00:57:33.105] iteration 6547 : loss : 0.113643, loss_ce: 0.012598
[00:57:33.415] iteration 6548 : loss : 0.063908, loss_ce: 0.019305
[00:57:33.724] iteration 6549 : loss : 0.061262, loss_ce: 0.013155
[00:57:34.031] iteration 6550 : loss : 0.091579, loss_ce: 0.019603
[00:57:34.339] iteration 6551 : loss : 0.070735, loss_ce: 0.022072
[00:57:34.652] iteration 6552 : loss : 0.062635, loss_ce: 0.020063
[00:57:34.955] iteration 6553 : loss : 0.074491, loss_ce: 0.028330
[00:57:35.264] iteration 6554 : loss : 0.115625, loss_ce: 0.012975
[00:57:35.569] iteration 6555 : loss : 0.058445, loss_ce: 0.012257
[00:57:35.869] iteration 6556 : loss : 0.123007, loss_ce: 0.007876
[00:57:36.175] iteration 6557 : loss : 0.065853, loss_ce: 0.023247
[00:57:36.481] iteration 6558 : loss : 0.078539, loss_ce: 0.026658
[00:57:36.789] iteration 6559 : loss : 0.078143, loss_ce: 0.018007
[00:57:37.090] iteration 6560 : loss : 0.062241, loss_ce: 0.024423
[00:57:37.417] iteration 6561 : loss : 0.059191, loss_ce: 0.021839
[00:57:37.726] iteration 6562 : loss : 0.113351, loss_ce: 0.020552
[00:57:38.043] iteration 6563 : loss : 0.050445, loss_ce: 0.007001
[00:57:38.345] iteration 6564 : loss : 0.096577, loss_ce: 0.013745
[00:57:38.651] iteration 6565 : loss : 0.058201, loss_ce: 0.013575
[00:57:38.964] iteration 6566 : loss : 0.076350, loss_ce: 0.020948
[00:57:39.269] iteration 6567 : loss : 0.080693, loss_ce: 0.020849
[00:57:39.578] iteration 6568 : loss : 0.045206, loss_ce: 0.009468
[00:57:39.888] iteration 6569 : loss : 0.063746, loss_ce: 0.026525
[00:57:40.190] iteration 6570 : loss : 0.090907, loss_ce: 0.024711
[00:57:40.505] iteration 6571 : loss : 0.079894, loss_ce: 0.023881
[00:57:40.809] iteration 6572 : loss : 0.063637, loss_ce: 0.028960
[00:57:41.121] iteration 6573 : loss : 0.055242, loss_ce: 0.016705
[00:57:41.430] iteration 6574 : loss : 0.076028, loss_ce: 0.029849
[00:57:41.738] iteration 6575 : loss : 0.073422, loss_ce: 0.006905
[00:57:42.051] iteration 6576 : loss : 0.079720, loss_ce: 0.015492
[00:57:42.358] iteration 6577 : loss : 0.111366, loss_ce: 0.006169
[00:57:42.661] iteration 6578 : loss : 0.067118, loss_ce: 0.019862
[00:57:42.969] iteration 6579 : loss : 0.074542, loss_ce: 0.022500
[00:57:43.269] iteration 6580 : loss : 0.051994, loss_ce: 0.024743
[00:57:43.593] iteration 6581 : loss : 0.039333, loss_ce: 0.007464
[00:57:43.905] iteration 6582 : loss : 0.231359, loss_ce: 0.012214
[00:57:44.214] iteration 6583 : loss : 0.096679, loss_ce: 0.021145
[00:57:44.515] iteration 6584 : loss : 0.117108, loss_ce: 0.015328
[00:57:44.828] iteration 6585 : loss : 0.051509, loss_ce: 0.017151
[00:57:45.128] iteration 6586 : loss : 0.058804, loss_ce: 0.019627
[00:57:45.438] iteration 6587 : loss : 0.067186, loss_ce: 0.024254
[00:57:45.743] iteration 6588 : loss : 0.144575, loss_ce: 0.014382
[00:57:46.050] iteration 6589 : loss : 0.083493, loss_ce: 0.016951
[00:57:46.359] iteration 6590 : loss : 0.119704, loss_ce: 0.011769
[00:57:46.665] iteration 6591 : loss : 0.069325, loss_ce: 0.014673
[00:57:46.968] iteration 6592 : loss : 0.056833, loss_ce: 0.021924
[00:57:47.273] iteration 6593 : loss : 0.051769, loss_ce: 0.015736
[00:57:47.580] iteration 6594 : loss : 0.060078, loss_ce: 0.018986
[00:57:47.889] iteration 6595 : loss : 0.086645, loss_ce: 0.018326
[00:57:48.190] iteration 6596 : loss : 0.060433, loss_ce: 0.025333
[00:57:48.496] iteration 6597 : loss : 0.058605, loss_ce: 0.021736
[00:57:48.812] iteration 6598 : loss : 0.151145, loss_ce: 0.007113
[00:57:49.121] iteration 6599 : loss : 0.077639, loss_ce: 0.015000
[00:57:49.433] iteration 6600 : loss : 0.106989, loss_ce: 0.008451
[00:57:49.753] iteration 6601 : loss : 0.056667, loss_ce: 0.016082
[00:57:50.051] iteration 6602 : loss : 0.073554, loss_ce: 0.018798
[00:57:50.357] iteration 6603 : loss : 0.068921, loss_ce: 0.028606
[00:57:50.674] iteration 6604 : loss : 0.077442, loss_ce: 0.013534
[00:57:50.973] iteration 6605 : loss : 0.072561, loss_ce: 0.016808
[00:57:51.278] iteration 6606 : loss : 0.084489, loss_ce: 0.029607
[00:57:51.581] iteration 6607 : loss : 0.114942, loss_ce: 0.011056
[00:57:51.886] iteration 6608 : loss : 0.091354, loss_ce: 0.024897
[00:57:52.191] iteration 6609 : loss : 0.104316, loss_ce: 0.021707
[00:57:52.505] iteration 6610 : loss : 0.056279, loss_ce: 0.014971
[00:57:52.810] iteration 6611 : loss : 0.054536, loss_ce: 0.023501
[00:57:53.118] iteration 6612 : loss : 0.122548, loss_ce: 0.011447
[00:57:53.426] iteration 6613 : loss : 0.064588, loss_ce: 0.015815
[00:57:53.729] iteration 6614 : loss : 0.075278, loss_ce: 0.022367
[00:57:54.029] iteration 6615 : loss : 0.075371, loss_ce: 0.027967
[00:57:54.332] iteration 6616 : loss : 0.096823, loss_ce: 0.013057
[00:57:54.639] iteration 6617 : loss : 0.237793, loss_ce: 0.010408
[00:57:54.954] iteration 6618 : loss : 0.080546, loss_ce: 0.025286
[00:57:55.256] iteration 6619 : loss : 0.125184, loss_ce: 0.032781
[00:57:55.559] iteration 6620 : loss : 0.060571, loss_ce: 0.022247
[00:57:55.887] iteration 6621 : loss : 0.137052, loss_ce: 0.038259
[00:57:56.187] iteration 6622 : loss : 0.069750, loss_ce: 0.020806
[00:57:56.492] iteration 6623 : loss : 0.132309, loss_ce: 0.012050
[00:57:56.793] iteration 6624 : loss : 0.091554, loss_ce: 0.025395
[00:57:57.097] iteration 6625 : loss : 0.081453, loss_ce: 0.020528
[00:57:57.400] iteration 6626 : loss : 0.054874, loss_ce: 0.010706
[00:57:57.707] iteration 6627 : loss : 0.111549, loss_ce: 0.014968
[00:57:58.007] iteration 6628 : loss : 0.069888, loss_ce: 0.017040
[00:57:58.308] iteration 6629 : loss : 0.041972, loss_ce: 0.008613
[00:57:58.621] iteration 6630 : loss : 0.072529, loss_ce: 0.017422
[00:57:58.928] iteration 6631 : loss : 0.052032, loss_ce: 0.023894
[00:57:59.229] iteration 6632 : loss : 0.079141, loss_ce: 0.020874
[00:57:59.533] iteration 6633 : loss : 0.123028, loss_ce: 0.014594
[00:57:59.837] iteration 6634 : loss : 0.059366, loss_ce: 0.014442
[00:58:00.140] iteration 6635 : loss : 0.060843, loss_ce: 0.021545
[00:58:00.448] iteration 6636 : loss : 0.068508, loss_ce: 0.023995
[00:58:00.755] iteration 6637 : loss : 0.057214, loss_ce: 0.014915
[00:58:01.077] iteration 6638 : loss : 0.066800, loss_ce: 0.027629
[00:58:01.380] iteration 6639 : loss : 0.110390, loss_ce: 0.016561
[00:58:01.690] iteration 6640 : loss : 0.076193, loss_ce: 0.020845
[00:58:02.021] iteration 6641 : loss : 0.066362, loss_ce: 0.019612
[00:58:02.320] iteration 6642 : loss : 0.125790, loss_ce: 0.023720
[00:58:02.621] iteration 6643 : loss : 0.125049, loss_ce: 0.008531
[00:58:02.930] iteration 6644 : loss : 0.066546, loss_ce: 0.031842
[00:58:03.236] iteration 6645 : loss : 0.048976, loss_ce: 0.017840
[00:58:03.539] iteration 6646 : loss : 0.136869, loss_ce: 0.028817
[00:58:03.849] iteration 6647 : loss : 0.068323, loss_ce: 0.022704
[00:58:04.150] iteration 6648 : loss : 0.091917, loss_ce: 0.023926
[00:58:04.460] iteration 6649 : loss : 0.125203, loss_ce: 0.023096
[00:58:04.765] iteration 6650 : loss : 0.106435, loss_ce: 0.010697
[00:58:05.077] iteration 6651 : loss : 0.091840, loss_ce: 0.025419
[00:58:05.389] iteration 6652 : loss : 0.065357, loss_ce: 0.031650
[00:58:05.691] iteration 6653 : loss : 0.248863, loss_ce: 0.007928
[00:58:05.996] iteration 6654 : loss : 0.116036, loss_ce: 0.018420
[00:58:06.311] iteration 6655 : loss : 0.233293, loss_ce: 0.011148
[00:58:06.620] iteration 6656 : loss : 0.068384, loss_ce: 0.026124
[00:58:06.928] iteration 6657 : loss : 0.065826, loss_ce: 0.015240
[00:58:07.239] iteration 6658 : loss : 0.063000, loss_ce: 0.016763
[00:58:07.549] iteration 6659 : loss : 0.092336, loss_ce: 0.017316
[00:58:07.852] iteration 6660 : loss : 0.125669, loss_ce: 0.012537
[00:58:08.188] iteration 6661 : loss : 0.066264, loss_ce: 0.016547
[00:58:08.498] iteration 6662 : loss : 0.070258, loss_ce: 0.014221
[00:58:08.811] iteration 6663 : loss : 0.074589, loss_ce: 0.016145
[00:58:09.117] iteration 6664 : loss : 0.115517, loss_ce: 0.011877
[00:58:09.426] iteration 6665 : loss : 0.058776, loss_ce: 0.022684
[00:58:09.736] iteration 6666 : loss : 0.081431, loss_ce: 0.018466
[00:58:10.045] iteration 6667 : loss : 0.082173, loss_ce: 0.017613
[00:58:10.357] iteration 6668 : loss : 0.068468, loss_ce: 0.024340
[00:58:10.658] iteration 6669 : loss : 0.097486, loss_ce: 0.023660
[00:58:10.964] iteration 6670 : loss : 0.057682, loss_ce: 0.019177
[00:58:11.278] iteration 6671 : loss : 0.065471, loss_ce: 0.027622
[00:58:11.368] iteration 6672 : loss : 0.118738, loss_ce: 0.050716
[00:58:30.534] iteration 6673 : loss : 0.075775, loss_ce: 0.023750
[00:58:30.836] iteration 6674 : loss : 0.103301, loss_ce: 0.013607
[00:58:31.148] iteration 6675 : loss : 0.235824, loss_ce: 0.008067
[00:58:31.450] iteration 6676 : loss : 0.074964, loss_ce: 0.028323
[00:58:31.757] iteration 6677 : loss : 0.067193, loss_ce: 0.030043
[00:58:32.059] iteration 6678 : loss : 0.047383, loss_ce: 0.013248
[00:58:32.361] iteration 6679 : loss : 0.063353, loss_ce: 0.023935
[00:58:32.659] iteration 6680 : loss : 0.059478, loss_ce: 0.021700
[00:58:32.983] iteration 6681 : loss : 0.072525, loss_ce: 0.025209
[00:58:33.288] iteration 6682 : loss : 0.055156, loss_ce: 0.014022
[00:58:33.591] iteration 6683 : loss : 0.108205, loss_ce: 0.007999
[00:58:33.893] iteration 6684 : loss : 0.071942, loss_ce: 0.024721
[00:58:34.208] iteration 6685 : loss : 0.063272, loss_ce: 0.024799
[00:58:34.513] iteration 6686 : loss : 0.100647, loss_ce: 0.010485
[00:58:34.816] iteration 6687 : loss : 0.068103, loss_ce: 0.018391
[00:58:35.121] iteration 6688 : loss : 0.053403, loss_ce: 0.013714
[00:58:35.423] iteration 6689 : loss : 0.063937, loss_ce: 0.023344
[00:58:35.734] iteration 6690 : loss : 0.075926, loss_ce: 0.024254
[00:58:36.037] iteration 6691 : loss : 0.077848, loss_ce: 0.021257
[00:58:36.338] iteration 6692 : loss : 0.107961, loss_ce: 0.012235
[00:58:36.639] iteration 6693 : loss : 0.080448, loss_ce: 0.015159
[00:58:36.942] iteration 6694 : loss : 0.055218, loss_ce: 0.007656
[00:58:37.245] iteration 6695 : loss : 0.065615, loss_ce: 0.027400
[00:58:37.551] iteration 6696 : loss : 0.065031, loss_ce: 0.019863
[00:58:37.849] iteration 6697 : loss : 0.069045, loss_ce: 0.022686
[00:58:38.157] iteration 6698 : loss : 0.059093, loss_ce: 0.015412
[00:58:38.460] iteration 6699 : loss : 0.073075, loss_ce: 0.022339
[00:58:38.771] iteration 6700 : loss : 0.128888, loss_ce: 0.011127
[00:58:39.094] iteration 6701 : loss : 0.080312, loss_ce: 0.019374
[00:58:39.389] iteration 6702 : loss : 0.062180, loss_ce: 0.023562
[00:58:39.696] iteration 6703 : loss : 0.125074, loss_ce: 0.014847
[00:58:40.000] iteration 6704 : loss : 0.120738, loss_ce: 0.014561
[00:58:40.308] iteration 6705 : loss : 0.078292, loss_ce: 0.026291
[00:58:40.614] iteration 6706 : loss : 0.071727, loss_ce: 0.020903
[00:58:40.917] iteration 6707 : loss : 0.056494, loss_ce: 0.021506
[00:58:41.218] iteration 6708 : loss : 0.083187, loss_ce: 0.025869
[00:58:41.525] iteration 6709 : loss : 0.075505, loss_ce: 0.020951
[00:58:41.821] iteration 6710 : loss : 0.065737, loss_ce: 0.030546
[00:58:42.122] iteration 6711 : loss : 0.058461, loss_ce: 0.018278
[00:58:42.430] iteration 6712 : loss : 0.076172, loss_ce: 0.022462
[00:58:42.729] iteration 6713 : loss : 0.077397, loss_ce: 0.022182
[00:58:43.033] iteration 6714 : loss : 0.100280, loss_ce: 0.007185
[00:58:43.338] iteration 6715 : loss : 0.095709, loss_ce: 0.031483
[00:58:43.648] iteration 6716 : loss : 0.092139, loss_ce: 0.029708
[00:58:43.948] iteration 6717 : loss : 0.116687, loss_ce: 0.013764
[00:58:44.254] iteration 6718 : loss : 0.068508, loss_ce: 0.016676
[00:58:44.572] iteration 6719 : loss : 0.078535, loss_ce: 0.028259
[00:58:44.870] iteration 6720 : loss : 0.069121, loss_ce: 0.028605
[00:58:45.184] iteration 6721 : loss : 0.069064, loss_ce: 0.023301
[00:58:45.484] iteration 6722 : loss : 0.120840, loss_ce: 0.015328
[00:58:45.794] iteration 6723 : loss : 0.067448, loss_ce: 0.031792
[00:58:46.093] iteration 6724 : loss : 0.068007, loss_ce: 0.021210
[00:58:46.399] iteration 6725 : loss : 0.052885, loss_ce: 0.016026
[00:58:46.709] iteration 6726 : loss : 0.114821, loss_ce: 0.020594
[00:58:47.008] iteration 6727 : loss : 0.072487, loss_ce: 0.020683
[00:58:47.319] iteration 6728 : loss : 0.141393, loss_ce: 0.011536
[00:58:47.628] iteration 6729 : loss : 0.067678, loss_ce: 0.024834
[00:58:47.941] iteration 6730 : loss : 0.049237, loss_ce: 0.015984
[00:58:48.252] iteration 6731 : loss : 0.102626, loss_ce: 0.020615
[00:58:48.558] iteration 6732 : loss : 0.142736, loss_ce: 0.019482
[00:58:48.864] iteration 6733 : loss : 0.095556, loss_ce: 0.014086
[00:58:49.169] iteration 6734 : loss : 0.077392, loss_ce: 0.023929
[00:58:49.479] iteration 6735 : loss : 0.111582, loss_ce: 0.016969
[00:58:49.783] iteration 6736 : loss : 0.069203, loss_ce: 0.024014
[00:58:50.084] iteration 6737 : loss : 0.100353, loss_ce: 0.027297
[00:58:50.386] iteration 6738 : loss : 0.097165, loss_ce: 0.010131
[00:58:50.691] iteration 6739 : loss : 0.074854, loss_ce: 0.017673
[00:58:51.000] iteration 6740 : loss : 0.070926, loss_ce: 0.027156
[00:58:51.327] iteration 6741 : loss : 0.122174, loss_ce: 0.012098
[00:58:51.634] iteration 6742 : loss : 0.065240, loss_ce: 0.013366
[00:58:51.936] iteration 6743 : loss : 0.124900, loss_ce: 0.004525
[00:58:52.248] iteration 6744 : loss : 0.045038, loss_ce: 0.014320
[00:58:52.554] iteration 6745 : loss : 0.123770, loss_ce: 0.017853
[00:58:52.855] iteration 6746 : loss : 0.122007, loss_ce: 0.021590
[00:58:53.166] iteration 6747 : loss : 0.078811, loss_ce: 0.030725
[00:58:53.469] iteration 6748 : loss : 0.115717, loss_ce: 0.017039
[00:58:53.778] iteration 6749 : loss : 0.084255, loss_ce: 0.020255
[00:58:54.081] iteration 6750 : loss : 0.142788, loss_ce: 0.020396
[00:58:54.385] iteration 6751 : loss : 0.065631, loss_ce: 0.022497
[00:58:54.697] iteration 6752 : loss : 0.069145, loss_ce: 0.026661
[00:58:55.009] iteration 6753 : loss : 0.062935, loss_ce: 0.023434
[00:58:55.310] iteration 6754 : loss : 0.055184, loss_ce: 0.022873
[00:58:55.622] iteration 6755 : loss : 0.048815, loss_ce: 0.020657
[00:58:55.922] iteration 6756 : loss : 0.061592, loss_ce: 0.020536
[00:58:56.228] iteration 6757 : loss : 0.109137, loss_ce: 0.024674
[00:58:56.535] iteration 6758 : loss : 0.241561, loss_ce: 0.006502
[00:58:56.834] iteration 6759 : loss : 0.056090, loss_ce: 0.018239
[00:58:57.138] iteration 6760 : loss : 0.106942, loss_ce: 0.005666
[00:58:57.461] iteration 6761 : loss : 0.046339, loss_ce: 0.013231
[00:58:57.767] iteration 6762 : loss : 0.079102, loss_ce: 0.015744
[00:58:58.074] iteration 6763 : loss : 0.064897, loss_ce: 0.017385
[00:58:58.383] iteration 6764 : loss : 0.119974, loss_ce: 0.018382
[00:58:58.690] iteration 6765 : loss : 0.075529, loss_ce: 0.012679
[00:58:58.991] iteration 6766 : loss : 0.062049, loss_ce: 0.015135
[00:58:59.294] iteration 6767 : loss : 0.060533, loss_ce: 0.016473
[00:58:59.609] iteration 6768 : loss : 0.294063, loss_ce: 0.018195
[00:58:59.915] iteration 6769 : loss : 0.064582, loss_ce: 0.021927
[00:59:00.223] iteration 6770 : loss : 0.063696, loss_ce: 0.021634
[00:59:00.532] iteration 6771 : loss : 0.120722, loss_ce: 0.016676
[00:59:00.832] iteration 6772 : loss : 0.062547, loss_ce: 0.011833
[00:59:01.142] iteration 6773 : loss : 0.122979, loss_ce: 0.009167
[00:59:01.447] iteration 6774 : loss : 0.064489, loss_ce: 0.018123
[00:59:01.753] iteration 6775 : loss : 0.057626, loss_ce: 0.019642
[00:59:02.068] iteration 6776 : loss : 0.072055, loss_ce: 0.020075
[00:59:02.372] iteration 6777 : loss : 0.073176, loss_ce: 0.030162
[00:59:02.685] iteration 6778 : loss : 0.070208, loss_ce: 0.013396
[00:59:02.988] iteration 6779 : loss : 0.117921, loss_ce: 0.009767
[00:59:03.295] iteration 6780 : loss : 0.054920, loss_ce: 0.023835
[00:59:03.629] iteration 6781 : loss : 0.064609, loss_ce: 0.019911
[00:59:03.929] iteration 6782 : loss : 0.075921, loss_ce: 0.014800
[00:59:04.234] iteration 6783 : loss : 0.057853, loss_ce: 0.019374
[00:59:04.543] iteration 6784 : loss : 0.072806, loss_ce: 0.025775
[00:59:04.844] iteration 6785 : loss : 0.066845, loss_ce: 0.015843
[00:59:05.150] iteration 6786 : loss : 0.136075, loss_ce: 0.020299
[00:59:05.461] iteration 6787 : loss : 0.122946, loss_ce: 0.010849
[00:59:05.764] iteration 6788 : loss : 0.116155, loss_ce: 0.012247
[00:59:06.068] iteration 6789 : loss : 0.173825, loss_ce: 0.013671
[00:59:06.373] iteration 6790 : loss : 0.104632, loss_ce: 0.006980
[00:59:06.695] iteration 6791 : loss : 0.072026, loss_ce: 0.024221
[00:59:06.996] iteration 6792 : loss : 0.077736, loss_ce: 0.016337
[00:59:07.303] iteration 6793 : loss : 0.072412, loss_ce: 0.024145
[00:59:07.607] iteration 6794 : loss : 0.069751, loss_ce: 0.016392
[00:59:07.913] iteration 6795 : loss : 0.068792, loss_ce: 0.022204
[00:59:08.220] iteration 6796 : loss : 0.146581, loss_ce: 0.010568
[00:59:08.528] iteration 6797 : loss : 0.068240, loss_ce: 0.010969
[00:59:08.842] iteration 6798 : loss : 0.046762, loss_ce: 0.016092
[00:59:09.150] iteration 6799 : loss : 0.119996, loss_ce: 0.021707
[00:59:09.468] iteration 6800 : loss : 0.069318, loss_ce: 0.024587
[00:59:09.826] iteration 6801 : loss : 0.045785, loss_ce: 0.016694
[00:59:10.135] iteration 6802 : loss : 0.084541, loss_ce: 0.038004
[00:59:10.446] iteration 6803 : loss : 0.122626, loss_ce: 0.020174
[00:59:10.754] iteration 6804 : loss : 0.075034, loss_ce: 0.018969
[00:59:11.065] iteration 6805 : loss : 0.051155, loss_ce: 0.019803
[00:59:11.379] iteration 6806 : loss : 0.075175, loss_ce: 0.025714
[00:59:11.686] iteration 6807 : loss : 0.078534, loss_ce: 0.026903
[00:59:11.994] iteration 6808 : loss : 0.064469, loss_ce: 0.025538
[00:59:12.304] iteration 6809 : loss : 0.112743, loss_ce: 0.031525
[00:59:12.607] iteration 6810 : loss : 0.077323, loss_ce: 0.030377
[00:59:12.698] iteration 6811 : loss : 0.124760, loss_ce: 0.034036
[00:59:28.998] iteration 6812 : loss : 0.068380, loss_ce: 0.022664
[00:59:29.309] iteration 6813 : loss : 0.063733, loss_ce: 0.021923
[00:59:29.612] iteration 6814 : loss : 0.071143, loss_ce: 0.019975
[00:59:29.924] iteration 6815 : loss : 0.069297, loss_ce: 0.013680
[00:59:30.232] iteration 6816 : loss : 0.184908, loss_ce: 0.014197
[00:59:30.534] iteration 6817 : loss : 0.078633, loss_ce: 0.006314
[00:59:30.841] iteration 6818 : loss : 0.064775, loss_ce: 0.018135
[00:59:31.142] iteration 6819 : loss : 0.059463, loss_ce: 0.025557
[00:59:31.457] iteration 6820 : loss : 0.065484, loss_ce: 0.009949
[00:59:31.788] iteration 6821 : loss : 0.078960, loss_ce: 0.011573
[00:59:32.094] iteration 6822 : loss : 0.120784, loss_ce: 0.015860
[00:59:32.398] iteration 6823 : loss : 0.066134, loss_ce: 0.022780
[00:59:32.699] iteration 6824 : loss : 0.063020, loss_ce: 0.013345
[00:59:33.002] iteration 6825 : loss : 0.060872, loss_ce: 0.024735
[00:59:33.309] iteration 6826 : loss : 0.072434, loss_ce: 0.013043
[00:59:33.619] iteration 6827 : loss : 0.095287, loss_ce: 0.021143
[00:59:33.924] iteration 6828 : loss : 0.118545, loss_ce: 0.022120
[00:59:34.230] iteration 6829 : loss : 0.089192, loss_ce: 0.019715
[00:59:34.537] iteration 6830 : loss : 0.074877, loss_ce: 0.018708
[00:59:34.847] iteration 6831 : loss : 0.065880, loss_ce: 0.010787
[00:59:35.155] iteration 6832 : loss : 0.059498, loss_ce: 0.011330
[00:59:35.461] iteration 6833 : loss : 0.061947, loss_ce: 0.019559
[00:59:35.766] iteration 6834 : loss : 0.065953, loss_ce: 0.033762
[00:59:36.073] iteration 6835 : loss : 0.134345, loss_ce: 0.022961
[00:59:36.381] iteration 6836 : loss : 0.123951, loss_ce: 0.024827
[00:59:36.685] iteration 6837 : loss : 0.092421, loss_ce: 0.031439
[00:59:36.994] iteration 6838 : loss : 0.061570, loss_ce: 0.013819
[00:59:37.299] iteration 6839 : loss : 0.061059, loss_ce: 0.025070
[00:59:37.607] iteration 6840 : loss : 0.127138, loss_ce: 0.010941
[00:59:37.935] iteration 6841 : loss : 0.062078, loss_ce: 0.021589
[00:59:38.238] iteration 6842 : loss : 0.110673, loss_ce: 0.015727
[00:59:38.548] iteration 6843 : loss : 0.079964, loss_ce: 0.015688
[00:59:38.851] iteration 6844 : loss : 0.069395, loss_ce: 0.021772
[00:59:39.157] iteration 6845 : loss : 0.064071, loss_ce: 0.024889
[00:59:39.462] iteration 6846 : loss : 0.116340, loss_ce: 0.016148
[00:59:39.769] iteration 6847 : loss : 0.064955, loss_ce: 0.017200
[00:59:40.074] iteration 6848 : loss : 0.064063, loss_ce: 0.018622
[00:59:40.388] iteration 6849 : loss : 0.054822, loss_ce: 0.016871
[00:59:40.693] iteration 6850 : loss : 0.062815, loss_ce: 0.024536
[00:59:40.996] iteration 6851 : loss : 0.185614, loss_ce: 0.007753
[00:59:41.315] iteration 6852 : loss : 0.165784, loss_ce: 0.015282
[00:59:41.622] iteration 6853 : loss : 0.107295, loss_ce: 0.019802
[00:59:41.933] iteration 6854 : loss : 0.108841, loss_ce: 0.014566
[00:59:42.249] iteration 6855 : loss : 0.126296, loss_ce: 0.016007
[00:59:42.556] iteration 6856 : loss : 0.072398, loss_ce: 0.018537
[00:59:42.874] iteration 6857 : loss : 0.065549, loss_ce: 0.010479
[00:59:43.184] iteration 6858 : loss : 0.115422, loss_ce: 0.016947
[00:59:43.487] iteration 6859 : loss : 0.074372, loss_ce: 0.029715
[00:59:43.792] iteration 6860 : loss : 0.108999, loss_ce: 0.014943
[00:59:44.107] iteration 6861 : loss : 0.063330, loss_ce: 0.017759
[00:59:44.420] iteration 6862 : loss : 0.062814, loss_ce: 0.019685
[00:59:44.724] iteration 6863 : loss : 0.065035, loss_ce: 0.022941
[00:59:45.028] iteration 6864 : loss : 0.066513, loss_ce: 0.019508
[00:59:45.339] iteration 6865 : loss : 0.058338, loss_ce: 0.011420
[00:59:45.640] iteration 6866 : loss : 0.101157, loss_ce: 0.018704
[00:59:45.951] iteration 6867 : loss : 0.205781, loss_ce: 0.006458
[00:59:46.261] iteration 6868 : loss : 0.136421, loss_ce: 0.022019
[00:59:46.562] iteration 6869 : loss : 0.058066, loss_ce: 0.014765
[00:59:46.868] iteration 6870 : loss : 0.151205, loss_ce: 0.018810
[00:59:47.179] iteration 6871 : loss : 0.139631, loss_ce: 0.020574
[00:59:47.481] iteration 6872 : loss : 0.052619, loss_ce: 0.013868
[00:59:47.795] iteration 6873 : loss : 0.058635, loss_ce: 0.026728
[00:59:48.103] iteration 6874 : loss : 0.061586, loss_ce: 0.021202
[00:59:48.404] iteration 6875 : loss : 0.075867, loss_ce: 0.011443
[00:59:48.723] iteration 6876 : loss : 0.052068, loss_ce: 0.016315
[00:59:49.023] iteration 6877 : loss : 0.073702, loss_ce: 0.023088
[00:59:49.335] iteration 6878 : loss : 0.110881, loss_ce: 0.017565
[00:59:49.639] iteration 6879 : loss : 0.054089, loss_ce: 0.006406
[00:59:49.949] iteration 6880 : loss : 0.133325, loss_ce: 0.017798
[00:59:50.278] iteration 6881 : loss : 0.069336, loss_ce: 0.013591
[00:59:50.582] iteration 6882 : loss : 0.091469, loss_ce: 0.017600
[00:59:50.892] iteration 6883 : loss : 0.053637, loss_ce: 0.014683
[00:59:51.201] iteration 6884 : loss : 0.061390, loss_ce: 0.026330
[00:59:51.505] iteration 6885 : loss : 0.085085, loss_ce: 0.027077
[00:59:51.809] iteration 6886 : loss : 0.071905, loss_ce: 0.028951
[00:59:52.123] iteration 6887 : loss : 0.066185, loss_ce: 0.020467
[00:59:52.426] iteration 6888 : loss : 0.063025, loss_ce: 0.019352
[00:59:52.728] iteration 6889 : loss : 0.105610, loss_ce: 0.026874
[00:59:53.033] iteration 6890 : loss : 0.078932, loss_ce: 0.021201
[00:59:53.346] iteration 6891 : loss : 0.062803, loss_ce: 0.010735
[00:59:53.654] iteration 6892 : loss : 0.070223, loss_ce: 0.020090
[00:59:53.958] iteration 6893 : loss : 0.066763, loss_ce: 0.020673
[00:59:54.256] iteration 6894 : loss : 0.056785, loss_ce: 0.018248
[00:59:54.568] iteration 6895 : loss : 0.062830, loss_ce: 0.013098
[00:59:54.871] iteration 6896 : loss : 0.063948, loss_ce: 0.015196
[00:59:55.178] iteration 6897 : loss : 0.052695, loss_ce: 0.018463
[00:59:55.486] iteration 6898 : loss : 0.109204, loss_ce: 0.013379
[00:59:55.793] iteration 6899 : loss : 0.057292, loss_ce: 0.015051
[00:59:56.100] iteration 6900 : loss : 0.063577, loss_ce: 0.025632
[00:59:56.426] iteration 6901 : loss : 0.078057, loss_ce: 0.027176
[00:59:56.726] iteration 6902 : loss : 0.058982, loss_ce: 0.026177
[00:59:57.034] iteration 6903 : loss : 0.111358, loss_ce: 0.008694
[00:59:57.338] iteration 6904 : loss : 0.053877, loss_ce: 0.021921
[00:59:57.649] iteration 6905 : loss : 0.061134, loss_ce: 0.012387
[00:59:57.950] iteration 6906 : loss : 0.067128, loss_ce: 0.027765
[00:59:58.260] iteration 6907 : loss : 0.062429, loss_ce: 0.012982
[00:59:58.562] iteration 6908 : loss : 0.055781, loss_ce: 0.018394
[00:59:58.870] iteration 6909 : loss : 0.117276, loss_ce: 0.022122
[00:59:59.174] iteration 6910 : loss : 0.075088, loss_ce: 0.016601
[00:59:59.478] iteration 6911 : loss : 0.065160, loss_ce: 0.023164
[00:59:59.786] iteration 6912 : loss : 0.074752, loss_ce: 0.030820
[01:00:00.091] iteration 6913 : loss : 0.076498, loss_ce: 0.029003
[01:00:00.404] iteration 6914 : loss : 0.052838, loss_ce: 0.013272
[01:00:00.712] iteration 6915 : loss : 0.058890, loss_ce: 0.018997
[01:00:01.026] iteration 6916 : loss : 0.056599, loss_ce: 0.024826
[01:00:01.329] iteration 6917 : loss : 0.060573, loss_ce: 0.019624
[01:00:01.631] iteration 6918 : loss : 0.056511, loss_ce: 0.022409
[01:00:01.934] iteration 6919 : loss : 0.115333, loss_ce: 0.012393
[01:00:02.244] iteration 6920 : loss : 0.170076, loss_ce: 0.021981
[01:00:02.570] iteration 6921 : loss : 0.062642, loss_ce: 0.019128
[01:00:02.872] iteration 6922 : loss : 0.064638, loss_ce: 0.026865
[01:00:03.189] iteration 6923 : loss : 0.113725, loss_ce: 0.015693
[01:00:03.500] iteration 6924 : loss : 0.176578, loss_ce: 0.019283
[01:00:03.802] iteration 6925 : loss : 0.178345, loss_ce: 0.013689
[01:00:04.104] iteration 6926 : loss : 0.064883, loss_ce: 0.022770
[01:00:04.406] iteration 6927 : loss : 0.067485, loss_ce: 0.021006
[01:00:04.713] iteration 6928 : loss : 0.043314, loss_ce: 0.018534
[01:00:05.019] iteration 6929 : loss : 0.115292, loss_ce: 0.016304
[01:00:05.321] iteration 6930 : loss : 0.136654, loss_ce: 0.020943
[01:00:05.636] iteration 6931 : loss : 0.052120, loss_ce: 0.012339
[01:00:05.949] iteration 6932 : loss : 0.050408, loss_ce: 0.009826
[01:00:06.257] iteration 6933 : loss : 0.051548, loss_ce: 0.013408
[01:00:06.576] iteration 6934 : loss : 0.057340, loss_ce: 0.019719
[01:00:06.886] iteration 6935 : loss : 0.050492, loss_ce: 0.021326
[01:00:07.192] iteration 6936 : loss : 0.056930, loss_ce: 0.013767
[01:00:07.500] iteration 6937 : loss : 0.118739, loss_ce: 0.015725
[01:00:07.811] iteration 6938 : loss : 0.069533, loss_ce: 0.016954
[01:00:08.124] iteration 6939 : loss : 0.064345, loss_ce: 0.015357
[01:00:08.429] iteration 6940 : loss : 0.103531, loss_ce: 0.017470
[01:00:08.762] iteration 6941 : loss : 0.106701, loss_ce: 0.009973
[01:00:09.080] iteration 6942 : loss : 0.179784, loss_ce: 0.016888
[01:00:09.384] iteration 6943 : loss : 0.065439, loss_ce: 0.023126
[01:00:09.696] iteration 6944 : loss : 0.056853, loss_ce: 0.012287
[01:00:10.008] iteration 6945 : loss : 0.054174, loss_ce: 0.014776
[01:00:10.327] iteration 6946 : loss : 0.077855, loss_ce: 0.026798
[01:00:10.630] iteration 6947 : loss : 0.068423, loss_ce: 0.024811
[01:00:10.946] iteration 6948 : loss : 0.055462, loss_ce: 0.013360
[01:00:11.261] iteration 6949 : loss : 0.053762, loss_ce: 0.026549
[01:00:11.346] iteration 6950 : loss : 0.224675, loss_ce: 0.016429
[01:00:30.510] iteration 6951 : loss : 0.062853, loss_ce: 0.014745
[01:00:30.808] iteration 6952 : loss : 0.071237, loss_ce: 0.017385
[01:00:31.120] iteration 6953 : loss : 0.116318, loss_ce: 0.009148
[01:00:31.425] iteration 6954 : loss : 0.101479, loss_ce: 0.015695
[01:00:31.727] iteration 6955 : loss : 0.040277, loss_ce: 0.011694
[01:00:32.030] iteration 6956 : loss : 0.114821, loss_ce: 0.014532
[01:00:32.332] iteration 6957 : loss : 0.071369, loss_ce: 0.021419
[01:00:32.639] iteration 6958 : loss : 0.114455, loss_ce: 0.017468
[01:00:32.941] iteration 6959 : loss : 0.050371, loss_ce: 0.019327
[01:00:33.242] iteration 6960 : loss : 0.108128, loss_ce: 0.023244
[01:00:33.559] iteration 6961 : loss : 0.126989, loss_ce: 0.011690
[01:00:33.859] iteration 6962 : loss : 0.082562, loss_ce: 0.012726
[01:00:34.160] iteration 6963 : loss : 0.083151, loss_ce: 0.020258
[01:00:34.467] iteration 6964 : loss : 0.077557, loss_ce: 0.027974
[01:00:34.772] iteration 6965 : loss : 0.121847, loss_ce: 0.018231
[01:00:35.079] iteration 6966 : loss : 0.067984, loss_ce: 0.023223
[01:00:35.379] iteration 6967 : loss : 0.121764, loss_ce: 0.019119
[01:00:35.686] iteration 6968 : loss : 0.075853, loss_ce: 0.024797
[01:00:35.987] iteration 6969 : loss : 0.059506, loss_ce: 0.015372
[01:00:36.291] iteration 6970 : loss : 0.060737, loss_ce: 0.015468
[01:00:36.598] iteration 6971 : loss : 0.064270, loss_ce: 0.020662
[01:00:36.908] iteration 6972 : loss : 0.063371, loss_ce: 0.016626
[01:00:37.216] iteration 6973 : loss : 0.069655, loss_ce: 0.016790
[01:00:37.516] iteration 6974 : loss : 0.071789, loss_ce: 0.014661
[01:00:37.824] iteration 6975 : loss : 0.072463, loss_ce: 0.020665
[01:00:38.129] iteration 6976 : loss : 0.058547, loss_ce: 0.024953
[01:00:38.441] iteration 6977 : loss : 0.068523, loss_ce: 0.018321
[01:00:38.745] iteration 6978 : loss : 0.054050, loss_ce: 0.024604
[01:00:39.057] iteration 6979 : loss : 0.065310, loss_ce: 0.023377
[01:00:39.365] iteration 6980 : loss : 0.072691, loss_ce: 0.019602
[01:00:39.690] iteration 6981 : loss : 0.070115, loss_ce: 0.009262
[01:00:39.990] iteration 6982 : loss : 0.117337, loss_ce: 0.021441
[01:00:40.304] iteration 6983 : loss : 0.122100, loss_ce: 0.017806
[01:00:40.603] iteration 6984 : loss : 0.067946, loss_ce: 0.025356
[01:00:40.911] iteration 6985 : loss : 0.071911, loss_ce: 0.024755
[01:00:41.217] iteration 6986 : loss : 0.113678, loss_ce: 0.015700
[01:00:41.521] iteration 6987 : loss : 0.090976, loss_ce: 0.010089
[01:00:41.826] iteration 6988 : loss : 0.047066, loss_ce: 0.015087
[01:00:42.133] iteration 6989 : loss : 0.073196, loss_ce: 0.029045
[01:00:42.446] iteration 6990 : loss : 0.069797, loss_ce: 0.023304
[01:00:42.748] iteration 6991 : loss : 0.109061, loss_ce: 0.011949
[01:00:43.054] iteration 6992 : loss : 0.057862, loss_ce: 0.013274
[01:00:43.362] iteration 6993 : loss : 0.061056, loss_ce: 0.024121
[01:00:43.669] iteration 6994 : loss : 0.073767, loss_ce: 0.024683
[01:00:43.975] iteration 6995 : loss : 0.062095, loss_ce: 0.016351
[01:00:44.277] iteration 6996 : loss : 0.150494, loss_ce: 0.011263
[01:00:44.579] iteration 6997 : loss : 0.250857, loss_ce: 0.015277
[01:00:44.880] iteration 6998 : loss : 0.068460, loss_ce: 0.016795
[01:00:45.180] iteration 6999 : loss : 0.129139, loss_ce: 0.016606
[01:00:45.482] iteration 7000 : loss : 0.057499, loss_ce: 0.027404
[01:00:45.776] iteration 7001 : loss : 0.072961, loss_ce: 0.028732
[01:00:46.062] iteration 7002 : loss : 0.064119, loss_ce: 0.027181
[01:00:46.338] iteration 7003 : loss : 0.075475, loss_ce: 0.032466
[01:00:46.620] iteration 7004 : loss : 0.147961, loss_ce: 0.014599
[01:00:46.897] iteration 7005 : loss : 0.122636, loss_ce: 0.028038
[01:00:47.176] iteration 7006 : loss : 0.073109, loss_ce: 0.008672
[01:00:47.451] iteration 7007 : loss : 0.068704, loss_ce: 0.020420
[01:00:47.730] iteration 7008 : loss : 0.069012, loss_ce: 0.021129
[01:00:48.010] iteration 7009 : loss : 0.113228, loss_ce: 0.019933
[01:00:48.284] iteration 7010 : loss : 0.043770, loss_ce: 0.006533
[01:00:48.565] iteration 7011 : loss : 0.052604, loss_ce: 0.007189
[01:00:48.850] iteration 7012 : loss : 0.089313, loss_ce: 0.024428
[01:00:49.137] iteration 7013 : loss : 0.118883, loss_ce: 0.015660
[01:00:49.442] iteration 7014 : loss : 0.069155, loss_ce: 0.016656
[01:00:49.740] iteration 7015 : loss : 0.045794, loss_ce: 0.013568
[01:00:50.034] iteration 7016 : loss : 0.075322, loss_ce: 0.024096
[01:00:50.328] iteration 7017 : loss : 0.088569, loss_ce: 0.016214
[01:00:50.624] iteration 7018 : loss : 0.128002, loss_ce: 0.009081
[01:00:50.914] iteration 7019 : loss : 0.050261, loss_ce: 0.019593
[01:00:51.218] iteration 7020 : loss : 0.051092, loss_ce: 0.014249
[01:00:51.533] iteration 7021 : loss : 0.068755, loss_ce: 0.019652
[01:00:51.826] iteration 7022 : loss : 0.056584, loss_ce: 0.018498
[01:00:52.117] iteration 7023 : loss : 0.115931, loss_ce: 0.007644
[01:00:52.406] iteration 7024 : loss : 0.054878, loss_ce: 0.006104
[01:00:52.698] iteration 7025 : loss : 0.064719, loss_ce: 0.017992
[01:00:52.990] iteration 7026 : loss : 0.135613, loss_ce: 0.023557
[01:00:53.284] iteration 7027 : loss : 0.171164, loss_ce: 0.005690
[01:00:53.580] iteration 7028 : loss : 0.082830, loss_ce: 0.018656
[01:00:53.873] iteration 7029 : loss : 0.060476, loss_ce: 0.026630
[01:00:54.165] iteration 7030 : loss : 0.065793, loss_ce: 0.015818
[01:00:54.458] iteration 7031 : loss : 0.071518, loss_ce: 0.026771
[01:00:54.756] iteration 7032 : loss : 0.055844, loss_ce: 0.024406
[01:00:55.049] iteration 7033 : loss : 0.106148, loss_ce: 0.014638
[01:00:55.342] iteration 7034 : loss : 0.171552, loss_ce: 0.004771
[01:00:55.632] iteration 7035 : loss : 0.065248, loss_ce: 0.023522
[01:00:55.921] iteration 7036 : loss : 0.081534, loss_ce: 0.025439
[01:00:56.220] iteration 7037 : loss : 0.111395, loss_ce: 0.013965
[01:00:56.513] iteration 7038 : loss : 0.072778, loss_ce: 0.015756
[01:00:56.809] iteration 7039 : loss : 0.070294, loss_ce: 0.019998
[01:00:57.103] iteration 7040 : loss : 0.062495, loss_ce: 0.022816
[01:00:57.413] iteration 7041 : loss : 0.119162, loss_ce: 0.012338
[01:00:57.707] iteration 7042 : loss : 0.059504, loss_ce: 0.019830
[01:00:58.000] iteration 7043 : loss : 0.118358, loss_ce: 0.008390
[01:00:58.296] iteration 7044 : loss : 0.052924, loss_ce: 0.015378
[01:00:58.591] iteration 7045 : loss : 0.179385, loss_ce: 0.004589
[01:00:58.882] iteration 7046 : loss : 0.079348, loss_ce: 0.018942
[01:00:59.173] iteration 7047 : loss : 0.056228, loss_ce: 0.018428
[01:00:59.469] iteration 7048 : loss : 0.060349, loss_ce: 0.027859
[01:00:59.764] iteration 7049 : loss : 0.078531, loss_ce: 0.023814
[01:01:00.061] iteration 7050 : loss : 0.055849, loss_ce: 0.021755
[01:01:00.362] iteration 7051 : loss : 0.117326, loss_ce: 0.017865
[01:01:00.649] iteration 7052 : loss : 0.068021, loss_ce: 0.024659
[01:01:00.946] iteration 7053 : loss : 0.049407, loss_ce: 0.013937
[01:01:01.242] iteration 7054 : loss : 0.090817, loss_ce: 0.015140
[01:01:01.538] iteration 7055 : loss : 0.084370, loss_ce: 0.010874
[01:01:01.837] iteration 7056 : loss : 0.083140, loss_ce: 0.037268
[01:01:02.131] iteration 7057 : loss : 0.107284, loss_ce: 0.011596
[01:01:02.423] iteration 7058 : loss : 0.063976, loss_ce: 0.021758
[01:01:02.719] iteration 7059 : loss : 0.072557, loss_ce: 0.027732
[01:01:03.011] iteration 7060 : loss : 0.066265, loss_ce: 0.017837
[01:01:03.315] iteration 7061 : loss : 0.067933, loss_ce: 0.026375
[01:01:03.610] iteration 7062 : loss : 0.063947, loss_ce: 0.009555
[01:01:03.906] iteration 7063 : loss : 0.082789, loss_ce: 0.027353
[01:01:04.205] iteration 7064 : loss : 0.110249, loss_ce: 0.006949
[01:01:04.502] iteration 7065 : loss : 0.113908, loss_ce: 0.009023
[01:01:04.800] iteration 7066 : loss : 0.051191, loss_ce: 0.020018
[01:01:05.102] iteration 7067 : loss : 0.048044, loss_ce: 0.012809
[01:01:05.405] iteration 7068 : loss : 0.077170, loss_ce: 0.017766
[01:01:05.702] iteration 7069 : loss : 0.077235, loss_ce: 0.018199
[01:01:06.000] iteration 7070 : loss : 0.069057, loss_ce: 0.024831
[01:01:06.294] iteration 7071 : loss : 0.055493, loss_ce: 0.019178
[01:01:06.590] iteration 7072 : loss : 0.077105, loss_ce: 0.031100
[01:01:06.883] iteration 7073 : loss : 0.089234, loss_ce: 0.015541
[01:01:07.173] iteration 7074 : loss : 0.061155, loss_ce: 0.015365
[01:01:07.471] iteration 7075 : loss : 0.093877, loss_ce: 0.025750
[01:01:07.766] iteration 7076 : loss : 0.077934, loss_ce: 0.032717
[01:01:08.068] iteration 7077 : loss : 0.067408, loss_ce: 0.019831
[01:01:08.370] iteration 7078 : loss : 0.078425, loss_ce: 0.016932
[01:01:08.668] iteration 7079 : loss : 0.054329, loss_ce: 0.019019
[01:01:08.965] iteration 7080 : loss : 0.077303, loss_ce: 0.013048
[01:01:09.295] iteration 7081 : loss : 0.058984, loss_ce: 0.025836
[01:01:09.591] iteration 7082 : loss : 0.075644, loss_ce: 0.028030
[01:01:09.887] iteration 7083 : loss : 0.082540, loss_ce: 0.025242
[01:01:10.186] iteration 7084 : loss : 0.063060, loss_ce: 0.020150
[01:01:10.482] iteration 7085 : loss : 0.105180, loss_ce: 0.016519
[01:01:10.782] iteration 7086 : loss : 0.131173, loss_ce: 0.014518
[01:01:11.077] iteration 7087 : loss : 0.073148, loss_ce: 0.024027
[01:01:11.376] iteration 7088 : loss : 0.075695, loss_ce: 0.018749
[01:01:11.457] iteration 7089 : loss : 0.115292, loss_ce: 0.023364
[01:01:29.592] iteration 7090 : loss : 0.057790, loss_ce: 0.021189
[01:01:29.890] iteration 7091 : loss : 0.067229, loss_ce: 0.019361
[01:01:30.189] iteration 7092 : loss : 0.079142, loss_ce: 0.019333
[01:01:30.486] iteration 7093 : loss : 0.103170, loss_ce: 0.015009
[01:01:30.780] iteration 7094 : loss : 0.055963, loss_ce: 0.017387
[01:01:31.077] iteration 7095 : loss : 0.055015, loss_ce: 0.014512
[01:01:31.373] iteration 7096 : loss : 0.069602, loss_ce: 0.016799
[01:01:31.666] iteration 7097 : loss : 0.053688, loss_ce: 0.025426
[01:01:31.954] iteration 7098 : loss : 0.093973, loss_ce: 0.013557
[01:01:32.246] iteration 7099 : loss : 0.048550, loss_ce: 0.017243
[01:01:32.548] iteration 7100 : loss : 0.055091, loss_ce: 0.019857
[01:01:32.854] iteration 7101 : loss : 0.134972, loss_ce: 0.006014
[01:01:33.150] iteration 7102 : loss : 0.111501, loss_ce: 0.016842
[01:01:33.443] iteration 7103 : loss : 0.069905, loss_ce: 0.016548
[01:01:33.741] iteration 7104 : loss : 0.048723, loss_ce: 0.016341
[01:01:34.035] iteration 7105 : loss : 0.053584, loss_ce: 0.020426
[01:01:34.330] iteration 7106 : loss : 0.125236, loss_ce: 0.018910
[01:01:34.627] iteration 7107 : loss : 0.063466, loss_ce: 0.023854
[01:01:34.931] iteration 7108 : loss : 0.118925, loss_ce: 0.009020
[01:01:35.234] iteration 7109 : loss : 0.109207, loss_ce: 0.012707
[01:01:35.532] iteration 7110 : loss : 0.074455, loss_ce: 0.016746
[01:01:35.829] iteration 7111 : loss : 0.080992, loss_ce: 0.022106
[01:01:36.130] iteration 7112 : loss : 0.119551, loss_ce: 0.016807
[01:01:36.429] iteration 7113 : loss : 0.074198, loss_ce: 0.025767
[01:01:36.723] iteration 7114 : loss : 0.120002, loss_ce: 0.020623
[01:01:37.019] iteration 7115 : loss : 0.062284, loss_ce: 0.014630
[01:01:37.314] iteration 7116 : loss : 0.052866, loss_ce: 0.016623
[01:01:37.608] iteration 7117 : loss : 0.086688, loss_ce: 0.020521
[01:01:37.906] iteration 7118 : loss : 0.088816, loss_ce: 0.018859
[01:01:38.202] iteration 7119 : loss : 0.053862, loss_ce: 0.015048
[01:01:38.495] iteration 7120 : loss : 0.131497, loss_ce: 0.022390
[01:01:38.810] iteration 7121 : loss : 0.070637, loss_ce: 0.024189
[01:01:39.103] iteration 7122 : loss : 0.069454, loss_ce: 0.029394
[01:01:39.398] iteration 7123 : loss : 0.064888, loss_ce: 0.030984
[01:01:39.686] iteration 7124 : loss : 0.057854, loss_ce: 0.013835
[01:01:39.977] iteration 7125 : loss : 0.114861, loss_ce: 0.014894
[01:01:40.274] iteration 7126 : loss : 0.286598, loss_ce: 0.007163
[01:01:40.567] iteration 7127 : loss : 0.148110, loss_ce: 0.010764
[01:01:40.861] iteration 7128 : loss : 0.073809, loss_ce: 0.032844
[01:01:41.158] iteration 7129 : loss : 0.074924, loss_ce: 0.015224
[01:01:41.451] iteration 7130 : loss : 0.079129, loss_ce: 0.011810
[01:01:41.748] iteration 7131 : loss : 0.084151, loss_ce: 0.016821
[01:01:42.043] iteration 7132 : loss : 0.196008, loss_ce: 0.010952
[01:01:42.342] iteration 7133 : loss : 0.105438, loss_ce: 0.012020
[01:01:42.638] iteration 7134 : loss : 0.140573, loss_ce: 0.011690
[01:01:42.933] iteration 7135 : loss : 0.058684, loss_ce: 0.010846
[01:01:43.231] iteration 7136 : loss : 0.127283, loss_ce: 0.031284
[01:01:43.526] iteration 7137 : loss : 0.114484, loss_ce: 0.011055
[01:01:43.825] iteration 7138 : loss : 0.112323, loss_ce: 0.019674
[01:01:44.129] iteration 7139 : loss : 0.070443, loss_ce: 0.014130
[01:01:44.424] iteration 7140 : loss : 0.120661, loss_ce: 0.025106
[01:01:44.744] iteration 7141 : loss : 0.067994, loss_ce: 0.024620
[01:01:45.043] iteration 7142 : loss : 0.055660, loss_ce: 0.025906
[01:01:45.336] iteration 7143 : loss : 0.059760, loss_ce: 0.025685
[01:01:45.632] iteration 7144 : loss : 0.058812, loss_ce: 0.011108
[01:01:45.929] iteration 7145 : loss : 0.057058, loss_ce: 0.018926
[01:01:46.220] iteration 7146 : loss : 0.066739, loss_ce: 0.012782
[01:01:46.513] iteration 7147 : loss : 0.061436, loss_ce: 0.015569
[01:01:46.805] iteration 7148 : loss : 0.066040, loss_ce: 0.015276
[01:01:47.098] iteration 7149 : loss : 0.134662, loss_ce: 0.014568
[01:01:47.390] iteration 7150 : loss : 0.089766, loss_ce: 0.022527
[01:01:47.683] iteration 7151 : loss : 0.072600, loss_ce: 0.016068
[01:01:47.979] iteration 7152 : loss : 0.058370, loss_ce: 0.018717
[01:01:48.268] iteration 7153 : loss : 0.129450, loss_ce: 0.012640
[01:01:48.558] iteration 7154 : loss : 0.071454, loss_ce: 0.020273
[01:01:48.853] iteration 7155 : loss : 0.068908, loss_ce: 0.025015
[01:01:49.152] iteration 7156 : loss : 0.070491, loss_ce: 0.017199
[01:01:49.448] iteration 7157 : loss : 0.072002, loss_ce: 0.032299
[01:01:49.743] iteration 7158 : loss : 0.115495, loss_ce: 0.018014
[01:01:50.038] iteration 7159 : loss : 0.066893, loss_ce: 0.020854
[01:01:50.332] iteration 7160 : loss : 0.054655, loss_ce: 0.018191
[01:01:50.643] iteration 7161 : loss : 0.073719, loss_ce: 0.017085
[01:01:50.941] iteration 7162 : loss : 0.074091, loss_ce: 0.022636
[01:01:51.237] iteration 7163 : loss : 0.058148, loss_ce: 0.022970
[01:01:51.535] iteration 7164 : loss : 0.057870, loss_ce: 0.015201
[01:01:51.836] iteration 7165 : loss : 0.057444, loss_ce: 0.015709
[01:01:52.131] iteration 7166 : loss : 0.053796, loss_ce: 0.017682
[01:01:52.432] iteration 7167 : loss : 0.045536, loss_ce: 0.014607
[01:01:52.728] iteration 7168 : loss : 0.081799, loss_ce: 0.017555
[01:01:53.029] iteration 7169 : loss : 0.054549, loss_ce: 0.016193
[01:01:53.327] iteration 7170 : loss : 0.111591, loss_ce: 0.017763
[01:01:53.625] iteration 7171 : loss : 0.046694, loss_ce: 0.013865
[01:01:53.924] iteration 7172 : loss : 0.048221, loss_ce: 0.015998
[01:01:54.224] iteration 7173 : loss : 0.067246, loss_ce: 0.018793
[01:01:54.519] iteration 7174 : loss : 0.054887, loss_ce: 0.017002
[01:01:54.818] iteration 7175 : loss : 0.059478, loss_ce: 0.012567
[01:01:55.112] iteration 7176 : loss : 0.121874, loss_ce: 0.012494
[01:01:55.411] iteration 7177 : loss : 0.069138, loss_ce: 0.025780
[01:01:55.713] iteration 7178 : loss : 0.053896, loss_ce: 0.013403
[01:01:56.011] iteration 7179 : loss : 0.058867, loss_ce: 0.023346
[01:01:56.308] iteration 7180 : loss : 0.057512, loss_ce: 0.017559
[01:01:56.623] iteration 7181 : loss : 0.071271, loss_ce: 0.019989
[01:01:56.920] iteration 7182 : loss : 0.048536, loss_ce: 0.012258
[01:01:57.218] iteration 7183 : loss : 0.063530, loss_ce: 0.011008
[01:01:57.517] iteration 7184 : loss : 0.090005, loss_ce: 0.025273
[01:01:57.819] iteration 7185 : loss : 0.161534, loss_ce: 0.009262
[01:01:58.117] iteration 7186 : loss : 0.057439, loss_ce: 0.015428
[01:01:58.413] iteration 7187 : loss : 0.111087, loss_ce: 0.016900
[01:01:58.707] iteration 7188 : loss : 0.059446, loss_ce: 0.015752
[01:01:59.007] iteration 7189 : loss : 0.066542, loss_ce: 0.026605
[01:01:59.306] iteration 7190 : loss : 0.055756, loss_ce: 0.010859
[01:01:59.602] iteration 7191 : loss : 0.063745, loss_ce: 0.023801
[01:01:59.904] iteration 7192 : loss : 0.112101, loss_ce: 0.011207
[01:02:00.204] iteration 7193 : loss : 0.163270, loss_ce: 0.017127
[01:02:00.502] iteration 7194 : loss : 0.084735, loss_ce: 0.022374
[01:02:00.802] iteration 7195 : loss : 0.073779, loss_ce: 0.026613
[01:02:01.098] iteration 7196 : loss : 0.072276, loss_ce: 0.017958
[01:02:01.395] iteration 7197 : loss : 0.056285, loss_ce: 0.027853
[01:02:01.693] iteration 7198 : loss : 0.162256, loss_ce: 0.010828
[01:02:01.992] iteration 7199 : loss : 0.064064, loss_ce: 0.023296
[01:02:02.289] iteration 7200 : loss : 0.058448, loss_ce: 0.024537
[01:02:02.606] iteration 7201 : loss : 0.065222, loss_ce: 0.017660
[01:02:02.901] iteration 7202 : loss : 0.063204, loss_ce: 0.020739
[01:02:03.199] iteration 7203 : loss : 0.056822, loss_ce: 0.024982
[01:02:03.494] iteration 7204 : loss : 0.062373, loss_ce: 0.016501
[01:02:03.792] iteration 7205 : loss : 0.181926, loss_ce: 0.010560
[01:02:04.090] iteration 7206 : loss : 0.043845, loss_ce: 0.012337
[01:02:04.388] iteration 7207 : loss : 0.055859, loss_ce: 0.024970
[01:02:04.684] iteration 7208 : loss : 0.096718, loss_ce: 0.016528
[01:02:04.982] iteration 7209 : loss : 0.061199, loss_ce: 0.020347
[01:02:05.277] iteration 7210 : loss : 0.063175, loss_ce: 0.015778
[01:02:05.575] iteration 7211 : loss : 0.069637, loss_ce: 0.021509
[01:02:05.875] iteration 7212 : loss : 0.159922, loss_ce: 0.012713
[01:02:06.172] iteration 7213 : loss : 0.074646, loss_ce: 0.017181
[01:02:06.473] iteration 7214 : loss : 0.074547, loss_ce: 0.021948
[01:02:06.774] iteration 7215 : loss : 0.071632, loss_ce: 0.019067
[01:02:07.073] iteration 7216 : loss : 0.170044, loss_ce: 0.003151
[01:02:07.372] iteration 7217 : loss : 0.045623, loss_ce: 0.010439
[01:02:07.675] iteration 7218 : loss : 0.063781, loss_ce: 0.013645
[01:02:07.975] iteration 7219 : loss : 0.074700, loss_ce: 0.015663
[01:02:08.276] iteration 7220 : loss : 0.079480, loss_ce: 0.034512
[01:02:08.596] iteration 7221 : loss : 0.085969, loss_ce: 0.028266
[01:02:08.905] iteration 7222 : loss : 0.166974, loss_ce: 0.005919
[01:02:09.210] iteration 7223 : loss : 0.065305, loss_ce: 0.023630
[01:02:09.515] iteration 7224 : loss : 0.074208, loss_ce: 0.020903
[01:02:09.823] iteration 7225 : loss : 0.084455, loss_ce: 0.023277
[01:02:10.126] iteration 7226 : loss : 0.054057, loss_ce: 0.011274
[01:02:10.431] iteration 7227 : loss : 0.062775, loss_ce: 0.022639
[01:02:10.509] iteration 7228 : loss : 0.355496, loss_ce: 0.013308
[01:02:30.125] iteration 7229 : loss : 0.063673, loss_ce: 0.018493
[01:02:30.424] iteration 7230 : loss : 0.120704, loss_ce: 0.013738
[01:02:30.721] iteration 7231 : loss : 0.060918, loss_ce: 0.021566
[01:02:31.018] iteration 7232 : loss : 0.110621, loss_ce: 0.010592
[01:02:31.310] iteration 7233 : loss : 0.058652, loss_ce: 0.019601
[01:02:31.598] iteration 7234 : loss : 0.113449, loss_ce: 0.018814
[01:02:31.893] iteration 7235 : loss : 0.120730, loss_ce: 0.014949
[01:02:32.185] iteration 7236 : loss : 0.056290, loss_ce: 0.012279
[01:02:32.477] iteration 7237 : loss : 0.061773, loss_ce: 0.014852
[01:02:32.768] iteration 7238 : loss : 0.131370, loss_ce: 0.010649
[01:02:33.062] iteration 7239 : loss : 0.092630, loss_ce: 0.009862
[01:02:33.352] iteration 7240 : loss : 0.064849, loss_ce: 0.016698
[01:02:33.663] iteration 7241 : loss : 0.044060, loss_ce: 0.015229
[01:02:33.953] iteration 7242 : loss : 0.056052, loss_ce: 0.021549
[01:02:34.241] iteration 7243 : loss : 0.122263, loss_ce: 0.022570
[01:02:34.531] iteration 7244 : loss : 0.064094, loss_ce: 0.020293
[01:02:34.821] iteration 7245 : loss : 0.068137, loss_ce: 0.017416
[01:02:35.111] iteration 7246 : loss : 0.109977, loss_ce: 0.011539
[01:02:35.407] iteration 7247 : loss : 0.087393, loss_ce: 0.029150
[01:02:35.696] iteration 7248 : loss : 0.091530, loss_ce: 0.013389
[01:02:35.989] iteration 7249 : loss : 0.094240, loss_ce: 0.019083
[01:02:36.280] iteration 7250 : loss : 0.059800, loss_ce: 0.023768
[01:02:36.572] iteration 7251 : loss : 0.095428, loss_ce: 0.016704
[01:02:36.866] iteration 7252 : loss : 0.105365, loss_ce: 0.011476
[01:02:37.158] iteration 7253 : loss : 0.067386, loss_ce: 0.018698
[01:02:37.451] iteration 7254 : loss : 0.051576, loss_ce: 0.015498
[01:02:37.742] iteration 7255 : loss : 0.055238, loss_ce: 0.013824
[01:02:38.032] iteration 7256 : loss : 0.066290, loss_ce: 0.021888
[01:02:38.323] iteration 7257 : loss : 0.071398, loss_ce: 0.027006
[01:02:38.624] iteration 7258 : loss : 0.045345, loss_ce: 0.010166
[01:02:38.915] iteration 7259 : loss : 0.072775, loss_ce: 0.020675
[01:02:39.213] iteration 7260 : loss : 0.050596, loss_ce: 0.016836
[01:02:39.525] iteration 7261 : loss : 0.138519, loss_ce: 0.011696
[01:02:39.824] iteration 7262 : loss : 0.055616, loss_ce: 0.012853
[01:02:40.126] iteration 7263 : loss : 0.065485, loss_ce: 0.026550
[01:02:40.425] iteration 7264 : loss : 0.118694, loss_ce: 0.019250
[01:02:40.729] iteration 7265 : loss : 0.063042, loss_ce: 0.014314
[01:02:41.026] iteration 7266 : loss : 0.111406, loss_ce: 0.011438
[01:02:41.320] iteration 7267 : loss : 0.056746, loss_ce: 0.014121
[01:02:41.612] iteration 7268 : loss : 0.054219, loss_ce: 0.017361
[01:02:41.902] iteration 7269 : loss : 0.094869, loss_ce: 0.023379
[01:02:42.190] iteration 7270 : loss : 0.074472, loss_ce: 0.020570
[01:02:42.486] iteration 7271 : loss : 0.073975, loss_ce: 0.018326
[01:02:42.775] iteration 7272 : loss : 0.070104, loss_ce: 0.020185
[01:02:43.066] iteration 7273 : loss : 0.129670, loss_ce: 0.014094
[01:02:43.358] iteration 7274 : loss : 0.099089, loss_ce: 0.014742
[01:02:43.655] iteration 7275 : loss : 0.122633, loss_ce: 0.029149
[01:02:43.945] iteration 7276 : loss : 0.052618, loss_ce: 0.012665
[01:02:44.237] iteration 7277 : loss : 0.101457, loss_ce: 0.013106
[01:02:44.531] iteration 7278 : loss : 0.054769, loss_ce: 0.026732
[01:02:44.821] iteration 7279 : loss : 0.047697, loss_ce: 0.018977
[01:02:45.116] iteration 7280 : loss : 0.110231, loss_ce: 0.006909
[01:02:45.424] iteration 7281 : loss : 0.112341, loss_ce: 0.012430
[01:02:45.718] iteration 7282 : loss : 0.064601, loss_ce: 0.019030
[01:02:46.013] iteration 7283 : loss : 0.061226, loss_ce: 0.016550
[01:02:46.307] iteration 7284 : loss : 0.064484, loss_ce: 0.021592
[01:02:46.598] iteration 7285 : loss : 0.078348, loss_ce: 0.026502
[01:02:46.892] iteration 7286 : loss : 0.058992, loss_ce: 0.012273
[01:02:47.187] iteration 7287 : loss : 0.050383, loss_ce: 0.022049
[01:02:47.478] iteration 7288 : loss : 0.063289, loss_ce: 0.024158
[01:02:47.771] iteration 7289 : loss : 0.072889, loss_ce: 0.025476
[01:02:48.064] iteration 7290 : loss : 0.060231, loss_ce: 0.020518
[01:02:48.355] iteration 7291 : loss : 0.065456, loss_ce: 0.023070
[01:02:48.648] iteration 7292 : loss : 0.081915, loss_ce: 0.021507
[01:02:48.942] iteration 7293 : loss : 0.075697, loss_ce: 0.017481
[01:02:49.236] iteration 7294 : loss : 0.065544, loss_ce: 0.017850
[01:02:49.530] iteration 7295 : loss : 0.186294, loss_ce: 0.010549
[01:02:49.824] iteration 7296 : loss : 0.118843, loss_ce: 0.006399
[01:02:50.117] iteration 7297 : loss : 0.063131, loss_ce: 0.009103
[01:02:50.409] iteration 7298 : loss : 0.066164, loss_ce: 0.027345
[01:02:50.699] iteration 7299 : loss : 0.065262, loss_ce: 0.027786
[01:02:50.990] iteration 7300 : loss : 0.066335, loss_ce: 0.030946
[01:02:51.303] iteration 7301 : loss : 0.078220, loss_ce: 0.015348
[01:02:51.595] iteration 7302 : loss : 0.067540, loss_ce: 0.028345
[01:02:51.895] iteration 7303 : loss : 0.115569, loss_ce: 0.016842
[01:02:52.188] iteration 7304 : loss : 0.067528, loss_ce: 0.016111
[01:02:52.481] iteration 7305 : loss : 0.063517, loss_ce: 0.015946
[01:02:52.773] iteration 7306 : loss : 0.046291, loss_ce: 0.016784
[01:02:53.066] iteration 7307 : loss : 0.062269, loss_ce: 0.026054
[01:02:53.360] iteration 7308 : loss : 0.054064, loss_ce: 0.018392
[01:02:53.656] iteration 7309 : loss : 0.172178, loss_ce: 0.010642
[01:02:53.950] iteration 7310 : loss : 0.067685, loss_ce: 0.018559
[01:02:54.248] iteration 7311 : loss : 0.072651, loss_ce: 0.024047
[01:02:54.546] iteration 7312 : loss : 0.066437, loss_ce: 0.017321
[01:02:54.845] iteration 7313 : loss : 0.088993, loss_ce: 0.015926
[01:02:55.144] iteration 7314 : loss : 0.058668, loss_ce: 0.015247
[01:02:55.445] iteration 7315 : loss : 0.073789, loss_ce: 0.028222
[01:02:55.745] iteration 7316 : loss : 0.091587, loss_ce: 0.013060
[01:02:56.047] iteration 7317 : loss : 0.148880, loss_ce: 0.015949
[01:02:56.339] iteration 7318 : loss : 0.075858, loss_ce: 0.027979
[01:02:56.628] iteration 7319 : loss : 0.079339, loss_ce: 0.027947
[01:02:56.920] iteration 7320 : loss : 0.139469, loss_ce: 0.020416
[01:02:57.230] iteration 7321 : loss : 0.083813, loss_ce: 0.018508
[01:02:57.527] iteration 7322 : loss : 0.089599, loss_ce: 0.027889
[01:02:57.821] iteration 7323 : loss : 0.075329, loss_ce: 0.028732
[01:02:58.117] iteration 7324 : loss : 0.060373, loss_ce: 0.027986
[01:02:58.407] iteration 7325 : loss : 0.072319, loss_ce: 0.026458
[01:02:58.700] iteration 7326 : loss : 0.085223, loss_ce: 0.023772
[01:02:58.993] iteration 7327 : loss : 0.059445, loss_ce: 0.007050
[01:02:59.289] iteration 7328 : loss : 0.055554, loss_ce: 0.023237
[01:02:59.581] iteration 7329 : loss : 0.072219, loss_ce: 0.018745
[01:02:59.874] iteration 7330 : loss : 0.060436, loss_ce: 0.018499
[01:03:00.168] iteration 7331 : loss : 0.053331, loss_ce: 0.020665
[01:03:00.466] iteration 7332 : loss : 0.207496, loss_ce: 0.006257
[01:03:00.757] iteration 7333 : loss : 0.073645, loss_ce: 0.017497
[01:03:01.051] iteration 7334 : loss : 0.104299, loss_ce: 0.024830
[01:03:01.347] iteration 7335 : loss : 0.153845, loss_ce: 0.019105
[01:03:01.644] iteration 7336 : loss : 0.258275, loss_ce: 0.010397
[01:03:01.939] iteration 7337 : loss : 0.125342, loss_ce: 0.018885
[01:03:02.229] iteration 7338 : loss : 0.081675, loss_ce: 0.035722
[01:03:02.521] iteration 7339 : loss : 0.059252, loss_ce: 0.011980
[01:03:02.814] iteration 7340 : loss : 0.066068, loss_ce: 0.020994
[01:03:03.122] iteration 7341 : loss : 0.091444, loss_ce: 0.015797
[01:03:03.416] iteration 7342 : loss : 0.069481, loss_ce: 0.016722
[01:03:03.715] iteration 7343 : loss : 0.063094, loss_ce: 0.019083
[01:03:04.010] iteration 7344 : loss : 0.115046, loss_ce: 0.004453
[01:03:04.299] iteration 7345 : loss : 0.067899, loss_ce: 0.025753
[01:03:04.591] iteration 7346 : loss : 0.087349, loss_ce: 0.021379
[01:03:04.883] iteration 7347 : loss : 0.118149, loss_ce: 0.012414
[01:03:05.172] iteration 7348 : loss : 0.177528, loss_ce: 0.010341
[01:03:05.465] iteration 7349 : loss : 0.094670, loss_ce: 0.017248
[01:03:05.756] iteration 7350 : loss : 0.106714, loss_ce: 0.027249
[01:03:06.053] iteration 7351 : loss : 0.054018, loss_ce: 0.018287
[01:03:06.352] iteration 7352 : loss : 0.068544, loss_ce: 0.022646
[01:03:06.651] iteration 7353 : loss : 0.121320, loss_ce: 0.017527
[01:03:06.955] iteration 7354 : loss : 0.111637, loss_ce: 0.011389
[01:03:07.249] iteration 7355 : loss : 0.064855, loss_ce: 0.019932
[01:03:07.547] iteration 7356 : loss : 0.123401, loss_ce: 0.021515
[01:03:07.845] iteration 7357 : loss : 0.088491, loss_ce: 0.020096
[01:03:08.140] iteration 7358 : loss : 0.071308, loss_ce: 0.016396
[01:03:08.441] iteration 7359 : loss : 0.054297, loss_ce: 0.015229
[01:03:08.746] iteration 7360 : loss : 0.047729, loss_ce: 0.017708
[01:03:09.081] iteration 7361 : loss : 0.062889, loss_ce: 0.020562
[01:03:09.382] iteration 7362 : loss : 0.058028, loss_ce: 0.020845
[01:03:09.679] iteration 7363 : loss : 0.068659, loss_ce: 0.020802
[01:03:09.980] iteration 7364 : loss : 0.068657, loss_ce: 0.029817
[01:03:10.280] iteration 7365 : loss : 0.124331, loss_ce: 0.028693
[01:03:10.575] iteration 7366 : loss : 0.067168, loss_ce: 0.016033
[01:03:10.655] iteration 7367 : loss : 0.056759, loss_ce: 0.035398
[01:03:28.501] iteration 7368 : loss : 0.052649, loss_ce: 0.021657
[01:03:28.798] iteration 7369 : loss : 0.054157, loss_ce: 0.020577
[01:03:29.098] iteration 7370 : loss : 0.078801, loss_ce: 0.021093
[01:03:29.399] iteration 7371 : loss : 0.079016, loss_ce: 0.011393
[01:03:29.701] iteration 7372 : loss : 0.070959, loss_ce: 0.020794
[01:03:29.996] iteration 7373 : loss : 0.065296, loss_ce: 0.022816
[01:03:30.298] iteration 7374 : loss : 0.079326, loss_ce: 0.016312
[01:03:30.595] iteration 7375 : loss : 0.129971, loss_ce: 0.025816
[01:03:30.894] iteration 7376 : loss : 0.112808, loss_ce: 0.010718
[01:03:31.189] iteration 7377 : loss : 0.055285, loss_ce: 0.021416
[01:03:31.481] iteration 7378 : loss : 0.124752, loss_ce: 0.013783
[01:03:31.773] iteration 7379 : loss : 0.111719, loss_ce: 0.010753
[01:03:32.063] iteration 7380 : loss : 0.066532, loss_ce: 0.033742
[01:03:32.379] iteration 7381 : loss : 0.100226, loss_ce: 0.014813
[01:03:32.671] iteration 7382 : loss : 0.057842, loss_ce: 0.014949
[01:03:32.964] iteration 7383 : loss : 0.055944, loss_ce: 0.019128
[01:03:33.252] iteration 7384 : loss : 0.049106, loss_ce: 0.014912
[01:03:33.542] iteration 7385 : loss : 0.051353, loss_ce: 0.013731
[01:03:33.833] iteration 7386 : loss : 0.085098, loss_ce: 0.018092
[01:03:34.124] iteration 7387 : loss : 0.061454, loss_ce: 0.017289
[01:03:34.416] iteration 7388 : loss : 0.067228, loss_ce: 0.026636
[01:03:34.709] iteration 7389 : loss : 0.050567, loss_ce: 0.019827
[01:03:35.002] iteration 7390 : loss : 0.157680, loss_ce: 0.011164
[01:03:35.295] iteration 7391 : loss : 0.057228, loss_ce: 0.022347
[01:03:35.588] iteration 7392 : loss : 0.093077, loss_ce: 0.028199
[01:03:35.880] iteration 7393 : loss : 0.055326, loss_ce: 0.013345
[01:03:36.172] iteration 7394 : loss : 0.078797, loss_ce: 0.031048
[01:03:36.465] iteration 7395 : loss : 0.063666, loss_ce: 0.025763
[01:03:36.757] iteration 7396 : loss : 0.053433, loss_ce: 0.016953
[01:03:37.048] iteration 7397 : loss : 0.068375, loss_ce: 0.019420
[01:03:37.339] iteration 7398 : loss : 0.066115, loss_ce: 0.021878
[01:03:37.632] iteration 7399 : loss : 0.124321, loss_ce: 0.028859
[01:03:37.928] iteration 7400 : loss : 0.104747, loss_ce: 0.009000
[01:03:38.235] iteration 7401 : loss : 0.065643, loss_ce: 0.020188
[01:03:38.530] iteration 7402 : loss : 0.114612, loss_ce: 0.018864
[01:03:38.826] iteration 7403 : loss : 0.074185, loss_ce: 0.013055
[01:03:39.121] iteration 7404 : loss : 0.108082, loss_ce: 0.007659
[01:03:39.413] iteration 7405 : loss : 0.084639, loss_ce: 0.024684
[01:03:39.709] iteration 7406 : loss : 0.098969, loss_ce: 0.015926
[01:03:40.005] iteration 7407 : loss : 0.062816, loss_ce: 0.015701
[01:03:40.297] iteration 7408 : loss : 0.061697, loss_ce: 0.025543
[01:03:40.588] iteration 7409 : loss : 0.175925, loss_ce: 0.022999
[01:03:40.882] iteration 7410 : loss : 0.058734, loss_ce: 0.015928
[01:03:41.176] iteration 7411 : loss : 0.115800, loss_ce: 0.021735
[01:03:41.468] iteration 7412 : loss : 0.139182, loss_ce: 0.010296
[01:03:41.764] iteration 7413 : loss : 0.120308, loss_ce: 0.015367
[01:03:42.057] iteration 7414 : loss : 0.073838, loss_ce: 0.011500
[01:03:42.352] iteration 7415 : loss : 0.075699, loss_ce: 0.011071
[01:03:42.647] iteration 7416 : loss : 0.050798, loss_ce: 0.016830
[01:03:42.939] iteration 7417 : loss : 0.056827, loss_ce: 0.021229
[01:03:43.234] iteration 7418 : loss : 0.048865, loss_ce: 0.015712
[01:03:43.529] iteration 7419 : loss : 0.090361, loss_ce: 0.027483
[01:03:43.825] iteration 7420 : loss : 0.077210, loss_ce: 0.008316
[01:03:44.138] iteration 7421 : loss : 0.054297, loss_ce: 0.015938
[01:03:44.435] iteration 7422 : loss : 0.063224, loss_ce: 0.014322
[01:03:44.731] iteration 7423 : loss : 0.047785, loss_ce: 0.011783
[01:03:45.029] iteration 7424 : loss : 0.131266, loss_ce: 0.011141
[01:03:45.334] iteration 7425 : loss : 0.060311, loss_ce: 0.024565
[01:03:45.635] iteration 7426 : loss : 0.059469, loss_ce: 0.013781
[01:03:45.938] iteration 7427 : loss : 0.189606, loss_ce: 0.012986
[01:03:46.236] iteration 7428 : loss : 0.114785, loss_ce: 0.005574
[01:03:46.534] iteration 7429 : loss : 0.067428, loss_ce: 0.025372
[01:03:46.829] iteration 7430 : loss : 0.171638, loss_ce: 0.012387
[01:03:47.124] iteration 7431 : loss : 0.057465, loss_ce: 0.022228
[01:03:47.417] iteration 7432 : loss : 0.113730, loss_ce: 0.030750
[01:03:47.711] iteration 7433 : loss : 0.070220, loss_ce: 0.021906
[01:03:48.006] iteration 7434 : loss : 0.057236, loss_ce: 0.010752
[01:03:48.298] iteration 7435 : loss : 0.044658, loss_ce: 0.012575
[01:03:48.600] iteration 7436 : loss : 0.122553, loss_ce: 0.016657
[01:03:48.895] iteration 7437 : loss : 0.110928, loss_ce: 0.022216
[01:03:49.189] iteration 7438 : loss : 0.067020, loss_ce: 0.023021
[01:03:49.485] iteration 7439 : loss : 0.052419, loss_ce: 0.012857
[01:03:49.776] iteration 7440 : loss : 0.077364, loss_ce: 0.015253
[01:03:50.088] iteration 7441 : loss : 0.048314, loss_ce: 0.015542
[01:03:50.381] iteration 7442 : loss : 0.112791, loss_ce: 0.010182
[01:03:50.679] iteration 7443 : loss : 0.063537, loss_ce: 0.016329
[01:03:50.972] iteration 7444 : loss : 0.103459, loss_ce: 0.017886
[01:03:51.271] iteration 7445 : loss : 0.057671, loss_ce: 0.010945
[01:03:51.566] iteration 7446 : loss : 0.065672, loss_ce: 0.020344
[01:03:51.860] iteration 7447 : loss : 0.058912, loss_ce: 0.017346
[01:03:52.157] iteration 7448 : loss : 0.052339, loss_ce: 0.013075
[01:03:52.454] iteration 7449 : loss : 0.057548, loss_ce: 0.017493
[01:03:52.750] iteration 7450 : loss : 0.074944, loss_ce: 0.018107
[01:03:53.043] iteration 7451 : loss : 0.052277, loss_ce: 0.011678
[01:03:53.339] iteration 7452 : loss : 0.067244, loss_ce: 0.028163
[01:03:53.630] iteration 7453 : loss : 0.118949, loss_ce: 0.013168
[01:03:53.928] iteration 7454 : loss : 0.085050, loss_ce: 0.010924
[01:03:54.219] iteration 7455 : loss : 0.146758, loss_ce: 0.015839
[01:03:54.511] iteration 7456 : loss : 0.062464, loss_ce: 0.023315
[01:03:54.807] iteration 7457 : loss : 0.049475, loss_ce: 0.021070
[01:03:55.102] iteration 7458 : loss : 0.077828, loss_ce: 0.018290
[01:03:55.393] iteration 7459 : loss : 0.061388, loss_ce: 0.017154
[01:03:55.691] iteration 7460 : loss : 0.056848, loss_ce: 0.026399
[01:03:56.006] iteration 7461 : loss : 0.129773, loss_ce: 0.017371
[01:03:56.297] iteration 7462 : loss : 0.089249, loss_ce: 0.032560
[01:03:56.591] iteration 7463 : loss : 0.103526, loss_ce: 0.015334
[01:03:56.886] iteration 7464 : loss : 0.059348, loss_ce: 0.019388
[01:03:57.181] iteration 7465 : loss : 0.077830, loss_ce: 0.029429
[01:03:57.477] iteration 7466 : loss : 0.064591, loss_ce: 0.016782
[01:03:57.769] iteration 7467 : loss : 0.066347, loss_ce: 0.016094
[01:03:58.063] iteration 7468 : loss : 0.100998, loss_ce: 0.009511
[01:03:58.354] iteration 7469 : loss : 0.055246, loss_ce: 0.018458
[01:03:58.646] iteration 7470 : loss : 0.070566, loss_ce: 0.013351
[01:03:58.942] iteration 7471 : loss : 0.060305, loss_ce: 0.012362
[01:03:59.239] iteration 7472 : loss : 0.077696, loss_ce: 0.027796
[01:03:59.537] iteration 7473 : loss : 0.045856, loss_ce: 0.018926
[01:03:59.835] iteration 7474 : loss : 0.061995, loss_ce: 0.024326
[01:04:00.131] iteration 7475 : loss : 0.062611, loss_ce: 0.027222
[01:04:00.430] iteration 7476 : loss : 0.115482, loss_ce: 0.019534
[01:04:00.727] iteration 7477 : loss : 0.047251, loss_ce: 0.013909
[01:04:01.022] iteration 7478 : loss : 0.099395, loss_ce: 0.039021
[01:04:01.314] iteration 7479 : loss : 0.064816, loss_ce: 0.014051
[01:04:01.611] iteration 7480 : loss : 0.117026, loss_ce: 0.022110
[01:04:01.928] iteration 7481 : loss : 0.051888, loss_ce: 0.007194
[01:04:02.224] iteration 7482 : loss : 0.073809, loss_ce: 0.018717
[01:04:02.520] iteration 7483 : loss : 0.135883, loss_ce: 0.017035
[01:04:02.820] iteration 7484 : loss : 0.056816, loss_ce: 0.022490
[01:04:03.120] iteration 7485 : loss : 0.076515, loss_ce: 0.008157
[01:04:03.418] iteration 7486 : loss : 0.076064, loss_ce: 0.022788
[01:04:03.720] iteration 7487 : loss : 0.063398, loss_ce: 0.013104
[01:04:04.014] iteration 7488 : loss : 0.061960, loss_ce: 0.027927
[01:04:04.312] iteration 7489 : loss : 0.071505, loss_ce: 0.016083
[01:04:04.614] iteration 7490 : loss : 0.101186, loss_ce: 0.019696
[01:04:04.924] iteration 7491 : loss : 0.063938, loss_ce: 0.008394
[01:04:05.226] iteration 7492 : loss : 0.064174, loss_ce: 0.032149
[01:04:05.529] iteration 7493 : loss : 0.081840, loss_ce: 0.015698
[01:04:05.828] iteration 7494 : loss : 0.122816, loss_ce: 0.019045
[01:04:06.132] iteration 7495 : loss : 0.090625, loss_ce: 0.014939
[01:04:06.432] iteration 7496 : loss : 0.060441, loss_ce: 0.019358
[01:04:06.733] iteration 7497 : loss : 0.063625, loss_ce: 0.019744
[01:04:07.035] iteration 7498 : loss : 0.066809, loss_ce: 0.020277
[01:04:07.342] iteration 7499 : loss : 0.111960, loss_ce: 0.011922
[01:04:07.643] iteration 7500 : loss : 0.080213, loss_ce: 0.020011
[01:04:07.970] iteration 7501 : loss : 0.056936, loss_ce: 0.018263
[01:04:08.277] iteration 7502 : loss : 0.062379, loss_ce: 0.025406
[01:04:08.576] iteration 7503 : loss : 0.075710, loss_ce: 0.018990
[01:04:08.881] iteration 7504 : loss : 0.079954, loss_ce: 0.024812
[01:04:09.182] iteration 7505 : loss : 0.060507, loss_ce: 0.017305
[01:04:09.258] iteration 7506 : loss : 0.418583, loss_ce: 0.008978
[01:04:29.872] iteration 7507 : loss : 0.062634, loss_ce: 0.014095
[01:04:30.172] iteration 7508 : loss : 0.052854, loss_ce: 0.009905
[01:04:30.470] iteration 7509 : loss : 0.082165, loss_ce: 0.025444
[01:04:30.759] iteration 7510 : loss : 0.062388, loss_ce: 0.026693
[01:04:31.057] iteration 7511 : loss : 0.065733, loss_ce: 0.011919
[01:04:31.354] iteration 7512 : loss : 0.124187, loss_ce: 0.011272
[01:04:31.644] iteration 7513 : loss : 0.250250, loss_ce: 0.014786
[01:04:31.936] iteration 7514 : loss : 0.050228, loss_ce: 0.017626
[01:04:32.227] iteration 7515 : loss : 0.104043, loss_ce: 0.012850
[01:04:32.518] iteration 7516 : loss : 0.069237, loss_ce: 0.032823
[01:04:32.808] iteration 7517 : loss : 0.113147, loss_ce: 0.023483
[01:04:33.100] iteration 7518 : loss : 0.065437, loss_ce: 0.018752
[01:04:33.394] iteration 7519 : loss : 0.062215, loss_ce: 0.021051
[01:04:33.685] iteration 7520 : loss : 0.074361, loss_ce: 0.025493
[01:04:33.994] iteration 7521 : loss : 0.074210, loss_ce: 0.019866
[01:04:34.292] iteration 7522 : loss : 0.093747, loss_ce: 0.007758
[01:04:34.591] iteration 7523 : loss : 0.052830, loss_ce: 0.016300
[01:04:34.885] iteration 7524 : loss : 0.058290, loss_ce: 0.016789
[01:04:35.188] iteration 7525 : loss : 0.070342, loss_ce: 0.021879
[01:04:35.485] iteration 7526 : loss : 0.131907, loss_ce: 0.016222
[01:04:35.781] iteration 7527 : loss : 0.071042, loss_ce: 0.015502
[01:04:36.079] iteration 7528 : loss : 0.089024, loss_ce: 0.023109
[01:04:36.372] iteration 7529 : loss : 0.199161, loss_ce: 0.014142
[01:04:36.669] iteration 7530 : loss : 0.087100, loss_ce: 0.017679
[01:04:36.964] iteration 7531 : loss : 0.062885, loss_ce: 0.015746
[01:04:37.261] iteration 7532 : loss : 0.069975, loss_ce: 0.021083
[01:04:37.558] iteration 7533 : loss : 0.068040, loss_ce: 0.021445
[01:04:37.852] iteration 7534 : loss : 0.120840, loss_ce: 0.019499
[01:04:38.145] iteration 7535 : loss : 0.057693, loss_ce: 0.018568
[01:04:38.436] iteration 7536 : loss : 0.064365, loss_ce: 0.022682
[01:04:38.732] iteration 7537 : loss : 0.069838, loss_ce: 0.020193
[01:04:39.024] iteration 7538 : loss : 0.060147, loss_ce: 0.027107
[01:04:39.317] iteration 7539 : loss : 0.113705, loss_ce: 0.011097
[01:04:39.608] iteration 7540 : loss : 0.062598, loss_ce: 0.021134
[01:04:39.916] iteration 7541 : loss : 0.062243, loss_ce: 0.013339
[01:04:40.212] iteration 7542 : loss : 0.062132, loss_ce: 0.023788
[01:04:40.504] iteration 7543 : loss : 0.115740, loss_ce: 0.025231
[01:04:40.798] iteration 7544 : loss : 0.055585, loss_ce: 0.015367
[01:04:41.089] iteration 7545 : loss : 0.057624, loss_ce: 0.019768
[01:04:41.383] iteration 7546 : loss : 0.070412, loss_ce: 0.015127
[01:04:41.673] iteration 7547 : loss : 0.086371, loss_ce: 0.024944
[01:04:41.967] iteration 7548 : loss : 0.060521, loss_ce: 0.013074
[01:04:42.263] iteration 7549 : loss : 0.058243, loss_ce: 0.008404
[01:04:42.555] iteration 7550 : loss : 0.161899, loss_ce: 0.014682
[01:04:42.852] iteration 7551 : loss : 0.075739, loss_ce: 0.030213
[01:04:43.144] iteration 7552 : loss : 0.050980, loss_ce: 0.010300
[01:04:43.437] iteration 7553 : loss : 0.113304, loss_ce: 0.012182
[01:04:43.729] iteration 7554 : loss : 0.176935, loss_ce: 0.007503
[01:04:44.018] iteration 7555 : loss : 0.111099, loss_ce: 0.011551
[01:04:44.311] iteration 7556 : loss : 0.068368, loss_ce: 0.032980
[01:04:44.606] iteration 7557 : loss : 0.139486, loss_ce: 0.014673
[01:04:44.897] iteration 7558 : loss : 0.101066, loss_ce: 0.024396
[01:04:45.186] iteration 7559 : loss : 0.058363, loss_ce: 0.017124
[01:04:45.480] iteration 7560 : loss : 0.054489, loss_ce: 0.013167
[01:04:45.789] iteration 7561 : loss : 0.133710, loss_ce: 0.023324
[01:04:46.080] iteration 7562 : loss : 0.078805, loss_ce: 0.022337
[01:04:46.371] iteration 7563 : loss : 0.074301, loss_ce: 0.013896
[01:04:46.666] iteration 7564 : loss : 0.069725, loss_ce: 0.017311
[01:04:46.958] iteration 7565 : loss : 0.083290, loss_ce: 0.017785
[01:04:47.249] iteration 7566 : loss : 0.074845, loss_ce: 0.016118
[01:04:47.544] iteration 7567 : loss : 0.062952, loss_ce: 0.017634
[01:04:47.837] iteration 7568 : loss : 0.230753, loss_ce: 0.015811
[01:04:48.133] iteration 7569 : loss : 0.137064, loss_ce: 0.016491
[01:04:48.425] iteration 7570 : loss : 0.081607, loss_ce: 0.026308
[01:04:48.722] iteration 7571 : loss : 0.054594, loss_ce: 0.025093
[01:04:49.014] iteration 7572 : loss : 0.060365, loss_ce: 0.029986
[01:04:49.315] iteration 7573 : loss : 0.060657, loss_ce: 0.016017
[01:04:49.620] iteration 7574 : loss : 0.198577, loss_ce: 0.004404
[01:04:49.918] iteration 7575 : loss : 0.054799, loss_ce: 0.014812
[01:04:50.219] iteration 7576 : loss : 0.059714, loss_ce: 0.011462
[01:04:50.517] iteration 7577 : loss : 0.061136, loss_ce: 0.013137
[01:04:50.818] iteration 7578 : loss : 0.109955, loss_ce: 0.017906
[01:04:51.119] iteration 7579 : loss : 0.099506, loss_ce: 0.013701
[01:04:51.412] iteration 7580 : loss : 0.113843, loss_ce: 0.020854
[01:04:51.721] iteration 7581 : loss : 0.162110, loss_ce: 0.010450
[01:04:52.010] iteration 7582 : loss : 0.120566, loss_ce: 0.015584
[01:04:52.302] iteration 7583 : loss : 0.063778, loss_ce: 0.031528
[01:04:52.593] iteration 7584 : loss : 0.067238, loss_ce: 0.026548
[01:04:52.892] iteration 7585 : loss : 0.086877, loss_ce: 0.019569
[01:04:53.185] iteration 7586 : loss : 0.067944, loss_ce: 0.011167
[01:04:53.477] iteration 7587 : loss : 0.119518, loss_ce: 0.035922
[01:04:53.769] iteration 7588 : loss : 0.089827, loss_ce: 0.040026
[01:04:54.065] iteration 7589 : loss : 0.098669, loss_ce: 0.025294
[01:04:54.357] iteration 7590 : loss : 0.117848, loss_ce: 0.011690
[01:04:54.648] iteration 7591 : loss : 0.055455, loss_ce: 0.021192
[01:04:54.944] iteration 7592 : loss : 0.160825, loss_ce: 0.004124
[01:04:55.235] iteration 7593 : loss : 0.077018, loss_ce: 0.022196
[01:04:55.531] iteration 7594 : loss : 0.061161, loss_ce: 0.024828
[01:04:55.825] iteration 7595 : loss : 0.063337, loss_ce: 0.016826
[01:04:56.117] iteration 7596 : loss : 0.075139, loss_ce: 0.017446
[01:04:56.410] iteration 7597 : loss : 0.069823, loss_ce: 0.025601
[01:04:56.698] iteration 7598 : loss : 0.079882, loss_ce: 0.024054
[01:04:56.990] iteration 7599 : loss : 0.064687, loss_ce: 0.022924
[01:04:57.282] iteration 7600 : loss : 0.069992, loss_ce: 0.014841
[01:04:57.595] iteration 7601 : loss : 0.052348, loss_ce: 0.016862
[01:04:57.887] iteration 7602 : loss : 0.128935, loss_ce: 0.012534
[01:04:58.178] iteration 7603 : loss : 0.060716, loss_ce: 0.010015
[01:04:58.468] iteration 7604 : loss : 0.078744, loss_ce: 0.019518
[01:04:58.764] iteration 7605 : loss : 0.059456, loss_ce: 0.017659
[01:04:59.060] iteration 7606 : loss : 0.124587, loss_ce: 0.027373
[01:04:59.355] iteration 7607 : loss : 0.068897, loss_ce: 0.018408
[01:04:59.652] iteration 7608 : loss : 0.069870, loss_ce: 0.019775
[01:04:59.948] iteration 7609 : loss : 0.068024, loss_ce: 0.017147
[01:05:00.246] iteration 7610 : loss : 0.116600, loss_ce: 0.011592
[01:05:00.537] iteration 7611 : loss : 0.074651, loss_ce: 0.020088
[01:05:00.830] iteration 7612 : loss : 0.062835, loss_ce: 0.030435
[01:05:01.122] iteration 7613 : loss : 0.055671, loss_ce: 0.017209
[01:05:01.417] iteration 7614 : loss : 0.045523, loss_ce: 0.017007
[01:05:01.709] iteration 7615 : loss : 0.163072, loss_ce: 0.009036
[01:05:02.003] iteration 7616 : loss : 0.055398, loss_ce: 0.024803
[01:05:02.298] iteration 7617 : loss : 0.072538, loss_ce: 0.028152
[01:05:02.591] iteration 7618 : loss : 0.056593, loss_ce: 0.010089
[01:05:02.888] iteration 7619 : loss : 0.073277, loss_ce: 0.025999
[01:05:03.181] iteration 7620 : loss : 0.053051, loss_ce: 0.016475
[01:05:03.488] iteration 7621 : loss : 0.049549, loss_ce: 0.020287
[01:05:03.779] iteration 7622 : loss : 0.054876, loss_ce: 0.022591
[01:05:04.072] iteration 7623 : loss : 0.127358, loss_ce: 0.029200
[01:05:04.375] iteration 7624 : loss : 0.081963, loss_ce: 0.018967
[01:05:04.667] iteration 7625 : loss : 0.058055, loss_ce: 0.021563
[01:05:04.962] iteration 7626 : loss : 0.069565, loss_ce: 0.021630
[01:05:05.259] iteration 7627 : loss : 0.114335, loss_ce: 0.008955
[01:05:05.554] iteration 7628 : loss : 0.060062, loss_ce: 0.015068
[01:05:05.857] iteration 7629 : loss : 0.055905, loss_ce: 0.017093
[01:05:06.156] iteration 7630 : loss : 0.117905, loss_ce: 0.023722
[01:05:06.456] iteration 7631 : loss : 0.051909, loss_ce: 0.028411
[01:05:06.760] iteration 7632 : loss : 0.061272, loss_ce: 0.015634
[01:05:07.063] iteration 7633 : loss : 0.090047, loss_ce: 0.011737
[01:05:07.368] iteration 7634 : loss : 0.110486, loss_ce: 0.011731
[01:05:07.668] iteration 7635 : loss : 0.076778, loss_ce: 0.016763
[01:05:07.966] iteration 7636 : loss : 0.064935, loss_ce: 0.013956
[01:05:08.269] iteration 7637 : loss : 0.063894, loss_ce: 0.010456
[01:05:08.565] iteration 7638 : loss : 0.073825, loss_ce: 0.016091
[01:05:08.863] iteration 7639 : loss : 0.062600, loss_ce: 0.027623
[01:05:09.165] iteration 7640 : loss : 0.048801, loss_ce: 0.022556
[01:05:09.494] iteration 7641 : loss : 0.049389, loss_ce: 0.015190
[01:05:09.793] iteration 7642 : loss : 0.344618, loss_ce: 0.002749
[01:05:10.093] iteration 7643 : loss : 0.057378, loss_ce: 0.019094
[01:05:10.394] iteration 7644 : loss : 0.084105, loss_ce: 0.018606
[01:05:10.472] iteration 7645 : loss : 0.233622, loss_ce: 0.007407
[01:05:28.130] iteration 7646 : loss : 0.106650, loss_ce: 0.008435
[01:05:28.425] iteration 7647 : loss : 0.061286, loss_ce: 0.023668
[01:05:28.720] iteration 7648 : loss : 0.059889, loss_ce: 0.027683
[01:05:29.020] iteration 7649 : loss : 0.116701, loss_ce: 0.010484
[01:05:29.313] iteration 7650 : loss : 0.065500, loss_ce: 0.013303
[01:05:29.608] iteration 7651 : loss : 0.068540, loss_ce: 0.036590
[01:05:29.899] iteration 7652 : loss : 0.062223, loss_ce: 0.025510
[01:05:30.188] iteration 7653 : loss : 0.079201, loss_ce: 0.023115
[01:05:30.477] iteration 7654 : loss : 0.069453, loss_ce: 0.010917
[01:05:30.775] iteration 7655 : loss : 0.048684, loss_ce: 0.015472
[01:05:31.064] iteration 7656 : loss : 0.176427, loss_ce: 0.009511
[01:05:31.356] iteration 7657 : loss : 0.062299, loss_ce: 0.025363
[01:05:31.648] iteration 7658 : loss : 0.055483, loss_ce: 0.011618
[01:05:31.944] iteration 7659 : loss : 0.062945, loss_ce: 0.030430
[01:05:32.244] iteration 7660 : loss : 0.134041, loss_ce: 0.023948
[01:05:32.567] iteration 7661 : loss : 0.059986, loss_ce: 0.035527
[01:05:32.860] iteration 7662 : loss : 0.057118, loss_ce: 0.013537
[01:05:33.152] iteration 7663 : loss : 0.053291, loss_ce: 0.020707
[01:05:33.445] iteration 7664 : loss : 0.065757, loss_ce: 0.022222
[01:05:33.742] iteration 7665 : loss : 0.068566, loss_ce: 0.017174
[01:05:34.035] iteration 7666 : loss : 0.071901, loss_ce: 0.024068
[01:05:34.330] iteration 7667 : loss : 0.057868, loss_ce: 0.018260
[01:05:34.626] iteration 7668 : loss : 0.050709, loss_ce: 0.012417
[01:05:34.916] iteration 7669 : loss : 0.106600, loss_ce: 0.016340
[01:05:35.210] iteration 7670 : loss : 0.064216, loss_ce: 0.017667
[01:05:35.503] iteration 7671 : loss : 0.066707, loss_ce: 0.019019
[01:05:35.798] iteration 7672 : loss : 0.053070, loss_ce: 0.026227
[01:05:36.093] iteration 7673 : loss : 0.069554, loss_ce: 0.016636
[01:05:36.384] iteration 7674 : loss : 0.056808, loss_ce: 0.021837
[01:05:36.677] iteration 7675 : loss : 0.058232, loss_ce: 0.020310
[01:05:36.973] iteration 7676 : loss : 0.066322, loss_ce: 0.018554
[01:05:37.265] iteration 7677 : loss : 0.053302, loss_ce: 0.016331
[01:05:37.558] iteration 7678 : loss : 0.154676, loss_ce: 0.007666
[01:05:37.855] iteration 7679 : loss : 0.168043, loss_ce: 0.008965
[01:05:38.147] iteration 7680 : loss : 0.073829, loss_ce: 0.020101
[01:05:38.456] iteration 7681 : loss : 0.114740, loss_ce: 0.010661
[01:05:38.749] iteration 7682 : loss : 0.047325, loss_ce: 0.012043
[01:05:39.047] iteration 7683 : loss : 0.114290, loss_ce: 0.025985
[01:05:39.348] iteration 7684 : loss : 0.050091, loss_ce: 0.012684
[01:05:39.646] iteration 7685 : loss : 0.083945, loss_ce: 0.022005
[01:05:39.943] iteration 7686 : loss : 0.069726, loss_ce: 0.012010
[01:05:40.246] iteration 7687 : loss : 0.079280, loss_ce: 0.028072
[01:05:40.547] iteration 7688 : loss : 0.059270, loss_ce: 0.016844
[01:05:40.846] iteration 7689 : loss : 0.110734, loss_ce: 0.013351
[01:05:41.139] iteration 7690 : loss : 0.079228, loss_ce: 0.024464
[01:05:41.436] iteration 7691 : loss : 0.057585, loss_ce: 0.022735
[01:05:41.727] iteration 7692 : loss : 0.111705, loss_ce: 0.023633
[01:05:42.021] iteration 7693 : loss : 0.053455, loss_ce: 0.026324
[01:05:42.315] iteration 7694 : loss : 0.067871, loss_ce: 0.027718
[01:05:42.610] iteration 7695 : loss : 0.052777, loss_ce: 0.016407
[01:05:42.903] iteration 7696 : loss : 0.062216, loss_ce: 0.023352
[01:05:43.197] iteration 7697 : loss : 0.110511, loss_ce: 0.014590
[01:05:43.495] iteration 7698 : loss : 0.062713, loss_ce: 0.016588
[01:05:43.790] iteration 7699 : loss : 0.047822, loss_ce: 0.011540
[01:05:44.089] iteration 7700 : loss : 0.114697, loss_ce: 0.009837
[01:05:44.403] iteration 7701 : loss : 0.062028, loss_ce: 0.024996
[01:05:44.701] iteration 7702 : loss : 0.059860, loss_ce: 0.015345
[01:05:44.995] iteration 7703 : loss : 0.052703, loss_ce: 0.015722
[01:05:45.291] iteration 7704 : loss : 0.111721, loss_ce: 0.015518
[01:05:45.580] iteration 7705 : loss : 0.056472, loss_ce: 0.022657
[01:05:45.872] iteration 7706 : loss : 0.042509, loss_ce: 0.015282
[01:05:46.165] iteration 7707 : loss : 0.085335, loss_ce: 0.019082
[01:05:46.454] iteration 7708 : loss : 0.127165, loss_ce: 0.011727
[01:05:46.746] iteration 7709 : loss : 0.057585, loss_ce: 0.015802
[01:05:47.038] iteration 7710 : loss : 0.107088, loss_ce: 0.011147
[01:05:47.336] iteration 7711 : loss : 0.069276, loss_ce: 0.025366
[01:05:47.630] iteration 7712 : loss : 0.131535, loss_ce: 0.021220
[01:05:47.921] iteration 7713 : loss : 0.065617, loss_ce: 0.021252
[01:05:48.217] iteration 7714 : loss : 0.064114, loss_ce: 0.012025
[01:05:48.511] iteration 7715 : loss : 0.065236, loss_ce: 0.021618
[01:05:48.803] iteration 7716 : loss : 0.134726, loss_ce: 0.012259
[01:05:49.099] iteration 7717 : loss : 0.113354, loss_ce: 0.013251
[01:05:49.392] iteration 7718 : loss : 0.109138, loss_ce: 0.019371
[01:05:49.685] iteration 7719 : loss : 0.061466, loss_ce: 0.020621
[01:05:49.977] iteration 7720 : loss : 0.063315, loss_ce: 0.019460
[01:05:50.285] iteration 7721 : loss : 0.068477, loss_ce: 0.011180
[01:05:50.582] iteration 7722 : loss : 0.116113, loss_ce: 0.018920
[01:05:50.878] iteration 7723 : loss : 0.059352, loss_ce: 0.015331
[01:05:51.170] iteration 7724 : loss : 0.055622, loss_ce: 0.010829
[01:05:51.461] iteration 7725 : loss : 0.051706, loss_ce: 0.017578
[01:05:51.753] iteration 7726 : loss : 0.062323, loss_ce: 0.021331
[01:05:52.043] iteration 7727 : loss : 0.073959, loss_ce: 0.022874
[01:05:52.336] iteration 7728 : loss : 0.104790, loss_ce: 0.011931
[01:05:52.631] iteration 7729 : loss : 0.042062, loss_ce: 0.016230
[01:05:52.922] iteration 7730 : loss : 0.076235, loss_ce: 0.023448
[01:05:53.219] iteration 7731 : loss : 0.117652, loss_ce: 0.017396
[01:05:53.510] iteration 7732 : loss : 0.044780, loss_ce: 0.013474
[01:05:53.807] iteration 7733 : loss : 0.050963, loss_ce: 0.018336
[01:05:54.105] iteration 7734 : loss : 0.052357, loss_ce: 0.016354
[01:05:54.406] iteration 7735 : loss : 0.057473, loss_ce: 0.022226
[01:05:54.704] iteration 7736 : loss : 0.089132, loss_ce: 0.019894
[01:05:55.001] iteration 7737 : loss : 0.103663, loss_ce: 0.021403
[01:05:55.303] iteration 7738 : loss : 0.123794, loss_ce: 0.010063
[01:05:55.603] iteration 7739 : loss : 0.058601, loss_ce: 0.009211
[01:05:55.905] iteration 7740 : loss : 0.075236, loss_ce: 0.013508
[01:05:56.225] iteration 7741 : loss : 0.057198, loss_ce: 0.013159
[01:05:56.523] iteration 7742 : loss : 0.063412, loss_ce: 0.016289
[01:05:56.814] iteration 7743 : loss : 0.061261, loss_ce: 0.020079
[01:05:57.105] iteration 7744 : loss : 0.070802, loss_ce: 0.015353
[01:05:57.400] iteration 7745 : loss : 0.052413, loss_ce: 0.012179
[01:05:57.692] iteration 7746 : loss : 0.114571, loss_ce: 0.015810
[01:05:57.984] iteration 7747 : loss : 0.063795, loss_ce: 0.015486
[01:05:58.279] iteration 7748 : loss : 0.112201, loss_ce: 0.015081
[01:05:58.571] iteration 7749 : loss : 0.065815, loss_ce: 0.026269
[01:05:58.869] iteration 7750 : loss : 0.132780, loss_ce: 0.016226
[01:05:59.163] iteration 7751 : loss : 0.168634, loss_ce: 0.009759
[01:05:59.456] iteration 7752 : loss : 0.227106, loss_ce: 0.020302
[01:05:59.753] iteration 7753 : loss : 0.053113, loss_ce: 0.018071
[01:06:00.044] iteration 7754 : loss : 0.059115, loss_ce: 0.016126
[01:06:00.340] iteration 7755 : loss : 0.052047, loss_ce: 0.015696
[01:06:00.636] iteration 7756 : loss : 0.112802, loss_ce: 0.005044
[01:06:00.929] iteration 7757 : loss : 0.114703, loss_ce: 0.015363
[01:06:01.225] iteration 7758 : loss : 0.064440, loss_ce: 0.019321
[01:06:01.521] iteration 7759 : loss : 0.050521, loss_ce: 0.012929
[01:06:01.819] iteration 7760 : loss : 0.077816, loss_ce: 0.022387
[01:06:02.130] iteration 7761 : loss : 0.064334, loss_ce: 0.019615
[01:06:02.428] iteration 7762 : loss : 0.084603, loss_ce: 0.011779
[01:06:02.721] iteration 7763 : loss : 0.080162, loss_ce: 0.021763
[01:06:03.015] iteration 7764 : loss : 0.119985, loss_ce: 0.011684
[01:06:03.309] iteration 7765 : loss : 0.079272, loss_ce: 0.016052
[01:06:03.600] iteration 7766 : loss : 0.072782, loss_ce: 0.008355
[01:06:03.893] iteration 7767 : loss : 0.075081, loss_ce: 0.023622
[01:06:04.187] iteration 7768 : loss : 0.062030, loss_ce: 0.013324
[01:06:04.488] iteration 7769 : loss : 0.118062, loss_ce: 0.015461
[01:06:04.781] iteration 7770 : loss : 0.102918, loss_ce: 0.020149
[01:06:05.078] iteration 7771 : loss : 0.066858, loss_ce: 0.011216
[01:06:05.380] iteration 7772 : loss : 0.080167, loss_ce: 0.018981
[01:06:05.681] iteration 7773 : loss : 0.064530, loss_ce: 0.028428
[01:06:05.975] iteration 7774 : loss : 0.080197, loss_ce: 0.023385
[01:06:06.283] iteration 7775 : loss : 0.071947, loss_ce: 0.011103
[01:06:06.576] iteration 7776 : loss : 0.060551, loss_ce: 0.017604
[01:06:06.874] iteration 7777 : loss : 0.088896, loss_ce: 0.020150
[01:06:07.180] iteration 7778 : loss : 0.065641, loss_ce: 0.025792
[01:06:07.478] iteration 7779 : loss : 0.064388, loss_ce: 0.014527
[01:06:07.777] iteration 7780 : loss : 0.142589, loss_ce: 0.008886
[01:06:08.090] iteration 7781 : loss : 0.069505, loss_ce: 0.018913
[01:06:08.388] iteration 7782 : loss : 0.063444, loss_ce: 0.018031
[01:06:08.687] iteration 7783 : loss : 0.076419, loss_ce: 0.012109
[01:06:08.768] iteration 7784 : loss : 0.214204, loss_ce: 0.022732
[01:06:27.667] iteration 7785 : loss : 0.071955, loss_ce: 0.026626
[01:06:27.966] iteration 7786 : loss : 0.072438, loss_ce: 0.031604
[01:06:28.260] iteration 7787 : loss : 0.113015, loss_ce: 0.016867
[01:06:28.563] iteration 7788 : loss : 0.061890, loss_ce: 0.020921
[01:06:28.865] iteration 7789 : loss : 0.180864, loss_ce: 0.010938
[01:06:29.160] iteration 7790 : loss : 0.125873, loss_ce: 0.013342
[01:06:29.457] iteration 7791 : loss : 0.094847, loss_ce: 0.031082
[01:06:29.755] iteration 7792 : loss : 0.068748, loss_ce: 0.024017
[01:06:30.052] iteration 7793 : loss : 0.072472, loss_ce: 0.018147
[01:06:30.350] iteration 7794 : loss : 0.063515, loss_ce: 0.023122
[01:06:30.648] iteration 7795 : loss : 0.066448, loss_ce: 0.023140
[01:06:30.941] iteration 7796 : loss : 0.120624, loss_ce: 0.010588
[01:06:31.234] iteration 7797 : loss : 0.110015, loss_ce: 0.010062
[01:06:31.528] iteration 7798 : loss : 0.090520, loss_ce: 0.013554
[01:06:31.817] iteration 7799 : loss : 0.054148, loss_ce: 0.023889
[01:06:32.108] iteration 7800 : loss : 0.059729, loss_ce: 0.015230
[01:06:32.420] iteration 7801 : loss : 0.045586, loss_ce: 0.012493
[01:06:32.716] iteration 7802 : loss : 0.085343, loss_ce: 0.024910
[01:06:33.014] iteration 7803 : loss : 0.064735, loss_ce: 0.008490
[01:06:33.307] iteration 7804 : loss : 0.070116, loss_ce: 0.025896
[01:06:33.602] iteration 7805 : loss : 0.082842, loss_ce: 0.013403
[01:06:33.902] iteration 7806 : loss : 0.130728, loss_ce: 0.012696
[01:06:34.197] iteration 7807 : loss : 0.078097, loss_ce: 0.011509
[01:06:34.487] iteration 7808 : loss : 0.065418, loss_ce: 0.019262
[01:06:34.782] iteration 7809 : loss : 0.066331, loss_ce: 0.014752
[01:06:35.075] iteration 7810 : loss : 0.072472, loss_ce: 0.015806
[01:06:35.365] iteration 7811 : loss : 0.049681, loss_ce: 0.020376
[01:06:35.661] iteration 7812 : loss : 0.057632, loss_ce: 0.024631
[01:06:35.954] iteration 7813 : loss : 0.118608, loss_ce: 0.022605
[01:06:36.245] iteration 7814 : loss : 0.075962, loss_ce: 0.006522
[01:06:36.543] iteration 7815 : loss : 0.070040, loss_ce: 0.021304
[01:06:36.835] iteration 7816 : loss : 0.085983, loss_ce: 0.015138
[01:06:37.128] iteration 7817 : loss : 0.128855, loss_ce: 0.010342
[01:06:37.423] iteration 7818 : loss : 0.060865, loss_ce: 0.024573
[01:06:37.715] iteration 7819 : loss : 0.126151, loss_ce: 0.009113
[01:06:38.009] iteration 7820 : loss : 0.063636, loss_ce: 0.017507
[01:06:38.324] iteration 7821 : loss : 0.041120, loss_ce: 0.015650
[01:06:38.615] iteration 7822 : loss : 0.058934, loss_ce: 0.018431
[01:06:38.909] iteration 7823 : loss : 0.060371, loss_ce: 0.012881
[01:06:39.198] iteration 7824 : loss : 0.110807, loss_ce: 0.014544
[01:06:39.490] iteration 7825 : loss : 0.058798, loss_ce: 0.013165
[01:06:39.781] iteration 7826 : loss : 0.162551, loss_ce: 0.006689
[01:06:40.072] iteration 7827 : loss : 0.064121, loss_ce: 0.024546
[01:06:40.364] iteration 7828 : loss : 0.058569, loss_ce: 0.024348
[01:06:40.653] iteration 7829 : loss : 0.071555, loss_ce: 0.024747
[01:06:40.943] iteration 7830 : loss : 0.068674, loss_ce: 0.021968
[01:06:41.235] iteration 7831 : loss : 0.073881, loss_ce: 0.016454
[01:06:41.525] iteration 7832 : loss : 0.118613, loss_ce: 0.008511
[01:06:41.819] iteration 7833 : loss : 0.058800, loss_ce: 0.024427
[01:06:42.111] iteration 7834 : loss : 0.108468, loss_ce: 0.015533
[01:06:42.403] iteration 7835 : loss : 0.063514, loss_ce: 0.024132
[01:06:42.697] iteration 7836 : loss : 0.142446, loss_ce: 0.014788
[01:06:42.996] iteration 7837 : loss : 0.137321, loss_ce: 0.018242
[01:06:43.292] iteration 7838 : loss : 0.064802, loss_ce: 0.016428
[01:06:43.583] iteration 7839 : loss : 0.060651, loss_ce: 0.021318
[01:06:43.878] iteration 7840 : loss : 0.073901, loss_ce: 0.015776
[01:06:44.195] iteration 7841 : loss : 0.088149, loss_ce: 0.021278
[01:06:44.491] iteration 7842 : loss : 0.048571, loss_ce: 0.020396
[01:06:44.790] iteration 7843 : loss : 0.058538, loss_ce: 0.018653
[01:06:45.088] iteration 7844 : loss : 0.131819, loss_ce: 0.015418
[01:06:45.388] iteration 7845 : loss : 0.068014, loss_ce: 0.016788
[01:06:45.684] iteration 7846 : loss : 0.109511, loss_ce: 0.008428
[01:06:45.983] iteration 7847 : loss : 0.057180, loss_ce: 0.029535
[01:06:46.278] iteration 7848 : loss : 0.056852, loss_ce: 0.018150
[01:06:46.570] iteration 7849 : loss : 0.053897, loss_ce: 0.026377
[01:06:46.862] iteration 7850 : loss : 0.066565, loss_ce: 0.021849
[01:06:47.155] iteration 7851 : loss : 0.068881, loss_ce: 0.022916
[01:06:47.446] iteration 7852 : loss : 0.068737, loss_ce: 0.022109
[01:06:47.739] iteration 7853 : loss : 0.051040, loss_ce: 0.022570
[01:06:48.032] iteration 7854 : loss : 0.106656, loss_ce: 0.017002
[01:06:48.327] iteration 7855 : loss : 0.061009, loss_ce: 0.027638
[01:06:48.620] iteration 7856 : loss : 0.050901, loss_ce: 0.018672
[01:06:48.915] iteration 7857 : loss : 0.060210, loss_ce: 0.009741
[01:06:49.209] iteration 7858 : loss : 0.064024, loss_ce: 0.034511
[01:06:49.506] iteration 7859 : loss : 0.163147, loss_ce: 0.007948
[01:06:49.798] iteration 7860 : loss : 0.104578, loss_ce: 0.007088
[01:06:50.113] iteration 7861 : loss : 0.123021, loss_ce: 0.018373
[01:06:50.405] iteration 7862 : loss : 0.216981, loss_ce: 0.009970
[01:06:50.697] iteration 7863 : loss : 0.067913, loss_ce: 0.030960
[01:06:50.996] iteration 7864 : loss : 0.064420, loss_ce: 0.015269
[01:06:51.291] iteration 7865 : loss : 0.062060, loss_ce: 0.021256
[01:06:51.587] iteration 7866 : loss : 0.061239, loss_ce: 0.014437
[01:06:51.878] iteration 7867 : loss : 0.128990, loss_ce: 0.031634
[01:06:52.171] iteration 7868 : loss : 0.055602, loss_ce: 0.017409
[01:06:52.466] iteration 7869 : loss : 0.054433, loss_ce: 0.012858
[01:06:52.760] iteration 7870 : loss : 0.112425, loss_ce: 0.020766
[01:06:53.050] iteration 7871 : loss : 0.097171, loss_ce: 0.013369
[01:06:53.343] iteration 7872 : loss : 0.062727, loss_ce: 0.022125
[01:06:53.633] iteration 7873 : loss : 0.068144, loss_ce: 0.013956
[01:06:53.929] iteration 7874 : loss : 0.117992, loss_ce: 0.023459
[01:06:54.224] iteration 7875 : loss : 0.087046, loss_ce: 0.024551
[01:06:54.516] iteration 7876 : loss : 0.123521, loss_ce: 0.013960
[01:06:54.808] iteration 7877 : loss : 0.064067, loss_ce: 0.013219
[01:06:55.101] iteration 7878 : loss : 0.061488, loss_ce: 0.017928
[01:06:55.392] iteration 7879 : loss : 0.062509, loss_ce: 0.021748
[01:06:55.684] iteration 7880 : loss : 0.073393, loss_ce: 0.011629
[01:06:55.995] iteration 7881 : loss : 0.056363, loss_ce: 0.022651
[01:06:56.288] iteration 7882 : loss : 0.081324, loss_ce: 0.021158
[01:06:56.581] iteration 7883 : loss : 0.051475, loss_ce: 0.018949
[01:06:56.877] iteration 7884 : loss : 0.068662, loss_ce: 0.011816
[01:06:57.171] iteration 7885 : loss : 0.058103, loss_ce: 0.011171
[01:06:57.468] iteration 7886 : loss : 0.068523, loss_ce: 0.023319
[01:06:57.762] iteration 7887 : loss : 0.063633, loss_ce: 0.014991
[01:06:58.057] iteration 7888 : loss : 0.057186, loss_ce: 0.019991
[01:06:58.357] iteration 7889 : loss : 0.061288, loss_ce: 0.022961
[01:06:58.654] iteration 7890 : loss : 0.073779, loss_ce: 0.015789
[01:06:58.945] iteration 7891 : loss : 0.058755, loss_ce: 0.009528
[01:06:59.247] iteration 7892 : loss : 0.050496, loss_ce: 0.014453
[01:06:59.546] iteration 7893 : loss : 0.089254, loss_ce: 0.028960
[01:06:59.845] iteration 7894 : loss : 0.074328, loss_ce: 0.009945
[01:07:00.144] iteration 7895 : loss : 0.128897, loss_ce: 0.006392
[01:07:00.444] iteration 7896 : loss : 0.069839, loss_ce: 0.022858
[01:07:00.744] iteration 7897 : loss : 0.124316, loss_ce: 0.014459
[01:07:01.044] iteration 7898 : loss : 0.059605, loss_ce: 0.008947
[01:07:01.336] iteration 7899 : loss : 0.131305, loss_ce: 0.011869
[01:07:01.631] iteration 7900 : loss : 0.101036, loss_ce: 0.017358
[01:07:01.943] iteration 7901 : loss : 0.047104, loss_ce: 0.014454
[01:07:02.237] iteration 7902 : loss : 0.071112, loss_ce: 0.023682
[01:07:02.529] iteration 7903 : loss : 0.047405, loss_ce: 0.014602
[01:07:02.824] iteration 7904 : loss : 0.056604, loss_ce: 0.020504
[01:07:03.116] iteration 7905 : loss : 0.069510, loss_ce: 0.028792
[01:07:03.410] iteration 7906 : loss : 0.067712, loss_ce: 0.014258
[01:07:03.713] iteration 7907 : loss : 0.062822, loss_ce: 0.012881
[01:07:04.011] iteration 7908 : loss : 0.057784, loss_ce: 0.029427
[01:07:04.310] iteration 7909 : loss : 0.128161, loss_ce: 0.008713
[01:07:04.617] iteration 7910 : loss : 0.086286, loss_ce: 0.019263
[01:07:04.918] iteration 7911 : loss : 0.066900, loss_ce: 0.026995
[01:07:05.221] iteration 7912 : loss : 0.064575, loss_ce: 0.017779
[01:07:05.522] iteration 7913 : loss : 0.054363, loss_ce: 0.015091
[01:07:05.820] iteration 7914 : loss : 0.048550, loss_ce: 0.021518
[01:07:06.124] iteration 7915 : loss : 0.054833, loss_ce: 0.023258
[01:07:06.425] iteration 7916 : loss : 0.117184, loss_ce: 0.011364
[01:07:06.726] iteration 7917 : loss : 0.087092, loss_ce: 0.015359
[01:07:07.029] iteration 7918 : loss : 0.111804, loss_ce: 0.008712
[01:07:07.331] iteration 7919 : loss : 0.171560, loss_ce: 0.011949
[01:07:07.633] iteration 7920 : loss : 0.086992, loss_ce: 0.028375
[01:07:07.962] iteration 7921 : loss : 0.062223, loss_ce: 0.010933
[01:07:08.258] iteration 7922 : loss : 0.061484, loss_ce: 0.014891
[01:07:08.336] iteration 7923 : loss : 0.461376, loss_ce: 0.000787
[01:07:26.234] iteration 7924 : loss : 0.064500, loss_ce: 0.025064
[01:07:26.532] iteration 7925 : loss : 0.182793, loss_ce: 0.012692
[01:07:26.838] iteration 7926 : loss : 0.054506, loss_ce: 0.016335
[01:07:27.139] iteration 7927 : loss : 0.054352, loss_ce: 0.009599
[01:07:27.446] iteration 7928 : loss : 0.101746, loss_ce: 0.025079
[01:07:27.745] iteration 7929 : loss : 0.067692, loss_ce: 0.019447
[01:07:28.044] iteration 7930 : loss : 0.123024, loss_ce: 0.011557
[01:07:28.337] iteration 7931 : loss : 0.169594, loss_ce: 0.010975
[01:07:28.636] iteration 7932 : loss : 0.116889, loss_ce: 0.015295
[01:07:28.939] iteration 7933 : loss : 0.135303, loss_ce: 0.028705
[01:07:29.241] iteration 7934 : loss : 0.056441, loss_ce: 0.018459
[01:07:29.540] iteration 7935 : loss : 0.059011, loss_ce: 0.025842
[01:07:29.837] iteration 7936 : loss : 0.175768, loss_ce: 0.015100
[01:07:30.138] iteration 7937 : loss : 0.088356, loss_ce: 0.014867
[01:07:30.437] iteration 7938 : loss : 0.055266, loss_ce: 0.010691
[01:07:30.733] iteration 7939 : loss : 0.093575, loss_ce: 0.032086
[01:07:31.033] iteration 7940 : loss : 0.187659, loss_ce: 0.008254
[01:07:31.346] iteration 7941 : loss : 0.070196, loss_ce: 0.017390
[01:07:31.649] iteration 7942 : loss : 0.073579, loss_ce: 0.024091
[01:07:31.946] iteration 7943 : loss : 0.114499, loss_ce: 0.012992
[01:07:32.246] iteration 7944 : loss : 0.061267, loss_ce: 0.024701
[01:07:32.548] iteration 7945 : loss : 0.060631, loss_ce: 0.013432
[01:07:32.849] iteration 7946 : loss : 0.139240, loss_ce: 0.015606
[01:07:33.151] iteration 7947 : loss : 0.095926, loss_ce: 0.010380
[01:07:33.450] iteration 7948 : loss : 0.129101, loss_ce: 0.015287
[01:07:33.749] iteration 7949 : loss : 0.116699, loss_ce: 0.007858
[01:07:34.047] iteration 7950 : loss : 0.067419, loss_ce: 0.016164
[01:07:34.349] iteration 7951 : loss : 0.057317, loss_ce: 0.032577
[01:07:34.650] iteration 7952 : loss : 0.106816, loss_ce: 0.015932
[01:07:34.950] iteration 7953 : loss : 0.056830, loss_ce: 0.019824
[01:07:35.254] iteration 7954 : loss : 0.068510, loss_ce: 0.010545
[01:07:35.556] iteration 7955 : loss : 0.063157, loss_ce: 0.018014
[01:07:35.858] iteration 7956 : loss : 0.065691, loss_ce: 0.015856
[01:07:36.155] iteration 7957 : loss : 0.122265, loss_ce: 0.011028
[01:07:36.447] iteration 7958 : loss : 0.047247, loss_ce: 0.019224
[01:07:36.744] iteration 7959 : loss : 0.222641, loss_ce: 0.006845
[01:07:37.037] iteration 7960 : loss : 0.088030, loss_ce: 0.026646
[01:07:37.354] iteration 7961 : loss : 0.075108, loss_ce: 0.012315
[01:07:37.646] iteration 7962 : loss : 0.054665, loss_ce: 0.019718
[01:07:37.941] iteration 7963 : loss : 0.173897, loss_ce: 0.008569
[01:07:38.237] iteration 7964 : loss : 0.075379, loss_ce: 0.029550
[01:07:38.531] iteration 7965 : loss : 0.071146, loss_ce: 0.017068
[01:07:38.830] iteration 7966 : loss : 0.062285, loss_ce: 0.018469
[01:07:39.125] iteration 7967 : loss : 0.075575, loss_ce: 0.019262
[01:07:39.422] iteration 7968 : loss : 0.063784, loss_ce: 0.016323
[01:07:39.721] iteration 7969 : loss : 0.067254, loss_ce: 0.027681
[01:07:40.016] iteration 7970 : loss : 0.086892, loss_ce: 0.013425
[01:07:40.312] iteration 7971 : loss : 0.066829, loss_ce: 0.010935
[01:07:40.609] iteration 7972 : loss : 0.056589, loss_ce: 0.013137
[01:07:40.903] iteration 7973 : loss : 0.063714, loss_ce: 0.019084
[01:07:41.198] iteration 7974 : loss : 0.050667, loss_ce: 0.013736
[01:07:41.495] iteration 7975 : loss : 0.058391, loss_ce: 0.020077
[01:07:41.790] iteration 7976 : loss : 0.098388, loss_ce: 0.012710
[01:07:42.088] iteration 7977 : loss : 0.174979, loss_ce: 0.009642
[01:07:42.381] iteration 7978 : loss : 0.058249, loss_ce: 0.013580
[01:07:42.676] iteration 7979 : loss : 0.148985, loss_ce: 0.017241
[01:07:42.967] iteration 7980 : loss : 0.061090, loss_ce: 0.027792
[01:07:43.276] iteration 7981 : loss : 0.058711, loss_ce: 0.016516
[01:07:43.571] iteration 7982 : loss : 0.060957, loss_ce: 0.020003
[01:07:43.863] iteration 7983 : loss : 0.070742, loss_ce: 0.015609
[01:07:44.164] iteration 7984 : loss : 0.085353, loss_ce: 0.028747
[01:07:44.460] iteration 7985 : loss : 0.042403, loss_ce: 0.016611
[01:07:44.756] iteration 7986 : loss : 0.080025, loss_ce: 0.016527
[01:07:45.055] iteration 7987 : loss : 0.061187, loss_ce: 0.025503
[01:07:45.348] iteration 7988 : loss : 0.040409, loss_ce: 0.010650
[01:07:45.642] iteration 7989 : loss : 0.053843, loss_ce: 0.011305
[01:07:45.937] iteration 7990 : loss : 0.063514, loss_ce: 0.022463
[01:07:46.230] iteration 7991 : loss : 0.120622, loss_ce: 0.014065
[01:07:46.522] iteration 7992 : loss : 0.055862, loss_ce: 0.013959
[01:07:46.816] iteration 7993 : loss : 0.118194, loss_ce: 0.019010
[01:07:47.110] iteration 7994 : loss : 0.051517, loss_ce: 0.021776
[01:07:47.401] iteration 7995 : loss : 0.052232, loss_ce: 0.019770
[01:07:47.693] iteration 7996 : loss : 0.057913, loss_ce: 0.019878
[01:07:47.988] iteration 7997 : loss : 0.061828, loss_ce: 0.026859
[01:07:48.283] iteration 7998 : loss : 0.054844, loss_ce: 0.021061
[01:07:48.574] iteration 7999 : loss : 0.038796, loss_ce: 0.008218
[01:07:48.870] iteration 8000 : loss : 0.065547, loss_ce: 0.014499
[01:07:49.181] iteration 8001 : loss : 0.184050, loss_ce: 0.006830
[01:07:49.478] iteration 8002 : loss : 0.110558, loss_ce: 0.019159
[01:07:49.779] iteration 8003 : loss : 0.101911, loss_ce: 0.007601
[01:07:50.077] iteration 8004 : loss : 0.054585, loss_ce: 0.020197
[01:07:50.374] iteration 8005 : loss : 0.054858, loss_ce: 0.014418
[01:07:50.670] iteration 8006 : loss : 0.059066, loss_ce: 0.017788
[01:07:50.969] iteration 8007 : loss : 0.057411, loss_ce: 0.019566
[01:07:51.267] iteration 8008 : loss : 0.071610, loss_ce: 0.012476
[01:07:51.556] iteration 8009 : loss : 0.047646, loss_ce: 0.020643
[01:07:51.845] iteration 8010 : loss : 0.054646, loss_ce: 0.024399
[01:07:52.138] iteration 8011 : loss : 0.075136, loss_ce: 0.018788
[01:07:52.428] iteration 8012 : loss : 0.055318, loss_ce: 0.027847
[01:07:52.722] iteration 8013 : loss : 0.053550, loss_ce: 0.014972
[01:07:53.014] iteration 8014 : loss : 0.053616, loss_ce: 0.012741
[01:07:53.308] iteration 8015 : loss : 0.050544, loss_ce: 0.012644
[01:07:53.599] iteration 8016 : loss : 0.073348, loss_ce: 0.022713
[01:07:53.893] iteration 8017 : loss : 0.072979, loss_ce: 0.025925
[01:07:54.184] iteration 8018 : loss : 0.056316, loss_ce: 0.014746
[01:07:54.480] iteration 8019 : loss : 0.060372, loss_ce: 0.019952
[01:07:54.773] iteration 8020 : loss : 0.066015, loss_ce: 0.017003
[01:07:55.085] iteration 8021 : loss : 0.054339, loss_ce: 0.023477
[01:07:55.373] iteration 8022 : loss : 0.061060, loss_ce: 0.016068
[01:07:55.663] iteration 8023 : loss : 0.067417, loss_ce: 0.025155
[01:07:55.958] iteration 8024 : loss : 0.088284, loss_ce: 0.015396
[01:07:56.253] iteration 8025 : loss : 0.052983, loss_ce: 0.018560
[01:07:56.547] iteration 8026 : loss : 0.085816, loss_ce: 0.016913
[01:07:56.843] iteration 8027 : loss : 0.078560, loss_ce: 0.016105
[01:07:57.136] iteration 8028 : loss : 0.171756, loss_ce: 0.005837
[01:07:57.432] iteration 8029 : loss : 0.075191, loss_ce: 0.018649
[01:07:57.725] iteration 8030 : loss : 0.142793, loss_ce: 0.020584
[01:07:58.018] iteration 8031 : loss : 0.072832, loss_ce: 0.028410
[01:07:58.314] iteration 8032 : loss : 0.055296, loss_ce: 0.019802
[01:07:58.606] iteration 8033 : loss : 0.105927, loss_ce: 0.006209
[01:07:58.901] iteration 8034 : loss : 0.056990, loss_ce: 0.014435
[01:07:59.191] iteration 8035 : loss : 0.063940, loss_ce: 0.013040
[01:07:59.485] iteration 8036 : loss : 0.059552, loss_ce: 0.016508
[01:07:59.774] iteration 8037 : loss : 0.060098, loss_ce: 0.026391
[01:08:00.069] iteration 8038 : loss : 0.127095, loss_ce: 0.010518
[01:08:00.364] iteration 8039 : loss : 0.062389, loss_ce: 0.017094
[01:08:00.656] iteration 8040 : loss : 0.050120, loss_ce: 0.010484
[01:08:00.969] iteration 8041 : loss : 0.124160, loss_ce: 0.013814
[01:08:01.264] iteration 8042 : loss : 0.070504, loss_ce: 0.017369
[01:08:01.556] iteration 8043 : loss : 0.052045, loss_ce: 0.016839
[01:08:01.851] iteration 8044 : loss : 0.122288, loss_ce: 0.022739
[01:08:02.146] iteration 8045 : loss : 0.058723, loss_ce: 0.019182
[01:08:02.446] iteration 8046 : loss : 0.064105, loss_ce: 0.027518
[01:08:02.744] iteration 8047 : loss : 0.112659, loss_ce: 0.018055
[01:08:03.044] iteration 8048 : loss : 0.136318, loss_ce: 0.011702
[01:08:03.347] iteration 8049 : loss : 0.056110, loss_ce: 0.027293
[01:08:03.649] iteration 8050 : loss : 0.064323, loss_ce: 0.018260
[01:08:03.949] iteration 8051 : loss : 0.048454, loss_ce: 0.020112
[01:08:04.251] iteration 8052 : loss : 0.055368, loss_ce: 0.020733
[01:08:04.556] iteration 8053 : loss : 0.052437, loss_ce: 0.029970
[01:08:04.857] iteration 8054 : loss : 0.057961, loss_ce: 0.014722
[01:08:05.169] iteration 8055 : loss : 0.112806, loss_ce: 0.017735
[01:08:05.475] iteration 8056 : loss : 0.045288, loss_ce: 0.013682
[01:08:05.780] iteration 8057 : loss : 0.086627, loss_ce: 0.005649
[01:08:06.082] iteration 8058 : loss : 0.059701, loss_ce: 0.024421
[01:08:06.376] iteration 8059 : loss : 0.074569, loss_ce: 0.014481
[01:08:06.677] iteration 8060 : loss : 0.107952, loss_ce: 0.012469
[01:08:06.994] iteration 8061 : loss : 0.058816, loss_ce: 0.021798
[01:08:07.078] iteration 8062 : loss : 0.421201, loss_ce: 0.000363
[01:08:28.877] iteration 8063 : loss : 0.102014, loss_ce: 0.009416
[01:08:29.167] iteration 8064 : loss : 0.054660, loss_ce: 0.015096
[01:08:29.458] iteration 8065 : loss : 0.119903, loss_ce: 0.015066
[01:08:29.750] iteration 8066 : loss : 0.080637, loss_ce: 0.021571
[01:08:30.042] iteration 8067 : loss : 0.058883, loss_ce: 0.024266
[01:08:30.332] iteration 8068 : loss : 0.083688, loss_ce: 0.026607
[01:08:30.621] iteration 8069 : loss : 0.098429, loss_ce: 0.024787
[01:08:30.910] iteration 8070 : loss : 0.078997, loss_ce: 0.041081
[01:08:31.203] iteration 8071 : loss : 0.056274, loss_ce: 0.014586
[01:08:31.494] iteration 8072 : loss : 0.055204, loss_ce: 0.014915
[01:08:31.787] iteration 8073 : loss : 0.065951, loss_ce: 0.023163
[01:08:32.080] iteration 8074 : loss : 0.060667, loss_ce: 0.019239
[01:08:32.372] iteration 8075 : loss : 0.072177, loss_ce: 0.028902
[01:08:32.668] iteration 8076 : loss : 0.057510, loss_ce: 0.019935
[01:08:32.959] iteration 8077 : loss : 0.054574, loss_ce: 0.024536
[01:08:33.249] iteration 8078 : loss : 0.114878, loss_ce: 0.017460
[01:08:33.543] iteration 8079 : loss : 0.059390, loss_ce: 0.020490
[01:08:33.832] iteration 8080 : loss : 0.075497, loss_ce: 0.029721
[01:08:34.141] iteration 8081 : loss : 0.073494, loss_ce: 0.027016
[01:08:34.440] iteration 8082 : loss : 0.086783, loss_ce: 0.024885
[01:08:34.732] iteration 8083 : loss : 0.057023, loss_ce: 0.011380
[01:08:35.028] iteration 8084 : loss : 0.112010, loss_ce: 0.014117
[01:08:35.323] iteration 8085 : loss : 0.091933, loss_ce: 0.016192
[01:08:35.620] iteration 8086 : loss : 0.060317, loss_ce: 0.028119
[01:08:35.912] iteration 8087 : loss : 0.067381, loss_ce: 0.021530
[01:08:36.206] iteration 8088 : loss : 0.078770, loss_ce: 0.021562
[01:08:36.504] iteration 8089 : loss : 0.047677, loss_ce: 0.014041
[01:08:36.798] iteration 8090 : loss : 0.065086, loss_ce: 0.014265
[01:08:37.095] iteration 8091 : loss : 0.129150, loss_ce: 0.019600
[01:08:37.392] iteration 8092 : loss : 0.126517, loss_ce: 0.015418
[01:08:37.688] iteration 8093 : loss : 0.065945, loss_ce: 0.032921
[01:08:37.987] iteration 8094 : loss : 0.062161, loss_ce: 0.017605
[01:08:38.286] iteration 8095 : loss : 0.070064, loss_ce: 0.018653
[01:08:38.584] iteration 8096 : loss : 0.074181, loss_ce: 0.026543
[01:08:38.884] iteration 8097 : loss : 0.063927, loss_ce: 0.014573
[01:08:39.182] iteration 8098 : loss : 0.067908, loss_ce: 0.022260
[01:08:39.479] iteration 8099 : loss : 0.060837, loss_ce: 0.008467
[01:08:39.777] iteration 8100 : loss : 0.058167, loss_ce: 0.022510
[01:08:40.089] iteration 8101 : loss : 0.114434, loss_ce: 0.014480
[01:08:40.389] iteration 8102 : loss : 0.055729, loss_ce: 0.020460
[01:08:40.685] iteration 8103 : loss : 0.068504, loss_ce: 0.019537
[01:08:40.984] iteration 8104 : loss : 0.109576, loss_ce: 0.013391
[01:08:41.278] iteration 8105 : loss : 0.058892, loss_ce: 0.026298
[01:08:41.574] iteration 8106 : loss : 0.059664, loss_ce: 0.019145
[01:08:41.873] iteration 8107 : loss : 0.051208, loss_ce: 0.009322
[01:08:42.171] iteration 8108 : loss : 0.054611, loss_ce: 0.016322
[01:08:42.470] iteration 8109 : loss : 0.052859, loss_ce: 0.027180
[01:08:42.765] iteration 8110 : loss : 0.056832, loss_ce: 0.020830
[01:08:43.065] iteration 8111 : loss : 0.082829, loss_ce: 0.017197
[01:08:43.364] iteration 8112 : loss : 0.057704, loss_ce: 0.021586
[01:08:43.662] iteration 8113 : loss : 0.074476, loss_ce: 0.021727
[01:08:43.961] iteration 8114 : loss : 0.063868, loss_ce: 0.018988
[01:08:44.257] iteration 8115 : loss : 0.079389, loss_ce: 0.020645
[01:08:44.555] iteration 8116 : loss : 0.061165, loss_ce: 0.029157
[01:08:44.850] iteration 8117 : loss : 0.058718, loss_ce: 0.010572
[01:08:45.146] iteration 8118 : loss : 0.198553, loss_ce: 0.022448
[01:08:45.444] iteration 8119 : loss : 0.067803, loss_ce: 0.020418
[01:08:45.737] iteration 8120 : loss : 0.061582, loss_ce: 0.015631
[01:08:46.049] iteration 8121 : loss : 0.060224, loss_ce: 0.033711
[01:08:46.345] iteration 8122 : loss : 0.049174, loss_ce: 0.020621
[01:08:46.645] iteration 8123 : loss : 0.070870, loss_ce: 0.019296
[01:08:46.943] iteration 8124 : loss : 0.054002, loss_ce: 0.022250
[01:08:47.245] iteration 8125 : loss : 0.050232, loss_ce: 0.014027
[01:08:47.540] iteration 8126 : loss : 0.124763, loss_ce: 0.013678
[01:08:47.835] iteration 8127 : loss : 0.048135, loss_ce: 0.021847
[01:08:48.136] iteration 8128 : loss : 0.058900, loss_ce: 0.013166
[01:08:48.437] iteration 8129 : loss : 0.082692, loss_ce: 0.014706
[01:08:48.733] iteration 8130 : loss : 0.146481, loss_ce: 0.011361
[01:08:49.031] iteration 8131 : loss : 0.059219, loss_ce: 0.021931
[01:08:49.330] iteration 8132 : loss : 0.062495, loss_ce: 0.020538
[01:08:49.628] iteration 8133 : loss : 0.053821, loss_ce: 0.021657
[01:08:49.926] iteration 8134 : loss : 0.055790, loss_ce: 0.015772
[01:08:50.221] iteration 8135 : loss : 0.060836, loss_ce: 0.012031
[01:08:50.517] iteration 8136 : loss : 0.059927, loss_ce: 0.009238
[01:08:50.818] iteration 8137 : loss : 0.066794, loss_ce: 0.015283
[01:08:51.113] iteration 8138 : loss : 0.058495, loss_ce: 0.014341
[01:08:51.413] iteration 8139 : loss : 0.065327, loss_ce: 0.025451
[01:08:51.711] iteration 8140 : loss : 0.067081, loss_ce: 0.013478
[01:08:52.028] iteration 8141 : loss : 0.063175, loss_ce: 0.020583
[01:08:52.328] iteration 8142 : loss : 0.050097, loss_ce: 0.018756
[01:08:52.626] iteration 8143 : loss : 0.069621, loss_ce: 0.018307
[01:08:52.927] iteration 8144 : loss : 0.074979, loss_ce: 0.023191
[01:08:53.222] iteration 8145 : loss : 0.051725, loss_ce: 0.019871
[01:08:53.521] iteration 8146 : loss : 0.062962, loss_ce: 0.018637
[01:08:53.824] iteration 8147 : loss : 0.292272, loss_ce: 0.018320
[01:08:54.124] iteration 8148 : loss : 0.068020, loss_ce: 0.008867
[01:08:54.424] iteration 8149 : loss : 0.067128, loss_ce: 0.019916
[01:08:54.725] iteration 8150 : loss : 0.065547, loss_ce: 0.025126
[01:08:55.025] iteration 8151 : loss : 0.072526, loss_ce: 0.012639
[01:08:55.323] iteration 8152 : loss : 0.067955, loss_ce: 0.013740
[01:08:55.620] iteration 8153 : loss : 0.068776, loss_ce: 0.020793
[01:08:55.917] iteration 8154 : loss : 0.069823, loss_ce: 0.018438
[01:08:56.215] iteration 8155 : loss : 0.074289, loss_ce: 0.022941
[01:08:56.505] iteration 8156 : loss : 0.060752, loss_ce: 0.021130
[01:08:56.803] iteration 8157 : loss : 0.103856, loss_ce: 0.015843
[01:08:57.097] iteration 8158 : loss : 0.062223, loss_ce: 0.023708
[01:08:57.388] iteration 8159 : loss : 0.060113, loss_ce: 0.014016
[01:08:57.681] iteration 8160 : loss : 0.074996, loss_ce: 0.020130
[01:08:57.988] iteration 8161 : loss : 0.169106, loss_ce: 0.014047
[01:08:58.284] iteration 8162 : loss : 0.114312, loss_ce: 0.006906
[01:08:58.580] iteration 8163 : loss : 0.061106, loss_ce: 0.014725
[01:08:58.877] iteration 8164 : loss : 0.109149, loss_ce: 0.018215
[01:08:59.174] iteration 8165 : loss : 0.073987, loss_ce: 0.019015
[01:08:59.472] iteration 8166 : loss : 0.066517, loss_ce: 0.016790
[01:08:59.765] iteration 8167 : loss : 0.074147, loss_ce: 0.016380
[01:09:00.059] iteration 8168 : loss : 0.053891, loss_ce: 0.017205
[01:09:00.351] iteration 8169 : loss : 0.051638, loss_ce: 0.017684
[01:09:00.644] iteration 8170 : loss : 0.057539, loss_ce: 0.028531
[01:09:00.939] iteration 8171 : loss : 0.106071, loss_ce: 0.012083
[01:09:01.232] iteration 8172 : loss : 0.065600, loss_ce: 0.014800
[01:09:01.523] iteration 8173 : loss : 0.053592, loss_ce: 0.016677
[01:09:01.817] iteration 8174 : loss : 0.069897, loss_ce: 0.021528
[01:09:02.109] iteration 8175 : loss : 0.060985, loss_ce: 0.025252
[01:09:02.402] iteration 8176 : loss : 0.116469, loss_ce: 0.010365
[01:09:02.695] iteration 8177 : loss : 0.185287, loss_ce: 0.011967
[01:09:02.990] iteration 8178 : loss : 0.098589, loss_ce: 0.013047
[01:09:03.284] iteration 8179 : loss : 0.133442, loss_ce: 0.010453
[01:09:03.577] iteration 8180 : loss : 0.114511, loss_ce: 0.009536
[01:09:03.886] iteration 8181 : loss : 0.083709, loss_ce: 0.016587
[01:09:04.181] iteration 8182 : loss : 0.073115, loss_ce: 0.027135
[01:09:04.472] iteration 8183 : loss : 0.069917, loss_ce: 0.033896
[01:09:04.768] iteration 8184 : loss : 0.119019, loss_ce: 0.010186
[01:09:05.063] iteration 8185 : loss : 0.074791, loss_ce: 0.016901
[01:09:05.360] iteration 8186 : loss : 0.045027, loss_ce: 0.010053
[01:09:05.659] iteration 8187 : loss : 0.072760, loss_ce: 0.028289
[01:09:05.957] iteration 8188 : loss : 0.062959, loss_ce: 0.016882
[01:09:06.255] iteration 8189 : loss : 0.053437, loss_ce: 0.013031
[01:09:06.551] iteration 8190 : loss : 0.077095, loss_ce: 0.019062
[01:09:06.848] iteration 8191 : loss : 0.068615, loss_ce: 0.020236
[01:09:07.149] iteration 8192 : loss : 0.068947, loss_ce: 0.019799
[01:09:07.451] iteration 8193 : loss : 0.112209, loss_ce: 0.019867
[01:09:07.756] iteration 8194 : loss : 0.064770, loss_ce: 0.017658
[01:09:08.052] iteration 8195 : loss : 0.118605, loss_ce: 0.017467
[01:09:08.348] iteration 8196 : loss : 0.107045, loss_ce: 0.012071
[01:09:08.645] iteration 8197 : loss : 0.069415, loss_ce: 0.026047
[01:09:08.947] iteration 8198 : loss : 0.071174, loss_ce: 0.019416
[01:09:09.247] iteration 8199 : loss : 0.083085, loss_ce: 0.015624
[01:09:09.553] iteration 8200 : loss : 0.080480, loss_ce: 0.017566
[01:09:09.662] iteration 8201 : loss : 0.058181, loss_ce: 0.022724
[01:09:28.280] iteration 8202 : loss : 0.042546, loss_ce: 0.015382
[01:09:28.579] iteration 8203 : loss : 0.066488, loss_ce: 0.017635
[01:09:28.879] iteration 8204 : loss : 0.045391, loss_ce: 0.007993
[01:09:29.182] iteration 8205 : loss : 0.108950, loss_ce: 0.012021
[01:09:29.484] iteration 8206 : loss : 0.047674, loss_ce: 0.010687
[01:09:29.780] iteration 8207 : loss : 0.051284, loss_ce: 0.013008
[01:09:30.080] iteration 8208 : loss : 0.059499, loss_ce: 0.021072
[01:09:30.377] iteration 8209 : loss : 0.077597, loss_ce: 0.019030
[01:09:30.677] iteration 8210 : loss : 0.045424, loss_ce: 0.020149
[01:09:30.977] iteration 8211 : loss : 0.097253, loss_ce: 0.029337
[01:09:31.278] iteration 8212 : loss : 0.066487, loss_ce: 0.019814
[01:09:31.577] iteration 8213 : loss : 0.120044, loss_ce: 0.008528
[01:09:31.875] iteration 8214 : loss : 0.089020, loss_ce: 0.005916
[01:09:32.168] iteration 8215 : loss : 0.054180, loss_ce: 0.010829
[01:09:32.468] iteration 8216 : loss : 0.117753, loss_ce: 0.015898
[01:09:32.766] iteration 8217 : loss : 0.072575, loss_ce: 0.013634
[01:09:33.069] iteration 8218 : loss : 0.076703, loss_ce: 0.021115
[01:09:33.369] iteration 8219 : loss : 0.069231, loss_ce: 0.025797
[01:09:33.670] iteration 8220 : loss : 0.103172, loss_ce: 0.013109
[01:09:33.992] iteration 8221 : loss : 0.169221, loss_ce: 0.005374
[01:09:34.291] iteration 8222 : loss : 0.074415, loss_ce: 0.018264
[01:09:34.587] iteration 8223 : loss : 0.065720, loss_ce: 0.012420
[01:09:34.883] iteration 8224 : loss : 0.062553, loss_ce: 0.017998
[01:09:35.184] iteration 8225 : loss : 0.069223, loss_ce: 0.025843
[01:09:35.483] iteration 8226 : loss : 0.050958, loss_ce: 0.012237
[01:09:35.785] iteration 8227 : loss : 0.127927, loss_ce: 0.006815
[01:09:36.084] iteration 8228 : loss : 0.047932, loss_ce: 0.014813
[01:09:36.386] iteration 8229 : loss : 0.067947, loss_ce: 0.018424
[01:09:36.689] iteration 8230 : loss : 0.074839, loss_ce: 0.020110
[01:09:36.988] iteration 8231 : loss : 0.067172, loss_ce: 0.017991
[01:09:37.289] iteration 8232 : loss : 0.065389, loss_ce: 0.015101
[01:09:37.589] iteration 8233 : loss : 0.112824, loss_ce: 0.014278
[01:09:37.889] iteration 8234 : loss : 0.035258, loss_ce: 0.015693
[01:09:38.183] iteration 8235 : loss : 0.066299, loss_ce: 0.019572
[01:09:38.481] iteration 8236 : loss : 0.070291, loss_ce: 0.016170
[01:09:38.779] iteration 8237 : loss : 0.044159, loss_ce: 0.012262
[01:09:39.072] iteration 8238 : loss : 0.052604, loss_ce: 0.015745
[01:09:39.375] iteration 8239 : loss : 0.054673, loss_ce: 0.013844
[01:09:39.678] iteration 8240 : loss : 0.056699, loss_ce: 0.025639
[01:09:39.996] iteration 8241 : loss : 0.056621, loss_ce: 0.014978
[01:09:40.292] iteration 8242 : loss : 0.110301, loss_ce: 0.023023
[01:09:40.593] iteration 8243 : loss : 0.072750, loss_ce: 0.018644
[01:09:40.890] iteration 8244 : loss : 0.062665, loss_ce: 0.017807
[01:09:41.190] iteration 8245 : loss : 0.062088, loss_ce: 0.013218
[01:09:41.487] iteration 8246 : loss : 0.114596, loss_ce: 0.027293
[01:09:41.788] iteration 8247 : loss : 0.047547, loss_ce: 0.013721
[01:09:42.089] iteration 8248 : loss : 0.058771, loss_ce: 0.017888
[01:09:42.389] iteration 8249 : loss : 0.074202, loss_ce: 0.013523
[01:09:42.685] iteration 8250 : loss : 0.061065, loss_ce: 0.016222
[01:09:42.984] iteration 8251 : loss : 0.066172, loss_ce: 0.018573
[01:09:43.284] iteration 8252 : loss : 0.128656, loss_ce: 0.023390
[01:09:43.584] iteration 8253 : loss : 0.059386, loss_ce: 0.019069
[01:09:43.882] iteration 8254 : loss : 0.116695, loss_ce: 0.022634
[01:09:44.187] iteration 8255 : loss : 0.079695, loss_ce: 0.020883
[01:09:44.486] iteration 8256 : loss : 0.063487, loss_ce: 0.019897
[01:09:44.786] iteration 8257 : loss : 0.123057, loss_ce: 0.008395
[01:09:45.087] iteration 8258 : loss : 0.060564, loss_ce: 0.023359
[01:09:45.384] iteration 8259 : loss : 0.055095, loss_ce: 0.018710
[01:09:45.680] iteration 8260 : loss : 0.110383, loss_ce: 0.014002
[01:09:46.001] iteration 8261 : loss : 0.063199, loss_ce: 0.018477
[01:09:46.294] iteration 8262 : loss : 0.240445, loss_ce: 0.020855
[01:09:46.589] iteration 8263 : loss : 0.061812, loss_ce: 0.029373
[01:09:46.884] iteration 8264 : loss : 0.060603, loss_ce: 0.018262
[01:09:47.181] iteration 8265 : loss : 0.062131, loss_ce: 0.013533
[01:09:47.473] iteration 8266 : loss : 0.063129, loss_ce: 0.021174
[01:09:47.767] iteration 8267 : loss : 0.055234, loss_ce: 0.014423
[01:09:48.061] iteration 8268 : loss : 0.052215, loss_ce: 0.015306
[01:09:48.353] iteration 8269 : loss : 0.050887, loss_ce: 0.012568
[01:09:48.651] iteration 8270 : loss : 0.045332, loss_ce: 0.013928
[01:09:48.942] iteration 8271 : loss : 0.056050, loss_ce: 0.024328
[01:09:49.238] iteration 8272 : loss : 0.051655, loss_ce: 0.014399
[01:09:49.531] iteration 8273 : loss : 0.166803, loss_ce: 0.007853
[01:09:49.827] iteration 8274 : loss : 0.068910, loss_ce: 0.022435
[01:09:50.124] iteration 8275 : loss : 0.126629, loss_ce: 0.015882
[01:09:50.419] iteration 8276 : loss : 0.057100, loss_ce: 0.014208
[01:09:50.713] iteration 8277 : loss : 0.065826, loss_ce: 0.010766
[01:09:51.009] iteration 8278 : loss : 0.071859, loss_ce: 0.017164
[01:09:51.301] iteration 8279 : loss : 0.043845, loss_ce: 0.009355
[01:09:51.597] iteration 8280 : loss : 0.098568, loss_ce: 0.011087
[01:09:51.906] iteration 8281 : loss : 0.067521, loss_ce: 0.023400
[01:09:52.202] iteration 8282 : loss : 0.105136, loss_ce: 0.017239
[01:09:52.498] iteration 8283 : loss : 0.063597, loss_ce: 0.028308
[01:09:52.797] iteration 8284 : loss : 0.107850, loss_ce: 0.010869
[01:09:53.089] iteration 8285 : loss : 0.060059, loss_ce: 0.016610
[01:09:53.385] iteration 8286 : loss : 0.062093, loss_ce: 0.017396
[01:09:53.678] iteration 8287 : loss : 0.061053, loss_ce: 0.010685
[01:09:53.969] iteration 8288 : loss : 0.105473, loss_ce: 0.010701
[01:09:54.260] iteration 8289 : loss : 0.053946, loss_ce: 0.017935
[01:09:54.552] iteration 8290 : loss : 0.050906, loss_ce: 0.017836
[01:09:54.843] iteration 8291 : loss : 0.050205, loss_ce: 0.018280
[01:09:55.139] iteration 8292 : loss : 0.081308, loss_ce: 0.020095
[01:09:55.433] iteration 8293 : loss : 0.066242, loss_ce: 0.012926
[01:09:55.729] iteration 8294 : loss : 0.061157, loss_ce: 0.027258
[01:09:56.027] iteration 8295 : loss : 0.074955, loss_ce: 0.021745
[01:09:56.323] iteration 8296 : loss : 0.056809, loss_ce: 0.013248
[01:09:56.620] iteration 8297 : loss : 0.136517, loss_ce: 0.016898
[01:09:56.912] iteration 8298 : loss : 0.062014, loss_ce: 0.024231
[01:09:57.208] iteration 8299 : loss : 0.112426, loss_ce: 0.025734
[01:09:57.503] iteration 8300 : loss : 0.053763, loss_ce: 0.012809
[01:09:57.812] iteration 8301 : loss : 0.064537, loss_ce: 0.019012
[01:09:58.104] iteration 8302 : loss : 0.066119, loss_ce: 0.013104
[01:09:58.397] iteration 8303 : loss : 0.070558, loss_ce: 0.023353
[01:09:58.692] iteration 8304 : loss : 0.059010, loss_ce: 0.019495
[01:09:58.987] iteration 8305 : loss : 0.057810, loss_ce: 0.013383
[01:09:59.285] iteration 8306 : loss : 0.053796, loss_ce: 0.022566
[01:09:59.585] iteration 8307 : loss : 0.070729, loss_ce: 0.021453
[01:09:59.881] iteration 8308 : loss : 0.062453, loss_ce: 0.014585
[01:10:00.181] iteration 8309 : loss : 0.053849, loss_ce: 0.024223
[01:10:00.482] iteration 8310 : loss : 0.076194, loss_ce: 0.017559
[01:10:00.780] iteration 8311 : loss : 0.053641, loss_ce: 0.012379
[01:10:01.081] iteration 8312 : loss : 0.067369, loss_ce: 0.022981
[01:10:01.379] iteration 8313 : loss : 0.070084, loss_ce: 0.021540
[01:10:01.673] iteration 8314 : loss : 0.069260, loss_ce: 0.014031
[01:10:01.966] iteration 8315 : loss : 0.048991, loss_ce: 0.018911
[01:10:02.260] iteration 8316 : loss : 0.069994, loss_ce: 0.013868
[01:10:02.557] iteration 8317 : loss : 0.059758, loss_ce: 0.021592
[01:10:02.849] iteration 8318 : loss : 0.072507, loss_ce: 0.026036
[01:10:03.141] iteration 8319 : loss : 0.060597, loss_ce: 0.018159
[01:10:03.433] iteration 8320 : loss : 0.062137, loss_ce: 0.018789
[01:10:03.742] iteration 8321 : loss : 0.114124, loss_ce: 0.013183
[01:10:04.035] iteration 8322 : loss : 0.057730, loss_ce: 0.018376
[01:10:04.328] iteration 8323 : loss : 0.049449, loss_ce: 0.021407
[01:10:04.628] iteration 8324 : loss : 0.044230, loss_ce: 0.014840
[01:10:04.929] iteration 8325 : loss : 0.076597, loss_ce: 0.022459
[01:10:05.232] iteration 8326 : loss : 0.056316, loss_ce: 0.019977
[01:10:05.533] iteration 8327 : loss : 0.112262, loss_ce: 0.013524
[01:10:05.833] iteration 8328 : loss : 0.057533, loss_ce: 0.020492
[01:10:06.132] iteration 8329 : loss : 0.154022, loss_ce: 0.012820
[01:10:06.434] iteration 8330 : loss : 0.066540, loss_ce: 0.012012
[01:10:06.732] iteration 8331 : loss : 0.063063, loss_ce: 0.026806
[01:10:07.028] iteration 8332 : loss : 0.061545, loss_ce: 0.018397
[01:10:07.328] iteration 8333 : loss : 0.059153, loss_ce: 0.020596
[01:10:07.624] iteration 8334 : loss : 0.063114, loss_ce: 0.012402
[01:10:07.921] iteration 8335 : loss : 0.057879, loss_ce: 0.018598
[01:10:08.221] iteration 8336 : loss : 0.058978, loss_ce: 0.022467
[01:10:08.520] iteration 8337 : loss : 0.063094, loss_ce: 0.019384
[01:10:08.816] iteration 8338 : loss : 0.292453, loss_ce: 0.015014
[01:10:09.115] iteration 8339 : loss : 0.163071, loss_ce: 0.007583
[01:10:09.192] iteration 8340 : loss : 0.335556, loss_ce: 0.000087
[01:10:28.338] iteration 8341 : loss : 0.061670, loss_ce: 0.021764
[01:10:28.635] iteration 8342 : loss : 0.119259, loss_ce: 0.012973
[01:10:28.937] iteration 8343 : loss : 0.057793, loss_ce: 0.009422
[01:10:29.239] iteration 8344 : loss : 0.047682, loss_ce: 0.016832
[01:10:29.542] iteration 8345 : loss : 0.059519, loss_ce: 0.015460
[01:10:29.836] iteration 8346 : loss : 0.157819, loss_ce: 0.010172
[01:10:30.130] iteration 8347 : loss : 0.055509, loss_ce: 0.015324
[01:10:30.429] iteration 8348 : loss : 0.129597, loss_ce: 0.014386
[01:10:30.729] iteration 8349 : loss : 0.059786, loss_ce: 0.013690
[01:10:31.024] iteration 8350 : loss : 0.065977, loss_ce: 0.028222
[01:10:31.320] iteration 8351 : loss : 0.194672, loss_ce: 0.012014
[01:10:31.617] iteration 8352 : loss : 0.047028, loss_ce: 0.011227
[01:10:31.913] iteration 8353 : loss : 0.061631, loss_ce: 0.018383
[01:10:32.211] iteration 8354 : loss : 0.068595, loss_ce: 0.024810
[01:10:32.507] iteration 8355 : loss : 0.057503, loss_ce: 0.025787
[01:10:32.800] iteration 8356 : loss : 0.061649, loss_ce: 0.014859
[01:10:33.096] iteration 8357 : loss : 0.060940, loss_ce: 0.025955
[01:10:33.394] iteration 8358 : loss : 0.066461, loss_ce: 0.015908
[01:10:33.694] iteration 8359 : loss : 0.067170, loss_ce: 0.013346
[01:10:33.991] iteration 8360 : loss : 0.058784, loss_ce: 0.029673
[01:10:34.303] iteration 8361 : loss : 0.167705, loss_ce: 0.004661
[01:10:34.604] iteration 8362 : loss : 0.050122, loss_ce: 0.011097
[01:10:34.899] iteration 8363 : loss : 0.067978, loss_ce: 0.016659
[01:10:35.196] iteration 8364 : loss : 0.054485, loss_ce: 0.012036
[01:10:35.495] iteration 8365 : loss : 0.083294, loss_ce: 0.025380
[01:10:35.792] iteration 8366 : loss : 0.067614, loss_ce: 0.015367
[01:10:36.087] iteration 8367 : loss : 0.108410, loss_ce: 0.014867
[01:10:36.380] iteration 8368 : loss : 0.115366, loss_ce: 0.021617
[01:10:36.673] iteration 8369 : loss : 0.059542, loss_ce: 0.024741
[01:10:36.964] iteration 8370 : loss : 0.044812, loss_ce: 0.010308
[01:10:37.257] iteration 8371 : loss : 0.062577, loss_ce: 0.022260
[01:10:37.549] iteration 8372 : loss : 0.078513, loss_ce: 0.015062
[01:10:37.842] iteration 8373 : loss : 0.076951, loss_ce: 0.021233
[01:10:38.135] iteration 8374 : loss : 0.064003, loss_ce: 0.014624
[01:10:38.424] iteration 8375 : loss : 0.108792, loss_ce: 0.012218
[01:10:38.713] iteration 8376 : loss : 0.055520, loss_ce: 0.022205
[01:10:39.009] iteration 8377 : loss : 0.065090, loss_ce: 0.013215
[01:10:39.299] iteration 8378 : loss : 0.122458, loss_ce: 0.022280
[01:10:39.589] iteration 8379 : loss : 0.177672, loss_ce: 0.012755
[01:10:39.882] iteration 8380 : loss : 0.064609, loss_ce: 0.026353
[01:10:40.191] iteration 8381 : loss : 0.057442, loss_ce: 0.014442
[01:10:40.484] iteration 8382 : loss : 0.073678, loss_ce: 0.024175
[01:10:40.778] iteration 8383 : loss : 0.054649, loss_ce: 0.018540
[01:10:41.069] iteration 8384 : loss : 0.073875, loss_ce: 0.022172
[01:10:41.359] iteration 8385 : loss : 0.062343, loss_ce: 0.012019
[01:10:41.647] iteration 8386 : loss : 0.067203, loss_ce: 0.016875
[01:10:41.937] iteration 8387 : loss : 0.060067, loss_ce: 0.017556
[01:10:42.232] iteration 8388 : loss : 0.061476, loss_ce: 0.019129
[01:10:42.524] iteration 8389 : loss : 0.059248, loss_ce: 0.026949
[01:10:42.816] iteration 8390 : loss : 0.050565, loss_ce: 0.019531
[01:10:43.112] iteration 8391 : loss : 0.058468, loss_ce: 0.010984
[01:10:43.405] iteration 8392 : loss : 0.052408, loss_ce: 0.012705
[01:10:43.696] iteration 8393 : loss : 0.124878, loss_ce: 0.016014
[01:10:43.988] iteration 8394 : loss : 0.113929, loss_ce: 0.019806
[01:10:44.282] iteration 8395 : loss : 0.064815, loss_ce: 0.022740
[01:10:44.575] iteration 8396 : loss : 0.041490, loss_ce: 0.014395
[01:10:44.870] iteration 8397 : loss : 0.086517, loss_ce: 0.011223
[01:10:45.166] iteration 8398 : loss : 0.279008, loss_ce: 0.002623
[01:10:45.463] iteration 8399 : loss : 0.076743, loss_ce: 0.016300
[01:10:45.756] iteration 8400 : loss : 0.059430, loss_ce: 0.015359
[01:10:46.066] iteration 8401 : loss : 0.124991, loss_ce: 0.020473
[01:10:46.360] iteration 8402 : loss : 0.066687, loss_ce: 0.014001
[01:10:46.657] iteration 8403 : loss : 0.057856, loss_ce: 0.014867
[01:10:46.952] iteration 8404 : loss : 0.051067, loss_ce: 0.019099
[01:10:47.246] iteration 8405 : loss : 0.124346, loss_ce: 0.008886
[01:10:47.538] iteration 8406 : loss : 0.050948, loss_ce: 0.012553
[01:10:47.830] iteration 8407 : loss : 0.056123, loss_ce: 0.024439
[01:10:48.123] iteration 8408 : loss : 0.049193, loss_ce: 0.026057
[01:10:48.416] iteration 8409 : loss : 0.062385, loss_ce: 0.020961
[01:10:48.711] iteration 8410 : loss : 0.058536, loss_ce: 0.016674
[01:10:49.004] iteration 8411 : loss : 0.057012, loss_ce: 0.012521
[01:10:49.301] iteration 8412 : loss : 0.078175, loss_ce: 0.020685
[01:10:49.597] iteration 8413 : loss : 0.064438, loss_ce: 0.029616
[01:10:49.896] iteration 8414 : loss : 0.054432, loss_ce: 0.022020
[01:10:50.197] iteration 8415 : loss : 0.116125, loss_ce: 0.010605
[01:10:50.498] iteration 8416 : loss : 0.128093, loss_ce: 0.019236
[01:10:50.797] iteration 8417 : loss : 0.057302, loss_ce: 0.023418
[01:10:51.094] iteration 8418 : loss : 0.118739, loss_ce: 0.014227
[01:10:51.390] iteration 8419 : loss : 0.059412, loss_ce: 0.019410
[01:10:51.686] iteration 8420 : loss : 0.072189, loss_ce: 0.026844
[01:10:51.996] iteration 8421 : loss : 0.051066, loss_ce: 0.014909
[01:10:52.288] iteration 8422 : loss : 0.061555, loss_ce: 0.010619
[01:10:52.581] iteration 8423 : loss : 0.064167, loss_ce: 0.020708
[01:10:52.874] iteration 8424 : loss : 0.181082, loss_ce: 0.008269
[01:10:53.170] iteration 8425 : loss : 0.113045, loss_ce: 0.010003
[01:10:53.465] iteration 8426 : loss : 0.069406, loss_ce: 0.010723
[01:10:53.761] iteration 8427 : loss : 0.055323, loss_ce: 0.024066
[01:10:54.060] iteration 8428 : loss : 0.065829, loss_ce: 0.016831
[01:10:54.351] iteration 8429 : loss : 0.111105, loss_ce: 0.012862
[01:10:54.646] iteration 8430 : loss : 0.061672, loss_ce: 0.021055
[01:10:54.941] iteration 8431 : loss : 0.059814, loss_ce: 0.018540
[01:10:55.231] iteration 8432 : loss : 0.067260, loss_ce: 0.024489
[01:10:55.523] iteration 8433 : loss : 0.130506, loss_ce: 0.018205
[01:10:55.818] iteration 8434 : loss : 0.062439, loss_ce: 0.018512
[01:10:56.111] iteration 8435 : loss : 0.078331, loss_ce: 0.005446
[01:10:56.407] iteration 8436 : loss : 0.105214, loss_ce: 0.018889
[01:10:56.699] iteration 8437 : loss : 0.103648, loss_ce: 0.015522
[01:10:56.991] iteration 8438 : loss : 0.289346, loss_ce: 0.013533
[01:10:57.284] iteration 8439 : loss : 0.073683, loss_ce: 0.023120
[01:10:57.574] iteration 8440 : loss : 0.062506, loss_ce: 0.017669
[01:10:57.878] iteration 8441 : loss : 0.081257, loss_ce: 0.017643
[01:10:58.174] iteration 8442 : loss : 0.065363, loss_ce: 0.014095
[01:10:58.468] iteration 8443 : loss : 0.109770, loss_ce: 0.011470
[01:10:58.761] iteration 8444 : loss : 0.058669, loss_ce: 0.019851
[01:10:59.053] iteration 8445 : loss : 0.066070, loss_ce: 0.025864
[01:10:59.345] iteration 8446 : loss : 0.068750, loss_ce: 0.017213
[01:10:59.637] iteration 8447 : loss : 0.064053, loss_ce: 0.029215
[01:10:59.933] iteration 8448 : loss : 0.055222, loss_ce: 0.022417
[01:11:00.231] iteration 8449 : loss : 0.104081, loss_ce: 0.012297
[01:11:00.525] iteration 8450 : loss : 0.062896, loss_ce: 0.021193
[01:11:00.820] iteration 8451 : loss : 0.061499, loss_ce: 0.028233
[01:11:01.116] iteration 8452 : loss : 0.059225, loss_ce: 0.020480
[01:11:01.407] iteration 8453 : loss : 0.055763, loss_ce: 0.017340
[01:11:01.699] iteration 8454 : loss : 0.105248, loss_ce: 0.011368
[01:11:01.993] iteration 8455 : loss : 0.061761, loss_ce: 0.025881
[01:11:02.287] iteration 8456 : loss : 0.063615, loss_ce: 0.017242
[01:11:02.582] iteration 8457 : loss : 0.040710, loss_ce: 0.011135
[01:11:02.872] iteration 8458 : loss : 0.114422, loss_ce: 0.013801
[01:11:03.168] iteration 8459 : loss : 0.060235, loss_ce: 0.019838
[01:11:03.462] iteration 8460 : loss : 0.060807, loss_ce: 0.024560
[01:11:03.775] iteration 8461 : loss : 0.052635, loss_ce: 0.021382
[01:11:04.067] iteration 8462 : loss : 0.113542, loss_ce: 0.008074
[01:11:04.367] iteration 8463 : loss : 0.120924, loss_ce: 0.020132
[01:11:04.663] iteration 8464 : loss : 0.052386, loss_ce: 0.021591
[01:11:05.009] iteration 8465 : loss : 0.047039, loss_ce: 0.020228
[01:11:05.313] iteration 8466 : loss : 0.067470, loss_ce: 0.014752
[01:11:05.616] iteration 8467 : loss : 0.047165, loss_ce: 0.019945
[01:11:05.917] iteration 8468 : loss : 0.055916, loss_ce: 0.013804
[01:11:06.220] iteration 8469 : loss : 0.062724, loss_ce: 0.026683
[01:11:06.517] iteration 8470 : loss : 0.129729, loss_ce: 0.014078
[01:11:06.817] iteration 8471 : loss : 0.081134, loss_ce: 0.025027
[01:11:07.124] iteration 8472 : loss : 0.229055, loss_ce: 0.004823
[01:11:07.423] iteration 8473 : loss : 0.077382, loss_ce: 0.011908
[01:11:07.729] iteration 8474 : loss : 0.074814, loss_ce: 0.022824
[01:11:08.031] iteration 8475 : loss : 0.085567, loss_ce: 0.022174
[01:11:08.331] iteration 8476 : loss : 0.061974, loss_ce: 0.016071
[01:11:08.640] iteration 8477 : loss : 0.047697, loss_ce: 0.012759
[01:11:08.939] iteration 8478 : loss : 0.105038, loss_ce: 0.016858
[01:11:09.018] iteration 8479 : loss : 0.290612, loss_ce: 0.018186
[01:11:28.216] iteration 8480 : loss : 0.062788, loss_ce: 0.027392
[01:11:28.531] iteration 8481 : loss : 0.066026, loss_ce: 0.019833
[01:11:28.829] iteration 8482 : loss : 0.052406, loss_ce: 0.014831
[01:11:29.129] iteration 8483 : loss : 0.056451, loss_ce: 0.015568
[01:11:29.423] iteration 8484 : loss : 0.126199, loss_ce: 0.006325
[01:11:29.715] iteration 8485 : loss : 0.066561, loss_ce: 0.022975
[01:11:30.004] iteration 8486 : loss : 0.051423, loss_ce: 0.012854
[01:11:30.296] iteration 8487 : loss : 0.057781, loss_ce: 0.014303
[01:11:30.589] iteration 8488 : loss : 0.068408, loss_ce: 0.038657
[01:11:30.880] iteration 8489 : loss : 0.112375, loss_ce: 0.008197
[01:11:31.174] iteration 8490 : loss : 0.041029, loss_ce: 0.012886
[01:11:31.465] iteration 8491 : loss : 0.060216, loss_ce: 0.021058
[01:11:31.755] iteration 8492 : loss : 0.057573, loss_ce: 0.017626
[01:11:32.045] iteration 8493 : loss : 0.072477, loss_ce: 0.023017
[01:11:32.333] iteration 8494 : loss : 0.062803, loss_ce: 0.021835
[01:11:32.630] iteration 8495 : loss : 0.057028, loss_ce: 0.014833
[01:11:32.924] iteration 8496 : loss : 0.065571, loss_ce: 0.020165
[01:11:33.219] iteration 8497 : loss : 0.054769, loss_ce: 0.014140
[01:11:33.513] iteration 8498 : loss : 0.064467, loss_ce: 0.020755
[01:11:33.805] iteration 8499 : loss : 0.102305, loss_ce: 0.021168
[01:11:34.099] iteration 8500 : loss : 0.066446, loss_ce: 0.018809
[01:11:34.409] iteration 8501 : loss : 0.068522, loss_ce: 0.021533
[01:11:34.703] iteration 8502 : loss : 0.283164, loss_ce: 0.006625
[01:11:34.999] iteration 8503 : loss : 0.109945, loss_ce: 0.007941
[01:11:35.300] iteration 8504 : loss : 0.048166, loss_ce: 0.015731
[01:11:35.598] iteration 8505 : loss : 0.051895, loss_ce: 0.016148
[01:11:35.894] iteration 8506 : loss : 0.063610, loss_ce: 0.015335
[01:11:36.190] iteration 8507 : loss : 0.044037, loss_ce: 0.018621
[01:11:36.488] iteration 8508 : loss : 0.060880, loss_ce: 0.029149
[01:11:36.783] iteration 8509 : loss : 0.108769, loss_ce: 0.010772
[01:11:37.076] iteration 8510 : loss : 0.071412, loss_ce: 0.033907
[01:11:37.365] iteration 8511 : loss : 0.055040, loss_ce: 0.020605
[01:11:37.657] iteration 8512 : loss : 0.058184, loss_ce: 0.023934
[01:11:37.949] iteration 8513 : loss : 0.067974, loss_ce: 0.019568
[01:11:38.240] iteration 8514 : loss : 0.052461, loss_ce: 0.018709
[01:11:38.537] iteration 8515 : loss : 0.056914, loss_ce: 0.026061
[01:11:38.832] iteration 8516 : loss : 0.105289, loss_ce: 0.005542
[01:11:39.127] iteration 8517 : loss : 0.059030, loss_ce: 0.021788
[01:11:39.427] iteration 8518 : loss : 0.052692, loss_ce: 0.007183
[01:11:39.730] iteration 8519 : loss : 0.053488, loss_ce: 0.022196
[01:11:40.028] iteration 8520 : loss : 0.059746, loss_ce: 0.009651
[01:11:40.344] iteration 8521 : loss : 0.037811, loss_ce: 0.005352
[01:11:40.644] iteration 8522 : loss : 0.066405, loss_ce: 0.027509
[01:11:40.942] iteration 8523 : loss : 0.111660, loss_ce: 0.011697
[01:11:41.240] iteration 8524 : loss : 0.050575, loss_ce: 0.009772
[01:11:41.534] iteration 8525 : loss : 0.055152, loss_ce: 0.017174
[01:11:41.824] iteration 8526 : loss : 0.063986, loss_ce: 0.017476
[01:11:42.117] iteration 8527 : loss : 0.103995, loss_ce: 0.014162
[01:11:42.412] iteration 8528 : loss : 0.089565, loss_ce: 0.010301
[01:11:42.705] iteration 8529 : loss : 0.122088, loss_ce: 0.011163
[01:11:42.997] iteration 8530 : loss : 0.056662, loss_ce: 0.015190
[01:11:43.290] iteration 8531 : loss : 0.059755, loss_ce: 0.020129
[01:11:43.585] iteration 8532 : loss : 0.056923, loss_ce: 0.014265
[01:11:43.881] iteration 8533 : loss : 0.066472, loss_ce: 0.014443
[01:11:44.174] iteration 8534 : loss : 0.058616, loss_ce: 0.015009
[01:11:44.466] iteration 8535 : loss : 0.086187, loss_ce: 0.023302
[01:11:44.758] iteration 8536 : loss : 0.102793, loss_ce: 0.005587
[01:11:45.051] iteration 8537 : loss : 0.111938, loss_ce: 0.010918
[01:11:45.346] iteration 8538 : loss : 0.073417, loss_ce: 0.022543
[01:11:45.639] iteration 8539 : loss : 0.291578, loss_ce: 0.013650
[01:11:45.935] iteration 8540 : loss : 0.066188, loss_ce: 0.018554
[01:11:46.250] iteration 8541 : loss : 0.063063, loss_ce: 0.029602
[01:11:46.547] iteration 8542 : loss : 0.064663, loss_ce: 0.019140
[01:11:46.842] iteration 8543 : loss : 0.231326, loss_ce: 0.013744
[01:11:47.138] iteration 8544 : loss : 0.063152, loss_ce: 0.017216
[01:11:47.435] iteration 8545 : loss : 0.110150, loss_ce: 0.017487
[01:11:47.730] iteration 8546 : loss : 0.064998, loss_ce: 0.022803
[01:11:48.024] iteration 8547 : loss : 0.056876, loss_ce: 0.024994
[01:11:48.318] iteration 8548 : loss : 0.056107, loss_ce: 0.012847
[01:11:48.611] iteration 8549 : loss : 0.121686, loss_ce: 0.005464
[01:11:48.906] iteration 8550 : loss : 0.138315, loss_ce: 0.013169
[01:11:49.203] iteration 8551 : loss : 0.044341, loss_ce: 0.019820
[01:11:49.499] iteration 8552 : loss : 0.167154, loss_ce: 0.020349
[01:11:49.797] iteration 8553 : loss : 0.156117, loss_ce: 0.007469
[01:11:50.094] iteration 8554 : loss : 0.070193, loss_ce: 0.025678
[01:11:50.387] iteration 8555 : loss : 0.117162, loss_ce: 0.024329
[01:11:50.682] iteration 8556 : loss : 0.125549, loss_ce: 0.005173
[01:11:50.975] iteration 8557 : loss : 0.164789, loss_ce: 0.014368
[01:11:51.271] iteration 8558 : loss : 0.104889, loss_ce: 0.009936
[01:11:51.567] iteration 8559 : loss : 0.059339, loss_ce: 0.012798
[01:11:51.861] iteration 8560 : loss : 0.069639, loss_ce: 0.010199
[01:11:52.174] iteration 8561 : loss : 0.096691, loss_ce: 0.012572
[01:11:52.468] iteration 8562 : loss : 0.056024, loss_ce: 0.020103
[01:11:52.760] iteration 8563 : loss : 0.075324, loss_ce: 0.027060
[01:11:53.054] iteration 8564 : loss : 0.099332, loss_ce: 0.011852
[01:11:53.351] iteration 8565 : loss : 0.069407, loss_ce: 0.020819
[01:11:53.648] iteration 8566 : loss : 0.114016, loss_ce: 0.011655
[01:11:53.943] iteration 8567 : loss : 0.050497, loss_ce: 0.016395
[01:11:54.245] iteration 8568 : loss : 0.053753, loss_ce: 0.012235
[01:11:54.542] iteration 8569 : loss : 0.059856, loss_ce: 0.028070
[01:11:54.839] iteration 8570 : loss : 0.110403, loss_ce: 0.022640
[01:11:55.136] iteration 8571 : loss : 0.073080, loss_ce: 0.023612
[01:11:55.435] iteration 8572 : loss : 0.127013, loss_ce: 0.022237
[01:11:55.735] iteration 8573 : loss : 0.078941, loss_ce: 0.011867
[01:11:56.034] iteration 8574 : loss : 0.050258, loss_ce: 0.021175
[01:11:56.329] iteration 8575 : loss : 0.133880, loss_ce: 0.027511
[01:11:56.621] iteration 8576 : loss : 0.124300, loss_ce: 0.003895
[01:11:56.914] iteration 8577 : loss : 0.055337, loss_ce: 0.020556
[01:11:57.207] iteration 8578 : loss : 0.105376, loss_ce: 0.015659
[01:11:57.498] iteration 8579 : loss : 0.051687, loss_ce: 0.008090
[01:11:57.790] iteration 8580 : loss : 0.042848, loss_ce: 0.008054
[01:11:58.098] iteration 8581 : loss : 0.117733, loss_ce: 0.013733
[01:11:58.391] iteration 8582 : loss : 0.055516, loss_ce: 0.015393
[01:11:58.685] iteration 8583 : loss : 0.058938, loss_ce: 0.027011
[01:11:58.979] iteration 8584 : loss : 0.080361, loss_ce: 0.018699
[01:11:59.275] iteration 8585 : loss : 0.127378, loss_ce: 0.015447
[01:11:59.565] iteration 8586 : loss : 0.126156, loss_ce: 0.020052
[01:11:59.863] iteration 8587 : loss : 0.061746, loss_ce: 0.022987
[01:12:00.158] iteration 8588 : loss : 0.060602, loss_ce: 0.019868
[01:12:00.454] iteration 8589 : loss : 0.054240, loss_ce: 0.028118
[01:12:00.744] iteration 8590 : loss : 0.058868, loss_ce: 0.015146
[01:12:01.043] iteration 8591 : loss : 0.061727, loss_ce: 0.019735
[01:12:01.337] iteration 8592 : loss : 0.046656, loss_ce: 0.013200
[01:12:01.632] iteration 8593 : loss : 0.046523, loss_ce: 0.020719
[01:12:01.929] iteration 8594 : loss : 0.066878, loss_ce: 0.016672
[01:12:02.225] iteration 8595 : loss : 0.165832, loss_ce: 0.005152
[01:12:02.517] iteration 8596 : loss : 0.073027, loss_ce: 0.021821
[01:12:02.810] iteration 8597 : loss : 0.053508, loss_ce: 0.011780
[01:12:03.105] iteration 8598 : loss : 0.068880, loss_ce: 0.019777
[01:12:03.398] iteration 8599 : loss : 0.113101, loss_ce: 0.010228
[01:12:03.690] iteration 8600 : loss : 0.069465, loss_ce: 0.026562
[01:12:04.002] iteration 8601 : loss : 0.235495, loss_ce: 0.008901
[01:12:04.302] iteration 8602 : loss : 0.067692, loss_ce: 0.022328
[01:12:04.602] iteration 8603 : loss : 0.056622, loss_ce: 0.024190
[01:12:04.901] iteration 8604 : loss : 0.061275, loss_ce: 0.021583
[01:12:05.201] iteration 8605 : loss : 0.077115, loss_ce: 0.020742
[01:12:05.495] iteration 8606 : loss : 0.133830, loss_ce: 0.015836
[01:12:05.793] iteration 8607 : loss : 0.071772, loss_ce: 0.015574
[01:12:06.101] iteration 8608 : loss : 0.064573, loss_ce: 0.019658
[01:12:06.399] iteration 8609 : loss : 0.113954, loss_ce: 0.011455
[01:12:06.700] iteration 8610 : loss : 0.056295, loss_ce: 0.018873
[01:12:07.000] iteration 8611 : loss : 0.114278, loss_ce: 0.013854
[01:12:07.301] iteration 8612 : loss : 0.139349, loss_ce: 0.015665
[01:12:07.601] iteration 8613 : loss : 0.063333, loss_ce: 0.013881
[01:12:07.899] iteration 8614 : loss : 0.119000, loss_ce: 0.018437
[01:12:08.195] iteration 8615 : loss : 0.181865, loss_ce: 0.008880
[01:12:08.495] iteration 8616 : loss : 0.111371, loss_ce: 0.016261
[01:12:08.793] iteration 8617 : loss : 0.076345, loss_ce: 0.009443
[01:12:08.873] iteration 8618 : loss : 0.046604, loss_ce: 0.019792
[01:12:30.236] iteration 8619 : loss : 0.063489, loss_ce: 0.023864
[01:12:30.534] iteration 8620 : loss : 0.108161, loss_ce: 0.014018
[01:12:30.852] iteration 8621 : loss : 0.110932, loss_ce: 0.014237
[01:12:31.144] iteration 8622 : loss : 0.053539, loss_ce: 0.025279
[01:12:31.441] iteration 8623 : loss : 0.058792, loss_ce: 0.026002
[01:12:31.734] iteration 8624 : loss : 0.059470, loss_ce: 0.010664
[01:12:32.024] iteration 8625 : loss : 0.107502, loss_ce: 0.010859
[01:12:32.318] iteration 8626 : loss : 0.063911, loss_ce: 0.014189
[01:12:32.609] iteration 8627 : loss : 0.109832, loss_ce: 0.013644
[01:12:32.901] iteration 8628 : loss : 0.110960, loss_ce: 0.021355
[01:12:33.190] iteration 8629 : loss : 0.102252, loss_ce: 0.012681
[01:12:33.482] iteration 8630 : loss : 0.105005, loss_ce: 0.018075
[01:12:33.772] iteration 8631 : loss : 0.064608, loss_ce: 0.023083
[01:12:34.066] iteration 8632 : loss : 0.057274, loss_ce: 0.012524
[01:12:34.360] iteration 8633 : loss : 0.064599, loss_ce: 0.018742
[01:12:34.651] iteration 8634 : loss : 0.056529, loss_ce: 0.011715
[01:12:34.946] iteration 8635 : loss : 0.044823, loss_ce: 0.018976
[01:12:35.238] iteration 8636 : loss : 0.058780, loss_ce: 0.015481
[01:12:35.532] iteration 8637 : loss : 0.045062, loss_ce: 0.011415
[01:12:35.822] iteration 8638 : loss : 0.060553, loss_ce: 0.026674
[01:12:36.114] iteration 8639 : loss : 0.093365, loss_ce: 0.016553
[01:12:36.409] iteration 8640 : loss : 0.053035, loss_ce: 0.018087
[01:12:36.717] iteration 8641 : loss : 0.059736, loss_ce: 0.021214
[01:12:37.013] iteration 8642 : loss : 0.104852, loss_ce: 0.010983
[01:12:37.307] iteration 8643 : loss : 0.055528, loss_ce: 0.015090
[01:12:37.599] iteration 8644 : loss : 0.076335, loss_ce: 0.018695
[01:12:37.894] iteration 8645 : loss : 0.060051, loss_ce: 0.011932
[01:12:38.190] iteration 8646 : loss : 0.047685, loss_ce: 0.012182
[01:12:38.484] iteration 8647 : loss : 0.060524, loss_ce: 0.017035
[01:12:38.778] iteration 8648 : loss : 0.057844, loss_ce: 0.012856
[01:12:39.070] iteration 8649 : loss : 0.068149, loss_ce: 0.024947
[01:12:39.363] iteration 8650 : loss : 0.062229, loss_ce: 0.018572
[01:12:39.658] iteration 8651 : loss : 0.046323, loss_ce: 0.014778
[01:12:39.949] iteration 8652 : loss : 0.054306, loss_ce: 0.020581
[01:12:40.242] iteration 8653 : loss : 0.068141, loss_ce: 0.022683
[01:12:40.538] iteration 8654 : loss : 0.054209, loss_ce: 0.029267
[01:12:40.826] iteration 8655 : loss : 0.109549, loss_ce: 0.010382
[01:12:41.119] iteration 8656 : loss : 0.047319, loss_ce: 0.015052
[01:12:41.413] iteration 8657 : loss : 0.047035, loss_ce: 0.019746
[01:12:41.704] iteration 8658 : loss : 0.067511, loss_ce: 0.011636
[01:12:41.998] iteration 8659 : loss : 0.048218, loss_ce: 0.021486
[01:12:42.293] iteration 8660 : loss : 0.054263, loss_ce: 0.016434
[01:12:42.606] iteration 8661 : loss : 0.056865, loss_ce: 0.029683
[01:12:42.899] iteration 8662 : loss : 0.134709, loss_ce: 0.012478
[01:12:43.191] iteration 8663 : loss : 0.064021, loss_ce: 0.019725
[01:12:43.482] iteration 8664 : loss : 0.173268, loss_ce: 0.009098
[01:12:43.775] iteration 8665 : loss : 0.063318, loss_ce: 0.023535
[01:12:44.071] iteration 8666 : loss : 0.121414, loss_ce: 0.010362
[01:12:44.366] iteration 8667 : loss : 0.057685, loss_ce: 0.020328
[01:12:44.664] iteration 8668 : loss : 0.053852, loss_ce: 0.014884
[01:12:44.962] iteration 8669 : loss : 0.057569, loss_ce: 0.015623
[01:12:45.258] iteration 8670 : loss : 0.055893, loss_ce: 0.019385
[01:12:45.561] iteration 8671 : loss : 0.114734, loss_ce: 0.007478
[01:12:45.862] iteration 8672 : loss : 0.050721, loss_ce: 0.011558
[01:12:46.161] iteration 8673 : loss : 0.065025, loss_ce: 0.013689
[01:12:46.455] iteration 8674 : loss : 0.059484, loss_ce: 0.013688
[01:12:46.751] iteration 8675 : loss : 0.067565, loss_ce: 0.017751
[01:12:47.044] iteration 8676 : loss : 0.101517, loss_ce: 0.023475
[01:12:47.341] iteration 8677 : loss : 0.043363, loss_ce: 0.017556
[01:12:47.635] iteration 8678 : loss : 0.100045, loss_ce: 0.024999
[01:12:47.926] iteration 8679 : loss : 0.057247, loss_ce: 0.020722
[01:12:48.220] iteration 8680 : loss : 0.055082, loss_ce: 0.024899
[01:12:48.524] iteration 8681 : loss : 0.065258, loss_ce: 0.018919
[01:12:48.814] iteration 8682 : loss : 0.153858, loss_ce: 0.005792
[01:12:49.107] iteration 8683 : loss : 0.054761, loss_ce: 0.008210
[01:12:49.399] iteration 8684 : loss : 0.048718, loss_ce: 0.019201
[01:12:49.696] iteration 8685 : loss : 0.062175, loss_ce: 0.025385
[01:12:49.990] iteration 8686 : loss : 0.070120, loss_ce: 0.019433
[01:12:50.285] iteration 8687 : loss : 0.065296, loss_ce: 0.010900
[01:12:50.578] iteration 8688 : loss : 0.040649, loss_ce: 0.009006
[01:12:50.872] iteration 8689 : loss : 0.067339, loss_ce: 0.017127
[01:12:51.165] iteration 8690 : loss : 0.071193, loss_ce: 0.022405
[01:12:51.457] iteration 8691 : loss : 0.071555, loss_ce: 0.016097
[01:12:51.748] iteration 8692 : loss : 0.049833, loss_ce: 0.019943
[01:12:52.041] iteration 8693 : loss : 0.093613, loss_ce: 0.008895
[01:12:52.336] iteration 8694 : loss : 0.110696, loss_ce: 0.010895
[01:12:52.629] iteration 8695 : loss : 0.054655, loss_ce: 0.016822
[01:12:52.921] iteration 8696 : loss : 0.060475, loss_ce: 0.021267
[01:12:53.211] iteration 8697 : loss : 0.053345, loss_ce: 0.018125
[01:12:53.501] iteration 8698 : loss : 0.108956, loss_ce: 0.012909
[01:12:53.800] iteration 8699 : loss : 0.063789, loss_ce: 0.016503
[01:12:54.093] iteration 8700 : loss : 0.050364, loss_ce: 0.011558
[01:12:54.409] iteration 8701 : loss : 0.063004, loss_ce: 0.012047
[01:12:54.700] iteration 8702 : loss : 0.056352, loss_ce: 0.027240
[01:12:54.996] iteration 8703 : loss : 0.050622, loss_ce: 0.010005
[01:12:55.292] iteration 8704 : loss : 0.106037, loss_ce: 0.009883
[01:12:55.585] iteration 8705 : loss : 0.045654, loss_ce: 0.020106
[01:12:55.877] iteration 8706 : loss : 0.068068, loss_ce: 0.029937
[01:12:56.171] iteration 8707 : loss : 0.053330, loss_ce: 0.012038
[01:12:56.464] iteration 8708 : loss : 0.051094, loss_ce: 0.012992
[01:12:56.757] iteration 8709 : loss : 0.077491, loss_ce: 0.017519
[01:12:57.053] iteration 8710 : loss : 0.116894, loss_ce: 0.010263
[01:12:57.349] iteration 8711 : loss : 0.065663, loss_ce: 0.019489
[01:12:57.644] iteration 8712 : loss : 0.055348, loss_ce: 0.014524
[01:12:57.937] iteration 8713 : loss : 0.069942, loss_ce: 0.036603
[01:12:58.234] iteration 8714 : loss : 0.285435, loss_ce: 0.005518
[01:12:58.531] iteration 8715 : loss : 0.056165, loss_ce: 0.017109
[01:12:58.826] iteration 8716 : loss : 0.061848, loss_ce: 0.011282
[01:12:59.123] iteration 8717 : loss : 0.082438, loss_ce: 0.007977
[01:12:59.422] iteration 8718 : loss : 0.053202, loss_ce: 0.009593
[01:12:59.723] iteration 8719 : loss : 0.050317, loss_ce: 0.018604
[01:13:00.024] iteration 8720 : loss : 0.059380, loss_ce: 0.024084
[01:13:00.341] iteration 8721 : loss : 0.113786, loss_ce: 0.012787
[01:13:00.642] iteration 8722 : loss : 0.079539, loss_ce: 0.018527
[01:13:00.940] iteration 8723 : loss : 0.064495, loss_ce: 0.020038
[01:13:01.238] iteration 8724 : loss : 0.048661, loss_ce: 0.020750
[01:13:01.534] iteration 8725 : loss : 0.063968, loss_ce: 0.024738
[01:13:01.829] iteration 8726 : loss : 0.065916, loss_ce: 0.015360
[01:13:02.121] iteration 8727 : loss : 0.106804, loss_ce: 0.009331
[01:13:02.414] iteration 8728 : loss : 0.058904, loss_ce: 0.012456
[01:13:02.709] iteration 8729 : loss : 0.159481, loss_ce: 0.012653
[01:13:03.003] iteration 8730 : loss : 0.081755, loss_ce: 0.027213
[01:13:03.295] iteration 8731 : loss : 0.067777, loss_ce: 0.014626
[01:13:03.588] iteration 8732 : loss : 0.107466, loss_ce: 0.010374
[01:13:03.880] iteration 8733 : loss : 0.087637, loss_ce: 0.018555
[01:13:04.172] iteration 8734 : loss : 0.160052, loss_ce: 0.008143
[01:13:04.463] iteration 8735 : loss : 0.057212, loss_ce: 0.019103
[01:13:04.754] iteration 8736 : loss : 0.057422, loss_ce: 0.013914
[01:13:05.048] iteration 8737 : loss : 0.057505, loss_ce: 0.014292
[01:13:05.344] iteration 8738 : loss : 0.052994, loss_ce: 0.020381
[01:13:05.639] iteration 8739 : loss : 0.075426, loss_ce: 0.030323
[01:13:05.932] iteration 8740 : loss : 0.057478, loss_ce: 0.019114
[01:13:06.251] iteration 8741 : loss : 0.073432, loss_ce: 0.024240
[01:13:06.552] iteration 8742 : loss : 0.283712, loss_ce: 0.006551
[01:13:06.853] iteration 8743 : loss : 0.067663, loss_ce: 0.026153
[01:13:07.151] iteration 8744 : loss : 0.107040, loss_ce: 0.008982
[01:13:07.447] iteration 8745 : loss : 0.068344, loss_ce: 0.014592
[01:13:07.746] iteration 8746 : loss : 0.057511, loss_ce: 0.012018
[01:13:08.041] iteration 8747 : loss : 0.058972, loss_ce: 0.010076
[01:13:08.339] iteration 8748 : loss : 0.060994, loss_ce: 0.019708
[01:13:08.632] iteration 8749 : loss : 0.210375, loss_ce: 0.004127
[01:13:08.932] iteration 8750 : loss : 0.073188, loss_ce: 0.018123
[01:13:09.231] iteration 8751 : loss : 0.052956, loss_ce: 0.014149
[01:13:09.526] iteration 8752 : loss : 0.060769, loss_ce: 0.021970
[01:13:09.823] iteration 8753 : loss : 0.064621, loss_ce: 0.020572
[01:13:10.122] iteration 8754 : loss : 0.053540, loss_ce: 0.018944
[01:13:10.418] iteration 8755 : loss : 0.052537, loss_ce: 0.021603
[01:13:10.714] iteration 8756 : loss : 0.127126, loss_ce: 0.026102
[01:13:10.792] iteration 8757 : loss : 0.075623, loss_ce: 0.039458
[01:13:28.940] iteration 8758 : loss : 0.063744, loss_ce: 0.016275
[01:13:29.239] iteration 8759 : loss : 0.110254, loss_ce: 0.012575
[01:13:29.534] iteration 8760 : loss : 0.071840, loss_ce: 0.010320
[01:13:29.849] iteration 8761 : loss : 0.051696, loss_ce: 0.009816
[01:13:30.144] iteration 8762 : loss : 0.090124, loss_ce: 0.022209
[01:13:30.441] iteration 8763 : loss : 0.054079, loss_ce: 0.014834
[01:13:30.736] iteration 8764 : loss : 0.077669, loss_ce: 0.018123
[01:13:31.027] iteration 8765 : loss : 0.046765, loss_ce: 0.021459
[01:13:31.317] iteration 8766 : loss : 0.108753, loss_ce: 0.013400
[01:13:31.615] iteration 8767 : loss : 0.073658, loss_ce: 0.021741
[01:13:31.913] iteration 8768 : loss : 0.061889, loss_ce: 0.022137
[01:13:32.211] iteration 8769 : loss : 0.068440, loss_ce: 0.014263
[01:13:32.508] iteration 8770 : loss : 0.089601, loss_ce: 0.015108
[01:13:32.805] iteration 8771 : loss : 0.054577, loss_ce: 0.008321
[01:13:33.103] iteration 8772 : loss : 0.057002, loss_ce: 0.025248
[01:13:33.401] iteration 8773 : loss : 0.118395, loss_ce: 0.006032
[01:13:33.701] iteration 8774 : loss : 0.067605, loss_ce: 0.023762
[01:13:34.001] iteration 8775 : loss : 0.066266, loss_ce: 0.029452
[01:13:34.299] iteration 8776 : loss : 0.064481, loss_ce: 0.025730
[01:13:34.601] iteration 8777 : loss : 0.055402, loss_ce: 0.007683
[01:13:34.899] iteration 8778 : loss : 0.113978, loss_ce: 0.006101
[01:13:35.201] iteration 8779 : loss : 0.106290, loss_ce: 0.011637
[01:13:35.501] iteration 8780 : loss : 0.062848, loss_ce: 0.019618
[01:13:35.829] iteration 8781 : loss : 0.051961, loss_ce: 0.023290
[01:13:36.125] iteration 8782 : loss : 0.059367, loss_ce: 0.010931
[01:13:36.424] iteration 8783 : loss : 0.104488, loss_ce: 0.005614
[01:13:36.725] iteration 8784 : loss : 0.052261, loss_ce: 0.015221
[01:13:37.019] iteration 8785 : loss : 0.076213, loss_ce: 0.010055
[01:13:37.318] iteration 8786 : loss : 0.053760, loss_ce: 0.022652
[01:13:37.619] iteration 8787 : loss : 0.048604, loss_ce: 0.009551
[01:13:37.919] iteration 8788 : loss : 0.112754, loss_ce: 0.011847
[01:13:38.218] iteration 8789 : loss : 0.066795, loss_ce: 0.022241
[01:13:38.516] iteration 8790 : loss : 0.067729, loss_ce: 0.022779
[01:13:38.814] iteration 8791 : loss : 0.176097, loss_ce: 0.014137
[01:13:39.111] iteration 8792 : loss : 0.060731, loss_ce: 0.028706
[01:13:39.410] iteration 8793 : loss : 0.075893, loss_ce: 0.025815
[01:13:39.708] iteration 8794 : loss : 0.047587, loss_ce: 0.020588
[01:13:40.005] iteration 8795 : loss : 0.057865, loss_ce: 0.027709
[01:13:40.302] iteration 8796 : loss : 0.054192, loss_ce: 0.017187
[01:13:40.604] iteration 8797 : loss : 0.065812, loss_ce: 0.022187
[01:13:40.899] iteration 8798 : loss : 0.053423, loss_ce: 0.018925
[01:13:41.197] iteration 8799 : loss : 0.050535, loss_ce: 0.022738
[01:13:41.493] iteration 8800 : loss : 0.071990, loss_ce: 0.022593
[01:13:41.815] iteration 8801 : loss : 0.064105, loss_ce: 0.014497
[01:13:42.115] iteration 8802 : loss : 0.160571, loss_ce: 0.009010
[01:13:42.418] iteration 8803 : loss : 0.064989, loss_ce: 0.015676
[01:13:42.719] iteration 8804 : loss : 0.061675, loss_ce: 0.030535
[01:13:43.022] iteration 8805 : loss : 0.053713, loss_ce: 0.017005
[01:13:43.322] iteration 8806 : loss : 0.058135, loss_ce: 0.018398
[01:13:43.625] iteration 8807 : loss : 0.067322, loss_ce: 0.017752
[01:13:43.929] iteration 8808 : loss : 0.042780, loss_ce: 0.011366
[01:13:44.231] iteration 8809 : loss : 0.058829, loss_ce: 0.018481
[01:13:44.530] iteration 8810 : loss : 0.069378, loss_ce: 0.008373
[01:13:44.826] iteration 8811 : loss : 0.060810, loss_ce: 0.017909
[01:13:45.128] iteration 8812 : loss : 0.050337, loss_ce: 0.019353
[01:13:45.426] iteration 8813 : loss : 0.122557, loss_ce: 0.025695
[01:13:45.724] iteration 8814 : loss : 0.056705, loss_ce: 0.026126
[01:13:46.022] iteration 8815 : loss : 0.065288, loss_ce: 0.014477
[01:13:46.319] iteration 8816 : loss : 0.070413, loss_ce: 0.016829
[01:13:46.619] iteration 8817 : loss : 0.069915, loss_ce: 0.013834
[01:13:46.913] iteration 8818 : loss : 0.047149, loss_ce: 0.014534
[01:13:47.212] iteration 8819 : loss : 0.066559, loss_ce: 0.027836
[01:13:47.509] iteration 8820 : loss : 0.061111, loss_ce: 0.022301
[01:13:47.823] iteration 8821 : loss : 0.104089, loss_ce: 0.006549
[01:13:48.119] iteration 8822 : loss : 0.055427, loss_ce: 0.017690
[01:13:48.421] iteration 8823 : loss : 0.047054, loss_ce: 0.015858
[01:13:48.719] iteration 8824 : loss : 0.059876, loss_ce: 0.016952
[01:13:49.018] iteration 8825 : loss : 0.104909, loss_ce: 0.007781
[01:13:49.318] iteration 8826 : loss : 0.054781, loss_ce: 0.024605
[01:13:49.616] iteration 8827 : loss : 0.053910, loss_ce: 0.014041
[01:13:49.912] iteration 8828 : loss : 0.065671, loss_ce: 0.025546
[01:13:50.211] iteration 8829 : loss : 0.045571, loss_ce: 0.018077
[01:13:50.514] iteration 8830 : loss : 0.050650, loss_ce: 0.022784
[01:13:50.816] iteration 8831 : loss : 0.172403, loss_ce: 0.004823
[01:13:51.112] iteration 8832 : loss : 0.105291, loss_ce: 0.011239
[01:13:51.410] iteration 8833 : loss : 0.114750, loss_ce: 0.009317
[01:13:51.704] iteration 8834 : loss : 0.046653, loss_ce: 0.012820
[01:13:51.997] iteration 8835 : loss : 0.056494, loss_ce: 0.016855
[01:13:52.292] iteration 8836 : loss : 0.060172, loss_ce: 0.018038
[01:13:52.590] iteration 8837 : loss : 0.063077, loss_ce: 0.018133
[01:13:52.884] iteration 8838 : loss : 0.067094, loss_ce: 0.024362
[01:13:53.178] iteration 8839 : loss : 0.040435, loss_ce: 0.006713
[01:13:53.471] iteration 8840 : loss : 0.122083, loss_ce: 0.012193
[01:13:53.782] iteration 8841 : loss : 0.111250, loss_ce: 0.009558
[01:13:54.076] iteration 8842 : loss : 0.052911, loss_ce: 0.019237
[01:13:54.369] iteration 8843 : loss : 0.063925, loss_ce: 0.013479
[01:13:54.667] iteration 8844 : loss : 0.051402, loss_ce: 0.021560
[01:13:54.963] iteration 8845 : loss : 0.111030, loss_ce: 0.009269
[01:13:55.257] iteration 8846 : loss : 0.047821, loss_ce: 0.011208
[01:13:55.550] iteration 8847 : loss : 0.045908, loss_ce: 0.017339
[01:13:55.849] iteration 8848 : loss : 0.113889, loss_ce: 0.010342
[01:13:56.139] iteration 8849 : loss : 0.055101, loss_ce: 0.015184
[01:13:56.428] iteration 8850 : loss : 0.059686, loss_ce: 0.021186
[01:13:56.719] iteration 8851 : loss : 0.064135, loss_ce: 0.017446
[01:13:57.013] iteration 8852 : loss : 0.099487, loss_ce: 0.011894
[01:13:57.304] iteration 8853 : loss : 0.138673, loss_ce: 0.016062
[01:13:57.601] iteration 8854 : loss : 0.072270, loss_ce: 0.020891
[01:13:57.894] iteration 8855 : loss : 0.056066, loss_ce: 0.020126
[01:13:58.190] iteration 8856 : loss : 0.049032, loss_ce: 0.013128
[01:13:58.482] iteration 8857 : loss : 0.056934, loss_ce: 0.015744
[01:13:58.778] iteration 8858 : loss : 0.054177, loss_ce: 0.016510
[01:13:59.071] iteration 8859 : loss : 0.093431, loss_ce: 0.013187
[01:13:59.372] iteration 8860 : loss : 0.117147, loss_ce: 0.010624
[01:13:59.688] iteration 8861 : loss : 0.103668, loss_ce: 0.009741
[01:13:59.979] iteration 8862 : loss : 0.050261, loss_ce: 0.016349
[01:14:00.278] iteration 8863 : loss : 0.110574, loss_ce: 0.009390
[01:14:00.572] iteration 8864 : loss : 0.060363, loss_ce: 0.012963
[01:14:00.868] iteration 8865 : loss : 0.065457, loss_ce: 0.017210
[01:14:01.165] iteration 8866 : loss : 0.171574, loss_ce: 0.007452
[01:14:01.462] iteration 8867 : loss : 0.107145, loss_ce: 0.009841
[01:14:01.752] iteration 8868 : loss : 0.058899, loss_ce: 0.022018
[01:14:02.050] iteration 8869 : loss : 0.062095, loss_ce: 0.023291
[01:14:02.345] iteration 8870 : loss : 0.057824, loss_ce: 0.011124
[01:14:02.639] iteration 8871 : loss : 0.082124, loss_ce: 0.016931
[01:14:02.933] iteration 8872 : loss : 0.062633, loss_ce: 0.029779
[01:14:03.225] iteration 8873 : loss : 0.068062, loss_ce: 0.015785
[01:14:03.520] iteration 8874 : loss : 0.118239, loss_ce: 0.027841
[01:14:03.816] iteration 8875 : loss : 0.050286, loss_ce: 0.009657
[01:14:04.116] iteration 8876 : loss : 0.055306, loss_ce: 0.018859
[01:14:04.414] iteration 8877 : loss : 0.076317, loss_ce: 0.018789
[01:14:04.715] iteration 8878 : loss : 0.048821, loss_ce: 0.009491
[01:14:05.014] iteration 8879 : loss : 0.122840, loss_ce: 0.012107
[01:14:05.318] iteration 8880 : loss : 0.055756, loss_ce: 0.013130
[01:14:05.638] iteration 8881 : loss : 0.067085, loss_ce: 0.012560
[01:14:05.940] iteration 8882 : loss : 0.133533, loss_ce: 0.020363
[01:14:06.245] iteration 8883 : loss : 0.050016, loss_ce: 0.025263
[01:14:06.542] iteration 8884 : loss : 0.114643, loss_ce: 0.025189
[01:14:06.844] iteration 8885 : loss : 0.051782, loss_ce: 0.009970
[01:14:07.145] iteration 8886 : loss : 0.075106, loss_ce: 0.026760
[01:14:07.449] iteration 8887 : loss : 0.098876, loss_ce: 0.021676
[01:14:07.747] iteration 8888 : loss : 0.113972, loss_ce: 0.010461
[01:14:08.043] iteration 8889 : loss : 0.069222, loss_ce: 0.017090
[01:14:08.338] iteration 8890 : loss : 0.060595, loss_ce: 0.009447
[01:14:08.638] iteration 8891 : loss : 0.062105, loss_ce: 0.012176
[01:14:08.936] iteration 8892 : loss : 0.172348, loss_ce: 0.004302
[01:14:09.243] iteration 8893 : loss : 0.065814, loss_ce: 0.023817
[01:14:09.539] iteration 8894 : loss : 0.070894, loss_ce: 0.015125
[01:14:09.834] iteration 8895 : loss : 0.057126, loss_ce: 0.013919
[01:14:09.910] iteration 8896 : loss : 0.339501, loss_ce: 0.000099
[01:14:29.461] iteration 8897 : loss : 0.067375, loss_ce: 0.020111
[01:14:29.763] iteration 8898 : loss : 0.089226, loss_ce: 0.012804
[01:14:30.061] iteration 8899 : loss : 0.088661, loss_ce: 0.038356
[01:14:30.355] iteration 8900 : loss : 0.056782, loss_ce: 0.024843
[01:14:30.667] iteration 8901 : loss : 0.090200, loss_ce: 0.031032
[01:14:30.961] iteration 8902 : loss : 0.119766, loss_ce: 0.015013
[01:14:31.254] iteration 8903 : loss : 0.140445, loss_ce: 0.017394
[01:14:31.545] iteration 8904 : loss : 0.178603, loss_ce: 0.020583
[01:14:31.838] iteration 8905 : loss : 0.085744, loss_ce: 0.024710
[01:14:32.133] iteration 8906 : loss : 0.074582, loss_ce: 0.016769
[01:14:32.428] iteration 8907 : loss : 0.071830, loss_ce: 0.029486
[01:14:32.716] iteration 8908 : loss : 0.105114, loss_ce: 0.025864
[01:14:33.011] iteration 8909 : loss : 0.066297, loss_ce: 0.022329
[01:14:33.303] iteration 8910 : loss : 0.083727, loss_ce: 0.036800
[01:14:33.599] iteration 8911 : loss : 0.163428, loss_ce: 0.018788
[01:14:33.893] iteration 8912 : loss : 0.065055, loss_ce: 0.027478
[01:14:34.188] iteration 8913 : loss : 0.152301, loss_ce: 0.011714
[01:14:34.484] iteration 8914 : loss : 0.059330, loss_ce: 0.017711
[01:14:34.782] iteration 8915 : loss : 0.082604, loss_ce: 0.015845
[01:14:35.079] iteration 8916 : loss : 0.102412, loss_ce: 0.029925
[01:14:35.375] iteration 8917 : loss : 0.137378, loss_ce: 0.030052
[01:14:35.673] iteration 8918 : loss : 0.077219, loss_ce: 0.024170
[01:14:35.969] iteration 8919 : loss : 0.085372, loss_ce: 0.030849
[01:14:36.262] iteration 8920 : loss : 0.127725, loss_ce: 0.013701
[01:14:36.574] iteration 8921 : loss : 0.086048, loss_ce: 0.027833
[01:14:36.866] iteration 8922 : loss : 0.063476, loss_ce: 0.018919
[01:14:37.158] iteration 8923 : loss : 0.085860, loss_ce: 0.022568
[01:14:37.454] iteration 8924 : loss : 0.071824, loss_ce: 0.018006
[01:14:37.746] iteration 8925 : loss : 0.082919, loss_ce: 0.017589
[01:14:38.040] iteration 8926 : loss : 0.085683, loss_ce: 0.013195
[01:14:38.333] iteration 8927 : loss : 0.096292, loss_ce: 0.018026
[01:14:38.628] iteration 8928 : loss : 0.066704, loss_ce: 0.006663
[01:14:38.919] iteration 8929 : loss : 0.053121, loss_ce: 0.025508
[01:14:39.213] iteration 8930 : loss : 0.107919, loss_ce: 0.028789
[01:14:39.504] iteration 8931 : loss : 0.055622, loss_ce: 0.017606
[01:14:39.798] iteration 8932 : loss : 0.077821, loss_ce: 0.022694
[01:14:40.090] iteration 8933 : loss : 0.059674, loss_ce: 0.025637
[01:14:40.384] iteration 8934 : loss : 0.068525, loss_ce: 0.029600
[01:14:40.677] iteration 8935 : loss : 0.079223, loss_ce: 0.012170
[01:14:40.971] iteration 8936 : loss : 0.082658, loss_ce: 0.024433
[01:14:41.263] iteration 8937 : loss : 0.056766, loss_ce: 0.018683
[01:14:41.556] iteration 8938 : loss : 0.072434, loss_ce: 0.012298
[01:14:41.846] iteration 8939 : loss : 0.219051, loss_ce: 0.011146
[01:14:42.137] iteration 8940 : loss : 0.070191, loss_ce: 0.016127
[01:14:42.448] iteration 8941 : loss : 0.060004, loss_ce: 0.019030
[01:14:42.739] iteration 8942 : loss : 0.048037, loss_ce: 0.008927
[01:14:43.035] iteration 8943 : loss : 0.064807, loss_ce: 0.017588
[01:14:43.330] iteration 8944 : loss : 0.049053, loss_ce: 0.012379
[01:14:43.623] iteration 8945 : loss : 0.056547, loss_ce: 0.016711
[01:14:43.919] iteration 8946 : loss : 0.059096, loss_ce: 0.019731
[01:14:44.213] iteration 8947 : loss : 0.054845, loss_ce: 0.011824
[01:14:44.506] iteration 8948 : loss : 0.055510, loss_ce: 0.020584
[01:14:44.799] iteration 8949 : loss : 0.078985, loss_ce: 0.021123
[01:14:45.090] iteration 8950 : loss : 0.067428, loss_ce: 0.024075
[01:14:45.382] iteration 8951 : loss : 0.085438, loss_ce: 0.018768
[01:14:45.672] iteration 8952 : loss : 0.066771, loss_ce: 0.017057
[01:14:45.967] iteration 8953 : loss : 0.071065, loss_ce: 0.019513
[01:14:46.256] iteration 8954 : loss : 0.053556, loss_ce: 0.016919
[01:14:46.550] iteration 8955 : loss : 0.080245, loss_ce: 0.013008
[01:14:46.840] iteration 8956 : loss : 0.063258, loss_ce: 0.013441
[01:14:47.131] iteration 8957 : loss : 0.063640, loss_ce: 0.015842
[01:14:47.422] iteration 8958 : loss : 0.054395, loss_ce: 0.029581
[01:14:47.717] iteration 8959 : loss : 0.119152, loss_ce: 0.009243
[01:14:48.010] iteration 8960 : loss : 0.172590, loss_ce: 0.011901
[01:14:48.318] iteration 8961 : loss : 0.046550, loss_ce: 0.019621
[01:14:48.609] iteration 8962 : loss : 0.062083, loss_ce: 0.027725
[01:14:48.896] iteration 8963 : loss : 0.077941, loss_ce: 0.014535
[01:14:49.192] iteration 8964 : loss : 0.069637, loss_ce: 0.015756
[01:14:49.486] iteration 8965 : loss : 0.057904, loss_ce: 0.024604
[01:14:49.783] iteration 8966 : loss : 0.056942, loss_ce: 0.014948
[01:14:50.076] iteration 8967 : loss : 0.061603, loss_ce: 0.022067
[01:14:50.373] iteration 8968 : loss : 0.049721, loss_ce: 0.013624
[01:14:50.672] iteration 8969 : loss : 0.078503, loss_ce: 0.025578
[01:14:50.968] iteration 8970 : loss : 0.058191, loss_ce: 0.022853
[01:14:51.263] iteration 8971 : loss : 0.113254, loss_ce: 0.012370
[01:14:51.561] iteration 8972 : loss : 0.052770, loss_ce: 0.014713
[01:14:51.857] iteration 8973 : loss : 0.051424, loss_ce: 0.013724
[01:14:52.155] iteration 8974 : loss : 0.075282, loss_ce: 0.022981
[01:14:52.453] iteration 8975 : loss : 0.156084, loss_ce: 0.017643
[01:14:52.752] iteration 8976 : loss : 0.055169, loss_ce: 0.016293
[01:14:53.047] iteration 8977 : loss : 0.051234, loss_ce: 0.015096
[01:14:53.341] iteration 8978 : loss : 0.066604, loss_ce: 0.013260
[01:14:53.642] iteration 8979 : loss : 0.079157, loss_ce: 0.013193
[01:14:53.938] iteration 8980 : loss : 0.043984, loss_ce: 0.012644
[01:14:54.252] iteration 8981 : loss : 0.044548, loss_ce: 0.014915
[01:14:54.549] iteration 8982 : loss : 0.119595, loss_ce: 0.023894
[01:14:54.847] iteration 8983 : loss : 0.055196, loss_ce: 0.014015
[01:14:55.143] iteration 8984 : loss : 0.063704, loss_ce: 0.018362
[01:14:55.436] iteration 8985 : loss : 0.046013, loss_ce: 0.011827
[01:14:55.735] iteration 8986 : loss : 0.046058, loss_ce: 0.012299
[01:14:56.035] iteration 8987 : loss : 0.084398, loss_ce: 0.012113
[01:14:56.332] iteration 8988 : loss : 0.112161, loss_ce: 0.019604
[01:14:56.633] iteration 8989 : loss : 0.060144, loss_ce: 0.018824
[01:14:56.931] iteration 8990 : loss : 0.047750, loss_ce: 0.017078
[01:14:57.228] iteration 8991 : loss : 0.061601, loss_ce: 0.014558
[01:14:57.524] iteration 8992 : loss : 0.131133, loss_ce: 0.020340
[01:14:57.820] iteration 8993 : loss : 0.113599, loss_ce: 0.016899
[01:14:58.116] iteration 8994 : loss : 0.164645, loss_ce: 0.006668
[01:14:58.416] iteration 8995 : loss : 0.098520, loss_ce: 0.026815
[01:14:58.711] iteration 8996 : loss : 0.078208, loss_ce: 0.032257
[01:14:59.009] iteration 8997 : loss : 0.066351, loss_ce: 0.017580
[01:14:59.308] iteration 8998 : loss : 0.086019, loss_ce: 0.028076
[01:14:59.606] iteration 8999 : loss : 0.060591, loss_ce: 0.019842
[01:14:59.904] iteration 9000 : loss : 0.074704, loss_ce: 0.025404
[01:15:00.219] iteration 9001 : loss : 0.064794, loss_ce: 0.019945
[01:15:00.519] iteration 9002 : loss : 0.057557, loss_ce: 0.022048
[01:15:00.819] iteration 9003 : loss : 0.113201, loss_ce: 0.006713
[01:15:01.119] iteration 9004 : loss : 0.062934, loss_ce: 0.009141
[01:15:01.415] iteration 9005 : loss : 0.051122, loss_ce: 0.007561
[01:15:01.713] iteration 9006 : loss : 0.054790, loss_ce: 0.017241
[01:15:02.011] iteration 9007 : loss : 0.076279, loss_ce: 0.017630
[01:15:02.309] iteration 9008 : loss : 0.052144, loss_ce: 0.014660
[01:15:02.605] iteration 9009 : loss : 0.042924, loss_ce: 0.014971
[01:15:02.904] iteration 9010 : loss : 0.114131, loss_ce: 0.012888
[01:15:03.199] iteration 9011 : loss : 0.062565, loss_ce: 0.009525
[01:15:03.493] iteration 9012 : loss : 0.218462, loss_ce: 0.027988
[01:15:03.791] iteration 9013 : loss : 0.057548, loss_ce: 0.015475
[01:15:04.088] iteration 9014 : loss : 0.115155, loss_ce: 0.007170
[01:15:04.386] iteration 9015 : loss : 0.057409, loss_ce: 0.021265
[01:15:04.686] iteration 9016 : loss : 0.109526, loss_ce: 0.007874
[01:15:04.985] iteration 9017 : loss : 0.060352, loss_ce: 0.016109
[01:15:05.281] iteration 9018 : loss : 0.049171, loss_ce: 0.015416
[01:15:05.589] iteration 9019 : loss : 0.048626, loss_ce: 0.008783
[01:15:05.892] iteration 9020 : loss : 0.063380, loss_ce: 0.018906
[01:15:06.232] iteration 9021 : loss : 0.106509, loss_ce: 0.016313
[01:15:06.535] iteration 9022 : loss : 0.074771, loss_ce: 0.011525
[01:15:06.835] iteration 9023 : loss : 0.116288, loss_ce: 0.018494
[01:15:07.146] iteration 9024 : loss : 0.057010, loss_ce: 0.022419
[01:15:07.448] iteration 9025 : loss : 0.064951, loss_ce: 0.025972
[01:15:07.756] iteration 9026 : loss : 0.050734, loss_ce: 0.009018
[01:15:08.058] iteration 9027 : loss : 0.057552, loss_ce: 0.021956
[01:15:08.366] iteration 9028 : loss : 0.078418, loss_ce: 0.028916
[01:15:08.667] iteration 9029 : loss : 0.063393, loss_ce: 0.027175
[01:15:08.973] iteration 9030 : loss : 0.049453, loss_ce: 0.012629
[01:15:09.284] iteration 9031 : loss : 0.051760, loss_ce: 0.021801
[01:15:09.583] iteration 9032 : loss : 0.067730, loss_ce: 0.014653
[01:15:09.883] iteration 9033 : loss : 0.085205, loss_ce: 0.009711
[01:15:10.187] iteration 9034 : loss : 0.066151, loss_ce: 0.019129
[01:15:10.278] iteration 9035 : loss : 0.116427, loss_ce: 0.000026
[01:15:28.464] iteration 9036 : loss : 0.059077, loss_ce: 0.021871
[01:15:28.763] iteration 9037 : loss : 0.056341, loss_ce: 0.025656
[01:15:29.062] iteration 9038 : loss : 0.102828, loss_ce: 0.013990
[01:15:29.357] iteration 9039 : loss : 0.063291, loss_ce: 0.022830
[01:15:29.656] iteration 9040 : loss : 0.100201, loss_ce: 0.023835
[01:15:29.966] iteration 9041 : loss : 0.050917, loss_ce: 0.021028
[01:15:30.263] iteration 9042 : loss : 0.167885, loss_ce: 0.012346
[01:15:30.557] iteration 9043 : loss : 0.050939, loss_ce: 0.017378
[01:15:30.851] iteration 9044 : loss : 0.072723, loss_ce: 0.011617
[01:15:31.147] iteration 9045 : loss : 0.061711, loss_ce: 0.010754
[01:15:31.446] iteration 9046 : loss : 0.164864, loss_ce: 0.012591
[01:15:31.740] iteration 9047 : loss : 0.053962, loss_ce: 0.023882
[01:15:32.035] iteration 9048 : loss : 0.115669, loss_ce: 0.009368
[01:15:32.333] iteration 9049 : loss : 0.065137, loss_ce: 0.022133
[01:15:32.627] iteration 9050 : loss : 0.107899, loss_ce: 0.008169
[01:15:32.921] iteration 9051 : loss : 0.055535, loss_ce: 0.021538
[01:15:33.217] iteration 9052 : loss : 0.066455, loss_ce: 0.025193
[01:15:33.512] iteration 9053 : loss : 0.063531, loss_ce: 0.023907
[01:15:33.812] iteration 9054 : loss : 0.117171, loss_ce: 0.010883
[01:15:34.111] iteration 9055 : loss : 0.072447, loss_ce: 0.011214
[01:15:34.407] iteration 9056 : loss : 0.107096, loss_ce: 0.004648
[01:15:34.707] iteration 9057 : loss : 0.059953, loss_ce: 0.007897
[01:15:35.006] iteration 9058 : loss : 0.058881, loss_ce: 0.018964
[01:15:35.305] iteration 9059 : loss : 0.062617, loss_ce: 0.023553
[01:15:35.598] iteration 9060 : loss : 0.061075, loss_ce: 0.021707
[01:15:35.916] iteration 9061 : loss : 0.061621, loss_ce: 0.019160
[01:15:36.215] iteration 9062 : loss : 0.053767, loss_ce: 0.012580
[01:15:36.508] iteration 9063 : loss : 0.259102, loss_ce: 0.010658
[01:15:36.806] iteration 9064 : loss : 0.059416, loss_ce: 0.012768
[01:15:37.104] iteration 9065 : loss : 0.074437, loss_ce: 0.016853
[01:15:37.400] iteration 9066 : loss : 0.048744, loss_ce: 0.014860
[01:15:37.695] iteration 9067 : loss : 0.049286, loss_ce: 0.015069
[01:15:37.989] iteration 9068 : loss : 0.057386, loss_ce: 0.029479
[01:15:38.288] iteration 9069 : loss : 0.049981, loss_ce: 0.011634
[01:15:38.581] iteration 9070 : loss : 0.065050, loss_ce: 0.022924
[01:15:38.876] iteration 9071 : loss : 0.045822, loss_ce: 0.014707
[01:15:39.174] iteration 9072 : loss : 0.078583, loss_ce: 0.022340
[01:15:39.477] iteration 9073 : loss : 0.234669, loss_ce: 0.009006
[01:15:39.779] iteration 9074 : loss : 0.053101, loss_ce: 0.014907
[01:15:40.078] iteration 9075 : loss : 0.069185, loss_ce: 0.022756
[01:15:40.379] iteration 9076 : loss : 0.057404, loss_ce: 0.025839
[01:15:40.682] iteration 9077 : loss : 0.048417, loss_ce: 0.019488
[01:15:40.983] iteration 9078 : loss : 0.036603, loss_ce: 0.010944
[01:15:41.286] iteration 9079 : loss : 0.066822, loss_ce: 0.031851
[01:15:41.586] iteration 9080 : loss : 0.051191, loss_ce: 0.014264
[01:15:41.898] iteration 9081 : loss : 0.071017, loss_ce: 0.026031
[01:15:42.191] iteration 9082 : loss : 0.048554, loss_ce: 0.017790
[01:15:42.483] iteration 9083 : loss : 0.045238, loss_ce: 0.009782
[01:15:42.778] iteration 9084 : loss : 0.088512, loss_ce: 0.013585
[01:15:43.072] iteration 9085 : loss : 0.053752, loss_ce: 0.011189
[01:15:43.366] iteration 9086 : loss : 0.119450, loss_ce: 0.020387
[01:15:43.662] iteration 9087 : loss : 0.069299, loss_ce: 0.013109
[01:15:43.953] iteration 9088 : loss : 0.066551, loss_ce: 0.015412
[01:15:44.247] iteration 9089 : loss : 0.052356, loss_ce: 0.016722
[01:15:44.549] iteration 9090 : loss : 0.050708, loss_ce: 0.014483
[01:15:44.845] iteration 9091 : loss : 0.060495, loss_ce: 0.022755
[01:15:45.139] iteration 9092 : loss : 0.055321, loss_ce: 0.017638
[01:15:45.433] iteration 9093 : loss : 0.071096, loss_ce: 0.018265
[01:15:45.728] iteration 9094 : loss : 0.065083, loss_ce: 0.036843
[01:15:46.020] iteration 9095 : loss : 0.107120, loss_ce: 0.024848
[01:15:46.310] iteration 9096 : loss : 0.064445, loss_ce: 0.023306
[01:15:46.604] iteration 9097 : loss : 0.083566, loss_ce: 0.019923
[01:15:46.898] iteration 9098 : loss : 0.064864, loss_ce: 0.019465
[01:15:47.193] iteration 9099 : loss : 0.117246, loss_ce: 0.015825
[01:15:47.484] iteration 9100 : loss : 0.064503, loss_ce: 0.021636
[01:15:47.798] iteration 9101 : loss : 0.053954, loss_ce: 0.025537
[01:15:48.089] iteration 9102 : loss : 0.059989, loss_ce: 0.024074
[01:15:48.384] iteration 9103 : loss : 0.054392, loss_ce: 0.022418
[01:15:48.677] iteration 9104 : loss : 0.044397, loss_ce: 0.015688
[01:15:48.972] iteration 9105 : loss : 0.064888, loss_ce: 0.028830
[01:15:49.266] iteration 9106 : loss : 0.108481, loss_ce: 0.007078
[01:15:49.557] iteration 9107 : loss : 0.066572, loss_ce: 0.018930
[01:15:49.857] iteration 9108 : loss : 0.067460, loss_ce: 0.023188
[01:15:50.153] iteration 9109 : loss : 0.042717, loss_ce: 0.019275
[01:15:50.445] iteration 9110 : loss : 0.070316, loss_ce: 0.017317
[01:15:50.738] iteration 9111 : loss : 0.041829, loss_ce: 0.007780
[01:15:51.031] iteration 9112 : loss : 0.072477, loss_ce: 0.016467
[01:15:51.324] iteration 9113 : loss : 0.202510, loss_ce: 0.013129
[01:15:51.618] iteration 9114 : loss : 0.112416, loss_ce: 0.009078
[01:15:51.910] iteration 9115 : loss : 0.049114, loss_ce: 0.012727
[01:15:52.201] iteration 9116 : loss : 0.099797, loss_ce: 0.016107
[01:15:52.500] iteration 9117 : loss : 0.063272, loss_ce: 0.014404
[01:15:52.796] iteration 9118 : loss : 0.058014, loss_ce: 0.011806
[01:15:53.087] iteration 9119 : loss : 0.062838, loss_ce: 0.023714
[01:15:53.376] iteration 9120 : loss : 0.088840, loss_ce: 0.021126
[01:15:53.692] iteration 9121 : loss : 0.056690, loss_ce: 0.020892
[01:15:53.987] iteration 9122 : loss : 0.054412, loss_ce: 0.016716
[01:15:54.280] iteration 9123 : loss : 0.112815, loss_ce: 0.013286
[01:15:54.574] iteration 9124 : loss : 0.101697, loss_ce: 0.006878
[01:15:54.866] iteration 9125 : loss : 0.058240, loss_ce: 0.020236
[01:15:55.164] iteration 9126 : loss : 0.059101, loss_ce: 0.016134
[01:15:55.459] iteration 9127 : loss : 0.057131, loss_ce: 0.016338
[01:15:55.752] iteration 9128 : loss : 0.063970, loss_ce: 0.024025
[01:15:56.046] iteration 9129 : loss : 0.060130, loss_ce: 0.017170
[01:15:56.340] iteration 9130 : loss : 0.064498, loss_ce: 0.029105
[01:15:56.635] iteration 9131 : loss : 0.056218, loss_ce: 0.016080
[01:15:56.934] iteration 9132 : loss : 0.067102, loss_ce: 0.016343
[01:15:57.229] iteration 9133 : loss : 0.159216, loss_ce: 0.007385
[01:15:57.528] iteration 9134 : loss : 0.062379, loss_ce: 0.022318
[01:15:57.825] iteration 9135 : loss : 0.088431, loss_ce: 0.009360
[01:15:58.121] iteration 9136 : loss : 0.064730, loss_ce: 0.023305
[01:15:58.420] iteration 9137 : loss : 0.060525, loss_ce: 0.024971
[01:15:58.716] iteration 9138 : loss : 0.067644, loss_ce: 0.019237
[01:15:59.016] iteration 9139 : loss : 0.103461, loss_ce: 0.015015
[01:15:59.312] iteration 9140 : loss : 0.081111, loss_ce: 0.015168
[01:15:59.627] iteration 9141 : loss : 0.061046, loss_ce: 0.013013
[01:15:59.928] iteration 9142 : loss : 0.060684, loss_ce: 0.015605
[01:16:00.228] iteration 9143 : loss : 0.062037, loss_ce: 0.013630
[01:16:00.527] iteration 9144 : loss : 0.051306, loss_ce: 0.011955
[01:16:00.827] iteration 9145 : loss : 0.050489, loss_ce: 0.017442
[01:16:01.124] iteration 9146 : loss : 0.079365, loss_ce: 0.012529
[01:16:01.420] iteration 9147 : loss : 0.113687, loss_ce: 0.012724
[01:16:01.718] iteration 9148 : loss : 0.109603, loss_ce: 0.009609
[01:16:02.016] iteration 9149 : loss : 0.050581, loss_ce: 0.014670
[01:16:02.315] iteration 9150 : loss : 0.070939, loss_ce: 0.018966
[01:16:02.614] iteration 9151 : loss : 0.046509, loss_ce: 0.014860
[01:16:02.913] iteration 9152 : loss : 0.058177, loss_ce: 0.017034
[01:16:03.206] iteration 9153 : loss : 0.054875, loss_ce: 0.015150
[01:16:03.505] iteration 9154 : loss : 0.114073, loss_ce: 0.011525
[01:16:03.801] iteration 9155 : loss : 0.117643, loss_ce: 0.016697
[01:16:04.105] iteration 9156 : loss : 0.042924, loss_ce: 0.009203
[01:16:04.403] iteration 9157 : loss : 0.054758, loss_ce: 0.016348
[01:16:04.704] iteration 9158 : loss : 0.055656, loss_ce: 0.012935
[01:16:05.010] iteration 9159 : loss : 0.059322, loss_ce: 0.017262
[01:16:05.314] iteration 9160 : loss : 0.067845, loss_ce: 0.016338
[01:16:05.637] iteration 9161 : loss : 0.103691, loss_ce: 0.013456
[01:16:05.935] iteration 9162 : loss : 0.075454, loss_ce: 0.015649
[01:16:06.241] iteration 9163 : loss : 0.059538, loss_ce: 0.038764
[01:16:06.543] iteration 9164 : loss : 0.108657, loss_ce: 0.013932
[01:16:06.846] iteration 9165 : loss : 0.043368, loss_ce: 0.022582
[01:16:07.152] iteration 9166 : loss : 0.048155, loss_ce: 0.010211
[01:16:07.459] iteration 9167 : loss : 0.110702, loss_ce: 0.012764
[01:16:07.767] iteration 9168 : loss : 0.058003, loss_ce: 0.014576
[01:16:08.066] iteration 9169 : loss : 0.065520, loss_ce: 0.028407
[01:16:08.370] iteration 9170 : loss : 0.055235, loss_ce: 0.010267
[01:16:08.670] iteration 9171 : loss : 0.051140, loss_ce: 0.016209
[01:16:08.978] iteration 9172 : loss : 0.090095, loss_ce: 0.025198
[01:16:09.285] iteration 9173 : loss : 0.120931, loss_ce: 0.015036
[01:16:09.369] iteration 9174 : loss : 0.319730, loss_ce: 0.010234
[01:16:30.425] iteration 9175 : loss : 0.052425, loss_ce: 0.019152
[01:16:30.725] iteration 9176 : loss : 0.114995, loss_ce: 0.016190
[01:16:31.025] iteration 9177 : loss : 0.065535, loss_ce: 0.020708
[01:16:31.320] iteration 9178 : loss : 0.254578, loss_ce: 0.006993
[01:16:31.613] iteration 9179 : loss : 0.081484, loss_ce: 0.013973
[01:16:31.905] iteration 9180 : loss : 0.059327, loss_ce: 0.022231
[01:16:32.210] iteration 9181 : loss : 0.090591, loss_ce: 0.026400
[01:16:32.503] iteration 9182 : loss : 0.059330, loss_ce: 0.017383
[01:16:32.798] iteration 9183 : loss : 0.069451, loss_ce: 0.020456
[01:16:33.090] iteration 9184 : loss : 0.053095, loss_ce: 0.015808
[01:16:33.380] iteration 9185 : loss : 0.051622, loss_ce: 0.017869
[01:16:33.675] iteration 9186 : loss : 0.052848, loss_ce: 0.030245
[01:16:33.973] iteration 9187 : loss : 0.067471, loss_ce: 0.026660
[01:16:34.268] iteration 9188 : loss : 0.064018, loss_ce: 0.016806
[01:16:34.561] iteration 9189 : loss : 0.056559, loss_ce: 0.012976
[01:16:34.854] iteration 9190 : loss : 0.064497, loss_ce: 0.012584
[01:16:35.145] iteration 9191 : loss : 0.051560, loss_ce: 0.025587
[01:16:35.435] iteration 9192 : loss : 0.083927, loss_ce: 0.009324
[01:16:35.730] iteration 9193 : loss : 0.057202, loss_ce: 0.017766
[01:16:36.023] iteration 9194 : loss : 0.061901, loss_ce: 0.013390
[01:16:36.316] iteration 9195 : loss : 0.051217, loss_ce: 0.021321
[01:16:36.607] iteration 9196 : loss : 0.041421, loss_ce: 0.009085
[01:16:36.902] iteration 9197 : loss : 0.057763, loss_ce: 0.014320
[01:16:37.197] iteration 9198 : loss : 0.111121, loss_ce: 0.012439
[01:16:37.491] iteration 9199 : loss : 0.110850, loss_ce: 0.014629
[01:16:37.784] iteration 9200 : loss : 0.073151, loss_ce: 0.025077
[01:16:38.097] iteration 9201 : loss : 0.050733, loss_ce: 0.014400
[01:16:38.388] iteration 9202 : loss : 0.047902, loss_ce: 0.018501
[01:16:38.680] iteration 9203 : loss : 0.061444, loss_ce: 0.011180
[01:16:38.976] iteration 9204 : loss : 0.046527, loss_ce: 0.014919
[01:16:39.271] iteration 9205 : loss : 0.110202, loss_ce: 0.013077
[01:16:39.567] iteration 9206 : loss : 0.065384, loss_ce: 0.006381
[01:16:39.858] iteration 9207 : loss : 0.064502, loss_ce: 0.013763
[01:16:40.148] iteration 9208 : loss : 0.065057, loss_ce: 0.015476
[01:16:40.437] iteration 9209 : loss : 0.090837, loss_ce: 0.008729
[01:16:40.733] iteration 9210 : loss : 0.046462, loss_ce: 0.012603
[01:16:41.023] iteration 9211 : loss : 0.060681, loss_ce: 0.022085
[01:16:41.316] iteration 9212 : loss : 0.059393, loss_ce: 0.031228
[01:16:41.610] iteration 9213 : loss : 0.059772, loss_ce: 0.031264
[01:16:41.901] iteration 9214 : loss : 0.065887, loss_ce: 0.024297
[01:16:42.194] iteration 9215 : loss : 0.110105, loss_ce: 0.018054
[01:16:42.488] iteration 9216 : loss : 0.057275, loss_ce: 0.011630
[01:16:42.782] iteration 9217 : loss : 0.055151, loss_ce: 0.020300
[01:16:43.077] iteration 9218 : loss : 0.057381, loss_ce: 0.010842
[01:16:43.368] iteration 9219 : loss : 0.068692, loss_ce: 0.016767
[01:16:43.660] iteration 9220 : loss : 0.053221, loss_ce: 0.019341
[01:16:43.972] iteration 9221 : loss : 0.138427, loss_ce: 0.013932
[01:16:44.268] iteration 9222 : loss : 0.111404, loss_ce: 0.010435
[01:16:44.562] iteration 9223 : loss : 0.043701, loss_ce: 0.020043
[01:16:44.857] iteration 9224 : loss : 0.054237, loss_ce: 0.018522
[01:16:45.151] iteration 9225 : loss : 0.066048, loss_ce: 0.015187
[01:16:45.447] iteration 9226 : loss : 0.085610, loss_ce: 0.015002
[01:16:45.749] iteration 9227 : loss : 0.115853, loss_ce: 0.010160
[01:16:46.042] iteration 9228 : loss : 0.071445, loss_ce: 0.018282
[01:16:46.339] iteration 9229 : loss : 0.039603, loss_ce: 0.009119
[01:16:46.635] iteration 9230 : loss : 0.054863, loss_ce: 0.014843
[01:16:46.932] iteration 9231 : loss : 0.060412, loss_ce: 0.022880
[01:16:47.229] iteration 9232 : loss : 0.061188, loss_ce: 0.018164
[01:16:47.526] iteration 9233 : loss : 0.064706, loss_ce: 0.021210
[01:16:47.828] iteration 9234 : loss : 0.109059, loss_ce: 0.014584
[01:16:48.124] iteration 9235 : loss : 0.048576, loss_ce: 0.022613
[01:16:48.421] iteration 9236 : loss : 0.073043, loss_ce: 0.014022
[01:16:48.714] iteration 9237 : loss : 0.064285, loss_ce: 0.013077
[01:16:49.011] iteration 9238 : loss : 0.113428, loss_ce: 0.009837
[01:16:49.307] iteration 9239 : loss : 0.119054, loss_ce: 0.017561
[01:16:49.602] iteration 9240 : loss : 0.062371, loss_ce: 0.023261
[01:16:49.916] iteration 9241 : loss : 0.067223, loss_ce: 0.029384
[01:16:50.210] iteration 9242 : loss : 0.062005, loss_ce: 0.012750
[01:16:50.510] iteration 9243 : loss : 0.102343, loss_ce: 0.014672
[01:16:50.808] iteration 9244 : loss : 0.052098, loss_ce: 0.016273
[01:16:51.105] iteration 9245 : loss : 0.067853, loss_ce: 0.018156
[01:16:51.407] iteration 9246 : loss : 0.058695, loss_ce: 0.019223
[01:16:51.705] iteration 9247 : loss : 0.138044, loss_ce: 0.013993
[01:16:52.002] iteration 9248 : loss : 0.123856, loss_ce: 0.019762
[01:16:52.297] iteration 9249 : loss : 0.048290, loss_ce: 0.017815
[01:16:52.594] iteration 9250 : loss : 0.060265, loss_ce: 0.011324
[01:16:52.888] iteration 9251 : loss : 0.053424, loss_ce: 0.019975
[01:16:53.183] iteration 9252 : loss : 0.051400, loss_ce: 0.014555
[01:16:53.485] iteration 9253 : loss : 0.073008, loss_ce: 0.011500
[01:16:53.782] iteration 9254 : loss : 0.066429, loss_ce: 0.017886
[01:16:54.077] iteration 9255 : loss : 0.063669, loss_ce: 0.025749
[01:16:54.378] iteration 9256 : loss : 0.070212, loss_ce: 0.018201
[01:16:54.672] iteration 9257 : loss : 0.056345, loss_ce: 0.027626
[01:16:54.970] iteration 9258 : loss : 0.061946, loss_ce: 0.030880
[01:16:55.268] iteration 9259 : loss : 0.053492, loss_ce: 0.012355
[01:16:55.567] iteration 9260 : loss : 0.123812, loss_ce: 0.007058
[01:16:55.881] iteration 9261 : loss : 0.104354, loss_ce: 0.009511
[01:16:56.178] iteration 9262 : loss : 0.099110, loss_ce: 0.008104
[01:16:56.476] iteration 9263 : loss : 0.048424, loss_ce: 0.014159
[01:16:56.771] iteration 9264 : loss : 0.054405, loss_ce: 0.007332
[01:16:57.070] iteration 9265 : loss : 0.057419, loss_ce: 0.016450
[01:16:57.366] iteration 9266 : loss : 0.058654, loss_ce: 0.013305
[01:16:57.662] iteration 9267 : loss : 0.051556, loss_ce: 0.020759
[01:16:57.961] iteration 9268 : loss : 0.061005, loss_ce: 0.025924
[01:16:58.255] iteration 9269 : loss : 0.169249, loss_ce: 0.011740
[01:16:58.556] iteration 9270 : loss : 0.063357, loss_ce: 0.022074
[01:16:58.851] iteration 9271 : loss : 0.164649, loss_ce: 0.004257
[01:16:59.148] iteration 9272 : loss : 0.061384, loss_ce: 0.015522
[01:16:59.447] iteration 9273 : loss : 0.039662, loss_ce: 0.012335
[01:16:59.747] iteration 9274 : loss : 0.124520, loss_ce: 0.013084
[01:17:00.047] iteration 9275 : loss : 0.055311, loss_ce: 0.019689
[01:17:00.344] iteration 9276 : loss : 0.041515, loss_ce: 0.014796
[01:17:00.643] iteration 9277 : loss : 0.059460, loss_ce: 0.016833
[01:17:00.942] iteration 9278 : loss : 0.086585, loss_ce: 0.011534
[01:17:01.240] iteration 9279 : loss : 0.065137, loss_ce: 0.018690
[01:17:01.538] iteration 9280 : loss : 0.061644, loss_ce: 0.014922
[01:17:01.854] iteration 9281 : loss : 0.046912, loss_ce: 0.013765
[01:17:02.148] iteration 9282 : loss : 0.066089, loss_ce: 0.011101
[01:17:02.449] iteration 9283 : loss : 0.060321, loss_ce: 0.011375
[01:17:02.745] iteration 9284 : loss : 0.046701, loss_ce: 0.015674
[01:17:03.044] iteration 9285 : loss : 0.061017, loss_ce: 0.029156
[01:17:03.344] iteration 9286 : loss : 0.045118, loss_ce: 0.013574
[01:17:03.644] iteration 9287 : loss : 0.119226, loss_ce: 0.013855
[01:17:03.939] iteration 9288 : loss : 0.068232, loss_ce: 0.021726
[01:17:04.239] iteration 9289 : loss : 0.110723, loss_ce: 0.009115
[01:17:04.541] iteration 9290 : loss : 0.069762, loss_ce: 0.016581
[01:17:04.839] iteration 9291 : loss : 0.047671, loss_ce: 0.016556
[01:17:05.142] iteration 9292 : loss : 0.056050, loss_ce: 0.016265
[01:17:05.440] iteration 9293 : loss : 0.107245, loss_ce: 0.012252
[01:17:05.738] iteration 9294 : loss : 0.051678, loss_ce: 0.012335
[01:17:06.035] iteration 9295 : loss : 0.076843, loss_ce: 0.010426
[01:17:06.325] iteration 9296 : loss : 0.066986, loss_ce: 0.021342
[01:17:06.625] iteration 9297 : loss : 0.057990, loss_ce: 0.030334
[01:17:06.924] iteration 9298 : loss : 0.068993, loss_ce: 0.021695
[01:17:07.222] iteration 9299 : loss : 0.062462, loss_ce: 0.011912
[01:17:07.524] iteration 9300 : loss : 0.070566, loss_ce: 0.017361
[01:17:07.848] iteration 9301 : loss : 0.070379, loss_ce: 0.020479
[01:17:08.146] iteration 9302 : loss : 0.110907, loss_ce: 0.013309
[01:17:08.443] iteration 9303 : loss : 0.108527, loss_ce: 0.009340
[01:17:08.744] iteration 9304 : loss : 0.050591, loss_ce: 0.018083
[01:17:09.044] iteration 9305 : loss : 0.079095, loss_ce: 0.029037
[01:17:09.346] iteration 9306 : loss : 0.060519, loss_ce: 0.020181
[01:17:09.643] iteration 9307 : loss : 0.049270, loss_ce: 0.017300
[01:17:09.943] iteration 9308 : loss : 0.054848, loss_ce: 0.011497
[01:17:10.239] iteration 9309 : loss : 0.057054, loss_ce: 0.019016
[01:17:10.536] iteration 9310 : loss : 0.177861, loss_ce: 0.012231
[01:17:10.832] iteration 9311 : loss : 0.059398, loss_ce: 0.025182
[01:17:11.130] iteration 9312 : loss : 0.059849, loss_ce: 0.019052
[01:17:11.205] iteration 9313 : loss : 0.054496, loss_ce: 0.027500
[01:17:30.495] iteration 9314 : loss : 0.044914, loss_ce: 0.008426
[01:17:30.787] iteration 9315 : loss : 0.066919, loss_ce: 0.023783
[01:17:31.089] iteration 9316 : loss : 0.061886, loss_ce: 0.021436
[01:17:31.380] iteration 9317 : loss : 0.040758, loss_ce: 0.017112
[01:17:31.669] iteration 9318 : loss : 0.055706, loss_ce: 0.019492
[01:17:31.960] iteration 9319 : loss : 0.288221, loss_ce: 0.008485
[01:17:32.251] iteration 9320 : loss : 0.057781, loss_ce: 0.017039
[01:17:32.562] iteration 9321 : loss : 0.048361, loss_ce: 0.009517
[01:17:32.857] iteration 9322 : loss : 0.060473, loss_ce: 0.021280
[01:17:33.153] iteration 9323 : loss : 0.056711, loss_ce: 0.018118
[01:17:33.448] iteration 9324 : loss : 0.050794, loss_ce: 0.025122
[01:17:33.739] iteration 9325 : loss : 0.066335, loss_ce: 0.029650
[01:17:34.034] iteration 9326 : loss : 0.108394, loss_ce: 0.012595
[01:17:34.327] iteration 9327 : loss : 0.049234, loss_ce: 0.009823
[01:17:34.623] iteration 9328 : loss : 0.075125, loss_ce: 0.020915
[01:17:34.918] iteration 9329 : loss : 0.056982, loss_ce: 0.019512
[01:17:35.212] iteration 9330 : loss : 0.066741, loss_ce: 0.009155
[01:17:35.510] iteration 9331 : loss : 0.054431, loss_ce: 0.012383
[01:17:35.803] iteration 9332 : loss : 0.055036, loss_ce: 0.013513
[01:17:36.099] iteration 9333 : loss : 0.052126, loss_ce: 0.018201
[01:17:36.393] iteration 9334 : loss : 0.060887, loss_ce: 0.018248
[01:17:36.686] iteration 9335 : loss : 0.052338, loss_ce: 0.011473
[01:17:36.991] iteration 9336 : loss : 0.056819, loss_ce: 0.019767
[01:17:37.291] iteration 9337 : loss : 0.114505, loss_ce: 0.007038
[01:17:37.589] iteration 9338 : loss : 0.099831, loss_ce: 0.032035
[01:17:37.890] iteration 9339 : loss : 0.065102, loss_ce: 0.017080
[01:17:38.185] iteration 9340 : loss : 0.050876, loss_ce: 0.014204
[01:17:38.499] iteration 9341 : loss : 0.059519, loss_ce: 0.006783
[01:17:38.801] iteration 9342 : loss : 0.043944, loss_ce: 0.017316
[01:17:39.099] iteration 9343 : loss : 0.064107, loss_ce: 0.013247
[01:17:39.398] iteration 9344 : loss : 0.171802, loss_ce: 0.012134
[01:17:39.696] iteration 9345 : loss : 0.051531, loss_ce: 0.016596
[01:17:39.996] iteration 9346 : loss : 0.106462, loss_ce: 0.011269
[01:17:40.296] iteration 9347 : loss : 0.119776, loss_ce: 0.023480
[01:17:40.594] iteration 9348 : loss : 0.057645, loss_ce: 0.021799
[01:17:40.891] iteration 9349 : loss : 0.059562, loss_ce: 0.014363
[01:17:41.188] iteration 9350 : loss : 0.055621, loss_ce: 0.014851
[01:17:41.490] iteration 9351 : loss : 0.052581, loss_ce: 0.013314
[01:17:41.788] iteration 9352 : loss : 0.097082, loss_ce: 0.020230
[01:17:42.085] iteration 9353 : loss : 0.057022, loss_ce: 0.024686
[01:17:42.385] iteration 9354 : loss : 0.036191, loss_ce: 0.005462
[01:17:42.686] iteration 9355 : loss : 0.050646, loss_ce: 0.009270
[01:17:42.983] iteration 9356 : loss : 0.111932, loss_ce: 0.013805
[01:17:43.281] iteration 9357 : loss : 0.051227, loss_ce: 0.017214
[01:17:43.579] iteration 9358 : loss : 0.118692, loss_ce: 0.016905
[01:17:43.881] iteration 9359 : loss : 0.056398, loss_ce: 0.012195
[01:17:44.185] iteration 9360 : loss : 0.078918, loss_ce: 0.018045
[01:17:44.503] iteration 9361 : loss : 0.052327, loss_ce: 0.019798
[01:17:44.802] iteration 9362 : loss : 0.051320, loss_ce: 0.012692
[01:17:45.102] iteration 9363 : loss : 0.085986, loss_ce: 0.019779
[01:17:45.398] iteration 9364 : loss : 0.116923, loss_ce: 0.007203
[01:17:45.696] iteration 9365 : loss : 0.054009, loss_ce: 0.012496
[01:17:45.995] iteration 9366 : loss : 0.059895, loss_ce: 0.034507
[01:17:46.292] iteration 9367 : loss : 0.054580, loss_ce: 0.029742
[01:17:46.589] iteration 9368 : loss : 0.058743, loss_ce: 0.019538
[01:17:46.886] iteration 9369 : loss : 0.225122, loss_ce: 0.015794
[01:17:47.182] iteration 9370 : loss : 0.046611, loss_ce: 0.011714
[01:17:47.478] iteration 9371 : loss : 0.081465, loss_ce: 0.022820
[01:17:47.775] iteration 9372 : loss : 0.072213, loss_ce: 0.022558
[01:17:48.075] iteration 9373 : loss : 0.106634, loss_ce: 0.015233
[01:17:48.369] iteration 9374 : loss : 0.056413, loss_ce: 0.010623
[01:17:48.672] iteration 9375 : loss : 0.111765, loss_ce: 0.009520
[01:17:48.968] iteration 9376 : loss : 0.117682, loss_ce: 0.015664
[01:17:49.264] iteration 9377 : loss : 0.054953, loss_ce: 0.014955
[01:17:49.562] iteration 9378 : loss : 0.087821, loss_ce: 0.009523
[01:17:49.859] iteration 9379 : loss : 0.067523, loss_ce: 0.013776
[01:17:50.164] iteration 9380 : loss : 0.059578, loss_ce: 0.020267
[01:17:50.487] iteration 9381 : loss : 0.066782, loss_ce: 0.020385
[01:17:50.785] iteration 9382 : loss : 0.136099, loss_ce: 0.009918
[01:17:51.087] iteration 9383 : loss : 0.124012, loss_ce: 0.014719
[01:17:51.383] iteration 9384 : loss : 0.054474, loss_ce: 0.020959
[01:17:51.681] iteration 9385 : loss : 0.060744, loss_ce: 0.013370
[01:17:51.982] iteration 9386 : loss : 0.050241, loss_ce: 0.014278
[01:17:52.280] iteration 9387 : loss : 0.045705, loss_ce: 0.009787
[01:17:52.578] iteration 9388 : loss : 0.063539, loss_ce: 0.036509
[01:17:52.878] iteration 9389 : loss : 0.113209, loss_ce: 0.005451
[01:17:53.174] iteration 9390 : loss : 0.072473, loss_ce: 0.010631
[01:17:53.471] iteration 9391 : loss : 0.054732, loss_ce: 0.015637
[01:17:53.768] iteration 9392 : loss : 0.073991, loss_ce: 0.014270
[01:17:54.069] iteration 9393 : loss : 0.066131, loss_ce: 0.010038
[01:17:54.366] iteration 9394 : loss : 0.072593, loss_ce: 0.016155
[01:17:54.665] iteration 9395 : loss : 0.061408, loss_ce: 0.009546
[01:17:54.967] iteration 9396 : loss : 0.110976, loss_ce: 0.009053
[01:17:55.266] iteration 9397 : loss : 0.053196, loss_ce: 0.014142
[01:17:55.563] iteration 9398 : loss : 0.058021, loss_ce: 0.018521
[01:17:55.861] iteration 9399 : loss : 0.068432, loss_ce: 0.013425
[01:17:56.159] iteration 9400 : loss : 0.060907, loss_ce: 0.019811
[01:17:56.471] iteration 9401 : loss : 0.047537, loss_ce: 0.016965
[01:17:56.765] iteration 9402 : loss : 0.047518, loss_ce: 0.020547
[01:17:57.057] iteration 9403 : loss : 0.066899, loss_ce: 0.019116
[01:17:57.350] iteration 9404 : loss : 0.060805, loss_ce: 0.031608
[01:17:57.647] iteration 9405 : loss : 0.063270, loss_ce: 0.018390
[01:17:57.942] iteration 9406 : loss : 0.067352, loss_ce: 0.011157
[01:17:58.236] iteration 9407 : loss : 0.076080, loss_ce: 0.020475
[01:17:58.531] iteration 9408 : loss : 0.061143, loss_ce: 0.019633
[01:17:58.828] iteration 9409 : loss : 0.069671, loss_ce: 0.023307
[01:17:59.124] iteration 9410 : loss : 0.052848, loss_ce: 0.013068
[01:17:59.415] iteration 9411 : loss : 0.162985, loss_ce: 0.009019
[01:17:59.707] iteration 9412 : loss : 0.089597, loss_ce: 0.013027
[01:18:00.001] iteration 9413 : loss : 0.046200, loss_ce: 0.025800
[01:18:00.296] iteration 9414 : loss : 0.112789, loss_ce: 0.013757
[01:18:00.594] iteration 9415 : loss : 0.094331, loss_ce: 0.015633
[01:18:00.892] iteration 9416 : loss : 0.073531, loss_ce: 0.018272
[01:18:01.189] iteration 9417 : loss : 0.055112, loss_ce: 0.025921
[01:18:01.483] iteration 9418 : loss : 0.060938, loss_ce: 0.021513
[01:18:01.775] iteration 9419 : loss : 0.060171, loss_ce: 0.014668
[01:18:02.068] iteration 9420 : loss : 0.176853, loss_ce: 0.010502
[01:18:02.378] iteration 9421 : loss : 0.062391, loss_ce: 0.029961
[01:18:02.671] iteration 9422 : loss : 0.049962, loss_ce: 0.010730
[01:18:02.965] iteration 9423 : loss : 0.110568, loss_ce: 0.010015
[01:18:03.260] iteration 9424 : loss : 0.095166, loss_ce: 0.007010
[01:18:03.554] iteration 9425 : loss : 0.103806, loss_ce: 0.009356
[01:18:03.847] iteration 9426 : loss : 0.051036, loss_ce: 0.017938
[01:18:04.138] iteration 9427 : loss : 0.055807, loss_ce: 0.020400
[01:18:04.429] iteration 9428 : loss : 0.040760, loss_ce: 0.012285
[01:18:04.722] iteration 9429 : loss : 0.054798, loss_ce: 0.016027
[01:18:05.015] iteration 9430 : loss : 0.175929, loss_ce: 0.013898
[01:18:05.310] iteration 9431 : loss : 0.050609, loss_ce: 0.018278
[01:18:05.604] iteration 9432 : loss : 0.046052, loss_ce: 0.011111
[01:18:05.894] iteration 9433 : loss : 0.056650, loss_ce: 0.019589
[01:18:06.187] iteration 9434 : loss : 0.109775, loss_ce: 0.010219
[01:18:06.481] iteration 9435 : loss : 0.106391, loss_ce: 0.018426
[01:18:06.780] iteration 9436 : loss : 0.043520, loss_ce: 0.024180
[01:18:07.079] iteration 9437 : loss : 0.091979, loss_ce: 0.020262
[01:18:07.376] iteration 9438 : loss : 0.105104, loss_ce: 0.008813
[01:18:07.670] iteration 9439 : loss : 0.198915, loss_ce: 0.011313
[01:18:07.966] iteration 9440 : loss : 0.057436, loss_ce: 0.013189
[01:18:08.285] iteration 9441 : loss : 0.056925, loss_ce: 0.027357
[01:18:08.586] iteration 9442 : loss : 0.067237, loss_ce: 0.019935
[01:18:08.887] iteration 9443 : loss : 0.072066, loss_ce: 0.022885
[01:18:09.188] iteration 9444 : loss : 0.146233, loss_ce: 0.015409
[01:18:09.494] iteration 9445 : loss : 0.085755, loss_ce: 0.017505
[01:18:09.796] iteration 9446 : loss : 0.066822, loss_ce: 0.015148
[01:18:10.100] iteration 9447 : loss : 0.117723, loss_ce: 0.019466
[01:18:10.415] iteration 9448 : loss : 0.053169, loss_ce: 0.020303
[01:18:10.716] iteration 9449 : loss : 0.114256, loss_ce: 0.012732
[01:18:11.016] iteration 9450 : loss : 0.070487, loss_ce: 0.018636
[01:18:11.314] iteration 9451 : loss : 0.069245, loss_ce: 0.027794
[01:18:11.389] iteration 9452 : loss : 0.231318, loss_ce: 0.019043
[01:18:30.171] iteration 9453 : loss : 0.055002, loss_ce: 0.015311
[01:18:30.467] iteration 9454 : loss : 0.297762, loss_ce: 0.009930
[01:18:30.765] iteration 9455 : loss : 0.063852, loss_ce: 0.020812
[01:18:31.056] iteration 9456 : loss : 0.073511, loss_ce: 0.014914
[01:18:31.350] iteration 9457 : loss : 0.076315, loss_ce: 0.033514
[01:18:31.642] iteration 9458 : loss : 0.040709, loss_ce: 0.010175
[01:18:31.933] iteration 9459 : loss : 0.053010, loss_ce: 0.015549
[01:18:32.225] iteration 9460 : loss : 0.051634, loss_ce: 0.020145
[01:18:32.534] iteration 9461 : loss : 0.107329, loss_ce: 0.016922
[01:18:32.828] iteration 9462 : loss : 0.184336, loss_ce: 0.008879
[01:18:33.120] iteration 9463 : loss : 0.061468, loss_ce: 0.008661
[01:18:33.412] iteration 9464 : loss : 0.046325, loss_ce: 0.015588
[01:18:33.704] iteration 9465 : loss : 0.065653, loss_ce: 0.013883
[01:18:33.998] iteration 9466 : loss : 0.056753, loss_ce: 0.024254
[01:18:34.290] iteration 9467 : loss : 0.074868, loss_ce: 0.020598
[01:18:34.582] iteration 9468 : loss : 0.049368, loss_ce: 0.014229
[01:18:34.876] iteration 9469 : loss : 0.055512, loss_ce: 0.017753
[01:18:35.165] iteration 9470 : loss : 0.064531, loss_ce: 0.016096
[01:18:35.460] iteration 9471 : loss : 0.048422, loss_ce: 0.021571
[01:18:35.750] iteration 9472 : loss : 0.060527, loss_ce: 0.016409
[01:18:36.042] iteration 9473 : loss : 0.059780, loss_ce: 0.022488
[01:18:36.336] iteration 9474 : loss : 0.169609, loss_ce: 0.011000
[01:18:36.632] iteration 9475 : loss : 0.069928, loss_ce: 0.022937
[01:18:36.949] iteration 9476 : loss : 0.103713, loss_ce: 0.015535
[01:18:37.241] iteration 9477 : loss : 0.055043, loss_ce: 0.019982
[01:18:37.534] iteration 9478 : loss : 0.049378, loss_ce: 0.014922
[01:18:37.823] iteration 9479 : loss : 0.046987, loss_ce: 0.007151
[01:18:38.115] iteration 9480 : loss : 0.056494, loss_ce: 0.007982
[01:18:38.425] iteration 9481 : loss : 0.056996, loss_ce: 0.017065
[01:18:38.719] iteration 9482 : loss : 0.038737, loss_ce: 0.015353
[01:18:39.013] iteration 9483 : loss : 0.065815, loss_ce: 0.015410
[01:18:39.311] iteration 9484 : loss : 0.049383, loss_ce: 0.011671
[01:18:39.607] iteration 9485 : loss : 0.057762, loss_ce: 0.008385
[01:18:39.903] iteration 9486 : loss : 0.058124, loss_ce: 0.018352
[01:18:40.198] iteration 9487 : loss : 0.051992, loss_ce: 0.022204
[01:18:40.489] iteration 9488 : loss : 0.098072, loss_ce: 0.015830
[01:18:40.786] iteration 9489 : loss : 0.053650, loss_ce: 0.024188
[01:18:41.077] iteration 9490 : loss : 0.063325, loss_ce: 0.023953
[01:18:41.372] iteration 9491 : loss : 0.072025, loss_ce: 0.020323
[01:18:41.666] iteration 9492 : loss : 0.060234, loss_ce: 0.018131
[01:18:41.962] iteration 9493 : loss : 0.066075, loss_ce: 0.007472
[01:18:42.259] iteration 9494 : loss : 0.055014, loss_ce: 0.020481
[01:18:42.557] iteration 9495 : loss : 0.060220, loss_ce: 0.020295
[01:18:42.854] iteration 9496 : loss : 0.061690, loss_ce: 0.015624
[01:18:43.152] iteration 9497 : loss : 0.065934, loss_ce: 0.021155
[01:18:43.449] iteration 9498 : loss : 0.067449, loss_ce: 0.027611
[01:18:43.751] iteration 9499 : loss : 0.045693, loss_ce: 0.014141
[01:18:44.049] iteration 9500 : loss : 0.063517, loss_ce: 0.014052
[01:18:44.365] iteration 9501 : loss : 0.045729, loss_ce: 0.016982
[01:18:44.663] iteration 9502 : loss : 0.057068, loss_ce: 0.026319
[01:18:44.962] iteration 9503 : loss : 0.051703, loss_ce: 0.016859
[01:18:45.260] iteration 9504 : loss : 0.054694, loss_ce: 0.012829
[01:18:45.556] iteration 9505 : loss : 0.038458, loss_ce: 0.013069
[01:18:45.853] iteration 9506 : loss : 0.064696, loss_ce: 0.020548
[01:18:46.149] iteration 9507 : loss : 0.055017, loss_ce: 0.024378
[01:18:46.447] iteration 9508 : loss : 0.107043, loss_ce: 0.008581
[01:18:46.746] iteration 9509 : loss : 0.066913, loss_ce: 0.009033
[01:18:47.046] iteration 9510 : loss : 0.056818, loss_ce: 0.018308
[01:18:47.349] iteration 9511 : loss : 0.064592, loss_ce: 0.008537
[01:18:47.647] iteration 9512 : loss : 0.062430, loss_ce: 0.031784
[01:18:47.943] iteration 9513 : loss : 0.057071, loss_ce: 0.015915
[01:18:48.241] iteration 9514 : loss : 0.118936, loss_ce: 0.014196
[01:18:48.538] iteration 9515 : loss : 0.104757, loss_ce: 0.010144
[01:18:48.835] iteration 9516 : loss : 0.052344, loss_ce: 0.019800
[01:18:49.130] iteration 9517 : loss : 0.042702, loss_ce: 0.011310
[01:18:49.427] iteration 9518 : loss : 0.112232, loss_ce: 0.010909
[01:18:49.727] iteration 9519 : loss : 0.050391, loss_ce: 0.017192
[01:18:50.022] iteration 9520 : loss : 0.044808, loss_ce: 0.016764
[01:18:50.331] iteration 9521 : loss : 0.104127, loss_ce: 0.014486
[01:18:50.630] iteration 9522 : loss : 0.066961, loss_ce: 0.013650
[01:18:50.926] iteration 9523 : loss : 0.056656, loss_ce: 0.015382
[01:18:51.222] iteration 9524 : loss : 0.060373, loss_ce: 0.013802
[01:18:51.520] iteration 9525 : loss : 0.056487, loss_ce: 0.015681
[01:18:51.818] iteration 9526 : loss : 0.066872, loss_ce: 0.019091
[01:18:52.115] iteration 9527 : loss : 0.053360, loss_ce: 0.018070
[01:18:52.413] iteration 9528 : loss : 0.055425, loss_ce: 0.015235
[01:18:52.710] iteration 9529 : loss : 0.107120, loss_ce: 0.006597
[01:18:53.008] iteration 9530 : loss : 0.063547, loss_ce: 0.015788
[01:18:53.305] iteration 9531 : loss : 0.046982, loss_ce: 0.016386
[01:18:53.602] iteration 9532 : loss : 0.061859, loss_ce: 0.016097
[01:18:53.901] iteration 9533 : loss : 0.055031, loss_ce: 0.022799
[01:18:54.199] iteration 9534 : loss : 0.050979, loss_ce: 0.012363
[01:18:54.498] iteration 9535 : loss : 0.055488, loss_ce: 0.010036
[01:18:54.797] iteration 9536 : loss : 0.076667, loss_ce: 0.010570
[01:18:55.094] iteration 9537 : loss : 0.047356, loss_ce: 0.017053
[01:18:55.387] iteration 9538 : loss : 0.109538, loss_ce: 0.014545
[01:18:55.685] iteration 9539 : loss : 0.048566, loss_ce: 0.012063
[01:18:55.983] iteration 9540 : loss : 0.161707, loss_ce: 0.006460
[01:18:56.307] iteration 9541 : loss : 0.066205, loss_ce: 0.027617
[01:18:56.606] iteration 9542 : loss : 0.116383, loss_ce: 0.012523
[01:18:56.907] iteration 9543 : loss : 0.055477, loss_ce: 0.015602
[01:18:57.202] iteration 9544 : loss : 0.053669, loss_ce: 0.008037
[01:18:57.499] iteration 9545 : loss : 0.076886, loss_ce: 0.009813
[01:18:57.794] iteration 9546 : loss : 0.061113, loss_ce: 0.015101
[01:18:58.095] iteration 9547 : loss : 0.048720, loss_ce: 0.016167
[01:18:58.392] iteration 9548 : loss : 0.055886, loss_ce: 0.014112
[01:18:58.691] iteration 9549 : loss : 0.078569, loss_ce: 0.017841
[01:18:58.990] iteration 9550 : loss : 0.117804, loss_ce: 0.016655
[01:18:59.293] iteration 9551 : loss : 0.170149, loss_ce: 0.008230
[01:18:59.593] iteration 9552 : loss : 0.053778, loss_ce: 0.012271
[01:18:59.892] iteration 9553 : loss : 0.052333, loss_ce: 0.014151
[01:19:00.190] iteration 9554 : loss : 0.052070, loss_ce: 0.015583
[01:19:00.488] iteration 9555 : loss : 0.061435, loss_ce: 0.021700
[01:19:00.790] iteration 9556 : loss : 0.062457, loss_ce: 0.015860
[01:19:01.089] iteration 9557 : loss : 0.106406, loss_ce: 0.008782
[01:19:01.386] iteration 9558 : loss : 0.092913, loss_ce: 0.022164
[01:19:01.681] iteration 9559 : loss : 0.116254, loss_ce: 0.024944
[01:19:01.973] iteration 9560 : loss : 0.063187, loss_ce: 0.016289
[01:19:02.282] iteration 9561 : loss : 0.048616, loss_ce: 0.010501
[01:19:02.577] iteration 9562 : loss : 0.052814, loss_ce: 0.021100
[01:19:02.871] iteration 9563 : loss : 0.064432, loss_ce: 0.026633
[01:19:03.163] iteration 9564 : loss : 0.094284, loss_ce: 0.009899
[01:19:03.458] iteration 9565 : loss : 0.062511, loss_ce: 0.021654
[01:19:03.748] iteration 9566 : loss : 0.044665, loss_ce: 0.012904
[01:19:04.041] iteration 9567 : loss : 0.052601, loss_ce: 0.011792
[01:19:04.334] iteration 9568 : loss : 0.059984, loss_ce: 0.016170
[01:19:04.630] iteration 9569 : loss : 0.103188, loss_ce: 0.010405
[01:19:04.923] iteration 9570 : loss : 0.055174, loss_ce: 0.023942
[01:19:05.222] iteration 9571 : loss : 0.051559, loss_ce: 0.016212
[01:19:05.512] iteration 9572 : loss : 0.057363, loss_ce: 0.016615
[01:19:05.805] iteration 9573 : loss : 0.047392, loss_ce: 0.013125
[01:19:06.100] iteration 9574 : loss : 0.071575, loss_ce: 0.017583
[01:19:06.397] iteration 9575 : loss : 0.054295, loss_ce: 0.018840
[01:19:06.690] iteration 9576 : loss : 0.101683, loss_ce: 0.010133
[01:19:06.989] iteration 9577 : loss : 0.110395, loss_ce: 0.016002
[01:19:07.285] iteration 9578 : loss : 0.129539, loss_ce: 0.024551
[01:19:07.585] iteration 9579 : loss : 0.065680, loss_ce: 0.015420
[01:19:07.882] iteration 9580 : loss : 0.051558, loss_ce: 0.029327
[01:19:08.196] iteration 9581 : loss : 0.041888, loss_ce: 0.009842
[01:19:08.498] iteration 9582 : loss : 0.059099, loss_ce: 0.016809
[01:19:08.796] iteration 9583 : loss : 0.056627, loss_ce: 0.018535
[01:19:09.096] iteration 9584 : loss : 0.106001, loss_ce: 0.011856
[01:19:09.391] iteration 9585 : loss : 0.053750, loss_ce: 0.023123
[01:19:09.696] iteration 9586 : loss : 0.063327, loss_ce: 0.009715
[01:19:10.002] iteration 9587 : loss : 0.053302, loss_ce: 0.018215
[01:19:10.306] iteration 9588 : loss : 0.122514, loss_ce: 0.011640
[01:19:10.605] iteration 9589 : loss : 0.078200, loss_ce: 0.014660
[01:19:10.901] iteration 9590 : loss : 0.081521, loss_ce: 0.014308
[01:19:10.979] iteration 9591 : loss : 0.241113, loss_ce: 0.043996
[01:19:29.009] iteration 9592 : loss : 0.066400, loss_ce: 0.010751
[01:19:29.306] iteration 9593 : loss : 0.063834, loss_ce: 0.015936
[01:19:29.606] iteration 9594 : loss : 0.067638, loss_ce: 0.018854
[01:19:29.909] iteration 9595 : loss : 0.047877, loss_ce: 0.017819
[01:19:30.211] iteration 9596 : loss : 0.059923, loss_ce: 0.013504
[01:19:30.506] iteration 9597 : loss : 0.042498, loss_ce: 0.011536
[01:19:30.808] iteration 9598 : loss : 0.067968, loss_ce: 0.012388
[01:19:31.106] iteration 9599 : loss : 0.058751, loss_ce: 0.024490
[01:19:31.397] iteration 9600 : loss : 0.063550, loss_ce: 0.008386
[01:19:31.719] iteration 9601 : loss : 0.075315, loss_ce: 0.016391
[01:19:32.012] iteration 9602 : loss : 0.047477, loss_ce: 0.023376
[01:19:32.306] iteration 9603 : loss : 0.056776, loss_ce: 0.018129
[01:19:32.603] iteration 9604 : loss : 0.042336, loss_ce: 0.011706
[01:19:32.903] iteration 9605 : loss : 0.062785, loss_ce: 0.024527
[01:19:33.195] iteration 9606 : loss : 0.061185, loss_ce: 0.021694
[01:19:33.490] iteration 9607 : loss : 0.071295, loss_ce: 0.013980
[01:19:33.785] iteration 9608 : loss : 0.054464, loss_ce: 0.026706
[01:19:34.082] iteration 9609 : loss : 0.039168, loss_ce: 0.012549
[01:19:34.378] iteration 9610 : loss : 0.056319, loss_ce: 0.026491
[01:19:34.673] iteration 9611 : loss : 0.116957, loss_ce: 0.016602
[01:19:34.964] iteration 9612 : loss : 0.162667, loss_ce: 0.008377
[01:19:35.257] iteration 9613 : loss : 0.047178, loss_ce: 0.012159
[01:19:35.554] iteration 9614 : loss : 0.047399, loss_ce: 0.016513
[01:19:35.848] iteration 9615 : loss : 0.101344, loss_ce: 0.013979
[01:19:36.144] iteration 9616 : loss : 0.055598, loss_ce: 0.018755
[01:19:36.438] iteration 9617 : loss : 0.060934, loss_ce: 0.022986
[01:19:36.734] iteration 9618 : loss : 0.098836, loss_ce: 0.013610
[01:19:37.031] iteration 9619 : loss : 0.074461, loss_ce: 0.012750
[01:19:37.330] iteration 9620 : loss : 0.050596, loss_ce: 0.012091
[01:19:37.642] iteration 9621 : loss : 0.069387, loss_ce: 0.018795
[01:19:37.937] iteration 9622 : loss : 0.058565, loss_ce: 0.019700
[01:19:38.232] iteration 9623 : loss : 0.063299, loss_ce: 0.019615
[01:19:38.528] iteration 9624 : loss : 0.070581, loss_ce: 0.022810
[01:19:38.824] iteration 9625 : loss : 0.066112, loss_ce: 0.029002
[01:19:39.116] iteration 9626 : loss : 0.112786, loss_ce: 0.021573
[01:19:39.412] iteration 9627 : loss : 0.055158, loss_ce: 0.007101
[01:19:39.711] iteration 9628 : loss : 0.116655, loss_ce: 0.009187
[01:19:39.999] iteration 9629 : loss : 0.378162, loss_ce: 0.006832
[01:19:40.299] iteration 9630 : loss : 0.061048, loss_ce: 0.010729
[01:19:40.595] iteration 9631 : loss : 0.053290, loss_ce: 0.016314
[01:19:40.893] iteration 9632 : loss : 0.155555, loss_ce: 0.009940
[01:19:41.185] iteration 9633 : loss : 0.081369, loss_ce: 0.018426
[01:19:41.477] iteration 9634 : loss : 0.056108, loss_ce: 0.020708
[01:19:41.773] iteration 9635 : loss : 0.131699, loss_ce: 0.009245
[01:19:42.066] iteration 9636 : loss : 0.085068, loss_ce: 0.011712
[01:19:42.360] iteration 9637 : loss : 0.056783, loss_ce: 0.012216
[01:19:42.655] iteration 9638 : loss : 0.113854, loss_ce: 0.010628
[01:19:42.953] iteration 9639 : loss : 0.079461, loss_ce: 0.018122
[01:19:43.250] iteration 9640 : loss : 0.059631, loss_ce: 0.014340
[01:19:43.564] iteration 9641 : loss : 0.035461, loss_ce: 0.007719
[01:19:43.859] iteration 9642 : loss : 0.068270, loss_ce: 0.021328
[01:19:44.161] iteration 9643 : loss : 0.052782, loss_ce: 0.014722
[01:19:44.464] iteration 9644 : loss : 0.068716, loss_ce: 0.023991
[01:19:44.763] iteration 9645 : loss : 0.112079, loss_ce: 0.010649
[01:19:45.061] iteration 9646 : loss : 0.043204, loss_ce: 0.013216
[01:19:45.357] iteration 9647 : loss : 0.059482, loss_ce: 0.012855
[01:19:45.657] iteration 9648 : loss : 0.047243, loss_ce: 0.008768
[01:19:45.959] iteration 9649 : loss : 0.111574, loss_ce: 0.012237
[01:19:46.250] iteration 9650 : loss : 0.063493, loss_ce: 0.021668
[01:19:46.545] iteration 9651 : loss : 0.104355, loss_ce: 0.008907
[01:19:46.850] iteration 9652 : loss : 0.060861, loss_ce: 0.016066
[01:19:47.147] iteration 9653 : loss : 0.138087, loss_ce: 0.010392
[01:19:47.440] iteration 9654 : loss : 0.050029, loss_ce: 0.017109
[01:19:47.730] iteration 9655 : loss : 0.057218, loss_ce: 0.013576
[01:19:48.023] iteration 9656 : loss : 0.051726, loss_ce: 0.021707
[01:19:48.318] iteration 9657 : loss : 0.051708, loss_ce: 0.021415
[01:19:48.610] iteration 9658 : loss : 0.044206, loss_ce: 0.011951
[01:19:48.904] iteration 9659 : loss : 0.108752, loss_ce: 0.017735
[01:19:49.197] iteration 9660 : loss : 0.063990, loss_ce: 0.010961
[01:19:49.509] iteration 9661 : loss : 0.061083, loss_ce: 0.022510
[01:19:49.801] iteration 9662 : loss : 0.052179, loss_ce: 0.017577
[01:19:50.093] iteration 9663 : loss : 0.059930, loss_ce: 0.014093
[01:19:50.383] iteration 9664 : loss : 0.069580, loss_ce: 0.013840
[01:19:50.676] iteration 9665 : loss : 0.222095, loss_ce: 0.005842
[01:19:50.965] iteration 9666 : loss : 0.052778, loss_ce: 0.015405
[01:19:51.259] iteration 9667 : loss : 0.078432, loss_ce: 0.023535
[01:19:51.552] iteration 9668 : loss : 0.054992, loss_ce: 0.020213
[01:19:51.847] iteration 9669 : loss : 0.050057, loss_ce: 0.024279
[01:19:52.140] iteration 9670 : loss : 0.053396, loss_ce: 0.015020
[01:19:52.439] iteration 9671 : loss : 0.058706, loss_ce: 0.012193
[01:19:52.733] iteration 9672 : loss : 0.105706, loss_ce: 0.008279
[01:19:53.025] iteration 9673 : loss : 0.109693, loss_ce: 0.013442
[01:19:53.319] iteration 9674 : loss : 0.113667, loss_ce: 0.015574
[01:19:53.611] iteration 9675 : loss : 0.043679, loss_ce: 0.018001
[01:19:53.907] iteration 9676 : loss : 0.110175, loss_ce: 0.021633
[01:19:54.200] iteration 9677 : loss : 0.108150, loss_ce: 0.009918
[01:19:54.495] iteration 9678 : loss : 0.055229, loss_ce: 0.025010
[01:19:54.789] iteration 9679 : loss : 0.050188, loss_ce: 0.015027
[01:19:55.087] iteration 9680 : loss : 0.045422, loss_ce: 0.020061
[01:19:55.398] iteration 9681 : loss : 0.067249, loss_ce: 0.018564
[01:19:55.694] iteration 9682 : loss : 0.047753, loss_ce: 0.010792
[01:19:55.985] iteration 9683 : loss : 0.062184, loss_ce: 0.016699
[01:19:56.274] iteration 9684 : loss : 0.048636, loss_ce: 0.017281
[01:19:56.568] iteration 9685 : loss : 0.111020, loss_ce: 0.013188
[01:19:56.864] iteration 9686 : loss : 0.063152, loss_ce: 0.012068
[01:19:57.157] iteration 9687 : loss : 0.058341, loss_ce: 0.014883
[01:19:57.458] iteration 9688 : loss : 0.168870, loss_ce: 0.010684
[01:19:57.753] iteration 9689 : loss : 0.062179, loss_ce: 0.015209
[01:19:58.041] iteration 9690 : loss : 0.051703, loss_ce: 0.015651
[01:19:58.335] iteration 9691 : loss : 0.057063, loss_ce: 0.014734
[01:19:58.631] iteration 9692 : loss : 0.120420, loss_ce: 0.020282
[01:19:58.923] iteration 9693 : loss : 0.231173, loss_ce: 0.002351
[01:19:59.214] iteration 9694 : loss : 0.069217, loss_ce: 0.009353
[01:19:59.512] iteration 9695 : loss : 0.078993, loss_ce: 0.011350
[01:19:59.803] iteration 9696 : loss : 0.055831, loss_ce: 0.027894
[01:20:00.101] iteration 9697 : loss : 0.072120, loss_ce: 0.025849
[01:20:00.397] iteration 9698 : loss : 0.055377, loss_ce: 0.017947
[01:20:00.696] iteration 9699 : loss : 0.061206, loss_ce: 0.021976
[01:20:00.995] iteration 9700 : loss : 0.049296, loss_ce: 0.028841
[01:20:01.318] iteration 9701 : loss : 0.063939, loss_ce: 0.015476
[01:20:01.615] iteration 9702 : loss : 0.052500, loss_ce: 0.017701
[01:20:01.913] iteration 9703 : loss : 0.040353, loss_ce: 0.017456
[01:20:02.210] iteration 9704 : loss : 0.049942, loss_ce: 0.012298
[01:20:02.511] iteration 9705 : loss : 0.069509, loss_ce: 0.022691
[01:20:02.806] iteration 9706 : loss : 0.056518, loss_ce: 0.022428
[01:20:03.105] iteration 9707 : loss : 0.104599, loss_ce: 0.006964
[01:20:03.404] iteration 9708 : loss : 0.055757, loss_ce: 0.014454
[01:20:03.701] iteration 9709 : loss : 0.043350, loss_ce: 0.008393
[01:20:03.997] iteration 9710 : loss : 0.118803, loss_ce: 0.019117
[01:20:04.296] iteration 9711 : loss : 0.053461, loss_ce: 0.016092
[01:20:04.595] iteration 9712 : loss : 0.178260, loss_ce: 0.004656
[01:20:04.895] iteration 9713 : loss : 0.134669, loss_ce: 0.020406
[01:20:05.202] iteration 9714 : loss : 0.071361, loss_ce: 0.023607
[01:20:05.501] iteration 9715 : loss : 0.104482, loss_ce: 0.016552
[01:20:05.806] iteration 9716 : loss : 0.048851, loss_ce: 0.020864
[01:20:06.111] iteration 9717 : loss : 0.053857, loss_ce: 0.016858
[01:20:06.415] iteration 9718 : loss : 0.041864, loss_ce: 0.009874
[01:20:06.719] iteration 9719 : loss : 0.053194, loss_ce: 0.017753
[01:20:07.025] iteration 9720 : loss : 0.054726, loss_ce: 0.025708
[01:20:07.347] iteration 9721 : loss : 0.057182, loss_ce: 0.022163
[01:20:07.649] iteration 9722 : loss : 0.041934, loss_ce: 0.012696
[01:20:07.952] iteration 9723 : loss : 0.065527, loss_ce: 0.018881
[01:20:08.256] iteration 9724 : loss : 0.048436, loss_ce: 0.023330
[01:20:08.561] iteration 9725 : loss : 0.115939, loss_ce: 0.009946
[01:20:08.862] iteration 9726 : loss : 0.061715, loss_ce: 0.020851
[01:20:09.166] iteration 9727 : loss : 0.058062, loss_ce: 0.020233
[01:20:09.469] iteration 9728 : loss : 0.115404, loss_ce: 0.009774
[01:20:09.773] iteration 9729 : loss : 0.082114, loss_ce: 0.011515
[01:20:09.855] iteration 9730 : loss : 0.444487, loss_ce: 0.004078
[01:20:31.396] iteration 9731 : loss : 0.051210, loss_ce: 0.011722
[01:20:31.688] iteration 9732 : loss : 0.045926, loss_ce: 0.018597
[01:20:31.981] iteration 9733 : loss : 0.044984, loss_ce: 0.013900
[01:20:32.276] iteration 9734 : loss : 0.117486, loss_ce: 0.007966
[01:20:32.570] iteration 9735 : loss : 0.087297, loss_ce: 0.036643
[01:20:32.865] iteration 9736 : loss : 0.106772, loss_ce: 0.010764
[01:20:33.162] iteration 9737 : loss : 0.066072, loss_ce: 0.018126
[01:20:33.454] iteration 9738 : loss : 0.044616, loss_ce: 0.012751
[01:20:33.747] iteration 9739 : loss : 0.054188, loss_ce: 0.022989
[01:20:34.038] iteration 9740 : loss : 0.052298, loss_ce: 0.009319
[01:20:34.355] iteration 9741 : loss : 0.056379, loss_ce: 0.020524
[01:20:34.649] iteration 9742 : loss : 0.117120, loss_ce: 0.016405
[01:20:34.946] iteration 9743 : loss : 0.071374, loss_ce: 0.025251
[01:20:35.244] iteration 9744 : loss : 0.059058, loss_ce: 0.025247
[01:20:35.542] iteration 9745 : loss : 0.069562, loss_ce: 0.033629
[01:20:35.838] iteration 9746 : loss : 0.054590, loss_ce: 0.010541
[01:20:36.139] iteration 9747 : loss : 0.054444, loss_ce: 0.013311
[01:20:36.431] iteration 9748 : loss : 0.059881, loss_ce: 0.009202
[01:20:36.722] iteration 9749 : loss : 0.057207, loss_ce: 0.015560
[01:20:37.014] iteration 9750 : loss : 0.064379, loss_ce: 0.014115
[01:20:37.307] iteration 9751 : loss : 0.073607, loss_ce: 0.024298
[01:20:37.601] iteration 9752 : loss : 0.120143, loss_ce: 0.007072
[01:20:37.893] iteration 9753 : loss : 0.054325, loss_ce: 0.012483
[01:20:38.183] iteration 9754 : loss : 0.089635, loss_ce: 0.011365
[01:20:38.478] iteration 9755 : loss : 0.115436, loss_ce: 0.015749
[01:20:38.770] iteration 9756 : loss : 0.053848, loss_ce: 0.010682
[01:20:39.065] iteration 9757 : loss : 0.058710, loss_ce: 0.012709
[01:20:39.358] iteration 9758 : loss : 0.062433, loss_ce: 0.018196
[01:20:39.649] iteration 9759 : loss : 0.067121, loss_ce: 0.021349
[01:20:39.940] iteration 9760 : loss : 0.119156, loss_ce: 0.021281
[01:20:40.248] iteration 9761 : loss : 0.069674, loss_ce: 0.023875
[01:20:40.539] iteration 9762 : loss : 0.061129, loss_ce: 0.020068
[01:20:40.829] iteration 9763 : loss : 0.085312, loss_ce: 0.017611
[01:20:41.120] iteration 9764 : loss : 0.068263, loss_ce: 0.019841
[01:20:41.417] iteration 9765 : loss : 0.053054, loss_ce: 0.013070
[01:20:41.708] iteration 9766 : loss : 0.101148, loss_ce: 0.009423
[01:20:42.005] iteration 9767 : loss : 0.050224, loss_ce: 0.020449
[01:20:42.294] iteration 9768 : loss : 0.059807, loss_ce: 0.017631
[01:20:42.590] iteration 9769 : loss : 0.050824, loss_ce: 0.017395
[01:20:42.883] iteration 9770 : loss : 0.079145, loss_ce: 0.015777
[01:20:43.180] iteration 9771 : loss : 0.045203, loss_ce: 0.016972
[01:20:43.473] iteration 9772 : loss : 0.060167, loss_ce: 0.025219
[01:20:43.764] iteration 9773 : loss : 0.045284, loss_ce: 0.014856
[01:20:44.058] iteration 9774 : loss : 0.054264, loss_ce: 0.020249
[01:20:44.353] iteration 9775 : loss : 0.064161, loss_ce: 0.013603
[01:20:44.648] iteration 9776 : loss : 0.050458, loss_ce: 0.016501
[01:20:44.945] iteration 9777 : loss : 0.050195, loss_ce: 0.017800
[01:20:45.238] iteration 9778 : loss : 0.040751, loss_ce: 0.006830
[01:20:45.530] iteration 9779 : loss : 0.052853, loss_ce: 0.010327
[01:20:45.820] iteration 9780 : loss : 0.075895, loss_ce: 0.021577
[01:20:46.134] iteration 9781 : loss : 0.060043, loss_ce: 0.027060
[01:20:46.424] iteration 9782 : loss : 0.058039, loss_ce: 0.025164
[01:20:46.717] iteration 9783 : loss : 0.054163, loss_ce: 0.015964
[01:20:47.011] iteration 9784 : loss : 0.059341, loss_ce: 0.014012
[01:20:47.302] iteration 9785 : loss : 0.057227, loss_ce: 0.020300
[01:20:47.596] iteration 9786 : loss : 0.068805, loss_ce: 0.010361
[01:20:47.892] iteration 9787 : loss : 0.056304, loss_ce: 0.009481
[01:20:48.186] iteration 9788 : loss : 0.062634, loss_ce: 0.014703
[01:20:48.479] iteration 9789 : loss : 0.042067, loss_ce: 0.012314
[01:20:48.771] iteration 9790 : loss : 0.060871, loss_ce: 0.022410
[01:20:49.075] iteration 9791 : loss : 0.056929, loss_ce: 0.017433
[01:20:49.374] iteration 9792 : loss : 0.045161, loss_ce: 0.014317
[01:20:49.671] iteration 9793 : loss : 0.054425, loss_ce: 0.019224
[01:20:49.975] iteration 9794 : loss : 0.056138, loss_ce: 0.019220
[01:20:50.277] iteration 9795 : loss : 0.049967, loss_ce: 0.019804
[01:20:50.575] iteration 9796 : loss : 0.068176, loss_ce: 0.027538
[01:20:50.874] iteration 9797 : loss : 0.074484, loss_ce: 0.030621
[01:20:51.172] iteration 9798 : loss : 0.054379, loss_ce: 0.013171
[01:20:51.466] iteration 9799 : loss : 0.126672, loss_ce: 0.009339
[01:20:51.759] iteration 9800 : loss : 0.104479, loss_ce: 0.012439
[01:20:52.068] iteration 9801 : loss : 0.137487, loss_ce: 0.021546
[01:20:52.363] iteration 9802 : loss : 0.062148, loss_ce: 0.030706
[01:20:52.657] iteration 9803 : loss : 0.063906, loss_ce: 0.017442
[01:20:52.954] iteration 9804 : loss : 0.041621, loss_ce: 0.012357
[01:20:53.248] iteration 9805 : loss : 0.119879, loss_ce: 0.013119
[01:20:53.544] iteration 9806 : loss : 0.066256, loss_ce: 0.014970
[01:20:53.841] iteration 9807 : loss : 0.052118, loss_ce: 0.019257
[01:20:54.135] iteration 9808 : loss : 0.121112, loss_ce: 0.010517
[01:20:54.428] iteration 9809 : loss : 0.103217, loss_ce: 0.014152
[01:20:54.720] iteration 9810 : loss : 0.124043, loss_ce: 0.017682
[01:20:55.017] iteration 9811 : loss : 0.054992, loss_ce: 0.012998
[01:20:55.316] iteration 9812 : loss : 0.058980, loss_ce: 0.016823
[01:20:55.609] iteration 9813 : loss : 0.061598, loss_ce: 0.019225
[01:20:55.905] iteration 9814 : loss : 0.061217, loss_ce: 0.024395
[01:20:56.200] iteration 9815 : loss : 0.110805, loss_ce: 0.016229
[01:20:56.495] iteration 9816 : loss : 0.096075, loss_ce: 0.008507
[01:20:56.788] iteration 9817 : loss : 0.048445, loss_ce: 0.012541
[01:20:57.081] iteration 9818 : loss : 0.051229, loss_ce: 0.016498
[01:20:57.377] iteration 9819 : loss : 0.048732, loss_ce: 0.021519
[01:20:57.671] iteration 9820 : loss : 0.106740, loss_ce: 0.009416
[01:20:57.982] iteration 9821 : loss : 0.105662, loss_ce: 0.016847
[01:20:58.276] iteration 9822 : loss : 0.054715, loss_ce: 0.021504
[01:20:58.569] iteration 9823 : loss : 0.052578, loss_ce: 0.019218
[01:20:58.864] iteration 9824 : loss : 0.153936, loss_ce: 0.008756
[01:20:59.161] iteration 9825 : loss : 0.058996, loss_ce: 0.021701
[01:20:59.459] iteration 9826 : loss : 0.059179, loss_ce: 0.016900
[01:20:59.754] iteration 9827 : loss : 0.053727, loss_ce: 0.019954
[01:21:00.051] iteration 9828 : loss : 0.160743, loss_ce: 0.010898
[01:21:00.344] iteration 9829 : loss : 0.199392, loss_ce: 0.006359
[01:21:00.640] iteration 9830 : loss : 0.059326, loss_ce: 0.010095
[01:21:00.935] iteration 9831 : loss : 0.064805, loss_ce: 0.030522
[01:21:01.226] iteration 9832 : loss : 0.132005, loss_ce: 0.014981
[01:21:01.519] iteration 9833 : loss : 0.128010, loss_ce: 0.017983
[01:21:01.813] iteration 9834 : loss : 0.070639, loss_ce: 0.010131
[01:21:02.107] iteration 9835 : loss : 0.048494, loss_ce: 0.016592
[01:21:02.404] iteration 9836 : loss : 0.055608, loss_ce: 0.026494
[01:21:02.697] iteration 9837 : loss : 0.061940, loss_ce: 0.012561
[01:21:02.992] iteration 9838 : loss : 0.106937, loss_ce: 0.011738
[01:21:03.288] iteration 9839 : loss : 0.054872, loss_ce: 0.009608
[01:21:03.583] iteration 9840 : loss : 0.052882, loss_ce: 0.013215
[01:21:03.898] iteration 9841 : loss : 0.074651, loss_ce: 0.029291
[01:21:04.193] iteration 9842 : loss : 0.062972, loss_ce: 0.025333
[01:21:04.492] iteration 9843 : loss : 0.084061, loss_ce: 0.017493
[01:21:04.789] iteration 9844 : loss : 0.057400, loss_ce: 0.014163
[01:21:05.082] iteration 9845 : loss : 0.087960, loss_ce: 0.013116
[01:21:05.380] iteration 9846 : loss : 0.053668, loss_ce: 0.008220
[01:21:05.674] iteration 9847 : loss : 0.109758, loss_ce: 0.018165
[01:21:05.966] iteration 9848 : loss : 0.065646, loss_ce: 0.012784
[01:21:06.266] iteration 9849 : loss : 0.067614, loss_ce: 0.024032
[01:21:06.565] iteration 9850 : loss : 0.059800, loss_ce: 0.023536
[01:21:06.863] iteration 9851 : loss : 0.060135, loss_ce: 0.011751
[01:21:07.162] iteration 9852 : loss : 0.112272, loss_ce: 0.005033
[01:21:07.460] iteration 9853 : loss : 0.043756, loss_ce: 0.015072
[01:21:07.766] iteration 9854 : loss : 0.050800, loss_ce: 0.012052
[01:21:08.066] iteration 9855 : loss : 0.119434, loss_ce: 0.014943
[01:21:08.371] iteration 9856 : loss : 0.066229, loss_ce: 0.023001
[01:21:08.675] iteration 9857 : loss : 0.058771, loss_ce: 0.032894
[01:21:08.985] iteration 9858 : loss : 0.049438, loss_ce: 0.011574
[01:21:09.284] iteration 9859 : loss : 0.067116, loss_ce: 0.022692
[01:21:09.586] iteration 9860 : loss : 0.067632, loss_ce: 0.027344
[01:21:09.908] iteration 9861 : loss : 0.054911, loss_ce: 0.010793
[01:21:10.207] iteration 9862 : loss : 0.113678, loss_ce: 0.019968
[01:21:10.508] iteration 9863 : loss : 0.065514, loss_ce: 0.022636
[01:21:10.809] iteration 9864 : loss : 0.142194, loss_ce: 0.014779
[01:21:11.117] iteration 9865 : loss : 0.040389, loss_ce: 0.013709
[01:21:11.421] iteration 9866 : loss : 0.122077, loss_ce: 0.018594
[01:21:11.724] iteration 9867 : loss : 0.068430, loss_ce: 0.014525
[01:21:12.036] iteration 9868 : loss : 0.075522, loss_ce: 0.011295
[01:21:12.117] iteration 9869 : loss : 0.117112, loss_ce: 0.030931
[01:21:30.940] iteration 9870 : loss : 0.118319, loss_ce: 0.017493
[01:21:31.235] iteration 9871 : loss : 0.072359, loss_ce: 0.014954
[01:21:31.530] iteration 9872 : loss : 0.060688, loss_ce: 0.014071
[01:21:31.825] iteration 9873 : loss : 0.045733, loss_ce: 0.020658
[01:21:32.124] iteration 9874 : loss : 0.109243, loss_ce: 0.020647
[01:21:32.419] iteration 9875 : loss : 0.078676, loss_ce: 0.017809
[01:21:32.713] iteration 9876 : loss : 0.057492, loss_ce: 0.015246
[01:21:33.009] iteration 9877 : loss : 0.050811, loss_ce: 0.011321
[01:21:33.305] iteration 9878 : loss : 0.049577, loss_ce: 0.023529
[01:21:33.602] iteration 9879 : loss : 0.049939, loss_ce: 0.013981
[01:21:33.897] iteration 9880 : loss : 0.126281, loss_ce: 0.014438
[01:21:34.208] iteration 9881 : loss : 0.122705, loss_ce: 0.016006
[01:21:34.500] iteration 9882 : loss : 0.058024, loss_ce: 0.015450
[01:21:34.792] iteration 9883 : loss : 0.060826, loss_ce: 0.018447
[01:21:35.088] iteration 9884 : loss : 0.042518, loss_ce: 0.014895
[01:21:35.382] iteration 9885 : loss : 0.060861, loss_ce: 0.018750
[01:21:35.674] iteration 9886 : loss : 0.108074, loss_ce: 0.008315
[01:21:35.968] iteration 9887 : loss : 0.044652, loss_ce: 0.008372
[01:21:36.261] iteration 9888 : loss : 0.049405, loss_ce: 0.012883
[01:21:36.555] iteration 9889 : loss : 0.161905, loss_ce: 0.007722
[01:21:36.847] iteration 9890 : loss : 0.047715, loss_ce: 0.012758
[01:21:37.138] iteration 9891 : loss : 0.055809, loss_ce: 0.016781
[01:21:37.427] iteration 9892 : loss : 0.055082, loss_ce: 0.017562
[01:21:37.721] iteration 9893 : loss : 0.051549, loss_ce: 0.008167
[01:21:38.018] iteration 9894 : loss : 0.042042, loss_ce: 0.014487
[01:21:38.313] iteration 9895 : loss : 0.052811, loss_ce: 0.012752
[01:21:38.606] iteration 9896 : loss : 0.051650, loss_ce: 0.016778
[01:21:38.907] iteration 9897 : loss : 0.058126, loss_ce: 0.022452
[01:21:39.205] iteration 9898 : loss : 0.069052, loss_ce: 0.009456
[01:21:39.505] iteration 9899 : loss : 0.052494, loss_ce: 0.012598
[01:21:39.805] iteration 9900 : loss : 0.047052, loss_ce: 0.017354
[01:21:40.126] iteration 9901 : loss : 0.066879, loss_ce: 0.024865
[01:21:40.426] iteration 9902 : loss : 0.060731, loss_ce: 0.009722
[01:21:40.724] iteration 9903 : loss : 0.053063, loss_ce: 0.017017
[01:21:41.021] iteration 9904 : loss : 0.052520, loss_ce: 0.016455
[01:21:41.317] iteration 9905 : loss : 0.116501, loss_ce: 0.005702
[01:21:41.610] iteration 9906 : loss : 0.042189, loss_ce: 0.017011
[01:21:41.903] iteration 9907 : loss : 0.051689, loss_ce: 0.012824
[01:21:42.194] iteration 9908 : loss : 0.050218, loss_ce: 0.010404
[01:21:42.486] iteration 9909 : loss : 0.045628, loss_ce: 0.015233
[01:21:42.783] iteration 9910 : loss : 0.056363, loss_ce: 0.018806
[01:21:43.076] iteration 9911 : loss : 0.110505, loss_ce: 0.010246
[01:21:43.371] iteration 9912 : loss : 0.049230, loss_ce: 0.012007
[01:21:43.668] iteration 9913 : loss : 0.105165, loss_ce: 0.008285
[01:21:43.964] iteration 9914 : loss : 0.060356, loss_ce: 0.025125
[01:21:44.259] iteration 9915 : loss : 0.056471, loss_ce: 0.020821
[01:21:44.555] iteration 9916 : loss : 0.074744, loss_ce: 0.022971
[01:21:44.851] iteration 9917 : loss : 0.051050, loss_ce: 0.012687
[01:21:45.148] iteration 9918 : loss : 0.050007, loss_ce: 0.010309
[01:21:45.440] iteration 9919 : loss : 0.117167, loss_ce: 0.013507
[01:21:45.733] iteration 9920 : loss : 0.114045, loss_ce: 0.017630
[01:21:46.041] iteration 9921 : loss : 0.072274, loss_ce: 0.022937
[01:21:46.335] iteration 9922 : loss : 0.066022, loss_ce: 0.025643
[01:21:46.629] iteration 9923 : loss : 0.060283, loss_ce: 0.013322
[01:21:46.921] iteration 9924 : loss : 0.055111, loss_ce: 0.008077
[01:21:47.215] iteration 9925 : loss : 0.049056, loss_ce: 0.017394
[01:21:47.508] iteration 9926 : loss : 0.057934, loss_ce: 0.012068
[01:21:47.801] iteration 9927 : loss : 0.056347, loss_ce: 0.015119
[01:21:48.097] iteration 9928 : loss : 0.039829, loss_ce: 0.011085
[01:21:48.392] iteration 9929 : loss : 0.113176, loss_ce: 0.024386
[01:21:48.687] iteration 9930 : loss : 0.055552, loss_ce: 0.019927
[01:21:48.983] iteration 9931 : loss : 0.040398, loss_ce: 0.013070
[01:21:49.278] iteration 9932 : loss : 0.050273, loss_ce: 0.017768
[01:21:49.571] iteration 9933 : loss : 0.038943, loss_ce: 0.010423
[01:21:49.870] iteration 9934 : loss : 0.077135, loss_ce: 0.010794
[01:21:50.165] iteration 9935 : loss : 0.048203, loss_ce: 0.015819
[01:21:50.458] iteration 9936 : loss : 0.059697, loss_ce: 0.016913
[01:21:50.753] iteration 9937 : loss : 0.066044, loss_ce: 0.022693
[01:21:51.048] iteration 9938 : loss : 0.047011, loss_ce: 0.014503
[01:21:51.341] iteration 9939 : loss : 0.051915, loss_ce: 0.023773
[01:21:51.636] iteration 9940 : loss : 0.108881, loss_ce: 0.013751
[01:21:51.946] iteration 9941 : loss : 0.054286, loss_ce: 0.010544
[01:21:52.237] iteration 9942 : loss : 0.049336, loss_ce: 0.022603
[01:21:52.532] iteration 9943 : loss : 0.049612, loss_ce: 0.008664
[01:21:52.822] iteration 9944 : loss : 0.070313, loss_ce: 0.013331
[01:21:53.114] iteration 9945 : loss : 0.056989, loss_ce: 0.015340
[01:21:53.406] iteration 9946 : loss : 0.050420, loss_ce: 0.015341
[01:21:53.703] iteration 9947 : loss : 0.112109, loss_ce: 0.009975
[01:21:53.999] iteration 9948 : loss : 0.058086, loss_ce: 0.011823
[01:21:54.300] iteration 9949 : loss : 0.080104, loss_ce: 0.017193
[01:21:54.597] iteration 9950 : loss : 0.065313, loss_ce: 0.011980
[01:21:54.896] iteration 9951 : loss : 0.066246, loss_ce: 0.018273
[01:21:55.193] iteration 9952 : loss : 0.106079, loss_ce: 0.015307
[01:21:55.496] iteration 9953 : loss : 0.114994, loss_ce: 0.008266
[01:21:55.798] iteration 9954 : loss : 0.064398, loss_ce: 0.013779
[01:21:56.098] iteration 9955 : loss : 0.060724, loss_ce: 0.014233
[01:21:56.393] iteration 9956 : loss : 0.059723, loss_ce: 0.013146
[01:21:56.685] iteration 9957 : loss : 0.101970, loss_ce: 0.006036
[01:21:56.980] iteration 9958 : loss : 0.157589, loss_ce: 0.007462
[01:21:57.273] iteration 9959 : loss : 0.140448, loss_ce: 0.020644
[01:21:57.569] iteration 9960 : loss : 0.116778, loss_ce: 0.016302
[01:21:57.876] iteration 9961 : loss : 0.057180, loss_ce: 0.010246
[01:21:58.168] iteration 9962 : loss : 0.055661, loss_ce: 0.013697
[01:21:58.456] iteration 9963 : loss : 0.046782, loss_ce: 0.020870
[01:21:58.749] iteration 9964 : loss : 0.049923, loss_ce: 0.022647
[01:21:59.047] iteration 9965 : loss : 0.075316, loss_ce: 0.026445
[01:21:59.343] iteration 9966 : loss : 0.056370, loss_ce: 0.016629
[01:21:59.636] iteration 9967 : loss : 0.085504, loss_ce: 0.021244
[01:21:59.930] iteration 9968 : loss : 0.048629, loss_ce: 0.020177
[01:22:00.224] iteration 9969 : loss : 0.044927, loss_ce: 0.012463
[01:22:00.518] iteration 9970 : loss : 0.056150, loss_ce: 0.020767
[01:22:00.815] iteration 9971 : loss : 0.060769, loss_ce: 0.016586
[01:22:01.113] iteration 9972 : loss : 0.103087, loss_ce: 0.008284
[01:22:01.406] iteration 9973 : loss : 0.056857, loss_ce: 0.023181
[01:22:01.701] iteration 9974 : loss : 0.108959, loss_ce: 0.021813
[01:22:01.996] iteration 9975 : loss : 0.107032, loss_ce: 0.006820
[01:22:02.291] iteration 9976 : loss : 0.055733, loss_ce: 0.022798
[01:22:02.584] iteration 9977 : loss : 0.057787, loss_ce: 0.022598
[01:22:02.882] iteration 9978 : loss : 0.057067, loss_ce: 0.015455
[01:22:03.180] iteration 9979 : loss : 0.051470, loss_ce: 0.010435
[01:22:03.475] iteration 9980 : loss : 0.118200, loss_ce: 0.014067
[01:22:03.787] iteration 9981 : loss : 0.071983, loss_ce: 0.011524
[01:22:04.081] iteration 9982 : loss : 0.049871, loss_ce: 0.016678
[01:22:04.375] iteration 9983 : loss : 0.048304, loss_ce: 0.018983
[01:22:04.669] iteration 9984 : loss : 0.058725, loss_ce: 0.023090
[01:22:04.962] iteration 9985 : loss : 0.051539, loss_ce: 0.014920
[01:22:05.254] iteration 9986 : loss : 0.061633, loss_ce: 0.010607
[01:22:05.549] iteration 9987 : loss : 0.111462, loss_ce: 0.011033
[01:22:05.845] iteration 9988 : loss : 0.044644, loss_ce: 0.021651
[01:22:06.138] iteration 9989 : loss : 0.038402, loss_ce: 0.011724
[01:22:06.429] iteration 9990 : loss : 0.059896, loss_ce: 0.019385
[01:22:06.725] iteration 9991 : loss : 0.044522, loss_ce: 0.014633
[01:22:07.026] iteration 9992 : loss : 0.168691, loss_ce: 0.010586
[01:22:07.324] iteration 9993 : loss : 0.057651, loss_ce: 0.018566
[01:22:07.626] iteration 9994 : loss : 0.079315, loss_ce: 0.016523
[01:22:07.927] iteration 9995 : loss : 0.060426, loss_ce: 0.014546
[01:22:08.223] iteration 9996 : loss : 0.062874, loss_ce: 0.026391
[01:22:08.522] iteration 9997 : loss : 0.041344, loss_ce: 0.009338
[01:22:08.823] iteration 9998 : loss : 0.110074, loss_ce: 0.016103
[01:22:09.130] iteration 9999 : loss : 0.110194, loss_ce: 0.012310
[01:22:09.432] iteration 10000 : loss : 0.065960, loss_ce: 0.020227
[01:22:09.752] iteration 10001 : loss : 0.056920, loss_ce: 0.016751
[01:22:10.053] iteration 10002 : loss : 0.111987, loss_ce: 0.010890
[01:22:10.356] iteration 10003 : loss : 0.066190, loss_ce: 0.034387
[01:22:10.659] iteration 10004 : loss : 0.064984, loss_ce: 0.021466
[01:22:10.966] iteration 10005 : loss : 0.076917, loss_ce: 0.010797
[01:22:11.258] iteration 10006 : loss : 0.046211, loss_ce: 0.013479
[01:22:11.557] iteration 10007 : loss : 0.065787, loss_ce: 0.020209
[01:22:11.637] iteration 10008 : loss : 0.101348, loss_ce: 0.025341
[01:22:30.283] iteration 10009 : loss : 0.060795, loss_ce: 0.014956
[01:22:30.584] iteration 10010 : loss : 0.055085, loss_ce: 0.022142
[01:22:30.884] iteration 10011 : loss : 0.046720, loss_ce: 0.016042
[01:22:31.184] iteration 10012 : loss : 0.054258, loss_ce: 0.009756
[01:22:31.482] iteration 10013 : loss : 0.063390, loss_ce: 0.009194
[01:22:31.777] iteration 10014 : loss : 0.061304, loss_ce: 0.012599
[01:22:32.070] iteration 10015 : loss : 0.066124, loss_ce: 0.018672
[01:22:32.367] iteration 10016 : loss : 0.056020, loss_ce: 0.017025
[01:22:32.659] iteration 10017 : loss : 0.058355, loss_ce: 0.014398
[01:22:32.957] iteration 10018 : loss : 0.108619, loss_ce: 0.020023
[01:22:33.257] iteration 10019 : loss : 0.117913, loss_ce: 0.006991
[01:22:33.554] iteration 10020 : loss : 0.119083, loss_ce: 0.009163
[01:22:33.865] iteration 10021 : loss : 0.059704, loss_ce: 0.017425
[01:22:34.161] iteration 10022 : loss : 0.059190, loss_ce: 0.017160
[01:22:34.460] iteration 10023 : loss : 0.105809, loss_ce: 0.017811
[01:22:34.754] iteration 10024 : loss : 0.117359, loss_ce: 0.008961
[01:22:35.051] iteration 10025 : loss : 0.053557, loss_ce: 0.020877
[01:22:35.349] iteration 10026 : loss : 0.046235, loss_ce: 0.024640
[01:22:35.650] iteration 10027 : loss : 0.073175, loss_ce: 0.018498
[01:22:35.949] iteration 10028 : loss : 0.079329, loss_ce: 0.023822
[01:22:36.243] iteration 10029 : loss : 0.073357, loss_ce: 0.039148
[01:22:36.537] iteration 10030 : loss : 0.063107, loss_ce: 0.016226
[01:22:36.833] iteration 10031 : loss : 0.049538, loss_ce: 0.017078
[01:22:37.130] iteration 10032 : loss : 0.068987, loss_ce: 0.018825
[01:22:37.429] iteration 10033 : loss : 0.068912, loss_ce: 0.012474
[01:22:37.723] iteration 10034 : loss : 0.105044, loss_ce: 0.013664
[01:22:38.018] iteration 10035 : loss : 0.049556, loss_ce: 0.023472
[01:22:38.315] iteration 10036 : loss : 0.052788, loss_ce: 0.010360
[01:22:38.613] iteration 10037 : loss : 0.062722, loss_ce: 0.032016
[01:22:38.910] iteration 10038 : loss : 0.102422, loss_ce: 0.006598
[01:22:39.206] iteration 10039 : loss : 0.056953, loss_ce: 0.013734
[01:22:39.504] iteration 10040 : loss : 0.045346, loss_ce: 0.015123
[01:22:39.814] iteration 10041 : loss : 0.165055, loss_ce: 0.007186
[01:22:40.114] iteration 10042 : loss : 0.062313, loss_ce: 0.028869
[01:22:40.412] iteration 10043 : loss : 0.128771, loss_ce: 0.011620
[01:22:40.709] iteration 10044 : loss : 0.110594, loss_ce: 0.011507
[01:22:41.005] iteration 10045 : loss : 0.043921, loss_ce: 0.018346
[01:22:41.302] iteration 10046 : loss : 0.056374, loss_ce: 0.020797
[01:22:41.598] iteration 10047 : loss : 0.060229, loss_ce: 0.007797
[01:22:41.897] iteration 10048 : loss : 0.112497, loss_ce: 0.010447
[01:22:42.194] iteration 10049 : loss : 0.175856, loss_ce: 0.009032
[01:22:42.490] iteration 10050 : loss : 0.046381, loss_ce: 0.022301
[01:22:42.790] iteration 10051 : loss : 0.046161, loss_ce: 0.012643
[01:22:43.085] iteration 10052 : loss : 0.052642, loss_ce: 0.023617
[01:22:43.382] iteration 10053 : loss : 0.065017, loss_ce: 0.020534
[01:22:43.679] iteration 10054 : loss : 0.049373, loss_ce: 0.016218
[01:22:43.977] iteration 10055 : loss : 0.053608, loss_ce: 0.020098
[01:22:44.277] iteration 10056 : loss : 0.066814, loss_ce: 0.018955
[01:22:44.577] iteration 10057 : loss : 0.051505, loss_ce: 0.011677
[01:22:44.874] iteration 10058 : loss : 0.051608, loss_ce: 0.012736
[01:22:45.170] iteration 10059 : loss : 0.051146, loss_ce: 0.019406
[01:22:45.468] iteration 10060 : loss : 0.051592, loss_ce: 0.017673
[01:22:45.782] iteration 10061 : loss : 0.117206, loss_ce: 0.010115
[01:22:46.077] iteration 10062 : loss : 0.168144, loss_ce: 0.009594
[01:22:46.372] iteration 10063 : loss : 0.059195, loss_ce: 0.019819
[01:22:46.666] iteration 10064 : loss : 0.062529, loss_ce: 0.012461
[01:22:46.959] iteration 10065 : loss : 0.045801, loss_ce: 0.019726
[01:22:47.254] iteration 10066 : loss : 0.095393, loss_ce: 0.005953
[01:22:47.547] iteration 10067 : loss : 0.052808, loss_ce: 0.004555
[01:22:47.841] iteration 10068 : loss : 0.068359, loss_ce: 0.020038
[01:22:48.137] iteration 10069 : loss : 0.058068, loss_ce: 0.014677
[01:22:48.426] iteration 10070 : loss : 0.043863, loss_ce: 0.012473
[01:22:48.720] iteration 10071 : loss : 0.044278, loss_ce: 0.014206
[01:22:49.013] iteration 10072 : loss : 0.048867, loss_ce: 0.019145
[01:22:49.303] iteration 10073 : loss : 0.115861, loss_ce: 0.010297
[01:22:49.594] iteration 10074 : loss : 0.073116, loss_ce: 0.015772
[01:22:49.884] iteration 10075 : loss : 0.080024, loss_ce: 0.015579
[01:22:50.180] iteration 10076 : loss : 0.131739, loss_ce: 0.028333
[01:22:50.473] iteration 10077 : loss : 0.045549, loss_ce: 0.017209
[01:22:50.765] iteration 10078 : loss : 0.045384, loss_ce: 0.011793
[01:22:51.059] iteration 10079 : loss : 0.059231, loss_ce: 0.020721
[01:22:51.355] iteration 10080 : loss : 0.114515, loss_ce: 0.020945
[01:22:51.665] iteration 10081 : loss : 0.105531, loss_ce: 0.017671
[01:22:51.958] iteration 10082 : loss : 0.058765, loss_ce: 0.015402
[01:22:52.253] iteration 10083 : loss : 0.068386, loss_ce: 0.017914
[01:22:52.546] iteration 10084 : loss : 0.047942, loss_ce: 0.017235
[01:22:52.841] iteration 10085 : loss : 0.062553, loss_ce: 0.012575
[01:22:53.130] iteration 10086 : loss : 0.109016, loss_ce: 0.015559
[01:22:53.420] iteration 10087 : loss : 0.056746, loss_ce: 0.010803
[01:22:53.715] iteration 10088 : loss : 0.283470, loss_ce: 0.009790
[01:22:54.007] iteration 10089 : loss : 0.054011, loss_ce: 0.014741
[01:22:54.300] iteration 10090 : loss : 0.052872, loss_ce: 0.015548
[01:22:54.594] iteration 10091 : loss : 0.054352, loss_ce: 0.018738
[01:22:54.885] iteration 10092 : loss : 0.058433, loss_ce: 0.009415
[01:22:55.178] iteration 10093 : loss : 0.049159, loss_ce: 0.014855
[01:22:55.471] iteration 10094 : loss : 0.058158, loss_ce: 0.014425
[01:22:55.763] iteration 10095 : loss : 0.058095, loss_ce: 0.013691
[01:22:56.053] iteration 10096 : loss : 0.048388, loss_ce: 0.018565
[01:22:56.347] iteration 10097 : loss : 0.055489, loss_ce: 0.007696
[01:22:56.641] iteration 10098 : loss : 0.064961, loss_ce: 0.015897
[01:22:56.938] iteration 10099 : loss : 0.049699, loss_ce: 0.013035
[01:22:57.233] iteration 10100 : loss : 0.107223, loss_ce: 0.011713
[01:22:57.542] iteration 10101 : loss : 0.069568, loss_ce: 0.021009
[01:22:57.836] iteration 10102 : loss : 0.046474, loss_ce: 0.019247
[01:22:58.131] iteration 10103 : loss : 0.107746, loss_ce: 0.013952
[01:22:58.424] iteration 10104 : loss : 0.109317, loss_ce: 0.012491
[01:22:58.717] iteration 10105 : loss : 0.071840, loss_ce: 0.020298
[01:22:59.010] iteration 10106 : loss : 0.072849, loss_ce: 0.022438
[01:22:59.308] iteration 10107 : loss : 0.050880, loss_ce: 0.015689
[01:22:59.608] iteration 10108 : loss : 0.231201, loss_ce: 0.006221
[01:22:59.908] iteration 10109 : loss : 0.060770, loss_ce: 0.013337
[01:23:00.210] iteration 10110 : loss : 0.041486, loss_ce: 0.016694
[01:23:00.511] iteration 10111 : loss : 0.052443, loss_ce: 0.015159
[01:23:00.809] iteration 10112 : loss : 0.061036, loss_ce: 0.012957
[01:23:01.106] iteration 10113 : loss : 0.069019, loss_ce: 0.010223
[01:23:01.402] iteration 10114 : loss : 0.110160, loss_ce: 0.017939
[01:23:01.697] iteration 10115 : loss : 0.052781, loss_ce: 0.010110
[01:23:01.989] iteration 10116 : loss : 0.045130, loss_ce: 0.017404
[01:23:02.283] iteration 10117 : loss : 0.055504, loss_ce: 0.022933
[01:23:02.573] iteration 10118 : loss : 0.054632, loss_ce: 0.027450
[01:23:02.870] iteration 10119 : loss : 0.048861, loss_ce: 0.016060
[01:23:03.164] iteration 10120 : loss : 0.062494, loss_ce: 0.020016
[01:23:03.481] iteration 10121 : loss : 0.060351, loss_ce: 0.010187
[01:23:03.769] iteration 10122 : loss : 0.047970, loss_ce: 0.015252
[01:23:04.063] iteration 10123 : loss : 0.053412, loss_ce: 0.011199
[01:23:04.356] iteration 10124 : loss : 0.163125, loss_ce: 0.004919
[01:23:04.651] iteration 10125 : loss : 0.053668, loss_ce: 0.016082
[01:23:04.947] iteration 10126 : loss : 0.082058, loss_ce: 0.016403
[01:23:05.238] iteration 10127 : loss : 0.046382, loss_ce: 0.016790
[01:23:05.529] iteration 10128 : loss : 0.106766, loss_ce: 0.012026
[01:23:05.822] iteration 10129 : loss : 0.056487, loss_ce: 0.017338
[01:23:06.115] iteration 10130 : loss : 0.077352, loss_ce: 0.009420
[01:23:06.420] iteration 10131 : loss : 0.117894, loss_ce: 0.020146
[01:23:06.714] iteration 10132 : loss : 0.058559, loss_ce: 0.024192
[01:23:07.009] iteration 10133 : loss : 0.056885, loss_ce: 0.019736
[01:23:07.310] iteration 10134 : loss : 0.059699, loss_ce: 0.028338
[01:23:07.609] iteration 10135 : loss : 0.050937, loss_ce: 0.015501
[01:23:07.903] iteration 10136 : loss : 0.043590, loss_ce: 0.016231
[01:23:08.202] iteration 10137 : loss : 0.057039, loss_ce: 0.023533
[01:23:08.502] iteration 10138 : loss : 0.048509, loss_ce: 0.011324
[01:23:08.803] iteration 10139 : loss : 0.109244, loss_ce: 0.012883
[01:23:09.098] iteration 10140 : loss : 0.063181, loss_ce: 0.014657
[01:23:09.420] iteration 10141 : loss : 0.057774, loss_ce: 0.011534
[01:23:09.715] iteration 10142 : loss : 0.068960, loss_ce: 0.019205
[01:23:10.014] iteration 10143 : loss : 0.055711, loss_ce: 0.017049
[01:23:10.304] iteration 10144 : loss : 0.055132, loss_ce: 0.022862
[01:23:10.602] iteration 10145 : loss : 0.048068, loss_ce: 0.016645
[01:23:10.897] iteration 10146 : loss : 0.121979, loss_ce: 0.009819
[01:23:10.974] iteration 10147 : loss : 0.077942, loss_ce: 0.033751
[01:23:29.259] iteration 10148 : loss : 0.059917, loss_ce: 0.014992
[01:23:29.559] iteration 10149 : loss : 0.082593, loss_ce: 0.010123
[01:23:29.860] iteration 10150 : loss : 0.133290, loss_ce: 0.013798
[01:23:30.165] iteration 10151 : loss : 0.056084, loss_ce: 0.016629
[01:23:30.466] iteration 10152 : loss : 0.061382, loss_ce: 0.013594
[01:23:30.761] iteration 10153 : loss : 0.074169, loss_ce: 0.019699
[01:23:31.055] iteration 10154 : loss : 0.056175, loss_ce: 0.019682
[01:23:31.355] iteration 10155 : loss : 0.058391, loss_ce: 0.022344
[01:23:31.654] iteration 10156 : loss : 0.051528, loss_ce: 0.012929
[01:23:31.953] iteration 10157 : loss : 0.062528, loss_ce: 0.021867
[01:23:32.254] iteration 10158 : loss : 0.061907, loss_ce: 0.019226
[01:23:32.556] iteration 10159 : loss : 0.057056, loss_ce: 0.013951
[01:23:32.847] iteration 10160 : loss : 0.135837, loss_ce: 0.015936
[01:23:33.166] iteration 10161 : loss : 0.064891, loss_ce: 0.023280
[01:23:33.464] iteration 10162 : loss : 0.117966, loss_ce: 0.007326
[01:23:33.766] iteration 10163 : loss : 0.078933, loss_ce: 0.021393
[01:23:34.068] iteration 10164 : loss : 0.051001, loss_ce: 0.017191
[01:23:34.366] iteration 10165 : loss : 0.054143, loss_ce: 0.015439
[01:23:34.666] iteration 10166 : loss : 0.058058, loss_ce: 0.022069
[01:23:34.963] iteration 10167 : loss : 0.056363, loss_ce: 0.015708
[01:23:35.267] iteration 10168 : loss : 0.049673, loss_ce: 0.013574
[01:23:35.568] iteration 10169 : loss : 0.110020, loss_ce: 0.015949
[01:23:35.864] iteration 10170 : loss : 0.108616, loss_ce: 0.014276
[01:23:36.163] iteration 10171 : loss : 0.081695, loss_ce: 0.015363
[01:23:36.464] iteration 10172 : loss : 0.055714, loss_ce: 0.014033
[01:23:36.763] iteration 10173 : loss : 0.082543, loss_ce: 0.017820
[01:23:37.064] iteration 10174 : loss : 0.044007, loss_ce: 0.015982
[01:23:37.358] iteration 10175 : loss : 0.062570, loss_ce: 0.011829
[01:23:37.654] iteration 10176 : loss : 0.078729, loss_ce: 0.012401
[01:23:37.954] iteration 10177 : loss : 0.121432, loss_ce: 0.015592
[01:23:38.253] iteration 10178 : loss : 0.051603, loss_ce: 0.015695
[01:23:38.554] iteration 10179 : loss : 0.068331, loss_ce: 0.025082
[01:23:38.850] iteration 10180 : loss : 0.059585, loss_ce: 0.013949
[01:23:39.162] iteration 10181 : loss : 0.099357, loss_ce: 0.009092
[01:23:39.464] iteration 10182 : loss : 0.055593, loss_ce: 0.017223
[01:23:39.763] iteration 10183 : loss : 0.055011, loss_ce: 0.011575
[01:23:40.065] iteration 10184 : loss : 0.042644, loss_ce: 0.013392
[01:23:40.364] iteration 10185 : loss : 0.069555, loss_ce: 0.015496
[01:23:40.665] iteration 10186 : loss : 0.098995, loss_ce: 0.009058
[01:23:40.966] iteration 10187 : loss : 0.048697, loss_ce: 0.017798
[01:23:41.263] iteration 10188 : loss : 0.060896, loss_ce: 0.010897
[01:23:41.561] iteration 10189 : loss : 0.160795, loss_ce: 0.011890
[01:23:41.861] iteration 10190 : loss : 0.121081, loss_ce: 0.019940
[01:23:42.161] iteration 10191 : loss : 0.058451, loss_ce: 0.024181
[01:23:42.459] iteration 10192 : loss : 0.106853, loss_ce: 0.016121
[01:23:42.757] iteration 10193 : loss : 0.075763, loss_ce: 0.018040
[01:23:43.055] iteration 10194 : loss : 0.075559, loss_ce: 0.009397
[01:23:43.355] iteration 10195 : loss : 0.072663, loss_ce: 0.015686
[01:23:43.653] iteration 10196 : loss : 0.041731, loss_ce: 0.007641
[01:23:43.956] iteration 10197 : loss : 0.052133, loss_ce: 0.019905
[01:23:44.254] iteration 10198 : loss : 0.039811, loss_ce: 0.011078
[01:23:44.557] iteration 10199 : loss : 0.051239, loss_ce: 0.028405
[01:23:44.855] iteration 10200 : loss : 0.110289, loss_ce: 0.013782
[01:23:45.172] iteration 10201 : loss : 0.115347, loss_ce: 0.018886
[01:23:45.468] iteration 10202 : loss : 0.063303, loss_ce: 0.023977
[01:23:45.765] iteration 10203 : loss : 0.079210, loss_ce: 0.011602
[01:23:46.061] iteration 10204 : loss : 0.056143, loss_ce: 0.020230
[01:23:46.360] iteration 10205 : loss : 0.105187, loss_ce: 0.008822
[01:23:46.659] iteration 10206 : loss : 0.056201, loss_ce: 0.015614
[01:23:46.953] iteration 10207 : loss : 0.045935, loss_ce: 0.010651
[01:23:47.247] iteration 10208 : loss : 0.137595, loss_ce: 0.014276
[01:23:47.546] iteration 10209 : loss : 0.069191, loss_ce: 0.021055
[01:23:47.842] iteration 10210 : loss : 0.070750, loss_ce: 0.018379
[01:23:48.133] iteration 10211 : loss : 0.059982, loss_ce: 0.015520
[01:23:48.431] iteration 10212 : loss : 0.054435, loss_ce: 0.021255
[01:23:48.727] iteration 10213 : loss : 0.047908, loss_ce: 0.010690
[01:23:49.027] iteration 10214 : loss : 0.055197, loss_ce: 0.014961
[01:23:49.330] iteration 10215 : loss : 0.075890, loss_ce: 0.039686
[01:23:49.629] iteration 10216 : loss : 0.054649, loss_ce: 0.017967
[01:23:49.927] iteration 10217 : loss : 0.062311, loss_ce: 0.014449
[01:23:50.225] iteration 10218 : loss : 0.056771, loss_ce: 0.014643
[01:23:50.524] iteration 10219 : loss : 0.056880, loss_ce: 0.014721
[01:23:50.829] iteration 10220 : loss : 0.111424, loss_ce: 0.010572
[01:23:51.144] iteration 10221 : loss : 0.049092, loss_ce: 0.022376
[01:23:51.439] iteration 10222 : loss : 0.117737, loss_ce: 0.010619
[01:23:51.733] iteration 10223 : loss : 0.062539, loss_ce: 0.020514
[01:23:52.030] iteration 10224 : loss : 0.058639, loss_ce: 0.021503
[01:23:52.323] iteration 10225 : loss : 0.094878, loss_ce: 0.007238
[01:23:52.616] iteration 10226 : loss : 0.063557, loss_ce: 0.014372
[01:23:52.910] iteration 10227 : loss : 0.055908, loss_ce: 0.023090
[01:23:53.203] iteration 10228 : loss : 0.101915, loss_ce: 0.009834
[01:23:53.499] iteration 10229 : loss : 0.062461, loss_ce: 0.021486
[01:23:53.795] iteration 10230 : loss : 0.059139, loss_ce: 0.008134
[01:23:54.088] iteration 10231 : loss : 0.053503, loss_ce: 0.022965
[01:23:54.383] iteration 10232 : loss : 0.075809, loss_ce: 0.014704
[01:23:54.681] iteration 10233 : loss : 0.063754, loss_ce: 0.017992
[01:23:54.976] iteration 10234 : loss : 0.061798, loss_ce: 0.015369
[01:23:55.271] iteration 10235 : loss : 0.055768, loss_ce: 0.010596
[01:23:55.563] iteration 10236 : loss : 0.042736, loss_ce: 0.019703
[01:23:55.855] iteration 10237 : loss : 0.048349, loss_ce: 0.018697
[01:23:56.149] iteration 10238 : loss : 0.046649, loss_ce: 0.015668
[01:23:56.445] iteration 10239 : loss : 0.116137, loss_ce: 0.017647
[01:23:56.739] iteration 10240 : loss : 0.057195, loss_ce: 0.020872
[01:23:57.049] iteration 10241 : loss : 0.090491, loss_ce: 0.015342
[01:23:57.339] iteration 10242 : loss : 0.053680, loss_ce: 0.016805
[01:23:57.633] iteration 10243 : loss : 0.067219, loss_ce: 0.006954
[01:23:57.927] iteration 10244 : loss : 0.043634, loss_ce: 0.012200
[01:23:58.221] iteration 10245 : loss : 0.058883, loss_ce: 0.029426
[01:23:58.512] iteration 10246 : loss : 0.052545, loss_ce: 0.017436
[01:23:58.806] iteration 10247 : loss : 0.044789, loss_ce: 0.012671
[01:23:59.101] iteration 10248 : loss : 0.063695, loss_ce: 0.024342
[01:23:59.395] iteration 10249 : loss : 0.056300, loss_ce: 0.008198
[01:23:59.691] iteration 10250 : loss : 0.065907, loss_ce: 0.020485
[01:23:59.982] iteration 10251 : loss : 0.054487, loss_ce: 0.010427
[01:24:00.277] iteration 10252 : loss : 0.121621, loss_ce: 0.013387
[01:24:00.569] iteration 10253 : loss : 0.067464, loss_ce: 0.018543
[01:24:00.860] iteration 10254 : loss : 0.093972, loss_ce: 0.020869
[01:24:01.155] iteration 10255 : loss : 0.066815, loss_ce: 0.025386
[01:24:01.449] iteration 10256 : loss : 0.081101, loss_ce: 0.010320
[01:24:01.743] iteration 10257 : loss : 0.051796, loss_ce: 0.022880
[01:24:02.039] iteration 10258 : loss : 0.051320, loss_ce: 0.011807
[01:24:02.332] iteration 10259 : loss : 0.043972, loss_ce: 0.008685
[01:24:02.625] iteration 10260 : loss : 0.184361, loss_ce: 0.006714
[01:24:02.934] iteration 10261 : loss : 0.221367, loss_ce: 0.007009
[01:24:03.227] iteration 10262 : loss : 0.114539, loss_ce: 0.022971
[01:24:03.522] iteration 10263 : loss : 0.093897, loss_ce: 0.017503
[01:24:03.814] iteration 10264 : loss : 0.051596, loss_ce: 0.017026
[01:24:04.116] iteration 10265 : loss : 0.058871, loss_ce: 0.019292
[01:24:04.415] iteration 10266 : loss : 0.051289, loss_ce: 0.008658
[01:24:04.716] iteration 10267 : loss : 0.058426, loss_ce: 0.019425
[01:24:05.018] iteration 10268 : loss : 0.061965, loss_ce: 0.017977
[01:24:05.320] iteration 10269 : loss : 0.063411, loss_ce: 0.022353
[01:24:05.622] iteration 10270 : loss : 0.059366, loss_ce: 0.018879
[01:24:05.927] iteration 10271 : loss : 0.069021, loss_ce: 0.024978
[01:24:06.232] iteration 10272 : loss : 0.058805, loss_ce: 0.013669
[01:24:06.536] iteration 10273 : loss : 0.045480, loss_ce: 0.017358
[01:24:06.838] iteration 10274 : loss : 0.060598, loss_ce: 0.018506
[01:24:07.139] iteration 10275 : loss : 0.057227, loss_ce: 0.015241
[01:24:07.436] iteration 10276 : loss : 0.106685, loss_ce: 0.014648
[01:24:07.736] iteration 10277 : loss : 0.060720, loss_ce: 0.015217
[01:24:08.033] iteration 10278 : loss : 0.101549, loss_ce: 0.005778
[01:24:08.334] iteration 10279 : loss : 0.112251, loss_ce: 0.011370
[01:24:08.633] iteration 10280 : loss : 0.052394, loss_ce: 0.017999
[01:24:08.945] iteration 10281 : loss : 0.040614, loss_ce: 0.011134
[01:24:09.247] iteration 10282 : loss : 0.131287, loss_ce: 0.008995
[01:24:09.551] iteration 10283 : loss : 0.057729, loss_ce: 0.013040
[01:24:09.856] iteration 10284 : loss : 0.050880, loss_ce: 0.022963
[01:24:10.161] iteration 10285 : loss : 0.061033, loss_ce: 0.020510
[01:24:10.242] iteration 10286 : loss : 0.406602, loss_ce: 0.005438
[01:24:31.697] iteration 10287 : loss : 0.110470, loss_ce: 0.011407
[01:24:31.995] iteration 10288 : loss : 0.101638, loss_ce: 0.017130
[01:24:32.286] iteration 10289 : loss : 0.049230, loss_ce: 0.006691
[01:24:32.579] iteration 10290 : loss : 0.060705, loss_ce: 0.012489
[01:24:32.873] iteration 10291 : loss : 0.067863, loss_ce: 0.018639
[01:24:33.166] iteration 10292 : loss : 0.109913, loss_ce: 0.016684
[01:24:33.457] iteration 10293 : loss : 0.050172, loss_ce: 0.016039
[01:24:33.749] iteration 10294 : loss : 0.123533, loss_ce: 0.016621
[01:24:34.041] iteration 10295 : loss : 0.048713, loss_ce: 0.008076
[01:24:34.339] iteration 10296 : loss : 0.169628, loss_ce: 0.008013
[01:24:34.630] iteration 10297 : loss : 0.051507, loss_ce: 0.024272
[01:24:34.928] iteration 10298 : loss : 0.067587, loss_ce: 0.024482
[01:24:35.219] iteration 10299 : loss : 0.058152, loss_ce: 0.025850
[01:24:35.512] iteration 10300 : loss : 0.061877, loss_ce: 0.018012
[01:24:35.826] iteration 10301 : loss : 0.113240, loss_ce: 0.009865
[01:24:36.122] iteration 10302 : loss : 0.071093, loss_ce: 0.013125
[01:24:36.416] iteration 10303 : loss : 0.094415, loss_ce: 0.009020
[01:24:36.707] iteration 10304 : loss : 0.058698, loss_ce: 0.018994
[01:24:37.003] iteration 10305 : loss : 0.050969, loss_ce: 0.014237
[01:24:37.298] iteration 10306 : loss : 0.049496, loss_ce: 0.015248
[01:24:37.595] iteration 10307 : loss : 0.112397, loss_ce: 0.016137
[01:24:37.892] iteration 10308 : loss : 0.046718, loss_ce: 0.008902
[01:24:38.190] iteration 10309 : loss : 0.048895, loss_ce: 0.016404
[01:24:38.487] iteration 10310 : loss : 0.049762, loss_ce: 0.017311
[01:24:38.783] iteration 10311 : loss : 0.057313, loss_ce: 0.018887
[01:24:39.078] iteration 10312 : loss : 0.047263, loss_ce: 0.022944
[01:24:39.373] iteration 10313 : loss : 0.076721, loss_ce: 0.013889
[01:24:39.667] iteration 10314 : loss : 0.114947, loss_ce: 0.021552
[01:24:39.963] iteration 10315 : loss : 0.124492, loss_ce: 0.019665
[01:24:40.261] iteration 10316 : loss : 0.048231, loss_ce: 0.015682
[01:24:40.559] iteration 10317 : loss : 0.050612, loss_ce: 0.018023
[01:24:40.855] iteration 10318 : loss : 0.055885, loss_ce: 0.013242
[01:24:41.154] iteration 10319 : loss : 0.101723, loss_ce: 0.013048
[01:24:41.452] iteration 10320 : loss : 0.103890, loss_ce: 0.014420
[01:24:41.767] iteration 10321 : loss : 0.057556, loss_ce: 0.022231
[01:24:42.063] iteration 10322 : loss : 0.049123, loss_ce: 0.013435
[01:24:42.359] iteration 10323 : loss : 0.056248, loss_ce: 0.013821
[01:24:42.656] iteration 10324 : loss : 0.061234, loss_ce: 0.020208
[01:24:42.952] iteration 10325 : loss : 0.090376, loss_ce: 0.013824
[01:24:43.249] iteration 10326 : loss : 0.066827, loss_ce: 0.027781
[01:24:43.546] iteration 10327 : loss : 0.111059, loss_ce: 0.014213
[01:24:43.847] iteration 10328 : loss : 0.049205, loss_ce: 0.013830
[01:24:44.144] iteration 10329 : loss : 0.059056, loss_ce: 0.012202
[01:24:44.437] iteration 10330 : loss : 0.058020, loss_ce: 0.013657
[01:24:44.734] iteration 10331 : loss : 0.108210, loss_ce: 0.010460
[01:24:45.032] iteration 10332 : loss : 0.045974, loss_ce: 0.014230
[01:24:45.331] iteration 10333 : loss : 0.086431, loss_ce: 0.012392
[01:24:45.626] iteration 10334 : loss : 0.049335, loss_ce: 0.022917
[01:24:45.925] iteration 10335 : loss : 0.052161, loss_ce: 0.023144
[01:24:46.224] iteration 10336 : loss : 0.050646, loss_ce: 0.013678
[01:24:46.523] iteration 10337 : loss : 0.050316, loss_ce: 0.017816
[01:24:46.820] iteration 10338 : loss : 0.046390, loss_ce: 0.014744
[01:24:47.116] iteration 10339 : loss : 0.049629, loss_ce: 0.011378
[01:24:47.413] iteration 10340 : loss : 0.088885, loss_ce: 0.016339
[01:24:47.730] iteration 10341 : loss : 0.106374, loss_ce: 0.012893
[01:24:48.023] iteration 10342 : loss : 0.054513, loss_ce: 0.005992
[01:24:48.322] iteration 10343 : loss : 0.068686, loss_ce: 0.015087
[01:24:48.625] iteration 10344 : loss : 0.055883, loss_ce: 0.018834
[01:24:48.925] iteration 10345 : loss : 0.042779, loss_ce: 0.018672
[01:24:49.223] iteration 10346 : loss : 0.106111, loss_ce: 0.009524
[01:24:49.521] iteration 10347 : loss : 0.048656, loss_ce: 0.018819
[01:24:49.818] iteration 10348 : loss : 0.090190, loss_ce: 0.020023
[01:24:50.112] iteration 10349 : loss : 0.049825, loss_ce: 0.018418
[01:24:50.413] iteration 10350 : loss : 0.046724, loss_ce: 0.023611
[01:24:50.711] iteration 10351 : loss : 0.045927, loss_ce: 0.009239
[01:24:51.011] iteration 10352 : loss : 0.048069, loss_ce: 0.011617
[01:24:51.309] iteration 10353 : loss : 0.048971, loss_ce: 0.009992
[01:24:51.613] iteration 10354 : loss : 0.050728, loss_ce: 0.016697
[01:24:51.912] iteration 10355 : loss : 0.041010, loss_ce: 0.011715
[01:24:52.208] iteration 10356 : loss : 0.050189, loss_ce: 0.014089
[01:24:52.502] iteration 10357 : loss : 0.109522, loss_ce: 0.011737
[01:24:52.805] iteration 10358 : loss : 0.157978, loss_ce: 0.006235
[01:24:53.103] iteration 10359 : loss : 0.062294, loss_ce: 0.011707
[01:24:53.403] iteration 10360 : loss : 0.076301, loss_ce: 0.019933
[01:24:53.717] iteration 10361 : loss : 0.104594, loss_ce: 0.011282
[01:24:54.013] iteration 10362 : loss : 0.058164, loss_ce: 0.024512
[01:24:54.312] iteration 10363 : loss : 0.053230, loss_ce: 0.020385
[01:24:54.612] iteration 10364 : loss : 0.050663, loss_ce: 0.014752
[01:24:54.909] iteration 10365 : loss : 0.051289, loss_ce: 0.013684
[01:24:55.207] iteration 10366 : loss : 0.056423, loss_ce: 0.018264
[01:24:55.508] iteration 10367 : loss : 0.083283, loss_ce: 0.010795
[01:24:55.806] iteration 10368 : loss : 0.054483, loss_ce: 0.016320
[01:24:56.107] iteration 10369 : loss : 0.112964, loss_ce: 0.018400
[01:24:56.402] iteration 10370 : loss : 0.057426, loss_ce: 0.011739
[01:24:56.696] iteration 10371 : loss : 0.060319, loss_ce: 0.009797
[01:24:56.992] iteration 10372 : loss : 0.044234, loss_ce: 0.020480
[01:24:57.286] iteration 10373 : loss : 0.156592, loss_ce: 0.012049
[01:24:57.576] iteration 10374 : loss : 0.064677, loss_ce: 0.022233
[01:24:57.872] iteration 10375 : loss : 0.050400, loss_ce: 0.015440
[01:24:58.166] iteration 10376 : loss : 0.050021, loss_ce: 0.026715
[01:24:58.460] iteration 10377 : loss : 0.067397, loss_ce: 0.015139
[01:24:58.755] iteration 10378 : loss : 0.049476, loss_ce: 0.018342
[01:24:59.047] iteration 10379 : loss : 0.048233, loss_ce: 0.015808
[01:24:59.345] iteration 10380 : loss : 0.108975, loss_ce: 0.019390
[01:24:59.651] iteration 10381 : loss : 0.062984, loss_ce: 0.020977
[01:24:59.942] iteration 10382 : loss : 0.042843, loss_ce: 0.010551
[01:25:00.236] iteration 10383 : loss : 0.128923, loss_ce: 0.010487
[01:25:00.540] iteration 10384 : loss : 0.056459, loss_ce: 0.016268
[01:25:00.833] iteration 10385 : loss : 0.069362, loss_ce: 0.020138
[01:25:01.128] iteration 10386 : loss : 0.070593, loss_ce: 0.023538
[01:25:01.421] iteration 10387 : loss : 0.054063, loss_ce: 0.010521
[01:25:01.711] iteration 10388 : loss : 0.079076, loss_ce: 0.015442
[01:25:02.005] iteration 10389 : loss : 0.120380, loss_ce: 0.008263
[01:25:02.298] iteration 10390 : loss : 0.051217, loss_ce: 0.021748
[01:25:02.590] iteration 10391 : loss : 0.061530, loss_ce: 0.022534
[01:25:02.885] iteration 10392 : loss : 0.191825, loss_ce: 0.010272
[01:25:03.177] iteration 10393 : loss : 0.058782, loss_ce: 0.019736
[01:25:03.470] iteration 10394 : loss : 0.054105, loss_ce: 0.021174
[01:25:03.761] iteration 10395 : loss : 0.054513, loss_ce: 0.015852
[01:25:04.060] iteration 10396 : loss : 0.079689, loss_ce: 0.018156
[01:25:04.354] iteration 10397 : loss : 0.059213, loss_ce: 0.022350
[01:25:04.646] iteration 10398 : loss : 0.049624, loss_ce: 0.011636
[01:25:04.941] iteration 10399 : loss : 0.045942, loss_ce: 0.018542
[01:25:05.237] iteration 10400 : loss : 0.158686, loss_ce: 0.004043
[01:25:05.550] iteration 10401 : loss : 0.116394, loss_ce: 0.012984
[01:25:05.840] iteration 10402 : loss : 0.059282, loss_ce: 0.016257
[01:25:06.139] iteration 10403 : loss : 0.051522, loss_ce: 0.017574
[01:25:06.433] iteration 10404 : loss : 0.045711, loss_ce: 0.017291
[01:25:06.726] iteration 10405 : loss : 0.061072, loss_ce: 0.022146
[01:25:07.018] iteration 10406 : loss : 0.041913, loss_ce: 0.015179
[01:25:07.312] iteration 10407 : loss : 0.056431, loss_ce: 0.010727
[01:25:07.603] iteration 10408 : loss : 0.198083, loss_ce: 0.007339
[01:25:07.904] iteration 10409 : loss : 0.055512, loss_ce: 0.011987
[01:25:08.199] iteration 10410 : loss : 0.075646, loss_ce: 0.021424
[01:25:08.496] iteration 10411 : loss : 0.062058, loss_ce: 0.021691
[01:25:08.801] iteration 10412 : loss : 0.054501, loss_ce: 0.013439
[01:25:09.104] iteration 10413 : loss : 0.061227, loss_ce: 0.019106
[01:25:09.411] iteration 10414 : loss : 0.041942, loss_ce: 0.012397
[01:25:09.713] iteration 10415 : loss : 0.092847, loss_ce: 0.011018
[01:25:10.015] iteration 10416 : loss : 0.057267, loss_ce: 0.016277
[01:25:10.323] iteration 10417 : loss : 0.060929, loss_ce: 0.008611
[01:25:10.625] iteration 10418 : loss : 0.051693, loss_ce: 0.013883
[01:25:10.935] iteration 10419 : loss : 0.074185, loss_ce: 0.014610
[01:25:11.236] iteration 10420 : loss : 0.110968, loss_ce: 0.012563
[01:25:11.556] iteration 10421 : loss : 0.052973, loss_ce: 0.012367
[01:25:11.852] iteration 10422 : loss : 0.122316, loss_ce: 0.021793
[01:25:12.146] iteration 10423 : loss : 0.055557, loss_ce: 0.017787
[01:25:12.441] iteration 10424 : loss : 0.057457, loss_ce: 0.017899
[01:25:12.518] iteration 10425 : loss : 0.116997, loss_ce: 0.028989
[01:25:30.637] iteration 10426 : loss : 0.038042, loss_ce: 0.011328
[01:25:30.935] iteration 10427 : loss : 0.189164, loss_ce: 0.013727
[01:25:31.232] iteration 10428 : loss : 0.072371, loss_ce: 0.009817
[01:25:31.528] iteration 10429 : loss : 0.161186, loss_ce: 0.005615
[01:25:31.821] iteration 10430 : loss : 0.053657, loss_ce: 0.028340
[01:25:32.118] iteration 10431 : loss : 0.054226, loss_ce: 0.024789
[01:25:32.411] iteration 10432 : loss : 0.051660, loss_ce: 0.017507
[01:25:32.711] iteration 10433 : loss : 0.053353, loss_ce: 0.011589
[01:25:33.006] iteration 10434 : loss : 0.050877, loss_ce: 0.021213
[01:25:33.301] iteration 10435 : loss : 0.066058, loss_ce: 0.015943
[01:25:33.596] iteration 10436 : loss : 0.068790, loss_ce: 0.012680
[01:25:33.889] iteration 10437 : loss : 0.125870, loss_ce: 0.008600
[01:25:34.185] iteration 10438 : loss : 0.051651, loss_ce: 0.019527
[01:25:34.483] iteration 10439 : loss : 0.063632, loss_ce: 0.016104
[01:25:34.778] iteration 10440 : loss : 0.051546, loss_ce: 0.022101
[01:25:35.091] iteration 10441 : loss : 0.048965, loss_ce: 0.019903
[01:25:35.385] iteration 10442 : loss : 0.040383, loss_ce: 0.010510
[01:25:35.678] iteration 10443 : loss : 0.057434, loss_ce: 0.016262
[01:25:35.971] iteration 10444 : loss : 0.053155, loss_ce: 0.015481
[01:25:36.262] iteration 10445 : loss : 0.050598, loss_ce: 0.018565
[01:25:36.557] iteration 10446 : loss : 0.055101, loss_ce: 0.026988
[01:25:36.851] iteration 10447 : loss : 0.053125, loss_ce: 0.013274
[01:25:37.150] iteration 10448 : loss : 0.058026, loss_ce: 0.017513
[01:25:37.443] iteration 10449 : loss : 0.068801, loss_ce: 0.019286
[01:25:37.736] iteration 10450 : loss : 0.062463, loss_ce: 0.023504
[01:25:38.026] iteration 10451 : loss : 0.110251, loss_ce: 0.007287
[01:25:38.325] iteration 10452 : loss : 0.070308, loss_ce: 0.010824
[01:25:38.616] iteration 10453 : loss : 0.036845, loss_ce: 0.012249
[01:25:38.917] iteration 10454 : loss : 0.062360, loss_ce: 0.015382
[01:25:39.215] iteration 10455 : loss : 0.061109, loss_ce: 0.013698
[01:25:39.511] iteration 10456 : loss : 0.049694, loss_ce: 0.018441
[01:25:39.809] iteration 10457 : loss : 0.108491, loss_ce: 0.011272
[01:25:40.107] iteration 10458 : loss : 0.064686, loss_ce: 0.019199
[01:25:40.403] iteration 10459 : loss : 0.065081, loss_ce: 0.021077
[01:25:40.699] iteration 10460 : loss : 0.047623, loss_ce: 0.015501
[01:25:41.009] iteration 10461 : loss : 0.062587, loss_ce: 0.007532
[01:25:41.305] iteration 10462 : loss : 0.112330, loss_ce: 0.010988
[01:25:41.603] iteration 10463 : loss : 0.042609, loss_ce: 0.009405
[01:25:41.902] iteration 10464 : loss : 0.067311, loss_ce: 0.008772
[01:25:42.201] iteration 10465 : loss : 0.052141, loss_ce: 0.016561
[01:25:42.499] iteration 10466 : loss : 0.059893, loss_ce: 0.016119
[01:25:42.801] iteration 10467 : loss : 0.066305, loss_ce: 0.025489
[01:25:43.103] iteration 10468 : loss : 0.063579, loss_ce: 0.026218
[01:25:43.404] iteration 10469 : loss : 0.172925, loss_ce: 0.009886
[01:25:43.705] iteration 10470 : loss : 0.110170, loss_ce: 0.014222
[01:25:44.002] iteration 10471 : loss : 0.049293, loss_ce: 0.018178
[01:25:44.302] iteration 10472 : loss : 0.056942, loss_ce: 0.024305
[01:25:44.603] iteration 10473 : loss : 0.058120, loss_ce: 0.024310
[01:25:44.906] iteration 10474 : loss : 0.045182, loss_ce: 0.014414
[01:25:45.204] iteration 10475 : loss : 0.089065, loss_ce: 0.019160
[01:25:45.505] iteration 10476 : loss : 0.060482, loss_ce: 0.022757
[01:25:45.802] iteration 10477 : loss : 0.053352, loss_ce: 0.013703
[01:25:46.098] iteration 10478 : loss : 0.051875, loss_ce: 0.016183
[01:25:46.396] iteration 10479 : loss : 0.045001, loss_ce: 0.015427
[01:25:46.698] iteration 10480 : loss : 0.055443, loss_ce: 0.017518
[01:25:47.007] iteration 10481 : loss : 0.063676, loss_ce: 0.023756
[01:25:47.306] iteration 10482 : loss : 0.109072, loss_ce: 0.019822
[01:25:47.602] iteration 10483 : loss : 0.054093, loss_ce: 0.015859
[01:25:47.901] iteration 10484 : loss : 0.102138, loss_ce: 0.011054
[01:25:48.199] iteration 10485 : loss : 0.043289, loss_ce: 0.017079
[01:25:48.496] iteration 10486 : loss : 0.046290, loss_ce: 0.009677
[01:25:48.796] iteration 10487 : loss : 0.101503, loss_ce: 0.014510
[01:25:49.092] iteration 10488 : loss : 0.050650, loss_ce: 0.014293
[01:25:49.390] iteration 10489 : loss : 0.053056, loss_ce: 0.015206
[01:25:49.686] iteration 10490 : loss : 0.104370, loss_ce: 0.017909
[01:25:49.984] iteration 10491 : loss : 0.054892, loss_ce: 0.014982
[01:25:50.281] iteration 10492 : loss : 0.049532, loss_ce: 0.006605
[01:25:50.579] iteration 10493 : loss : 0.054623, loss_ce: 0.010208
[01:25:50.873] iteration 10494 : loss : 0.054431, loss_ce: 0.019160
[01:25:51.170] iteration 10495 : loss : 0.066307, loss_ce: 0.017894
[01:25:51.464] iteration 10496 : loss : 0.057453, loss_ce: 0.009643
[01:25:51.762] iteration 10497 : loss : 0.067934, loss_ce: 0.006522
[01:25:52.060] iteration 10498 : loss : 0.049443, loss_ce: 0.017254
[01:25:52.359] iteration 10499 : loss : 0.165415, loss_ce: 0.014354
[01:25:52.654] iteration 10500 : loss : 0.048799, loss_ce: 0.011179
[01:25:52.969] iteration 10501 : loss : 0.051013, loss_ce: 0.015845
[01:25:53.268] iteration 10502 : loss : 0.056427, loss_ce: 0.012561
[01:25:53.565] iteration 10503 : loss : 0.114772, loss_ce: 0.014400
[01:25:53.861] iteration 10504 : loss : 0.129248, loss_ce: 0.014659
[01:25:54.159] iteration 10505 : loss : 0.051828, loss_ce: 0.012215
[01:25:54.459] iteration 10506 : loss : 0.111858, loss_ce: 0.021132
[01:25:54.756] iteration 10507 : loss : 0.043545, loss_ce: 0.012869
[01:25:55.056] iteration 10508 : loss : 0.104751, loss_ce: 0.007660
[01:25:55.356] iteration 10509 : loss : 0.054201, loss_ce: 0.020886
[01:25:55.651] iteration 10510 : loss : 0.070317, loss_ce: 0.020889
[01:25:55.952] iteration 10511 : loss : 0.051925, loss_ce: 0.022474
[01:25:56.253] iteration 10512 : loss : 0.041944, loss_ce: 0.010535
[01:25:56.550] iteration 10513 : loss : 0.048175, loss_ce: 0.024835
[01:25:56.843] iteration 10514 : loss : 0.045142, loss_ce: 0.011665
[01:25:57.139] iteration 10515 : loss : 0.096951, loss_ce: 0.017333
[01:25:57.436] iteration 10516 : loss : 0.229298, loss_ce: 0.018137
[01:25:57.730] iteration 10517 : loss : 0.111957, loss_ce: 0.006833
[01:25:58.028] iteration 10518 : loss : 0.052738, loss_ce: 0.021159
[01:25:58.323] iteration 10519 : loss : 0.108753, loss_ce: 0.017941
[01:25:58.625] iteration 10520 : loss : 0.063637, loss_ce: 0.023995
[01:25:58.937] iteration 10521 : loss : 0.175855, loss_ce: 0.008184
[01:25:59.234] iteration 10522 : loss : 0.056102, loss_ce: 0.014693
[01:25:59.533] iteration 10523 : loss : 0.111569, loss_ce: 0.014352
[01:25:59.829] iteration 10524 : loss : 0.062302, loss_ce: 0.014944
[01:26:00.126] iteration 10525 : loss : 0.052931, loss_ce: 0.018566
[01:26:00.426] iteration 10526 : loss : 0.090103, loss_ce: 0.015492
[01:26:00.725] iteration 10527 : loss : 0.074392, loss_ce: 0.031289
[01:26:01.022] iteration 10528 : loss : 0.114935, loss_ce: 0.009696
[01:26:01.319] iteration 10529 : loss : 0.059789, loss_ce: 0.014477
[01:26:01.612] iteration 10530 : loss : 0.062189, loss_ce: 0.018889
[01:26:01.902] iteration 10531 : loss : 0.061061, loss_ce: 0.010809
[01:26:02.198] iteration 10532 : loss : 0.091208, loss_ce: 0.022410
[01:26:02.492] iteration 10533 : loss : 0.056572, loss_ce: 0.018139
[01:26:02.783] iteration 10534 : loss : 0.114104, loss_ce: 0.008851
[01:26:03.074] iteration 10535 : loss : 0.057865, loss_ce: 0.014742
[01:26:03.369] iteration 10536 : loss : 0.060601, loss_ce: 0.017412
[01:26:03.660] iteration 10537 : loss : 0.084129, loss_ce: 0.019735
[01:26:03.955] iteration 10538 : loss : 0.063570, loss_ce: 0.024317
[01:26:04.248] iteration 10539 : loss : 0.053914, loss_ce: 0.013560
[01:26:04.542] iteration 10540 : loss : 0.100905, loss_ce: 0.011801
[01:26:04.857] iteration 10541 : loss : 0.053099, loss_ce: 0.020628
[01:26:05.147] iteration 10542 : loss : 0.057537, loss_ce: 0.022066
[01:26:05.437] iteration 10543 : loss : 0.050845, loss_ce: 0.013181
[01:26:05.731] iteration 10544 : loss : 0.045340, loss_ce: 0.014105
[01:26:06.021] iteration 10545 : loss : 0.071695, loss_ce: 0.005905
[01:26:06.314] iteration 10546 : loss : 0.043321, loss_ce: 0.013440
[01:26:06.612] iteration 10547 : loss : 0.054702, loss_ce: 0.021175
[01:26:06.909] iteration 10548 : loss : 0.051002, loss_ce: 0.021631
[01:26:07.207] iteration 10549 : loss : 0.106092, loss_ce: 0.013330
[01:26:07.510] iteration 10550 : loss : 0.159456, loss_ce: 0.012654
[01:26:07.816] iteration 10551 : loss : 0.043349, loss_ce: 0.006890
[01:26:08.114] iteration 10552 : loss : 0.056090, loss_ce: 0.014670
[01:26:08.418] iteration 10553 : loss : 0.047355, loss_ce: 0.015132
[01:26:08.718] iteration 10554 : loss : 0.105791, loss_ce: 0.004943
[01:26:09.013] iteration 10555 : loss : 0.045737, loss_ce: 0.014410
[01:26:09.313] iteration 10556 : loss : 0.046316, loss_ce: 0.014174
[01:26:09.606] iteration 10557 : loss : 0.170826, loss_ce: 0.006598
[01:26:09.901] iteration 10558 : loss : 0.058327, loss_ce: 0.012130
[01:26:10.201] iteration 10559 : loss : 0.044190, loss_ce: 0.013405
[01:26:10.502] iteration 10560 : loss : 0.067309, loss_ce: 0.010721
[01:26:10.818] iteration 10561 : loss : 0.097546, loss_ce: 0.016672
[01:26:11.115] iteration 10562 : loss : 0.059974, loss_ce: 0.022987
[01:26:11.412] iteration 10563 : loss : 0.054381, loss_ce: 0.017110
[01:26:11.494] iteration 10564 : loss : 0.179462, loss_ce: 0.009412
[01:26:32.035] iteration 10565 : loss : 0.052150, loss_ce: 0.010367
[01:26:32.329] iteration 10566 : loss : 0.053857, loss_ce: 0.025005
[01:26:32.627] iteration 10567 : loss : 0.088075, loss_ce: 0.013270
[01:26:32.920] iteration 10568 : loss : 0.061739, loss_ce: 0.009433
[01:26:33.217] iteration 10569 : loss : 0.112301, loss_ce: 0.017749
[01:26:33.508] iteration 10570 : loss : 0.060767, loss_ce: 0.026907
[01:26:33.800] iteration 10571 : loss : 0.060214, loss_ce: 0.018184
[01:26:34.090] iteration 10572 : loss : 0.107030, loss_ce: 0.018398
[01:26:34.382] iteration 10573 : loss : 0.156323, loss_ce: 0.004685
[01:26:34.673] iteration 10574 : loss : 0.043391, loss_ce: 0.017738
[01:26:34.965] iteration 10575 : loss : 0.058795, loss_ce: 0.005251
[01:26:35.258] iteration 10576 : loss : 0.054485, loss_ce: 0.014698
[01:26:35.552] iteration 10577 : loss : 0.105769, loss_ce: 0.009467
[01:26:35.844] iteration 10578 : loss : 0.065692, loss_ce: 0.010807
[01:26:36.135] iteration 10579 : loss : 0.050351, loss_ce: 0.022818
[01:26:36.425] iteration 10580 : loss : 0.057572, loss_ce: 0.019904
[01:26:36.739] iteration 10581 : loss : 0.115581, loss_ce: 0.009635
[01:26:37.036] iteration 10582 : loss : 0.039370, loss_ce: 0.009171
[01:26:37.325] iteration 10583 : loss : 0.064627, loss_ce: 0.017320
[01:26:37.616] iteration 10584 : loss : 0.068954, loss_ce: 0.014914
[01:26:37.911] iteration 10585 : loss : 0.073402, loss_ce: 0.021583
[01:26:38.202] iteration 10586 : loss : 0.060329, loss_ce: 0.024768
[01:26:38.498] iteration 10587 : loss : 0.046760, loss_ce: 0.013917
[01:26:38.793] iteration 10588 : loss : 0.066940, loss_ce: 0.013835
[01:26:39.086] iteration 10589 : loss : 0.057877, loss_ce: 0.018559
[01:26:39.377] iteration 10590 : loss : 0.090976, loss_ce: 0.020086
[01:26:39.670] iteration 10591 : loss : 0.063916, loss_ce: 0.024038
[01:26:39.965] iteration 10592 : loss : 0.050571, loss_ce: 0.016179
[01:26:40.256] iteration 10593 : loss : 0.057963, loss_ce: 0.017875
[01:26:40.548] iteration 10594 : loss : 0.048155, loss_ce: 0.019858
[01:26:40.839] iteration 10595 : loss : 0.160170, loss_ce: 0.014190
[01:26:41.132] iteration 10596 : loss : 0.357330, loss_ce: 0.005751
[01:26:41.423] iteration 10597 : loss : 0.064101, loss_ce: 0.014749
[01:26:41.714] iteration 10598 : loss : 0.048319, loss_ce: 0.014467
[01:26:42.003] iteration 10599 : loss : 0.049055, loss_ce: 0.016277
[01:26:42.297] iteration 10600 : loss : 0.046208, loss_ce: 0.016931
[01:26:42.611] iteration 10601 : loss : 0.051708, loss_ce: 0.023224
[01:26:42.906] iteration 10602 : loss : 0.045419, loss_ce: 0.012666
[01:26:43.195] iteration 10603 : loss : 0.098909, loss_ce: 0.007725
[01:26:43.488] iteration 10604 : loss : 0.060169, loss_ce: 0.022507
[01:26:43.781] iteration 10605 : loss : 0.042723, loss_ce: 0.005899
[01:26:44.079] iteration 10606 : loss : 0.049754, loss_ce: 0.010174
[01:26:44.377] iteration 10607 : loss : 0.063817, loss_ce: 0.018129
[01:26:44.674] iteration 10608 : loss : 0.050662, loss_ce: 0.022067
[01:26:44.976] iteration 10609 : loss : 0.059932, loss_ce: 0.008534
[01:26:45.273] iteration 10610 : loss : 0.104197, loss_ce: 0.012201
[01:26:45.573] iteration 10611 : loss : 0.063684, loss_ce: 0.024642
[01:26:45.873] iteration 10612 : loss : 0.047474, loss_ce: 0.021194
[01:26:46.169] iteration 10613 : loss : 0.054466, loss_ce: 0.020285
[01:26:46.464] iteration 10614 : loss : 0.103676, loss_ce: 0.015210
[01:26:46.762] iteration 10615 : loss : 0.060826, loss_ce: 0.013886
[01:26:47.054] iteration 10616 : loss : 0.071011, loss_ce: 0.013876
[01:26:47.346] iteration 10617 : loss : 0.051060, loss_ce: 0.013454
[01:26:47.639] iteration 10618 : loss : 0.052193, loss_ce: 0.017275
[01:26:47.933] iteration 10619 : loss : 0.057675, loss_ce: 0.019954
[01:26:48.226] iteration 10620 : loss : 0.119870, loss_ce: 0.012034
[01:26:48.533] iteration 10621 : loss : 0.049685, loss_ce: 0.015155
[01:26:48.829] iteration 10622 : loss : 0.168828, loss_ce: 0.007907
[01:26:49.122] iteration 10623 : loss : 0.116568, loss_ce: 0.017809
[01:26:49.417] iteration 10624 : loss : 0.060836, loss_ce: 0.018745
[01:26:49.715] iteration 10625 : loss : 0.117636, loss_ce: 0.012274
[01:26:50.011] iteration 10626 : loss : 0.115871, loss_ce: 0.010475
[01:26:50.304] iteration 10627 : loss : 0.047983, loss_ce: 0.011454
[01:26:50.600] iteration 10628 : loss : 0.044591, loss_ce: 0.016759
[01:26:50.895] iteration 10629 : loss : 0.054079, loss_ce: 0.023168
[01:26:51.188] iteration 10630 : loss : 0.106422, loss_ce: 0.014400
[01:26:51.481] iteration 10631 : loss : 0.081949, loss_ce: 0.015861
[01:26:51.772] iteration 10632 : loss : 0.049452, loss_ce: 0.005469
[01:26:52.067] iteration 10633 : loss : 0.044280, loss_ce: 0.018137
[01:26:52.364] iteration 10634 : loss : 0.081152, loss_ce: 0.009425
[01:26:52.657] iteration 10635 : loss : 0.054048, loss_ce: 0.021120
[01:26:52.951] iteration 10636 : loss : 0.069190, loss_ce: 0.017083
[01:26:53.245] iteration 10637 : loss : 0.066201, loss_ce: 0.023059
[01:26:53.540] iteration 10638 : loss : 0.107915, loss_ce: 0.009582
[01:26:53.838] iteration 10639 : loss : 0.059132, loss_ce: 0.024229
[01:26:54.134] iteration 10640 : loss : 0.044805, loss_ce: 0.017805
[01:26:54.443] iteration 10641 : loss : 0.050418, loss_ce: 0.016758
[01:26:54.738] iteration 10642 : loss : 0.042270, loss_ce: 0.008877
[01:26:55.033] iteration 10643 : loss : 0.056806, loss_ce: 0.010625
[01:26:55.329] iteration 10644 : loss : 0.054864, loss_ce: 0.021533
[01:26:55.623] iteration 10645 : loss : 0.077506, loss_ce: 0.013451
[01:26:55.916] iteration 10646 : loss : 0.037773, loss_ce: 0.010242
[01:26:56.210] iteration 10647 : loss : 0.037368, loss_ce: 0.015447
[01:26:56.503] iteration 10648 : loss : 0.111750, loss_ce: 0.016205
[01:26:56.794] iteration 10649 : loss : 0.107074, loss_ce: 0.015587
[01:26:57.092] iteration 10650 : loss : 0.107637, loss_ce: 0.014879
[01:26:57.383] iteration 10651 : loss : 0.056856, loss_ce: 0.019882
[01:26:57.674] iteration 10652 : loss : 0.047314, loss_ce: 0.017150
[01:26:57.968] iteration 10653 : loss : 0.104468, loss_ce: 0.016127
[01:26:58.261] iteration 10654 : loss : 0.120251, loss_ce: 0.011623
[01:26:58.552] iteration 10655 : loss : 0.093801, loss_ce: 0.018266
[01:26:58.852] iteration 10656 : loss : 0.052495, loss_ce: 0.017340
[01:26:59.152] iteration 10657 : loss : 0.048175, loss_ce: 0.013168
[01:26:59.450] iteration 10658 : loss : 0.060592, loss_ce: 0.020169
[01:26:59.747] iteration 10659 : loss : 0.061983, loss_ce: 0.012380
[01:27:00.042] iteration 10660 : loss : 0.049036, loss_ce: 0.024243
[01:27:00.356] iteration 10661 : loss : 0.056377, loss_ce: 0.016962
[01:27:00.651] iteration 10662 : loss : 0.052841, loss_ce: 0.013047
[01:27:00.947] iteration 10663 : loss : 0.053352, loss_ce: 0.013723
[01:27:01.249] iteration 10664 : loss : 0.102834, loss_ce: 0.007464
[01:27:01.551] iteration 10665 : loss : 0.057592, loss_ce: 0.023265
[01:27:01.847] iteration 10666 : loss : 0.051495, loss_ce: 0.011889
[01:27:02.146] iteration 10667 : loss : 0.063920, loss_ce: 0.011148
[01:27:02.443] iteration 10668 : loss : 0.054116, loss_ce: 0.015777
[01:27:02.739] iteration 10669 : loss : 0.175674, loss_ce: 0.015470
[01:27:03.037] iteration 10670 : loss : 0.116047, loss_ce: 0.012436
[01:27:03.334] iteration 10671 : loss : 0.042579, loss_ce: 0.013972
[01:27:03.631] iteration 10672 : loss : 0.115359, loss_ce: 0.017173
[01:27:03.930] iteration 10673 : loss : 0.050794, loss_ce: 0.014022
[01:27:04.227] iteration 10674 : loss : 0.045624, loss_ce: 0.008754
[01:27:04.531] iteration 10675 : loss : 0.060699, loss_ce: 0.022548
[01:27:04.830] iteration 10676 : loss : 0.054899, loss_ce: 0.017561
[01:27:05.128] iteration 10677 : loss : 0.057954, loss_ce: 0.023931
[01:27:05.420] iteration 10678 : loss : 0.050264, loss_ce: 0.013668
[01:27:05.718] iteration 10679 : loss : 0.104740, loss_ce: 0.008929
[01:27:06.016] iteration 10680 : loss : 0.124962, loss_ce: 0.012307
[01:27:06.338] iteration 10681 : loss : 0.045991, loss_ce: 0.015901
[01:27:06.637] iteration 10682 : loss : 0.049130, loss_ce: 0.015496
[01:27:06.935] iteration 10683 : loss : 0.045832, loss_ce: 0.009935
[01:27:07.234] iteration 10684 : loss : 0.055698, loss_ce: 0.025700
[01:27:07.533] iteration 10685 : loss : 0.056178, loss_ce: 0.012110
[01:27:07.828] iteration 10686 : loss : 0.044254, loss_ce: 0.013860
[01:27:08.129] iteration 10687 : loss : 0.045203, loss_ce: 0.016769
[01:27:08.437] iteration 10688 : loss : 0.051397, loss_ce: 0.015577
[01:27:08.734] iteration 10689 : loss : 0.058862, loss_ce: 0.014866
[01:27:09.045] iteration 10690 : loss : 0.047419, loss_ce: 0.020509
[01:27:09.349] iteration 10691 : loss : 0.058169, loss_ce: 0.020287
[01:27:09.651] iteration 10692 : loss : 0.097745, loss_ce: 0.007835
[01:27:09.951] iteration 10693 : loss : 0.098966, loss_ce: 0.011697
[01:27:10.257] iteration 10694 : loss : 0.112359, loss_ce: 0.013099
[01:27:10.558] iteration 10695 : loss : 0.062929, loss_ce: 0.014710
[01:27:10.857] iteration 10696 : loss : 0.052178, loss_ce: 0.024309
[01:27:11.165] iteration 10697 : loss : 0.047250, loss_ce: 0.017901
[01:27:11.470] iteration 10698 : loss : 0.048997, loss_ce: 0.014576
[01:27:11.778] iteration 10699 : loss : 0.065942, loss_ce: 0.014444
[01:27:12.086] iteration 10700 : loss : 0.078827, loss_ce: 0.010449
[01:27:12.423] iteration 10701 : loss : 0.204419, loss_ce: 0.012557
[01:27:12.723] iteration 10702 : loss : 0.053448, loss_ce: 0.011001
[01:27:12.810] iteration 10703 : loss : 0.395872, loss_ce: 0.002879
[01:27:30.831] iteration 10704 : loss : 0.108028, loss_ce: 0.010169
[01:27:31.130] iteration 10705 : loss : 0.045406, loss_ce: 0.013744
[01:27:31.425] iteration 10706 : loss : 0.045235, loss_ce: 0.014372
[01:27:31.729] iteration 10707 : loss : 0.050822, loss_ce: 0.015952
[01:27:32.031] iteration 10708 : loss : 0.106200, loss_ce: 0.009108
[01:27:32.326] iteration 10709 : loss : 0.050235, loss_ce: 0.011200
[01:27:32.622] iteration 10710 : loss : 0.059704, loss_ce: 0.024707
[01:27:32.915] iteration 10711 : loss : 0.060385, loss_ce: 0.015667
[01:27:33.215] iteration 10712 : loss : 0.114948, loss_ce: 0.011559
[01:27:33.511] iteration 10713 : loss : 0.046667, loss_ce: 0.018811
[01:27:33.806] iteration 10714 : loss : 0.078654, loss_ce: 0.020768
[01:27:34.105] iteration 10715 : loss : 0.105200, loss_ce: 0.014302
[01:27:34.402] iteration 10716 : loss : 0.134429, loss_ce: 0.005486
[01:27:34.700] iteration 10717 : loss : 0.052768, loss_ce: 0.018028
[01:27:34.999] iteration 10718 : loss : 0.053640, loss_ce: 0.022569
[01:27:35.301] iteration 10719 : loss : 0.049259, loss_ce: 0.011440
[01:27:35.600] iteration 10720 : loss : 0.050453, loss_ce: 0.016905
[01:27:35.923] iteration 10721 : loss : 0.046153, loss_ce: 0.015910
[01:27:36.219] iteration 10722 : loss : 0.118334, loss_ce: 0.014538
[01:27:36.519] iteration 10723 : loss : 0.092527, loss_ce: 0.016902
[01:27:36.815] iteration 10724 : loss : 0.104619, loss_ce: 0.006465
[01:27:37.109] iteration 10725 : loss : 0.129173, loss_ce: 0.009981
[01:27:37.406] iteration 10726 : loss : 0.079500, loss_ce: 0.017319
[01:27:37.696] iteration 10727 : loss : 0.190817, loss_ce: 0.007226
[01:27:37.989] iteration 10728 : loss : 0.060392, loss_ce: 0.020653
[01:27:38.284] iteration 10729 : loss : 0.057352, loss_ce: 0.026198
[01:27:38.579] iteration 10730 : loss : 0.053942, loss_ce: 0.014543
[01:27:38.878] iteration 10731 : loss : 0.054580, loss_ce: 0.007962
[01:27:39.177] iteration 10732 : loss : 0.048895, loss_ce: 0.013245
[01:27:39.471] iteration 10733 : loss : 0.061802, loss_ce: 0.019920
[01:27:39.766] iteration 10734 : loss : 0.052711, loss_ce: 0.007460
[01:27:40.064] iteration 10735 : loss : 0.043361, loss_ce: 0.015430
[01:27:40.361] iteration 10736 : loss : 0.080200, loss_ce: 0.014288
[01:27:40.656] iteration 10737 : loss : 0.110610, loss_ce: 0.024053
[01:27:40.951] iteration 10738 : loss : 0.048612, loss_ce: 0.023031
[01:27:41.246] iteration 10739 : loss : 0.061694, loss_ce: 0.017750
[01:27:41.544] iteration 10740 : loss : 0.057213, loss_ce: 0.014857
[01:27:41.856] iteration 10741 : loss : 0.059304, loss_ce: 0.019703
[01:27:42.147] iteration 10742 : loss : 0.054284, loss_ce: 0.015007
[01:27:42.441] iteration 10743 : loss : 0.073000, loss_ce: 0.010888
[01:27:42.737] iteration 10744 : loss : 0.070310, loss_ce: 0.017352
[01:27:43.032] iteration 10745 : loss : 0.036814, loss_ce: 0.009550
[01:27:43.330] iteration 10746 : loss : 0.038173, loss_ce: 0.008860
[01:27:43.627] iteration 10747 : loss : 0.067889, loss_ce: 0.013540
[01:27:43.921] iteration 10748 : loss : 0.053716, loss_ce: 0.019321
[01:27:44.220] iteration 10749 : loss : 0.063571, loss_ce: 0.017198
[01:27:44.513] iteration 10750 : loss : 0.048747, loss_ce: 0.012711
[01:27:44.812] iteration 10751 : loss : 0.058017, loss_ce: 0.021035
[01:27:45.108] iteration 10752 : loss : 0.053296, loss_ce: 0.020234
[01:27:45.404] iteration 10753 : loss : 0.058253, loss_ce: 0.019237
[01:27:45.704] iteration 10754 : loss : 0.048547, loss_ce: 0.020583
[01:27:46.006] iteration 10755 : loss : 0.056107, loss_ce: 0.015677
[01:27:46.300] iteration 10756 : loss : 0.052155, loss_ce: 0.013001
[01:27:46.595] iteration 10757 : loss : 0.063408, loss_ce: 0.014354
[01:27:46.889] iteration 10758 : loss : 0.052119, loss_ce: 0.016649
[01:27:47.181] iteration 10759 : loss : 0.075154, loss_ce: 0.009999
[01:27:47.476] iteration 10760 : loss : 0.044996, loss_ce: 0.013825
[01:27:47.784] iteration 10761 : loss : 0.118785, loss_ce: 0.007988
[01:27:48.074] iteration 10762 : loss : 0.074364, loss_ce: 0.011748
[01:27:48.367] iteration 10763 : loss : 0.046072, loss_ce: 0.017269
[01:27:48.662] iteration 10764 : loss : 0.114579, loss_ce: 0.012223
[01:27:48.954] iteration 10765 : loss : 0.107869, loss_ce: 0.018636
[01:27:49.250] iteration 10766 : loss : 0.125089, loss_ce: 0.014730
[01:27:49.548] iteration 10767 : loss : 0.062960, loss_ce: 0.015392
[01:27:49.844] iteration 10768 : loss : 0.054179, loss_ce: 0.014837
[01:27:50.136] iteration 10769 : loss : 0.054516, loss_ce: 0.017502
[01:27:50.431] iteration 10770 : loss : 0.056345, loss_ce: 0.021516
[01:27:50.728] iteration 10771 : loss : 0.108430, loss_ce: 0.012851
[01:27:51.026] iteration 10772 : loss : 0.049141, loss_ce: 0.013053
[01:27:51.319] iteration 10773 : loss : 0.078358, loss_ce: 0.021021
[01:27:51.617] iteration 10774 : loss : 0.052380, loss_ce: 0.013853
[01:27:51.913] iteration 10775 : loss : 0.049040, loss_ce: 0.020584
[01:27:52.209] iteration 10776 : loss : 0.044319, loss_ce: 0.013705
[01:27:52.509] iteration 10777 : loss : 0.108971, loss_ce: 0.019344
[01:27:52.809] iteration 10778 : loss : 0.109263, loss_ce: 0.012924
[01:27:53.109] iteration 10779 : loss : 0.043677, loss_ce: 0.020219
[01:27:53.406] iteration 10780 : loss : 0.054988, loss_ce: 0.025300
[01:27:53.721] iteration 10781 : loss : 0.054430, loss_ce: 0.018238
[01:27:54.017] iteration 10782 : loss : 0.041185, loss_ce: 0.011222
[01:27:54.313] iteration 10783 : loss : 0.072179, loss_ce: 0.016144
[01:27:54.609] iteration 10784 : loss : 0.110840, loss_ce: 0.007872
[01:27:54.910] iteration 10785 : loss : 0.060666, loss_ce: 0.013982
[01:27:55.209] iteration 10786 : loss : 0.111046, loss_ce: 0.024684
[01:27:55.504] iteration 10787 : loss : 0.111627, loss_ce: 0.018064
[01:27:55.806] iteration 10788 : loss : 0.046722, loss_ce: 0.013333
[01:27:56.104] iteration 10789 : loss : 0.049318, loss_ce: 0.016367
[01:27:56.404] iteration 10790 : loss : 0.059270, loss_ce: 0.012637
[01:27:56.699] iteration 10791 : loss : 0.048163, loss_ce: 0.025416
[01:27:56.995] iteration 10792 : loss : 0.039518, loss_ce: 0.015935
[01:27:57.298] iteration 10793 : loss : 0.039783, loss_ce: 0.015041
[01:27:57.600] iteration 10794 : loss : 0.046481, loss_ce: 0.016085
[01:27:57.898] iteration 10795 : loss : 0.050330, loss_ce: 0.020736
[01:27:58.197] iteration 10796 : loss : 0.080026, loss_ce: 0.010912
[01:27:58.499] iteration 10797 : loss : 0.041051, loss_ce: 0.007489
[01:27:58.795] iteration 10798 : loss : 0.094718, loss_ce: 0.018432
[01:27:59.097] iteration 10799 : loss : 0.120307, loss_ce: 0.014118
[01:27:59.394] iteration 10800 : loss : 0.077404, loss_ce: 0.016531
[01:27:59.703] iteration 10801 : loss : 0.058379, loss_ce: 0.015043
[01:28:00.000] iteration 10802 : loss : 0.120648, loss_ce: 0.014606
[01:28:00.298] iteration 10803 : loss : 0.107460, loss_ce: 0.012594
[01:28:00.595] iteration 10804 : loss : 0.107686, loss_ce: 0.016711
[01:28:00.897] iteration 10805 : loss : 0.055102, loss_ce: 0.010317
[01:28:01.201] iteration 10806 : loss : 0.051643, loss_ce: 0.013152
[01:28:01.502] iteration 10807 : loss : 0.050550, loss_ce: 0.017612
[01:28:01.798] iteration 10808 : loss : 0.068517, loss_ce: 0.020252
[01:28:02.094] iteration 10809 : loss : 0.052506, loss_ce: 0.016074
[01:28:02.388] iteration 10810 : loss : 0.051969, loss_ce: 0.020906
[01:28:02.685] iteration 10811 : loss : 0.054374, loss_ce: 0.020742
[01:28:02.986] iteration 10812 : loss : 0.037293, loss_ce: 0.012335
[01:28:03.282] iteration 10813 : loss : 0.052302, loss_ce: 0.020143
[01:28:03.580] iteration 10814 : loss : 0.106371, loss_ce: 0.006722
[01:28:03.879] iteration 10815 : loss : 0.051629, loss_ce: 0.020246
[01:28:04.179] iteration 10816 : loss : 0.055040, loss_ce: 0.012505
[01:28:04.479] iteration 10817 : loss : 0.102821, loss_ce: 0.014573
[01:28:04.779] iteration 10818 : loss : 0.163443, loss_ce: 0.008112
[01:28:05.078] iteration 10819 : loss : 0.056221, loss_ce: 0.013864
[01:28:05.375] iteration 10820 : loss : 0.059912, loss_ce: 0.010743
[01:28:05.684] iteration 10821 : loss : 0.151026, loss_ce: 0.013918
[01:28:05.981] iteration 10822 : loss : 0.115149, loss_ce: 0.019668
[01:28:06.280] iteration 10823 : loss : 0.035379, loss_ce: 0.008242
[01:28:06.578] iteration 10824 : loss : 0.100570, loss_ce: 0.016623
[01:28:06.872] iteration 10825 : loss : 0.052957, loss_ce: 0.012088
[01:28:07.182] iteration 10826 : loss : 0.057534, loss_ce: 0.011633
[01:28:07.483] iteration 10827 : loss : 0.048248, loss_ce: 0.017169
[01:28:07.784] iteration 10828 : loss : 0.053507, loss_ce: 0.020486
[01:28:08.086] iteration 10829 : loss : 0.055348, loss_ce: 0.014897
[01:28:08.387] iteration 10830 : loss : 0.045050, loss_ce: 0.020741
[01:28:08.692] iteration 10831 : loss : 0.089187, loss_ce: 0.015294
[01:28:08.996] iteration 10832 : loss : 0.069160, loss_ce: 0.015265
[01:28:09.301] iteration 10833 : loss : 0.145448, loss_ce: 0.013908
[01:28:09.604] iteration 10834 : loss : 0.118877, loss_ce: 0.014482
[01:28:09.906] iteration 10835 : loss : 0.046014, loss_ce: 0.014581
[01:28:10.213] iteration 10836 : loss : 0.062603, loss_ce: 0.014478
[01:28:10.522] iteration 10837 : loss : 0.052045, loss_ce: 0.025832
[01:28:10.827] iteration 10838 : loss : 0.063998, loss_ce: 0.015234
[01:28:11.128] iteration 10839 : loss : 0.080442, loss_ce: 0.017121
[01:28:11.426] iteration 10840 : loss : 0.055957, loss_ce: 0.020443
[01:28:11.743] iteration 10841 : loss : 0.054560, loss_ce: 0.023400
[01:28:11.825] iteration 10842 : loss : 0.106047, loss_ce: 0.019997
[01:28:33.051] iteration 10843 : loss : 0.166814, loss_ce: 0.007275
[01:28:33.343] iteration 10844 : loss : 0.109725, loss_ce: 0.013936
[01:28:33.641] iteration 10845 : loss : 0.117968, loss_ce: 0.009737
[01:28:33.942] iteration 10846 : loss : 0.052973, loss_ce: 0.014650
[01:28:34.239] iteration 10847 : loss : 0.096951, loss_ce: 0.016457
[01:28:34.533] iteration 10848 : loss : 0.055201, loss_ce: 0.017006
[01:28:34.827] iteration 10849 : loss : 0.050797, loss_ce: 0.016174
[01:28:35.115] iteration 10850 : loss : 0.045999, loss_ce: 0.020208
[01:28:35.411] iteration 10851 : loss : 0.053751, loss_ce: 0.009054
[01:28:35.701] iteration 10852 : loss : 0.169760, loss_ce: 0.010502
[01:28:35.995] iteration 10853 : loss : 0.047109, loss_ce: 0.016560
[01:28:36.288] iteration 10854 : loss : 0.076349, loss_ce: 0.010713
[01:28:36.579] iteration 10855 : loss : 0.047842, loss_ce: 0.019843
[01:28:36.876] iteration 10856 : loss : 0.107700, loss_ce: 0.010625
[01:28:37.169] iteration 10857 : loss : 0.118640, loss_ce: 0.010482
[01:28:37.462] iteration 10858 : loss : 0.115187, loss_ce: 0.018502
[01:28:37.754] iteration 10859 : loss : 0.059078, loss_ce: 0.014827
[01:28:38.045] iteration 10860 : loss : 0.069101, loss_ce: 0.014943
[01:28:38.351] iteration 10861 : loss : 0.074688, loss_ce: 0.026306
[01:28:38.646] iteration 10862 : loss : 0.065669, loss_ce: 0.011114
[01:28:38.939] iteration 10863 : loss : 0.048296, loss_ce: 0.016353
[01:28:39.236] iteration 10864 : loss : 0.230578, loss_ce: 0.014170
[01:28:39.531] iteration 10865 : loss : 0.114288, loss_ce: 0.011520
[01:28:39.830] iteration 10866 : loss : 0.060799, loss_ce: 0.015267
[01:28:40.129] iteration 10867 : loss : 0.051676, loss_ce: 0.015861
[01:28:40.427] iteration 10868 : loss : 0.059319, loss_ce: 0.011899
[01:28:40.726] iteration 10869 : loss : 0.065037, loss_ce: 0.011666
[01:28:41.022] iteration 10870 : loss : 0.050726, loss_ce: 0.016329
[01:28:41.316] iteration 10871 : loss : 0.038757, loss_ce: 0.015971
[01:28:41.607] iteration 10872 : loss : 0.037740, loss_ce: 0.005425
[01:28:41.899] iteration 10873 : loss : 0.115035, loss_ce: 0.017730
[01:28:42.189] iteration 10874 : loss : 0.055526, loss_ce: 0.013506
[01:28:42.485] iteration 10875 : loss : 0.112915, loss_ce: 0.017268
[01:28:42.781] iteration 10876 : loss : 0.063820, loss_ce: 0.011493
[01:28:43.072] iteration 10877 : loss : 0.084504, loss_ce: 0.011701
[01:28:43.361] iteration 10878 : loss : 0.046951, loss_ce: 0.015636
[01:28:43.652] iteration 10879 : loss : 0.054271, loss_ce: 0.027145
[01:28:43.948] iteration 10880 : loss : 0.108216, loss_ce: 0.014846
[01:28:44.262] iteration 10881 : loss : 0.045827, loss_ce: 0.022060
[01:28:44.553] iteration 10882 : loss : 0.061977, loss_ce: 0.019042
[01:28:44.848] iteration 10883 : loss : 0.070296, loss_ce: 0.023181
[01:28:45.141] iteration 10884 : loss : 0.116690, loss_ce: 0.011531
[01:28:45.433] iteration 10885 : loss : 0.046839, loss_ce: 0.010482
[01:28:45.728] iteration 10886 : loss : 0.061298, loss_ce: 0.023032
[01:28:46.016] iteration 10887 : loss : 0.044870, loss_ce: 0.021431
[01:28:46.307] iteration 10888 : loss : 0.050446, loss_ce: 0.018242
[01:28:46.601] iteration 10889 : loss : 0.052998, loss_ce: 0.028865
[01:28:46.896] iteration 10890 : loss : 0.058986, loss_ce: 0.014211
[01:28:47.190] iteration 10891 : loss : 0.116550, loss_ce: 0.019774
[01:28:47.482] iteration 10892 : loss : 0.102984, loss_ce: 0.009673
[01:28:47.776] iteration 10893 : loss : 0.096835, loss_ce: 0.009407
[01:28:48.070] iteration 10894 : loss : 0.060052, loss_ce: 0.016411
[01:28:48.364] iteration 10895 : loss : 0.103718, loss_ce: 0.008347
[01:28:48.658] iteration 10896 : loss : 0.047505, loss_ce: 0.018984
[01:28:48.954] iteration 10897 : loss : 0.054903, loss_ce: 0.018455
[01:28:49.243] iteration 10898 : loss : 0.045157, loss_ce: 0.017583
[01:28:49.540] iteration 10899 : loss : 0.074928, loss_ce: 0.014608
[01:28:49.837] iteration 10900 : loss : 0.109523, loss_ce: 0.011821
[01:28:50.153] iteration 10901 : loss : 0.052043, loss_ce: 0.015190
[01:28:50.447] iteration 10902 : loss : 0.071016, loss_ce: 0.029787
[01:28:50.742] iteration 10903 : loss : 0.052062, loss_ce: 0.019923
[01:28:51.034] iteration 10904 : loss : 0.061911, loss_ce: 0.017265
[01:28:51.324] iteration 10905 : loss : 0.053720, loss_ce: 0.017406
[01:28:51.619] iteration 10906 : loss : 0.049946, loss_ce: 0.008608
[01:28:51.908] iteration 10907 : loss : 0.105661, loss_ce: 0.010258
[01:28:52.195] iteration 10908 : loss : 0.047156, loss_ce: 0.018350
[01:28:52.490] iteration 10909 : loss : 0.059323, loss_ce: 0.018107
[01:28:52.783] iteration 10910 : loss : 0.108477, loss_ce: 0.005835
[01:28:53.079] iteration 10911 : loss : 0.041120, loss_ce: 0.022322
[01:28:53.371] iteration 10912 : loss : 0.052512, loss_ce: 0.023845
[01:28:53.667] iteration 10913 : loss : 0.058200, loss_ce: 0.024562
[01:28:53.955] iteration 10914 : loss : 0.035661, loss_ce: 0.004847
[01:28:54.258] iteration 10915 : loss : 0.080607, loss_ce: 0.017763
[01:28:54.556] iteration 10916 : loss : 0.118372, loss_ce: 0.017744
[01:28:54.851] iteration 10917 : loss : 0.064254, loss_ce: 0.020753
[01:28:55.146] iteration 10918 : loss : 0.043478, loss_ce: 0.012648
[01:28:55.441] iteration 10919 : loss : 0.055367, loss_ce: 0.021616
[01:28:55.736] iteration 10920 : loss : 0.102847, loss_ce: 0.011368
[01:28:56.046] iteration 10921 : loss : 0.063414, loss_ce: 0.015191
[01:28:56.341] iteration 10922 : loss : 0.055718, loss_ce: 0.013204
[01:28:56.637] iteration 10923 : loss : 0.049457, loss_ce: 0.012961
[01:28:56.935] iteration 10924 : loss : 0.056405, loss_ce: 0.014626
[01:28:57.237] iteration 10925 : loss : 0.062742, loss_ce: 0.015000
[01:28:57.533] iteration 10926 : loss : 0.050015, loss_ce: 0.012969
[01:28:57.831] iteration 10927 : loss : 0.065564, loss_ce: 0.012956
[01:28:58.127] iteration 10928 : loss : 0.047926, loss_ce: 0.011459
[01:28:58.426] iteration 10929 : loss : 0.064457, loss_ce: 0.018531
[01:28:58.721] iteration 10930 : loss : 0.053372, loss_ce: 0.012618
[01:28:59.017] iteration 10931 : loss : 0.050867, loss_ce: 0.015858
[01:28:59.315] iteration 10932 : loss : 0.224883, loss_ce: 0.009098
[01:28:59.613] iteration 10933 : loss : 0.057402, loss_ce: 0.019808
[01:28:59.909] iteration 10934 : loss : 0.067189, loss_ce: 0.014325
[01:29:00.207] iteration 10935 : loss : 0.059300, loss_ce: 0.016074
[01:29:00.504] iteration 10936 : loss : 0.045630, loss_ce: 0.016461
[01:29:00.800] iteration 10937 : loss : 0.139935, loss_ce: 0.015745
[01:29:01.095] iteration 10938 : loss : 0.064956, loss_ce: 0.023943
[01:29:01.391] iteration 10939 : loss : 0.053241, loss_ce: 0.012456
[01:29:01.691] iteration 10940 : loss : 0.064633, loss_ce: 0.018174
[01:29:02.013] iteration 10941 : loss : 0.059627, loss_ce: 0.015421
[01:29:02.309] iteration 10942 : loss : 0.116848, loss_ce: 0.015361
[01:29:02.604] iteration 10943 : loss : 0.054917, loss_ce: 0.020705
[01:29:02.904] iteration 10944 : loss : 0.045709, loss_ce: 0.019316
[01:29:03.202] iteration 10945 : loss : 0.054059, loss_ce: 0.017588
[01:29:03.500] iteration 10946 : loss : 0.061658, loss_ce: 0.009747
[01:29:03.795] iteration 10947 : loss : 0.112057, loss_ce: 0.005311
[01:29:04.094] iteration 10948 : loss : 0.065965, loss_ce: 0.012375
[01:29:04.394] iteration 10949 : loss : 0.064447, loss_ce: 0.020115
[01:29:04.692] iteration 10950 : loss : 0.054081, loss_ce: 0.018435
[01:29:04.990] iteration 10951 : loss : 0.067639, loss_ce: 0.025211
[01:29:05.289] iteration 10952 : loss : 0.104059, loss_ce: 0.008619
[01:29:05.590] iteration 10953 : loss : 0.065628, loss_ce: 0.019813
[01:29:05.888] iteration 10954 : loss : 0.157310, loss_ce: 0.005155
[01:29:06.188] iteration 10955 : loss : 0.091763, loss_ce: 0.014124
[01:29:06.486] iteration 10956 : loss : 0.060607, loss_ce: 0.015741
[01:29:06.781] iteration 10957 : loss : 0.058884, loss_ce: 0.013869
[01:29:07.078] iteration 10958 : loss : 0.136655, loss_ce: 0.008910
[01:29:07.374] iteration 10959 : loss : 0.047132, loss_ce: 0.006922
[01:29:07.670] iteration 10960 : loss : 0.105727, loss_ce: 0.011374
[01:29:07.984] iteration 10961 : loss : 0.064097, loss_ce: 0.016375
[01:29:08.283] iteration 10962 : loss : 0.058269, loss_ce: 0.014301
[01:29:08.579] iteration 10963 : loss : 0.037601, loss_ce: 0.013866
[01:29:08.877] iteration 10964 : loss : 0.121799, loss_ce: 0.014550
[01:29:09.183] iteration 10965 : loss : 0.047051, loss_ce: 0.020419
[01:29:09.482] iteration 10966 : loss : 0.066299, loss_ce: 0.014841
[01:29:09.784] iteration 10967 : loss : 0.056114, loss_ce: 0.020675
[01:29:10.086] iteration 10968 : loss : 0.120052, loss_ce: 0.018739
[01:29:10.388] iteration 10969 : loss : 0.066975, loss_ce: 0.020213
[01:29:10.694] iteration 10970 : loss : 0.055381, loss_ce: 0.014069
[01:29:10.993] iteration 10971 : loss : 0.065704, loss_ce: 0.018147
[01:29:11.292] iteration 10972 : loss : 0.056597, loss_ce: 0.019845
[01:29:11.593] iteration 10973 : loss : 0.062242, loss_ce: 0.017360
[01:29:11.898] iteration 10974 : loss : 0.048982, loss_ce: 0.021287
[01:29:12.199] iteration 10975 : loss : 0.115923, loss_ce: 0.015260
[01:29:12.499] iteration 10976 : loss : 0.063584, loss_ce: 0.021333
[01:29:12.800] iteration 10977 : loss : 0.041138, loss_ce: 0.011835
[01:29:13.104] iteration 10978 : loss : 0.055855, loss_ce: 0.019260
[01:29:13.406] iteration 10979 : loss : 0.172862, loss_ce: 0.010315
[01:29:13.708] iteration 10980 : loss : 0.035928, loss_ce: 0.012792
[01:29:13.823] iteration 10981 : loss : 0.080598, loss_ce: 0.037413
[01:29:31.196] iteration 10982 : loss : 0.050904, loss_ce: 0.017658
[01:29:31.495] iteration 10983 : loss : 0.062657, loss_ce: 0.012873
[01:29:31.790] iteration 10984 : loss : 0.072173, loss_ce: 0.022730
[01:29:32.085] iteration 10985 : loss : 0.047660, loss_ce: 0.014526
[01:29:32.380] iteration 10986 : loss : 0.222398, loss_ce: 0.009154
[01:29:32.674] iteration 10987 : loss : 0.050781, loss_ce: 0.009131
[01:29:32.968] iteration 10988 : loss : 0.063740, loss_ce: 0.009987
[01:29:33.265] iteration 10989 : loss : 0.105612, loss_ce: 0.010483
[01:29:33.565] iteration 10990 : loss : 0.046284, loss_ce: 0.015207
[01:29:33.858] iteration 10991 : loss : 0.059168, loss_ce: 0.017523
[01:29:34.154] iteration 10992 : loss : 0.058265, loss_ce: 0.012788
[01:29:34.452] iteration 10993 : loss : 0.043675, loss_ce: 0.019103
[01:29:34.740] iteration 10994 : loss : 0.114851, loss_ce: 0.017812
[01:29:35.032] iteration 10995 : loss : 0.077013, loss_ce: 0.018062
[01:29:35.330] iteration 10996 : loss : 0.108613, loss_ce: 0.007770
[01:29:35.625] iteration 10997 : loss : 0.065478, loss_ce: 0.024823
[01:29:35.921] iteration 10998 : loss : 0.039967, loss_ce: 0.016610
[01:29:36.218] iteration 10999 : loss : 0.043087, loss_ce: 0.018738
[01:29:36.514] iteration 11000 : loss : 0.098382, loss_ce: 0.010454
[01:29:36.827] iteration 11001 : loss : 0.109248, loss_ce: 0.009281
[01:29:37.124] iteration 11002 : loss : 0.060589, loss_ce: 0.025059
[01:29:37.419] iteration 11003 : loss : 0.060484, loss_ce: 0.019714
[01:29:37.712] iteration 11004 : loss : 0.038798, loss_ce: 0.009472
[01:29:38.004] iteration 11005 : loss : 0.051604, loss_ce: 0.008141
[01:29:38.295] iteration 11006 : loss : 0.067113, loss_ce: 0.008983
[01:29:38.587] iteration 11007 : loss : 0.058616, loss_ce: 0.025031
[01:29:38.884] iteration 11008 : loss : 0.051227, loss_ce: 0.022481
[01:29:39.177] iteration 11009 : loss : 0.056895, loss_ce: 0.019256
[01:29:39.474] iteration 11010 : loss : 0.059533, loss_ce: 0.026340
[01:29:39.769] iteration 11011 : loss : 0.108048, loss_ce: 0.015012
[01:29:40.064] iteration 11012 : loss : 0.048316, loss_ce: 0.029157
[01:29:40.356] iteration 11013 : loss : 0.051537, loss_ce: 0.011864
[01:29:40.648] iteration 11014 : loss : 0.101979, loss_ce: 0.005586
[01:29:40.945] iteration 11015 : loss : 0.048679, loss_ce: 0.017085
[01:29:41.239] iteration 11016 : loss : 0.055056, loss_ce: 0.016546
[01:29:41.532] iteration 11017 : loss : 0.060698, loss_ce: 0.020480
[01:29:41.824] iteration 11018 : loss : 0.097289, loss_ce: 0.015789
[01:29:42.122] iteration 11019 : loss : 0.056182, loss_ce: 0.018067
[01:29:42.415] iteration 11020 : loss : 0.223283, loss_ce: 0.002610
[01:29:42.727] iteration 11021 : loss : 0.050344, loss_ce: 0.012242
[01:29:43.024] iteration 11022 : loss : 0.051896, loss_ce: 0.014118
[01:29:43.320] iteration 11023 : loss : 0.048895, loss_ce: 0.013009
[01:29:43.615] iteration 11024 : loss : 0.044133, loss_ce: 0.014906
[01:29:43.913] iteration 11025 : loss : 0.058633, loss_ce: 0.019550
[01:29:44.207] iteration 11026 : loss : 0.043922, loss_ce: 0.006822
[01:29:44.502] iteration 11027 : loss : 0.164133, loss_ce: 0.011318
[01:29:44.797] iteration 11028 : loss : 0.054824, loss_ce: 0.020507
[01:29:45.093] iteration 11029 : loss : 0.114014, loss_ce: 0.010890
[01:29:45.390] iteration 11030 : loss : 0.047613, loss_ce: 0.010518
[01:29:45.682] iteration 11031 : loss : 0.088202, loss_ce: 0.018315
[01:29:45.979] iteration 11032 : loss : 0.051219, loss_ce: 0.012221
[01:29:46.275] iteration 11033 : loss : 0.049020, loss_ce: 0.016849
[01:29:46.571] iteration 11034 : loss : 0.049602, loss_ce: 0.017639
[01:29:46.864] iteration 11035 : loss : 0.107098, loss_ce: 0.008665
[01:29:47.160] iteration 11036 : loss : 0.050579, loss_ce: 0.021648
[01:29:47.453] iteration 11037 : loss : 0.045343, loss_ce: 0.013592
[01:29:47.752] iteration 11038 : loss : 0.046737, loss_ce: 0.008673
[01:29:48.051] iteration 11039 : loss : 0.052149, loss_ce: 0.009337
[01:29:48.347] iteration 11040 : loss : 0.048068, loss_ce: 0.023243
[01:29:48.661] iteration 11041 : loss : 0.296620, loss_ce: 0.001848
[01:29:48.957] iteration 11042 : loss : 0.151005, loss_ce: 0.011508
[01:29:49.259] iteration 11043 : loss : 0.050250, loss_ce: 0.014622
[01:29:49.555] iteration 11044 : loss : 0.036197, loss_ce: 0.008113
[01:29:49.852] iteration 11045 : loss : 0.048265, loss_ce: 0.017190
[01:29:50.151] iteration 11046 : loss : 0.056403, loss_ce: 0.021514
[01:29:50.445] iteration 11047 : loss : 0.045620, loss_ce: 0.012217
[01:29:50.740] iteration 11048 : loss : 0.056022, loss_ce: 0.014351
[01:29:51.039] iteration 11049 : loss : 0.059945, loss_ce: 0.023936
[01:29:51.336] iteration 11050 : loss : 0.085477, loss_ce: 0.014154
[01:29:51.633] iteration 11051 : loss : 0.074632, loss_ce: 0.013509
[01:29:51.931] iteration 11052 : loss : 0.049192, loss_ce: 0.013896
[01:29:52.225] iteration 11053 : loss : 0.156987, loss_ce: 0.006084
[01:29:52.521] iteration 11054 : loss : 0.064621, loss_ce: 0.018182
[01:29:52.820] iteration 11055 : loss : 0.063524, loss_ce: 0.018255
[01:29:53.117] iteration 11056 : loss : 0.048502, loss_ce: 0.013821
[01:29:53.418] iteration 11057 : loss : 0.055998, loss_ce: 0.022827
[01:29:53.718] iteration 11058 : loss : 0.050913, loss_ce: 0.026221
[01:29:54.014] iteration 11059 : loss : 0.050351, loss_ce: 0.025333
[01:29:54.313] iteration 11060 : loss : 0.106952, loss_ce: 0.008354
[01:29:54.629] iteration 11061 : loss : 0.066874, loss_ce: 0.025922
[01:29:54.926] iteration 11062 : loss : 0.036868, loss_ce: 0.011735
[01:29:55.225] iteration 11063 : loss : 0.063075, loss_ce: 0.015868
[01:29:55.527] iteration 11064 : loss : 0.055149, loss_ce: 0.024719
[01:29:55.825] iteration 11065 : loss : 0.063700, loss_ce: 0.013632
[01:29:56.129] iteration 11066 : loss : 0.118537, loss_ce: 0.012472
[01:29:56.426] iteration 11067 : loss : 0.036969, loss_ce: 0.008568
[01:29:56.722] iteration 11068 : loss : 0.167303, loss_ce: 0.019896
[01:29:57.019] iteration 11069 : loss : 0.071781, loss_ce: 0.008206
[01:29:57.315] iteration 11070 : loss : 0.056386, loss_ce: 0.013465
[01:29:57.612] iteration 11071 : loss : 0.065935, loss_ce: 0.016710
[01:29:57.915] iteration 11072 : loss : 0.060505, loss_ce: 0.020756
[01:29:58.213] iteration 11073 : loss : 0.164099, loss_ce: 0.004998
[01:29:58.510] iteration 11074 : loss : 0.057003, loss_ce: 0.019679
[01:29:58.812] iteration 11075 : loss : 0.048896, loss_ce: 0.022535
[01:29:59.111] iteration 11076 : loss : 0.056573, loss_ce: 0.012706
[01:29:59.405] iteration 11077 : loss : 0.048864, loss_ce: 0.012668
[01:29:59.702] iteration 11078 : loss : 0.060768, loss_ce: 0.014826
[01:29:59.998] iteration 11079 : loss : 0.061975, loss_ce: 0.014424
[01:30:00.296] iteration 11080 : loss : 0.044570, loss_ce: 0.017000
[01:30:00.612] iteration 11081 : loss : 0.044396, loss_ce: 0.012140
[01:30:00.911] iteration 11082 : loss : 0.059036, loss_ce: 0.017140
[01:30:01.209] iteration 11083 : loss : 0.066440, loss_ce: 0.020712
[01:30:01.505] iteration 11084 : loss : 0.061986, loss_ce: 0.011158
[01:30:01.804] iteration 11085 : loss : 0.039351, loss_ce: 0.012839
[01:30:02.102] iteration 11086 : loss : 0.122850, loss_ce: 0.016125
[01:30:02.398] iteration 11087 : loss : 0.120182, loss_ce: 0.009242
[01:30:02.695] iteration 11088 : loss : 0.039332, loss_ce: 0.007161
[01:30:02.994] iteration 11089 : loss : 0.055236, loss_ce: 0.025553
[01:30:03.292] iteration 11090 : loss : 0.052292, loss_ce: 0.018404
[01:30:03.595] iteration 11091 : loss : 0.056607, loss_ce: 0.018099
[01:30:03.893] iteration 11092 : loss : 0.071067, loss_ce: 0.015375
[01:30:04.197] iteration 11093 : loss : 0.062182, loss_ce: 0.011369
[01:30:04.497] iteration 11094 : loss : 0.071956, loss_ce: 0.021490
[01:30:04.795] iteration 11095 : loss : 0.048940, loss_ce: 0.011464
[01:30:05.091] iteration 11096 : loss : 0.104262, loss_ce: 0.009891
[01:30:05.392] iteration 11097 : loss : 0.050213, loss_ce: 0.024212
[01:30:05.686] iteration 11098 : loss : 0.046250, loss_ce: 0.021082
[01:30:05.983] iteration 11099 : loss : 0.049031, loss_ce: 0.007636
[01:30:06.279] iteration 11100 : loss : 0.048160, loss_ce: 0.018206
[01:30:06.588] iteration 11101 : loss : 0.118131, loss_ce: 0.016069
[01:30:06.880] iteration 11102 : loss : 0.056176, loss_ce: 0.024100
[01:30:07.174] iteration 11103 : loss : 0.040759, loss_ce: 0.011776
[01:30:07.468] iteration 11104 : loss : 0.138526, loss_ce: 0.010002
[01:30:07.766] iteration 11105 : loss : 0.096045, loss_ce: 0.009986
[01:30:08.063] iteration 11106 : loss : 0.054826, loss_ce: 0.005721
[01:30:08.364] iteration 11107 : loss : 0.063797, loss_ce: 0.027359
[01:30:08.664] iteration 11108 : loss : 0.073023, loss_ce: 0.014548
[01:30:08.966] iteration 11109 : loss : 0.077470, loss_ce: 0.008996
[01:30:09.268] iteration 11110 : loss : 0.053930, loss_ce: 0.011702
[01:30:09.571] iteration 11111 : loss : 0.063013, loss_ce: 0.018190
[01:30:09.867] iteration 11112 : loss : 0.054942, loss_ce: 0.017677
[01:30:10.167] iteration 11113 : loss : 0.047481, loss_ce: 0.013753
[01:30:10.466] iteration 11114 : loss : 0.067482, loss_ce: 0.015422
[01:30:10.767] iteration 11115 : loss : 0.046575, loss_ce: 0.012962
[01:30:11.069] iteration 11116 : loss : 0.158347, loss_ce: 0.008289
[01:30:11.375] iteration 11117 : loss : 0.041490, loss_ce: 0.018337
[01:30:11.673] iteration 11118 : loss : 0.065352, loss_ce: 0.015548
[01:30:11.976] iteration 11119 : loss : 0.045961, loss_ce: 0.012307
[01:30:12.050] iteration 11120 : loss : 0.077863, loss_ce: 0.021887
[01:30:32.057] iteration 11121 : loss : 0.102673, loss_ce: 0.013242
[01:30:32.355] iteration 11122 : loss : 0.053350, loss_ce: 0.015963
[01:30:32.649] iteration 11123 : loss : 0.046218, loss_ce: 0.016578
[01:30:32.944] iteration 11124 : loss : 0.045512, loss_ce: 0.018025
[01:30:33.241] iteration 11125 : loss : 0.107303, loss_ce: 0.015064
[01:30:33.537] iteration 11126 : loss : 0.048027, loss_ce: 0.018666
[01:30:33.827] iteration 11127 : loss : 0.055674, loss_ce: 0.016213
[01:30:34.123] iteration 11128 : loss : 0.119208, loss_ce: 0.008462
[01:30:34.423] iteration 11129 : loss : 0.054229, loss_ce: 0.011166
[01:30:34.724] iteration 11130 : loss : 0.055180, loss_ce: 0.009933
[01:30:35.021] iteration 11131 : loss : 0.044372, loss_ce: 0.016111
[01:30:35.315] iteration 11132 : loss : 0.052178, loss_ce: 0.014447
[01:30:35.616] iteration 11133 : loss : 0.052337, loss_ce: 0.016505
[01:30:35.913] iteration 11134 : loss : 0.051630, loss_ce: 0.027858
[01:30:36.208] iteration 11135 : loss : 0.061097, loss_ce: 0.015704
[01:30:36.499] iteration 11136 : loss : 0.051802, loss_ce: 0.013473
[01:30:36.795] iteration 11137 : loss : 0.056655, loss_ce: 0.009490
[01:30:37.084] iteration 11138 : loss : 0.051820, loss_ce: 0.020009
[01:30:37.379] iteration 11139 : loss : 0.055353, loss_ce: 0.017697
[01:30:37.669] iteration 11140 : loss : 0.045325, loss_ce: 0.014439
[01:30:37.981] iteration 11141 : loss : 0.044235, loss_ce: 0.012958
[01:30:38.276] iteration 11142 : loss : 0.142923, loss_ce: 0.005740
[01:30:38.566] iteration 11143 : loss : 0.064343, loss_ce: 0.022921
[01:30:38.857] iteration 11144 : loss : 0.063220, loss_ce: 0.013557
[01:30:39.149] iteration 11145 : loss : 0.045023, loss_ce: 0.015960
[01:30:39.444] iteration 11146 : loss : 0.116961, loss_ce: 0.015962
[01:30:39.736] iteration 11147 : loss : 0.050393, loss_ce: 0.012433
[01:30:40.027] iteration 11148 : loss : 0.077369, loss_ce: 0.008827
[01:30:40.322] iteration 11149 : loss : 0.113273, loss_ce: 0.015810
[01:30:40.616] iteration 11150 : loss : 0.046561, loss_ce: 0.012303
[01:30:40.910] iteration 11151 : loss : 0.060066, loss_ce: 0.014021
[01:30:41.207] iteration 11152 : loss : 0.107280, loss_ce: 0.011781
[01:30:41.504] iteration 11153 : loss : 0.053670, loss_ce: 0.019717
[01:30:41.798] iteration 11154 : loss : 0.077065, loss_ce: 0.010026
[01:30:42.090] iteration 11155 : loss : 0.058706, loss_ce: 0.011799
[01:30:42.384] iteration 11156 : loss : 0.051703, loss_ce: 0.020139
[01:30:42.679] iteration 11157 : loss : 0.104436, loss_ce: 0.013657
[01:30:42.975] iteration 11158 : loss : 0.164302, loss_ce: 0.011255
[01:30:43.268] iteration 11159 : loss : 0.105872, loss_ce: 0.008408
[01:30:43.558] iteration 11160 : loss : 0.157042, loss_ce: 0.005955
[01:30:43.869] iteration 11161 : loss : 0.166261, loss_ce: 0.006787
[01:30:44.165] iteration 11162 : loss : 0.051829, loss_ce: 0.016897
[01:30:44.456] iteration 11163 : loss : 0.108652, loss_ce: 0.016403
[01:30:44.750] iteration 11164 : loss : 0.059998, loss_ce: 0.021686
[01:30:45.044] iteration 11165 : loss : 0.048493, loss_ce: 0.012720
[01:30:45.336] iteration 11166 : loss : 0.048079, loss_ce: 0.011870
[01:30:45.627] iteration 11167 : loss : 0.148115, loss_ce: 0.005353
[01:30:45.919] iteration 11168 : loss : 0.048982, loss_ce: 0.011917
[01:30:46.210] iteration 11169 : loss : 0.091242, loss_ce: 0.014591
[01:30:46.505] iteration 11170 : loss : 0.067356, loss_ce: 0.021547
[01:30:46.796] iteration 11171 : loss : 0.046226, loss_ce: 0.014561
[01:30:47.087] iteration 11172 : loss : 0.046248, loss_ce: 0.014466
[01:30:47.379] iteration 11173 : loss : 0.048766, loss_ce: 0.025625
[01:30:47.673] iteration 11174 : loss : 0.056801, loss_ce: 0.017574
[01:30:47.966] iteration 11175 : loss : 0.122117, loss_ce: 0.014978
[01:30:48.259] iteration 11176 : loss : 0.051073, loss_ce: 0.016004
[01:30:48.550] iteration 11177 : loss : 0.059230, loss_ce: 0.013912
[01:30:48.844] iteration 11178 : loss : 0.055850, loss_ce: 0.015422
[01:30:49.138] iteration 11179 : loss : 0.046686, loss_ce: 0.019485
[01:30:49.434] iteration 11180 : loss : 0.056936, loss_ce: 0.016283
[01:30:49.752] iteration 11181 : loss : 0.064212, loss_ce: 0.013639
[01:30:50.049] iteration 11182 : loss : 0.073646, loss_ce: 0.026605
[01:30:50.347] iteration 11183 : loss : 0.049105, loss_ce: 0.021401
[01:30:50.645] iteration 11184 : loss : 0.054166, loss_ce: 0.023810
[01:30:50.945] iteration 11185 : loss : 0.096514, loss_ce: 0.011861
[01:30:51.239] iteration 11186 : loss : 0.050217, loss_ce: 0.020338
[01:30:51.530] iteration 11187 : loss : 0.055538, loss_ce: 0.022263
[01:30:51.822] iteration 11188 : loss : 0.039795, loss_ce: 0.014922
[01:30:52.115] iteration 11189 : loss : 0.053083, loss_ce: 0.011874
[01:30:52.409] iteration 11190 : loss : 0.043635, loss_ce: 0.013749
[01:30:52.701] iteration 11191 : loss : 0.047698, loss_ce: 0.016184
[01:30:52.993] iteration 11192 : loss : 0.173060, loss_ce: 0.007565
[01:30:53.286] iteration 11193 : loss : 0.051407, loss_ce: 0.017217
[01:30:53.579] iteration 11194 : loss : 0.046933, loss_ce: 0.011383
[01:30:53.874] iteration 11195 : loss : 0.055453, loss_ce: 0.023055
[01:30:54.169] iteration 11196 : loss : 0.112662, loss_ce: 0.005786
[01:30:54.465] iteration 11197 : loss : 0.089378, loss_ce: 0.016954
[01:30:54.758] iteration 11198 : loss : 0.054352, loss_ce: 0.013708
[01:30:55.051] iteration 11199 : loss : 0.040717, loss_ce: 0.015167
[01:30:55.345] iteration 11200 : loss : 0.057203, loss_ce: 0.018415
[01:30:55.655] iteration 11201 : loss : 0.056750, loss_ce: 0.021117
[01:30:55.947] iteration 11202 : loss : 0.054472, loss_ce: 0.023609
[01:30:56.243] iteration 11203 : loss : 0.058859, loss_ce: 0.013897
[01:30:56.539] iteration 11204 : loss : 0.052690, loss_ce: 0.009674
[01:30:56.831] iteration 11205 : loss : 0.045913, loss_ce: 0.015141
[01:30:57.122] iteration 11206 : loss : 0.152642, loss_ce: 0.013370
[01:30:57.417] iteration 11207 : loss : 0.041405, loss_ce: 0.009221
[01:30:57.711] iteration 11208 : loss : 0.049161, loss_ce: 0.014508
[01:30:58.007] iteration 11209 : loss : 0.045343, loss_ce: 0.011436
[01:30:58.304] iteration 11210 : loss : 0.052811, loss_ce: 0.013521
[01:30:58.599] iteration 11211 : loss : 0.054575, loss_ce: 0.014575
[01:30:58.891] iteration 11212 : loss : 0.127328, loss_ce: 0.017689
[01:30:59.182] iteration 11213 : loss : 0.055106, loss_ce: 0.010428
[01:30:59.479] iteration 11214 : loss : 0.070373, loss_ce: 0.017724
[01:30:59.775] iteration 11215 : loss : 0.053101, loss_ce: 0.009846
[01:31:00.068] iteration 11216 : loss : 0.047343, loss_ce: 0.014804
[01:31:00.359] iteration 11217 : loss : 0.058245, loss_ce: 0.016470
[01:31:00.655] iteration 11218 : loss : 0.054246, loss_ce: 0.012333
[01:31:00.946] iteration 11219 : loss : 0.085216, loss_ce: 0.014619
[01:31:01.238] iteration 11220 : loss : 0.127053, loss_ce: 0.020077
[01:31:01.542] iteration 11221 : loss : 0.047014, loss_ce: 0.015111
[01:31:01.837] iteration 11222 : loss : 0.091760, loss_ce: 0.015008
[01:31:02.131] iteration 11223 : loss : 0.065339, loss_ce: 0.020542
[01:31:02.425] iteration 11224 : loss : 0.102188, loss_ce: 0.014219
[01:31:02.722] iteration 11225 : loss : 0.102228, loss_ce: 0.010338
[01:31:03.021] iteration 11226 : loss : 0.059044, loss_ce: 0.012528
[01:31:03.311] iteration 11227 : loss : 0.108963, loss_ce: 0.012000
[01:31:03.602] iteration 11228 : loss : 0.111501, loss_ce: 0.014280
[01:31:03.895] iteration 11229 : loss : 0.045399, loss_ce: 0.015802
[01:31:04.195] iteration 11230 : loss : 0.058882, loss_ce: 0.023048
[01:31:04.489] iteration 11231 : loss : 0.115224, loss_ce: 0.006788
[01:31:04.784] iteration 11232 : loss : 0.047930, loss_ce: 0.017740
[01:31:05.077] iteration 11233 : loss : 0.084079, loss_ce: 0.013499
[01:31:05.371] iteration 11234 : loss : 0.047212, loss_ce: 0.009802
[01:31:05.667] iteration 11235 : loss : 0.047728, loss_ce: 0.014884
[01:31:05.962] iteration 11236 : loss : 0.051450, loss_ce: 0.015645
[01:31:06.260] iteration 11237 : loss : 0.107955, loss_ce: 0.018775
[01:31:06.558] iteration 11238 : loss : 0.053731, loss_ce: 0.023595
[01:31:06.857] iteration 11239 : loss : 0.051545, loss_ce: 0.016116
[01:31:07.155] iteration 11240 : loss : 0.103307, loss_ce: 0.008306
[01:31:07.467] iteration 11241 : loss : 0.047038, loss_ce: 0.016510
[01:31:07.763] iteration 11242 : loss : 0.082088, loss_ce: 0.015671
[01:31:08.063] iteration 11243 : loss : 0.057878, loss_ce: 0.017673
[01:31:08.363] iteration 11244 : loss : 0.059707, loss_ce: 0.019894
[01:31:08.669] iteration 11245 : loss : 0.051012, loss_ce: 0.011768
[01:31:08.974] iteration 11246 : loss : 0.047506, loss_ce: 0.015848
[01:31:09.276] iteration 11247 : loss : 0.042879, loss_ce: 0.014942
[01:31:09.582] iteration 11248 : loss : 0.053523, loss_ce: 0.022666
[01:31:09.892] iteration 11249 : loss : 0.046667, loss_ce: 0.015629
[01:31:10.198] iteration 11250 : loss : 0.057451, loss_ce: 0.029790
[01:31:10.503] iteration 11251 : loss : 0.040312, loss_ce: 0.010736
[01:31:10.815] iteration 11252 : loss : 0.056362, loss_ce: 0.017932
[01:31:11.121] iteration 11253 : loss : 0.054323, loss_ce: 0.016301
[01:31:11.422] iteration 11254 : loss : 0.057830, loss_ce: 0.017712
[01:31:11.719] iteration 11255 : loss : 0.057597, loss_ce: 0.017400
[01:31:12.026] iteration 11256 : loss : 0.053395, loss_ce: 0.018454
[01:31:12.332] iteration 11257 : loss : 0.052079, loss_ce: 0.018043
[01:31:12.635] iteration 11258 : loss : 0.150467, loss_ce: 0.010175
[01:31:12.726] iteration 11259 : loss : 0.042997, loss_ce: 0.015285
[01:31:30.942] iteration 11260 : loss : 0.110341, loss_ce: 0.016508
[01:31:31.264] iteration 11261 : loss : 0.057271, loss_ce: 0.029176
[01:31:31.559] iteration 11262 : loss : 0.042470, loss_ce: 0.022254
[01:31:31.854] iteration 11263 : loss : 0.099367, loss_ce: 0.012628
[01:31:32.154] iteration 11264 : loss : 0.156341, loss_ce: 0.005469
[01:31:32.450] iteration 11265 : loss : 0.046486, loss_ce: 0.013432
[01:31:32.743] iteration 11266 : loss : 0.054803, loss_ce: 0.015331
[01:31:33.041] iteration 11267 : loss : 0.075752, loss_ce: 0.003714
[01:31:33.340] iteration 11268 : loss : 0.049014, loss_ce: 0.010553
[01:31:33.636] iteration 11269 : loss : 0.051627, loss_ce: 0.017321
[01:31:33.933] iteration 11270 : loss : 0.048068, loss_ce: 0.012492
[01:31:34.231] iteration 11271 : loss : 0.119906, loss_ce: 0.007104
[01:31:34.522] iteration 11272 : loss : 0.058198, loss_ce: 0.014715
[01:31:34.816] iteration 11273 : loss : 0.062780, loss_ce: 0.010494
[01:31:35.109] iteration 11274 : loss : 0.045145, loss_ce: 0.013105
[01:31:35.405] iteration 11275 : loss : 0.050932, loss_ce: 0.015165
[01:31:35.702] iteration 11276 : loss : 0.054432, loss_ce: 0.020951
[01:31:35.998] iteration 11277 : loss : 0.053552, loss_ce: 0.014389
[01:31:36.294] iteration 11278 : loss : 0.054187, loss_ce: 0.014733
[01:31:36.591] iteration 11279 : loss : 0.047857, loss_ce: 0.016939
[01:31:36.882] iteration 11280 : loss : 0.061901, loss_ce: 0.011159
[01:31:37.200] iteration 11281 : loss : 0.051077, loss_ce: 0.018127
[01:31:37.493] iteration 11282 : loss : 0.044639, loss_ce: 0.019683
[01:31:37.788] iteration 11283 : loss : 0.052017, loss_ce: 0.021912
[01:31:38.080] iteration 11284 : loss : 0.059056, loss_ce: 0.013906
[01:31:38.376] iteration 11285 : loss : 0.075956, loss_ce: 0.011408
[01:31:38.677] iteration 11286 : loss : 0.106894, loss_ce: 0.011953
[01:31:38.972] iteration 11287 : loss : 0.082945, loss_ce: 0.013594
[01:31:39.273] iteration 11288 : loss : 0.050726, loss_ce: 0.022566
[01:31:39.572] iteration 11289 : loss : 0.044123, loss_ce: 0.014356
[01:31:39.873] iteration 11290 : loss : 0.074545, loss_ce: 0.012912
[01:31:40.180] iteration 11291 : loss : 0.050006, loss_ce: 0.014260
[01:31:40.476] iteration 11292 : loss : 0.127952, loss_ce: 0.004833
[01:31:40.781] iteration 11293 : loss : 0.043315, loss_ce: 0.010470
[01:31:41.084] iteration 11294 : loss : 0.044144, loss_ce: 0.014841
[01:31:41.382] iteration 11295 : loss : 0.068731, loss_ce: 0.015235
[01:31:41.677] iteration 11296 : loss : 0.049070, loss_ce: 0.022240
[01:31:41.972] iteration 11297 : loss : 0.051884, loss_ce: 0.012655
[01:31:42.266] iteration 11298 : loss : 0.082841, loss_ce: 0.010063
[01:31:42.565] iteration 11299 : loss : 0.054799, loss_ce: 0.022498
[01:31:42.862] iteration 11300 : loss : 0.047791, loss_ce: 0.013990
[01:31:43.174] iteration 11301 : loss : 0.049325, loss_ce: 0.028048
[01:31:43.469] iteration 11302 : loss : 0.058687, loss_ce: 0.028313
[01:31:43.766] iteration 11303 : loss : 0.055910, loss_ce: 0.019157
[01:31:44.060] iteration 11304 : loss : 0.086521, loss_ce: 0.023988
[01:31:44.354] iteration 11305 : loss : 0.106640, loss_ce: 0.011535
[01:31:44.650] iteration 11306 : loss : 0.157685, loss_ce: 0.003124
[01:31:44.946] iteration 11307 : loss : 0.054002, loss_ce: 0.017088
[01:31:45.237] iteration 11308 : loss : 0.075576, loss_ce: 0.017194
[01:31:45.526] iteration 11309 : loss : 0.051386, loss_ce: 0.011003
[01:31:45.817] iteration 11310 : loss : 0.057856, loss_ce: 0.019151
[01:31:46.112] iteration 11311 : loss : 0.043056, loss_ce: 0.014043
[01:31:46.408] iteration 11312 : loss : 0.048354, loss_ce: 0.010097
[01:31:46.700] iteration 11313 : loss : 0.057436, loss_ce: 0.008042
[01:31:46.995] iteration 11314 : loss : 0.053288, loss_ce: 0.017041
[01:31:47.287] iteration 11315 : loss : 0.091567, loss_ce: 0.015773
[01:31:47.583] iteration 11316 : loss : 0.049789, loss_ce: 0.018395
[01:31:47.876] iteration 11317 : loss : 0.065854, loss_ce: 0.013456
[01:31:48.169] iteration 11318 : loss : 0.058134, loss_ce: 0.015455
[01:31:48.464] iteration 11319 : loss : 0.119101, loss_ce: 0.014147
[01:31:48.760] iteration 11320 : loss : 0.045705, loss_ce: 0.009324
[01:31:49.076] iteration 11321 : loss : 0.056979, loss_ce: 0.010310
[01:31:49.373] iteration 11322 : loss : 0.109996, loss_ce: 0.012735
[01:31:49.667] iteration 11323 : loss : 0.074447, loss_ce: 0.009878
[01:31:49.962] iteration 11324 : loss : 0.055454, loss_ce: 0.009112
[01:31:50.256] iteration 11325 : loss : 0.111159, loss_ce: 0.014401
[01:31:50.550] iteration 11326 : loss : 0.058089, loss_ce: 0.010004
[01:31:50.844] iteration 11327 : loss : 0.057604, loss_ce: 0.010051
[01:31:51.140] iteration 11328 : loss : 0.098791, loss_ce: 0.005651
[01:31:51.430] iteration 11329 : loss : 0.165100, loss_ce: 0.006093
[01:31:51.727] iteration 11330 : loss : 0.046610, loss_ce: 0.019437
[01:31:52.021] iteration 11331 : loss : 0.052734, loss_ce: 0.016331
[01:31:52.317] iteration 11332 : loss : 0.051995, loss_ce: 0.016194
[01:31:52.611] iteration 11333 : loss : 0.045565, loss_ce: 0.013467
[01:31:52.905] iteration 11334 : loss : 0.055532, loss_ce: 0.018035
[01:31:53.202] iteration 11335 : loss : 0.053955, loss_ce: 0.023019
[01:31:53.496] iteration 11336 : loss : 0.046484, loss_ce: 0.013878
[01:31:53.790] iteration 11337 : loss : 0.045612, loss_ce: 0.015986
[01:31:54.089] iteration 11338 : loss : 0.039296, loss_ce: 0.014969
[01:31:54.389] iteration 11339 : loss : 0.058088, loss_ce: 0.019114
[01:31:54.688] iteration 11340 : loss : 0.057180, loss_ce: 0.014474
[01:31:55.004] iteration 11341 : loss : 0.067859, loss_ce: 0.022423
[01:31:55.307] iteration 11342 : loss : 0.253391, loss_ce: 0.014190
[01:31:55.604] iteration 11343 : loss : 0.046971, loss_ce: 0.012906
[01:31:55.906] iteration 11344 : loss : 0.043116, loss_ce: 0.018737
[01:31:56.203] iteration 11345 : loss : 0.061795, loss_ce: 0.021786
[01:31:56.494] iteration 11346 : loss : 0.217019, loss_ce: 0.009723
[01:31:56.785] iteration 11347 : loss : 0.059266, loss_ce: 0.018103
[01:31:57.082] iteration 11348 : loss : 0.051009, loss_ce: 0.025576
[01:31:57.379] iteration 11349 : loss : 0.056936, loss_ce: 0.013942
[01:31:57.671] iteration 11350 : loss : 0.160759, loss_ce: 0.008097
[01:31:57.965] iteration 11351 : loss : 0.062312, loss_ce: 0.023083
[01:31:58.261] iteration 11352 : loss : 0.049502, loss_ce: 0.016189
[01:31:58.553] iteration 11353 : loss : 0.060754, loss_ce: 0.021220
[01:31:58.845] iteration 11354 : loss : 0.064976, loss_ce: 0.015712
[01:31:59.139] iteration 11355 : loss : 0.063675, loss_ce: 0.012688
[01:31:59.433] iteration 11356 : loss : 0.045396, loss_ce: 0.014206
[01:31:59.729] iteration 11357 : loss : 0.051285, loss_ce: 0.015331
[01:32:00.021] iteration 11358 : loss : 0.052862, loss_ce: 0.018267
[01:32:00.316] iteration 11359 : loss : 0.105468, loss_ce: 0.019115
[01:32:00.609] iteration 11360 : loss : 0.048990, loss_ce: 0.015372
[01:32:00.921] iteration 11361 : loss : 0.071551, loss_ce: 0.009672
[01:32:01.221] iteration 11362 : loss : 0.056116, loss_ce: 0.018132
[01:32:01.511] iteration 11363 : loss : 0.055717, loss_ce: 0.014874
[01:32:01.804] iteration 11364 : loss : 0.097557, loss_ce: 0.010859
[01:32:02.097] iteration 11365 : loss : 0.038034, loss_ce: 0.007215
[01:32:02.389] iteration 11366 : loss : 0.070726, loss_ce: 0.016382
[01:32:02.681] iteration 11367 : loss : 0.100020, loss_ce: 0.018634
[01:32:02.978] iteration 11368 : loss : 0.048161, loss_ce: 0.018634
[01:32:03.274] iteration 11369 : loss : 0.156483, loss_ce: 0.010316
[01:32:03.568] iteration 11370 : loss : 0.065735, loss_ce: 0.014415
[01:32:03.862] iteration 11371 : loss : 0.057110, loss_ce: 0.011505
[01:32:04.150] iteration 11372 : loss : 0.116402, loss_ce: 0.024416
[01:32:04.446] iteration 11373 : loss : 0.060711, loss_ce: 0.016476
[01:32:04.738] iteration 11374 : loss : 0.157392, loss_ce: 0.010737
[01:32:05.031] iteration 11375 : loss : 0.046815, loss_ce: 0.022203
[01:32:05.324] iteration 11376 : loss : 0.121153, loss_ce: 0.014438
[01:32:05.621] iteration 11377 : loss : 0.067578, loss_ce: 0.013179
[01:32:05.917] iteration 11378 : loss : 0.131796, loss_ce: 0.019212
[01:32:06.216] iteration 11379 : loss : 0.036907, loss_ce: 0.010936
[01:32:06.510] iteration 11380 : loss : 0.052285, loss_ce: 0.008394
[01:32:06.822] iteration 11381 : loss : 0.050076, loss_ce: 0.017100
[01:32:07.120] iteration 11382 : loss : 0.059301, loss_ce: 0.030800
[01:32:07.414] iteration 11383 : loss : 0.046814, loss_ce: 0.012859
[01:32:07.719] iteration 11384 : loss : 0.176951, loss_ce: 0.011724
[01:32:08.021] iteration 11385 : loss : 0.068821, loss_ce: 0.012977
[01:32:08.326] iteration 11386 : loss : 0.075570, loss_ce: 0.019399
[01:32:08.629] iteration 11387 : loss : 0.058203, loss_ce: 0.016733
[01:32:08.935] iteration 11388 : loss : 0.050162, loss_ce: 0.016802
[01:32:09.241] iteration 11389 : loss : 0.105359, loss_ce: 0.016671
[01:32:09.543] iteration 11390 : loss : 0.062472, loss_ce: 0.020750
[01:32:09.847] iteration 11391 : loss : 0.286757, loss_ce: 0.013369
[01:32:10.147] iteration 11392 : loss : 0.044883, loss_ce: 0.019069
[01:32:10.447] iteration 11393 : loss : 0.052418, loss_ce: 0.019243
[01:32:10.745] iteration 11394 : loss : 0.114184, loss_ce: 0.015076
[01:32:11.046] iteration 11395 : loss : 0.048173, loss_ce: 0.017320
[01:32:11.352] iteration 11396 : loss : 0.056825, loss_ce: 0.015682
[01:32:11.656] iteration 11397 : loss : 0.106304, loss_ce: 0.018259
[01:32:11.739] iteration 11398 : loss : 0.114121, loss_ce: 0.022292
[01:32:30.823] iteration 11399 : loss : 0.061951, loss_ce: 0.029574
[01:32:31.124] iteration 11400 : loss : 0.041463, loss_ce: 0.015161
[01:32:31.439] iteration 11401 : loss : 0.048506, loss_ce: 0.015007
[01:32:31.739] iteration 11402 : loss : 0.043121, loss_ce: 0.020117
[01:32:32.038] iteration 11403 : loss : 0.054979, loss_ce: 0.015415
[01:32:32.333] iteration 11404 : loss : 0.059524, loss_ce: 0.018977
[01:32:32.623] iteration 11405 : loss : 0.068696, loss_ce: 0.008982
[01:32:32.915] iteration 11406 : loss : 0.041917, loss_ce: 0.012157
[01:32:33.206] iteration 11407 : loss : 0.059757, loss_ce: 0.016483
[01:32:33.501] iteration 11408 : loss : 0.173461, loss_ce: 0.008703
[01:32:33.794] iteration 11409 : loss : 0.060400, loss_ce: 0.008835
[01:32:34.084] iteration 11410 : loss : 0.055715, loss_ce: 0.012577
[01:32:34.379] iteration 11411 : loss : 0.102938, loss_ce: 0.013487
[01:32:34.676] iteration 11412 : loss : 0.046133, loss_ce: 0.008526
[01:32:34.965] iteration 11413 : loss : 0.053695, loss_ce: 0.018856
[01:32:35.254] iteration 11414 : loss : 0.076270, loss_ce: 0.018778
[01:32:35.548] iteration 11415 : loss : 0.043813, loss_ce: 0.007295
[01:32:35.839] iteration 11416 : loss : 0.055723, loss_ce: 0.012028
[01:32:36.131] iteration 11417 : loss : 0.055696, loss_ce: 0.025998
[01:32:36.422] iteration 11418 : loss : 0.067744, loss_ce: 0.009365
[01:32:36.711] iteration 11419 : loss : 0.111845, loss_ce: 0.007266
[01:32:37.004] iteration 11420 : loss : 0.049527, loss_ce: 0.016524
[01:32:37.313] iteration 11421 : loss : 0.048280, loss_ce: 0.008600
[01:32:37.608] iteration 11422 : loss : 0.049225, loss_ce: 0.016315
[01:32:37.902] iteration 11423 : loss : 0.071871, loss_ce: 0.014767
[01:32:38.195] iteration 11424 : loss : 0.060476, loss_ce: 0.010110
[01:32:38.489] iteration 11425 : loss : 0.054974, loss_ce: 0.016863
[01:32:38.785] iteration 11426 : loss : 0.048648, loss_ce: 0.012542
[01:32:39.080] iteration 11427 : loss : 0.109391, loss_ce: 0.009321
[01:32:39.373] iteration 11428 : loss : 0.113055, loss_ce: 0.007635
[01:32:39.667] iteration 11429 : loss : 0.058453, loss_ce: 0.016842
[01:32:39.960] iteration 11430 : loss : 0.119924, loss_ce: 0.010877
[01:32:40.253] iteration 11431 : loss : 0.056830, loss_ce: 0.013917
[01:32:40.549] iteration 11432 : loss : 0.057216, loss_ce: 0.020839
[01:32:40.840] iteration 11433 : loss : 0.050364, loss_ce: 0.007107
[01:32:41.136] iteration 11434 : loss : 0.052319, loss_ce: 0.019538
[01:32:41.430] iteration 11435 : loss : 0.051441, loss_ce: 0.013027
[01:32:41.722] iteration 11436 : loss : 0.052246, loss_ce: 0.020283
[01:32:42.016] iteration 11437 : loss : 0.050748, loss_ce: 0.017426
[01:32:42.310] iteration 11438 : loss : 0.111586, loss_ce: 0.018698
[01:32:42.603] iteration 11439 : loss : 0.051298, loss_ce: 0.011585
[01:32:42.894] iteration 11440 : loss : 0.053240, loss_ce: 0.018223
[01:32:43.209] iteration 11441 : loss : 0.099172, loss_ce: 0.008597
[01:32:43.499] iteration 11442 : loss : 0.047473, loss_ce: 0.011794
[01:32:43.795] iteration 11443 : loss : 0.047976, loss_ce: 0.012324
[01:32:44.088] iteration 11444 : loss : 0.043785, loss_ce: 0.013544
[01:32:44.389] iteration 11445 : loss : 0.050854, loss_ce: 0.018429
[01:32:44.688] iteration 11446 : loss : 0.045975, loss_ce: 0.017815
[01:32:44.988] iteration 11447 : loss : 0.047715, loss_ce: 0.023512
[01:32:45.285] iteration 11448 : loss : 0.099693, loss_ce: 0.006722
[01:32:45.588] iteration 11449 : loss : 0.059132, loss_ce: 0.018407
[01:32:45.887] iteration 11450 : loss : 0.052291, loss_ce: 0.024242
[01:32:46.185] iteration 11451 : loss : 0.057512, loss_ce: 0.015683
[01:32:46.479] iteration 11452 : loss : 0.035098, loss_ce: 0.007501
[01:32:46.770] iteration 11453 : loss : 0.046299, loss_ce: 0.017022
[01:32:47.059] iteration 11454 : loss : 0.045256, loss_ce: 0.014281
[01:32:47.352] iteration 11455 : loss : 0.041962, loss_ce: 0.012913
[01:32:47.645] iteration 11456 : loss : 0.104325, loss_ce: 0.008232
[01:32:47.941] iteration 11457 : loss : 0.044797, loss_ce: 0.020243
[01:32:48.233] iteration 11458 : loss : 0.053339, loss_ce: 0.014736
[01:32:48.527] iteration 11459 : loss : 0.041216, loss_ce: 0.015648
[01:32:48.824] iteration 11460 : loss : 0.065066, loss_ce: 0.021788
[01:32:49.136] iteration 11461 : loss : 0.042930, loss_ce: 0.012190
[01:32:49.432] iteration 11462 : loss : 0.040676, loss_ce: 0.010491
[01:32:49.726] iteration 11463 : loss : 0.067638, loss_ce: 0.016494
[01:32:50.024] iteration 11464 : loss : 0.045344, loss_ce: 0.015776
[01:32:50.318] iteration 11465 : loss : 0.047429, loss_ce: 0.013842
[01:32:50.613] iteration 11466 : loss : 0.089885, loss_ce: 0.014651
[01:32:50.908] iteration 11467 : loss : 0.053400, loss_ce: 0.020946
[01:32:51.197] iteration 11468 : loss : 0.059354, loss_ce: 0.022448
[01:32:51.493] iteration 11469 : loss : 0.074154, loss_ce: 0.015588
[01:32:51.787] iteration 11470 : loss : 0.053236, loss_ce: 0.022814
[01:32:52.083] iteration 11471 : loss : 0.045172, loss_ce: 0.015463
[01:32:52.380] iteration 11472 : loss : 0.072771, loss_ce: 0.020465
[01:32:52.674] iteration 11473 : loss : 0.058717, loss_ce: 0.018059
[01:32:52.970] iteration 11474 : loss : 0.055322, loss_ce: 0.013667
[01:32:53.266] iteration 11475 : loss : 0.110303, loss_ce: 0.008383
[01:32:53.558] iteration 11476 : loss : 0.110465, loss_ce: 0.005946
[01:32:53.849] iteration 11477 : loss : 0.058976, loss_ce: 0.020195
[01:32:54.142] iteration 11478 : loss : 0.048558, loss_ce: 0.020229
[01:32:54.432] iteration 11479 : loss : 0.133918, loss_ce: 0.008455
[01:32:54.719] iteration 11480 : loss : 0.110529, loss_ce: 0.007186
[01:32:55.029] iteration 11481 : loss : 0.112651, loss_ce: 0.012057
[01:32:55.321] iteration 11482 : loss : 0.038285, loss_ce: 0.015128
[01:32:55.613] iteration 11483 : loss : 0.049422, loss_ce: 0.014030
[01:32:55.908] iteration 11484 : loss : 0.044051, loss_ce: 0.015321
[01:32:56.203] iteration 11485 : loss : 0.054499, loss_ce: 0.008517
[01:32:56.497] iteration 11486 : loss : 0.112734, loss_ce: 0.011252
[01:32:56.792] iteration 11487 : loss : 0.055855, loss_ce: 0.019924
[01:32:57.087] iteration 11488 : loss : 0.100393, loss_ce: 0.014794
[01:32:57.389] iteration 11489 : loss : 0.052759, loss_ce: 0.008204
[01:32:57.683] iteration 11490 : loss : 0.047971, loss_ce: 0.011623
[01:32:57.975] iteration 11491 : loss : 0.054612, loss_ce: 0.020852
[01:32:58.273] iteration 11492 : loss : 0.047587, loss_ce: 0.013418
[01:32:58.569] iteration 11493 : loss : 0.056604, loss_ce: 0.023277
[01:32:58.861] iteration 11494 : loss : 0.054579, loss_ce: 0.015867
[01:32:59.159] iteration 11495 : loss : 0.110293, loss_ce: 0.008244
[01:32:59.452] iteration 11496 : loss : 0.050369, loss_ce: 0.020670
[01:32:59.745] iteration 11497 : loss : 0.060446, loss_ce: 0.013404
[01:33:00.039] iteration 11498 : loss : 0.116008, loss_ce: 0.017036
[01:33:00.334] iteration 11499 : loss : 0.062779, loss_ce: 0.016688
[01:33:00.634] iteration 11500 : loss : 0.058040, loss_ce: 0.020306
[01:33:00.949] iteration 11501 : loss : 0.058496, loss_ce: 0.016311
[01:33:01.243] iteration 11502 : loss : 0.093005, loss_ce: 0.015162
[01:33:01.542] iteration 11503 : loss : 0.044999, loss_ce: 0.015047
[01:33:01.841] iteration 11504 : loss : 0.042356, loss_ce: 0.017158
[01:33:02.136] iteration 11505 : loss : 0.067196, loss_ce: 0.012288
[01:33:02.435] iteration 11506 : loss : 0.060875, loss_ce: 0.021636
[01:33:02.738] iteration 11507 : loss : 0.105831, loss_ce: 0.008811
[01:33:03.037] iteration 11508 : loss : 0.038901, loss_ce: 0.012345
[01:33:03.336] iteration 11509 : loss : 0.046995, loss_ce: 0.022673
[01:33:03.634] iteration 11510 : loss : 0.061732, loss_ce: 0.006887
[01:33:03.930] iteration 11511 : loss : 0.062190, loss_ce: 0.011280
[01:33:04.230] iteration 11512 : loss : 0.050485, loss_ce: 0.016595
[01:33:04.527] iteration 11513 : loss : 0.056079, loss_ce: 0.019859
[01:33:04.825] iteration 11514 : loss : 0.051981, loss_ce: 0.020314
[01:33:05.123] iteration 11515 : loss : 0.035125, loss_ce: 0.009635
[01:33:05.424] iteration 11516 : loss : 0.052920, loss_ce: 0.017371
[01:33:05.717] iteration 11517 : loss : 0.046776, loss_ce: 0.015250
[01:33:06.020] iteration 11518 : loss : 0.049258, loss_ce: 0.021001
[01:33:06.324] iteration 11519 : loss : 0.048692, loss_ce: 0.015542
[01:33:06.619] iteration 11520 : loss : 0.060729, loss_ce: 0.018437
[01:33:06.936] iteration 11521 : loss : 0.053597, loss_ce: 0.015609
[01:33:07.239] iteration 11522 : loss : 0.119788, loss_ce: 0.010471
[01:33:07.541] iteration 11523 : loss : 0.104808, loss_ce: 0.009822
[01:33:07.845] iteration 11524 : loss : 0.046732, loss_ce: 0.015707
[01:33:08.147] iteration 11525 : loss : 0.051997, loss_ce: 0.014909
[01:33:08.446] iteration 11526 : loss : 0.060646, loss_ce: 0.010706
[01:33:08.749] iteration 11527 : loss : 0.045666, loss_ce: 0.014916
[01:33:09.054] iteration 11528 : loss : 0.051435, loss_ce: 0.012881
[01:33:09.357] iteration 11529 : loss : 0.054988, loss_ce: 0.017215
[01:33:09.657] iteration 11530 : loss : 0.049213, loss_ce: 0.016293
[01:33:09.960] iteration 11531 : loss : 0.113944, loss_ce: 0.013741
[01:33:10.263] iteration 11532 : loss : 0.036409, loss_ce: 0.012730
[01:33:10.568] iteration 11533 : loss : 0.048035, loss_ce: 0.009561
[01:33:10.868] iteration 11534 : loss : 0.107676, loss_ce: 0.007973
[01:33:11.176] iteration 11535 : loss : 0.058332, loss_ce: 0.016140
[01:33:11.477] iteration 11536 : loss : 0.059252, loss_ce: 0.019862
[01:33:11.554] iteration 11537 : loss : 0.043119, loss_ce: 0.026831
[01:33:29.945] iteration 11538 : loss : 0.072846, loss_ce: 0.009101
[01:33:30.239] iteration 11539 : loss : 0.052516, loss_ce: 0.015031
[01:33:30.535] iteration 11540 : loss : 0.048601, loss_ce: 0.013741
[01:33:30.853] iteration 11541 : loss : 0.047491, loss_ce: 0.012881
[01:33:31.148] iteration 11542 : loss : 0.062266, loss_ce: 0.013660
[01:33:31.439] iteration 11543 : loss : 0.068605, loss_ce: 0.025639
[01:33:31.732] iteration 11544 : loss : 0.087752, loss_ce: 0.019477
[01:33:32.023] iteration 11545 : loss : 0.049319, loss_ce: 0.011899
[01:33:32.315] iteration 11546 : loss : 0.050033, loss_ce: 0.019442
[01:33:32.612] iteration 11547 : loss : 0.072325, loss_ce: 0.014425
[01:33:32.903] iteration 11548 : loss : 0.072436, loss_ce: 0.020429
[01:33:33.198] iteration 11549 : loss : 0.177657, loss_ce: 0.016198
[01:33:33.491] iteration 11550 : loss : 0.097620, loss_ce: 0.012702
[01:33:33.788] iteration 11551 : loss : 0.187548, loss_ce: 0.007794
[01:33:34.083] iteration 11552 : loss : 0.059348, loss_ce: 0.009293
[01:33:34.386] iteration 11553 : loss : 0.050508, loss_ce: 0.014077
[01:33:34.684] iteration 11554 : loss : 0.063248, loss_ce: 0.025653
[01:33:34.985] iteration 11555 : loss : 0.052386, loss_ce: 0.023342
[01:33:35.284] iteration 11556 : loss : 0.037562, loss_ce: 0.009639
[01:33:35.585] iteration 11557 : loss : 0.059865, loss_ce: 0.019925
[01:33:35.883] iteration 11558 : loss : 0.140029, loss_ce: 0.013962
[01:33:36.183] iteration 11559 : loss : 0.047208, loss_ce: 0.019391
[01:33:36.474] iteration 11560 : loss : 0.059293, loss_ce: 0.020375
[01:33:36.787] iteration 11561 : loss : 0.047731, loss_ce: 0.019260
[01:33:37.085] iteration 11562 : loss : 0.107462, loss_ce: 0.014854
[01:33:37.380] iteration 11563 : loss : 0.047421, loss_ce: 0.014602
[01:33:37.675] iteration 11564 : loss : 0.111004, loss_ce: 0.018217
[01:33:37.969] iteration 11565 : loss : 0.047419, loss_ce: 0.018304
[01:33:38.266] iteration 11566 : loss : 0.074572, loss_ce: 0.015290
[01:33:38.562] iteration 11567 : loss : 0.110400, loss_ce: 0.014674
[01:33:38.856] iteration 11568 : loss : 0.056467, loss_ce: 0.019348
[01:33:39.151] iteration 11569 : loss : 0.111869, loss_ce: 0.014199
[01:33:39.447] iteration 11570 : loss : 0.110046, loss_ce: 0.018947
[01:33:39.742] iteration 11571 : loss : 0.056471, loss_ce: 0.017080
[01:33:40.039] iteration 11572 : loss : 0.104319, loss_ce: 0.009117
[01:33:40.334] iteration 11573 : loss : 0.053295, loss_ce: 0.014778
[01:33:40.629] iteration 11574 : loss : 0.047307, loss_ce: 0.018592
[01:33:40.925] iteration 11575 : loss : 0.106169, loss_ce: 0.015203
[01:33:41.224] iteration 11576 : loss : 0.053352, loss_ce: 0.010309
[01:33:41.515] iteration 11577 : loss : 0.116391, loss_ce: 0.007566
[01:33:41.812] iteration 11578 : loss : 0.058363, loss_ce: 0.025479
[01:33:42.105] iteration 11579 : loss : 0.067413, loss_ce: 0.015601
[01:33:42.405] iteration 11580 : loss : 0.054573, loss_ce: 0.007856
[01:33:42.714] iteration 11581 : loss : 0.075773, loss_ce: 0.006627
[01:33:43.008] iteration 11582 : loss : 0.108483, loss_ce: 0.014830
[01:33:43.300] iteration 11583 : loss : 0.051173, loss_ce: 0.017078
[01:33:43.597] iteration 11584 : loss : 0.064954, loss_ce: 0.021308
[01:33:43.888] iteration 11585 : loss : 0.107150, loss_ce: 0.015828
[01:33:44.187] iteration 11586 : loss : 0.052464, loss_ce: 0.012803
[01:33:44.480] iteration 11587 : loss : 0.059613, loss_ce: 0.010448
[01:33:44.774] iteration 11588 : loss : 0.055711, loss_ce: 0.013085
[01:33:45.069] iteration 11589 : loss : 0.120364, loss_ce: 0.010333
[01:33:45.360] iteration 11590 : loss : 0.040392, loss_ce: 0.009135
[01:33:45.654] iteration 11591 : loss : 0.053407, loss_ce: 0.011494
[01:33:45.946] iteration 11592 : loss : 0.048821, loss_ce: 0.020936
[01:33:46.241] iteration 11593 : loss : 0.044875, loss_ce: 0.017024
[01:33:46.536] iteration 11594 : loss : 0.091156, loss_ce: 0.006881
[01:33:46.832] iteration 11595 : loss : 0.042292, loss_ce: 0.010506
[01:33:47.124] iteration 11596 : loss : 0.047715, loss_ce: 0.008890
[01:33:47.415] iteration 11597 : loss : 0.044366, loss_ce: 0.007863
[01:33:47.710] iteration 11598 : loss : 0.282046, loss_ce: 0.001971
[01:33:48.001] iteration 11599 : loss : 0.042361, loss_ce: 0.013226
[01:33:48.292] iteration 11600 : loss : 0.048805, loss_ce: 0.021041
[01:33:48.607] iteration 11601 : loss : 0.053878, loss_ce: 0.016765
[01:33:48.897] iteration 11602 : loss : 0.057503, loss_ce: 0.013539
[01:33:49.190] iteration 11603 : loss : 0.048091, loss_ce: 0.025822
[01:33:49.486] iteration 11604 : loss : 0.053773, loss_ce: 0.025992
[01:33:49.780] iteration 11605 : loss : 0.043444, loss_ce: 0.014054
[01:33:50.072] iteration 11606 : loss : 0.102930, loss_ce: 0.011783
[01:33:50.368] iteration 11607 : loss : 0.050981, loss_ce: 0.021880
[01:33:50.663] iteration 11608 : loss : 0.052718, loss_ce: 0.018319
[01:33:50.957] iteration 11609 : loss : 0.038914, loss_ce: 0.007773
[01:33:51.250] iteration 11610 : loss : 0.059791, loss_ce: 0.011208
[01:33:51.546] iteration 11611 : loss : 0.039450, loss_ce: 0.011653
[01:33:51.846] iteration 11612 : loss : 0.055704, loss_ce: 0.019941
[01:33:52.142] iteration 11613 : loss : 0.111248, loss_ce: 0.014790
[01:33:52.444] iteration 11614 : loss : 0.115214, loss_ce: 0.010252
[01:33:52.743] iteration 11615 : loss : 0.049026, loss_ce: 0.019549
[01:33:53.045] iteration 11616 : loss : 0.048877, loss_ce: 0.019645
[01:33:53.342] iteration 11617 : loss : 0.293803, loss_ce: 0.005110
[01:33:53.640] iteration 11618 : loss : 0.231827, loss_ce: 0.003313
[01:33:53.939] iteration 11619 : loss : 0.046364, loss_ce: 0.013870
[01:33:54.238] iteration 11620 : loss : 0.059056, loss_ce: 0.020213
[01:33:54.556] iteration 11621 : loss : 0.050883, loss_ce: 0.013243
[01:33:54.851] iteration 11622 : loss : 0.043537, loss_ce: 0.011236
[01:33:55.148] iteration 11623 : loss : 0.053276, loss_ce: 0.013933
[01:33:55.449] iteration 11624 : loss : 0.049697, loss_ce: 0.016569
[01:33:55.746] iteration 11625 : loss : 0.046062, loss_ce: 0.014816
[01:33:56.047] iteration 11626 : loss : 0.054474, loss_ce: 0.018428
[01:33:56.346] iteration 11627 : loss : 0.053870, loss_ce: 0.021417
[01:33:56.646] iteration 11628 : loss : 0.049008, loss_ce: 0.010769
[01:33:56.945] iteration 11629 : loss : 0.055976, loss_ce: 0.014048
[01:33:57.243] iteration 11630 : loss : 0.053596, loss_ce: 0.018357
[01:33:57.541] iteration 11631 : loss : 0.053000, loss_ce: 0.023438
[01:33:57.836] iteration 11632 : loss : 0.047879, loss_ce: 0.015028
[01:33:58.136] iteration 11633 : loss : 0.056294, loss_ce: 0.017708
[01:33:58.433] iteration 11634 : loss : 0.102515, loss_ce: 0.012355
[01:33:58.732] iteration 11635 : loss : 0.101534, loss_ce: 0.017737
[01:33:59.028] iteration 11636 : loss : 0.045122, loss_ce: 0.013159
[01:33:59.328] iteration 11637 : loss : 0.039714, loss_ce: 0.011839
[01:33:59.625] iteration 11638 : loss : 0.047877, loss_ce: 0.012182
[01:33:59.923] iteration 11639 : loss : 0.045819, loss_ce: 0.010154
[01:34:00.221] iteration 11640 : loss : 0.052227, loss_ce: 0.019424
[01:34:00.536] iteration 11641 : loss : 0.061655, loss_ce: 0.012419
[01:34:00.833] iteration 11642 : loss : 0.050309, loss_ce: 0.011007
[01:34:01.135] iteration 11643 : loss : 0.165758, loss_ce: 0.016115
[01:34:01.433] iteration 11644 : loss : 0.051184, loss_ce: 0.016799
[01:34:01.730] iteration 11645 : loss : 0.070439, loss_ce: 0.022149
[01:34:02.031] iteration 11646 : loss : 0.060770, loss_ce: 0.016864
[01:34:02.328] iteration 11647 : loss : 0.062555, loss_ce: 0.016372
[01:34:02.628] iteration 11648 : loss : 0.101337, loss_ce: 0.010610
[01:34:02.924] iteration 11649 : loss : 0.112401, loss_ce: 0.009967
[01:34:03.222] iteration 11650 : loss : 0.044046, loss_ce: 0.017751
[01:34:03.519] iteration 11651 : loss : 0.048198, loss_ce: 0.013662
[01:34:03.816] iteration 11652 : loss : 0.052328, loss_ce: 0.021328
[01:34:04.114] iteration 11653 : loss : 0.119683, loss_ce: 0.009117
[01:34:04.412] iteration 11654 : loss : 0.161067, loss_ce: 0.010156
[01:34:04.704] iteration 11655 : loss : 0.037011, loss_ce: 0.011766
[01:34:04.998] iteration 11656 : loss : 0.047624, loss_ce: 0.014448
[01:34:05.297] iteration 11657 : loss : 0.108806, loss_ce: 0.015472
[01:34:05.593] iteration 11658 : loss : 0.056874, loss_ce: 0.028935
[01:34:05.892] iteration 11659 : loss : 0.044675, loss_ce: 0.014952
[01:34:06.190] iteration 11660 : loss : 0.110235, loss_ce: 0.008974
[01:34:06.499] iteration 11661 : loss : 0.054896, loss_ce: 0.008629
[01:34:06.804] iteration 11662 : loss : 0.161562, loss_ce: 0.018434
[01:34:07.107] iteration 11663 : loss : 0.118984, loss_ce: 0.009604
[01:34:07.412] iteration 11664 : loss : 0.062577, loss_ce: 0.016779
[01:34:07.710] iteration 11665 : loss : 0.055907, loss_ce: 0.017456
[01:34:08.008] iteration 11666 : loss : 0.049026, loss_ce: 0.011487
[01:34:08.309] iteration 11667 : loss : 0.041667, loss_ce: 0.011103
[01:34:08.607] iteration 11668 : loss : 0.037158, loss_ce: 0.013090
[01:34:08.906] iteration 11669 : loss : 0.050285, loss_ce: 0.014919
[01:34:09.215] iteration 11670 : loss : 0.049688, loss_ce: 0.021629
[01:34:09.521] iteration 11671 : loss : 0.039298, loss_ce: 0.011980
[01:34:09.825] iteration 11672 : loss : 0.065142, loss_ce: 0.019813
[01:34:10.130] iteration 11673 : loss : 0.102980, loss_ce: 0.011377
[01:34:10.432] iteration 11674 : loss : 0.057278, loss_ce: 0.011044
[01:34:10.734] iteration 11675 : loss : 0.043864, loss_ce: 0.016025
[01:34:10.816] iteration 11676 : loss : 0.285976, loss_ce: 0.005556
[01:34:29.924] iteration 11677 : loss : 0.048633, loss_ce: 0.020777
[01:34:30.221] iteration 11678 : loss : 0.047212, loss_ce: 0.021999
[01:34:30.518] iteration 11679 : loss : 0.110540, loss_ce: 0.015239
[01:34:30.815] iteration 11680 : loss : 0.109639, loss_ce: 0.004939
[01:34:31.124] iteration 11681 : loss : 0.052429, loss_ce: 0.014005
[01:34:31.413] iteration 11682 : loss : 0.032353, loss_ce: 0.007424
[01:34:31.705] iteration 11683 : loss : 0.066646, loss_ce: 0.014674
[01:34:32.002] iteration 11684 : loss : 0.039168, loss_ce: 0.006691
[01:34:32.294] iteration 11685 : loss : 0.062223, loss_ce: 0.020199
[01:34:32.588] iteration 11686 : loss : 0.051648, loss_ce: 0.009272
[01:34:32.883] iteration 11687 : loss : 0.052542, loss_ce: 0.017224
[01:34:33.174] iteration 11688 : loss : 0.048675, loss_ce: 0.020265
[01:34:33.470] iteration 11689 : loss : 0.044922, loss_ce: 0.015309
[01:34:33.764] iteration 11690 : loss : 0.108444, loss_ce: 0.019040
[01:34:34.059] iteration 11691 : loss : 0.064867, loss_ce: 0.010924
[01:34:34.354] iteration 11692 : loss : 0.046162, loss_ce: 0.008873
[01:34:34.646] iteration 11693 : loss : 0.063508, loss_ce: 0.015017
[01:34:34.937] iteration 11694 : loss : 0.055167, loss_ce: 0.015110
[01:34:35.233] iteration 11695 : loss : 0.077054, loss_ce: 0.013103
[01:34:35.523] iteration 11696 : loss : 0.047554, loss_ce: 0.014894
[01:34:35.816] iteration 11697 : loss : 0.168403, loss_ce: 0.005407
[01:34:36.106] iteration 11698 : loss : 0.104931, loss_ce: 0.008775
[01:34:36.395] iteration 11699 : loss : 0.159971, loss_ce: 0.007912
[01:34:36.689] iteration 11700 : loss : 0.110988, loss_ce: 0.016371
[01:34:37.003] iteration 11701 : loss : 0.040948, loss_ce: 0.024968
[01:34:37.292] iteration 11702 : loss : 0.057800, loss_ce: 0.013857
[01:34:37.584] iteration 11703 : loss : 0.047445, loss_ce: 0.013274
[01:34:37.877] iteration 11704 : loss : 0.054303, loss_ce: 0.013427
[01:34:38.170] iteration 11705 : loss : 0.044113, loss_ce: 0.016293
[01:34:38.465] iteration 11706 : loss : 0.052947, loss_ce: 0.016711
[01:34:38.761] iteration 11707 : loss : 0.061243, loss_ce: 0.017871
[01:34:39.053] iteration 11708 : loss : 0.040722, loss_ce: 0.013069
[01:34:39.359] iteration 11709 : loss : 0.050634, loss_ce: 0.014863
[01:34:39.652] iteration 11710 : loss : 0.046794, loss_ce: 0.015763
[01:34:39.944] iteration 11711 : loss : 0.088254, loss_ce: 0.018647
[01:34:40.237] iteration 11712 : loss : 0.070337, loss_ce: 0.008414
[01:34:40.532] iteration 11713 : loss : 0.046540, loss_ce: 0.012657
[01:34:40.823] iteration 11714 : loss : 0.288947, loss_ce: 0.011804
[01:34:41.117] iteration 11715 : loss : 0.107072, loss_ce: 0.008556
[01:34:41.411] iteration 11716 : loss : 0.106094, loss_ce: 0.016729
[01:34:41.706] iteration 11717 : loss : 0.055075, loss_ce: 0.008054
[01:34:42.007] iteration 11718 : loss : 0.037739, loss_ce: 0.011776
[01:34:42.302] iteration 11719 : loss : 0.050758, loss_ce: 0.014900
[01:34:42.601] iteration 11720 : loss : 0.108398, loss_ce: 0.017573
[01:34:42.914] iteration 11721 : loss : 0.054909, loss_ce: 0.015890
[01:34:43.210] iteration 11722 : loss : 0.098264, loss_ce: 0.013071
[01:34:43.506] iteration 11723 : loss : 0.074132, loss_ce: 0.015059
[01:34:43.802] iteration 11724 : loss : 0.057991, loss_ce: 0.020746
[01:34:44.101] iteration 11725 : loss : 0.113508, loss_ce: 0.018721
[01:34:44.398] iteration 11726 : loss : 0.083879, loss_ce: 0.013465
[01:34:44.696] iteration 11727 : loss : 0.049246, loss_ce: 0.023649
[01:34:44.992] iteration 11728 : loss : 0.048479, loss_ce: 0.008654
[01:34:45.290] iteration 11729 : loss : 0.054870, loss_ce: 0.017684
[01:34:45.589] iteration 11730 : loss : 0.060006, loss_ce: 0.019286
[01:34:45.885] iteration 11731 : loss : 0.058195, loss_ce: 0.015580
[01:34:46.185] iteration 11732 : loss : 0.042443, loss_ce: 0.016049
[01:34:46.482] iteration 11733 : loss : 0.053311, loss_ce: 0.024054
[01:34:46.781] iteration 11734 : loss : 0.061186, loss_ce: 0.019623
[01:34:47.077] iteration 11735 : loss : 0.108507, loss_ce: 0.013686
[01:34:47.376] iteration 11736 : loss : 0.091836, loss_ce: 0.019643
[01:34:47.670] iteration 11737 : loss : 0.053864, loss_ce: 0.021748
[01:34:47.970] iteration 11738 : loss : 0.060506, loss_ce: 0.019909
[01:34:48.266] iteration 11739 : loss : 0.061050, loss_ce: 0.010376
[01:34:48.562] iteration 11740 : loss : 0.042081, loss_ce: 0.007712
[01:34:48.874] iteration 11741 : loss : 0.042672, loss_ce: 0.016572
[01:34:49.172] iteration 11742 : loss : 0.052696, loss_ce: 0.016110
[01:34:49.466] iteration 11743 : loss : 0.050379, loss_ce: 0.017810
[01:34:49.763] iteration 11744 : loss : 0.054281, loss_ce: 0.012955
[01:34:50.058] iteration 11745 : loss : 0.052068, loss_ce: 0.018807
[01:34:50.353] iteration 11746 : loss : 0.078638, loss_ce: 0.018641
[01:34:50.654] iteration 11747 : loss : 0.107879, loss_ce: 0.004866
[01:34:50.952] iteration 11748 : loss : 0.050041, loss_ce: 0.010609
[01:34:51.255] iteration 11749 : loss : 0.048029, loss_ce: 0.021760
[01:34:51.552] iteration 11750 : loss : 0.052497, loss_ce: 0.016759
[01:34:51.853] iteration 11751 : loss : 0.048844, loss_ce: 0.022623
[01:34:52.148] iteration 11752 : loss : 0.063060, loss_ce: 0.015640
[01:34:52.450] iteration 11753 : loss : 0.059830, loss_ce: 0.021992
[01:34:52.746] iteration 11754 : loss : 0.065139, loss_ce: 0.003032
[01:34:53.042] iteration 11755 : loss : 0.061902, loss_ce: 0.013322
[01:34:53.342] iteration 11756 : loss : 0.043008, loss_ce: 0.007726
[01:34:53.648] iteration 11757 : loss : 0.068508, loss_ce: 0.020481
[01:34:53.943] iteration 11758 : loss : 0.061317, loss_ce: 0.018277
[01:34:54.243] iteration 11759 : loss : 0.083041, loss_ce: 0.009424
[01:34:54.541] iteration 11760 : loss : 0.065898, loss_ce: 0.014264
[01:34:54.853] iteration 11761 : loss : 0.047955, loss_ce: 0.025790
[01:34:55.149] iteration 11762 : loss : 0.049850, loss_ce: 0.015397
[01:34:55.448] iteration 11763 : loss : 0.050560, loss_ce: 0.014620
[01:34:55.749] iteration 11764 : loss : 0.047278, loss_ce: 0.019714
[01:34:56.045] iteration 11765 : loss : 0.039847, loss_ce: 0.018784
[01:34:56.340] iteration 11766 : loss : 0.051202, loss_ce: 0.015116
[01:34:56.636] iteration 11767 : loss : 0.115137, loss_ce: 0.015105
[01:34:56.933] iteration 11768 : loss : 0.167275, loss_ce: 0.004037
[01:34:57.230] iteration 11769 : loss : 0.050827, loss_ce: 0.012979
[01:34:57.526] iteration 11770 : loss : 0.054859, loss_ce: 0.020077
[01:34:57.827] iteration 11771 : loss : 0.119453, loss_ce: 0.016766
[01:34:58.122] iteration 11772 : loss : 0.070504, loss_ce: 0.018085
[01:34:58.419] iteration 11773 : loss : 0.063462, loss_ce: 0.021236
[01:34:58.717] iteration 11774 : loss : 0.108930, loss_ce: 0.014922
[01:34:59.013] iteration 11775 : loss : 0.062939, loss_ce: 0.023412
[01:34:59.313] iteration 11776 : loss : 0.052834, loss_ce: 0.012744
[01:34:59.608] iteration 11777 : loss : 0.044013, loss_ce: 0.012404
[01:34:59.907] iteration 11778 : loss : 0.092617, loss_ce: 0.012417
[01:35:00.208] iteration 11779 : loss : 0.046461, loss_ce: 0.018461
[01:35:00.509] iteration 11780 : loss : 0.053195, loss_ce: 0.017587
[01:35:00.821] iteration 11781 : loss : 0.124179, loss_ce: 0.009186
[01:35:01.120] iteration 11782 : loss : 0.057216, loss_ce: 0.010930
[01:35:01.413] iteration 11783 : loss : 0.053430, loss_ce: 0.020920
[01:35:01.708] iteration 11784 : loss : 0.157794, loss_ce: 0.010057
[01:35:02.004] iteration 11785 : loss : 0.052301, loss_ce: 0.012418
[01:35:02.299] iteration 11786 : loss : 0.042666, loss_ce: 0.014761
[01:35:02.591] iteration 11787 : loss : 0.057904, loss_ce: 0.020758
[01:35:02.888] iteration 11788 : loss : 0.041869, loss_ce: 0.014591
[01:35:03.183] iteration 11789 : loss : 0.053435, loss_ce: 0.015630
[01:35:03.477] iteration 11790 : loss : 0.040588, loss_ce: 0.015210
[01:35:03.771] iteration 11791 : loss : 0.059592, loss_ce: 0.014510
[01:35:04.066] iteration 11792 : loss : 0.053580, loss_ce: 0.014462
[01:35:04.358] iteration 11793 : loss : 0.049982, loss_ce: 0.016781
[01:35:04.650] iteration 11794 : loss : 0.052117, loss_ce: 0.019171
[01:35:04.941] iteration 11795 : loss : 0.050532, loss_ce: 0.020935
[01:35:05.235] iteration 11796 : loss : 0.046992, loss_ce: 0.014186
[01:35:05.529] iteration 11797 : loss : 0.120032, loss_ce: 0.008177
[01:35:05.821] iteration 11798 : loss : 0.055532, loss_ce: 0.018163
[01:35:06.114] iteration 11799 : loss : 0.105989, loss_ce: 0.012060
[01:35:06.415] iteration 11800 : loss : 0.041154, loss_ce: 0.011319
[01:35:06.749] iteration 11801 : loss : 0.050092, loss_ce: 0.008951
[01:35:07.049] iteration 11802 : loss : 0.049727, loss_ce: 0.010448
[01:35:07.346] iteration 11803 : loss : 0.045006, loss_ce: 0.011795
[01:35:07.644] iteration 11804 : loss : 0.053367, loss_ce: 0.014404
[01:35:07.937] iteration 11805 : loss : 0.116815, loss_ce: 0.009524
[01:35:08.233] iteration 11806 : loss : 0.110047, loss_ce: 0.012962
[01:35:08.529] iteration 11807 : loss : 0.061360, loss_ce: 0.017790
[01:35:08.835] iteration 11808 : loss : 0.064896, loss_ce: 0.023279
[01:35:09.132] iteration 11809 : loss : 0.053242, loss_ce: 0.015614
[01:35:09.435] iteration 11810 : loss : 0.054799, loss_ce: 0.013442
[01:35:09.738] iteration 11811 : loss : 0.055820, loss_ce: 0.023480
[01:35:10.050] iteration 11812 : loss : 0.051848, loss_ce: 0.018327
[01:35:10.359] iteration 11813 : loss : 0.058788, loss_ce: 0.012337
[01:35:10.666] iteration 11814 : loss : 0.060906, loss_ce: 0.004944
[01:35:10.751] iteration 11815 : loss : 0.346124, loss_ce: 0.007639
[01:35:28.113] iteration 11816 : loss : 0.052134, loss_ce: 0.023875
[01:35:28.411] iteration 11817 : loss : 0.109342, loss_ce: 0.012376
[01:35:28.708] iteration 11818 : loss : 0.107954, loss_ce: 0.009167
[01:35:29.002] iteration 11819 : loss : 0.051243, loss_ce: 0.008803
[01:35:29.297] iteration 11820 : loss : 0.077495, loss_ce: 0.006865
[01:35:29.613] iteration 11821 : loss : 0.110876, loss_ce: 0.008837
[01:35:29.909] iteration 11822 : loss : 0.050058, loss_ce: 0.010436
[01:35:30.210] iteration 11823 : loss : 0.051927, loss_ce: 0.029003
[01:35:30.514] iteration 11824 : loss : 0.062863, loss_ce: 0.024777
[01:35:30.811] iteration 11825 : loss : 0.060301, loss_ce: 0.017535
[01:35:31.110] iteration 11826 : loss : 0.052989, loss_ce: 0.012293
[01:35:31.404] iteration 11827 : loss : 0.114348, loss_ce: 0.015034
[01:35:31.701] iteration 11828 : loss : 0.058041, loss_ce: 0.018193
[01:35:31.997] iteration 11829 : loss : 0.121774, loss_ce: 0.010455
[01:35:32.295] iteration 11830 : loss : 0.055089, loss_ce: 0.021764
[01:35:32.595] iteration 11831 : loss : 0.062279, loss_ce: 0.013763
[01:35:32.892] iteration 11832 : loss : 0.100582, loss_ce: 0.015734
[01:35:33.186] iteration 11833 : loss : 0.043582, loss_ce: 0.016655
[01:35:33.482] iteration 11834 : loss : 0.042378, loss_ce: 0.010636
[01:35:33.774] iteration 11835 : loss : 0.158252, loss_ce: 0.009837
[01:35:34.068] iteration 11836 : loss : 0.055921, loss_ce: 0.014632
[01:35:34.365] iteration 11837 : loss : 0.044064, loss_ce: 0.008873
[01:35:34.664] iteration 11838 : loss : 0.099278, loss_ce: 0.008492
[01:35:34.960] iteration 11839 : loss : 0.066510, loss_ce: 0.008704
[01:35:35.252] iteration 11840 : loss : 0.061978, loss_ce: 0.022800
[01:35:35.565] iteration 11841 : loss : 0.041302, loss_ce: 0.014164
[01:35:35.862] iteration 11842 : loss : 0.139131, loss_ce: 0.010393
[01:35:36.158] iteration 11843 : loss : 0.048831, loss_ce: 0.016473
[01:35:36.454] iteration 11844 : loss : 0.161066, loss_ce: 0.017264
[01:35:36.752] iteration 11845 : loss : 0.055931, loss_ce: 0.016744
[01:35:37.048] iteration 11846 : loss : 0.054052, loss_ce: 0.020187
[01:35:37.339] iteration 11847 : loss : 0.052097, loss_ce: 0.016502
[01:35:37.639] iteration 11848 : loss : 0.050804, loss_ce: 0.022910
[01:35:37.938] iteration 11849 : loss : 0.039417, loss_ce: 0.017312
[01:35:38.234] iteration 11850 : loss : 0.086804, loss_ce: 0.014136
[01:35:38.529] iteration 11851 : loss : 0.048376, loss_ce: 0.017534
[01:35:38.824] iteration 11852 : loss : 0.058027, loss_ce: 0.012493
[01:35:39.119] iteration 11853 : loss : 0.071455, loss_ce: 0.013211
[01:35:39.411] iteration 11854 : loss : 0.104258, loss_ce: 0.007937
[01:35:39.705] iteration 11855 : loss : 0.085245, loss_ce: 0.020911
[01:35:40.002] iteration 11856 : loss : 0.052582, loss_ce: 0.016152
[01:35:40.297] iteration 11857 : loss : 0.049036, loss_ce: 0.015893
[01:35:40.597] iteration 11858 : loss : 0.048657, loss_ce: 0.017130
[01:35:40.893] iteration 11859 : loss : 0.054913, loss_ce: 0.018549
[01:35:41.186] iteration 11860 : loss : 0.099654, loss_ce: 0.007861
[01:35:41.505] iteration 11861 : loss : 0.055976, loss_ce: 0.016939
[01:35:41.797] iteration 11862 : loss : 0.051893, loss_ce: 0.015721
[01:35:42.089] iteration 11863 : loss : 0.058952, loss_ce: 0.019912
[01:35:42.388] iteration 11864 : loss : 0.042682, loss_ce: 0.011647
[01:35:42.686] iteration 11865 : loss : 0.055044, loss_ce: 0.014469
[01:35:42.980] iteration 11866 : loss : 0.047217, loss_ce: 0.013683
[01:35:43.272] iteration 11867 : loss : 0.064997, loss_ce: 0.023566
[01:35:43.567] iteration 11868 : loss : 0.101333, loss_ce: 0.009898
[01:35:43.857] iteration 11869 : loss : 0.049528, loss_ce: 0.012396
[01:35:44.158] iteration 11870 : loss : 0.122656, loss_ce: 0.017384
[01:35:44.455] iteration 11871 : loss : 0.050299, loss_ce: 0.022494
[01:35:44.750] iteration 11872 : loss : 0.052732, loss_ce: 0.015056
[01:35:45.044] iteration 11873 : loss : 0.060619, loss_ce: 0.012883
[01:35:45.347] iteration 11874 : loss : 0.044295, loss_ce: 0.009620
[01:35:45.640] iteration 11875 : loss : 0.061657, loss_ce: 0.013676
[01:35:45.935] iteration 11876 : loss : 0.068597, loss_ce: 0.019935
[01:35:46.229] iteration 11877 : loss : 0.055212, loss_ce: 0.016544
[01:35:46.524] iteration 11878 : loss : 0.044820, loss_ce: 0.018865
[01:35:46.823] iteration 11879 : loss : 0.048216, loss_ce: 0.013975
[01:35:47.121] iteration 11880 : loss : 0.042295, loss_ce: 0.012487
[01:35:47.434] iteration 11881 : loss : 0.049190, loss_ce: 0.016060
[01:35:47.732] iteration 11882 : loss : 0.174502, loss_ce: 0.006522
[01:35:48.029] iteration 11883 : loss : 0.121763, loss_ce: 0.011123
[01:35:48.326] iteration 11884 : loss : 0.055938, loss_ce: 0.017386
[01:35:48.626] iteration 11885 : loss : 0.044589, loss_ce: 0.013555
[01:35:48.923] iteration 11886 : loss : 0.067214, loss_ce: 0.007815
[01:35:49.219] iteration 11887 : loss : 0.047358, loss_ce: 0.011852
[01:35:49.517] iteration 11888 : loss : 0.058655, loss_ce: 0.016211
[01:35:49.814] iteration 11889 : loss : 0.056604, loss_ce: 0.008709
[01:35:50.113] iteration 11890 : loss : 0.054125, loss_ce: 0.021650
[01:35:50.407] iteration 11891 : loss : 0.048656, loss_ce: 0.017208
[01:35:50.706] iteration 11892 : loss : 0.040863, loss_ce: 0.013514
[01:35:51.004] iteration 11893 : loss : 0.055139, loss_ce: 0.023486
[01:35:51.301] iteration 11894 : loss : 0.114942, loss_ce: 0.013231
[01:35:51.597] iteration 11895 : loss : 0.056833, loss_ce: 0.016706
[01:35:51.890] iteration 11896 : loss : 0.052427, loss_ce: 0.025876
[01:35:52.189] iteration 11897 : loss : 0.054706, loss_ce: 0.012865
[01:35:52.485] iteration 11898 : loss : 0.048600, loss_ce: 0.016193
[01:35:52.783] iteration 11899 : loss : 0.035395, loss_ce: 0.007395
[01:35:53.080] iteration 11900 : loss : 0.050789, loss_ce: 0.012894
[01:35:53.390] iteration 11901 : loss : 0.095799, loss_ce: 0.011157
[01:35:53.686] iteration 11902 : loss : 0.043789, loss_ce: 0.021257
[01:35:53.982] iteration 11903 : loss : 0.105004, loss_ce: 0.012547
[01:35:54.282] iteration 11904 : loss : 0.067717, loss_ce: 0.019991
[01:35:54.584] iteration 11905 : loss : 0.106931, loss_ce: 0.004318
[01:35:54.879] iteration 11906 : loss : 0.063160, loss_ce: 0.012659
[01:35:55.174] iteration 11907 : loss : 0.045603, loss_ce: 0.016308
[01:35:55.473] iteration 11908 : loss : 0.045551, loss_ce: 0.013349
[01:35:55.774] iteration 11909 : loss : 0.052727, loss_ce: 0.013680
[01:35:56.070] iteration 11910 : loss : 0.106604, loss_ce: 0.011904
[01:35:56.368] iteration 11911 : loss : 0.052642, loss_ce: 0.016824
[01:35:56.668] iteration 11912 : loss : 0.071682, loss_ce: 0.013887
[01:35:56.966] iteration 11913 : loss : 0.104594, loss_ce: 0.013553
[01:35:57.263] iteration 11914 : loss : 0.111568, loss_ce: 0.017907
[01:35:57.560] iteration 11915 : loss : 0.116282, loss_ce: 0.007143
[01:35:57.856] iteration 11916 : loss : 0.053378, loss_ce: 0.021551
[01:35:58.153] iteration 11917 : loss : 0.107927, loss_ce: 0.016525
[01:35:58.451] iteration 11918 : loss : 0.092816, loss_ce: 0.015597
[01:35:58.749] iteration 11919 : loss : 0.065572, loss_ce: 0.017308
[01:35:59.047] iteration 11920 : loss : 0.053307, loss_ce: 0.020293
[01:35:59.368] iteration 11921 : loss : 0.065309, loss_ce: 0.022608
[01:35:59.667] iteration 11922 : loss : 0.048762, loss_ce: 0.015908
[01:35:59.964] iteration 11923 : loss : 0.049881, loss_ce: 0.018362
[01:36:00.262] iteration 11924 : loss : 0.123019, loss_ce: 0.012609
[01:36:00.560] iteration 11925 : loss : 0.102044, loss_ce: 0.008993
[01:36:00.862] iteration 11926 : loss : 0.049176, loss_ce: 0.019254
[01:36:01.166] iteration 11927 : loss : 0.051624, loss_ce: 0.016017
[01:36:01.463] iteration 11928 : loss : 0.052813, loss_ce: 0.021399
[01:36:01.759] iteration 11929 : loss : 0.037721, loss_ce: 0.010114
[01:36:02.058] iteration 11930 : loss : 0.092326, loss_ce: 0.016693
[01:36:02.360] iteration 11931 : loss : 0.106091, loss_ce: 0.011349
[01:36:02.656] iteration 11932 : loss : 0.064378, loss_ce: 0.017935
[01:36:02.953] iteration 11933 : loss : 0.114022, loss_ce: 0.012945
[01:36:03.251] iteration 11934 : loss : 0.069868, loss_ce: 0.020172
[01:36:03.550] iteration 11935 : loss : 0.052861, loss_ce: 0.020878
[01:36:03.851] iteration 11936 : loss : 0.105376, loss_ce: 0.007171
[01:36:04.148] iteration 11937 : loss : 0.062741, loss_ce: 0.014686
[01:36:04.446] iteration 11938 : loss : 0.178546, loss_ce: 0.008984
[01:36:04.745] iteration 11939 : loss : 0.063581, loss_ce: 0.017561
[01:36:05.047] iteration 11940 : loss : 0.077455, loss_ce: 0.012656
[01:36:05.385] iteration 11941 : loss : 0.062226, loss_ce: 0.019735
[01:36:05.686] iteration 11942 : loss : 0.162235, loss_ce: 0.006687
[01:36:05.989] iteration 11943 : loss : 0.051141, loss_ce: 0.014654
[01:36:06.289] iteration 11944 : loss : 0.050040, loss_ce: 0.017666
[01:36:06.591] iteration 11945 : loss : 0.050543, loss_ce: 0.023849
[01:36:06.890] iteration 11946 : loss : 0.099553, loss_ce: 0.011841
[01:36:07.188] iteration 11947 : loss : 0.109643, loss_ce: 0.020235
[01:36:07.489] iteration 11948 : loss : 0.054175, loss_ce: 0.016934
[01:36:07.786] iteration 11949 : loss : 0.057149, loss_ce: 0.009861
[01:36:08.087] iteration 11950 : loss : 0.046527, loss_ce: 0.010167
[01:36:08.391] iteration 11951 : loss : 0.043994, loss_ce: 0.012650
[01:36:08.690] iteration 11952 : loss : 0.053774, loss_ce: 0.011592
[01:36:08.992] iteration 11953 : loss : 0.107291, loss_ce: 0.014590
[01:36:09.075] iteration 11954 : loss : 0.280923, loss_ce: 0.012027
[01:36:29.908] iteration 11955 : loss : 0.039753, loss_ce: 0.013463
[01:36:30.200] iteration 11956 : loss : 0.107511, loss_ce: 0.011337
[01:36:30.494] iteration 11957 : loss : 0.051046, loss_ce: 0.016749
[01:36:30.788] iteration 11958 : loss : 0.036942, loss_ce: 0.009342
[01:36:31.084] iteration 11959 : loss : 0.045515, loss_ce: 0.010970
[01:36:31.375] iteration 11960 : loss : 0.097911, loss_ce: 0.007450
[01:36:31.678] iteration 11961 : loss : 0.060497, loss_ce: 0.013707
[01:36:31.969] iteration 11962 : loss : 0.050952, loss_ce: 0.010777
[01:36:32.260] iteration 11963 : loss : 0.043886, loss_ce: 0.012218
[01:36:32.550] iteration 11964 : loss : 0.048219, loss_ce: 0.005603
[01:36:32.842] iteration 11965 : loss : 0.106080, loss_ce: 0.014924
[01:36:33.133] iteration 11966 : loss : 0.157083, loss_ce: 0.005825
[01:36:33.422] iteration 11967 : loss : 0.170741, loss_ce: 0.005441
[01:36:33.715] iteration 11968 : loss : 0.047936, loss_ce: 0.010732
[01:36:34.005] iteration 11969 : loss : 0.154405, loss_ce: 0.004621
[01:36:34.305] iteration 11970 : loss : 0.056707, loss_ce: 0.015005
[01:36:34.599] iteration 11971 : loss : 0.051561, loss_ce: 0.010452
[01:36:34.897] iteration 11972 : loss : 0.108050, loss_ce: 0.009254
[01:36:35.194] iteration 11973 : loss : 0.059948, loss_ce: 0.022479
[01:36:35.490] iteration 11974 : loss : 0.054530, loss_ce: 0.024863
[01:36:35.789] iteration 11975 : loss : 0.167781, loss_ce: 0.013469
[01:36:36.088] iteration 11976 : loss : 0.102653, loss_ce: 0.010333
[01:36:36.382] iteration 11977 : loss : 0.050619, loss_ce: 0.012019
[01:36:36.675] iteration 11978 : loss : 0.058020, loss_ce: 0.014084
[01:36:36.967] iteration 11979 : loss : 0.096830, loss_ce: 0.007835
[01:36:37.257] iteration 11980 : loss : 0.104825, loss_ce: 0.007098
[01:36:37.567] iteration 11981 : loss : 0.103740, loss_ce: 0.008072
[01:36:37.859] iteration 11982 : loss : 0.104515, loss_ce: 0.011843
[01:36:38.151] iteration 11983 : loss : 0.049615, loss_ce: 0.022295
[01:36:38.444] iteration 11984 : loss : 0.055137, loss_ce: 0.017866
[01:36:38.738] iteration 11985 : loss : 0.050914, loss_ce: 0.012069
[01:36:39.026] iteration 11986 : loss : 0.053420, loss_ce: 0.015786
[01:36:39.320] iteration 11987 : loss : 0.046624, loss_ce: 0.020000
[01:36:39.610] iteration 11988 : loss : 0.049412, loss_ce: 0.013450
[01:36:39.901] iteration 11989 : loss : 0.052451, loss_ce: 0.019108
[01:36:40.195] iteration 11990 : loss : 0.048519, loss_ce: 0.015888
[01:36:40.488] iteration 11991 : loss : 0.042665, loss_ce: 0.010750
[01:36:40.782] iteration 11992 : loss : 0.072844, loss_ce: 0.015516
[01:36:41.076] iteration 11993 : loss : 0.054427, loss_ce: 0.022248
[01:36:41.366] iteration 11994 : loss : 0.054470, loss_ce: 0.017211
[01:36:41.657] iteration 11995 : loss : 0.108256, loss_ce: 0.007391
[01:36:41.946] iteration 11996 : loss : 0.046566, loss_ce: 0.018115
[01:36:42.241] iteration 11997 : loss : 0.062267, loss_ce: 0.015999
[01:36:42.532] iteration 11998 : loss : 0.111666, loss_ce: 0.018499
[01:36:42.826] iteration 11999 : loss : 0.059589, loss_ce: 0.014343
[01:36:43.117] iteration 12000 : loss : 0.056723, loss_ce: 0.011424
[01:36:43.424] iteration 12001 : loss : 0.052814, loss_ce: 0.020920
[01:36:43.717] iteration 12002 : loss : 0.051805, loss_ce: 0.016822
[01:36:44.009] iteration 12003 : loss : 0.041637, loss_ce: 0.009570
[01:36:44.305] iteration 12004 : loss : 0.058400, loss_ce: 0.020188
[01:36:44.598] iteration 12005 : loss : 0.047468, loss_ce: 0.012038
[01:36:44.889] iteration 12006 : loss : 0.042954, loss_ce: 0.015197
[01:36:45.180] iteration 12007 : loss : 0.106985, loss_ce: 0.006193
[01:36:45.471] iteration 12008 : loss : 0.097517, loss_ce: 0.004608
[01:36:45.768] iteration 12009 : loss : 0.117342, loss_ce: 0.022406
[01:36:46.062] iteration 12010 : loss : 0.051070, loss_ce: 0.010551
[01:36:46.355] iteration 12011 : loss : 0.067954, loss_ce: 0.038570
[01:36:46.647] iteration 12012 : loss : 0.118701, loss_ce: 0.019369
[01:36:46.938] iteration 12013 : loss : 0.059502, loss_ce: 0.018272
[01:36:47.232] iteration 12014 : loss : 0.053213, loss_ce: 0.022838
[01:36:47.527] iteration 12015 : loss : 0.179453, loss_ce: 0.016943
[01:36:47.819] iteration 12016 : loss : 0.049774, loss_ce: 0.016770
[01:36:48.112] iteration 12017 : loss : 0.043633, loss_ce: 0.010306
[01:36:48.406] iteration 12018 : loss : 0.156800, loss_ce: 0.006523
[01:36:48.698] iteration 12019 : loss : 0.054976, loss_ce: 0.020694
[01:36:48.992] iteration 12020 : loss : 0.107592, loss_ce: 0.015708
[01:36:49.303] iteration 12021 : loss : 0.108426, loss_ce: 0.015954
[01:36:49.598] iteration 12022 : loss : 0.056347, loss_ce: 0.014932
[01:36:49.892] iteration 12023 : loss : 0.044436, loss_ce: 0.005967
[01:36:50.189] iteration 12024 : loss : 0.054917, loss_ce: 0.020107
[01:36:50.487] iteration 12025 : loss : 0.040751, loss_ce: 0.018165
[01:36:50.785] iteration 12026 : loss : 0.043085, loss_ce: 0.018011
[01:36:51.076] iteration 12027 : loss : 0.061773, loss_ce: 0.024308
[01:36:51.370] iteration 12028 : loss : 0.059586, loss_ce: 0.019647
[01:36:51.666] iteration 12029 : loss : 0.049667, loss_ce: 0.020386
[01:36:51.966] iteration 12030 : loss : 0.056199, loss_ce: 0.008685
[01:36:52.260] iteration 12031 : loss : 0.045698, loss_ce: 0.011177
[01:36:52.559] iteration 12032 : loss : 0.047494, loss_ce: 0.014707
[01:36:52.855] iteration 12033 : loss : 0.040294, loss_ce: 0.013635
[01:36:53.146] iteration 12034 : loss : 0.039000, loss_ce: 0.011923
[01:36:53.444] iteration 12035 : loss : 0.111600, loss_ce: 0.006326
[01:36:53.741] iteration 12036 : loss : 0.109669, loss_ce: 0.020211
[01:36:54.040] iteration 12037 : loss : 0.058584, loss_ce: 0.017068
[01:36:54.337] iteration 12038 : loss : 0.068976, loss_ce: 0.010144
[01:36:54.639] iteration 12039 : loss : 0.074771, loss_ce: 0.023778
[01:36:54.939] iteration 12040 : loss : 0.042191, loss_ce: 0.013434
[01:36:55.257] iteration 12041 : loss : 0.111016, loss_ce: 0.018516
[01:36:55.555] iteration 12042 : loss : 0.066944, loss_ce: 0.018121
[01:36:55.853] iteration 12043 : loss : 0.043951, loss_ce: 0.022389
[01:36:56.149] iteration 12044 : loss : 0.120278, loss_ce: 0.014692
[01:36:56.444] iteration 12045 : loss : 0.056769, loss_ce: 0.011119
[01:36:56.741] iteration 12046 : loss : 0.063423, loss_ce: 0.010642
[01:36:57.041] iteration 12047 : loss : 0.057500, loss_ce: 0.021863
[01:36:57.337] iteration 12048 : loss : 0.058440, loss_ce: 0.020949
[01:36:57.634] iteration 12049 : loss : 0.046627, loss_ce: 0.018283
[01:36:57.931] iteration 12050 : loss : 0.046217, loss_ce: 0.016577
[01:36:58.229] iteration 12051 : loss : 0.049594, loss_ce: 0.023976
[01:36:58.526] iteration 12052 : loss : 0.076883, loss_ce: 0.025341
[01:36:58.828] iteration 12053 : loss : 0.048488, loss_ce: 0.018667
[01:36:59.126] iteration 12054 : loss : 0.042380, loss_ce: 0.011734
[01:36:59.423] iteration 12055 : loss : 0.054212, loss_ce: 0.013920
[01:36:59.718] iteration 12056 : loss : 0.053704, loss_ce: 0.018337
[01:37:00.016] iteration 12057 : loss : 0.053375, loss_ce: 0.014945
[01:37:00.311] iteration 12058 : loss : 0.130050, loss_ce: 0.004773
[01:37:00.610] iteration 12059 : loss : 0.047670, loss_ce: 0.011177
[01:37:00.909] iteration 12060 : loss : 0.111510, loss_ce: 0.010142
[01:37:01.224] iteration 12061 : loss : 0.052850, loss_ce: 0.020046
[01:37:01.523] iteration 12062 : loss : 0.060192, loss_ce: 0.025336
[01:37:01.820] iteration 12063 : loss : 0.043096, loss_ce: 0.012811
[01:37:02.118] iteration 12064 : loss : 0.051977, loss_ce: 0.023361
[01:37:02.417] iteration 12065 : loss : 0.047260, loss_ce: 0.019378
[01:37:02.717] iteration 12066 : loss : 0.049818, loss_ce: 0.019742
[01:37:03.015] iteration 12067 : loss : 0.111995, loss_ce: 0.005344
[01:37:03.317] iteration 12068 : loss : 0.048797, loss_ce: 0.009771
[01:37:03.616] iteration 12069 : loss : 0.117961, loss_ce: 0.009638
[01:37:03.912] iteration 12070 : loss : 0.105401, loss_ce: 0.016548
[01:37:04.209] iteration 12071 : loss : 0.109675, loss_ce: 0.005058
[01:37:04.510] iteration 12072 : loss : 0.179938, loss_ce: 0.007209
[01:37:04.812] iteration 12073 : loss : 0.045372, loss_ce: 0.010056
[01:37:05.107] iteration 12074 : loss : 0.076970, loss_ce: 0.015114
[01:37:05.403] iteration 12075 : loss : 0.040963, loss_ce: 0.015367
[01:37:05.701] iteration 12076 : loss : 0.037482, loss_ce: 0.011938
[01:37:06.003] iteration 12077 : loss : 0.038849, loss_ce: 0.016149
[01:37:06.310] iteration 12078 : loss : 0.044833, loss_ce: 0.017582
[01:37:06.618] iteration 12079 : loss : 0.057710, loss_ce: 0.010658
[01:37:06.919] iteration 12080 : loss : 0.101886, loss_ce: 0.009002
[01:37:07.247] iteration 12081 : loss : 0.055643, loss_ce: 0.025657
[01:37:07.546] iteration 12082 : loss : 0.047767, loss_ce: 0.013167
[01:37:07.849] iteration 12083 : loss : 0.052832, loss_ce: 0.013695
[01:37:08.150] iteration 12084 : loss : 0.071767, loss_ce: 0.013634
[01:37:08.454] iteration 12085 : loss : 0.051434, loss_ce: 0.014688
[01:37:08.755] iteration 12086 : loss : 0.048975, loss_ce: 0.019023
[01:37:09.058] iteration 12087 : loss : 0.055112, loss_ce: 0.022117
[01:37:09.363] iteration 12088 : loss : 0.226272, loss_ce: 0.003993
[01:37:09.663] iteration 12089 : loss : 0.052560, loss_ce: 0.016171
[01:37:09.968] iteration 12090 : loss : 0.047498, loss_ce: 0.014778
[01:37:10.268] iteration 12091 : loss : 0.048130, loss_ce: 0.009188
[01:37:10.566] iteration 12092 : loss : 0.047884, loss_ce: 0.013580
[01:37:10.645] iteration 12093 : loss : 0.341968, loss_ce: 0.008231
[01:37:28.584] iteration 12094 : loss : 0.103301, loss_ce: 0.010384
[01:37:28.881] iteration 12095 : loss : 0.049652, loss_ce: 0.013569
[01:37:29.175] iteration 12096 : loss : 0.055969, loss_ce: 0.020485
[01:37:29.471] iteration 12097 : loss : 0.167431, loss_ce: 0.007464
[01:37:29.772] iteration 12098 : loss : 0.038586, loss_ce: 0.008466
[01:37:30.066] iteration 12099 : loss : 0.048642, loss_ce: 0.014200
[01:37:30.357] iteration 12100 : loss : 0.080859, loss_ce: 0.013134
[01:37:30.675] iteration 12101 : loss : 0.058646, loss_ce: 0.016395
[01:37:30.972] iteration 12102 : loss : 0.061151, loss_ce: 0.012940
[01:37:31.265] iteration 12103 : loss : 0.044931, loss_ce: 0.012805
[01:37:31.555] iteration 12104 : loss : 0.059365, loss_ce: 0.015134
[01:37:31.849] iteration 12105 : loss : 0.102934, loss_ce: 0.008477
[01:37:32.143] iteration 12106 : loss : 0.040480, loss_ce: 0.014512
[01:37:32.439] iteration 12107 : loss : 0.071675, loss_ce: 0.017056
[01:37:32.731] iteration 12108 : loss : 0.042250, loss_ce: 0.013706
[01:37:33.026] iteration 12109 : loss : 0.039198, loss_ce: 0.008393
[01:37:33.321] iteration 12110 : loss : 0.046201, loss_ce: 0.014489
[01:37:33.612] iteration 12111 : loss : 0.137356, loss_ce: 0.009138
[01:37:33.906] iteration 12112 : loss : 0.051370, loss_ce: 0.013000
[01:37:34.197] iteration 12113 : loss : 0.069358, loss_ce: 0.022228
[01:37:34.490] iteration 12114 : loss : 0.050354, loss_ce: 0.014757
[01:37:34.785] iteration 12115 : loss : 0.045704, loss_ce: 0.019887
[01:37:35.083] iteration 12116 : loss : 0.044219, loss_ce: 0.014600
[01:37:35.375] iteration 12117 : loss : 0.043278, loss_ce: 0.012325
[01:37:35.671] iteration 12118 : loss : 0.053059, loss_ce: 0.008899
[01:37:35.969] iteration 12119 : loss : 0.067344, loss_ce: 0.012837
[01:37:36.266] iteration 12120 : loss : 0.032789, loss_ce: 0.005238
[01:37:36.579] iteration 12121 : loss : 0.101801, loss_ce: 0.010445
[01:37:36.870] iteration 12122 : loss : 0.099876, loss_ce: 0.012370
[01:37:37.165] iteration 12123 : loss : 0.050067, loss_ce: 0.014378
[01:37:37.461] iteration 12124 : loss : 0.051369, loss_ce: 0.019567
[01:37:37.758] iteration 12125 : loss : 0.054303, loss_ce: 0.014911
[01:37:38.048] iteration 12126 : loss : 0.051855, loss_ce: 0.011227
[01:37:38.344] iteration 12127 : loss : 0.060531, loss_ce: 0.021284
[01:37:38.638] iteration 12128 : loss : 0.103115, loss_ce: 0.013067
[01:37:38.931] iteration 12129 : loss : 0.060174, loss_ce: 0.015567
[01:37:39.234] iteration 12130 : loss : 0.053971, loss_ce: 0.013892
[01:37:39.534] iteration 12131 : loss : 0.058446, loss_ce: 0.023323
[01:37:39.833] iteration 12132 : loss : 0.054055, loss_ce: 0.013721
[01:37:40.130] iteration 12133 : loss : 0.117525, loss_ce: 0.013323
[01:37:40.430] iteration 12134 : loss : 0.055247, loss_ce: 0.020596
[01:37:40.731] iteration 12135 : loss : 0.047591, loss_ce: 0.011528
[01:37:41.029] iteration 12136 : loss : 0.036017, loss_ce: 0.009515
[01:37:41.327] iteration 12137 : loss : 0.062722, loss_ce: 0.015631
[01:37:41.624] iteration 12138 : loss : 0.044093, loss_ce: 0.018590
[01:37:41.921] iteration 12139 : loss : 0.057377, loss_ce: 0.028801
[01:37:42.222] iteration 12140 : loss : 0.065757, loss_ce: 0.011852
[01:37:42.535] iteration 12141 : loss : 0.046230, loss_ce: 0.011420
[01:37:42.828] iteration 12142 : loss : 0.039917, loss_ce: 0.010667
[01:37:43.125] iteration 12143 : loss : 0.051187, loss_ce: 0.019226
[01:37:43.421] iteration 12144 : loss : 0.059537, loss_ce: 0.019749
[01:37:43.716] iteration 12145 : loss : 0.047294, loss_ce: 0.018771
[01:37:44.013] iteration 12146 : loss : 0.064799, loss_ce: 0.007153
[01:37:44.313] iteration 12147 : loss : 0.045114, loss_ce: 0.007256
[01:37:44.610] iteration 12148 : loss : 0.056648, loss_ce: 0.016091
[01:37:44.908] iteration 12149 : loss : 0.100006, loss_ce: 0.006666
[01:37:45.205] iteration 12150 : loss : 0.050923, loss_ce: 0.010087
[01:37:45.498] iteration 12151 : loss : 0.039573, loss_ce: 0.012067
[01:37:45.792] iteration 12152 : loss : 0.053519, loss_ce: 0.020828
[01:37:46.087] iteration 12153 : loss : 0.057563, loss_ce: 0.017140
[01:37:46.383] iteration 12154 : loss : 0.111424, loss_ce: 0.018677
[01:37:46.677] iteration 12155 : loss : 0.100637, loss_ce: 0.008724
[01:37:46.971] iteration 12156 : loss : 0.053012, loss_ce: 0.010665
[01:37:47.266] iteration 12157 : loss : 0.045245, loss_ce: 0.009923
[01:37:47.559] iteration 12158 : loss : 0.059325, loss_ce: 0.024544
[01:37:47.855] iteration 12159 : loss : 0.044540, loss_ce: 0.015740
[01:37:48.148] iteration 12160 : loss : 0.122561, loss_ce: 0.011122
[01:37:48.460] iteration 12161 : loss : 0.090040, loss_ce: 0.006177
[01:37:48.751] iteration 12162 : loss : 0.040576, loss_ce: 0.009869
[01:37:49.046] iteration 12163 : loss : 0.049809, loss_ce: 0.015292
[01:37:49.341] iteration 12164 : loss : 0.046853, loss_ce: 0.019224
[01:37:49.634] iteration 12165 : loss : 0.051262, loss_ce: 0.021475
[01:37:49.927] iteration 12166 : loss : 0.082243, loss_ce: 0.013742
[01:37:50.222] iteration 12167 : loss : 0.106769, loss_ce: 0.018863
[01:37:50.519] iteration 12168 : loss : 0.061477, loss_ce: 0.019074
[01:37:50.816] iteration 12169 : loss : 0.112156, loss_ce: 0.016310
[01:37:51.111] iteration 12170 : loss : 0.052001, loss_ce: 0.010036
[01:37:51.406] iteration 12171 : loss : 0.050882, loss_ce: 0.020385
[01:37:51.701] iteration 12172 : loss : 0.044136, loss_ce: 0.014249
[01:37:51.993] iteration 12173 : loss : 0.057751, loss_ce: 0.012344
[01:37:52.289] iteration 12174 : loss : 0.051150, loss_ce: 0.026376
[01:37:52.581] iteration 12175 : loss : 0.051954, loss_ce: 0.037454
[01:37:52.871] iteration 12176 : loss : 0.101202, loss_ce: 0.005718
[01:37:53.167] iteration 12177 : loss : 0.113170, loss_ce: 0.009705
[01:37:53.464] iteration 12178 : loss : 0.053977, loss_ce: 0.012111
[01:37:53.762] iteration 12179 : loss : 0.054191, loss_ce: 0.019533
[01:37:54.055] iteration 12180 : loss : 0.053883, loss_ce: 0.016871
[01:37:54.367] iteration 12181 : loss : 0.049665, loss_ce: 0.018445
[01:37:54.664] iteration 12182 : loss : 0.046448, loss_ce: 0.016999
[01:37:54.966] iteration 12183 : loss : 0.042997, loss_ce: 0.012848
[01:37:55.264] iteration 12184 : loss : 0.051184, loss_ce: 0.021437
[01:37:55.563] iteration 12185 : loss : 0.164397, loss_ce: 0.009243
[01:37:55.859] iteration 12186 : loss : 0.165593, loss_ce: 0.005939
[01:37:56.159] iteration 12187 : loss : 0.052359, loss_ce: 0.010461
[01:37:56.454] iteration 12188 : loss : 0.053980, loss_ce: 0.022624
[01:37:56.744] iteration 12189 : loss : 0.052507, loss_ce: 0.020291
[01:37:57.037] iteration 12190 : loss : 0.048330, loss_ce: 0.015026
[01:37:57.334] iteration 12191 : loss : 0.062350, loss_ce: 0.018601
[01:37:57.624] iteration 12192 : loss : 0.041721, loss_ce: 0.010164
[01:37:57.915] iteration 12193 : loss : 0.041123, loss_ce: 0.016919
[01:37:58.214] iteration 12194 : loss : 0.051537, loss_ce: 0.027959
[01:37:58.507] iteration 12195 : loss : 0.133488, loss_ce: 0.012348
[01:37:58.800] iteration 12196 : loss : 0.050393, loss_ce: 0.014263
[01:37:59.098] iteration 12197 : loss : 0.118656, loss_ce: 0.012200
[01:37:59.394] iteration 12198 : loss : 0.043101, loss_ce: 0.012548
[01:37:59.695] iteration 12199 : loss : 0.102925, loss_ce: 0.015571
[01:37:59.987] iteration 12200 : loss : 0.108965, loss_ce: 0.017307
[01:38:00.300] iteration 12201 : loss : 0.097881, loss_ce: 0.006139
[01:38:00.592] iteration 12202 : loss : 0.051171, loss_ce: 0.020596
[01:38:00.888] iteration 12203 : loss : 0.056113, loss_ce: 0.008153
[01:38:01.185] iteration 12204 : loss : 0.050984, loss_ce: 0.008800
[01:38:01.481] iteration 12205 : loss : 0.047549, loss_ce: 0.009942
[01:38:01.774] iteration 12206 : loss : 0.058857, loss_ce: 0.012196
[01:38:02.066] iteration 12207 : loss : 0.107729, loss_ce: 0.008402
[01:38:02.367] iteration 12208 : loss : 0.045579, loss_ce: 0.012891
[01:38:02.657] iteration 12209 : loss : 0.109080, loss_ce: 0.010059
[01:38:02.947] iteration 12210 : loss : 0.039932, loss_ce: 0.018031
[01:38:03.242] iteration 12211 : loss : 0.046808, loss_ce: 0.018241
[01:38:03.535] iteration 12212 : loss : 0.044247, loss_ce: 0.014658
[01:38:03.828] iteration 12213 : loss : 0.049738, loss_ce: 0.019250
[01:38:04.119] iteration 12214 : loss : 0.038352, loss_ce: 0.008955
[01:38:04.411] iteration 12215 : loss : 0.165123, loss_ce: 0.009821
[01:38:04.710] iteration 12216 : loss : 0.047487, loss_ce: 0.015191
[01:38:05.009] iteration 12217 : loss : 0.042113, loss_ce: 0.013000
[01:38:05.304] iteration 12218 : loss : 0.055547, loss_ce: 0.015273
[01:38:05.602] iteration 12219 : loss : 0.048150, loss_ce: 0.016696
[01:38:05.904] iteration 12220 : loss : 0.100046, loss_ce: 0.013461
[01:38:06.217] iteration 12221 : loss : 0.141305, loss_ce: 0.005069
[01:38:06.519] iteration 12222 : loss : 0.066416, loss_ce: 0.011009
[01:38:06.827] iteration 12223 : loss : 0.047573, loss_ce: 0.024961
[01:38:07.130] iteration 12224 : loss : 0.046915, loss_ce: 0.022820
[01:38:07.427] iteration 12225 : loss : 0.056114, loss_ce: 0.014837
[01:38:07.728] iteration 12226 : loss : 0.042652, loss_ce: 0.013969
[01:38:08.024] iteration 12227 : loss : 0.045147, loss_ce: 0.017010
[01:38:08.325] iteration 12228 : loss : 0.127564, loss_ce: 0.017107
[01:38:08.630] iteration 12229 : loss : 0.049304, loss_ce: 0.016400
[01:38:08.927] iteration 12230 : loss : 0.044729, loss_ce: 0.011565
[01:38:09.229] iteration 12231 : loss : 0.108203, loss_ce: 0.007816
[01:38:09.311] iteration 12232 : loss : 0.321739, loss_ce: 0.000035
[01:38:27.169] iteration 12233 : loss : 0.051082, loss_ce: 0.016245
[01:38:27.470] iteration 12234 : loss : 0.059856, loss_ce: 0.029199
[01:38:27.771] iteration 12235 : loss : 0.066802, loss_ce: 0.026893
[01:38:28.067] iteration 12236 : loss : 0.075976, loss_ce: 0.012357
[01:38:28.374] iteration 12237 : loss : 0.088710, loss_ce: 0.025621
[01:38:28.667] iteration 12238 : loss : 0.117242, loss_ce: 0.017417
[01:38:28.964] iteration 12239 : loss : 0.070157, loss_ce: 0.016911
[01:38:29.262] iteration 12240 : loss : 0.051949, loss_ce: 0.021283
[01:38:29.576] iteration 12241 : loss : 0.058356, loss_ce: 0.017215
[01:38:29.875] iteration 12242 : loss : 0.062413, loss_ce: 0.024261
[01:38:30.167] iteration 12243 : loss : 0.078084, loss_ce: 0.021945
[01:38:30.462] iteration 12244 : loss : 0.072935, loss_ce: 0.022455
[01:38:30.758] iteration 12245 : loss : 0.063903, loss_ce: 0.023197
[01:38:31.053] iteration 12246 : loss : 0.069383, loss_ce: 0.020076
[01:38:31.345] iteration 12247 : loss : 0.079284, loss_ce: 0.019392
[01:38:31.634] iteration 12248 : loss : 0.105386, loss_ce: 0.010578
[01:38:31.925] iteration 12249 : loss : 0.074445, loss_ce: 0.019302
[01:38:32.217] iteration 12250 : loss : 0.053208, loss_ce: 0.010445
[01:38:32.509] iteration 12251 : loss : 0.046602, loss_ce: 0.011323
[01:38:32.804] iteration 12252 : loss : 0.061440, loss_ce: 0.013112
[01:38:33.096] iteration 12253 : loss : 0.053855, loss_ce: 0.012723
[01:38:33.388] iteration 12254 : loss : 0.054039, loss_ce: 0.017899
[01:38:33.682] iteration 12255 : loss : 0.055569, loss_ce: 0.017686
[01:38:33.976] iteration 12256 : loss : 0.057070, loss_ce: 0.023085
[01:38:34.268] iteration 12257 : loss : 0.114685, loss_ce: 0.011224
[01:38:34.564] iteration 12258 : loss : 0.062343, loss_ce: 0.016079
[01:38:34.858] iteration 12259 : loss : 0.051960, loss_ce: 0.013164
[01:38:35.147] iteration 12260 : loss : 0.220947, loss_ce: 0.003093
[01:38:35.455] iteration 12261 : loss : 0.048226, loss_ce: 0.016500
[01:38:35.745] iteration 12262 : loss : 0.051581, loss_ce: 0.026152
[01:38:36.036] iteration 12263 : loss : 0.046529, loss_ce: 0.018699
[01:38:36.328] iteration 12264 : loss : 0.107846, loss_ce: 0.014178
[01:38:36.622] iteration 12265 : loss : 0.050572, loss_ce: 0.016229
[01:38:36.914] iteration 12266 : loss : 0.061521, loss_ce: 0.009432
[01:38:37.207] iteration 12267 : loss : 0.053131, loss_ce: 0.019494
[01:38:37.501] iteration 12268 : loss : 0.071173, loss_ce: 0.018502
[01:38:37.794] iteration 12269 : loss : 0.046986, loss_ce: 0.010848
[01:38:38.089] iteration 12270 : loss : 0.057172, loss_ce: 0.017864
[01:38:38.384] iteration 12271 : loss : 0.058627, loss_ce: 0.019659
[01:38:38.677] iteration 12272 : loss : 0.100362, loss_ce: 0.012494
[01:38:38.968] iteration 12273 : loss : 0.051788, loss_ce: 0.012396
[01:38:39.259] iteration 12274 : loss : 0.115741, loss_ce: 0.009680
[01:38:39.552] iteration 12275 : loss : 0.056712, loss_ce: 0.017897
[01:38:39.841] iteration 12276 : loss : 0.083138, loss_ce: 0.012648
[01:38:40.130] iteration 12277 : loss : 0.048980, loss_ce: 0.018217
[01:38:40.425] iteration 12278 : loss : 0.099068, loss_ce: 0.005108
[01:38:40.718] iteration 12279 : loss : 0.043183, loss_ce: 0.019971
[01:38:41.011] iteration 12280 : loss : 0.107026, loss_ce: 0.017858
[01:38:41.328] iteration 12281 : loss : 0.054125, loss_ce: 0.013103
[01:38:41.618] iteration 12282 : loss : 0.054292, loss_ce: 0.019302
[01:38:41.914] iteration 12283 : loss : 0.045470, loss_ce: 0.018330
[01:38:42.209] iteration 12284 : loss : 0.060951, loss_ce: 0.031094
[01:38:42.500] iteration 12285 : loss : 0.064745, loss_ce: 0.024678
[01:38:42.793] iteration 12286 : loss : 0.112630, loss_ce: 0.014728
[01:38:43.085] iteration 12287 : loss : 0.176531, loss_ce: 0.005872
[01:38:43.379] iteration 12288 : loss : 0.051547, loss_ce: 0.020999
[01:38:43.671] iteration 12289 : loss : 0.055799, loss_ce: 0.011206
[01:38:43.963] iteration 12290 : loss : 0.044553, loss_ce: 0.010830
[01:38:44.259] iteration 12291 : loss : 0.039832, loss_ce: 0.014708
[01:38:44.557] iteration 12292 : loss : 0.055532, loss_ce: 0.014152
[01:38:44.859] iteration 12293 : loss : 0.061838, loss_ce: 0.017447
[01:38:45.158] iteration 12294 : loss : 0.056708, loss_ce: 0.025983
[01:38:45.457] iteration 12295 : loss : 0.049601, loss_ce: 0.022210
[01:38:45.758] iteration 12296 : loss : 0.055259, loss_ce: 0.019184
[01:38:46.058] iteration 12297 : loss : 0.055433, loss_ce: 0.009390
[01:38:46.347] iteration 12298 : loss : 0.046720, loss_ce: 0.016826
[01:38:46.642] iteration 12299 : loss : 0.066443, loss_ce: 0.025054
[01:38:46.936] iteration 12300 : loss : 0.055075, loss_ce: 0.013109
[01:38:47.246] iteration 12301 : loss : 0.064964, loss_ce: 0.019359
[01:38:47.537] iteration 12302 : loss : 0.097945, loss_ce: 0.014444
[01:38:47.834] iteration 12303 : loss : 0.052795, loss_ce: 0.013318
[01:38:48.130] iteration 12304 : loss : 0.095820, loss_ce: 0.017767
[01:38:48.425] iteration 12305 : loss : 0.053116, loss_ce: 0.017152
[01:38:48.717] iteration 12306 : loss : 0.054588, loss_ce: 0.030488
[01:38:49.012] iteration 12307 : loss : 0.045334, loss_ce: 0.022453
[01:38:49.305] iteration 12308 : loss : 0.108841, loss_ce: 0.015119
[01:38:49.598] iteration 12309 : loss : 0.102882, loss_ce: 0.017480
[01:38:49.889] iteration 12310 : loss : 0.060540, loss_ce: 0.014940
[01:38:50.184] iteration 12311 : loss : 0.042302, loss_ce: 0.007958
[01:38:50.478] iteration 12312 : loss : 0.055376, loss_ce: 0.007958
[01:38:50.773] iteration 12313 : loss : 0.036256, loss_ce: 0.007579
[01:38:51.062] iteration 12314 : loss : 0.076178, loss_ce: 0.011906
[01:38:51.357] iteration 12315 : loss : 0.053326, loss_ce: 0.018145
[01:38:51.652] iteration 12316 : loss : 0.057688, loss_ce: 0.012046
[01:38:51.944] iteration 12317 : loss : 0.041071, loss_ce: 0.010452
[01:38:52.235] iteration 12318 : loss : 0.054441, loss_ce: 0.017261
[01:38:52.527] iteration 12319 : loss : 0.119152, loss_ce: 0.019849
[01:38:52.820] iteration 12320 : loss : 0.108124, loss_ce: 0.011463
[01:38:53.132] iteration 12321 : loss : 0.050047, loss_ce: 0.021214
[01:38:53.423] iteration 12322 : loss : 0.056951, loss_ce: 0.020253
[01:38:53.719] iteration 12323 : loss : 0.049098, loss_ce: 0.015253
[01:38:54.012] iteration 12324 : loss : 0.053656, loss_ce: 0.010409
[01:38:54.307] iteration 12325 : loss : 0.056538, loss_ce: 0.014300
[01:38:54.600] iteration 12326 : loss : 0.045032, loss_ce: 0.011066
[01:38:54.898] iteration 12327 : loss : 0.066930, loss_ce: 0.020443
[01:38:55.192] iteration 12328 : loss : 0.053337, loss_ce: 0.019872
[01:38:55.486] iteration 12329 : loss : 0.051781, loss_ce: 0.012315
[01:38:55.778] iteration 12330 : loss : 0.119921, loss_ce: 0.010735
[01:38:56.072] iteration 12331 : loss : 0.062038, loss_ce: 0.014222
[01:38:56.365] iteration 12332 : loss : 0.047337, loss_ce: 0.022181
[01:38:56.658] iteration 12333 : loss : 0.050170, loss_ce: 0.012163
[01:38:56.950] iteration 12334 : loss : 0.054083, loss_ce: 0.009248
[01:38:57.243] iteration 12335 : loss : 0.054893, loss_ce: 0.007430
[01:38:57.534] iteration 12336 : loss : 0.053834, loss_ce: 0.029263
[01:38:57.825] iteration 12337 : loss : 0.055971, loss_ce: 0.012733
[01:38:58.119] iteration 12338 : loss : 0.118938, loss_ce: 0.018941
[01:38:58.411] iteration 12339 : loss : 0.118195, loss_ce: 0.013151
[01:38:58.705] iteration 12340 : loss : 0.064331, loss_ce: 0.015343
[01:38:59.017] iteration 12341 : loss : 0.048412, loss_ce: 0.015108
[01:38:59.317] iteration 12342 : loss : 0.037231, loss_ce: 0.009062
[01:38:59.611] iteration 12343 : loss : 0.041066, loss_ce: 0.017333
[01:38:59.905] iteration 12344 : loss : 0.051133, loss_ce: 0.017235
[01:39:00.202] iteration 12345 : loss : 0.046954, loss_ce: 0.025065
[01:39:00.495] iteration 12346 : loss : 0.045309, loss_ce: 0.012996
[01:39:00.793] iteration 12347 : loss : 0.103004, loss_ce: 0.012323
[01:39:01.089] iteration 12348 : loss : 0.112504, loss_ce: 0.012882
[01:39:01.385] iteration 12349 : loss : 0.075745, loss_ce: 0.010155
[01:39:01.680] iteration 12350 : loss : 0.111358, loss_ce: 0.016253
[01:39:01.973] iteration 12351 : loss : 0.113987, loss_ce: 0.013277
[01:39:02.272] iteration 12352 : loss : 0.051790, loss_ce: 0.013479
[01:39:02.572] iteration 12353 : loss : 0.056760, loss_ce: 0.023001
[01:39:02.869] iteration 12354 : loss : 0.100170, loss_ce: 0.011352
[01:39:03.170] iteration 12355 : loss : 0.132884, loss_ce: 0.011289
[01:39:03.471] iteration 12356 : loss : 0.166341, loss_ce: 0.019149
[01:39:03.769] iteration 12357 : loss : 0.111242, loss_ce: 0.007081
[01:39:04.073] iteration 12358 : loss : 0.043710, loss_ce: 0.020061
[01:39:04.378] iteration 12359 : loss : 0.063133, loss_ce: 0.010836
[01:39:04.682] iteration 12360 : loss : 0.048072, loss_ce: 0.015808
[01:39:05.004] iteration 12361 : loss : 0.054851, loss_ce: 0.016354
[01:39:05.306] iteration 12362 : loss : 0.054680, loss_ce: 0.014196
[01:39:05.609] iteration 12363 : loss : 0.051678, loss_ce: 0.020035
[01:39:05.918] iteration 12364 : loss : 0.076034, loss_ce: 0.010296
[01:39:06.228] iteration 12365 : loss : 0.121511, loss_ce: 0.013336
[01:39:06.533] iteration 12366 : loss : 0.058814, loss_ce: 0.009173
[01:39:06.833] iteration 12367 : loss : 0.043005, loss_ce: 0.010019
[01:39:07.137] iteration 12368 : loss : 0.051259, loss_ce: 0.014003
[01:39:07.437] iteration 12369 : loss : 0.058393, loss_ce: 0.016947
[01:39:07.743] iteration 12370 : loss : 0.050446, loss_ce: 0.016014
[01:39:07.820] iteration 12371 : loss : 0.085038, loss_ce: 0.000021
[01:39:25.483] iteration 12372 : loss : 0.055346, loss_ce: 0.012667
[01:39:25.778] iteration 12373 : loss : 0.048100, loss_ce: 0.006234
[01:39:26.073] iteration 12374 : loss : 0.047853, loss_ce: 0.012295
[01:39:26.374] iteration 12375 : loss : 0.064914, loss_ce: 0.014938
[01:39:26.668] iteration 12376 : loss : 0.046984, loss_ce: 0.014976
[01:39:26.960] iteration 12377 : loss : 0.056314, loss_ce: 0.014530
[01:39:27.252] iteration 12378 : loss : 0.034958, loss_ce: 0.007054
[01:39:27.545] iteration 12379 : loss : 0.052522, loss_ce: 0.020678
[01:39:27.840] iteration 12380 : loss : 0.060828, loss_ce: 0.017593
[01:39:28.152] iteration 12381 : loss : 0.056135, loss_ce: 0.027486
[01:39:28.453] iteration 12382 : loss : 0.049554, loss_ce: 0.020654
[01:39:28.745] iteration 12383 : loss : 0.055508, loss_ce: 0.009545
[01:39:29.042] iteration 12384 : loss : 0.052451, loss_ce: 0.017575
[01:39:29.338] iteration 12385 : loss : 0.056831, loss_ce: 0.024200
[01:39:29.631] iteration 12386 : loss : 0.056612, loss_ce: 0.011038
[01:39:29.926] iteration 12387 : loss : 0.049211, loss_ce: 0.017679
[01:39:30.223] iteration 12388 : loss : 0.102968, loss_ce: 0.013648
[01:39:30.515] iteration 12389 : loss : 0.045030, loss_ce: 0.016675
[01:39:30.810] iteration 12390 : loss : 0.045516, loss_ce: 0.013400
[01:39:31.102] iteration 12391 : loss : 0.053407, loss_ce: 0.017398
[01:39:31.399] iteration 12392 : loss : 0.061634, loss_ce: 0.019060
[01:39:31.691] iteration 12393 : loss : 0.043497, loss_ce: 0.014634
[01:39:31.985] iteration 12394 : loss : 0.051209, loss_ce: 0.014327
[01:39:32.282] iteration 12395 : loss : 0.041199, loss_ce: 0.012343
[01:39:32.577] iteration 12396 : loss : 0.056658, loss_ce: 0.017390
[01:39:32.872] iteration 12397 : loss : 0.046703, loss_ce: 0.021062
[01:39:33.166] iteration 12398 : loss : 0.068148, loss_ce: 0.021237
[01:39:33.463] iteration 12399 : loss : 0.045412, loss_ce: 0.014875
[01:39:33.760] iteration 12400 : loss : 0.068364, loss_ce: 0.010703
[01:39:34.073] iteration 12401 : loss : 0.058257, loss_ce: 0.029126
[01:39:34.376] iteration 12402 : loss : 0.056211, loss_ce: 0.023760
[01:39:34.676] iteration 12403 : loss : 0.058350, loss_ce: 0.013408
[01:39:34.977] iteration 12404 : loss : 0.048336, loss_ce: 0.012676
[01:39:35.278] iteration 12405 : loss : 0.100028, loss_ce: 0.008097
[01:39:35.570] iteration 12406 : loss : 0.044271, loss_ce: 0.020809
[01:39:35.872] iteration 12407 : loss : 0.054817, loss_ce: 0.019266
[01:39:36.174] iteration 12408 : loss : 0.123961, loss_ce: 0.011482
[01:39:36.469] iteration 12409 : loss : 0.055703, loss_ce: 0.021830
[01:39:36.767] iteration 12410 : loss : 0.104513, loss_ce: 0.007696
[01:39:37.070] iteration 12411 : loss : 0.116145, loss_ce: 0.015110
[01:39:37.362] iteration 12412 : loss : 0.046704, loss_ce: 0.010525
[01:39:37.660] iteration 12413 : loss : 0.046447, loss_ce: 0.019879
[01:39:37.959] iteration 12414 : loss : 0.045145, loss_ce: 0.015847
[01:39:38.255] iteration 12415 : loss : 0.050649, loss_ce: 0.018706
[01:39:38.551] iteration 12416 : loss : 0.062382, loss_ce: 0.009678
[01:39:38.845] iteration 12417 : loss : 0.048793, loss_ce: 0.011052
[01:39:39.140] iteration 12418 : loss : 0.036538, loss_ce: 0.012748
[01:39:39.437] iteration 12419 : loss : 0.057456, loss_ce: 0.013261
[01:39:39.730] iteration 12420 : loss : 0.130959, loss_ce: 0.008973
[01:39:40.039] iteration 12421 : loss : 0.048327, loss_ce: 0.012232
[01:39:40.332] iteration 12422 : loss : 0.044610, loss_ce: 0.014107
[01:39:40.625] iteration 12423 : loss : 0.051922, loss_ce: 0.015792
[01:39:40.925] iteration 12424 : loss : 0.047261, loss_ce: 0.016207
[01:39:41.216] iteration 12425 : loss : 0.086608, loss_ce: 0.024647
[01:39:41.511] iteration 12426 : loss : 0.045809, loss_ce: 0.018588
[01:39:41.807] iteration 12427 : loss : 0.087767, loss_ce: 0.015787
[01:39:42.104] iteration 12428 : loss : 0.052126, loss_ce: 0.016557
[01:39:42.400] iteration 12429 : loss : 0.111752, loss_ce: 0.021622
[01:39:42.696] iteration 12430 : loss : 0.085635, loss_ce: 0.007761
[01:39:42.997] iteration 12431 : loss : 0.129907, loss_ce: 0.006041
[01:39:43.289] iteration 12432 : loss : 0.044594, loss_ce: 0.011857
[01:39:43.582] iteration 12433 : loss : 0.065790, loss_ce: 0.017570
[01:39:43.876] iteration 12434 : loss : 0.110412, loss_ce: 0.009948
[01:39:44.170] iteration 12435 : loss : 0.070213, loss_ce: 0.016153
[01:39:44.467] iteration 12436 : loss : 0.046221, loss_ce: 0.018229
[01:39:44.766] iteration 12437 : loss : 0.045184, loss_ce: 0.013546
[01:39:45.062] iteration 12438 : loss : 0.057056, loss_ce: 0.014292
[01:39:45.357] iteration 12439 : loss : 0.066078, loss_ce: 0.014789
[01:39:45.648] iteration 12440 : loss : 0.059000, loss_ce: 0.010392
[01:39:45.956] iteration 12441 : loss : 0.052354, loss_ce: 0.018973
[01:39:46.250] iteration 12442 : loss : 0.105310, loss_ce: 0.014220
[01:39:46.543] iteration 12443 : loss : 0.050437, loss_ce: 0.010909
[01:39:46.838] iteration 12444 : loss : 0.078157, loss_ce: 0.015989
[01:39:47.132] iteration 12445 : loss : 0.121550, loss_ce: 0.015193
[01:39:47.428] iteration 12446 : loss : 0.101488, loss_ce: 0.012621
[01:39:47.721] iteration 12447 : loss : 0.042029, loss_ce: 0.012002
[01:39:48.015] iteration 12448 : loss : 0.108441, loss_ce: 0.014587
[01:39:48.312] iteration 12449 : loss : 0.048257, loss_ce: 0.015740
[01:39:48.606] iteration 12450 : loss : 0.036237, loss_ce: 0.008525
[01:39:48.900] iteration 12451 : loss : 0.056622, loss_ce: 0.018595
[01:39:49.199] iteration 12452 : loss : 0.048477, loss_ce: 0.016011
[01:39:49.496] iteration 12453 : loss : 0.053725, loss_ce: 0.028573
[01:39:49.793] iteration 12454 : loss : 0.053478, loss_ce: 0.013038
[01:39:50.095] iteration 12455 : loss : 0.053050, loss_ce: 0.016409
[01:39:50.393] iteration 12456 : loss : 0.104876, loss_ce: 0.011423
[01:39:50.690] iteration 12457 : loss : 0.077047, loss_ce: 0.015058
[01:39:50.988] iteration 12458 : loss : 0.053949, loss_ce: 0.010435
[01:39:51.284] iteration 12459 : loss : 0.048844, loss_ce: 0.013048
[01:39:51.578] iteration 12460 : loss : 0.047327, loss_ce: 0.013535
[01:39:51.890] iteration 12461 : loss : 0.049774, loss_ce: 0.016545
[01:39:52.182] iteration 12462 : loss : 0.045630, loss_ce: 0.015226
[01:39:52.475] iteration 12463 : loss : 0.052551, loss_ce: 0.020999
[01:39:52.768] iteration 12464 : loss : 0.094472, loss_ce: 0.012572
[01:39:53.063] iteration 12465 : loss : 0.056842, loss_ce: 0.017302
[01:39:53.357] iteration 12466 : loss : 0.045934, loss_ce: 0.018913
[01:39:53.653] iteration 12467 : loss : 0.057241, loss_ce: 0.018496
[01:39:53.951] iteration 12468 : loss : 0.054872, loss_ce: 0.010696
[01:39:54.244] iteration 12469 : loss : 0.051537, loss_ce: 0.018832
[01:39:54.536] iteration 12470 : loss : 0.061087, loss_ce: 0.017025
[01:39:54.830] iteration 12471 : loss : 0.049398, loss_ce: 0.014011
[01:39:55.126] iteration 12472 : loss : 0.119452, loss_ce: 0.011647
[01:39:55.419] iteration 12473 : loss : 0.051167, loss_ce: 0.009761
[01:39:55.713] iteration 12474 : loss : 0.109391, loss_ce: 0.015246
[01:39:56.004] iteration 12475 : loss : 0.053740, loss_ce: 0.019199
[01:39:56.294] iteration 12476 : loss : 0.043420, loss_ce: 0.015870
[01:39:56.588] iteration 12477 : loss : 0.044063, loss_ce: 0.017162
[01:39:56.882] iteration 12478 : loss : 0.040149, loss_ce: 0.006398
[01:39:57.177] iteration 12479 : loss : 0.062464, loss_ce: 0.015696
[01:39:57.470] iteration 12480 : loss : 0.101409, loss_ce: 0.010926
[01:39:57.773] iteration 12481 : loss : 0.051799, loss_ce: 0.012238
[01:39:58.068] iteration 12482 : loss : 0.045382, loss_ce: 0.011073
[01:39:58.363] iteration 12483 : loss : 0.051487, loss_ce: 0.008957
[01:39:58.656] iteration 12484 : loss : 0.050409, loss_ce: 0.016372
[01:39:58.949] iteration 12485 : loss : 0.105238, loss_ce: 0.010540
[01:39:59.243] iteration 12486 : loss : 0.055387, loss_ce: 0.021683
[01:39:59.538] iteration 12487 : loss : 0.064161, loss_ce: 0.017057
[01:39:59.832] iteration 12488 : loss : 0.033748, loss_ce: 0.010329
[01:40:00.124] iteration 12489 : loss : 0.065652, loss_ce: 0.017698
[01:40:00.420] iteration 12490 : loss : 0.058421, loss_ce: 0.023575
[01:40:00.717] iteration 12491 : loss : 0.048176, loss_ce: 0.012878
[01:40:01.012] iteration 12492 : loss : 0.106718, loss_ce: 0.010128
[01:40:01.307] iteration 12493 : loss : 0.047022, loss_ce: 0.012041
[01:40:01.612] iteration 12494 : loss : 0.093590, loss_ce: 0.008952
[01:40:01.922] iteration 12495 : loss : 0.104212, loss_ce: 0.011886
[01:40:02.223] iteration 12496 : loss : 0.060427, loss_ce: 0.015937
[01:40:02.523] iteration 12497 : loss : 0.044883, loss_ce: 0.010097
[01:40:02.823] iteration 12498 : loss : 0.066395, loss_ce: 0.016486
[01:40:03.122] iteration 12499 : loss : 0.086753, loss_ce: 0.014300
[01:40:03.428] iteration 12500 : loss : 0.045863, loss_ce: 0.010540
[01:40:03.751] iteration 12501 : loss : 0.062946, loss_ce: 0.018965
[01:40:04.047] iteration 12502 : loss : 0.046928, loss_ce: 0.015116
[01:40:04.344] iteration 12503 : loss : 0.052561, loss_ce: 0.012291
[01:40:04.642] iteration 12504 : loss : 0.052812, loss_ce: 0.021458
[01:40:04.942] iteration 12505 : loss : 0.039568, loss_ce: 0.015575
[01:40:05.240] iteration 12506 : loss : 0.117029, loss_ce: 0.016240
[01:40:05.545] iteration 12507 : loss : 0.056576, loss_ce: 0.008588
[01:40:05.853] iteration 12508 : loss : 0.055794, loss_ce: 0.011039
[01:40:06.157] iteration 12509 : loss : 0.060348, loss_ce: 0.027848
[01:40:06.237] iteration 12510 : loss : 0.342751, loss_ce: 0.007642
[01:40:28.183] iteration 12511 : loss : 0.053789, loss_ce: 0.015312
[01:40:28.479] iteration 12512 : loss : 0.079345, loss_ce: 0.009534
[01:40:28.777] iteration 12513 : loss : 0.059665, loss_ce: 0.017872
[01:40:29.072] iteration 12514 : loss : 0.058055, loss_ce: 0.017723
[01:40:29.367] iteration 12515 : loss : 0.059708, loss_ce: 0.013696
[01:40:29.662] iteration 12516 : loss : 0.048332, loss_ce: 0.016911
[01:40:29.953] iteration 12517 : loss : 0.108447, loss_ce: 0.017162
[01:40:30.242] iteration 12518 : loss : 0.044925, loss_ce: 0.017545
[01:40:30.535] iteration 12519 : loss : 0.044257, loss_ce: 0.015055
[01:40:30.835] iteration 12520 : loss : 0.055054, loss_ce: 0.018719
[01:40:31.144] iteration 12521 : loss : 0.054976, loss_ce: 0.017557
[01:40:31.438] iteration 12522 : loss : 0.043504, loss_ce: 0.015509
[01:40:31.728] iteration 12523 : loss : 0.047675, loss_ce: 0.015252
[01:40:32.019] iteration 12524 : loss : 0.051281, loss_ce: 0.021394
[01:40:32.311] iteration 12525 : loss : 0.049428, loss_ce: 0.014232
[01:40:32.603] iteration 12526 : loss : 0.109590, loss_ce: 0.010382
[01:40:32.897] iteration 12527 : loss : 0.054034, loss_ce: 0.025598
[01:40:33.189] iteration 12528 : loss : 0.169573, loss_ce: 0.003595
[01:40:33.480] iteration 12529 : loss : 0.111892, loss_ce: 0.011982
[01:40:33.771] iteration 12530 : loss : 0.107289, loss_ce: 0.010681
[01:40:34.065] iteration 12531 : loss : 0.049655, loss_ce: 0.012028
[01:40:34.358] iteration 12532 : loss : 0.106808, loss_ce: 0.004965
[01:40:34.655] iteration 12533 : loss : 0.052801, loss_ce: 0.020064
[01:40:34.946] iteration 12534 : loss : 0.158640, loss_ce: 0.005626
[01:40:35.238] iteration 12535 : loss : 0.092219, loss_ce: 0.007128
[01:40:35.530] iteration 12536 : loss : 0.051003, loss_ce: 0.011253
[01:40:35.828] iteration 12537 : loss : 0.115412, loss_ce: 0.014204
[01:40:36.118] iteration 12538 : loss : 0.095531, loss_ce: 0.008364
[01:40:36.411] iteration 12539 : loss : 0.058275, loss_ce: 0.024631
[01:40:36.704] iteration 12540 : loss : 0.108666, loss_ce: 0.018071
[01:40:37.014] iteration 12541 : loss : 0.157629, loss_ce: 0.006715
[01:40:37.307] iteration 12542 : loss : 0.101115, loss_ce: 0.010256
[01:40:37.600] iteration 12543 : loss : 0.046183, loss_ce: 0.016345
[01:40:37.889] iteration 12544 : loss : 0.065966, loss_ce: 0.017829
[01:40:38.181] iteration 12545 : loss : 0.043427, loss_ce: 0.018089
[01:40:38.476] iteration 12546 : loss : 0.049613, loss_ce: 0.008558
[01:40:38.767] iteration 12547 : loss : 0.143538, loss_ce: 0.019586
[01:40:39.063] iteration 12548 : loss : 0.052751, loss_ce: 0.014435
[01:40:39.364] iteration 12549 : loss : 0.057947, loss_ce: 0.024389
[01:40:39.661] iteration 12550 : loss : 0.055672, loss_ce: 0.013592
[01:40:39.958] iteration 12551 : loss : 0.109564, loss_ce: 0.016438
[01:40:40.255] iteration 12552 : loss : 0.042412, loss_ce: 0.012645
[01:40:40.556] iteration 12553 : loss : 0.052376, loss_ce: 0.020128
[01:40:40.859] iteration 12554 : loss : 0.046231, loss_ce: 0.019506
[01:40:41.152] iteration 12555 : loss : 0.054336, loss_ce: 0.012728
[01:40:41.445] iteration 12556 : loss : 0.077643, loss_ce: 0.012722
[01:40:41.740] iteration 12557 : loss : 0.046293, loss_ce: 0.013187
[01:40:42.034] iteration 12558 : loss : 0.067312, loss_ce: 0.014370
[01:40:42.327] iteration 12559 : loss : 0.043581, loss_ce: 0.021279
[01:40:42.621] iteration 12560 : loss : 0.052520, loss_ce: 0.015184
[01:40:42.928] iteration 12561 : loss : 0.101420, loss_ce: 0.005729
[01:40:43.222] iteration 12562 : loss : 0.056348, loss_ce: 0.018776
[01:40:43.519] iteration 12563 : loss : 0.107267, loss_ce: 0.012563
[01:40:43.813] iteration 12564 : loss : 0.082196, loss_ce: 0.008796
[01:40:44.109] iteration 12565 : loss : 0.156999, loss_ce: 0.006925
[01:40:44.401] iteration 12566 : loss : 0.044177, loss_ce: 0.012468
[01:40:44.691] iteration 12567 : loss : 0.046179, loss_ce: 0.013804
[01:40:44.981] iteration 12568 : loss : 0.043309, loss_ce: 0.017279
[01:40:45.272] iteration 12569 : loss : 0.055678, loss_ce: 0.018822
[01:40:45.567] iteration 12570 : loss : 0.048257, loss_ce: 0.018292
[01:40:45.865] iteration 12571 : loss : 0.052740, loss_ce: 0.016177
[01:40:46.156] iteration 12572 : loss : 0.051392, loss_ce: 0.016315
[01:40:46.447] iteration 12573 : loss : 0.052291, loss_ce: 0.018071
[01:40:46.742] iteration 12574 : loss : 0.082225, loss_ce: 0.015285
[01:40:47.036] iteration 12575 : loss : 0.050970, loss_ce: 0.015804
[01:40:47.327] iteration 12576 : loss : 0.052024, loss_ce: 0.014561
[01:40:47.622] iteration 12577 : loss : 0.051778, loss_ce: 0.011438
[01:40:47.911] iteration 12578 : loss : 0.058244, loss_ce: 0.024444
[01:40:48.200] iteration 12579 : loss : 0.044263, loss_ce: 0.012325
[01:40:48.494] iteration 12580 : loss : 0.063219, loss_ce: 0.027515
[01:40:48.810] iteration 12581 : loss : 0.046289, loss_ce: 0.015612
[01:40:49.106] iteration 12582 : loss : 0.043877, loss_ce: 0.010833
[01:40:49.399] iteration 12583 : loss : 0.111240, loss_ce: 0.017692
[01:40:49.690] iteration 12584 : loss : 0.047204, loss_ce: 0.016564
[01:40:49.984] iteration 12585 : loss : 0.165103, loss_ce: 0.013942
[01:40:50.281] iteration 12586 : loss : 0.108418, loss_ce: 0.014364
[01:40:50.577] iteration 12587 : loss : 0.046816, loss_ce: 0.017687
[01:40:50.869] iteration 12588 : loss : 0.059489, loss_ce: 0.009561
[01:40:51.165] iteration 12589 : loss : 0.078214, loss_ce: 0.020771
[01:40:51.461] iteration 12590 : loss : 0.052391, loss_ce: 0.016246
[01:40:51.757] iteration 12591 : loss : 0.055196, loss_ce: 0.015943
[01:40:52.050] iteration 12592 : loss : 0.046653, loss_ce: 0.011817
[01:40:52.344] iteration 12593 : loss : 0.049452, loss_ce: 0.014921
[01:40:52.640] iteration 12594 : loss : 0.067043, loss_ce: 0.021186
[01:40:52.933] iteration 12595 : loss : 0.088805, loss_ce: 0.016828
[01:40:53.229] iteration 12596 : loss : 0.062049, loss_ce: 0.012740
[01:40:53.524] iteration 12597 : loss : 0.055446, loss_ce: 0.016450
[01:40:53.818] iteration 12598 : loss : 0.051145, loss_ce: 0.015622
[01:40:54.116] iteration 12599 : loss : 0.056292, loss_ce: 0.014035
[01:40:54.409] iteration 12600 : loss : 0.054989, loss_ce: 0.017692
[01:40:54.721] iteration 12601 : loss : 0.110067, loss_ce: 0.010676
[01:40:55.022] iteration 12602 : loss : 0.050064, loss_ce: 0.014075
[01:40:55.325] iteration 12603 : loss : 0.048218, loss_ce: 0.009706
[01:40:55.623] iteration 12604 : loss : 0.073897, loss_ce: 0.020332
[01:40:55.925] iteration 12605 : loss : 0.062940, loss_ce: 0.018446
[01:40:56.221] iteration 12606 : loss : 0.042703, loss_ce: 0.022291
[01:40:56.513] iteration 12607 : loss : 0.054217, loss_ce: 0.014975
[01:40:56.807] iteration 12608 : loss : 0.040446, loss_ce: 0.019479
[01:40:57.101] iteration 12609 : loss : 0.061443, loss_ce: 0.018764
[01:40:57.395] iteration 12610 : loss : 0.052260, loss_ce: 0.012012
[01:40:57.688] iteration 12611 : loss : 0.044851, loss_ce: 0.008546
[01:40:57.980] iteration 12612 : loss : 0.128624, loss_ce: 0.007249
[01:40:58.279] iteration 12613 : loss : 0.079256, loss_ce: 0.012332
[01:40:58.573] iteration 12614 : loss : 0.050875, loss_ce: 0.018157
[01:40:58.866] iteration 12615 : loss : 0.056441, loss_ce: 0.010629
[01:40:59.161] iteration 12616 : loss : 0.058698, loss_ce: 0.027647
[01:40:59.452] iteration 12617 : loss : 0.044447, loss_ce: 0.009678
[01:40:59.746] iteration 12618 : loss : 0.047895, loss_ce: 0.017371
[01:41:00.044] iteration 12619 : loss : 0.043412, loss_ce: 0.010897
[01:41:00.337] iteration 12620 : loss : 0.050906, loss_ce: 0.014325
[01:41:00.646] iteration 12621 : loss : 0.053065, loss_ce: 0.015771
[01:41:00.942] iteration 12622 : loss : 0.071176, loss_ce: 0.009258
[01:41:01.232] iteration 12623 : loss : 0.059253, loss_ce: 0.016680
[01:41:01.522] iteration 12624 : loss : 0.111661, loss_ce: 0.018469
[01:41:01.813] iteration 12625 : loss : 0.106016, loss_ce: 0.013542
[01:41:02.113] iteration 12626 : loss : 0.111967, loss_ce: 0.011461
[01:41:02.404] iteration 12627 : loss : 0.109103, loss_ce: 0.016602
[01:41:02.699] iteration 12628 : loss : 0.047304, loss_ce: 0.007389
[01:41:02.991] iteration 12629 : loss : 0.139061, loss_ce: 0.019655
[01:41:03.282] iteration 12630 : loss : 0.198011, loss_ce: 0.012897
[01:41:03.575] iteration 12631 : loss : 0.044931, loss_ce: 0.012112
[01:41:03.871] iteration 12632 : loss : 0.058044, loss_ce: 0.027405
[01:41:04.169] iteration 12633 : loss : 0.067686, loss_ce: 0.023601
[01:41:04.468] iteration 12634 : loss : 0.042025, loss_ce: 0.005033
[01:41:04.769] iteration 12635 : loss : 0.055494, loss_ce: 0.018257
[01:41:05.064] iteration 12636 : loss : 0.111203, loss_ce: 0.011967
[01:41:05.365] iteration 12637 : loss : 0.056862, loss_ce: 0.024950
[01:41:05.665] iteration 12638 : loss : 0.162642, loss_ce: 0.004117
[01:41:05.962] iteration 12639 : loss : 0.051147, loss_ce: 0.010081
[01:41:06.260] iteration 12640 : loss : 0.057513, loss_ce: 0.018512
[01:41:06.603] iteration 12641 : loss : 0.049283, loss_ce: 0.013483
[01:41:06.903] iteration 12642 : loss : 0.051373, loss_ce: 0.018259
[01:41:07.207] iteration 12643 : loss : 0.059111, loss_ce: 0.032650
[01:41:07.502] iteration 12644 : loss : 0.063830, loss_ce: 0.014954
[01:41:07.801] iteration 12645 : loss : 0.060309, loss_ce: 0.015158
[01:41:08.094] iteration 12646 : loss : 0.043362, loss_ce: 0.010463
[01:41:08.390] iteration 12647 : loss : 0.118121, loss_ce: 0.008445
[01:41:08.688] iteration 12648 : loss : 0.045773, loss_ce: 0.017374
[01:41:08.765] iteration 12649 : loss : 0.353425, loss_ce: 0.014341
[01:41:26.724] iteration 12650 : loss : 0.102955, loss_ce: 0.014792
[01:41:27.022] iteration 12651 : loss : 0.039489, loss_ce: 0.009279
[01:41:27.321] iteration 12652 : loss : 0.166293, loss_ce: 0.007433
[01:41:27.620] iteration 12653 : loss : 0.057551, loss_ce: 0.015746
[01:41:27.919] iteration 12654 : loss : 0.050444, loss_ce: 0.022420
[01:41:28.214] iteration 12655 : loss : 0.050007, loss_ce: 0.016245
[01:41:28.508] iteration 12656 : loss : 0.047380, loss_ce: 0.025462
[01:41:28.804] iteration 12657 : loss : 0.057183, loss_ce: 0.027350
[01:41:29.104] iteration 12658 : loss : 0.056129, loss_ce: 0.016551
[01:41:29.401] iteration 12659 : loss : 0.056651, loss_ce: 0.032100
[01:41:29.700] iteration 12660 : loss : 0.103968, loss_ce: 0.010176
[01:41:30.014] iteration 12661 : loss : 0.053708, loss_ce: 0.019359
[01:41:30.320] iteration 12662 : loss : 0.056041, loss_ce: 0.018399
[01:41:30.623] iteration 12663 : loss : 0.056281, loss_ce: 0.012163
[01:41:30.923] iteration 12664 : loss : 0.046766, loss_ce: 0.018383
[01:41:31.224] iteration 12665 : loss : 0.056002, loss_ce: 0.012389
[01:41:31.529] iteration 12666 : loss : 0.040372, loss_ce: 0.010196
[01:41:31.833] iteration 12667 : loss : 0.058456, loss_ce: 0.015981
[01:41:32.133] iteration 12668 : loss : 0.160671, loss_ce: 0.012611
[01:41:32.437] iteration 12669 : loss : 0.156892, loss_ce: 0.004780
[01:41:32.737] iteration 12670 : loss : 0.061209, loss_ce: 0.009547
[01:41:33.039] iteration 12671 : loss : 0.104712, loss_ce: 0.006171
[01:41:33.344] iteration 12672 : loss : 0.046518, loss_ce: 0.008379
[01:41:33.648] iteration 12673 : loss : 0.039053, loss_ce: 0.014206
[01:41:33.953] iteration 12674 : loss : 0.110374, loss_ce: 0.009445
[01:41:34.254] iteration 12675 : loss : 0.045263, loss_ce: 0.013899
[01:41:34.558] iteration 12676 : loss : 0.072754, loss_ce: 0.016378
[01:41:34.859] iteration 12677 : loss : 0.053567, loss_ce: 0.009357
[01:41:35.184] iteration 12678 : loss : 0.060085, loss_ce: 0.015854
[01:41:35.657] iteration 12679 : loss : 0.075126, loss_ce: 0.015872
[01:41:35.976] iteration 12680 : loss : 0.049368, loss_ce: 0.014785
[01:41:36.313] iteration 12681 : loss : 0.043856, loss_ce: 0.012999
[01:41:36.619] iteration 12682 : loss : 0.104350, loss_ce: 0.009173
[01:41:36.920] iteration 12683 : loss : 0.111008, loss_ce: 0.010242
[01:41:37.222] iteration 12684 : loss : 0.104434, loss_ce: 0.006171
[01:41:37.522] iteration 12685 : loss : 0.050980, loss_ce: 0.014600
[01:41:37.829] iteration 12686 : loss : 0.043903, loss_ce: 0.016349
[01:41:38.132] iteration 12687 : loss : 0.059394, loss_ce: 0.016070
[01:41:38.434] iteration 12688 : loss : 0.107841, loss_ce: 0.005462
[01:41:38.738] iteration 12689 : loss : 0.042916, loss_ce: 0.007921
[01:41:39.043] iteration 12690 : loss : 0.069547, loss_ce: 0.013307
[01:41:39.344] iteration 12691 : loss : 0.044158, loss_ce: 0.011418
[01:41:39.647] iteration 12692 : loss : 0.046601, loss_ce: 0.014360
[01:41:39.948] iteration 12693 : loss : 0.048537, loss_ce: 0.020159
[01:41:40.256] iteration 12694 : loss : 0.062704, loss_ce: 0.015987
[01:41:40.561] iteration 12695 : loss : 0.110695, loss_ce: 0.009415
[01:41:40.863] iteration 12696 : loss : 0.048907, loss_ce: 0.013485
[01:41:41.170] iteration 12697 : loss : 0.058479, loss_ce: 0.008956
[01:41:41.474] iteration 12698 : loss : 0.071573, loss_ce: 0.006422
[01:41:41.776] iteration 12699 : loss : 0.064611, loss_ce: 0.015220
[01:41:42.080] iteration 12700 : loss : 0.042494, loss_ce: 0.016041
[01:41:42.399] iteration 12701 : loss : 0.053796, loss_ce: 0.023760
[01:41:42.703] iteration 12702 : loss : 0.097964, loss_ce: 0.013120
[01:41:43.009] iteration 12703 : loss : 0.075811, loss_ce: 0.025281
[01:41:43.311] iteration 12704 : loss : 0.056157, loss_ce: 0.016538
[01:41:43.614] iteration 12705 : loss : 0.037356, loss_ce: 0.015022
[01:41:43.914] iteration 12706 : loss : 0.045531, loss_ce: 0.007777
[01:41:44.217] iteration 12707 : loss : 0.062661, loss_ce: 0.018646
[01:41:44.526] iteration 12708 : loss : 0.077210, loss_ce: 0.025495
[01:41:44.834] iteration 12709 : loss : 0.045423, loss_ce: 0.020051
[01:41:45.139] iteration 12710 : loss : 0.071378, loss_ce: 0.018927
[01:41:45.440] iteration 12711 : loss : 0.050115, loss_ce: 0.016226
[01:41:45.742] iteration 12712 : loss : 0.047987, loss_ce: 0.021979
[01:41:46.043] iteration 12713 : loss : 0.282681, loss_ce: 0.006917
[01:41:46.345] iteration 12714 : loss : 0.068594, loss_ce: 0.016549
[01:41:46.643] iteration 12715 : loss : 0.115316, loss_ce: 0.019220
[01:41:46.940] iteration 12716 : loss : 0.054138, loss_ce: 0.017221
[01:41:47.238] iteration 12717 : loss : 0.104664, loss_ce: 0.006548
[01:41:47.538] iteration 12718 : loss : 0.048664, loss_ce: 0.020761
[01:41:47.838] iteration 12719 : loss : 0.042440, loss_ce: 0.014334
[01:41:48.138] iteration 12720 : loss : 0.069004, loss_ce: 0.014143
[01:41:48.453] iteration 12721 : loss : 0.107222, loss_ce: 0.015698
[01:41:48.756] iteration 12722 : loss : 0.109566, loss_ce: 0.011033
[01:41:49.061] iteration 12723 : loss : 0.045461, loss_ce: 0.017424
[01:41:49.365] iteration 12724 : loss : 0.072945, loss_ce: 0.017890
[01:41:49.663] iteration 12725 : loss : 0.107888, loss_ce: 0.009946
[01:41:49.957] iteration 12726 : loss : 0.178477, loss_ce: 0.006575
[01:41:50.257] iteration 12727 : loss : 0.063961, loss_ce: 0.022694
[01:41:50.552] iteration 12728 : loss : 0.056211, loss_ce: 0.014223
[01:41:50.850] iteration 12729 : loss : 0.048392, loss_ce: 0.008174
[01:41:51.151] iteration 12730 : loss : 0.048550, loss_ce: 0.020258
[01:41:51.451] iteration 12731 : loss : 0.051662, loss_ce: 0.009815
[01:41:51.755] iteration 12732 : loss : 0.049573, loss_ce: 0.014620
[01:41:52.055] iteration 12733 : loss : 0.053264, loss_ce: 0.021748
[01:41:52.353] iteration 12734 : loss : 0.047660, loss_ce: 0.013806
[01:41:52.660] iteration 12735 : loss : 0.056187, loss_ce: 0.014757
[01:41:52.966] iteration 12736 : loss : 0.044450, loss_ce: 0.014484
[01:41:53.270] iteration 12737 : loss : 0.112007, loss_ce: 0.012142
[01:41:53.572] iteration 12738 : loss : 0.087675, loss_ce: 0.011559
[01:41:53.871] iteration 12739 : loss : 0.101865, loss_ce: 0.012417
[01:41:54.169] iteration 12740 : loss : 0.046320, loss_ce: 0.010789
[01:41:54.481] iteration 12741 : loss : 0.051897, loss_ce: 0.027410
[01:41:54.780] iteration 12742 : loss : 0.064470, loss_ce: 0.015783
[01:41:55.081] iteration 12743 : loss : 0.046492, loss_ce: 0.014750
[01:41:55.375] iteration 12744 : loss : 0.063066, loss_ce: 0.030031
[01:41:55.681] iteration 12745 : loss : 0.050432, loss_ce: 0.010838
[01:41:55.979] iteration 12746 : loss : 0.079573, loss_ce: 0.016599
[01:41:56.282] iteration 12747 : loss : 0.058248, loss_ce: 0.013964
[01:41:56.582] iteration 12748 : loss : 0.057423, loss_ce: 0.015450
[01:41:56.879] iteration 12749 : loss : 0.061701, loss_ce: 0.014676
[01:41:57.175] iteration 12750 : loss : 0.059924, loss_ce: 0.025185
[01:41:57.473] iteration 12751 : loss : 0.058691, loss_ce: 0.021617
[01:41:57.770] iteration 12752 : loss : 0.067861, loss_ce: 0.018641
[01:41:58.068] iteration 12753 : loss : 0.045357, loss_ce: 0.013704
[01:41:58.368] iteration 12754 : loss : 0.072156, loss_ce: 0.013296
[01:41:58.666] iteration 12755 : loss : 0.113554, loss_ce: 0.018647
[01:41:58.963] iteration 12756 : loss : 0.055197, loss_ce: 0.015018
[01:41:59.276] iteration 12757 : loss : 0.049815, loss_ce: 0.018294
[01:41:59.584] iteration 12758 : loss : 0.047611, loss_ce: 0.011921
[01:41:59.890] iteration 12759 : loss : 0.093093, loss_ce: 0.016547
[01:42:00.201] iteration 12760 : loss : 0.058461, loss_ce: 0.013746
[01:42:00.520] iteration 12761 : loss : 0.041281, loss_ce: 0.010280
[01:42:00.829] iteration 12762 : loss : 0.106737, loss_ce: 0.012991
[01:42:01.132] iteration 12763 : loss : 0.044932, loss_ce: 0.006049
[01:42:01.437] iteration 12764 : loss : 0.113574, loss_ce: 0.011964
[01:42:01.737] iteration 12765 : loss : 0.047974, loss_ce: 0.013215
[01:42:02.036] iteration 12766 : loss : 0.052228, loss_ce: 0.028099
[01:42:02.333] iteration 12767 : loss : 0.049380, loss_ce: 0.011630
[01:42:02.632] iteration 12768 : loss : 0.048606, loss_ce: 0.016266
[01:42:02.929] iteration 12769 : loss : 0.048363, loss_ce: 0.016637
[01:42:03.228] iteration 12770 : loss : 0.050575, loss_ce: 0.009273
[01:42:03.523] iteration 12771 : loss : 0.350020, loss_ce: 0.001945
[01:42:03.827] iteration 12772 : loss : 0.098909, loss_ce: 0.005896
[01:42:04.123] iteration 12773 : loss : 0.107590, loss_ce: 0.012445
[01:42:04.425] iteration 12774 : loss : 0.045064, loss_ce: 0.018736
[01:42:04.726] iteration 12775 : loss : 0.059805, loss_ce: 0.023748
[01:42:05.032] iteration 12776 : loss : 0.099733, loss_ce: 0.012396
[01:42:05.329] iteration 12777 : loss : 0.047631, loss_ce: 0.013869
[01:42:05.629] iteration 12778 : loss : 0.047339, loss_ce: 0.019439
[01:42:05.930] iteration 12779 : loss : 0.053103, loss_ce: 0.025134
[01:42:06.238] iteration 12780 : loss : 0.056405, loss_ce: 0.019357
[01:42:06.566] iteration 12781 : loss : 0.109259, loss_ce: 0.016507
[01:42:06.867] iteration 12782 : loss : 0.060130, loss_ce: 0.019477
[01:42:07.185] iteration 12783 : loss : 0.052896, loss_ce: 0.012473
[01:42:07.482] iteration 12784 : loss : 0.044094, loss_ce: 0.005603
[01:42:07.785] iteration 12785 : loss : 0.047971, loss_ce: 0.029508
[01:42:08.090] iteration 12786 : loss : 0.046317, loss_ce: 0.016552
[01:42:08.395] iteration 12787 : loss : 0.078183, loss_ce: 0.008803
[01:42:08.478] iteration 12788 : loss : 0.355324, loss_ce: 0.009395
[01:42:29.028] iteration 12789 : loss : 0.057198, loss_ce: 0.016240
[01:42:29.336] iteration 12790 : loss : 0.046060, loss_ce: 0.006506
[01:42:29.642] iteration 12791 : loss : 0.048642, loss_ce: 0.013469
[01:42:29.946] iteration 12792 : loss : 0.042133, loss_ce: 0.013515
[01:42:30.250] iteration 12793 : loss : 0.049678, loss_ce: 0.014726
[01:42:30.551] iteration 12794 : loss : 0.062482, loss_ce: 0.018244
[01:42:30.854] iteration 12795 : loss : 0.052841, loss_ce: 0.016585
[01:42:31.154] iteration 12796 : loss : 0.101002, loss_ce: 0.012264
[01:42:31.452] iteration 12797 : loss : 0.050269, loss_ce: 0.013184
[01:42:31.748] iteration 12798 : loss : 0.061391, loss_ce: 0.014075
[01:42:32.048] iteration 12799 : loss : 0.118558, loss_ce: 0.016959
[01:42:32.341] iteration 12800 : loss : 0.044147, loss_ce: 0.015530
[01:42:32.657] iteration 12801 : loss : 0.050356, loss_ce: 0.021318
[01:42:32.951] iteration 12802 : loss : 0.096781, loss_ce: 0.010812
[01:42:33.249] iteration 12803 : loss : 0.100936, loss_ce: 0.010393
[01:42:33.546] iteration 12804 : loss : 0.045546, loss_ce: 0.014009
[01:42:33.844] iteration 12805 : loss : 0.046895, loss_ce: 0.018535
[01:42:34.140] iteration 12806 : loss : 0.058765, loss_ce: 0.015364
[01:42:34.439] iteration 12807 : loss : 0.052064, loss_ce: 0.023092
[01:42:34.735] iteration 12808 : loss : 0.051499, loss_ce: 0.013860
[01:42:35.032] iteration 12809 : loss : 0.045774, loss_ce: 0.018097
[01:42:35.329] iteration 12810 : loss : 0.114487, loss_ce: 0.002772
[01:42:35.626] iteration 12811 : loss : 0.054489, loss_ce: 0.014296
[01:42:35.927] iteration 12812 : loss : 0.058011, loss_ce: 0.021386
[01:42:36.226] iteration 12813 : loss : 0.057461, loss_ce: 0.024219
[01:42:36.522] iteration 12814 : loss : 0.048803, loss_ce: 0.012547
[01:42:36.813] iteration 12815 : loss : 0.055328, loss_ce: 0.022152
[01:42:37.104] iteration 12816 : loss : 0.075739, loss_ce: 0.006727
[01:42:37.396] iteration 12817 : loss : 0.052148, loss_ce: 0.012310
[01:42:37.696] iteration 12818 : loss : 0.046581, loss_ce: 0.014324
[01:42:37.996] iteration 12819 : loss : 0.042616, loss_ce: 0.012597
[01:42:38.295] iteration 12820 : loss : 0.110649, loss_ce: 0.010711
[01:42:38.614] iteration 12821 : loss : 0.050932, loss_ce: 0.015868
[01:42:38.912] iteration 12822 : loss : 0.050963, loss_ce: 0.015990
[01:42:39.217] iteration 12823 : loss : 0.099395, loss_ce: 0.007547
[01:42:39.510] iteration 12824 : loss : 0.035330, loss_ce: 0.005276
[01:42:39.811] iteration 12825 : loss : 0.053620, loss_ce: 0.022981
[01:42:40.109] iteration 12826 : loss : 0.045786, loss_ce: 0.012780
[01:42:40.407] iteration 12827 : loss : 0.055219, loss_ce: 0.016012
[01:42:40.704] iteration 12828 : loss : 0.048837, loss_ce: 0.018343
[01:42:41.006] iteration 12829 : loss : 0.052298, loss_ce: 0.014414
[01:42:41.305] iteration 12830 : loss : 0.122563, loss_ce: 0.011758
[01:42:41.604] iteration 12831 : loss : 0.057403, loss_ce: 0.016097
[01:42:41.903] iteration 12832 : loss : 0.050129, loss_ce: 0.015710
[01:42:42.204] iteration 12833 : loss : 0.104236, loss_ce: 0.015818
[01:42:42.504] iteration 12834 : loss : 0.051586, loss_ce: 0.016134
[01:42:42.804] iteration 12835 : loss : 0.046902, loss_ce: 0.017897
[01:42:43.103] iteration 12836 : loss : 0.049516, loss_ce: 0.011094
[01:42:43.403] iteration 12837 : loss : 0.050712, loss_ce: 0.016045
[01:42:43.704] iteration 12838 : loss : 0.051265, loss_ce: 0.014394
[01:42:44.004] iteration 12839 : loss : 0.105310, loss_ce: 0.008534
[01:42:44.308] iteration 12840 : loss : 0.119968, loss_ce: 0.012697
[01:42:44.625] iteration 12841 : loss : 0.048142, loss_ce: 0.015678
[01:42:44.924] iteration 12842 : loss : 0.060823, loss_ce: 0.026815
[01:42:45.227] iteration 12843 : loss : 0.052325, loss_ce: 0.013973
[01:42:45.527] iteration 12844 : loss : 0.094283, loss_ce: 0.007562
[01:42:45.827] iteration 12845 : loss : 0.063006, loss_ce: 0.011748
[01:42:46.128] iteration 12846 : loss : 0.161979, loss_ce: 0.011656
[01:42:46.427] iteration 12847 : loss : 0.048930, loss_ce: 0.014262
[01:42:46.726] iteration 12848 : loss : 0.055902, loss_ce: 0.019870
[01:42:47.024] iteration 12849 : loss : 0.110682, loss_ce: 0.014955
[01:42:47.329] iteration 12850 : loss : 0.106372, loss_ce: 0.012509
[01:42:47.630] iteration 12851 : loss : 0.055686, loss_ce: 0.010747
[01:42:47.929] iteration 12852 : loss : 0.057213, loss_ce: 0.013545
[01:42:48.232] iteration 12853 : loss : 0.045005, loss_ce: 0.015674
[01:42:48.537] iteration 12854 : loss : 0.042219, loss_ce: 0.014208
[01:42:48.843] iteration 12855 : loss : 0.080694, loss_ce: 0.017840
[01:42:49.147] iteration 12856 : loss : 0.066518, loss_ce: 0.017350
[01:42:49.454] iteration 12857 : loss : 0.067321, loss_ce: 0.019294
[01:42:49.758] iteration 12858 : loss : 0.109463, loss_ce: 0.014043
[01:42:50.064] iteration 12859 : loss : 0.044359, loss_ce: 0.016267
[01:42:50.367] iteration 12860 : loss : 0.104029, loss_ce: 0.010573
[01:42:50.686] iteration 12861 : loss : 0.072185, loss_ce: 0.015865
[01:42:50.987] iteration 12862 : loss : 0.045402, loss_ce: 0.017002
[01:42:51.290] iteration 12863 : loss : 0.166219, loss_ce: 0.004740
[01:42:51.598] iteration 12864 : loss : 0.040585, loss_ce: 0.015231
[01:42:51.898] iteration 12865 : loss : 0.109144, loss_ce: 0.016105
[01:42:52.198] iteration 12866 : loss : 0.112622, loss_ce: 0.011540
[01:42:52.502] iteration 12867 : loss : 0.047759, loss_ce: 0.011249
[01:42:52.804] iteration 12868 : loss : 0.111204, loss_ce: 0.015776
[01:42:53.104] iteration 12869 : loss : 0.059986, loss_ce: 0.019150
[01:42:53.407] iteration 12870 : loss : 0.057759, loss_ce: 0.015908
[01:42:53.711] iteration 12871 : loss : 0.059212, loss_ce: 0.015235
[01:42:54.012] iteration 12872 : loss : 0.047836, loss_ce: 0.017682
[01:42:54.315] iteration 12873 : loss : 0.071948, loss_ce: 0.019652
[01:42:54.621] iteration 12874 : loss : 0.051761, loss_ce: 0.026830
[01:42:54.923] iteration 12875 : loss : 0.049568, loss_ce: 0.015232
[01:42:55.226] iteration 12876 : loss : 0.103177, loss_ce: 0.014404
[01:42:55.532] iteration 12877 : loss : 0.049765, loss_ce: 0.014318
[01:42:55.834] iteration 12878 : loss : 0.052342, loss_ce: 0.022840
[01:42:56.134] iteration 12879 : loss : 0.060189, loss_ce: 0.011109
[01:42:56.438] iteration 12880 : loss : 0.046156, loss_ce: 0.017921
[01:42:56.767] iteration 12881 : loss : 0.114569, loss_ce: 0.017379
[01:42:57.069] iteration 12882 : loss : 0.050372, loss_ce: 0.016896
[01:42:57.371] iteration 12883 : loss : 0.042909, loss_ce: 0.015980
[01:42:57.676] iteration 12884 : loss : 0.056044, loss_ce: 0.025787
[01:42:57.977] iteration 12885 : loss : 0.110777, loss_ce: 0.014610
[01:42:58.279] iteration 12886 : loss : 0.042589, loss_ce: 0.009016
[01:42:58.581] iteration 12887 : loss : 0.045498, loss_ce: 0.012746
[01:42:58.882] iteration 12888 : loss : 0.053879, loss_ce: 0.011303
[01:42:59.183] iteration 12889 : loss : 0.105768, loss_ce: 0.019434
[01:42:59.487] iteration 12890 : loss : 0.048914, loss_ce: 0.013750
[01:42:59.790] iteration 12891 : loss : 0.105164, loss_ce: 0.012968
[01:43:00.091] iteration 12892 : loss : 0.037366, loss_ce: 0.006892
[01:43:00.390] iteration 12893 : loss : 0.058358, loss_ce: 0.009385
[01:43:00.693] iteration 12894 : loss : 0.053134, loss_ce: 0.019969
[01:43:00.994] iteration 12895 : loss : 0.062898, loss_ce: 0.015312
[01:43:01.298] iteration 12896 : loss : 0.117575, loss_ce: 0.004129
[01:43:01.603] iteration 12897 : loss : 0.124880, loss_ce: 0.013902
[01:43:01.908] iteration 12898 : loss : 0.053644, loss_ce: 0.019070
[01:43:02.210] iteration 12899 : loss : 0.047966, loss_ce: 0.017517
[01:43:02.510] iteration 12900 : loss : 0.044793, loss_ce: 0.014440
[01:43:02.828] iteration 12901 : loss : 0.059701, loss_ce: 0.020129
[01:43:03.126] iteration 12902 : loss : 0.043300, loss_ce: 0.008459
[01:43:03.432] iteration 12903 : loss : 0.161716, loss_ce: 0.016161
[01:43:03.736] iteration 12904 : loss : 0.048618, loss_ce: 0.022951
[01:43:04.036] iteration 12905 : loss : 0.054826, loss_ce: 0.019594
[01:43:04.339] iteration 12906 : loss : 0.063664, loss_ce: 0.015013
[01:43:04.645] iteration 12907 : loss : 0.112757, loss_ce: 0.013355
[01:43:04.948] iteration 12908 : loss : 0.053960, loss_ce: 0.020990
[01:43:05.249] iteration 12909 : loss : 0.055069, loss_ce: 0.023348
[01:43:05.551] iteration 12910 : loss : 0.045395, loss_ce: 0.017054
[01:43:05.864] iteration 12911 : loss : 0.112288, loss_ce: 0.010713
[01:43:06.171] iteration 12912 : loss : 0.112318, loss_ce: 0.007076
[01:43:06.472] iteration 12913 : loss : 0.042575, loss_ce: 0.017621
[01:43:06.772] iteration 12914 : loss : 0.059813, loss_ce: 0.015069
[01:43:07.070] iteration 12915 : loss : 0.044586, loss_ce: 0.011982
[01:43:07.372] iteration 12916 : loss : 0.069111, loss_ce: 0.015722
[01:43:07.674] iteration 12917 : loss : 0.104662, loss_ce: 0.010701
[01:43:07.975] iteration 12918 : loss : 0.070439, loss_ce: 0.017595
[01:43:08.280] iteration 12919 : loss : 0.056503, loss_ce: 0.017284
[01:43:08.579] iteration 12920 : loss : 0.045283, loss_ce: 0.003703
[01:43:08.906] iteration 12921 : loss : 0.108663, loss_ce: 0.011441
[01:43:09.206] iteration 12922 : loss : 0.067105, loss_ce: 0.024842
[01:43:09.516] iteration 12923 : loss : 0.040750, loss_ce: 0.011629
[01:43:09.820] iteration 12924 : loss : 0.051122, loss_ce: 0.012594
[01:43:10.130] iteration 12925 : loss : 0.043670, loss_ce: 0.014785
[01:43:10.430] iteration 12926 : loss : 0.046739, loss_ce: 0.012554
[01:43:10.509] iteration 12927 : loss : 0.344683, loss_ce: 0.007376
[01:43:27.939] iteration 12928 : loss : 0.037470, loss_ce: 0.013206
[01:43:28.242] iteration 12929 : loss : 0.056724, loss_ce: 0.024464
[01:43:28.543] iteration 12930 : loss : 0.050720, loss_ce: 0.018694
[01:43:28.847] iteration 12931 : loss : 0.057821, loss_ce: 0.009633
[01:43:29.149] iteration 12932 : loss : 0.048962, loss_ce: 0.007810
[01:43:29.449] iteration 12933 : loss : 0.060819, loss_ce: 0.018343
[01:43:29.745] iteration 12934 : loss : 0.053014, loss_ce: 0.021077
[01:43:30.048] iteration 12935 : loss : 0.064695, loss_ce: 0.023705
[01:43:30.351] iteration 12936 : loss : 0.049828, loss_ce: 0.006348
[01:43:30.647] iteration 12937 : loss : 0.054458, loss_ce: 0.017792
[01:43:30.945] iteration 12938 : loss : 0.054892, loss_ce: 0.012684
[01:43:31.246] iteration 12939 : loss : 0.067099, loss_ce: 0.011358
[01:43:31.546] iteration 12940 : loss : 0.050128, loss_ce: 0.014959
[01:43:31.870] iteration 12941 : loss : 0.165402, loss_ce: 0.008517
[01:43:32.169] iteration 12942 : loss : 0.054549, loss_ce: 0.019563
[01:43:32.470] iteration 12943 : loss : 0.048740, loss_ce: 0.018001
[01:43:32.772] iteration 12944 : loss : 0.065350, loss_ce: 0.013361
[01:43:33.075] iteration 12945 : loss : 0.108582, loss_ce: 0.018201
[01:43:33.370] iteration 12946 : loss : 0.051226, loss_ce: 0.018872
[01:43:33.666] iteration 12947 : loss : 0.160469, loss_ce: 0.009463
[01:43:33.968] iteration 12948 : loss : 0.046235, loss_ce: 0.005879
[01:43:34.268] iteration 12949 : loss : 0.042778, loss_ce: 0.015369
[01:43:34.570] iteration 12950 : loss : 0.064301, loss_ce: 0.013046
[01:43:34.873] iteration 12951 : loss : 0.112853, loss_ce: 0.012683
[01:43:35.174] iteration 12952 : loss : 0.084276, loss_ce: 0.012684
[01:43:35.476] iteration 12953 : loss : 0.112468, loss_ce: 0.007027
[01:43:35.779] iteration 12954 : loss : 0.100158, loss_ce: 0.008671
[01:43:36.084] iteration 12955 : loss : 0.050720, loss_ce: 0.017070
[01:43:36.385] iteration 12956 : loss : 0.036881, loss_ce: 0.012832
[01:43:36.691] iteration 12957 : loss : 0.043711, loss_ce: 0.010248
[01:43:36.996] iteration 12958 : loss : 0.081424, loss_ce: 0.019013
[01:43:37.295] iteration 12959 : loss : 0.047040, loss_ce: 0.013195
[01:43:37.599] iteration 12960 : loss : 0.039606, loss_ce: 0.019022
[01:43:37.919] iteration 12961 : loss : 0.105332, loss_ce: 0.019669
[01:43:38.223] iteration 12962 : loss : 0.096615, loss_ce: 0.010031
[01:43:38.529] iteration 12963 : loss : 0.103853, loss_ce: 0.011473
[01:43:38.835] iteration 12964 : loss : 0.052236, loss_ce: 0.016769
[01:43:39.139] iteration 12965 : loss : 0.170480, loss_ce: 0.015551
[01:43:39.448] iteration 12966 : loss : 0.054658, loss_ce: 0.016706
[01:43:39.749] iteration 12967 : loss : 0.058680, loss_ce: 0.024621
[01:43:40.056] iteration 12968 : loss : 0.116161, loss_ce: 0.018675
[01:43:40.363] iteration 12969 : loss : 0.041638, loss_ce: 0.011813
[01:43:40.667] iteration 12970 : loss : 0.044378, loss_ce: 0.017413
[01:43:40.975] iteration 12971 : loss : 0.057848, loss_ce: 0.019895
[01:43:41.287] iteration 12972 : loss : 0.051408, loss_ce: 0.016509
[01:43:41.593] iteration 12973 : loss : 0.049001, loss_ce: 0.012254
[01:43:41.899] iteration 12974 : loss : 0.055706, loss_ce: 0.023724
[01:43:42.208] iteration 12975 : loss : 0.041191, loss_ce: 0.014095
[01:43:42.512] iteration 12976 : loss : 0.052161, loss_ce: 0.015880
[01:43:42.817] iteration 12977 : loss : 0.052513, loss_ce: 0.009751
[01:43:43.125] iteration 12978 : loss : 0.045222, loss_ce: 0.018516
[01:43:43.428] iteration 12979 : loss : 0.058836, loss_ce: 0.017613
[01:43:43.732] iteration 12980 : loss : 0.108529, loss_ce: 0.006878
[01:43:44.060] iteration 12981 : loss : 0.164772, loss_ce: 0.011193
[01:43:44.364] iteration 12982 : loss : 0.117754, loss_ce: 0.014957
[01:43:44.665] iteration 12983 : loss : 0.042686, loss_ce: 0.011275
[01:43:44.974] iteration 12984 : loss : 0.056483, loss_ce: 0.011792
[01:43:45.276] iteration 12985 : loss : 0.053002, loss_ce: 0.020564
[01:43:45.578] iteration 12986 : loss : 0.108389, loss_ce: 0.012072
[01:43:45.880] iteration 12987 : loss : 0.108657, loss_ce: 0.008274
[01:43:46.180] iteration 12988 : loss : 0.048186, loss_ce: 0.009642
[01:43:46.479] iteration 12989 : loss : 0.041634, loss_ce: 0.013430
[01:43:46.781] iteration 12990 : loss : 0.045981, loss_ce: 0.011414
[01:43:47.085] iteration 12991 : loss : 0.044181, loss_ce: 0.013601
[01:43:47.388] iteration 12992 : loss : 0.046724, loss_ce: 0.016393
[01:43:47.692] iteration 12993 : loss : 0.040198, loss_ce: 0.012675
[01:43:47.994] iteration 12994 : loss : 0.046956, loss_ce: 0.010179
[01:43:48.296] iteration 12995 : loss : 0.049056, loss_ce: 0.012728
[01:43:48.599] iteration 12996 : loss : 0.055101, loss_ce: 0.016728
[01:43:48.903] iteration 12997 : loss : 0.047170, loss_ce: 0.014139
[01:43:49.209] iteration 12998 : loss : 0.114166, loss_ce: 0.008957
[01:43:49.510] iteration 12999 : loss : 0.104600, loss_ce: 0.010912
[01:43:49.812] iteration 13000 : loss : 0.048680, loss_ce: 0.013032
[01:43:50.131] iteration 13001 : loss : 0.056383, loss_ce: 0.015195
[01:43:50.435] iteration 13002 : loss : 0.120468, loss_ce: 0.009079
[01:43:50.733] iteration 13003 : loss : 0.048469, loss_ce: 0.020447
[01:43:51.036] iteration 13004 : loss : 0.101157, loss_ce: 0.011454
[01:43:51.341] iteration 13005 : loss : 0.054078, loss_ce: 0.027830
[01:43:51.643] iteration 13006 : loss : 0.109613, loss_ce: 0.015667
[01:43:51.944] iteration 13007 : loss : 0.050943, loss_ce: 0.026296
[01:43:52.253] iteration 13008 : loss : 0.060761, loss_ce: 0.011994
[01:43:52.556] iteration 13009 : loss : 0.039578, loss_ce: 0.010047
[01:43:52.858] iteration 13010 : loss : 0.051666, loss_ce: 0.021083
[01:43:53.160] iteration 13011 : loss : 0.102895, loss_ce: 0.010444
[01:43:53.464] iteration 13012 : loss : 0.049088, loss_ce: 0.012752
[01:43:53.764] iteration 13013 : loss : 0.042642, loss_ce: 0.009888
[01:43:54.065] iteration 13014 : loss : 0.045819, loss_ce: 0.017278
[01:43:54.369] iteration 13015 : loss : 0.046701, loss_ce: 0.012080
[01:43:54.675] iteration 13016 : loss : 0.051559, loss_ce: 0.017351
[01:43:54.976] iteration 13017 : loss : 0.042437, loss_ce: 0.014214
[01:43:55.280] iteration 13018 : loss : 0.041773, loss_ce: 0.014071
[01:43:55.586] iteration 13019 : loss : 0.050340, loss_ce: 0.013361
[01:43:55.889] iteration 13020 : loss : 0.049173, loss_ce: 0.013199
[01:43:56.207] iteration 13021 : loss : 0.061449, loss_ce: 0.015371
[01:43:56.506] iteration 13022 : loss : 0.100714, loss_ce: 0.007757
[01:43:56.807] iteration 13023 : loss : 0.041836, loss_ce: 0.011107
[01:43:57.104] iteration 13024 : loss : 0.109959, loss_ce: 0.008588
[01:43:57.403] iteration 13025 : loss : 0.087084, loss_ce: 0.019496
[01:43:57.702] iteration 13026 : loss : 0.106658, loss_ce: 0.009755
[01:43:57.999] iteration 13027 : loss : 0.060523, loss_ce: 0.016163
[01:43:58.304] iteration 13028 : loss : 0.044566, loss_ce: 0.023188
[01:43:58.606] iteration 13029 : loss : 0.099961, loss_ce: 0.008494
[01:43:58.900] iteration 13030 : loss : 0.052328, loss_ce: 0.021648
[01:43:59.199] iteration 13031 : loss : 0.121969, loss_ce: 0.013523
[01:43:59.502] iteration 13032 : loss : 0.070645, loss_ce: 0.011206
[01:43:59.798] iteration 13033 : loss : 0.049015, loss_ce: 0.016556
[01:44:00.095] iteration 13034 : loss : 0.052346, loss_ce: 0.011822
[01:44:00.398] iteration 13035 : loss : 0.043304, loss_ce: 0.013641
[01:44:00.694] iteration 13036 : loss : 0.056995, loss_ce: 0.013069
[01:44:00.991] iteration 13037 : loss : 0.057516, loss_ce: 0.017772
[01:44:01.292] iteration 13038 : loss : 0.162250, loss_ce: 0.008137
[01:44:01.589] iteration 13039 : loss : 0.041857, loss_ce: 0.009388
[01:44:01.889] iteration 13040 : loss : 0.047625, loss_ce: 0.011996
[01:44:02.201] iteration 13041 : loss : 0.041281, loss_ce: 0.010259
[01:44:02.501] iteration 13042 : loss : 0.059043, loss_ce: 0.018368
[01:44:02.797] iteration 13043 : loss : 0.118607, loss_ce: 0.015148
[01:44:03.101] iteration 13044 : loss : 0.050290, loss_ce: 0.022431
[01:44:03.398] iteration 13045 : loss : 0.049339, loss_ce: 0.014414
[01:44:03.697] iteration 13046 : loss : 0.237789, loss_ce: 0.013581
[01:44:03.992] iteration 13047 : loss : 0.281625, loss_ce: 0.003471
[01:44:04.289] iteration 13048 : loss : 0.104622, loss_ce: 0.017379
[01:44:04.585] iteration 13049 : loss : 0.042234, loss_ce: 0.016510
[01:44:04.884] iteration 13050 : loss : 0.034307, loss_ce: 0.012471
[01:44:05.189] iteration 13051 : loss : 0.161166, loss_ce: 0.017163
[01:44:05.492] iteration 13052 : loss : 0.058513, loss_ce: 0.031065
[01:44:05.807] iteration 13053 : loss : 0.062505, loss_ce: 0.012143
[01:44:06.111] iteration 13054 : loss : 0.102170, loss_ce: 0.012670
[01:44:06.413] iteration 13055 : loss : 0.036808, loss_ce: 0.013584
[01:44:06.716] iteration 13056 : loss : 0.044492, loss_ce: 0.011450
[01:44:07.020] iteration 13057 : loss : 0.045119, loss_ce: 0.010787
[01:44:07.328] iteration 13058 : loss : 0.062772, loss_ce: 0.009183
[01:44:07.638] iteration 13059 : loss : 0.042503, loss_ce: 0.014843
[01:44:07.938] iteration 13060 : loss : 0.041334, loss_ce: 0.012836
[01:44:08.273] iteration 13061 : loss : 0.044665, loss_ce: 0.008355
[01:44:08.575] iteration 13062 : loss : 0.053140, loss_ce: 0.018292
[01:44:08.884] iteration 13063 : loss : 0.053565, loss_ce: 0.021135
[01:44:09.188] iteration 13064 : loss : 0.060109, loss_ce: 0.013484
[01:44:09.500] iteration 13065 : loss : 0.060480, loss_ce: 0.013942
[01:44:09.580] iteration 13066 : loss : 0.122064, loss_ce: 0.015139
[01:44:30.519] iteration 13067 : loss : 0.047170, loss_ce: 0.020074
[01:44:30.818] iteration 13068 : loss : 0.108965, loss_ce: 0.010509
[01:44:31.117] iteration 13069 : loss : 0.102549, loss_ce: 0.007913
[01:44:31.414] iteration 13070 : loss : 0.051016, loss_ce: 0.025691
[01:44:31.713] iteration 13071 : loss : 0.041226, loss_ce: 0.007842
[01:44:32.012] iteration 13072 : loss : 0.109873, loss_ce: 0.006354
[01:44:32.305] iteration 13073 : loss : 0.106082, loss_ce: 0.007460
[01:44:32.603] iteration 13074 : loss : 0.047263, loss_ce: 0.016464
[01:44:32.903] iteration 13075 : loss : 0.032662, loss_ce: 0.007620
[01:44:33.201] iteration 13076 : loss : 0.036442, loss_ce: 0.008495
[01:44:33.499] iteration 13077 : loss : 0.050053, loss_ce: 0.020814
[01:44:33.796] iteration 13078 : loss : 0.061471, loss_ce: 0.014333
[01:44:34.093] iteration 13079 : loss : 0.100337, loss_ce: 0.011156
[01:44:34.386] iteration 13080 : loss : 0.117572, loss_ce: 0.020244
[01:44:34.706] iteration 13081 : loss : 0.040949, loss_ce: 0.011861
[01:44:35.003] iteration 13082 : loss : 0.100377, loss_ce: 0.014419
[01:44:35.303] iteration 13083 : loss : 0.041005, loss_ce: 0.012130
[01:44:35.601] iteration 13084 : loss : 0.278545, loss_ce: 0.004020
[01:44:35.893] iteration 13085 : loss : 0.047594, loss_ce: 0.017389
[01:44:36.187] iteration 13086 : loss : 0.109854, loss_ce: 0.012607
[01:44:36.487] iteration 13087 : loss : 0.040523, loss_ce: 0.017825
[01:44:36.785] iteration 13088 : loss : 0.049581, loss_ce: 0.019596
[01:44:37.078] iteration 13089 : loss : 0.060602, loss_ce: 0.019711
[01:44:37.378] iteration 13090 : loss : 0.066526, loss_ce: 0.017289
[01:44:37.674] iteration 13091 : loss : 0.048905, loss_ce: 0.010601
[01:44:37.972] iteration 13092 : loss : 0.045156, loss_ce: 0.011544
[01:44:38.268] iteration 13093 : loss : 0.038200, loss_ce: 0.011930
[01:44:38.565] iteration 13094 : loss : 0.035846, loss_ce: 0.012747
[01:44:38.860] iteration 13095 : loss : 0.052356, loss_ce: 0.009046
[01:44:39.159] iteration 13096 : loss : 0.044482, loss_ce: 0.012723
[01:44:39.464] iteration 13097 : loss : 0.114348, loss_ce: 0.013268
[01:44:39.766] iteration 13098 : loss : 0.110749, loss_ce: 0.005655
[01:44:40.070] iteration 13099 : loss : 0.056544, loss_ce: 0.018183
[01:44:40.376] iteration 13100 : loss : 0.075504, loss_ce: 0.018239
[01:44:40.696] iteration 13101 : loss : 0.043119, loss_ce: 0.005833
[01:44:40.994] iteration 13102 : loss : 0.047645, loss_ce: 0.024212
[01:44:41.297] iteration 13103 : loss : 0.041173, loss_ce: 0.010549
[01:44:41.591] iteration 13104 : loss : 0.049288, loss_ce: 0.008539
[01:44:41.891] iteration 13105 : loss : 0.124586, loss_ce: 0.007776
[01:44:42.189] iteration 13106 : loss : 0.044596, loss_ce: 0.011234
[01:44:42.484] iteration 13107 : loss : 0.124708, loss_ce: 0.009751
[01:44:42.782] iteration 13108 : loss : 0.067441, loss_ce: 0.007711
[01:44:43.080] iteration 13109 : loss : 0.105977, loss_ce: 0.010970
[01:44:43.383] iteration 13110 : loss : 0.059716, loss_ce: 0.026072
[01:44:43.680] iteration 13111 : loss : 0.048338, loss_ce: 0.013859
[01:44:43.977] iteration 13112 : loss : 0.046984, loss_ce: 0.020891
[01:44:44.273] iteration 13113 : loss : 0.053909, loss_ce: 0.015919
[01:44:44.570] iteration 13114 : loss : 0.047037, loss_ce: 0.015023
[01:44:44.865] iteration 13115 : loss : 0.050583, loss_ce: 0.025104
[01:44:45.164] iteration 13116 : loss : 0.105623, loss_ce: 0.020920
[01:44:45.458] iteration 13117 : loss : 0.045152, loss_ce: 0.008346
[01:44:45.754] iteration 13118 : loss : 0.043499, loss_ce: 0.016807
[01:44:46.053] iteration 13119 : loss : 0.041212, loss_ce: 0.016792
[01:44:46.347] iteration 13120 : loss : 0.057430, loss_ce: 0.013442
[01:44:46.668] iteration 13121 : loss : 0.046307, loss_ce: 0.021291
[01:44:46.964] iteration 13122 : loss : 0.144639, loss_ce: 0.011988
[01:44:47.262] iteration 13123 : loss : 0.098831, loss_ce: 0.007664
[01:44:47.565] iteration 13124 : loss : 0.045515, loss_ce: 0.014071
[01:44:47.866] iteration 13125 : loss : 0.052200, loss_ce: 0.012964
[01:44:48.166] iteration 13126 : loss : 0.043067, loss_ce: 0.010813
[01:44:48.465] iteration 13127 : loss : 0.112503, loss_ce: 0.007888
[01:44:48.761] iteration 13128 : loss : 0.047063, loss_ce: 0.025015
[01:44:49.061] iteration 13129 : loss : 0.055482, loss_ce: 0.015773
[01:44:49.359] iteration 13130 : loss : 0.035349, loss_ce: 0.010655
[01:44:49.655] iteration 13131 : loss : 0.115100, loss_ce: 0.008483
[01:44:49.958] iteration 13132 : loss : 0.034856, loss_ce: 0.014052
[01:44:50.258] iteration 13133 : loss : 0.050916, loss_ce: 0.014671
[01:44:50.558] iteration 13134 : loss : 0.037738, loss_ce: 0.009808
[01:44:50.855] iteration 13135 : loss : 0.047152, loss_ce: 0.013721
[01:44:51.152] iteration 13136 : loss : 0.054034, loss_ce: 0.017355
[01:44:51.446] iteration 13137 : loss : 0.050124, loss_ce: 0.014506
[01:44:51.752] iteration 13138 : loss : 0.059674, loss_ce: 0.016183
[01:44:52.052] iteration 13139 : loss : 0.108026, loss_ce: 0.008689
[01:44:52.348] iteration 13140 : loss : 0.069193, loss_ce: 0.017002
[01:44:52.661] iteration 13141 : loss : 0.039409, loss_ce: 0.009524
[01:44:52.957] iteration 13142 : loss : 0.101977, loss_ce: 0.016026
[01:44:53.257] iteration 13143 : loss : 0.060626, loss_ce: 0.018063
[01:44:53.557] iteration 13144 : loss : 0.045859, loss_ce: 0.018352
[01:44:53.854] iteration 13145 : loss : 0.054080, loss_ce: 0.005666
[01:44:54.154] iteration 13146 : loss : 0.050293, loss_ce: 0.016079
[01:44:54.456] iteration 13147 : loss : 0.064380, loss_ce: 0.014460
[01:44:54.759] iteration 13148 : loss : 0.111839, loss_ce: 0.014084
[01:44:55.056] iteration 13149 : loss : 0.041688, loss_ce: 0.018264
[01:44:55.353] iteration 13150 : loss : 0.051205, loss_ce: 0.014267
[01:44:55.654] iteration 13151 : loss : 0.057709, loss_ce: 0.018414
[01:44:55.952] iteration 13152 : loss : 0.043625, loss_ce: 0.017909
[01:44:56.254] iteration 13153 : loss : 0.050127, loss_ce: 0.012815
[01:44:56.557] iteration 13154 : loss : 0.036701, loss_ce: 0.015570
[01:44:56.860] iteration 13155 : loss : 0.064309, loss_ce: 0.013457
[01:44:57.164] iteration 13156 : loss : 0.049818, loss_ce: 0.014031
[01:44:57.471] iteration 13157 : loss : 0.058087, loss_ce: 0.024574
[01:44:57.773] iteration 13158 : loss : 0.051089, loss_ce: 0.013255
[01:44:58.077] iteration 13159 : loss : 0.053655, loss_ce: 0.013027
[01:44:58.381] iteration 13160 : loss : 0.052215, loss_ce: 0.013472
[01:44:58.699] iteration 13161 : loss : 0.047039, loss_ce: 0.010516
[01:44:59.005] iteration 13162 : loss : 0.060535, loss_ce: 0.010711
[01:44:59.310] iteration 13163 : loss : 0.068139, loss_ce: 0.023273
[01:44:59.616] iteration 13164 : loss : 0.051238, loss_ce: 0.016398
[01:44:59.919] iteration 13165 : loss : 0.057273, loss_ce: 0.008855
[01:45:00.222] iteration 13166 : loss : 0.034412, loss_ce: 0.007429
[01:45:00.529] iteration 13167 : loss : 0.045874, loss_ce: 0.012333
[01:45:00.832] iteration 13168 : loss : 0.053808, loss_ce: 0.011262
[01:45:01.139] iteration 13169 : loss : 0.048351, loss_ce: 0.013717
[01:45:01.439] iteration 13170 : loss : 0.042894, loss_ce: 0.020225
[01:45:01.740] iteration 13171 : loss : 0.112295, loss_ce: 0.016216
[01:45:02.041] iteration 13172 : loss : 0.055554, loss_ce: 0.016352
[01:45:02.347] iteration 13173 : loss : 0.045305, loss_ce: 0.014806
[01:45:02.654] iteration 13174 : loss : 0.057040, loss_ce: 0.025720
[01:45:02.951] iteration 13175 : loss : 0.123375, loss_ce: 0.010224
[01:45:03.253] iteration 13176 : loss : 0.056908, loss_ce: 0.019361
[01:45:03.552] iteration 13177 : loss : 0.107020, loss_ce: 0.014921
[01:45:03.853] iteration 13178 : loss : 0.119829, loss_ce: 0.012699
[01:45:04.157] iteration 13179 : loss : 0.050993, loss_ce: 0.014010
[01:45:04.461] iteration 13180 : loss : 0.051720, loss_ce: 0.018099
[01:45:04.781] iteration 13181 : loss : 0.052019, loss_ce: 0.007636
[01:45:05.086] iteration 13182 : loss : 0.228617, loss_ce: 0.006877
[01:45:05.391] iteration 13183 : loss : 0.052411, loss_ce: 0.013198
[01:45:05.691] iteration 13184 : loss : 0.044596, loss_ce: 0.009685
[01:45:05.998] iteration 13185 : loss : 0.047889, loss_ce: 0.016500
[01:45:06.301] iteration 13186 : loss : 0.046395, loss_ce: 0.011658
[01:45:06.601] iteration 13187 : loss : 0.163101, loss_ce: 0.007175
[01:45:06.908] iteration 13188 : loss : 0.053682, loss_ce: 0.019513
[01:45:07.215] iteration 13189 : loss : 0.054470, loss_ce: 0.015153
[01:45:07.523] iteration 13190 : loss : 0.049959, loss_ce: 0.013710
[01:45:07.842] iteration 13191 : loss : 0.100671, loss_ce: 0.006980
[01:45:08.149] iteration 13192 : loss : 0.044224, loss_ce: 0.014908
[01:45:08.457] iteration 13193 : loss : 0.051801, loss_ce: 0.019260
[01:45:08.759] iteration 13194 : loss : 0.037198, loss_ce: 0.017864
[01:45:09.069] iteration 13195 : loss : 0.051655, loss_ce: 0.016471
[01:45:09.384] iteration 13196 : loss : 0.053718, loss_ce: 0.014994
[01:45:09.689] iteration 13197 : loss : 0.055328, loss_ce: 0.013639
[01:45:09.996] iteration 13198 : loss : 0.105656, loss_ce: 0.014777
[01:45:10.296] iteration 13199 : loss : 0.055018, loss_ce: 0.011350
[01:45:10.604] iteration 13200 : loss : 0.057508, loss_ce: 0.006867
[01:45:10.940] iteration 13201 : loss : 0.048665, loss_ce: 0.011969
[01:45:11.251] iteration 13202 : loss : 0.052586, loss_ce: 0.026097
[01:45:11.559] iteration 13203 : loss : 0.053823, loss_ce: 0.019316
[01:45:11.867] iteration 13204 : loss : 0.043461, loss_ce: 0.018720
[01:45:11.945] iteration 13205 : loss : 0.103555, loss_ce: 0.012102
[01:45:31.222] iteration 13206 : loss : 0.048842, loss_ce: 0.008778
[01:45:31.521] iteration 13207 : loss : 0.050716, loss_ce: 0.018978
[01:45:31.820] iteration 13208 : loss : 0.098531, loss_ce: 0.013474
[01:45:32.122] iteration 13209 : loss : 0.057508, loss_ce: 0.013870
[01:45:32.425] iteration 13210 : loss : 0.086961, loss_ce: 0.013164
[01:45:32.719] iteration 13211 : loss : 0.043957, loss_ce: 0.012022
[01:45:33.019] iteration 13212 : loss : 0.044327, loss_ce: 0.018068
[01:45:33.322] iteration 13213 : loss : 0.228255, loss_ce: 0.002909
[01:45:33.622] iteration 13214 : loss : 0.050541, loss_ce: 0.011872
[01:45:33.921] iteration 13215 : loss : 0.113866, loss_ce: 0.011778
[01:45:34.220] iteration 13216 : loss : 0.046275, loss_ce: 0.017301
[01:45:34.520] iteration 13217 : loss : 0.058715, loss_ce: 0.017528
[01:45:34.821] iteration 13218 : loss : 0.049587, loss_ce: 0.019583
[01:45:35.119] iteration 13219 : loss : 0.048176, loss_ce: 0.020132
[01:45:35.414] iteration 13220 : loss : 0.044597, loss_ce: 0.009273
[01:45:35.732] iteration 13221 : loss : 0.058014, loss_ce: 0.012803
[01:45:36.036] iteration 13222 : loss : 0.049681, loss_ce: 0.025355
[01:45:36.337] iteration 13223 : loss : 0.065641, loss_ce: 0.011563
[01:45:36.637] iteration 13224 : loss : 0.053058, loss_ce: 0.013987
[01:45:36.938] iteration 13225 : loss : 0.059600, loss_ce: 0.020763
[01:45:37.239] iteration 13226 : loss : 0.054520, loss_ce: 0.017720
[01:45:37.536] iteration 13227 : loss : 0.040341, loss_ce: 0.019369
[01:45:37.833] iteration 13228 : loss : 0.037603, loss_ce: 0.008171
[01:45:38.135] iteration 13229 : loss : 0.047158, loss_ce: 0.009413
[01:45:38.435] iteration 13230 : loss : 0.049026, loss_ce: 0.017611
[01:45:38.732] iteration 13231 : loss : 0.060692, loss_ce: 0.019984
[01:45:39.028] iteration 13232 : loss : 0.057951, loss_ce: 0.010520
[01:45:39.325] iteration 13233 : loss : 0.042265, loss_ce: 0.013919
[01:45:39.622] iteration 13234 : loss : 0.045763, loss_ce: 0.017413
[01:45:39.924] iteration 13235 : loss : 0.041490, loss_ce: 0.009135
[01:45:40.221] iteration 13236 : loss : 0.045140, loss_ce: 0.011762
[01:45:40.521] iteration 13237 : loss : 0.054123, loss_ce: 0.022176
[01:45:40.819] iteration 13238 : loss : 0.058075, loss_ce: 0.019011
[01:45:41.119] iteration 13239 : loss : 0.051337, loss_ce: 0.010954
[01:45:41.413] iteration 13240 : loss : 0.044945, loss_ce: 0.009533
[01:45:41.731] iteration 13241 : loss : 0.044108, loss_ce: 0.014252
[01:45:42.030] iteration 13242 : loss : 0.044847, loss_ce: 0.013698
[01:45:42.326] iteration 13243 : loss : 0.106301, loss_ce: 0.009001
[01:45:42.625] iteration 13244 : loss : 0.056492, loss_ce: 0.015018
[01:45:42.922] iteration 13245 : loss : 0.048941, loss_ce: 0.015393
[01:45:43.222] iteration 13246 : loss : 0.060906, loss_ce: 0.019825
[01:45:43.522] iteration 13247 : loss : 0.046633, loss_ce: 0.020961
[01:45:43.825] iteration 13248 : loss : 0.047615, loss_ce: 0.011749
[01:45:44.126] iteration 13249 : loss : 0.045900, loss_ce: 0.020515
[01:45:44.435] iteration 13250 : loss : 0.045075, loss_ce: 0.014060
[01:45:44.743] iteration 13251 : loss : 0.038867, loss_ce: 0.014962
[01:45:45.049] iteration 13252 : loss : 0.050999, loss_ce: 0.019868
[01:45:45.354] iteration 13253 : loss : 0.052371, loss_ce: 0.011714
[01:45:45.659] iteration 13254 : loss : 0.114078, loss_ce: 0.004640
[01:45:45.965] iteration 13255 : loss : 0.113986, loss_ce: 0.006607
[01:45:46.267] iteration 13256 : loss : 0.095086, loss_ce: 0.005297
[01:45:46.562] iteration 13257 : loss : 0.050708, loss_ce: 0.020949
[01:45:46.863] iteration 13258 : loss : 0.105022, loss_ce: 0.011074
[01:45:47.159] iteration 13259 : loss : 0.251565, loss_ce: 0.005998
[01:45:47.458] iteration 13260 : loss : 0.104167, loss_ce: 0.012441
[01:45:47.770] iteration 13261 : loss : 0.070321, loss_ce: 0.019080
[01:45:48.068] iteration 13262 : loss : 0.108452, loss_ce: 0.009676
[01:45:48.369] iteration 13263 : loss : 0.047541, loss_ce: 0.012626
[01:45:48.667] iteration 13264 : loss : 0.046344, loss_ce: 0.014596
[01:45:48.966] iteration 13265 : loss : 0.050324, loss_ce: 0.010379
[01:45:49.268] iteration 13266 : loss : 0.170323, loss_ce: 0.010662
[01:45:49.566] iteration 13267 : loss : 0.049438, loss_ce: 0.020475
[01:45:49.861] iteration 13268 : loss : 0.070993, loss_ce: 0.019568
[01:45:50.160] iteration 13269 : loss : 0.101890, loss_ce: 0.009646
[01:45:50.462] iteration 13270 : loss : 0.071573, loss_ce: 0.023851
[01:45:50.758] iteration 13271 : loss : 0.068365, loss_ce: 0.014699
[01:45:51.057] iteration 13272 : loss : 0.051002, loss_ce: 0.012981
[01:45:51.362] iteration 13273 : loss : 0.033858, loss_ce: 0.009161
[01:45:51.661] iteration 13274 : loss : 0.058823, loss_ce: 0.015316
[01:45:51.958] iteration 13275 : loss : 0.052343, loss_ce: 0.014587
[01:45:52.261] iteration 13276 : loss : 0.213705, loss_ce: 0.005522
[01:45:52.555] iteration 13277 : loss : 0.058152, loss_ce: 0.012622
[01:45:52.860] iteration 13278 : loss : 0.052122, loss_ce: 0.014248
[01:45:53.158] iteration 13279 : loss : 0.048125, loss_ce: 0.018368
[01:45:53.456] iteration 13280 : loss : 0.056107, loss_ce: 0.022835
[01:45:53.777] iteration 13281 : loss : 0.059223, loss_ce: 0.016446
[01:45:54.079] iteration 13282 : loss : 0.075235, loss_ce: 0.011186
[01:45:54.378] iteration 13283 : loss : 0.051764, loss_ce: 0.026216
[01:45:54.677] iteration 13284 : loss : 0.053473, loss_ce: 0.014427
[01:45:54.977] iteration 13285 : loss : 0.289620, loss_ce: 0.002722
[01:45:55.274] iteration 13286 : loss : 0.053576, loss_ce: 0.017661
[01:45:55.567] iteration 13287 : loss : 0.044074, loss_ce: 0.015194
[01:45:55.861] iteration 13288 : loss : 0.051584, loss_ce: 0.014957
[01:45:56.159] iteration 13289 : loss : 0.051550, loss_ce: 0.020368
[01:45:56.458] iteration 13290 : loss : 0.104525, loss_ce: 0.008757
[01:45:56.756] iteration 13291 : loss : 0.050526, loss_ce: 0.017728
[01:45:57.053] iteration 13292 : loss : 0.050369, loss_ce: 0.012633
[01:45:57.351] iteration 13293 : loss : 0.053010, loss_ce: 0.012224
[01:45:57.650] iteration 13294 : loss : 0.047020, loss_ce: 0.019820
[01:45:57.950] iteration 13295 : loss : 0.065658, loss_ce: 0.020521
[01:45:58.248] iteration 13296 : loss : 0.064405, loss_ce: 0.017078
[01:45:58.542] iteration 13297 : loss : 0.048738, loss_ce: 0.017435
[01:45:58.847] iteration 13298 : loss : 0.075436, loss_ce: 0.016198
[01:45:59.149] iteration 13299 : loss : 0.070696, loss_ce: 0.018198
[01:45:59.448] iteration 13300 : loss : 0.116020, loss_ce: 0.011222
[01:45:59.764] iteration 13301 : loss : 0.041340, loss_ce: 0.017254
[01:46:00.071] iteration 13302 : loss : 0.050020, loss_ce: 0.014070
[01:46:00.371] iteration 13303 : loss : 0.042574, loss_ce: 0.016903
[01:46:00.677] iteration 13304 : loss : 0.043515, loss_ce: 0.018932
[01:46:00.982] iteration 13305 : loss : 0.042919, loss_ce: 0.012288
[01:46:01.285] iteration 13306 : loss : 0.045667, loss_ce: 0.010560
[01:46:01.585] iteration 13307 : loss : 0.050317, loss_ce: 0.016062
[01:46:01.884] iteration 13308 : loss : 0.053676, loss_ce: 0.012579
[01:46:02.178] iteration 13309 : loss : 0.126562, loss_ce: 0.017550
[01:46:02.477] iteration 13310 : loss : 0.129885, loss_ce: 0.007081
[01:46:02.777] iteration 13311 : loss : 0.049748, loss_ce: 0.016917
[01:46:03.076] iteration 13312 : loss : 0.055917, loss_ce: 0.017140
[01:46:03.376] iteration 13313 : loss : 0.052292, loss_ce: 0.021144
[01:46:03.677] iteration 13314 : loss : 0.054784, loss_ce: 0.014169
[01:46:03.974] iteration 13315 : loss : 0.054002, loss_ce: 0.018225
[01:46:04.274] iteration 13316 : loss : 0.103512, loss_ce: 0.007779
[01:46:04.570] iteration 13317 : loss : 0.039555, loss_ce: 0.008298
[01:46:04.867] iteration 13318 : loss : 0.112959, loss_ce: 0.014447
[01:46:05.167] iteration 13319 : loss : 0.047471, loss_ce: 0.015752
[01:46:05.468] iteration 13320 : loss : 0.047979, loss_ce: 0.022036
[01:46:05.778] iteration 13321 : loss : 0.049511, loss_ce: 0.018192
[01:46:06.072] iteration 13322 : loss : 0.058331, loss_ce: 0.020984
[01:46:06.368] iteration 13323 : loss : 0.049865, loss_ce: 0.015496
[01:46:06.666] iteration 13324 : loss : 0.049860, loss_ce: 0.012066
[01:46:06.962] iteration 13325 : loss : 0.108799, loss_ce: 0.007691
[01:46:07.254] iteration 13326 : loss : 0.051677, loss_ce: 0.015816
[01:46:07.557] iteration 13327 : loss : 0.109070, loss_ce: 0.012204
[01:46:07.861] iteration 13328 : loss : 0.044574, loss_ce: 0.013308
[01:46:08.162] iteration 13329 : loss : 0.044794, loss_ce: 0.019047
[01:46:08.464] iteration 13330 : loss : 0.056108, loss_ce: 0.018741
[01:46:08.768] iteration 13331 : loss : 0.121643, loss_ce: 0.009368
[01:46:09.069] iteration 13332 : loss : 0.050738, loss_ce: 0.017177
[01:46:09.372] iteration 13333 : loss : 0.040288, loss_ce: 0.011049
[01:46:09.673] iteration 13334 : loss : 0.105601, loss_ce: 0.013498
[01:46:09.982] iteration 13335 : loss : 0.039117, loss_ce: 0.015726
[01:46:10.281] iteration 13336 : loss : 0.051867, loss_ce: 0.018163
[01:46:10.582] iteration 13337 : loss : 0.044818, loss_ce: 0.013510
[01:46:10.888] iteration 13338 : loss : 0.042032, loss_ce: 0.010023
[01:46:11.186] iteration 13339 : loss : 0.098666, loss_ce: 0.005246
[01:46:11.494] iteration 13340 : loss : 0.050734, loss_ce: 0.025112
[01:46:11.824] iteration 13341 : loss : 0.047473, loss_ce: 0.010724
[01:46:12.126] iteration 13342 : loss : 0.052994, loss_ce: 0.008977
[01:46:12.429] iteration 13343 : loss : 0.104586, loss_ce: 0.009861
[01:46:12.511] iteration 13344 : loss : 0.232149, loss_ce: 0.019480
[01:46:30.230] iteration 13345 : loss : 0.057484, loss_ce: 0.010872
[01:46:30.531] iteration 13346 : loss : 0.055089, loss_ce: 0.011870
[01:46:30.836] iteration 13347 : loss : 0.050623, loss_ce: 0.015774
[01:46:31.142] iteration 13348 : loss : 0.040259, loss_ce: 0.015063
[01:46:31.449] iteration 13349 : loss : 0.044289, loss_ce: 0.022519
[01:46:31.749] iteration 13350 : loss : 0.048558, loss_ce: 0.011401
[01:46:32.048] iteration 13351 : loss : 0.054635, loss_ce: 0.016452
[01:46:32.349] iteration 13352 : loss : 0.052149, loss_ce: 0.008841
[01:46:32.652] iteration 13353 : loss : 0.107946, loss_ce: 0.012752
[01:46:32.947] iteration 13354 : loss : 0.040588, loss_ce: 0.012182
[01:46:33.254] iteration 13355 : loss : 0.048657, loss_ce: 0.013711
[01:46:33.555] iteration 13356 : loss : 0.109435, loss_ce: 0.006313
[01:46:33.858] iteration 13357 : loss : 0.166906, loss_ce: 0.008502
[01:46:34.161] iteration 13358 : loss : 0.062495, loss_ce: 0.018343
[01:46:34.465] iteration 13359 : loss : 0.068207, loss_ce: 0.011614
[01:46:34.769] iteration 13360 : loss : 0.041737, loss_ce: 0.014078
[01:46:35.098] iteration 13361 : loss : 0.047762, loss_ce: 0.011277
[01:46:35.401] iteration 13362 : loss : 0.045329, loss_ce: 0.030504
[01:46:35.705] iteration 13363 : loss : 0.101217, loss_ce: 0.010970
[01:46:36.007] iteration 13364 : loss : 0.285036, loss_ce: 0.002791
[01:46:36.308] iteration 13365 : loss : 0.048780, loss_ce: 0.012810
[01:46:36.608] iteration 13366 : loss : 0.097656, loss_ce: 0.008836
[01:46:36.903] iteration 13367 : loss : 0.048362, loss_ce: 0.017364
[01:46:37.203] iteration 13368 : loss : 0.048105, loss_ce: 0.014580
[01:46:37.498] iteration 13369 : loss : 0.047734, loss_ce: 0.015066
[01:46:37.800] iteration 13370 : loss : 0.119524, loss_ce: 0.007408
[01:46:38.099] iteration 13371 : loss : 0.057376, loss_ce: 0.011444
[01:46:38.393] iteration 13372 : loss : 0.051972, loss_ce: 0.011004
[01:46:38.697] iteration 13373 : loss : 0.103547, loss_ce: 0.010402
[01:46:38.995] iteration 13374 : loss : 0.041778, loss_ce: 0.011688
[01:46:39.290] iteration 13375 : loss : 0.042470, loss_ce: 0.011373
[01:46:39.590] iteration 13376 : loss : 0.062361, loss_ce: 0.021768
[01:46:39.893] iteration 13377 : loss : 0.070938, loss_ce: 0.015215
[01:46:40.191] iteration 13378 : loss : 0.113920, loss_ce: 0.016224
[01:46:40.486] iteration 13379 : loss : 0.062308, loss_ce: 0.014341
[01:46:40.789] iteration 13380 : loss : 0.108468, loss_ce: 0.008024
[01:46:41.109] iteration 13381 : loss : 0.058078, loss_ce: 0.020590
[01:46:41.405] iteration 13382 : loss : 0.107372, loss_ce: 0.009558
[01:46:41.705] iteration 13383 : loss : 0.036083, loss_ce: 0.007945
[01:46:42.006] iteration 13384 : loss : 0.065330, loss_ce: 0.015690
[01:46:42.305] iteration 13385 : loss : 0.054271, loss_ce: 0.016255
[01:46:42.601] iteration 13386 : loss : 0.109454, loss_ce: 0.005302
[01:46:42.899] iteration 13387 : loss : 0.134481, loss_ce: 0.015353
[01:46:43.202] iteration 13388 : loss : 0.107302, loss_ce: 0.012106
[01:46:43.500] iteration 13389 : loss : 0.111159, loss_ce: 0.007342
[01:46:43.795] iteration 13390 : loss : 0.054546, loss_ce: 0.016529
[01:46:44.094] iteration 13391 : loss : 0.043114, loss_ce: 0.011852
[01:46:44.393] iteration 13392 : loss : 0.051838, loss_ce: 0.015461
[01:46:44.697] iteration 13393 : loss : 0.048790, loss_ce: 0.010347
[01:46:44.991] iteration 13394 : loss : 0.040157, loss_ce: 0.012615
[01:46:45.292] iteration 13395 : loss : 0.046808, loss_ce: 0.010819
[01:46:45.590] iteration 13396 : loss : 0.048959, loss_ce: 0.010088
[01:46:45.887] iteration 13397 : loss : 0.104261, loss_ce: 0.012802
[01:46:46.187] iteration 13398 : loss : 0.118379, loss_ce: 0.010114
[01:46:46.486] iteration 13399 : loss : 0.051541, loss_ce: 0.012285
[01:46:46.785] iteration 13400 : loss : 0.046548, loss_ce: 0.028455
[01:46:47.098] iteration 13401 : loss : 0.052085, loss_ce: 0.023725
[01:46:47.399] iteration 13402 : loss : 0.047154, loss_ce: 0.015405
[01:46:47.694] iteration 13403 : loss : 0.047719, loss_ce: 0.015492
[01:46:47.989] iteration 13404 : loss : 0.041917, loss_ce: 0.018472
[01:46:48.285] iteration 13405 : loss : 0.047295, loss_ce: 0.017503
[01:46:48.586] iteration 13406 : loss : 0.051502, loss_ce: 0.016468
[01:46:48.883] iteration 13407 : loss : 0.154897, loss_ce: 0.007755
[01:46:49.185] iteration 13408 : loss : 0.096465, loss_ce: 0.008805
[01:46:49.492] iteration 13409 : loss : 0.044793, loss_ce: 0.016725
[01:46:49.798] iteration 13410 : loss : 0.042923, loss_ce: 0.013583
[01:46:50.106] iteration 13411 : loss : 0.230484, loss_ce: 0.003554
[01:46:50.413] iteration 13412 : loss : 0.058192, loss_ce: 0.016080
[01:46:50.722] iteration 13413 : loss : 0.046542, loss_ce: 0.024467
[01:46:51.025] iteration 13414 : loss : 0.109051, loss_ce: 0.010633
[01:46:51.323] iteration 13415 : loss : 0.046526, loss_ce: 0.011040
[01:46:51.620] iteration 13416 : loss : 0.043091, loss_ce: 0.013505
[01:46:51.919] iteration 13417 : loss : 0.052649, loss_ce: 0.014547
[01:46:52.219] iteration 13418 : loss : 0.059245, loss_ce: 0.013968
[01:46:52.520] iteration 13419 : loss : 0.047244, loss_ce: 0.023523
[01:46:52.814] iteration 13420 : loss : 0.108890, loss_ce: 0.017328
[01:46:53.126] iteration 13421 : loss : 0.049094, loss_ce: 0.011465
[01:46:53.424] iteration 13422 : loss : 0.048947, loss_ce: 0.018629
[01:46:53.720] iteration 13423 : loss : 0.127421, loss_ce: 0.009261
[01:46:54.021] iteration 13424 : loss : 0.108613, loss_ce: 0.013102
[01:46:54.316] iteration 13425 : loss : 0.050040, loss_ce: 0.020532
[01:46:54.618] iteration 13426 : loss : 0.059713, loss_ce: 0.010978
[01:46:54.921] iteration 13427 : loss : 0.102725, loss_ce: 0.017102
[01:46:55.219] iteration 13428 : loss : 0.047743, loss_ce: 0.013715
[01:46:55.520] iteration 13429 : loss : 0.046738, loss_ce: 0.013214
[01:46:55.819] iteration 13430 : loss : 0.071282, loss_ce: 0.027468
[01:46:56.117] iteration 13431 : loss : 0.065276, loss_ce: 0.016840
[01:46:56.410] iteration 13432 : loss : 0.043506, loss_ce: 0.007830
[01:46:56.707] iteration 13433 : loss : 0.048435, loss_ce: 0.015035
[01:46:57.005] iteration 13434 : loss : 0.114356, loss_ce: 0.015346
[01:46:57.301] iteration 13435 : loss : 0.043912, loss_ce: 0.011221
[01:46:57.602] iteration 13436 : loss : 0.107530, loss_ce: 0.018524
[01:46:57.901] iteration 13437 : loss : 0.062451, loss_ce: 0.019264
[01:46:58.200] iteration 13438 : loss : 0.050767, loss_ce: 0.023870
[01:46:58.497] iteration 13439 : loss : 0.059225, loss_ce: 0.010410
[01:46:58.795] iteration 13440 : loss : 0.042004, loss_ce: 0.015544
[01:46:59.110] iteration 13441 : loss : 0.038419, loss_ce: 0.014025
[01:46:59.408] iteration 13442 : loss : 0.054805, loss_ce: 0.016832
[01:46:59.708] iteration 13443 : loss : 0.048236, loss_ce: 0.022408
[01:47:00.008] iteration 13444 : loss : 0.039595, loss_ce: 0.013147
[01:47:00.302] iteration 13445 : loss : 0.113281, loss_ce: 0.010848
[01:47:00.597] iteration 13446 : loss : 0.053632, loss_ce: 0.014717
[01:47:00.900] iteration 13447 : loss : 0.107102, loss_ce: 0.013232
[01:47:01.201] iteration 13448 : loss : 0.038135, loss_ce: 0.014880
[01:47:01.501] iteration 13449 : loss : 0.094362, loss_ce: 0.014645
[01:47:01.800] iteration 13450 : loss : 0.050125, loss_ce: 0.021942
[01:47:02.098] iteration 13451 : loss : 0.049641, loss_ce: 0.019571
[01:47:02.394] iteration 13452 : loss : 0.057067, loss_ce: 0.015411
[01:47:02.690] iteration 13453 : loss : 0.048277, loss_ce: 0.017414
[01:47:02.986] iteration 13454 : loss : 0.044977, loss_ce: 0.019273
[01:47:03.288] iteration 13455 : loss : 0.043741, loss_ce: 0.012111
[01:47:03.588] iteration 13456 : loss : 0.048853, loss_ce: 0.020470
[01:47:03.885] iteration 13457 : loss : 0.058023, loss_ce: 0.015664
[01:47:04.181] iteration 13458 : loss : 0.035071, loss_ce: 0.013159
[01:47:04.481] iteration 13459 : loss : 0.045810, loss_ce: 0.013875
[01:47:04.782] iteration 13460 : loss : 0.113579, loss_ce: 0.013846
[01:47:05.102] iteration 13461 : loss : 0.046442, loss_ce: 0.012171
[01:47:05.403] iteration 13462 : loss : 0.086347, loss_ce: 0.010850
[01:47:05.703] iteration 13463 : loss : 0.280183, loss_ce: 0.004631
[01:47:06.007] iteration 13464 : loss : 0.042497, loss_ce: 0.010779
[01:47:06.308] iteration 13465 : loss : 0.111170, loss_ce: 0.010455
[01:47:06.613] iteration 13466 : loss : 0.100433, loss_ce: 0.011293
[01:47:06.918] iteration 13467 : loss : 0.042669, loss_ce: 0.012357
[01:47:07.229] iteration 13468 : loss : 0.052161, loss_ce: 0.017616
[01:47:07.536] iteration 13469 : loss : 0.166591, loss_ce: 0.014965
[01:47:07.840] iteration 13470 : loss : 0.043539, loss_ce: 0.021858
[01:47:08.145] iteration 13471 : loss : 0.109952, loss_ce: 0.012348
[01:47:08.451] iteration 13472 : loss : 0.053111, loss_ce: 0.016322
[01:47:08.764] iteration 13473 : loss : 0.055685, loss_ce: 0.022700
[01:47:09.067] iteration 13474 : loss : 0.068988, loss_ce: 0.016322
[01:47:09.381] iteration 13475 : loss : 0.049654, loss_ce: 0.019639
[01:47:09.691] iteration 13476 : loss : 0.052671, loss_ce: 0.015903
[01:47:10.006] iteration 13477 : loss : 0.192904, loss_ce: 0.014600
[01:47:10.314] iteration 13478 : loss : 0.049397, loss_ce: 0.016411
[01:47:10.624] iteration 13479 : loss : 0.049648, loss_ce: 0.015223
[01:47:10.935] iteration 13480 : loss : 0.056156, loss_ce: 0.015748
[01:47:11.281] iteration 13481 : loss : 0.042937, loss_ce: 0.018891
[01:47:11.596] iteration 13482 : loss : 0.060601, loss_ce: 0.009756
[01:47:11.688] iteration 13483 : loss : 0.298752, loss_ce: 0.019555
[01:47:29.112] iteration 13484 : loss : 0.105842, loss_ce: 0.009660
[01:47:29.415] iteration 13485 : loss : 0.107904, loss_ce: 0.011258
[01:47:29.721] iteration 13486 : loss : 0.080255, loss_ce: 0.012235
[01:47:30.023] iteration 13487 : loss : 0.067677, loss_ce: 0.014863
[01:47:30.323] iteration 13488 : loss : 0.046328, loss_ce: 0.016568
[01:47:30.626] iteration 13489 : loss : 0.046088, loss_ce: 0.013008
[01:47:30.925] iteration 13490 : loss : 0.058528, loss_ce: 0.024093
[01:47:31.225] iteration 13491 : loss : 0.040172, loss_ce: 0.013437
[01:47:31.531] iteration 13492 : loss : 0.067297, loss_ce: 0.011981
[01:47:31.830] iteration 13493 : loss : 0.057449, loss_ce: 0.018007
[01:47:32.132] iteration 13494 : loss : 0.111326, loss_ce: 0.006725
[01:47:32.430] iteration 13495 : loss : 0.046933, loss_ce: 0.017562
[01:47:32.728] iteration 13496 : loss : 0.060609, loss_ce: 0.013634
[01:47:33.023] iteration 13497 : loss : 0.048667, loss_ce: 0.014954
[01:47:33.324] iteration 13498 : loss : 0.051208, loss_ce: 0.025692
[01:47:33.625] iteration 13499 : loss : 0.051121, loss_ce: 0.014504
[01:47:33.926] iteration 13500 : loss : 0.053788, loss_ce: 0.021034
[01:47:34.245] iteration 13501 : loss : 0.050897, loss_ce: 0.009635
[01:47:34.544] iteration 13502 : loss : 0.052933, loss_ce: 0.018521
[01:47:34.846] iteration 13503 : loss : 0.057394, loss_ce: 0.009997
[01:47:35.148] iteration 13504 : loss : 0.108673, loss_ce: 0.014442
[01:47:35.446] iteration 13505 : loss : 0.053134, loss_ce: 0.021779
[01:47:35.745] iteration 13506 : loss : 0.049173, loss_ce: 0.010716
[01:47:36.045] iteration 13507 : loss : 0.115511, loss_ce: 0.004346
[01:47:36.341] iteration 13508 : loss : 0.049364, loss_ce: 0.012812
[01:47:36.641] iteration 13509 : loss : 0.037047, loss_ce: 0.013547
[01:47:36.941] iteration 13510 : loss : 0.050555, loss_ce: 0.016758
[01:47:37.241] iteration 13511 : loss : 0.046437, loss_ce: 0.021250
[01:47:37.541] iteration 13512 : loss : 0.056386, loss_ce: 0.016509
[01:47:37.841] iteration 13513 : loss : 0.111966, loss_ce: 0.006111
[01:47:38.143] iteration 13514 : loss : 0.048684, loss_ce: 0.012772
[01:47:38.440] iteration 13515 : loss : 0.055967, loss_ce: 0.022444
[01:47:38.743] iteration 13516 : loss : 0.069218, loss_ce: 0.013326
[01:47:39.045] iteration 13517 : loss : 0.221795, loss_ce: 0.013809
[01:47:39.351] iteration 13518 : loss : 0.048057, loss_ce: 0.015583
[01:47:39.656] iteration 13519 : loss : 0.043015, loss_ce: 0.015537
[01:47:39.964] iteration 13520 : loss : 0.035065, loss_ce: 0.005922
[01:47:40.303] iteration 13521 : loss : 0.112271, loss_ce: 0.017386
[01:47:40.609] iteration 13522 : loss : 0.084719, loss_ce: 0.014285
[01:47:40.913] iteration 13523 : loss : 0.043318, loss_ce: 0.008845
[01:47:41.227] iteration 13524 : loss : 0.104656, loss_ce: 0.020869
[01:47:41.526] iteration 13525 : loss : 0.158668, loss_ce: 0.008247
[01:47:41.823] iteration 13526 : loss : 0.045745, loss_ce: 0.008076
[01:47:42.125] iteration 13527 : loss : 0.056919, loss_ce: 0.016996
[01:47:42.427] iteration 13528 : loss : 0.040106, loss_ce: 0.010428
[01:47:42.727] iteration 13529 : loss : 0.061386, loss_ce: 0.014587
[01:47:43.024] iteration 13530 : loss : 0.059910, loss_ce: 0.021210
[01:47:43.326] iteration 13531 : loss : 0.037078, loss_ce: 0.006651
[01:47:43.627] iteration 13532 : loss : 0.038082, loss_ce: 0.013128
[01:47:43.932] iteration 13533 : loss : 0.286633, loss_ce: 0.005518
[01:47:44.233] iteration 13534 : loss : 0.050852, loss_ce: 0.014801
[01:47:44.532] iteration 13535 : loss : 0.055181, loss_ce: 0.014219
[01:47:44.830] iteration 13536 : loss : 0.112035, loss_ce: 0.005408
[01:47:45.126] iteration 13537 : loss : 0.048943, loss_ce: 0.017893
[01:47:45.421] iteration 13538 : loss : 0.086305, loss_ce: 0.012727
[01:47:45.723] iteration 13539 : loss : 0.165965, loss_ce: 0.007207
[01:47:46.023] iteration 13540 : loss : 0.049746, loss_ce: 0.026084
[01:47:46.339] iteration 13541 : loss : 0.054232, loss_ce: 0.013311
[01:47:46.638] iteration 13542 : loss : 0.101041, loss_ce: 0.008663
[01:47:46.939] iteration 13543 : loss : 0.070481, loss_ce: 0.017624
[01:47:47.237] iteration 13544 : loss : 0.061051, loss_ce: 0.029427
[01:47:47.536] iteration 13545 : loss : 0.048165, loss_ce: 0.015981
[01:47:47.838] iteration 13546 : loss : 0.074565, loss_ce: 0.018468
[01:47:48.132] iteration 13547 : loss : 0.050305, loss_ce: 0.021965
[01:47:48.427] iteration 13548 : loss : 0.043618, loss_ce: 0.008626
[01:47:48.725] iteration 13549 : loss : 0.063520, loss_ce: 0.015280
[01:47:49.023] iteration 13550 : loss : 0.050682, loss_ce: 0.014896
[01:47:49.324] iteration 13551 : loss : 0.051715, loss_ce: 0.011723
[01:47:49.620] iteration 13552 : loss : 0.043364, loss_ce: 0.012927
[01:47:49.916] iteration 13553 : loss : 0.060001, loss_ce: 0.024358
[01:47:50.219] iteration 13554 : loss : 0.049070, loss_ce: 0.020279
[01:47:50.520] iteration 13555 : loss : 0.101157, loss_ce: 0.007788
[01:47:50.817] iteration 13556 : loss : 0.078674, loss_ce: 0.013615
[01:47:51.115] iteration 13557 : loss : 0.048789, loss_ce: 0.022299
[01:47:51.407] iteration 13558 : loss : 0.039735, loss_ce: 0.014221
[01:47:51.702] iteration 13559 : loss : 0.045954, loss_ce: 0.013536
[01:47:51.995] iteration 13560 : loss : 0.219207, loss_ce: 0.007152
[01:47:52.309] iteration 13561 : loss : 0.055611, loss_ce: 0.025057
[01:47:52.607] iteration 13562 : loss : 0.042903, loss_ce: 0.009239
[01:47:52.907] iteration 13563 : loss : 0.039627, loss_ce: 0.008866
[01:47:53.205] iteration 13564 : loss : 0.045783, loss_ce: 0.017734
[01:47:53.510] iteration 13565 : loss : 0.048114, loss_ce: 0.013606
[01:47:53.807] iteration 13566 : loss : 0.036469, loss_ce: 0.009712
[01:47:54.102] iteration 13567 : loss : 0.039834, loss_ce: 0.011461
[01:47:54.407] iteration 13568 : loss : 0.053010, loss_ce: 0.014269
[01:47:54.709] iteration 13569 : loss : 0.122459, loss_ce: 0.015720
[01:47:55.013] iteration 13570 : loss : 0.046326, loss_ce: 0.020397
[01:47:55.318] iteration 13571 : loss : 0.052708, loss_ce: 0.011220
[01:47:55.620] iteration 13572 : loss : 0.050815, loss_ce: 0.022530
[01:47:55.927] iteration 13573 : loss : 0.045557, loss_ce: 0.014432
[01:47:56.232] iteration 13574 : loss : 0.046678, loss_ce: 0.010858
[01:47:56.532] iteration 13575 : loss : 0.110262, loss_ce: 0.008981
[01:47:56.829] iteration 13576 : loss : 0.041984, loss_ce: 0.013371
[01:47:57.128] iteration 13577 : loss : 0.043125, loss_ce: 0.004337
[01:47:57.426] iteration 13578 : loss : 0.106352, loss_ce: 0.012374
[01:47:57.727] iteration 13579 : loss : 0.041575, loss_ce: 0.012059
[01:47:58.027] iteration 13580 : loss : 0.055807, loss_ce: 0.020705
[01:47:58.341] iteration 13581 : loss : 0.122195, loss_ce: 0.024763
[01:47:58.636] iteration 13582 : loss : 0.101933, loss_ce: 0.013411
[01:47:58.934] iteration 13583 : loss : 0.037324, loss_ce: 0.012997
[01:47:59.235] iteration 13584 : loss : 0.104043, loss_ce: 0.013520
[01:47:59.534] iteration 13585 : loss : 0.043816, loss_ce: 0.015268
[01:47:59.835] iteration 13586 : loss : 0.065143, loss_ce: 0.014979
[01:48:00.132] iteration 13587 : loss : 0.100750, loss_ce: 0.008651
[01:48:00.433] iteration 13588 : loss : 0.047456, loss_ce: 0.014355
[01:48:00.731] iteration 13589 : loss : 0.061867, loss_ce: 0.018687
[01:48:01.038] iteration 13590 : loss : 0.053281, loss_ce: 0.015170
[01:48:01.334] iteration 13591 : loss : 0.047308, loss_ce: 0.019074
[01:48:01.630] iteration 13592 : loss : 0.053203, loss_ce: 0.017105
[01:48:01.927] iteration 13593 : loss : 0.054450, loss_ce: 0.025999
[01:48:02.223] iteration 13594 : loss : 0.043831, loss_ce: 0.017420
[01:48:02.525] iteration 13595 : loss : 0.042175, loss_ce: 0.012144
[01:48:02.823] iteration 13596 : loss : 0.090136, loss_ce: 0.007889
[01:48:03.121] iteration 13597 : loss : 0.045008, loss_ce: 0.012591
[01:48:03.416] iteration 13598 : loss : 0.053744, loss_ce: 0.013174
[01:48:03.715] iteration 13599 : loss : 0.104538, loss_ce: 0.009766
[01:48:04.014] iteration 13600 : loss : 0.050046, loss_ce: 0.016861
[01:48:04.333] iteration 13601 : loss : 0.106080, loss_ce: 0.011896
[01:48:04.628] iteration 13602 : loss : 0.117090, loss_ce: 0.017873
[01:48:04.929] iteration 13603 : loss : 0.053892, loss_ce: 0.011432
[01:48:05.228] iteration 13604 : loss : 0.046762, loss_ce: 0.019683
[01:48:05.527] iteration 13605 : loss : 0.063772, loss_ce: 0.016130
[01:48:05.828] iteration 13606 : loss : 0.042064, loss_ce: 0.012504
[01:48:06.128] iteration 13607 : loss : 0.047728, loss_ce: 0.010496
[01:48:06.432] iteration 13608 : loss : 0.050210, loss_ce: 0.023570
[01:48:06.732] iteration 13609 : loss : 0.105660, loss_ce: 0.010000
[01:48:07.041] iteration 13610 : loss : 0.051044, loss_ce: 0.010590
[01:48:07.345] iteration 13611 : loss : 0.048416, loss_ce: 0.011623
[01:48:07.654] iteration 13612 : loss : 0.049682, loss_ce: 0.012222
[01:48:07.952] iteration 13613 : loss : 0.049369, loss_ce: 0.021361
[01:48:08.265] iteration 13614 : loss : 0.044738, loss_ce: 0.007856
[01:48:08.568] iteration 13615 : loss : 0.042180, loss_ce: 0.010807
[01:48:08.869] iteration 13616 : loss : 0.108628, loss_ce: 0.009266
[01:48:09.173] iteration 13617 : loss : 0.055419, loss_ce: 0.014051
[01:48:09.490] iteration 13618 : loss : 0.046779, loss_ce: 0.019617
[01:48:09.802] iteration 13619 : loss : 0.034906, loss_ce: 0.012386
[01:48:10.105] iteration 13620 : loss : 0.048839, loss_ce: 0.015633
[01:48:10.437] iteration 13621 : loss : 0.050383, loss_ce: 0.017908
[01:48:10.522] iteration 13622 : loss : 0.323010, loss_ce: 0.000036
[01:48:30.241] iteration 13623 : loss : 0.237511, loss_ce: 0.001926
[01:48:30.550] iteration 13624 : loss : 0.064701, loss_ce: 0.020105
[01:48:30.855] iteration 13625 : loss : 0.056396, loss_ce: 0.015435
[01:48:31.159] iteration 13626 : loss : 0.173154, loss_ce: 0.006390
[01:48:31.461] iteration 13627 : loss : 0.081778, loss_ce: 0.023180
[01:48:31.756] iteration 13628 : loss : 0.042125, loss_ce: 0.008330
[01:48:32.056] iteration 13629 : loss : 0.045129, loss_ce: 0.011227
[01:48:32.354] iteration 13630 : loss : 0.051775, loss_ce: 0.010420
[01:48:32.650] iteration 13631 : loss : 0.057321, loss_ce: 0.011451
[01:48:32.949] iteration 13632 : loss : 0.045877, loss_ce: 0.014323
[01:48:33.246] iteration 13633 : loss : 0.073325, loss_ce: 0.015251
[01:48:33.544] iteration 13634 : loss : 0.106182, loss_ce: 0.013585
[01:48:33.841] iteration 13635 : loss : 0.161525, loss_ce: 0.014813
[01:48:34.138] iteration 13636 : loss : 0.109275, loss_ce: 0.011665
[01:48:34.439] iteration 13637 : loss : 0.056799, loss_ce: 0.026002
[01:48:34.735] iteration 13638 : loss : 0.065754, loss_ce: 0.019238
[01:48:35.033] iteration 13639 : loss : 0.065270, loss_ce: 0.024461
[01:48:35.324] iteration 13640 : loss : 0.060220, loss_ce: 0.022134
[01:48:35.634] iteration 13641 : loss : 0.064081, loss_ce: 0.009890
[01:48:35.930] iteration 13642 : loss : 0.053052, loss_ce: 0.013556
[01:48:36.227] iteration 13643 : loss : 0.049780, loss_ce: 0.015433
[01:48:36.527] iteration 13644 : loss : 0.074022, loss_ce: 0.013760
[01:48:36.824] iteration 13645 : loss : 0.063535, loss_ce: 0.012902
[01:48:37.120] iteration 13646 : loss : 0.057014, loss_ce: 0.015372
[01:48:37.416] iteration 13647 : loss : 0.048387, loss_ce: 0.014120
[01:48:37.714] iteration 13648 : loss : 0.118140, loss_ce: 0.016292
[01:48:38.009] iteration 13649 : loss : 0.110343, loss_ce: 0.013310
[01:48:38.305] iteration 13650 : loss : 0.047315, loss_ce: 0.017169
[01:48:38.599] iteration 13651 : loss : 0.055643, loss_ce: 0.018124
[01:48:38.895] iteration 13652 : loss : 0.107997, loss_ce: 0.015651
[01:48:39.196] iteration 13653 : loss : 0.061884, loss_ce: 0.007925
[01:48:39.494] iteration 13654 : loss : 0.055934, loss_ce: 0.019098
[01:48:39.795] iteration 13655 : loss : 0.057067, loss_ce: 0.017309
[01:48:40.093] iteration 13656 : loss : 0.050176, loss_ce: 0.017079
[01:48:40.391] iteration 13657 : loss : 0.042432, loss_ce: 0.017188
[01:48:40.687] iteration 13658 : loss : 0.047466, loss_ce: 0.013387
[01:48:40.983] iteration 13659 : loss : 0.061209, loss_ce: 0.012152
[01:48:41.278] iteration 13660 : loss : 0.047330, loss_ce: 0.017311
[01:48:41.595] iteration 13661 : loss : 0.074642, loss_ce: 0.020205
[01:48:41.894] iteration 13662 : loss : 0.065673, loss_ce: 0.019368
[01:48:42.197] iteration 13663 : loss : 0.042011, loss_ce: 0.014856
[01:48:42.494] iteration 13664 : loss : 0.040832, loss_ce: 0.010867
[01:48:42.792] iteration 13665 : loss : 0.061492, loss_ce: 0.004905
[01:48:43.089] iteration 13666 : loss : 0.067622, loss_ce: 0.029081
[01:48:43.385] iteration 13667 : loss : 0.055682, loss_ce: 0.021332
[01:48:43.686] iteration 13668 : loss : 0.105855, loss_ce: 0.011356
[01:48:43.986] iteration 13669 : loss : 0.058413, loss_ce: 0.025857
[01:48:44.289] iteration 13670 : loss : 0.056614, loss_ce: 0.017232
[01:48:44.594] iteration 13671 : loss : 0.040040, loss_ce: 0.016788
[01:48:44.896] iteration 13672 : loss : 0.045003, loss_ce: 0.020932
[01:48:45.201] iteration 13673 : loss : 0.057794, loss_ce: 0.020524
[01:48:45.509] iteration 13674 : loss : 0.046928, loss_ce: 0.008870
[01:48:45.814] iteration 13675 : loss : 0.106299, loss_ce: 0.012020
[01:48:46.117] iteration 13676 : loss : 0.115418, loss_ce: 0.007474
[01:48:46.414] iteration 13677 : loss : 0.046506, loss_ce: 0.010508
[01:48:46.708] iteration 13678 : loss : 0.046936, loss_ce: 0.012659
[01:48:47.004] iteration 13679 : loss : 0.105541, loss_ce: 0.012447
[01:48:47.303] iteration 13680 : loss : 0.048016, loss_ce: 0.013779
[01:48:47.615] iteration 13681 : loss : 0.113336, loss_ce: 0.017135
[01:48:47.915] iteration 13682 : loss : 0.054262, loss_ce: 0.015884
[01:48:48.213] iteration 13683 : loss : 0.064994, loss_ce: 0.018928
[01:48:48.511] iteration 13684 : loss : 0.046792, loss_ce: 0.018818
[01:48:48.810] iteration 13685 : loss : 0.042496, loss_ce: 0.016899
[01:48:49.111] iteration 13686 : loss : 0.044140, loss_ce: 0.012428
[01:48:49.415] iteration 13687 : loss : 0.046088, loss_ce: 0.020476
[01:48:49.711] iteration 13688 : loss : 0.044776, loss_ce: 0.011060
[01:48:50.015] iteration 13689 : loss : 0.052289, loss_ce: 0.020906
[01:48:50.314] iteration 13690 : loss : 0.048996, loss_ce: 0.012414
[01:48:50.612] iteration 13691 : loss : 0.037294, loss_ce: 0.012673
[01:48:50.909] iteration 13692 : loss : 0.044499, loss_ce: 0.014566
[01:48:51.209] iteration 13693 : loss : 0.056709, loss_ce: 0.011374
[01:48:51.510] iteration 13694 : loss : 0.046013, loss_ce: 0.016424
[01:48:51.811] iteration 13695 : loss : 0.055787, loss_ce: 0.018980
[01:48:52.110] iteration 13696 : loss : 0.050970, loss_ce: 0.012895
[01:48:52.405] iteration 13697 : loss : 0.048467, loss_ce: 0.018501
[01:48:52.705] iteration 13698 : loss : 0.047984, loss_ce: 0.021075
[01:48:53.006] iteration 13699 : loss : 0.054431, loss_ce: 0.024810
[01:48:53.301] iteration 13700 : loss : 0.034710, loss_ce: 0.010474
[01:48:53.620] iteration 13701 : loss : 0.051868, loss_ce: 0.015538
[01:48:53.919] iteration 13702 : loss : 0.058809, loss_ce: 0.011219
[01:48:54.219] iteration 13703 : loss : 0.048392, loss_ce: 0.013362
[01:48:54.519] iteration 13704 : loss : 0.101965, loss_ce: 0.011597
[01:48:54.822] iteration 13705 : loss : 0.051409, loss_ce: 0.024077
[01:48:55.123] iteration 13706 : loss : 0.053193, loss_ce: 0.012834
[01:48:55.418] iteration 13707 : loss : 0.049656, loss_ce: 0.019198
[01:48:55.713] iteration 13708 : loss : 0.107996, loss_ce: 0.006412
[01:48:56.012] iteration 13709 : loss : 0.058114, loss_ce: 0.019544
[01:48:56.311] iteration 13710 : loss : 0.060581, loss_ce: 0.020115
[01:48:56.612] iteration 13711 : loss : 0.050195, loss_ce: 0.017662
[01:48:56.909] iteration 13712 : loss : 0.041631, loss_ce: 0.011233
[01:48:57.208] iteration 13713 : loss : 0.054302, loss_ce: 0.013380
[01:48:57.507] iteration 13714 : loss : 0.100117, loss_ce: 0.006785
[01:48:57.807] iteration 13715 : loss : 0.118338, loss_ce: 0.014995
[01:48:58.110] iteration 13716 : loss : 0.049844, loss_ce: 0.024694
[01:48:58.408] iteration 13717 : loss : 0.051784, loss_ce: 0.019830
[01:48:58.711] iteration 13718 : loss : 0.042689, loss_ce: 0.009245
[01:48:59.010] iteration 13719 : loss : 0.064573, loss_ce: 0.017816
[01:48:59.316] iteration 13720 : loss : 0.126277, loss_ce: 0.009704
[01:48:59.639] iteration 13721 : loss : 0.043796, loss_ce: 0.009940
[01:48:59.940] iteration 13722 : loss : 0.045998, loss_ce: 0.023052
[01:49:00.245] iteration 13723 : loss : 0.050521, loss_ce: 0.026008
[01:49:00.553] iteration 13724 : loss : 0.040337, loss_ce: 0.013863
[01:49:00.855] iteration 13725 : loss : 0.059436, loss_ce: 0.016639
[01:49:01.156] iteration 13726 : loss : 0.043549, loss_ce: 0.011337
[01:49:01.455] iteration 13727 : loss : 0.047540, loss_ce: 0.016869
[01:49:01.758] iteration 13728 : loss : 0.051233, loss_ce: 0.017508
[01:49:02.056] iteration 13729 : loss : 0.048581, loss_ce: 0.015753
[01:49:02.356] iteration 13730 : loss : 0.048123, loss_ce: 0.013787
[01:49:02.654] iteration 13731 : loss : 0.040979, loss_ce: 0.016132
[01:49:02.958] iteration 13732 : loss : 0.036972, loss_ce: 0.013357
[01:49:03.260] iteration 13733 : loss : 0.103058, loss_ce: 0.009568
[01:49:03.564] iteration 13734 : loss : 0.041448, loss_ce: 0.011926
[01:49:03.862] iteration 13735 : loss : 0.046214, loss_ce: 0.013455
[01:49:04.166] iteration 13736 : loss : 0.050440, loss_ce: 0.017210
[01:49:04.466] iteration 13737 : loss : 0.052418, loss_ce: 0.013156
[01:49:04.770] iteration 13738 : loss : 0.058892, loss_ce: 0.028154
[01:49:05.071] iteration 13739 : loss : 0.129137, loss_ce: 0.011897
[01:49:05.370] iteration 13740 : loss : 0.118744, loss_ce: 0.019043
[01:49:05.685] iteration 13741 : loss : 0.039708, loss_ce: 0.012612
[01:49:05.986] iteration 13742 : loss : 0.047353, loss_ce: 0.013229
[01:49:06.286] iteration 13743 : loss : 0.047700, loss_ce: 0.010467
[01:49:06.588] iteration 13744 : loss : 0.154861, loss_ce: 0.006623
[01:49:06.890] iteration 13745 : loss : 0.111904, loss_ce: 0.012556
[01:49:07.189] iteration 13746 : loss : 0.108718, loss_ce: 0.008832
[01:49:07.498] iteration 13747 : loss : 0.048632, loss_ce: 0.017697
[01:49:07.804] iteration 13748 : loss : 0.039057, loss_ce: 0.013026
[01:49:08.106] iteration 13749 : loss : 0.071140, loss_ce: 0.021880
[01:49:08.409] iteration 13750 : loss : 0.040176, loss_ce: 0.014356
[01:49:08.712] iteration 13751 : loss : 0.063342, loss_ce: 0.015671
[01:49:09.018] iteration 13752 : loss : 0.081576, loss_ce: 0.016105
[01:49:09.321] iteration 13753 : loss : 0.059053, loss_ce: 0.009199
[01:49:09.630] iteration 13754 : loss : 0.043019, loss_ce: 0.014578
[01:49:09.935] iteration 13755 : loss : 0.054339, loss_ce: 0.010439
[01:49:10.239] iteration 13756 : loss : 0.047862, loss_ce: 0.013979
[01:49:10.540] iteration 13757 : loss : 0.105449, loss_ce: 0.010060
[01:49:10.838] iteration 13758 : loss : 0.042073, loss_ce: 0.012260
[01:49:11.141] iteration 13759 : loss : 0.048302, loss_ce: 0.016933
[01:49:11.441] iteration 13760 : loss : 0.102554, loss_ce: 0.005098
[01:49:11.537] iteration 13761 : loss : 0.102808, loss_ce: 0.016230
[01:49:30.030] iteration 13762 : loss : 0.046851, loss_ce: 0.017304
[01:49:30.335] iteration 13763 : loss : 0.051532, loss_ce: 0.020258
[01:49:30.643] iteration 13764 : loss : 0.031026, loss_ce: 0.005763
[01:49:30.951] iteration 13765 : loss : 0.060269, loss_ce: 0.029047
[01:49:31.262] iteration 13766 : loss : 0.047803, loss_ce: 0.013701
[01:49:31.565] iteration 13767 : loss : 0.114443, loss_ce: 0.015117
[01:49:31.870] iteration 13768 : loss : 0.066832, loss_ce: 0.005463
[01:49:32.176] iteration 13769 : loss : 0.112913, loss_ce: 0.015285
[01:49:32.478] iteration 13770 : loss : 0.050120, loss_ce: 0.020172
[01:49:32.780] iteration 13771 : loss : 0.057034, loss_ce: 0.022303
[01:49:33.086] iteration 13772 : loss : 0.044411, loss_ce: 0.014419
[01:49:33.386] iteration 13773 : loss : 0.040714, loss_ce: 0.015326
[01:49:33.691] iteration 13774 : loss : 0.044117, loss_ce: 0.012002
[01:49:33.991] iteration 13775 : loss : 0.043974, loss_ce: 0.017886
[01:49:34.297] iteration 13776 : loss : 0.102001, loss_ce: 0.010837
[01:49:34.605] iteration 13777 : loss : 0.077505, loss_ce: 0.012783
[01:49:34.912] iteration 13778 : loss : 0.049215, loss_ce: 0.011758
[01:49:35.214] iteration 13779 : loss : 0.039729, loss_ce: 0.008755
[01:49:35.517] iteration 13780 : loss : 0.044711, loss_ce: 0.015303
[01:49:35.836] iteration 13781 : loss : 0.103360, loss_ce: 0.013105
[01:49:36.136] iteration 13782 : loss : 0.116513, loss_ce: 0.014855
[01:49:36.432] iteration 13783 : loss : 0.059189, loss_ce: 0.005817
[01:49:36.732] iteration 13784 : loss : 0.046299, loss_ce: 0.012658
[01:49:37.033] iteration 13785 : loss : 0.055639, loss_ce: 0.012593
[01:49:37.325] iteration 13786 : loss : 0.054956, loss_ce: 0.022447
[01:49:37.624] iteration 13787 : loss : 0.054627, loss_ce: 0.026700
[01:49:37.918] iteration 13788 : loss : 0.054745, loss_ce: 0.024207
[01:49:38.217] iteration 13789 : loss : 0.169945, loss_ce: 0.009023
[01:49:38.513] iteration 13790 : loss : 0.045933, loss_ce: 0.010570
[01:49:38.815] iteration 13791 : loss : 0.056184, loss_ce: 0.017977
[01:49:39.110] iteration 13792 : loss : 0.045080, loss_ce: 0.009823
[01:49:39.405] iteration 13793 : loss : 0.109754, loss_ce: 0.009527
[01:49:39.701] iteration 13794 : loss : 0.047371, loss_ce: 0.016880
[01:49:40.003] iteration 13795 : loss : 0.047562, loss_ce: 0.020963
[01:49:40.300] iteration 13796 : loss : 0.055695, loss_ce: 0.021120
[01:49:40.600] iteration 13797 : loss : 0.054545, loss_ce: 0.022569
[01:49:40.899] iteration 13798 : loss : 0.060567, loss_ce: 0.013050
[01:49:41.197] iteration 13799 : loss : 0.049830, loss_ce: 0.015807
[01:49:41.502] iteration 13800 : loss : 0.047733, loss_ce: 0.010657
[01:49:41.820] iteration 13801 : loss : 0.100644, loss_ce: 0.010501
[01:49:42.119] iteration 13802 : loss : 0.109842, loss_ce: 0.004984
[01:49:42.419] iteration 13803 : loss : 0.047007, loss_ce: 0.016063
[01:49:42.727] iteration 13804 : loss : 0.068859, loss_ce: 0.010926
[01:49:43.027] iteration 13805 : loss : 0.043545, loss_ce: 0.013944
[01:49:43.329] iteration 13806 : loss : 0.049297, loss_ce: 0.016183
[01:49:43.629] iteration 13807 : loss : 0.039145, loss_ce: 0.008572
[01:49:43.932] iteration 13808 : loss : 0.068584, loss_ce: 0.010531
[01:49:44.229] iteration 13809 : loss : 0.105571, loss_ce: 0.006671
[01:49:44.527] iteration 13810 : loss : 0.107753, loss_ce: 0.016698
[01:49:44.827] iteration 13811 : loss : 0.048591, loss_ce: 0.020394
[01:49:45.129] iteration 13812 : loss : 0.056737, loss_ce: 0.013266
[01:49:45.424] iteration 13813 : loss : 0.041939, loss_ce: 0.016059
[01:49:45.726] iteration 13814 : loss : 0.048703, loss_ce: 0.010954
[01:49:46.024] iteration 13815 : loss : 0.047259, loss_ce: 0.023520
[01:49:46.323] iteration 13816 : loss : 0.047252, loss_ce: 0.020770
[01:49:46.624] iteration 13817 : loss : 0.052708, loss_ce: 0.016145
[01:49:46.923] iteration 13818 : loss : 0.113575, loss_ce: 0.013131
[01:49:47.223] iteration 13819 : loss : 0.094890, loss_ce: 0.013177
[01:49:47.526] iteration 13820 : loss : 0.047160, loss_ce: 0.015396
[01:49:47.845] iteration 13821 : loss : 0.054161, loss_ce: 0.020467
[01:49:48.141] iteration 13822 : loss : 0.051120, loss_ce: 0.016282
[01:49:48.436] iteration 13823 : loss : 0.050606, loss_ce: 0.014834
[01:49:48.735] iteration 13824 : loss : 0.100193, loss_ce: 0.011811
[01:49:49.039] iteration 13825 : loss : 0.057797, loss_ce: 0.009152
[01:49:49.346] iteration 13826 : loss : 0.063312, loss_ce: 0.018540
[01:49:49.650] iteration 13827 : loss : 0.046790, loss_ce: 0.014111
[01:49:49.952] iteration 13828 : loss : 0.059466, loss_ce: 0.034619
[01:49:50.256] iteration 13829 : loss : 0.054803, loss_ce: 0.014230
[01:49:50.557] iteration 13830 : loss : 0.047194, loss_ce: 0.010973
[01:49:50.861] iteration 13831 : loss : 0.047028, loss_ce: 0.009330
[01:49:51.160] iteration 13832 : loss : 0.284344, loss_ce: 0.009345
[01:49:51.456] iteration 13833 : loss : 0.050612, loss_ce: 0.020584
[01:49:51.757] iteration 13834 : loss : 0.047420, loss_ce: 0.007689
[01:49:52.057] iteration 13835 : loss : 0.064943, loss_ce: 0.014514
[01:49:52.354] iteration 13836 : loss : 0.043731, loss_ce: 0.021614
[01:49:52.651] iteration 13837 : loss : 0.055537, loss_ce: 0.017606
[01:49:52.947] iteration 13838 : loss : 0.047523, loss_ce: 0.012130
[01:49:53.246] iteration 13839 : loss : 0.044052, loss_ce: 0.018286
[01:49:53.546] iteration 13840 : loss : 0.103730, loss_ce: 0.007555
[01:49:53.866] iteration 13841 : loss : 0.110423, loss_ce: 0.007695
[01:49:54.160] iteration 13842 : loss : 0.102989, loss_ce: 0.012533
[01:49:54.458] iteration 13843 : loss : 0.044306, loss_ce: 0.013725
[01:49:54.758] iteration 13844 : loss : 0.105980, loss_ce: 0.009154
[01:49:55.056] iteration 13845 : loss : 0.297149, loss_ce: 0.004224
[01:49:55.356] iteration 13846 : loss : 0.103819, loss_ce: 0.005687
[01:49:55.656] iteration 13847 : loss : 0.058125, loss_ce: 0.011993
[01:49:55.955] iteration 13848 : loss : 0.099033, loss_ce: 0.006932
[01:49:56.254] iteration 13849 : loss : 0.107290, loss_ce: 0.014314
[01:49:56.547] iteration 13850 : loss : 0.035865, loss_ce: 0.015048
[01:49:56.850] iteration 13851 : loss : 0.059698, loss_ce: 0.028696
[01:49:57.144] iteration 13852 : loss : 0.039294, loss_ce: 0.009115
[01:49:57.437] iteration 13853 : loss : 0.050511, loss_ce: 0.011706
[01:49:57.741] iteration 13854 : loss : 0.057183, loss_ce: 0.021954
[01:49:58.038] iteration 13855 : loss : 0.050528, loss_ce: 0.009538
[01:49:58.338] iteration 13856 : loss : 0.056554, loss_ce: 0.015426
[01:49:58.634] iteration 13857 : loss : 0.104561, loss_ce: 0.021267
[01:49:58.932] iteration 13858 : loss : 0.044054, loss_ce: 0.013152
[01:49:59.231] iteration 13859 : loss : 0.062732, loss_ce: 0.018898
[01:49:59.529] iteration 13860 : loss : 0.057130, loss_ce: 0.017545
[01:49:59.843] iteration 13861 : loss : 0.099851, loss_ce: 0.007213
[01:50:00.140] iteration 13862 : loss : 0.064837, loss_ce: 0.016871
[01:50:00.439] iteration 13863 : loss : 0.043995, loss_ce: 0.009555
[01:50:00.738] iteration 13864 : loss : 0.105497, loss_ce: 0.006935
[01:50:01.036] iteration 13865 : loss : 0.053261, loss_ce: 0.008040
[01:50:01.334] iteration 13866 : loss : 0.055050, loss_ce: 0.011515
[01:50:01.631] iteration 13867 : loss : 0.046154, loss_ce: 0.015213
[01:50:01.931] iteration 13868 : loss : 0.042668, loss_ce: 0.012411
[01:50:02.233] iteration 13869 : loss : 0.048503, loss_ce: 0.009613
[01:50:02.534] iteration 13870 : loss : 0.042578, loss_ce: 0.012651
[01:50:02.831] iteration 13871 : loss : 0.044903, loss_ce: 0.020953
[01:50:03.129] iteration 13872 : loss : 0.050644, loss_ce: 0.014934
[01:50:03.425] iteration 13873 : loss : 0.042484, loss_ce: 0.018158
[01:50:03.723] iteration 13874 : loss : 0.050521, loss_ce: 0.010215
[01:50:04.016] iteration 13875 : loss : 0.038327, loss_ce: 0.010589
[01:50:04.326] iteration 13876 : loss : 0.099988, loss_ce: 0.011441
[01:50:04.628] iteration 13877 : loss : 0.048703, loss_ce: 0.013584
[01:50:04.934] iteration 13878 : loss : 0.057323, loss_ce: 0.016755
[01:50:05.237] iteration 13879 : loss : 0.042624, loss_ce: 0.018195
[01:50:05.540] iteration 13880 : loss : 0.046343, loss_ce: 0.008590
[01:50:05.859] iteration 13881 : loss : 0.087696, loss_ce: 0.010269
[01:50:06.158] iteration 13882 : loss : 0.108906, loss_ce: 0.013232
[01:50:06.453] iteration 13883 : loss : 0.051715, loss_ce: 0.016846
[01:50:06.754] iteration 13884 : loss : 0.053983, loss_ce: 0.013736
[01:50:07.061] iteration 13885 : loss : 0.057503, loss_ce: 0.032195
[01:50:07.363] iteration 13886 : loss : 0.063131, loss_ce: 0.016263
[01:50:07.672] iteration 13887 : loss : 0.153653, loss_ce: 0.006717
[01:50:07.973] iteration 13888 : loss : 0.042980, loss_ce: 0.015360
[01:50:08.274] iteration 13889 : loss : 0.284159, loss_ce: 0.007073
[01:50:08.586] iteration 13890 : loss : 0.056611, loss_ce: 0.020068
[01:50:08.886] iteration 13891 : loss : 0.050834, loss_ce: 0.020166
[01:50:09.193] iteration 13892 : loss : 0.056403, loss_ce: 0.014573
[01:50:09.500] iteration 13893 : loss : 0.124178, loss_ce: 0.010385
[01:50:09.806] iteration 13894 : loss : 0.053662, loss_ce: 0.016298
[01:50:10.105] iteration 13895 : loss : 0.052330, loss_ce: 0.018450
[01:50:10.405] iteration 13896 : loss : 0.053370, loss_ce: 0.018549
[01:50:10.706] iteration 13897 : loss : 0.065812, loss_ce: 0.012629
[01:50:11.006] iteration 13898 : loss : 0.048587, loss_ce: 0.023408
[01:50:11.311] iteration 13899 : loss : 0.052013, loss_ce: 0.020184
[01:50:11.393] iteration 13900 : loss : 0.296692, loss_ce: 0.004642
[01:50:11.996] save model to D:\data/output\epoch_99.pth
[01:50:30.283] iteration 13901 : loss : 0.114528, loss_ce: 0.010881
[01:50:30.584] iteration 13902 : loss : 0.104944, loss_ce: 0.012456
[01:50:30.883] iteration 13903 : loss : 0.038873, loss_ce: 0.011656
[01:50:31.183] iteration 13904 : loss : 0.048308, loss_ce: 0.016112
[01:50:31.482] iteration 13905 : loss : 0.042362, loss_ce: 0.015192
[01:50:31.778] iteration 13906 : loss : 0.103524, loss_ce: 0.008214
[01:50:32.076] iteration 13907 : loss : 0.047166, loss_ce: 0.010163
[01:50:32.376] iteration 13908 : loss : 0.052533, loss_ce: 0.015996
[01:50:32.671] iteration 13909 : loss : 0.046569, loss_ce: 0.016390
[01:50:32.967] iteration 13910 : loss : 0.171565, loss_ce: 0.012444
[01:50:33.265] iteration 13911 : loss : 0.050989, loss_ce: 0.021513
[01:50:33.562] iteration 13912 : loss : 0.040614, loss_ce: 0.013558
[01:50:33.863] iteration 13913 : loss : 0.097681, loss_ce: 0.003666
[01:50:34.156] iteration 13914 : loss : 0.052770, loss_ce: 0.013513
[01:50:34.459] iteration 13915 : loss : 0.098719, loss_ce: 0.009250
[01:50:34.753] iteration 13916 : loss : 0.066069, loss_ce: 0.010460
[01:50:35.055] iteration 13917 : loss : 0.102798, loss_ce: 0.011939
[01:50:35.357] iteration 13918 : loss : 0.171184, loss_ce: 0.014981
[01:50:35.658] iteration 13919 : loss : 0.066760, loss_ce: 0.017269
[01:50:35.962] iteration 13920 : loss : 0.041625, loss_ce: 0.015585
[01:50:36.275] iteration 13921 : loss : 0.042525, loss_ce: 0.017337
[01:50:36.579] iteration 13922 : loss : 0.046323, loss_ce: 0.011538
[01:50:36.886] iteration 13923 : loss : 0.045775, loss_ce: 0.015246
[01:50:37.184] iteration 13924 : loss : 0.111744, loss_ce: 0.007508
[01:50:37.493] iteration 13925 : loss : 0.066247, loss_ce: 0.011023
[01:50:37.798] iteration 13926 : loss : 0.056065, loss_ce: 0.011695
[01:50:38.101] iteration 13927 : loss : 0.055044, loss_ce: 0.010022
[01:50:38.407] iteration 13928 : loss : 0.040694, loss_ce: 0.016477
[01:50:38.708] iteration 13929 : loss : 0.046856, loss_ce: 0.015449
[01:50:39.012] iteration 13930 : loss : 0.057783, loss_ce: 0.022175
[01:50:39.317] iteration 13931 : loss : 0.038371, loss_ce: 0.012814
[01:50:39.619] iteration 13932 : loss : 0.060303, loss_ce: 0.014925
[01:50:39.922] iteration 13933 : loss : 0.043357, loss_ce: 0.008993
[01:50:40.224] iteration 13934 : loss : 0.058536, loss_ce: 0.024559
[01:50:40.526] iteration 13935 : loss : 0.051423, loss_ce: 0.023857
[01:50:40.828] iteration 13936 : loss : 0.045223, loss_ce: 0.009549
[01:50:41.131] iteration 13937 : loss : 0.154189, loss_ce: 0.005718
[01:50:41.435] iteration 13938 : loss : 0.047210, loss_ce: 0.016083
[01:50:41.737] iteration 13939 : loss : 0.064785, loss_ce: 0.018596
[01:50:42.040] iteration 13940 : loss : 0.052476, loss_ce: 0.013541
[01:50:42.358] iteration 13941 : loss : 0.047367, loss_ce: 0.006777
[01:50:42.659] iteration 13942 : loss : 0.043403, loss_ce: 0.016809
[01:50:42.965] iteration 13943 : loss : 0.054567, loss_ce: 0.008102
[01:50:43.268] iteration 13944 : loss : 0.062235, loss_ce: 0.014119
[01:50:43.570] iteration 13945 : loss : 0.037247, loss_ce: 0.013968
[01:50:43.871] iteration 13946 : loss : 0.053119, loss_ce: 0.016272
[01:50:44.176] iteration 13947 : loss : 0.065255, loss_ce: 0.016580
[01:50:44.477] iteration 13948 : loss : 0.037791, loss_ce: 0.014339
[01:50:44.782] iteration 13949 : loss : 0.049277, loss_ce: 0.006550
[01:50:45.082] iteration 13950 : loss : 0.041368, loss_ce: 0.006049
[01:50:45.383] iteration 13951 : loss : 0.056816, loss_ce: 0.015661
[01:50:45.682] iteration 13952 : loss : 0.042442, loss_ce: 0.015425
[01:50:45.987] iteration 13953 : loss : 0.247306, loss_ce: 0.018351
[01:50:46.288] iteration 13954 : loss : 0.042625, loss_ce: 0.016205
[01:50:46.590] iteration 13955 : loss : 0.085518, loss_ce: 0.013928
[01:50:46.892] iteration 13956 : loss : 0.107720, loss_ce: 0.004388
[01:50:47.195] iteration 13957 : loss : 0.113377, loss_ce: 0.013327
[01:50:47.499] iteration 13958 : loss : 0.044264, loss_ce: 0.017205
[01:50:47.800] iteration 13959 : loss : 0.075342, loss_ce: 0.014441
[01:50:48.104] iteration 13960 : loss : 0.167600, loss_ce: 0.009296
[01:50:48.424] iteration 13961 : loss : 0.043935, loss_ce: 0.017440
[01:50:48.726] iteration 13962 : loss : 0.069626, loss_ce: 0.019446
[01:50:49.026] iteration 13963 : loss : 0.063092, loss_ce: 0.008641
[01:50:49.328] iteration 13964 : loss : 0.049232, loss_ce: 0.012842
[01:50:49.632] iteration 13965 : loss : 0.123556, loss_ce: 0.015590
[01:50:49.934] iteration 13966 : loss : 0.041209, loss_ce: 0.012471
[01:50:50.238] iteration 13967 : loss : 0.056118, loss_ce: 0.011261
[01:50:50.541] iteration 13968 : loss : 0.114097, loss_ce: 0.017579
[01:50:50.842] iteration 13969 : loss : 0.106745, loss_ce: 0.011929
[01:50:51.141] iteration 13970 : loss : 0.054396, loss_ce: 0.018607
[01:50:51.454] iteration 13971 : loss : 0.059063, loss_ce: 0.021993
[01:50:51.752] iteration 13972 : loss : 0.105925, loss_ce: 0.011901
[01:50:52.055] iteration 13973 : loss : 0.043252, loss_ce: 0.015073
[01:50:52.355] iteration 13974 : loss : 0.044969, loss_ce: 0.006898
[01:50:52.657] iteration 13975 : loss : 0.042277, loss_ce: 0.011733
[01:50:52.961] iteration 13976 : loss : 0.043933, loss_ce: 0.011801
[01:50:53.264] iteration 13977 : loss : 0.047330, loss_ce: 0.014724
[01:50:53.570] iteration 13978 : loss : 0.037237, loss_ce: 0.013440
[01:50:53.873] iteration 13979 : loss : 0.048918, loss_ce: 0.017166
[01:50:54.178] iteration 13980 : loss : 0.102469, loss_ce: 0.010160
[01:50:54.504] iteration 13981 : loss : 0.102545, loss_ce: 0.020314
[01:50:54.806] iteration 13982 : loss : 0.050256, loss_ce: 0.020902
[01:50:55.110] iteration 13983 : loss : 0.052289, loss_ce: 0.019802
[01:50:55.410] iteration 13984 : loss : 0.046954, loss_ce: 0.024636
[01:50:55.712] iteration 13985 : loss : 0.040825, loss_ce: 0.006188
[01:50:56.016] iteration 13986 : loss : 0.043145, loss_ce: 0.009195
[01:50:56.318] iteration 13987 : loss : 0.067865, loss_ce: 0.013027
[01:50:56.618] iteration 13988 : loss : 0.061027, loss_ce: 0.027105
[01:50:56.920] iteration 13989 : loss : 0.045922, loss_ce: 0.014360
[01:50:57.220] iteration 13990 : loss : 0.091374, loss_ce: 0.006322
[01:50:57.518] iteration 13991 : loss : 0.111992, loss_ce: 0.013174
[01:50:57.814] iteration 13992 : loss : 0.048969, loss_ce: 0.010667
[01:50:58.114] iteration 13993 : loss : 0.058408, loss_ce: 0.015987
[01:50:58.409] iteration 13994 : loss : 0.057075, loss_ce: 0.018243
[01:50:58.706] iteration 13995 : loss : 0.052188, loss_ce: 0.016099
[01:50:59.005] iteration 13996 : loss : 0.061747, loss_ce: 0.014770
[01:50:59.303] iteration 13997 : loss : 0.051435, loss_ce: 0.011386
[01:50:59.600] iteration 13998 : loss : 0.049534, loss_ce: 0.014626
[01:50:59.897] iteration 13999 : loss : 0.047339, loss_ce: 0.017346
[01:51:00.196] iteration 14000 : loss : 0.043056, loss_ce: 0.022981
[01:51:00.510] iteration 14001 : loss : 0.055570, loss_ce: 0.014086
[01:51:00.811] iteration 14002 : loss : 0.054427, loss_ce: 0.007474
[01:51:01.111] iteration 14003 : loss : 0.038105, loss_ce: 0.011787
[01:51:01.410] iteration 14004 : loss : 0.119488, loss_ce: 0.014454
[01:51:01.711] iteration 14005 : loss : 0.110218, loss_ce: 0.017474
[01:51:02.014] iteration 14006 : loss : 0.049988, loss_ce: 0.017602
[01:51:02.308] iteration 14007 : loss : 0.050408, loss_ce: 0.011815
[01:51:02.608] iteration 14008 : loss : 0.043405, loss_ce: 0.013690
[01:51:02.909] iteration 14009 : loss : 0.055897, loss_ce: 0.014107
[01:51:03.207] iteration 14010 : loss : 0.059481, loss_ce: 0.011282
[01:51:03.503] iteration 14011 : loss : 0.048346, loss_ce: 0.013225
[01:51:03.801] iteration 14012 : loss : 0.039551, loss_ce: 0.010412
[01:51:04.098] iteration 14013 : loss : 0.101274, loss_ce: 0.009551
[01:51:04.397] iteration 14014 : loss : 0.047196, loss_ce: 0.013474
[01:51:04.696] iteration 14015 : loss : 0.044196, loss_ce: 0.009380
[01:51:04.996] iteration 14016 : loss : 0.047483, loss_ce: 0.010147
[01:51:05.293] iteration 14017 : loss : 0.102301, loss_ce: 0.006847
[01:51:05.600] iteration 14018 : loss : 0.047447, loss_ce: 0.015365
[01:51:05.895] iteration 14019 : loss : 0.044712, loss_ce: 0.021809
[01:51:06.193] iteration 14020 : loss : 0.048587, loss_ce: 0.016793
[01:51:06.514] iteration 14021 : loss : 0.052503, loss_ce: 0.018760
[01:51:06.815] iteration 14022 : loss : 0.065275, loss_ce: 0.021902
[01:51:07.118] iteration 14023 : loss : 0.042204, loss_ce: 0.012465
[01:51:07.427] iteration 14024 : loss : 0.204977, loss_ce: 0.011495
[01:51:07.731] iteration 14025 : loss : 0.054741, loss_ce: 0.018726
[01:51:08.030] iteration 14026 : loss : 0.038604, loss_ce: 0.009300
[01:51:08.336] iteration 14027 : loss : 0.046677, loss_ce: 0.015567
[01:51:08.641] iteration 14028 : loss : 0.048320, loss_ce: 0.018277
[01:51:08.944] iteration 14029 : loss : 0.043701, loss_ce: 0.019911
[01:51:09.249] iteration 14030 : loss : 0.052077, loss_ce: 0.022599
[01:51:09.555] iteration 14031 : loss : 0.055150, loss_ce: 0.022779
[01:51:09.865] iteration 14032 : loss : 0.105418, loss_ce: 0.009609
[01:51:10.176] iteration 14033 : loss : 0.113634, loss_ce: 0.023426
[01:51:10.488] iteration 14034 : loss : 0.058414, loss_ce: 0.009649
[01:51:10.793] iteration 14035 : loss : 0.063439, loss_ce: 0.022050
[01:51:11.098] iteration 14036 : loss : 0.052461, loss_ce: 0.015818
[01:51:11.407] iteration 14037 : loss : 0.057453, loss_ce: 0.019388
[01:51:11.707] iteration 14038 : loss : 0.056670, loss_ce: 0.014043
[01:51:11.786] iteration 14039 : loss : 0.387191, loss_ce: 0.000324
[01:51:30.436] iteration 14040 : loss : 0.059678, loss_ce: 0.014472
[01:51:30.761] iteration 14041 : loss : 0.048624, loss_ce: 0.021216
[01:51:31.063] iteration 14042 : loss : 0.059786, loss_ce: 0.020878
[01:51:31.363] iteration 14043 : loss : 0.047513, loss_ce: 0.017862
[01:51:31.666] iteration 14044 : loss : 0.063364, loss_ce: 0.030910
[01:51:31.962] iteration 14045 : loss : 0.067000, loss_ce: 0.027100
[01:51:32.266] iteration 14046 : loss : 0.071842, loss_ce: 0.014038
[01:51:32.565] iteration 14047 : loss : 0.106182, loss_ce: 0.020956
[01:51:32.863] iteration 14048 : loss : 0.057603, loss_ce: 0.026506
[01:51:33.165] iteration 14049 : loss : 0.045688, loss_ce: 0.018239
[01:51:33.467] iteration 14050 : loss : 0.061359, loss_ce: 0.012139
[01:51:33.763] iteration 14051 : loss : 0.055120, loss_ce: 0.014549
[01:51:34.066] iteration 14052 : loss : 0.087382, loss_ce: 0.019862
[01:51:34.364] iteration 14053 : loss : 0.058398, loss_ce: 0.021558
[01:51:34.662] iteration 14054 : loss : 0.047867, loss_ce: 0.019000
[01:51:34.955] iteration 14055 : loss : 0.061357, loss_ce: 0.020847
[01:51:35.255] iteration 14056 : loss : 0.042570, loss_ce: 0.016872
[01:51:35.553] iteration 14057 : loss : 0.173000, loss_ce: 0.010249
[01:51:35.847] iteration 14058 : loss : 0.057547, loss_ce: 0.011927
[01:51:36.143] iteration 14059 : loss : 0.059322, loss_ce: 0.014274
[01:51:36.450] iteration 14060 : loss : 0.059339, loss_ce: 0.012260
[01:51:36.763] iteration 14061 : loss : 0.276589, loss_ce: 0.002601
[01:51:37.062] iteration 14062 : loss : 0.038331, loss_ce: 0.016445
[01:51:37.359] iteration 14063 : loss : 0.045561, loss_ce: 0.013293
[01:51:37.656] iteration 14064 : loss : 0.059398, loss_ce: 0.015180
[01:51:37.956] iteration 14065 : loss : 0.045367, loss_ce: 0.020053
[01:51:38.256] iteration 14066 : loss : 0.109396, loss_ce: 0.018078
[01:51:38.553] iteration 14067 : loss : 0.053143, loss_ce: 0.024346
[01:51:38.857] iteration 14068 : loss : 0.054403, loss_ce: 0.010717
[01:51:39.154] iteration 14069 : loss : 0.041729, loss_ce: 0.011904
[01:51:39.458] iteration 14070 : loss : 0.052585, loss_ce: 0.019183
[01:51:39.754] iteration 14071 : loss : 0.061812, loss_ce: 0.022550
[01:51:40.056] iteration 14072 : loss : 0.047401, loss_ce: 0.019306
[01:51:40.357] iteration 14073 : loss : 0.057118, loss_ce: 0.020859
[01:51:40.663] iteration 14074 : loss : 0.053659, loss_ce: 0.025593
[01:51:40.962] iteration 14075 : loss : 0.048134, loss_ce: 0.009536
[01:51:41.268] iteration 14076 : loss : 0.052116, loss_ce: 0.012072
[01:51:41.570] iteration 14077 : loss : 0.040369, loss_ce: 0.012595
[01:51:41.878] iteration 14078 : loss : 0.040931, loss_ce: 0.008372
[01:51:42.182] iteration 14079 : loss : 0.132939, loss_ce: 0.007686
[01:51:42.486] iteration 14080 : loss : 0.050906, loss_ce: 0.013680
[01:51:42.812] iteration 14081 : loss : 0.070869, loss_ce: 0.016873
[01:51:43.121] iteration 14082 : loss : 0.046193, loss_ce: 0.015755
[01:51:43.426] iteration 14083 : loss : 0.050901, loss_ce: 0.018726
[01:51:43.727] iteration 14084 : loss : 0.055126, loss_ce: 0.027290
[01:51:44.040] iteration 14085 : loss : 0.047507, loss_ce: 0.015623
[01:51:44.345] iteration 14086 : loss : 0.118147, loss_ce: 0.007776
[01:51:44.653] iteration 14087 : loss : 0.107476, loss_ce: 0.013020
[01:51:44.957] iteration 14088 : loss : 0.054591, loss_ce: 0.009195
[01:51:45.262] iteration 14089 : loss : 0.042570, loss_ce: 0.018857
[01:51:45.563] iteration 14090 : loss : 0.101212, loss_ce: 0.013543
[01:51:45.864] iteration 14091 : loss : 0.110550, loss_ce: 0.017758
[01:51:46.166] iteration 14092 : loss : 0.059183, loss_ce: 0.019670
[01:51:46.465] iteration 14093 : loss : 0.104098, loss_ce: 0.011807
[01:51:46.766] iteration 14094 : loss : 0.057349, loss_ce: 0.009961
[01:51:47.067] iteration 14095 : loss : 0.068225, loss_ce: 0.017079
[01:51:47.374] iteration 14096 : loss : 0.102223, loss_ce: 0.008822
[01:51:47.679] iteration 14097 : loss : 0.040523, loss_ce: 0.015053
[01:51:47.979] iteration 14098 : loss : 0.107085, loss_ce: 0.011162
[01:51:48.279] iteration 14099 : loss : 0.045512, loss_ce: 0.013331
[01:51:48.582] iteration 14100 : loss : 0.040362, loss_ce: 0.011435
[01:51:48.899] iteration 14101 : loss : 0.085460, loss_ce: 0.023118
[01:51:49.201] iteration 14102 : loss : 0.046126, loss_ce: 0.008800
[01:51:49.503] iteration 14103 : loss : 0.070877, loss_ce: 0.012736
[01:51:49.809] iteration 14104 : loss : 0.057366, loss_ce: 0.017638
[01:51:50.118] iteration 14105 : loss : 0.068696, loss_ce: 0.011799
[01:51:50.425] iteration 14106 : loss : 0.053620, loss_ce: 0.020006
[01:51:50.727] iteration 14107 : loss : 0.044136, loss_ce: 0.010729
[01:51:51.028] iteration 14108 : loss : 0.155849, loss_ce: 0.007011
[01:51:51.333] iteration 14109 : loss : 0.104694, loss_ce: 0.010606
[01:51:51.637] iteration 14110 : loss : 0.102507, loss_ce: 0.011675
[01:51:51.936] iteration 14111 : loss : 0.043932, loss_ce: 0.015174
[01:51:52.240] iteration 14112 : loss : 0.059346, loss_ce: 0.022204
[01:51:52.540] iteration 14113 : loss : 0.061167, loss_ce: 0.013421
[01:51:52.844] iteration 14114 : loss : 0.060451, loss_ce: 0.022630
[01:51:53.148] iteration 14115 : loss : 0.043880, loss_ce: 0.021512
[01:51:53.455] iteration 14116 : loss : 0.165755, loss_ce: 0.010081
[01:51:53.755] iteration 14117 : loss : 0.049732, loss_ce: 0.024204
[01:51:54.053] iteration 14118 : loss : 0.047065, loss_ce: 0.014052
[01:51:54.360] iteration 14119 : loss : 0.053164, loss_ce: 0.022760
[01:51:54.664] iteration 14120 : loss : 0.056898, loss_ce: 0.012897
[01:51:54.984] iteration 14121 : loss : 0.040148, loss_ce: 0.015911
[01:51:55.285] iteration 14122 : loss : 0.070880, loss_ce: 0.020065
[01:51:55.587] iteration 14123 : loss : 0.055632, loss_ce: 0.007506
[01:51:55.886] iteration 14124 : loss : 0.043701, loss_ce: 0.017819
[01:51:56.190] iteration 14125 : loss : 0.047211, loss_ce: 0.021203
[01:51:56.493] iteration 14126 : loss : 0.040766, loss_ce: 0.015759
[01:51:56.800] iteration 14127 : loss : 0.043793, loss_ce: 0.011475
[01:51:57.103] iteration 14128 : loss : 0.051423, loss_ce: 0.027053
[01:51:57.412] iteration 14129 : loss : 0.045116, loss_ce: 0.014839
[01:51:57.719] iteration 14130 : loss : 0.050083, loss_ce: 0.014586
[01:51:58.021] iteration 14131 : loss : 0.051251, loss_ce: 0.009516
[01:51:58.323] iteration 14132 : loss : 0.086228, loss_ce: 0.016997
[01:51:58.630] iteration 14133 : loss : 0.061576, loss_ce: 0.015666
[01:51:58.933] iteration 14134 : loss : 0.108398, loss_ce: 0.006937
[01:51:59.233] iteration 14135 : loss : 0.044293, loss_ce: 0.018131
[01:51:59.536] iteration 14136 : loss : 0.106324, loss_ce: 0.022292
[01:51:59.838] iteration 14137 : loss : 0.069324, loss_ce: 0.010575
[01:52:00.142] iteration 14138 : loss : 0.054053, loss_ce: 0.015371
[01:52:00.449] iteration 14139 : loss : 0.052471, loss_ce: 0.023020
[01:52:00.753] iteration 14140 : loss : 0.068048, loss_ce: 0.013751
[01:52:01.069] iteration 14141 : loss : 0.116188, loss_ce: 0.015057
[01:52:01.369] iteration 14142 : loss : 0.062645, loss_ce: 0.014743
[01:52:01.668] iteration 14143 : loss : 0.093204, loss_ce: 0.010326
[01:52:01.965] iteration 14144 : loss : 0.104220, loss_ce: 0.007064
[01:52:02.262] iteration 14145 : loss : 0.062380, loss_ce: 0.014711
[01:52:02.565] iteration 14146 : loss : 0.045086, loss_ce: 0.008469
[01:52:02.868] iteration 14147 : loss : 0.175472, loss_ce: 0.004988
[01:52:03.166] iteration 14148 : loss : 0.048255, loss_ce: 0.018213
[01:52:03.463] iteration 14149 : loss : 0.114062, loss_ce: 0.008231
[01:52:03.763] iteration 14150 : loss : 0.048406, loss_ce: 0.015848
[01:52:04.061] iteration 14151 : loss : 0.121490, loss_ce: 0.010672
[01:52:04.355] iteration 14152 : loss : 0.039763, loss_ce: 0.015235
[01:52:04.650] iteration 14153 : loss : 0.100685, loss_ce: 0.010176
[01:52:04.951] iteration 14154 : loss : 0.043086, loss_ce: 0.013692
[01:52:05.248] iteration 14155 : loss : 0.057138, loss_ce: 0.018354
[01:52:05.548] iteration 14156 : loss : 0.050904, loss_ce: 0.008221
[01:52:05.846] iteration 14157 : loss : 0.057842, loss_ce: 0.013502
[01:52:06.145] iteration 14158 : loss : 0.046384, loss_ce: 0.011861
[01:52:06.444] iteration 14159 : loss : 0.047141, loss_ce: 0.015216
[01:52:06.741] iteration 14160 : loss : 0.052586, loss_ce: 0.012160
[01:52:07.052] iteration 14161 : loss : 0.288261, loss_ce: 0.002557
[01:52:07.349] iteration 14162 : loss : 0.047444, loss_ce: 0.014402
[01:52:07.659] iteration 14163 : loss : 0.048712, loss_ce: 0.018068
[01:52:07.963] iteration 14164 : loss : 0.349758, loss_ce: 0.001975
[01:52:08.268] iteration 14165 : loss : 0.048253, loss_ce: 0.010519
[01:52:08.575] iteration 14166 : loss : 0.050023, loss_ce: 0.015630
[01:52:08.880] iteration 14167 : loss : 0.119332, loss_ce: 0.011616
[01:52:09.191] iteration 14168 : loss : 0.038584, loss_ce: 0.016608
[01:52:09.491] iteration 14169 : loss : 0.110263, loss_ce: 0.013453
[01:52:09.789] iteration 14170 : loss : 0.056378, loss_ce: 0.012492
[01:52:10.092] iteration 14171 : loss : 0.031448, loss_ce: 0.011409
[01:52:10.396] iteration 14172 : loss : 0.079504, loss_ce: 0.027347
[01:52:10.698] iteration 14173 : loss : 0.106124, loss_ce: 0.012781
[01:52:11.000] iteration 14174 : loss : 0.055640, loss_ce: 0.011403
[01:52:11.298] iteration 14175 : loss : 0.062986, loss_ce: 0.012020
[01:52:11.595] iteration 14176 : loss : 0.041385, loss_ce: 0.011141
[01:52:11.897] iteration 14177 : loss : 0.056090, loss_ce: 0.015513
[01:52:11.978] iteration 14178 : loss : 0.184853, loss_ce: 0.029264
[01:52:33.035] iteration 14179 : loss : 0.052977, loss_ce: 0.011852
[01:52:33.339] iteration 14180 : loss : 0.104790, loss_ce: 0.007630
[01:52:33.656] iteration 14181 : loss : 0.038408, loss_ce: 0.008917
[01:52:33.963] iteration 14182 : loss : 0.041663, loss_ce: 0.012294
[01:52:34.263] iteration 14183 : loss : 0.046023, loss_ce: 0.015640
[01:52:34.563] iteration 14184 : loss : 0.069964, loss_ce: 0.011339
[01:52:34.866] iteration 14185 : loss : 0.064500, loss_ce: 0.012894
[01:52:35.171] iteration 14186 : loss : 0.038383, loss_ce: 0.011646
[01:52:35.471] iteration 14187 : loss : 0.059730, loss_ce: 0.024650
[01:52:35.774] iteration 14188 : loss : 0.127016, loss_ce: 0.007548
[01:52:36.072] iteration 14189 : loss : 0.043284, loss_ce: 0.021665
[01:52:36.373] iteration 14190 : loss : 0.049525, loss_ce: 0.021303
[01:52:36.670] iteration 14191 : loss : 0.045044, loss_ce: 0.015875
[01:52:36.974] iteration 14192 : loss : 0.054534, loss_ce: 0.015623
[01:52:37.280] iteration 14193 : loss : 0.048057, loss_ce: 0.014645
[01:52:37.580] iteration 14194 : loss : 0.053222, loss_ce: 0.012949
[01:52:37.889] iteration 14195 : loss : 0.047483, loss_ce: 0.013213
[01:52:38.191] iteration 14196 : loss : 0.109729, loss_ce: 0.011324
[01:52:38.490] iteration 14197 : loss : 0.062940, loss_ce: 0.024424
[01:52:38.796] iteration 14198 : loss : 0.059203, loss_ce: 0.023422
[01:52:39.095] iteration 14199 : loss : 0.065865, loss_ce: 0.013409
[01:52:39.398] iteration 14200 : loss : 0.057443, loss_ce: 0.017185
[01:52:39.718] iteration 14201 : loss : 0.102137, loss_ce: 0.010940
[01:52:40.019] iteration 14202 : loss : 0.049778, loss_ce: 0.015774
[01:52:40.323] iteration 14203 : loss : 0.283655, loss_ce: 0.013171
[01:52:40.623] iteration 14204 : loss : 0.042795, loss_ce: 0.014325
[01:52:40.922] iteration 14205 : loss : 0.129812, loss_ce: 0.006742
[01:52:41.223] iteration 14206 : loss : 0.061002, loss_ce: 0.011836
[01:52:41.520] iteration 14207 : loss : 0.099333, loss_ce: 0.012690
[01:52:41.821] iteration 14208 : loss : 0.047370, loss_ce: 0.027723
[01:52:42.125] iteration 14209 : loss : 0.060484, loss_ce: 0.010097
[01:52:42.433] iteration 14210 : loss : 0.046102, loss_ce: 0.016391
[01:52:42.732] iteration 14211 : loss : 0.105311, loss_ce: 0.009060
[01:52:43.037] iteration 14212 : loss : 0.045482, loss_ce: 0.022611
[01:52:43.341] iteration 14213 : loss : 0.057698, loss_ce: 0.013581
[01:52:43.641] iteration 14214 : loss : 0.057158, loss_ce: 0.015611
[01:52:43.945] iteration 14215 : loss : 0.048569, loss_ce: 0.012061
[01:52:44.246] iteration 14216 : loss : 0.056782, loss_ce: 0.011838
[01:52:44.552] iteration 14217 : loss : 0.045421, loss_ce: 0.014122
[01:52:44.854] iteration 14218 : loss : 0.045551, loss_ce: 0.016511
[01:52:45.158] iteration 14219 : loss : 0.041929, loss_ce: 0.012284
[01:52:45.459] iteration 14220 : loss : 0.045838, loss_ce: 0.012923
[01:52:45.784] iteration 14221 : loss : 0.056388, loss_ce: 0.011694
[01:52:46.083] iteration 14222 : loss : 0.167354, loss_ce: 0.010794
[01:52:46.383] iteration 14223 : loss : 0.050999, loss_ce: 0.007769
[01:52:46.688] iteration 14224 : loss : 0.079443, loss_ce: 0.019050
[01:52:46.989] iteration 14225 : loss : 0.049769, loss_ce: 0.015748
[01:52:47.287] iteration 14226 : loss : 0.048275, loss_ce: 0.019165
[01:52:47.590] iteration 14227 : loss : 0.118000, loss_ce: 0.014864
[01:52:47.895] iteration 14228 : loss : 0.042501, loss_ce: 0.018424
[01:52:48.197] iteration 14229 : loss : 0.054331, loss_ce: 0.021827
[01:52:48.496] iteration 14230 : loss : 0.053699, loss_ce: 0.011070
[01:52:48.800] iteration 14231 : loss : 0.048375, loss_ce: 0.017099
[01:52:49.107] iteration 14232 : loss : 0.057876, loss_ce: 0.026059
[01:52:49.412] iteration 14233 : loss : 0.046922, loss_ce: 0.022134
[01:52:49.716] iteration 14234 : loss : 0.051392, loss_ce: 0.014130
[01:52:50.019] iteration 14235 : loss : 0.041863, loss_ce: 0.008305
[01:52:50.322] iteration 14236 : loss : 0.067001, loss_ce: 0.011752
[01:52:50.632] iteration 14237 : loss : 0.052026, loss_ce: 0.015626
[01:52:50.934] iteration 14238 : loss : 0.061883, loss_ce: 0.017855
[01:52:51.239] iteration 14239 : loss : 0.114336, loss_ce: 0.005554
[01:52:51.536] iteration 14240 : loss : 0.043671, loss_ce: 0.013084
[01:52:51.852] iteration 14241 : loss : 0.051152, loss_ce: 0.015302
[01:52:52.149] iteration 14242 : loss : 0.132481, loss_ce: 0.007259
[01:52:52.451] iteration 14243 : loss : 0.061903, loss_ce: 0.012927
[01:52:52.754] iteration 14244 : loss : 0.047027, loss_ce: 0.010699
[01:52:53.057] iteration 14245 : loss : 0.046183, loss_ce: 0.012261
[01:52:53.355] iteration 14246 : loss : 0.051189, loss_ce: 0.018013
[01:52:53.655] iteration 14247 : loss : 0.043159, loss_ce: 0.014557
[01:52:53.953] iteration 14248 : loss : 0.057155, loss_ce: 0.008188
[01:52:54.259] iteration 14249 : loss : 0.046190, loss_ce: 0.012857
[01:52:54.556] iteration 14250 : loss : 0.227876, loss_ce: 0.003238
[01:52:54.852] iteration 14251 : loss : 0.046373, loss_ce: 0.013778
[01:52:55.149] iteration 14252 : loss : 0.071858, loss_ce: 0.014950
[01:52:55.448] iteration 14253 : loss : 0.099794, loss_ce: 0.015006
[01:52:55.742] iteration 14254 : loss : 0.055159, loss_ce: 0.016456
[01:52:56.041] iteration 14255 : loss : 0.046563, loss_ce: 0.014952
[01:52:56.340] iteration 14256 : loss : 0.043041, loss_ce: 0.012088
[01:52:56.644] iteration 14257 : loss : 0.105676, loss_ce: 0.011587
[01:52:56.948] iteration 14258 : loss : 0.047141, loss_ce: 0.014594
[01:52:57.248] iteration 14259 : loss : 0.119292, loss_ce: 0.011011
[01:52:57.545] iteration 14260 : loss : 0.164579, loss_ce: 0.005406
[01:52:57.858] iteration 14261 : loss : 0.043307, loss_ce: 0.014363
[01:52:58.159] iteration 14262 : loss : 0.034924, loss_ce: 0.007994
[01:52:58.456] iteration 14263 : loss : 0.050653, loss_ce: 0.019560
[01:52:58.758] iteration 14264 : loss : 0.099355, loss_ce: 0.005073
[01:52:59.057] iteration 14265 : loss : 0.041437, loss_ce: 0.015522
[01:52:59.354] iteration 14266 : loss : 0.054296, loss_ce: 0.020733
[01:52:59.651] iteration 14267 : loss : 0.047821, loss_ce: 0.019414
[01:52:59.953] iteration 14268 : loss : 0.058545, loss_ce: 0.011993
[01:53:00.250] iteration 14269 : loss : 0.041054, loss_ce: 0.014845
[01:53:00.552] iteration 14270 : loss : 0.056015, loss_ce: 0.012631
[01:53:00.854] iteration 14271 : loss : 0.053105, loss_ce: 0.016848
[01:53:01.153] iteration 14272 : loss : 0.039069, loss_ce: 0.014894
[01:53:01.456] iteration 14273 : loss : 0.054422, loss_ce: 0.010598
[01:53:01.753] iteration 14274 : loss : 0.098791, loss_ce: 0.011133
[01:53:02.050] iteration 14275 : loss : 0.057602, loss_ce: 0.018249
[01:53:02.353] iteration 14276 : loss : 0.050229, loss_ce: 0.019912
[01:53:02.656] iteration 14277 : loss : 0.058547, loss_ce: 0.024635
[01:53:02.953] iteration 14278 : loss : 0.042882, loss_ce: 0.018004
[01:53:03.248] iteration 14279 : loss : 0.046070, loss_ce: 0.013661
[01:53:03.547] iteration 14280 : loss : 0.045799, loss_ce: 0.010752
[01:53:03.862] iteration 14281 : loss : 0.050842, loss_ce: 0.016075
[01:53:04.160] iteration 14282 : loss : 0.058595, loss_ce: 0.008432
[01:53:04.463] iteration 14283 : loss : 0.058134, loss_ce: 0.011626
[01:53:04.770] iteration 14284 : loss : 0.056068, loss_ce: 0.014166
[01:53:05.074] iteration 14285 : loss : 0.050508, loss_ce: 0.014890
[01:53:05.378] iteration 14286 : loss : 0.048673, loss_ce: 0.012050
[01:53:05.680] iteration 14287 : loss : 0.045664, loss_ce: 0.010539
[01:53:05.984] iteration 14288 : loss : 0.048300, loss_ce: 0.016479
[01:53:06.284] iteration 14289 : loss : 0.052487, loss_ce: 0.007450
[01:53:06.581] iteration 14290 : loss : 0.043632, loss_ce: 0.007726
[01:53:06.880] iteration 14291 : loss : 0.110067, loss_ce: 0.019660
[01:53:07.180] iteration 14292 : loss : 0.050773, loss_ce: 0.014453
[01:53:07.479] iteration 14293 : loss : 0.044458, loss_ce: 0.019843
[01:53:07.777] iteration 14294 : loss : 0.113809, loss_ce: 0.012532
[01:53:08.073] iteration 14295 : loss : 0.041197, loss_ce: 0.021445
[01:53:08.374] iteration 14296 : loss : 0.055692, loss_ce: 0.012079
[01:53:08.672] iteration 14297 : loss : 0.066845, loss_ce: 0.016589
[01:53:08.971] iteration 14298 : loss : 0.057467, loss_ce: 0.018729
[01:53:09.270] iteration 14299 : loss : 0.039018, loss_ce: 0.011113
[01:53:09.564] iteration 14300 : loss : 0.102216, loss_ce: 0.007411
[01:53:09.886] iteration 14301 : loss : 0.043098, loss_ce: 0.012826
[01:53:10.196] iteration 14302 : loss : 0.042334, loss_ce: 0.016065
[01:53:10.503] iteration 14303 : loss : 0.100307, loss_ce: 0.007277
[01:53:10.804] iteration 14304 : loss : 0.045265, loss_ce: 0.015237
[01:53:11.106] iteration 14305 : loss : 0.051111, loss_ce: 0.011816
[01:53:11.411] iteration 14306 : loss : 0.046812, loss_ce: 0.019879
[01:53:11.709] iteration 14307 : loss : 0.056033, loss_ce: 0.016447
[01:53:12.013] iteration 14308 : loss : 0.042671, loss_ce: 0.004340
[01:53:12.317] iteration 14309 : loss : 0.051942, loss_ce: 0.020989
[01:53:12.617] iteration 14310 : loss : 0.105315, loss_ce: 0.010831
[01:53:12.918] iteration 14311 : loss : 0.056737, loss_ce: 0.011602
[01:53:13.217] iteration 14312 : loss : 0.046996, loss_ce: 0.013209
[01:53:13.517] iteration 14313 : loss : 0.043799, loss_ce: 0.015038
[01:53:13.817] iteration 14314 : loss : 0.062018, loss_ce: 0.014968
[01:53:14.117] iteration 14315 : loss : 0.058981, loss_ce: 0.021218
[01:53:14.423] iteration 14316 : loss : 0.040372, loss_ce: 0.009378
[01:53:14.515] iteration 14317 : loss : 0.120846, loss_ce: 0.014469
[01:53:32.414] iteration 14318 : loss : 0.053509, loss_ce: 0.007998
[01:53:32.720] iteration 14319 : loss : 0.052791, loss_ce: 0.012071
[01:53:33.023] iteration 14320 : loss : 0.045570, loss_ce: 0.007644
[01:53:33.351] iteration 14321 : loss : 0.041921, loss_ce: 0.015798
[01:53:33.654] iteration 14322 : loss : 0.047179, loss_ce: 0.016655
[01:53:33.958] iteration 14323 : loss : 0.056473, loss_ce: 0.013226
[01:53:34.259] iteration 14324 : loss : 0.046869, loss_ce: 0.015931
[01:53:34.564] iteration 14325 : loss : 0.051352, loss_ce: 0.007898
[01:53:34.866] iteration 14326 : loss : 0.044278, loss_ce: 0.016761
[01:53:35.168] iteration 14327 : loss : 0.040873, loss_ce: 0.017599
[01:53:35.470] iteration 14328 : loss : 0.051299, loss_ce: 0.018697
[01:53:35.768] iteration 14329 : loss : 0.042770, loss_ce: 0.007520
[01:53:36.066] iteration 14330 : loss : 0.080306, loss_ce: 0.016355
[01:53:36.369] iteration 14331 : loss : 0.065982, loss_ce: 0.023463
[01:53:36.668] iteration 14332 : loss : 0.063053, loss_ce: 0.019494
[01:53:36.969] iteration 14333 : loss : 0.045986, loss_ce: 0.024775
[01:53:37.275] iteration 14334 : loss : 0.050196, loss_ce: 0.018659
[01:53:37.574] iteration 14335 : loss : 0.050433, loss_ce: 0.010538
[01:53:37.874] iteration 14336 : loss : 0.055064, loss_ce: 0.016471
[01:53:38.175] iteration 14337 : loss : 0.045115, loss_ce: 0.014223
[01:53:38.474] iteration 14338 : loss : 0.046683, loss_ce: 0.020291
[01:53:38.779] iteration 14339 : loss : 0.054762, loss_ce: 0.015014
[01:53:39.083] iteration 14340 : loss : 0.038426, loss_ce: 0.008309
[01:53:39.403] iteration 14341 : loss : 0.045350, loss_ce: 0.014438
[01:53:39.706] iteration 14342 : loss : 0.051304, loss_ce: 0.011227
[01:53:40.010] iteration 14343 : loss : 0.112240, loss_ce: 0.010622
[01:53:40.309] iteration 14344 : loss : 0.253594, loss_ce: 0.002301
[01:53:40.606] iteration 14345 : loss : 0.050063, loss_ce: 0.021227
[01:53:40.907] iteration 14346 : loss : 0.098257, loss_ce: 0.007711
[01:53:41.204] iteration 14347 : loss : 0.053595, loss_ce: 0.017385
[01:53:41.499] iteration 14348 : loss : 0.046797, loss_ce: 0.008506
[01:53:41.794] iteration 14349 : loss : 0.060309, loss_ce: 0.015869
[01:53:42.090] iteration 14350 : loss : 0.057594, loss_ce: 0.021201
[01:53:42.385] iteration 14351 : loss : 0.046765, loss_ce: 0.012520
[01:53:42.677] iteration 14352 : loss : 0.058862, loss_ce: 0.014656
[01:53:42.975] iteration 14353 : loss : 0.046348, loss_ce: 0.010792
[01:53:43.270] iteration 14354 : loss : 0.026730, loss_ce: 0.006183
[01:53:43.572] iteration 14355 : loss : 0.072021, loss_ce: 0.012146
[01:53:43.875] iteration 14356 : loss : 0.040811, loss_ce: 0.012511
[01:53:44.171] iteration 14357 : loss : 0.059289, loss_ce: 0.014763
[01:53:44.468] iteration 14358 : loss : 0.047010, loss_ce: 0.021809
[01:53:44.763] iteration 14359 : loss : 0.038035, loss_ce: 0.012248
[01:53:45.057] iteration 14360 : loss : 0.049628, loss_ce: 0.022094
[01:53:45.365] iteration 14361 : loss : 0.050331, loss_ce: 0.007933
[01:53:45.664] iteration 14362 : loss : 0.098852, loss_ce: 0.006344
[01:53:45.960] iteration 14363 : loss : 0.052388, loss_ce: 0.011458
[01:53:46.259] iteration 14364 : loss : 0.052015, loss_ce: 0.013179
[01:53:46.557] iteration 14365 : loss : 0.104726, loss_ce: 0.017500
[01:53:46.857] iteration 14366 : loss : 0.038550, loss_ce: 0.010481
[01:53:47.152] iteration 14367 : loss : 0.049873, loss_ce: 0.010955
[01:53:47.456] iteration 14368 : loss : 0.064206, loss_ce: 0.012297
[01:53:47.758] iteration 14369 : loss : 0.044016, loss_ce: 0.014567
[01:53:48.059] iteration 14370 : loss : 0.224678, loss_ce: 0.007703
[01:53:48.361] iteration 14371 : loss : 0.058451, loss_ce: 0.023443
[01:53:48.658] iteration 14372 : loss : 0.066039, loss_ce: 0.014705
[01:53:48.960] iteration 14373 : loss : 0.047326, loss_ce: 0.014833
[01:53:49.260] iteration 14374 : loss : 0.107903, loss_ce: 0.010394
[01:53:49.556] iteration 14375 : loss : 0.048128, loss_ce: 0.007956
[01:53:49.857] iteration 14376 : loss : 0.043206, loss_ce: 0.011021
[01:53:50.158] iteration 14377 : loss : 0.048365, loss_ce: 0.016344
[01:53:50.459] iteration 14378 : loss : 0.102478, loss_ce: 0.014125
[01:53:50.760] iteration 14379 : loss : 0.057301, loss_ce: 0.012397
[01:53:51.060] iteration 14380 : loss : 0.053480, loss_ce: 0.021359
[01:53:51.376] iteration 14381 : loss : 0.050463, loss_ce: 0.017724
[01:53:51.670] iteration 14382 : loss : 0.053123, loss_ce: 0.022860
[01:53:51.974] iteration 14383 : loss : 0.066967, loss_ce: 0.021729
[01:53:52.276] iteration 14384 : loss : 0.055800, loss_ce: 0.009886
[01:53:52.574] iteration 14385 : loss : 0.047502, loss_ce: 0.010622
[01:53:52.871] iteration 14386 : loss : 0.043729, loss_ce: 0.017693
[01:53:53.171] iteration 14387 : loss : 0.056802, loss_ce: 0.018354
[01:53:53.469] iteration 14388 : loss : 0.052224, loss_ce: 0.011140
[01:53:53.767] iteration 14389 : loss : 0.040730, loss_ce: 0.008917
[01:53:54.064] iteration 14390 : loss : 0.056763, loss_ce: 0.014184
[01:53:54.374] iteration 14391 : loss : 0.122766, loss_ce: 0.016463
[01:53:54.677] iteration 14392 : loss : 0.046969, loss_ce: 0.011119
[01:53:54.984] iteration 14393 : loss : 0.034629, loss_ce: 0.007966
[01:53:55.295] iteration 14394 : loss : 0.041970, loss_ce: 0.011894
[01:53:55.598] iteration 14395 : loss : 0.039467, loss_ce: 0.016042
[01:53:55.905] iteration 14396 : loss : 0.108041, loss_ce: 0.017869
[01:53:56.214] iteration 14397 : loss : 0.067871, loss_ce: 0.023019
[01:53:56.507] iteration 14398 : loss : 0.063887, loss_ce: 0.013577
[01:53:56.810] iteration 14399 : loss : 0.061332, loss_ce: 0.010731
[01:53:57.107] iteration 14400 : loss : 0.044216, loss_ce: 0.011510
[01:53:57.424] iteration 14401 : loss : 0.112892, loss_ce: 0.011113
[01:53:57.718] iteration 14402 : loss : 0.050578, loss_ce: 0.015594
[01:53:58.015] iteration 14403 : loss : 0.050058, loss_ce: 0.014083
[01:53:58.318] iteration 14404 : loss : 0.057052, loss_ce: 0.017725
[01:53:58.616] iteration 14405 : loss : 0.035940, loss_ce: 0.011938
[01:53:58.914] iteration 14406 : loss : 0.045382, loss_ce: 0.009477
[01:53:59.215] iteration 14407 : loss : 0.054451, loss_ce: 0.013225
[01:53:59.516] iteration 14408 : loss : 0.044057, loss_ce: 0.011157
[01:53:59.813] iteration 14409 : loss : 0.078827, loss_ce: 0.012667
[01:54:00.118] iteration 14410 : loss : 0.061199, loss_ce: 0.023897
[01:54:00.413] iteration 14411 : loss : 0.040760, loss_ce: 0.013778
[01:54:00.712] iteration 14412 : loss : 0.048144, loss_ce: 0.023677
[01:54:01.009] iteration 14413 : loss : 0.052309, loss_ce: 0.012970
[01:54:01.308] iteration 14414 : loss : 0.049162, loss_ce: 0.018361
[01:54:01.603] iteration 14415 : loss : 0.103941, loss_ce: 0.014215
[01:54:01.898] iteration 14416 : loss : 0.045675, loss_ce: 0.009507
[01:54:02.201] iteration 14417 : loss : 0.044697, loss_ce: 0.024268
[01:54:02.499] iteration 14418 : loss : 0.070307, loss_ce: 0.027092
[01:54:02.796] iteration 14419 : loss : 0.046937, loss_ce: 0.008532
[01:54:03.095] iteration 14420 : loss : 0.035063, loss_ce: 0.010005
[01:54:03.411] iteration 14421 : loss : 0.048605, loss_ce: 0.022647
[01:54:03.709] iteration 14422 : loss : 0.056195, loss_ce: 0.016184
[01:54:04.009] iteration 14423 : loss : 0.116150, loss_ce: 0.012099
[01:54:04.309] iteration 14424 : loss : 0.044442, loss_ce: 0.016432
[01:54:04.604] iteration 14425 : loss : 0.107190, loss_ce: 0.012053
[01:54:04.905] iteration 14426 : loss : 0.103644, loss_ce: 0.007425
[01:54:05.203] iteration 14427 : loss : 0.108030, loss_ce: 0.007804
[01:54:05.505] iteration 14428 : loss : 0.049998, loss_ce: 0.011642
[01:54:05.797] iteration 14429 : loss : 0.250177, loss_ce: 0.003163
[01:54:06.098] iteration 14430 : loss : 0.055920, loss_ce: 0.015770
[01:54:06.397] iteration 14431 : loss : 0.038793, loss_ce: 0.009303
[01:54:06.692] iteration 14432 : loss : 0.039942, loss_ce: 0.012157
[01:54:06.986] iteration 14433 : loss : 0.052567, loss_ce: 0.013068
[01:54:07.287] iteration 14434 : loss : 0.052252, loss_ce: 0.013597
[01:54:07.586] iteration 14435 : loss : 0.045209, loss_ce: 0.020492
[01:54:07.885] iteration 14436 : loss : 0.043573, loss_ce: 0.013647
[01:54:08.181] iteration 14437 : loss : 0.049852, loss_ce: 0.018102
[01:54:08.478] iteration 14438 : loss : 0.046274, loss_ce: 0.022498
[01:54:08.774] iteration 14439 : loss : 0.056732, loss_ce: 0.017992
[01:54:09.075] iteration 14440 : loss : 0.044652, loss_ce: 0.017897
[01:54:09.401] iteration 14441 : loss : 0.156461, loss_ce: 0.008150
[01:54:09.703] iteration 14442 : loss : 0.044833, loss_ce: 0.016560
[01:54:10.007] iteration 14443 : loss : 0.054358, loss_ce: 0.016755
[01:54:10.313] iteration 14444 : loss : 0.039307, loss_ce: 0.008477
[01:54:10.610] iteration 14445 : loss : 0.106926, loss_ce: 0.014587
[01:54:10.917] iteration 14446 : loss : 0.222870, loss_ce: 0.003398
[01:54:11.223] iteration 14447 : loss : 0.104721, loss_ce: 0.015769
[01:54:11.527] iteration 14448 : loss : 0.114494, loss_ce: 0.011028
[01:54:11.843] iteration 14449 : loss : 0.055834, loss_ce: 0.022927
[01:54:12.152] iteration 14450 : loss : 0.041948, loss_ce: 0.012492
[01:54:12.462] iteration 14451 : loss : 0.052342, loss_ce: 0.012415
[01:54:12.774] iteration 14452 : loss : 0.080395, loss_ce: 0.018168
[01:54:13.081] iteration 14453 : loss : 0.071672, loss_ce: 0.017749
[01:54:13.385] iteration 14454 : loss : 0.047798, loss_ce: 0.008040
[01:54:13.689] iteration 14455 : loss : 0.045821, loss_ce: 0.015137
[01:54:13.770] iteration 14456 : loss : 0.221121, loss_ce: 0.004906
[01:54:32.249] iteration 14457 : loss : 0.283077, loss_ce: 0.005699
[01:54:32.550] iteration 14458 : loss : 0.100080, loss_ce: 0.010157
[01:54:32.848] iteration 14459 : loss : 0.078001, loss_ce: 0.019970
[01:54:33.145] iteration 14460 : loss : 0.122434, loss_ce: 0.014776
[01:54:33.464] iteration 14461 : loss : 0.049581, loss_ce: 0.015425
[01:54:33.762] iteration 14462 : loss : 0.040949, loss_ce: 0.015585
[01:54:34.061] iteration 14463 : loss : 0.052994, loss_ce: 0.023379
[01:54:34.358] iteration 14464 : loss : 0.053829, loss_ce: 0.016535
[01:54:34.653] iteration 14465 : loss : 0.102650, loss_ce: 0.012959
[01:54:34.951] iteration 14466 : loss : 0.050347, loss_ce: 0.020207
[01:54:35.247] iteration 14467 : loss : 0.115732, loss_ce: 0.016990
[01:54:35.545] iteration 14468 : loss : 0.042226, loss_ce: 0.012658
[01:54:35.843] iteration 14469 : loss : 0.056870, loss_ce: 0.029656
[01:54:36.139] iteration 14470 : loss : 0.060349, loss_ce: 0.010925
[01:54:36.433] iteration 14471 : loss : 0.046507, loss_ce: 0.013744
[01:54:36.732] iteration 14472 : loss : 0.156154, loss_ce: 0.009447
[01:54:37.030] iteration 14473 : loss : 0.048129, loss_ce: 0.016043
[01:54:37.330] iteration 14474 : loss : 0.099053, loss_ce: 0.010343
[01:54:37.629] iteration 14475 : loss : 0.043435, loss_ce: 0.011831
[01:54:37.931] iteration 14476 : loss : 0.047188, loss_ce: 0.018719
[01:54:38.229] iteration 14477 : loss : 0.054023, loss_ce: 0.010142
[01:54:38.524] iteration 14478 : loss : 0.056463, loss_ce: 0.015548
[01:54:38.821] iteration 14479 : loss : 0.103644, loss_ce: 0.002746
[01:54:39.119] iteration 14480 : loss : 0.053102, loss_ce: 0.010266
[01:54:39.437] iteration 14481 : loss : 0.040963, loss_ce: 0.009523
[01:54:39.733] iteration 14482 : loss : 0.099380, loss_ce: 0.007528
[01:54:40.030] iteration 14483 : loss : 0.048356, loss_ce: 0.014141
[01:54:40.327] iteration 14484 : loss : 0.048682, loss_ce: 0.018211
[01:54:40.622] iteration 14485 : loss : 0.044705, loss_ce: 0.010038
[01:54:40.920] iteration 14486 : loss : 0.042712, loss_ce: 0.010642
[01:54:41.215] iteration 14487 : loss : 0.042562, loss_ce: 0.012149
[01:54:41.510] iteration 14488 : loss : 0.050361, loss_ce: 0.016388
[01:54:41.806] iteration 14489 : loss : 0.044418, loss_ce: 0.013015
[01:54:42.102] iteration 14490 : loss : 0.039638, loss_ce: 0.014159
[01:54:42.399] iteration 14491 : loss : 0.048533, loss_ce: 0.013039
[01:54:42.693] iteration 14492 : loss : 0.047850, loss_ce: 0.019813
[01:54:42.990] iteration 14493 : loss : 0.079380, loss_ce: 0.005626
[01:54:43.289] iteration 14494 : loss : 0.048320, loss_ce: 0.011574
[01:54:43.594] iteration 14495 : loss : 0.046381, loss_ce: 0.012426
[01:54:43.890] iteration 14496 : loss : 0.035568, loss_ce: 0.009904
[01:54:44.191] iteration 14497 : loss : 0.055125, loss_ce: 0.017476
[01:54:44.497] iteration 14498 : loss : 0.038052, loss_ce: 0.009753
[01:54:44.806] iteration 14499 : loss : 0.090859, loss_ce: 0.014643
[01:54:45.112] iteration 14500 : loss : 0.054348, loss_ce: 0.017515
[01:54:45.427] iteration 14501 : loss : 0.161112, loss_ce: 0.011699
[01:54:45.729] iteration 14502 : loss : 0.047712, loss_ce: 0.016171
[01:54:46.030] iteration 14503 : loss : 0.050034, loss_ce: 0.010142
[01:54:46.330] iteration 14504 : loss : 0.052949, loss_ce: 0.014576
[01:54:46.628] iteration 14505 : loss : 0.048427, loss_ce: 0.015836
[01:54:46.925] iteration 14506 : loss : 0.054484, loss_ce: 0.010192
[01:54:47.222] iteration 14507 : loss : 0.060844, loss_ce: 0.025453
[01:54:47.521] iteration 14508 : loss : 0.046353, loss_ce: 0.008643
[01:54:47.822] iteration 14509 : loss : 0.087551, loss_ce: 0.006336
[01:54:48.122] iteration 14510 : loss : 0.031426, loss_ce: 0.008273
[01:54:48.421] iteration 14511 : loss : 0.054141, loss_ce: 0.019011
[01:54:48.716] iteration 14512 : loss : 0.052532, loss_ce: 0.018225
[01:54:49.015] iteration 14513 : loss : 0.071453, loss_ce: 0.023357
[01:54:49.314] iteration 14514 : loss : 0.048645, loss_ce: 0.010425
[01:54:49.617] iteration 14515 : loss : 0.053405, loss_ce: 0.016298
[01:54:49.914] iteration 14516 : loss : 0.061036, loss_ce: 0.020546
[01:54:50.218] iteration 14517 : loss : 0.055210, loss_ce: 0.016990
[01:54:50.515] iteration 14518 : loss : 0.035902, loss_ce: 0.010564
[01:54:50.813] iteration 14519 : loss : 0.049350, loss_ce: 0.024566
[01:54:51.112] iteration 14520 : loss : 0.068496, loss_ce: 0.009954
[01:54:51.427] iteration 14521 : loss : 0.045470, loss_ce: 0.012751
[01:54:51.728] iteration 14522 : loss : 0.051435, loss_ce: 0.017949
[01:54:52.027] iteration 14523 : loss : 0.037740, loss_ce: 0.011040
[01:54:52.328] iteration 14524 : loss : 0.057191, loss_ce: 0.021708
[01:54:52.628] iteration 14525 : loss : 0.104596, loss_ce: 0.015612
[01:54:52.924] iteration 14526 : loss : 0.048832, loss_ce: 0.014592
[01:54:53.222] iteration 14527 : loss : 0.045502, loss_ce: 0.015648
[01:54:53.516] iteration 14528 : loss : 0.049561, loss_ce: 0.011725
[01:54:53.816] iteration 14529 : loss : 0.050628, loss_ce: 0.014148
[01:54:54.115] iteration 14530 : loss : 0.037053, loss_ce: 0.012828
[01:54:54.416] iteration 14531 : loss : 0.161973, loss_ce: 0.009874
[01:54:54.717] iteration 14532 : loss : 0.043814, loss_ce: 0.018862
[01:54:55.019] iteration 14533 : loss : 0.051714, loss_ce: 0.016531
[01:54:55.317] iteration 14534 : loss : 0.046766, loss_ce: 0.006516
[01:54:55.619] iteration 14535 : loss : 0.070517, loss_ce: 0.016727
[01:54:55.918] iteration 14536 : loss : 0.113636, loss_ce: 0.016025
[01:54:56.218] iteration 14537 : loss : 0.045037, loss_ce: 0.018011
[01:54:56.511] iteration 14538 : loss : 0.078285, loss_ce: 0.013999
[01:54:56.809] iteration 14539 : loss : 0.230443, loss_ce: 0.004861
[01:54:57.105] iteration 14540 : loss : 0.041128, loss_ce: 0.014425
[01:54:57.421] iteration 14541 : loss : 0.066293, loss_ce: 0.017969
[01:54:57.724] iteration 14542 : loss : 0.044190, loss_ce: 0.014100
[01:54:58.022] iteration 14543 : loss : 0.109279, loss_ce: 0.014989
[01:54:58.317] iteration 14544 : loss : 0.055051, loss_ce: 0.013203
[01:54:58.615] iteration 14545 : loss : 0.052218, loss_ce: 0.015815
[01:54:58.915] iteration 14546 : loss : 0.076528, loss_ce: 0.013099
[01:54:59.218] iteration 14547 : loss : 0.155519, loss_ce: 0.008163
[01:54:59.520] iteration 14548 : loss : 0.052902, loss_ce: 0.020750
[01:54:59.825] iteration 14549 : loss : 0.050450, loss_ce: 0.017464
[01:55:00.126] iteration 14550 : loss : 0.045321, loss_ce: 0.018257
[01:55:00.431] iteration 14551 : loss : 0.056287, loss_ce: 0.014056
[01:55:00.734] iteration 14552 : loss : 0.041380, loss_ce: 0.015996
[01:55:01.042] iteration 14553 : loss : 0.046083, loss_ce: 0.016850
[01:55:01.343] iteration 14554 : loss : 0.048998, loss_ce: 0.015810
[01:55:01.637] iteration 14555 : loss : 0.061628, loss_ce: 0.012819
[01:55:01.938] iteration 14556 : loss : 0.038039, loss_ce: 0.014843
[01:55:02.238] iteration 14557 : loss : 0.051718, loss_ce: 0.014053
[01:55:02.538] iteration 14558 : loss : 0.061886, loss_ce: 0.010905
[01:55:02.837] iteration 14559 : loss : 0.041519, loss_ce: 0.017760
[01:55:03.135] iteration 14560 : loss : 0.059615, loss_ce: 0.008386
[01:55:03.450] iteration 14561 : loss : 0.227545, loss_ce: 0.008435
[01:55:03.753] iteration 14562 : loss : 0.049234, loss_ce: 0.014180
[01:55:04.051] iteration 14563 : loss : 0.040056, loss_ce: 0.011022
[01:55:04.348] iteration 14564 : loss : 0.063567, loss_ce: 0.017298
[01:55:04.648] iteration 14565 : loss : 0.076142, loss_ce: 0.025296
[01:55:04.951] iteration 14566 : loss : 0.045263, loss_ce: 0.005998
[01:55:05.256] iteration 14567 : loss : 0.045838, loss_ce: 0.016890
[01:55:05.551] iteration 14568 : loss : 0.114071, loss_ce: 0.007141
[01:55:05.856] iteration 14569 : loss : 0.152654, loss_ce: 0.006816
[01:55:06.154] iteration 14570 : loss : 0.100919, loss_ce: 0.015889
[01:55:06.453] iteration 14571 : loss : 0.042362, loss_ce: 0.010102
[01:55:06.748] iteration 14572 : loss : 0.054044, loss_ce: 0.023807
[01:55:07.051] iteration 14573 : loss : 0.054355, loss_ce: 0.021615
[01:55:07.347] iteration 14574 : loss : 0.050655, loss_ce: 0.016590
[01:55:07.645] iteration 14575 : loss : 0.051608, loss_ce: 0.021353
[01:55:07.945] iteration 14576 : loss : 0.055095, loss_ce: 0.021123
[01:55:08.244] iteration 14577 : loss : 0.042370, loss_ce: 0.017821
[01:55:08.541] iteration 14578 : loss : 0.108022, loss_ce: 0.009929
[01:55:08.841] iteration 14579 : loss : 0.061513, loss_ce: 0.011161
[01:55:09.140] iteration 14580 : loss : 0.054074, loss_ce: 0.019985
[01:55:09.466] iteration 14581 : loss : 0.053158, loss_ce: 0.014615
[01:55:09.762] iteration 14582 : loss : 0.044900, loss_ce: 0.018522
[01:55:10.063] iteration 14583 : loss : 0.123349, loss_ce: 0.006133
[01:55:10.370] iteration 14584 : loss : 0.061205, loss_ce: 0.012018
[01:55:10.670] iteration 14585 : loss : 0.093167, loss_ce: 0.009720
[01:55:10.968] iteration 14586 : loss : 0.052544, loss_ce: 0.009950
[01:55:11.272] iteration 14587 : loss : 0.041168, loss_ce: 0.013762
[01:55:11.581] iteration 14588 : loss : 0.060231, loss_ce: 0.017481
[01:55:11.885] iteration 14589 : loss : 0.044709, loss_ce: 0.012774
[01:55:12.188] iteration 14590 : loss : 0.116172, loss_ce: 0.014090
[01:55:12.498] iteration 14591 : loss : 0.053477, loss_ce: 0.016115
[01:55:12.804] iteration 14592 : loss : 0.061544, loss_ce: 0.011238
[01:55:13.112] iteration 14593 : loss : 0.056047, loss_ce: 0.009068
[01:55:13.424] iteration 14594 : loss : 0.039276, loss_ce: 0.014343
[01:55:13.509] iteration 14595 : loss : 0.366792, loss_ce: 0.001500
[01:55:30.778] iteration 14596 : loss : 0.073946, loss_ce: 0.020700
[01:55:31.079] iteration 14597 : loss : 0.047540, loss_ce: 0.013900
[01:55:31.385] iteration 14598 : loss : 0.110029, loss_ce: 0.009016
[01:55:31.692] iteration 14599 : loss : 0.041776, loss_ce: 0.008168
[01:55:32.000] iteration 14600 : loss : 0.045124, loss_ce: 0.012109
[01:55:32.322] iteration 14601 : loss : 0.042886, loss_ce: 0.017075
[01:55:32.625] iteration 14602 : loss : 0.053050, loss_ce: 0.010310
[01:55:32.929] iteration 14603 : loss : 0.059331, loss_ce: 0.013016
[01:55:33.229] iteration 14604 : loss : 0.044300, loss_ce: 0.013250
[01:55:33.535] iteration 14605 : loss : 0.131189, loss_ce: 0.005865
[01:55:33.841] iteration 14606 : loss : 0.050681, loss_ce: 0.013314
[01:55:34.142] iteration 14607 : loss : 0.055859, loss_ce: 0.007512
[01:55:34.446] iteration 14608 : loss : 0.051140, loss_ce: 0.021324
[01:55:34.747] iteration 14609 : loss : 0.056250, loss_ce: 0.016374
[01:55:35.051] iteration 14610 : loss : 0.061548, loss_ce: 0.007563
[01:55:35.362] iteration 14611 : loss : 0.105786, loss_ce: 0.009304
[01:55:35.667] iteration 14612 : loss : 0.040303, loss_ce: 0.007854
[01:55:35.974] iteration 14613 : loss : 0.103252, loss_ce: 0.010522
[01:55:36.277] iteration 14614 : loss : 0.058155, loss_ce: 0.015038
[01:55:36.581] iteration 14615 : loss : 0.099146, loss_ce: 0.014314
[01:55:36.891] iteration 14616 : loss : 0.045550, loss_ce: 0.019144
[01:55:37.193] iteration 14617 : loss : 0.064588, loss_ce: 0.007678
[01:55:37.497] iteration 14618 : loss : 0.040656, loss_ce: 0.010614
[01:55:37.802] iteration 14619 : loss : 0.103337, loss_ce: 0.009429
[01:55:38.106] iteration 14620 : loss : 0.040736, loss_ce: 0.015065
[01:55:38.431] iteration 14621 : loss : 0.159951, loss_ce: 0.013638
[01:55:38.733] iteration 14622 : loss : 0.047032, loss_ce: 0.010958
[01:55:39.038] iteration 14623 : loss : 0.047573, loss_ce: 0.011725
[01:55:39.342] iteration 14624 : loss : 0.045890, loss_ce: 0.010185
[01:55:39.651] iteration 14625 : loss : 0.055016, loss_ce: 0.013581
[01:55:39.950] iteration 14626 : loss : 0.105309, loss_ce: 0.012545
[01:55:40.259] iteration 14627 : loss : 0.040059, loss_ce: 0.016043
[01:55:40.563] iteration 14628 : loss : 0.104177, loss_ce: 0.003568
[01:55:40.869] iteration 14629 : loss : 0.057614, loss_ce: 0.021486
[01:55:41.170] iteration 14630 : loss : 0.033111, loss_ce: 0.012090
[01:55:41.473] iteration 14631 : loss : 0.050642, loss_ce: 0.023164
[01:55:41.781] iteration 14632 : loss : 0.043760, loss_ce: 0.015578
[01:55:42.088] iteration 14633 : loss : 0.059234, loss_ce: 0.015487
[01:55:42.391] iteration 14634 : loss : 0.046778, loss_ce: 0.015203
[01:55:42.695] iteration 14635 : loss : 0.038274, loss_ce: 0.012469
[01:55:43.000] iteration 14636 : loss : 0.040436, loss_ce: 0.011510
[01:55:43.310] iteration 14637 : loss : 0.057095, loss_ce: 0.020532
[01:55:43.614] iteration 14638 : loss : 0.047595, loss_ce: 0.015731
[01:55:43.916] iteration 14639 : loss : 0.044461, loss_ce: 0.014368
[01:55:44.223] iteration 14640 : loss : 0.045026, loss_ce: 0.013453
[01:55:44.550] iteration 14641 : loss : 0.055665, loss_ce: 0.012712
[01:55:44.855] iteration 14642 : loss : 0.047640, loss_ce: 0.014618
[01:55:45.162] iteration 14643 : loss : 0.061651, loss_ce: 0.021129
[01:55:45.470] iteration 14644 : loss : 0.041197, loss_ce: 0.012226
[01:55:45.772] iteration 14645 : loss : 0.032602, loss_ce: 0.010068
[01:55:46.074] iteration 14646 : loss : 0.066164, loss_ce: 0.018463
[01:55:46.382] iteration 14647 : loss : 0.051248, loss_ce: 0.014693
[01:55:46.684] iteration 14648 : loss : 0.040498, loss_ce: 0.011440
[01:55:46.986] iteration 14649 : loss : 0.056167, loss_ce: 0.010282
[01:55:47.288] iteration 14650 : loss : 0.109654, loss_ce: 0.012412
[01:55:47.590] iteration 14651 : loss : 0.044667, loss_ce: 0.013612
[01:55:47.893] iteration 14652 : loss : 0.094153, loss_ce: 0.012311
[01:55:48.196] iteration 14653 : loss : 0.045474, loss_ce: 0.016055
[01:55:48.497] iteration 14654 : loss : 0.061210, loss_ce: 0.012931
[01:55:48.799] iteration 14655 : loss : 0.103388, loss_ce: 0.009560
[01:55:49.103] iteration 14656 : loss : 0.047631, loss_ce: 0.010172
[01:55:49.409] iteration 14657 : loss : 0.045317, loss_ce: 0.018350
[01:55:49.712] iteration 14658 : loss : 0.082906, loss_ce: 0.006706
[01:55:50.017] iteration 14659 : loss : 0.159103, loss_ce: 0.006203
[01:55:50.319] iteration 14660 : loss : 0.051251, loss_ce: 0.028733
[01:55:50.642] iteration 14661 : loss : 0.043583, loss_ce: 0.012674
[01:55:50.946] iteration 14662 : loss : 0.170378, loss_ce: 0.011286
[01:55:51.246] iteration 14663 : loss : 0.045273, loss_ce: 0.013870
[01:55:51.548] iteration 14664 : loss : 0.045761, loss_ce: 0.008761
[01:55:51.847] iteration 14665 : loss : 0.046573, loss_ce: 0.011609
[01:55:52.146] iteration 14666 : loss : 0.122303, loss_ce: 0.015284
[01:55:52.444] iteration 14667 : loss : 0.064665, loss_ce: 0.015979
[01:55:52.741] iteration 14668 : loss : 0.108559, loss_ce: 0.017531
[01:55:53.034] iteration 14669 : loss : 0.104055, loss_ce: 0.011841
[01:55:53.330] iteration 14670 : loss : 0.056548, loss_ce: 0.015834
[01:55:53.628] iteration 14671 : loss : 0.046124, loss_ce: 0.012582
[01:55:53.923] iteration 14672 : loss : 0.054281, loss_ce: 0.019592
[01:55:54.225] iteration 14673 : loss : 0.044412, loss_ce: 0.010041
[01:55:54.522] iteration 14674 : loss : 0.138240, loss_ce: 0.010751
[01:55:54.819] iteration 14675 : loss : 0.054268, loss_ce: 0.020797
[01:55:55.114] iteration 14676 : loss : 0.041979, loss_ce: 0.019138
[01:55:55.410] iteration 14677 : loss : 0.059396, loss_ce: 0.016552
[01:55:55.713] iteration 14678 : loss : 0.053365, loss_ce: 0.015484
[01:55:56.013] iteration 14679 : loss : 0.042845, loss_ce: 0.013859
[01:55:56.312] iteration 14680 : loss : 0.057065, loss_ce: 0.017939
[01:55:56.631] iteration 14681 : loss : 0.049109, loss_ce: 0.023313
[01:55:56.931] iteration 14682 : loss : 0.105056, loss_ce: 0.011635
[01:55:57.228] iteration 14683 : loss : 0.060652, loss_ce: 0.017610
[01:55:57.532] iteration 14684 : loss : 0.109865, loss_ce: 0.013556
[01:55:57.833] iteration 14685 : loss : 0.039611, loss_ce: 0.010340
[01:55:58.131] iteration 14686 : loss : 0.118094, loss_ce: 0.009823
[01:55:58.431] iteration 14687 : loss : 0.043345, loss_ce: 0.013842
[01:55:58.730] iteration 14688 : loss : 0.110154, loss_ce: 0.010889
[01:55:59.024] iteration 14689 : loss : 0.049653, loss_ce: 0.014461
[01:55:59.319] iteration 14690 : loss : 0.062482, loss_ce: 0.010219
[01:55:59.621] iteration 14691 : loss : 0.044494, loss_ce: 0.024789
[01:55:59.919] iteration 14692 : loss : 0.158413, loss_ce: 0.004388
[01:56:00.218] iteration 14693 : loss : 0.074194, loss_ce: 0.012939
[01:56:00.519] iteration 14694 : loss : 0.044094, loss_ce: 0.007662
[01:56:00.821] iteration 14695 : loss : 0.080584, loss_ce: 0.010004
[01:56:01.118] iteration 14696 : loss : 0.099782, loss_ce: 0.012097
[01:56:01.418] iteration 14697 : loss : 0.043486, loss_ce: 0.020774
[01:56:01.718] iteration 14698 : loss : 0.053296, loss_ce: 0.022759
[01:56:02.015] iteration 14699 : loss : 0.057299, loss_ce: 0.012094
[01:56:02.312] iteration 14700 : loss : 0.053498, loss_ce: 0.016627
[01:56:02.629] iteration 14701 : loss : 0.061650, loss_ce: 0.029563
[01:56:02.930] iteration 14702 : loss : 0.040824, loss_ce: 0.011021
[01:56:03.231] iteration 14703 : loss : 0.058575, loss_ce: 0.011982
[01:56:03.531] iteration 14704 : loss : 0.055933, loss_ce: 0.025847
[01:56:03.834] iteration 14705 : loss : 0.048314, loss_ce: 0.016471
[01:56:04.135] iteration 14706 : loss : 0.059244, loss_ce: 0.017474
[01:56:04.437] iteration 14707 : loss : 0.055229, loss_ce: 0.021881
[01:56:04.740] iteration 14708 : loss : 0.061625, loss_ce: 0.015698
[01:56:05.041] iteration 14709 : loss : 0.048354, loss_ce: 0.008389
[01:56:05.344] iteration 14710 : loss : 0.042717, loss_ce: 0.015374
[01:56:05.648] iteration 14711 : loss : 0.054527, loss_ce: 0.013962
[01:56:05.953] iteration 14712 : loss : 0.057888, loss_ce: 0.017242
[01:56:06.251] iteration 14713 : loss : 0.042836, loss_ce: 0.010469
[01:56:06.548] iteration 14714 : loss : 0.043309, loss_ce: 0.017142
[01:56:06.851] iteration 14715 : loss : 0.047078, loss_ce: 0.021706
[01:56:07.148] iteration 14716 : loss : 0.052391, loss_ce: 0.022824
[01:56:07.445] iteration 14717 : loss : 0.038501, loss_ce: 0.013822
[01:56:07.748] iteration 14718 : loss : 0.096359, loss_ce: 0.006954
[01:56:08.050] iteration 14719 : loss : 0.054166, loss_ce: 0.018671
[01:56:08.360] iteration 14720 : loss : 0.056970, loss_ce: 0.012289
[01:56:08.690] iteration 14721 : loss : 0.041451, loss_ce: 0.010447
[01:56:08.997] iteration 14722 : loss : 0.051544, loss_ce: 0.018247
[01:56:09.302] iteration 14723 : loss : 0.060982, loss_ce: 0.010597
[01:56:09.611] iteration 14724 : loss : 0.057209, loss_ce: 0.009842
[01:56:09.919] iteration 14725 : loss : 0.106234, loss_ce: 0.023200
[01:56:10.223] iteration 14726 : loss : 0.044757, loss_ce: 0.012018
[01:56:10.528] iteration 14727 : loss : 0.057838, loss_ce: 0.018506
[01:56:10.829] iteration 14728 : loss : 0.054820, loss_ce: 0.012385
[01:56:11.131] iteration 14729 : loss : 0.050342, loss_ce: 0.008031
[01:56:11.440] iteration 14730 : loss : 0.042610, loss_ce: 0.011885
[01:56:11.742] iteration 14731 : loss : 0.104066, loss_ce: 0.020628
[01:56:12.046] iteration 14732 : loss : 0.051919, loss_ce: 0.016587
[01:56:12.349] iteration 14733 : loss : 0.047664, loss_ce: 0.021567
[01:56:12.424] iteration 14734 : loss : 0.180254, loss_ce: 0.013241
[01:56:34.195] iteration 14735 : loss : 0.098478, loss_ce: 0.013441
[01:56:34.492] iteration 14736 : loss : 0.049289, loss_ce: 0.025624
[01:56:34.795] iteration 14737 : loss : 0.056179, loss_ce: 0.023923
[01:56:35.097] iteration 14738 : loss : 0.060718, loss_ce: 0.018935
[01:56:35.412] iteration 14739 : loss : 0.104716, loss_ce: 0.021021
[01:56:35.716] iteration 14740 : loss : 0.113146, loss_ce: 0.006602
[01:56:36.031] iteration 14741 : loss : 0.107035, loss_ce: 0.020242
[01:56:36.329] iteration 14742 : loss : 0.103583, loss_ce: 0.010092
[01:56:36.629] iteration 14743 : loss : 0.039477, loss_ce: 0.012647
[01:56:36.926] iteration 14744 : loss : 0.042700, loss_ce: 0.023502
[01:56:37.233] iteration 14745 : loss : 0.126545, loss_ce: 0.006593
[01:56:37.539] iteration 14746 : loss : 0.057302, loss_ce: 0.012323
[01:56:37.847] iteration 14747 : loss : 0.101831, loss_ce: 0.006093
[01:56:38.154] iteration 14748 : loss : 0.049289, loss_ce: 0.008333
[01:56:38.458] iteration 14749 : loss : 0.056992, loss_ce: 0.016207
[01:56:38.762] iteration 14750 : loss : 0.059118, loss_ce: 0.014948
[01:56:39.068] iteration 14751 : loss : 0.045291, loss_ce: 0.018110
[01:56:39.379] iteration 14752 : loss : 0.056006, loss_ce: 0.018146
[01:56:39.693] iteration 14753 : loss : 0.064874, loss_ce: 0.011735
[01:56:39.999] iteration 14754 : loss : 0.046644, loss_ce: 0.017422
[01:56:40.306] iteration 14755 : loss : 0.050487, loss_ce: 0.016955
[01:56:40.613] iteration 14756 : loss : 0.048168, loss_ce: 0.014275
[01:56:40.916] iteration 14757 : loss : 0.059669, loss_ce: 0.015886
[01:56:41.223] iteration 14758 : loss : 0.044715, loss_ce: 0.013150
[01:56:41.533] iteration 14759 : loss : 0.102319, loss_ce: 0.010365
[01:56:41.848] iteration 14760 : loss : 0.111248, loss_ce: 0.006991
[01:56:42.178] iteration 14761 : loss : 0.057050, loss_ce: 0.017739
[01:56:42.478] iteration 14762 : loss : 0.049450, loss_ce: 0.007703
[01:56:42.783] iteration 14763 : loss : 0.233672, loss_ce: 0.007597
[01:56:43.091] iteration 14764 : loss : 0.106468, loss_ce: 0.013868
[01:56:43.403] iteration 14765 : loss : 0.046246, loss_ce: 0.018165
[01:56:43.715] iteration 14766 : loss : 0.055590, loss_ce: 0.020785
[01:56:44.020] iteration 14767 : loss : 0.082590, loss_ce: 0.023698
[01:56:44.327] iteration 14768 : loss : 0.045934, loss_ce: 0.011676
[01:56:44.630] iteration 14769 : loss : 0.047340, loss_ce: 0.009768
[01:56:44.932] iteration 14770 : loss : 0.048619, loss_ce: 0.017080
[01:56:45.237] iteration 14771 : loss : 0.049162, loss_ce: 0.014036
[01:56:45.549] iteration 14772 : loss : 0.095450, loss_ce: 0.006436
[01:56:45.861] iteration 14773 : loss : 0.056942, loss_ce: 0.013051
[01:56:46.168] iteration 14774 : loss : 0.041843, loss_ce: 0.017086
[01:56:46.487] iteration 14775 : loss : 0.046509, loss_ce: 0.011715
[01:56:46.788] iteration 14776 : loss : 0.035664, loss_ce: 0.014742
[01:56:47.083] iteration 14777 : loss : 0.054341, loss_ce: 0.020402
[01:56:47.386] iteration 14778 : loss : 0.060337, loss_ce: 0.019901
[01:56:47.682] iteration 14779 : loss : 0.043570, loss_ce: 0.010377
[01:56:47.975] iteration 14780 : loss : 0.049304, loss_ce: 0.006864
[01:56:48.290] iteration 14781 : loss : 0.055403, loss_ce: 0.024855
[01:56:48.586] iteration 14782 : loss : 0.051791, loss_ce: 0.026510
[01:56:48.890] iteration 14783 : loss : 0.047453, loss_ce: 0.021153
[01:56:49.192] iteration 14784 : loss : 0.048964, loss_ce: 0.014719
[01:56:49.490] iteration 14785 : loss : 0.042301, loss_ce: 0.010616
[01:56:49.790] iteration 14786 : loss : 0.047076, loss_ce: 0.017118
[01:56:50.092] iteration 14787 : loss : 0.044608, loss_ce: 0.019037
[01:56:50.391] iteration 14788 : loss : 0.052723, loss_ce: 0.021053
[01:56:50.697] iteration 14789 : loss : 0.038909, loss_ce: 0.011116
[01:56:50.998] iteration 14790 : loss : 0.112496, loss_ce: 0.008391
[01:56:51.297] iteration 14791 : loss : 0.038648, loss_ce: 0.005616
[01:56:51.595] iteration 14792 : loss : 0.037195, loss_ce: 0.005698
[01:56:51.901] iteration 14793 : loss : 0.054490, loss_ce: 0.021046
[01:56:52.200] iteration 14794 : loss : 0.051488, loss_ce: 0.015430
[01:56:52.503] iteration 14795 : loss : 0.044181, loss_ce: 0.015175
[01:56:52.802] iteration 14796 : loss : 0.049005, loss_ce: 0.010381
[01:56:53.104] iteration 14797 : loss : 0.071312, loss_ce: 0.015224
[01:56:53.412] iteration 14798 : loss : 0.036415, loss_ce: 0.008006
[01:56:53.717] iteration 14799 : loss : 0.062144, loss_ce: 0.012125
[01:56:54.019] iteration 14800 : loss : 0.046129, loss_ce: 0.016088
[01:56:54.344] iteration 14801 : loss : 0.046711, loss_ce: 0.006225
[01:56:54.647] iteration 14802 : loss : 0.097713, loss_ce: 0.006305
[01:56:54.949] iteration 14803 : loss : 0.106753, loss_ce: 0.010904
[01:56:55.250] iteration 14804 : loss : 0.048497, loss_ce: 0.009391
[01:56:55.550] iteration 14805 : loss : 0.106317, loss_ce: 0.015143
[01:56:55.859] iteration 14806 : loss : 0.052428, loss_ce: 0.013415
[01:56:56.162] iteration 14807 : loss : 0.106011, loss_ce: 0.009406
[01:56:56.464] iteration 14808 : loss : 0.109497, loss_ce: 0.007700
[01:56:56.771] iteration 14809 : loss : 0.045196, loss_ce: 0.011615
[01:56:57.076] iteration 14810 : loss : 0.047636, loss_ce: 0.017190
[01:56:57.374] iteration 14811 : loss : 0.049627, loss_ce: 0.014360
[01:56:57.681] iteration 14812 : loss : 0.047271, loss_ce: 0.015018
[01:56:57.983] iteration 14813 : loss : 0.048422, loss_ce: 0.009358
[01:56:58.283] iteration 14814 : loss : 0.042902, loss_ce: 0.015182
[01:56:58.586] iteration 14815 : loss : 0.065023, loss_ce: 0.015793
[01:56:58.894] iteration 14816 : loss : 0.103350, loss_ce: 0.008436
[01:56:59.195] iteration 14817 : loss : 0.059167, loss_ce: 0.020058
[01:56:59.499] iteration 14818 : loss : 0.054028, loss_ce: 0.018637
[01:56:59.803] iteration 14819 : loss : 0.045842, loss_ce: 0.006128
[01:57:00.107] iteration 14820 : loss : 0.058635, loss_ce: 0.014482
[01:57:00.432] iteration 14821 : loss : 0.042639, loss_ce: 0.016830
[01:57:00.736] iteration 14822 : loss : 0.070687, loss_ce: 0.010114
[01:57:01.035] iteration 14823 : loss : 0.038650, loss_ce: 0.016298
[01:57:01.336] iteration 14824 : loss : 0.040553, loss_ce: 0.015346
[01:57:01.640] iteration 14825 : loss : 0.048013, loss_ce: 0.014495
[01:57:01.943] iteration 14826 : loss : 0.047565, loss_ce: 0.014615
[01:57:02.246] iteration 14827 : loss : 0.051241, loss_ce: 0.017031
[01:57:02.551] iteration 14828 : loss : 0.049523, loss_ce: 0.020113
[01:57:02.851] iteration 14829 : loss : 0.046062, loss_ce: 0.016020
[01:57:03.155] iteration 14830 : loss : 0.051329, loss_ce: 0.021543
[01:57:03.459] iteration 14831 : loss : 0.065923, loss_ce: 0.011843
[01:57:03.761] iteration 14832 : loss : 0.105396, loss_ce: 0.009542
[01:57:04.064] iteration 14833 : loss : 0.046831, loss_ce: 0.010789
[01:57:04.367] iteration 14834 : loss : 0.042812, loss_ce: 0.010677
[01:57:04.669] iteration 14835 : loss : 0.052573, loss_ce: 0.009185
[01:57:04.973] iteration 14836 : loss : 0.043601, loss_ce: 0.013047
[01:57:05.282] iteration 14837 : loss : 0.049825, loss_ce: 0.013929
[01:57:05.588] iteration 14838 : loss : 0.045425, loss_ce: 0.019740
[01:57:05.890] iteration 14839 : loss : 0.049210, loss_ce: 0.017387
[01:57:06.196] iteration 14840 : loss : 0.049054, loss_ce: 0.014614
[01:57:06.512] iteration 14841 : loss : 0.096277, loss_ce: 0.007782
[01:57:06.814] iteration 14842 : loss : 0.032460, loss_ce: 0.012048
[01:57:07.118] iteration 14843 : loss : 0.044289, loss_ce: 0.010121
[01:57:07.422] iteration 14844 : loss : 0.046124, loss_ce: 0.012739
[01:57:07.728] iteration 14845 : loss : 0.072879, loss_ce: 0.010825
[01:57:08.032] iteration 14846 : loss : 0.048443, loss_ce: 0.015186
[01:57:08.333] iteration 14847 : loss : 0.051454, loss_ce: 0.011208
[01:57:08.636] iteration 14848 : loss : 0.041324, loss_ce: 0.014788
[01:57:08.936] iteration 14849 : loss : 0.044248, loss_ce: 0.014713
[01:57:09.240] iteration 14850 : loss : 0.044901, loss_ce: 0.014249
[01:57:09.548] iteration 14851 : loss : 0.047635, loss_ce: 0.009194
[01:57:09.853] iteration 14852 : loss : 0.044553, loss_ce: 0.006617
[01:57:10.155] iteration 14853 : loss : 0.047330, loss_ce: 0.009611
[01:57:10.459] iteration 14854 : loss : 0.100069, loss_ce: 0.012424
[01:57:10.765] iteration 14855 : loss : 0.040298, loss_ce: 0.016399
[01:57:11.064] iteration 14856 : loss : 0.036450, loss_ce: 0.017255
[01:57:11.365] iteration 14857 : loss : 0.066250, loss_ce: 0.019472
[01:57:11.666] iteration 14858 : loss : 0.107101, loss_ce: 0.021083
[01:57:11.970] iteration 14859 : loss : 0.051714, loss_ce: 0.016206
[01:57:12.274] iteration 14860 : loss : 0.052906, loss_ce: 0.021216
[01:57:12.598] iteration 14861 : loss : 0.043642, loss_ce: 0.011962
[01:57:12.898] iteration 14862 : loss : 0.133250, loss_ce: 0.006892
[01:57:13.208] iteration 14863 : loss : 0.108246, loss_ce: 0.018057
[01:57:13.508] iteration 14864 : loss : 0.077811, loss_ce: 0.013679
[01:57:13.811] iteration 14865 : loss : 0.050641, loss_ce: 0.014527
[01:57:14.110] iteration 14866 : loss : 0.102564, loss_ce: 0.007598
[01:57:14.413] iteration 14867 : loss : 0.115397, loss_ce: 0.014975
[01:57:14.713] iteration 14868 : loss : 0.058952, loss_ce: 0.015415
[01:57:15.015] iteration 14869 : loss : 0.050119, loss_ce: 0.015864
[01:57:15.322] iteration 14870 : loss : 0.041653, loss_ce: 0.013376
[01:57:15.630] iteration 14871 : loss : 0.044854, loss_ce: 0.011797
[01:57:15.945] iteration 14872 : loss : 0.043772, loss_ce: 0.008884
[01:57:16.037] iteration 14873 : loss : 0.340240, loss_ce: 0.007957
[01:57:33.674] iteration 14874 : loss : 0.059112, loss_ce: 0.021729
[01:57:33.975] iteration 14875 : loss : 0.045616, loss_ce: 0.013471
[01:57:34.274] iteration 14876 : loss : 0.057867, loss_ce: 0.021810
[01:57:34.577] iteration 14877 : loss : 0.051192, loss_ce: 0.014849
[01:57:34.883] iteration 14878 : loss : 0.060674, loss_ce: 0.023261
[01:57:35.182] iteration 14879 : loss : 0.050868, loss_ce: 0.015338
[01:57:35.479] iteration 14880 : loss : 0.047778, loss_ce: 0.009389
[01:57:35.793] iteration 14881 : loss : 0.241333, loss_ce: 0.003425
[01:57:36.092] iteration 14882 : loss : 0.043816, loss_ce: 0.020502
[01:57:36.388] iteration 14883 : loss : 0.061211, loss_ce: 0.021856
[01:57:36.684] iteration 14884 : loss : 0.046432, loss_ce: 0.013470
[01:57:36.982] iteration 14885 : loss : 0.035268, loss_ce: 0.015398
[01:57:37.279] iteration 14886 : loss : 0.046302, loss_ce: 0.018713
[01:57:37.576] iteration 14887 : loss : 0.054578, loss_ce: 0.021484
[01:57:37.873] iteration 14888 : loss : 0.061676, loss_ce: 0.022611
[01:57:38.173] iteration 14889 : loss : 0.031347, loss_ce: 0.011126
[01:57:38.470] iteration 14890 : loss : 0.074541, loss_ce: 0.021140
[01:57:38.766] iteration 14891 : loss : 0.053507, loss_ce: 0.022854
[01:57:39.065] iteration 14892 : loss : 0.043369, loss_ce: 0.015052
[01:57:39.370] iteration 14893 : loss : 0.052305, loss_ce: 0.012268
[01:57:39.669] iteration 14894 : loss : 0.060179, loss_ce: 0.016377
[01:57:39.969] iteration 14895 : loss : 0.045649, loss_ce: 0.011176
[01:57:40.273] iteration 14896 : loss : 0.037224, loss_ce: 0.010990
[01:57:40.569] iteration 14897 : loss : 0.043409, loss_ce: 0.013887
[01:57:40.867] iteration 14898 : loss : 0.053465, loss_ce: 0.022250
[01:57:41.170] iteration 14899 : loss : 0.097799, loss_ce: 0.010392
[01:57:41.472] iteration 14900 : loss : 0.098470, loss_ce: 0.005945
[01:57:41.788] iteration 14901 : loss : 0.034892, loss_ce: 0.012985
[01:57:42.087] iteration 14902 : loss : 0.214365, loss_ce: 0.003378
[01:57:42.390] iteration 14903 : loss : 0.052251, loss_ce: 0.015505
[01:57:42.691] iteration 14904 : loss : 0.042281, loss_ce: 0.010418
[01:57:42.997] iteration 14905 : loss : 0.053604, loss_ce: 0.016619
[01:57:43.296] iteration 14906 : loss : 0.053455, loss_ce: 0.011532
[01:57:43.600] iteration 14907 : loss : 0.052366, loss_ce: 0.013943
[01:57:43.904] iteration 14908 : loss : 0.035512, loss_ce: 0.012724
[01:57:44.206] iteration 14909 : loss : 0.193466, loss_ce: 0.003295
[01:57:44.509] iteration 14910 : loss : 0.094448, loss_ce: 0.007245
[01:57:44.808] iteration 14911 : loss : 0.049940, loss_ce: 0.014938
[01:57:45.114] iteration 14912 : loss : 0.047406, loss_ce: 0.014912
[01:57:45.421] iteration 14913 : loss : 0.052177, loss_ce: 0.015102
[01:57:45.728] iteration 14914 : loss : 0.052508, loss_ce: 0.015244
[01:57:46.030] iteration 14915 : loss : 0.068433, loss_ce: 0.006401
[01:57:46.331] iteration 14916 : loss : 0.038829, loss_ce: 0.014828
[01:57:46.633] iteration 14917 : loss : 0.050315, loss_ce: 0.016875
[01:57:46.938] iteration 14918 : loss : 0.048783, loss_ce: 0.014286
[01:57:47.242] iteration 14919 : loss : 0.049333, loss_ce: 0.012564
[01:57:47.545] iteration 14920 : loss : 0.042631, loss_ce: 0.009076
[01:57:47.866] iteration 14921 : loss : 0.049421, loss_ce: 0.016483
[01:57:48.172] iteration 14922 : loss : 0.100239, loss_ce: 0.012346
[01:57:48.475] iteration 14923 : loss : 0.052483, loss_ce: 0.026338
[01:57:48.776] iteration 14924 : loss : 0.098656, loss_ce: 0.012541
[01:57:49.082] iteration 14925 : loss : 0.050017, loss_ce: 0.011826
[01:57:49.385] iteration 14926 : loss : 0.058120, loss_ce: 0.013770
[01:57:49.687] iteration 14927 : loss : 0.051020, loss_ce: 0.028128
[01:57:49.994] iteration 14928 : loss : 0.045304, loss_ce: 0.014929
[01:57:50.295] iteration 14929 : loss : 0.060473, loss_ce: 0.015410
[01:57:50.604] iteration 14930 : loss : 0.100542, loss_ce: 0.010596
[01:57:50.906] iteration 14931 : loss : 0.105158, loss_ce: 0.018613
[01:57:51.214] iteration 14932 : loss : 0.059339, loss_ce: 0.013220
[01:57:51.517] iteration 14933 : loss : 0.058798, loss_ce: 0.020713
[01:57:51.817] iteration 14934 : loss : 0.046938, loss_ce: 0.006096
[01:57:52.122] iteration 14935 : loss : 0.280067, loss_ce: 0.004505
[01:57:52.424] iteration 14936 : loss : 0.044489, loss_ce: 0.016011
[01:57:52.723] iteration 14937 : loss : 0.045053, loss_ce: 0.009621
[01:57:53.024] iteration 14938 : loss : 0.039471, loss_ce: 0.012743
[01:57:53.329] iteration 14939 : loss : 0.072610, loss_ce: 0.016971
[01:57:53.629] iteration 14940 : loss : 0.048264, loss_ce: 0.016828
[01:57:53.947] iteration 14941 : loss : 0.058051, loss_ce: 0.009366
[01:57:54.249] iteration 14942 : loss : 0.109005, loss_ce: 0.005057
[01:57:54.547] iteration 14943 : loss : 0.113001, loss_ce: 0.013750
[01:57:54.851] iteration 14944 : loss : 0.047235, loss_ce: 0.007710
[01:57:55.155] iteration 14945 : loss : 0.038750, loss_ce: 0.013159
[01:57:55.454] iteration 14946 : loss : 0.054328, loss_ce: 0.022457
[01:57:55.755] iteration 14947 : loss : 0.041660, loss_ce: 0.018705
[01:57:56.059] iteration 14948 : loss : 0.098089, loss_ce: 0.007708
[01:57:56.365] iteration 14949 : loss : 0.119371, loss_ce: 0.022953
[01:57:56.670] iteration 14950 : loss : 0.097126, loss_ce: 0.010144
[01:57:56.977] iteration 14951 : loss : 0.052894, loss_ce: 0.024951
[01:57:57.284] iteration 14952 : loss : 0.049087, loss_ce: 0.008341
[01:57:57.589] iteration 14953 : loss : 0.052153, loss_ce: 0.015717
[01:57:57.896] iteration 14954 : loss : 0.048352, loss_ce: 0.016601
[01:57:58.202] iteration 14955 : loss : 0.111250, loss_ce: 0.008852
[01:57:58.506] iteration 14956 : loss : 0.045152, loss_ce: 0.016047
[01:57:58.812] iteration 14957 : loss : 0.051528, loss_ce: 0.014946
[01:57:59.114] iteration 14958 : loss : 0.035787, loss_ce: 0.011811
[01:57:59.420] iteration 14959 : loss : 0.051208, loss_ce: 0.015417
[01:57:59.726] iteration 14960 : loss : 0.044460, loss_ce: 0.014146
[01:58:00.041] iteration 14961 : loss : 0.041162, loss_ce: 0.013066
[01:58:00.344] iteration 14962 : loss : 0.053620, loss_ce: 0.009947
[01:58:00.654] iteration 14963 : loss : 0.100298, loss_ce: 0.008537
[01:58:00.960] iteration 14964 : loss : 0.037277, loss_ce: 0.008027
[01:58:01.260] iteration 14965 : loss : 0.052607, loss_ce: 0.016641
[01:58:01.558] iteration 14966 : loss : 0.110964, loss_ce: 0.014276
[01:58:01.856] iteration 14967 : loss : 0.047372, loss_ce: 0.011441
[01:58:02.153] iteration 14968 : loss : 0.045835, loss_ce: 0.007893
[01:58:02.450] iteration 14969 : loss : 0.104686, loss_ce: 0.008722
[01:58:02.749] iteration 14970 : loss : 0.055527, loss_ce: 0.013116
[01:58:03.048] iteration 14971 : loss : 0.118425, loss_ce: 0.012659
[01:58:03.350] iteration 14972 : loss : 0.100392, loss_ce: 0.012816
[01:58:03.648] iteration 14973 : loss : 0.056202, loss_ce: 0.015911
[01:58:03.946] iteration 14974 : loss : 0.049092, loss_ce: 0.017239
[01:58:04.243] iteration 14975 : loss : 0.049846, loss_ce: 0.017105
[01:58:04.546] iteration 14976 : loss : 0.098274, loss_ce: 0.017454
[01:58:04.843] iteration 14977 : loss : 0.066679, loss_ce: 0.011603
[01:58:05.143] iteration 14978 : loss : 0.042439, loss_ce: 0.014977
[01:58:05.443] iteration 14979 : loss : 0.100070, loss_ce: 0.008005
[01:58:05.746] iteration 14980 : loss : 0.046856, loss_ce: 0.014537
[01:58:06.066] iteration 14981 : loss : 0.101168, loss_ce: 0.014514
[01:58:06.365] iteration 14982 : loss : 0.113930, loss_ce: 0.017513
[01:58:06.665] iteration 14983 : loss : 0.044182, loss_ce: 0.013458
[01:58:06.968] iteration 14984 : loss : 0.046404, loss_ce: 0.012678
[01:58:07.267] iteration 14985 : loss : 0.043633, loss_ce: 0.013488
[01:58:07.559] iteration 14986 : loss : 0.043491, loss_ce: 0.009562
[01:58:07.861] iteration 14987 : loss : 0.060611, loss_ce: 0.016926
[01:58:08.160] iteration 14988 : loss : 0.111489, loss_ce: 0.003700
[01:58:08.461] iteration 14989 : loss : 0.055914, loss_ce: 0.010876
[01:58:08.759] iteration 14990 : loss : 0.163350, loss_ce: 0.009978
[01:58:09.059] iteration 14991 : loss : 0.100998, loss_ce: 0.010144
[01:58:09.361] iteration 14992 : loss : 0.042387, loss_ce: 0.016317
[01:58:09.655] iteration 14993 : loss : 0.110120, loss_ce: 0.008543
[01:58:09.955] iteration 14994 : loss : 0.047429, loss_ce: 0.009259
[01:58:10.254] iteration 14995 : loss : 0.104574, loss_ce: 0.013182
[01:58:10.551] iteration 14996 : loss : 0.043571, loss_ce: 0.016095
[01:58:10.860] iteration 14997 : loss : 0.051658, loss_ce: 0.011949
[01:58:11.161] iteration 14998 : loss : 0.109079, loss_ce: 0.020076
[01:58:11.471] iteration 14999 : loss : 0.045628, loss_ce: 0.014596
[01:58:11.769] iteration 15000 : loss : 0.044051, loss_ce: 0.009084
[01:58:12.089] iteration 15001 : loss : 0.044674, loss_ce: 0.019247
[01:58:12.383] iteration 15002 : loss : 0.059893, loss_ce: 0.011964
[01:58:12.690] iteration 15003 : loss : 0.034538, loss_ce: 0.009758
[01:58:12.990] iteration 15004 : loss : 0.041441, loss_ce: 0.013400
[01:58:13.301] iteration 15005 : loss : 0.046331, loss_ce: 0.016320
[01:58:13.606] iteration 15006 : loss : 0.055086, loss_ce: 0.023039
[01:58:13.907] iteration 15007 : loss : 0.053284, loss_ce: 0.012070
[01:58:14.212] iteration 15008 : loss : 0.039890, loss_ce: 0.013620
[01:58:14.513] iteration 15009 : loss : 0.043246, loss_ce: 0.015549
[01:58:14.828] iteration 15010 : loss : 0.047842, loss_ce: 0.012668
[01:58:15.141] iteration 15011 : loss : 0.050559, loss_ce: 0.010690
[01:58:15.224] iteration 15012 : loss : 0.028440, loss_ce: 0.014120
[01:58:35.213] iteration 15013 : loss : 0.114526, loss_ce: 0.007643
[01:58:35.509] iteration 15014 : loss : 0.047436, loss_ce: 0.015169
[01:58:35.812] iteration 15015 : loss : 0.044611, loss_ce: 0.011801
[01:58:36.109] iteration 15016 : loss : 0.057687, loss_ce: 0.010262
[01:58:36.411] iteration 15017 : loss : 0.044780, loss_ce: 0.012970
[01:58:36.708] iteration 15018 : loss : 0.044928, loss_ce: 0.014360
[01:58:37.007] iteration 15019 : loss : 0.049048, loss_ce: 0.019281
[01:58:37.303] iteration 15020 : loss : 0.048768, loss_ce: 0.007378
[01:58:37.613] iteration 15021 : loss : 0.150138, loss_ce: 0.003686
[01:58:37.914] iteration 15022 : loss : 0.042046, loss_ce: 0.008323
[01:58:38.213] iteration 15023 : loss : 0.050715, loss_ce: 0.015190
[01:58:38.512] iteration 15024 : loss : 0.044427, loss_ce: 0.010952
[01:58:38.816] iteration 15025 : loss : 0.103699, loss_ce: 0.014793
[01:58:39.117] iteration 15026 : loss : 0.060304, loss_ce: 0.012316
[01:58:39.413] iteration 15027 : loss : 0.051700, loss_ce: 0.020814
[01:58:39.714] iteration 15028 : loss : 0.048694, loss_ce: 0.023863
[01:58:40.010] iteration 15029 : loss : 0.166671, loss_ce: 0.015063
[01:58:40.308] iteration 15030 : loss : 0.049049, loss_ce: 0.008043
[01:58:40.600] iteration 15031 : loss : 0.113323, loss_ce: 0.005943
[01:58:40.904] iteration 15032 : loss : 0.044609, loss_ce: 0.015491
[01:58:41.200] iteration 15033 : loss : 0.292987, loss_ce: 0.006915
[01:58:41.498] iteration 15034 : loss : 0.043044, loss_ce: 0.018219
[01:58:41.797] iteration 15035 : loss : 0.046262, loss_ce: 0.023503
[01:58:42.090] iteration 15036 : loss : 0.064847, loss_ce: 0.016227
[01:58:42.388] iteration 15037 : loss : 0.039941, loss_ce: 0.015250
[01:58:42.684] iteration 15038 : loss : 0.033336, loss_ce: 0.011111
[01:58:42.982] iteration 15039 : loss : 0.049703, loss_ce: 0.017397
[01:58:43.282] iteration 15040 : loss : 0.045392, loss_ce: 0.014955
[01:58:43.602] iteration 15041 : loss : 0.116013, loss_ce: 0.013042
[01:58:43.900] iteration 15042 : loss : 0.035033, loss_ce: 0.006752
[01:58:44.202] iteration 15043 : loss : 0.041675, loss_ce: 0.016580
[01:58:44.506] iteration 15044 : loss : 0.049691, loss_ce: 0.017195
[01:58:44.808] iteration 15045 : loss : 0.039139, loss_ce: 0.011118
[01:58:45.115] iteration 15046 : loss : 0.053091, loss_ce: 0.012954
[01:58:45.417] iteration 15047 : loss : 0.117569, loss_ce: 0.011253
[01:58:45.720] iteration 15048 : loss : 0.041203, loss_ce: 0.008248
[01:58:46.025] iteration 15049 : loss : 0.097110, loss_ce: 0.005114
[01:58:46.327] iteration 15050 : loss : 0.165059, loss_ce: 0.003076
[01:58:46.624] iteration 15051 : loss : 0.042406, loss_ce: 0.016905
[01:58:46.922] iteration 15052 : loss : 0.042919, loss_ce: 0.011096
[01:58:47.218] iteration 15053 : loss : 0.040395, loss_ce: 0.016506
[01:58:47.521] iteration 15054 : loss : 0.098307, loss_ce: 0.011734
[01:58:47.820] iteration 15055 : loss : 0.106781, loss_ce: 0.005870
[01:58:48.115] iteration 15056 : loss : 0.050789, loss_ce: 0.018934
[01:58:48.416] iteration 15057 : loss : 0.060272, loss_ce: 0.020086
[01:58:48.720] iteration 15058 : loss : 0.050809, loss_ce: 0.012961
[01:58:49.017] iteration 15059 : loss : 0.039240, loss_ce: 0.010901
[01:58:49.317] iteration 15060 : loss : 0.046709, loss_ce: 0.011132
[01:58:49.636] iteration 15061 : loss : 0.050081, loss_ce: 0.013166
[01:58:49.928] iteration 15062 : loss : 0.101999, loss_ce: 0.010536
[01:58:50.222] iteration 15063 : loss : 0.105303, loss_ce: 0.011535
[01:58:50.521] iteration 15064 : loss : 0.050309, loss_ce: 0.011189
[01:58:50.817] iteration 15065 : loss : 0.040627, loss_ce: 0.016208
[01:58:51.115] iteration 15066 : loss : 0.047164, loss_ce: 0.016958
[01:58:51.412] iteration 15067 : loss : 0.063422, loss_ce: 0.016171
[01:58:51.714] iteration 15068 : loss : 0.111481, loss_ce: 0.006334
[01:58:52.010] iteration 15069 : loss : 0.061773, loss_ce: 0.012089
[01:58:52.308] iteration 15070 : loss : 0.093368, loss_ce: 0.013479
[01:58:52.605] iteration 15071 : loss : 0.043035, loss_ce: 0.012285
[01:58:52.909] iteration 15072 : loss : 0.045281, loss_ce: 0.016545
[01:58:53.211] iteration 15073 : loss : 0.047423, loss_ce: 0.008675
[01:58:53.508] iteration 15074 : loss : 0.170473, loss_ce: 0.017118
[01:58:53.806] iteration 15075 : loss : 0.045123, loss_ce: 0.013499
[01:58:54.106] iteration 15076 : loss : 0.047428, loss_ce: 0.013250
[01:58:54.408] iteration 15077 : loss : 0.118503, loss_ce: 0.007538
[01:58:54.707] iteration 15078 : loss : 0.043392, loss_ce: 0.009132
[01:58:55.004] iteration 15079 : loss : 0.044557, loss_ce: 0.009799
[01:58:55.302] iteration 15080 : loss : 0.061827, loss_ce: 0.010144
[01:58:55.613] iteration 15081 : loss : 0.045291, loss_ce: 0.013553
[01:58:55.912] iteration 15082 : loss : 0.052775, loss_ce: 0.015653
[01:58:56.214] iteration 15083 : loss : 0.045576, loss_ce: 0.020545
[01:58:56.510] iteration 15084 : loss : 0.041681, loss_ce: 0.017208
[01:58:56.805] iteration 15085 : loss : 0.045002, loss_ce: 0.011782
[01:58:57.104] iteration 15086 : loss : 0.065189, loss_ce: 0.012064
[01:58:57.403] iteration 15087 : loss : 0.044337, loss_ce: 0.016659
[01:58:57.701] iteration 15088 : loss : 0.115033, loss_ce: 0.009805
[01:58:58.002] iteration 15089 : loss : 0.041949, loss_ce: 0.008760
[01:58:58.300] iteration 15090 : loss : 0.103929, loss_ce: 0.019600
[01:58:58.597] iteration 15091 : loss : 0.044762, loss_ce: 0.018811
[01:58:58.888] iteration 15092 : loss : 0.044390, loss_ce: 0.010500
[01:58:59.189] iteration 15093 : loss : 0.073219, loss_ce: 0.019965
[01:58:59.492] iteration 15094 : loss : 0.046987, loss_ce: 0.015436
[01:58:59.788] iteration 15095 : loss : 0.043405, loss_ce: 0.014988
[01:59:00.090] iteration 15096 : loss : 0.052188, loss_ce: 0.015228
[01:59:00.393] iteration 15097 : loss : 0.057093, loss_ce: 0.009642
[01:59:00.695] iteration 15098 : loss : 0.048174, loss_ce: 0.023732
[01:59:00.997] iteration 15099 : loss : 0.044429, loss_ce: 0.007816
[01:59:01.299] iteration 15100 : loss : 0.105071, loss_ce: 0.012739
[01:59:01.614] iteration 15101 : loss : 0.055560, loss_ce: 0.015123
[01:59:01.917] iteration 15102 : loss : 0.041273, loss_ce: 0.016160
[01:59:02.223] iteration 15103 : loss : 0.045542, loss_ce: 0.016696
[01:59:02.530] iteration 15104 : loss : 0.048391, loss_ce: 0.016570
[01:59:02.835] iteration 15105 : loss : 0.047943, loss_ce: 0.013411
[01:59:03.136] iteration 15106 : loss : 0.041012, loss_ce: 0.007730
[01:59:03.441] iteration 15107 : loss : 0.057812, loss_ce: 0.025951
[01:59:03.747] iteration 15108 : loss : 0.054727, loss_ce: 0.017134
[01:59:04.047] iteration 15109 : loss : 0.046516, loss_ce: 0.022290
[01:59:04.351] iteration 15110 : loss : 0.044276, loss_ce: 0.014917
[01:59:04.651] iteration 15111 : loss : 0.045360, loss_ce: 0.013758
[01:59:04.956] iteration 15112 : loss : 0.111572, loss_ce: 0.010744
[01:59:05.255] iteration 15113 : loss : 0.043784, loss_ce: 0.013738
[01:59:05.557] iteration 15114 : loss : 0.104244, loss_ce: 0.012568
[01:59:05.862] iteration 15115 : loss : 0.152910, loss_ce: 0.005484
[01:59:06.166] iteration 15116 : loss : 0.050342, loss_ce: 0.021214
[01:59:06.473] iteration 15117 : loss : 0.054497, loss_ce: 0.018451
[01:59:06.774] iteration 15118 : loss : 0.046861, loss_ce: 0.013380
[01:59:07.073] iteration 15119 : loss : 0.049114, loss_ce: 0.015134
[01:59:07.374] iteration 15120 : loss : 0.052340, loss_ce: 0.018439
[01:59:07.688] iteration 15121 : loss : 0.048436, loss_ce: 0.019563
[01:59:07.991] iteration 15122 : loss : 0.048337, loss_ce: 0.016482
[01:59:08.298] iteration 15123 : loss : 0.044387, loss_ce: 0.005924
[01:59:08.603] iteration 15124 : loss : 0.052507, loss_ce: 0.013823
[01:59:08.904] iteration 15125 : loss : 0.049497, loss_ce: 0.016713
[01:59:09.203] iteration 15126 : loss : 0.050919, loss_ce: 0.013815
[01:59:09.509] iteration 15127 : loss : 0.042914, loss_ce: 0.012158
[01:59:09.814] iteration 15128 : loss : 0.053444, loss_ce: 0.013440
[01:59:10.113] iteration 15129 : loss : 0.048294, loss_ce: 0.013229
[01:59:10.416] iteration 15130 : loss : 0.045965, loss_ce: 0.013101
[01:59:10.718] iteration 15131 : loss : 0.100588, loss_ce: 0.009350
[01:59:11.021] iteration 15132 : loss : 0.040845, loss_ce: 0.012439
[01:59:11.325] iteration 15133 : loss : 0.099206, loss_ce: 0.013639
[01:59:11.627] iteration 15134 : loss : 0.032995, loss_ce: 0.008557
[01:59:11.933] iteration 15135 : loss : 0.047255, loss_ce: 0.017455
[01:59:12.239] iteration 15136 : loss : 0.048612, loss_ce: 0.018153
[01:59:12.543] iteration 15137 : loss : 0.047080, loss_ce: 0.015481
[01:59:12.850] iteration 15138 : loss : 0.046512, loss_ce: 0.011496
[01:59:13.162] iteration 15139 : loss : 0.109158, loss_ce: 0.013780
[01:59:13.471] iteration 15140 : loss : 0.101692, loss_ce: 0.007888
[01:59:13.809] iteration 15141 : loss : 0.159717, loss_ce: 0.014601
[01:59:14.119] iteration 15142 : loss : 0.043187, loss_ce: 0.018214
[01:59:14.435] iteration 15143 : loss : 0.045067, loss_ce: 0.016849
[01:59:14.745] iteration 15144 : loss : 0.067794, loss_ce: 0.012227
[01:59:15.051] iteration 15145 : loss : 0.048947, loss_ce: 0.020404
[01:59:15.359] iteration 15146 : loss : 0.041457, loss_ce: 0.020409
[01:59:15.666] iteration 15147 : loss : 0.039357, loss_ce: 0.009302
[01:59:15.981] iteration 15148 : loss : 0.041088, loss_ce: 0.018216
[01:59:16.289] iteration 15149 : loss : 0.043413, loss_ce: 0.014554
[01:59:16.605] iteration 15150 : loss : 0.054310, loss_ce: 0.017590
[01:59:16.693] iteration 15151 : loss : 0.432295, loss_ce: 0.000860
[01:59:33.628] iteration 15152 : loss : 0.062918, loss_ce: 0.015003
[01:59:33.927] iteration 15153 : loss : 0.040602, loss_ce: 0.014217
[01:59:34.235] iteration 15154 : loss : 0.047910, loss_ce: 0.010281
[01:59:34.544] iteration 15155 : loss : 0.131281, loss_ce: 0.026310
[01:59:34.852] iteration 15156 : loss : 0.053040, loss_ce: 0.024310
[01:59:35.155] iteration 15157 : loss : 0.048551, loss_ce: 0.012945
[01:59:35.462] iteration 15158 : loss : 0.046498, loss_ce: 0.024477
[01:59:35.768] iteration 15159 : loss : 0.050921, loss_ce: 0.018281
[01:59:36.069] iteration 15160 : loss : 0.116281, loss_ce: 0.012864
[01:59:36.387] iteration 15161 : loss : 0.046812, loss_ce: 0.008074
[01:59:36.687] iteration 15162 : loss : 0.045876, loss_ce: 0.007872
[01:59:36.985] iteration 15163 : loss : 0.061490, loss_ce: 0.011629
[01:59:37.292] iteration 15164 : loss : 0.051381, loss_ce: 0.028146
[01:59:37.590] iteration 15165 : loss : 0.110405, loss_ce: 0.013467
[01:59:37.889] iteration 15166 : loss : 0.056145, loss_ce: 0.014386
[01:59:38.190] iteration 15167 : loss : 0.043205, loss_ce: 0.014434
[01:59:38.489] iteration 15168 : loss : 0.159593, loss_ce: 0.009027
[01:59:38.791] iteration 15169 : loss : 0.107276, loss_ce: 0.012764
[01:59:39.089] iteration 15170 : loss : 0.052949, loss_ce: 0.016711
[01:59:39.388] iteration 15171 : loss : 0.077647, loss_ce: 0.022274
[01:59:39.684] iteration 15172 : loss : 0.105620, loss_ce: 0.014199
[01:59:39.981] iteration 15173 : loss : 0.109905, loss_ce: 0.011937
[01:59:40.280] iteration 15174 : loss : 0.072099, loss_ce: 0.022009
[01:59:40.576] iteration 15175 : loss : 0.048055, loss_ce: 0.018427
[01:59:40.877] iteration 15176 : loss : 0.048915, loss_ce: 0.016546
[01:59:41.178] iteration 15177 : loss : 0.046323, loss_ce: 0.008195
[01:59:41.478] iteration 15178 : loss : 0.043029, loss_ce: 0.014388
[01:59:41.781] iteration 15179 : loss : 0.041613, loss_ce: 0.012109
[01:59:42.080] iteration 15180 : loss : 0.112413, loss_ce: 0.011683
[01:59:42.398] iteration 15181 : loss : 0.040068, loss_ce: 0.006837
[01:59:42.699] iteration 15182 : loss : 0.053925, loss_ce: 0.014265
[01:59:43.002] iteration 15183 : loss : 0.043186, loss_ce: 0.019895
[01:59:43.304] iteration 15184 : loss : 0.105910, loss_ce: 0.015749
[01:59:43.602] iteration 15185 : loss : 0.053907, loss_ce: 0.023138
[01:59:43.909] iteration 15186 : loss : 0.040392, loss_ce: 0.018824
[01:59:44.204] iteration 15187 : loss : 0.047505, loss_ce: 0.026641
[01:59:44.510] iteration 15188 : loss : 0.048616, loss_ce: 0.018064
[01:59:44.810] iteration 15189 : loss : 0.055144, loss_ce: 0.033203
[01:59:45.110] iteration 15190 : loss : 0.039794, loss_ce: 0.009117
[01:59:45.411] iteration 15191 : loss : 0.048777, loss_ce: 0.015794
[01:59:45.712] iteration 15192 : loss : 0.112111, loss_ce: 0.009693
[01:59:46.013] iteration 15193 : loss : 0.096245, loss_ce: 0.008749
[01:59:46.312] iteration 15194 : loss : 0.059940, loss_ce: 0.012857
[01:59:46.609] iteration 15195 : loss : 0.053986, loss_ce: 0.019459
[01:59:46.909] iteration 15196 : loss : 0.055006, loss_ce: 0.009641
[01:59:47.205] iteration 15197 : loss : 0.061644, loss_ce: 0.016151
[01:59:47.507] iteration 15198 : loss : 0.043536, loss_ce: 0.010512
[01:59:47.803] iteration 15199 : loss : 0.030135, loss_ce: 0.008512
[01:59:48.104] iteration 15200 : loss : 0.040269, loss_ce: 0.011327
[01:59:48.421] iteration 15201 : loss : 0.052401, loss_ce: 0.019806
[01:59:48.714] iteration 15202 : loss : 0.115969, loss_ce: 0.007907
[01:59:49.017] iteration 15203 : loss : 0.046373, loss_ce: 0.013110
[01:59:49.320] iteration 15204 : loss : 0.044825, loss_ce: 0.012530
[01:59:49.619] iteration 15205 : loss : 0.052385, loss_ce: 0.008911
[01:59:49.917] iteration 15206 : loss : 0.045172, loss_ce: 0.016356
[01:59:50.217] iteration 15207 : loss : 0.055192, loss_ce: 0.013683
[01:59:50.521] iteration 15208 : loss : 0.043139, loss_ce: 0.007319
[01:59:50.819] iteration 15209 : loss : 0.043298, loss_ce: 0.016088
[01:59:51.120] iteration 15210 : loss : 0.050338, loss_ce: 0.010765
[01:59:51.425] iteration 15211 : loss : 0.114474, loss_ce: 0.022126
[01:59:51.729] iteration 15212 : loss : 0.052231, loss_ce: 0.014146
[01:59:52.033] iteration 15213 : loss : 0.123557, loss_ce: 0.010062
[01:59:52.333] iteration 15214 : loss : 0.041702, loss_ce: 0.011139
[01:59:52.639] iteration 15215 : loss : 0.051922, loss_ce: 0.012953
[01:59:52.940] iteration 15216 : loss : 0.046999, loss_ce: 0.016732
[01:59:53.246] iteration 15217 : loss : 0.053715, loss_ce: 0.010710
[01:59:53.550] iteration 15218 : loss : 0.042158, loss_ce: 0.012087
[01:59:53.853] iteration 15219 : loss : 0.222135, loss_ce: 0.006166
[01:59:54.154] iteration 15220 : loss : 0.039252, loss_ce: 0.009146
[01:59:54.476] iteration 15221 : loss : 0.057030, loss_ce: 0.018211
[01:59:54.780] iteration 15222 : loss : 0.282034, loss_ce: 0.005332
[01:59:55.082] iteration 15223 : loss : 0.098326, loss_ce: 0.009031
[01:59:55.387] iteration 15224 : loss : 0.073049, loss_ce: 0.014892
[01:59:55.689] iteration 15225 : loss : 0.045522, loss_ce: 0.017679
[01:59:55.992] iteration 15226 : loss : 0.220883, loss_ce: 0.004047
[01:59:56.296] iteration 15227 : loss : 0.047549, loss_ce: 0.020481
[01:59:56.599] iteration 15228 : loss : 0.056076, loss_ce: 0.014804
[01:59:56.896] iteration 15229 : loss : 0.099967, loss_ce: 0.009008
[01:59:57.199] iteration 15230 : loss : 0.044048, loss_ce: 0.014439
[01:59:57.506] iteration 15231 : loss : 0.051944, loss_ce: 0.021286
[01:59:57.810] iteration 15232 : loss : 0.109659, loss_ce: 0.020359
[01:59:58.112] iteration 15233 : loss : 0.105261, loss_ce: 0.007649
[01:59:58.416] iteration 15234 : loss : 0.065326, loss_ce: 0.014849
[01:59:58.718] iteration 15235 : loss : 0.046470, loss_ce: 0.013627
[01:59:59.020] iteration 15236 : loss : 0.036899, loss_ce: 0.013971
[01:59:59.327] iteration 15237 : loss : 0.056352, loss_ce: 0.024181
[01:59:59.629] iteration 15238 : loss : 0.092765, loss_ce: 0.011330
[01:59:59.931] iteration 15239 : loss : 0.117548, loss_ce: 0.008812
[02:00:00.233] iteration 15240 : loss : 0.055278, loss_ce: 0.019355
[02:00:00.551] iteration 15241 : loss : 0.048203, loss_ce: 0.011884
[02:00:00.855] iteration 15242 : loss : 0.047558, loss_ce: 0.016746
[02:00:01.155] iteration 15243 : loss : 0.057342, loss_ce: 0.014961
[02:00:01.456] iteration 15244 : loss : 0.038753, loss_ce: 0.013208
[02:00:01.760] iteration 15245 : loss : 0.037890, loss_ce: 0.011833
[02:00:02.062] iteration 15246 : loss : 0.105181, loss_ce: 0.010612
[02:00:02.368] iteration 15247 : loss : 0.167105, loss_ce: 0.004990
[02:00:02.669] iteration 15248 : loss : 0.044167, loss_ce: 0.010419
[02:00:02.973] iteration 15249 : loss : 0.117176, loss_ce: 0.013556
[02:00:03.277] iteration 15250 : loss : 0.044085, loss_ce: 0.017345
[02:00:03.578] iteration 15251 : loss : 0.040913, loss_ce: 0.013544
[02:00:03.881] iteration 15252 : loss : 0.049638, loss_ce: 0.016688
[02:00:04.186] iteration 15253 : loss : 0.038365, loss_ce: 0.018152
[02:00:04.490] iteration 15254 : loss : 0.036825, loss_ce: 0.005105
[02:00:04.792] iteration 15255 : loss : 0.112506, loss_ce: 0.008379
[02:00:05.097] iteration 15256 : loss : 0.108982, loss_ce: 0.007483
[02:00:05.398] iteration 15257 : loss : 0.048292, loss_ce: 0.019271
[02:00:05.696] iteration 15258 : loss : 0.042598, loss_ce: 0.014304
[02:00:05.999] iteration 15259 : loss : 0.066917, loss_ce: 0.015224
[02:00:06.302] iteration 15260 : loss : 0.046732, loss_ce: 0.013459
[02:00:06.621] iteration 15261 : loss : 0.048084, loss_ce: 0.015607
[02:00:06.921] iteration 15262 : loss : 0.052965, loss_ce: 0.018360
[02:00:07.225] iteration 15263 : loss : 0.070349, loss_ce: 0.017840
[02:00:07.529] iteration 15264 : loss : 0.060716, loss_ce: 0.011271
[02:00:07.835] iteration 15265 : loss : 0.124507, loss_ce: 0.006797
[02:00:08.144] iteration 15266 : loss : 0.052750, loss_ce: 0.016373
[02:00:08.449] iteration 15267 : loss : 0.062600, loss_ce: 0.011430
[02:00:08.752] iteration 15268 : loss : 0.110688, loss_ce: 0.014347
[02:00:09.057] iteration 15269 : loss : 0.046007, loss_ce: 0.016189
[02:00:09.362] iteration 15270 : loss : 0.047022, loss_ce: 0.012868
[02:00:09.665] iteration 15271 : loss : 0.049569, loss_ce: 0.014023
[02:00:09.967] iteration 15272 : loss : 0.045504, loss_ce: 0.012374
[02:00:10.277] iteration 15273 : loss : 0.042459, loss_ce: 0.014881
[02:00:10.580] iteration 15274 : loss : 0.052118, loss_ce: 0.006728
[02:00:10.889] iteration 15275 : loss : 0.046321, loss_ce: 0.016764
[02:00:11.192] iteration 15276 : loss : 0.110366, loss_ce: 0.012059
[02:00:11.495] iteration 15277 : loss : 0.096170, loss_ce: 0.011163
[02:00:11.800] iteration 15278 : loss : 0.048485, loss_ce: 0.022149
[02:00:12.111] iteration 15279 : loss : 0.103358, loss_ce: 0.008915
[02:00:12.408] iteration 15280 : loss : 0.041977, loss_ce: 0.018245
[02:00:12.726] iteration 15281 : loss : 0.056224, loss_ce: 0.021028
[02:00:13.034] iteration 15282 : loss : 0.044314, loss_ce: 0.023223
[02:00:13.341] iteration 15283 : loss : 0.056210, loss_ce: 0.017928
[02:00:13.640] iteration 15284 : loss : 0.117649, loss_ce: 0.011279
[02:00:13.948] iteration 15285 : loss : 0.043842, loss_ce: 0.019698
[02:00:14.257] iteration 15286 : loss : 0.077218, loss_ce: 0.009088
[02:00:14.556] iteration 15287 : loss : 0.038463, loss_ce: 0.012543
[02:00:14.861] iteration 15288 : loss : 0.045405, loss_ce: 0.011375
[02:00:15.174] iteration 15289 : loss : 0.055806, loss_ce: 0.027458
[02:00:15.273] iteration 15290 : loss : 0.235902, loss_ce: 0.007338
[02:00:36.389] iteration 15291 : loss : 0.039129, loss_ce: 0.020184
[02:00:36.684] iteration 15292 : loss : 0.050242, loss_ce: 0.011262
[02:00:36.985] iteration 15293 : loss : 0.039233, loss_ce: 0.009976
[02:00:37.281] iteration 15294 : loss : 0.049612, loss_ce: 0.017540
[02:00:37.577] iteration 15295 : loss : 0.034103, loss_ce: 0.010196
[02:00:37.876] iteration 15296 : loss : 0.062564, loss_ce: 0.014777
[02:00:38.174] iteration 15297 : loss : 0.052859, loss_ce: 0.019680
[02:00:38.470] iteration 15298 : loss : 0.039944, loss_ce: 0.013805
[02:00:38.765] iteration 15299 : loss : 0.045687, loss_ce: 0.014950
[02:00:39.059] iteration 15300 : loss : 0.050829, loss_ce: 0.005904
[02:00:39.383] iteration 15301 : loss : 0.042715, loss_ce: 0.013226
[02:00:39.686] iteration 15302 : loss : 0.111445, loss_ce: 0.012234
[02:00:39.986] iteration 15303 : loss : 0.056170, loss_ce: 0.021932
[02:00:40.291] iteration 15304 : loss : 0.052255, loss_ce: 0.012567
[02:00:40.591] iteration 15305 : loss : 0.046570, loss_ce: 0.015866
[02:00:40.895] iteration 15306 : loss : 0.039398, loss_ce: 0.012857
[02:00:41.198] iteration 15307 : loss : 0.043005, loss_ce: 0.014481
[02:00:41.496] iteration 15308 : loss : 0.047803, loss_ce: 0.006281
[02:00:41.794] iteration 15309 : loss : 0.058375, loss_ce: 0.019186
[02:00:42.092] iteration 15310 : loss : 0.108992, loss_ce: 0.007336
[02:00:42.389] iteration 15311 : loss : 0.042135, loss_ce: 0.011288
[02:00:42.683] iteration 15312 : loss : 0.049945, loss_ce: 0.009415
[02:00:42.982] iteration 15313 : loss : 0.049747, loss_ce: 0.017526
[02:00:43.278] iteration 15314 : loss : 0.038310, loss_ce: 0.019224
[02:00:43.576] iteration 15315 : loss : 0.106987, loss_ce: 0.007180
[02:00:43.874] iteration 15316 : loss : 0.039801, loss_ce: 0.017699
[02:00:44.170] iteration 15317 : loss : 0.039669, loss_ce: 0.009952
[02:00:44.464] iteration 15318 : loss : 0.043717, loss_ce: 0.009729
[02:00:44.769] iteration 15319 : loss : 0.099417, loss_ce: 0.009226
[02:00:45.061] iteration 15320 : loss : 0.045853, loss_ce: 0.011411
[02:00:45.378] iteration 15321 : loss : 0.041807, loss_ce: 0.015804
[02:00:45.675] iteration 15322 : loss : 0.050936, loss_ce: 0.020032
[02:00:45.975] iteration 15323 : loss : 0.105033, loss_ce: 0.009108
[02:00:46.270] iteration 15324 : loss : 0.044209, loss_ce: 0.011845
[02:00:46.569] iteration 15325 : loss : 0.048986, loss_ce: 0.024889
[02:00:46.868] iteration 15326 : loss : 0.050098, loss_ce: 0.011658
[02:00:47.167] iteration 15327 : loss : 0.042703, loss_ce: 0.022174
[02:00:47.465] iteration 15328 : loss : 0.043605, loss_ce: 0.017577
[02:00:47.762] iteration 15329 : loss : 0.043720, loss_ce: 0.011575
[02:00:48.061] iteration 15330 : loss : 0.096429, loss_ce: 0.009485
[02:00:48.356] iteration 15331 : loss : 0.047674, loss_ce: 0.020387
[02:00:48.654] iteration 15332 : loss : 0.052960, loss_ce: 0.014594
[02:00:48.956] iteration 15333 : loss : 0.102594, loss_ce: 0.015846
[02:00:49.259] iteration 15334 : loss : 0.049657, loss_ce: 0.019875
[02:00:49.559] iteration 15335 : loss : 0.098437, loss_ce: 0.010256
[02:00:49.856] iteration 15336 : loss : 0.047885, loss_ce: 0.018074
[02:00:50.154] iteration 15337 : loss : 0.060796, loss_ce: 0.011961
[02:00:50.453] iteration 15338 : loss : 0.053765, loss_ce: 0.010222
[02:00:50.755] iteration 15339 : loss : 0.058388, loss_ce: 0.018783
[02:00:51.058] iteration 15340 : loss : 0.046647, loss_ce: 0.012471
[02:00:51.369] iteration 15341 : loss : 0.053548, loss_ce: 0.012974
[02:00:51.670] iteration 15342 : loss : 0.044545, loss_ce: 0.009291
[02:00:51.968] iteration 15343 : loss : 0.106217, loss_ce: 0.009691
[02:00:52.271] iteration 15344 : loss : 0.050953, loss_ce: 0.016772
[02:00:52.569] iteration 15345 : loss : 0.103492, loss_ce: 0.007637
[02:00:52.866] iteration 15346 : loss : 0.054861, loss_ce: 0.014111
[02:00:53.163] iteration 15347 : loss : 0.054657, loss_ce: 0.011044
[02:00:53.466] iteration 15348 : loss : 0.045114, loss_ce: 0.016210
[02:00:53.766] iteration 15349 : loss : 0.049163, loss_ce: 0.020397
[02:00:54.064] iteration 15350 : loss : 0.108574, loss_ce: 0.014199
[02:00:54.372] iteration 15351 : loss : 0.052790, loss_ce: 0.008945
[02:00:54.677] iteration 15352 : loss : 0.060133, loss_ce: 0.014019
[02:00:54.981] iteration 15353 : loss : 0.040856, loss_ce: 0.021127
[02:00:55.281] iteration 15354 : loss : 0.056614, loss_ce: 0.015866
[02:00:55.585] iteration 15355 : loss : 0.066269, loss_ce: 0.009190
[02:00:55.890] iteration 15356 : loss : 0.051719, loss_ce: 0.011465
[02:00:56.197] iteration 15357 : loss : 0.059303, loss_ce: 0.012639
[02:00:56.491] iteration 15358 : loss : 0.049425, loss_ce: 0.017043
[02:00:56.792] iteration 15359 : loss : 0.051783, loss_ce: 0.016537
[02:00:57.096] iteration 15360 : loss : 0.172298, loss_ce: 0.005715
[02:00:57.407] iteration 15361 : loss : 0.048436, loss_ce: 0.027030
[02:00:57.706] iteration 15362 : loss : 0.102351, loss_ce: 0.011179
[02:00:58.005] iteration 15363 : loss : 0.037324, loss_ce: 0.009543
[02:00:58.301] iteration 15364 : loss : 0.046297, loss_ce: 0.011126
[02:00:58.594] iteration 15365 : loss : 0.052044, loss_ce: 0.020384
[02:00:58.896] iteration 15366 : loss : 0.052383, loss_ce: 0.020718
[02:00:59.196] iteration 15367 : loss : 0.058673, loss_ce: 0.012498
[02:00:59.492] iteration 15368 : loss : 0.052769, loss_ce: 0.021009
[02:00:59.790] iteration 15369 : loss : 0.100259, loss_ce: 0.011187
[02:01:00.093] iteration 15370 : loss : 0.091488, loss_ce: 0.011167
[02:01:00.393] iteration 15371 : loss : 0.044810, loss_ce: 0.019453
[02:01:00.692] iteration 15372 : loss : 0.099614, loss_ce: 0.016593
[02:01:00.996] iteration 15373 : loss : 0.047212, loss_ce: 0.015746
[02:01:01.292] iteration 15374 : loss : 0.065062, loss_ce: 0.006225
[02:01:01.591] iteration 15375 : loss : 0.036304, loss_ce: 0.016160
[02:01:01.887] iteration 15376 : loss : 0.052579, loss_ce: 0.019297
[02:01:02.185] iteration 15377 : loss : 0.041335, loss_ce: 0.011777
[02:01:02.482] iteration 15378 : loss : 0.083555, loss_ce: 0.013805
[02:01:02.783] iteration 15379 : loss : 0.108038, loss_ce: 0.014076
[02:01:03.077] iteration 15380 : loss : 0.097795, loss_ce: 0.010060
[02:01:03.397] iteration 15381 : loss : 0.049063, loss_ce: 0.017776
[02:01:03.693] iteration 15382 : loss : 0.048046, loss_ce: 0.012365
[02:01:03.990] iteration 15383 : loss : 0.060746, loss_ce: 0.014781
[02:01:04.286] iteration 15384 : loss : 0.053855, loss_ce: 0.015314
[02:01:04.584] iteration 15385 : loss : 0.038366, loss_ce: 0.008060
[02:01:04.888] iteration 15386 : loss : 0.040586, loss_ce: 0.013986
[02:01:05.191] iteration 15387 : loss : 0.045292, loss_ce: 0.011736
[02:01:05.493] iteration 15388 : loss : 0.103133, loss_ce: 0.017722
[02:01:05.791] iteration 15389 : loss : 0.056935, loss_ce: 0.019467
[02:01:06.085] iteration 15390 : loss : 0.047352, loss_ce: 0.012603
[02:01:06.384] iteration 15391 : loss : 0.042123, loss_ce: 0.015854
[02:01:06.681] iteration 15392 : loss : 0.037205, loss_ce: 0.009111
[02:01:06.978] iteration 15393 : loss : 0.046589, loss_ce: 0.019226
[02:01:07.276] iteration 15394 : loss : 0.051562, loss_ce: 0.011901
[02:01:07.571] iteration 15395 : loss : 0.063409, loss_ce: 0.011538
[02:01:07.869] iteration 15396 : loss : 0.096374, loss_ce: 0.012755
[02:01:08.167] iteration 15397 : loss : 0.106175, loss_ce: 0.021856
[02:01:08.473] iteration 15398 : loss : 0.162968, loss_ce: 0.008722
[02:01:08.773] iteration 15399 : loss : 0.099471, loss_ce: 0.006297
[02:01:09.076] iteration 15400 : loss : 0.044334, loss_ce: 0.014994
[02:01:09.396] iteration 15401 : loss : 0.048935, loss_ce: 0.014449
[02:01:09.701] iteration 15402 : loss : 0.103917, loss_ce: 0.011311
[02:01:10.003] iteration 15403 : loss : 0.159499, loss_ce: 0.007201
[02:01:10.302] iteration 15404 : loss : 0.037291, loss_ce: 0.006569
[02:01:10.600] iteration 15405 : loss : 0.053929, loss_ce: 0.011284
[02:01:10.898] iteration 15406 : loss : 0.043780, loss_ce: 0.014329
[02:01:11.196] iteration 15407 : loss : 0.034009, loss_ce: 0.008034
[02:01:11.496] iteration 15408 : loss : 0.104060, loss_ce: 0.007679
[02:01:11.792] iteration 15409 : loss : 0.044232, loss_ce: 0.014038
[02:01:12.094] iteration 15410 : loss : 0.036902, loss_ce: 0.013561
[02:01:12.408] iteration 15411 : loss : 0.048937, loss_ce: 0.024193
[02:01:12.712] iteration 15412 : loss : 0.056967, loss_ce: 0.014811
[02:01:13.017] iteration 15413 : loss : 0.040788, loss_ce: 0.011707
[02:01:13.331] iteration 15414 : loss : 0.051350, loss_ce: 0.013997
[02:01:13.635] iteration 15415 : loss : 0.055938, loss_ce: 0.012663
[02:01:13.944] iteration 15416 : loss : 0.051733, loss_ce: 0.013474
[02:01:14.251] iteration 15417 : loss : 0.049008, loss_ce: 0.021120
[02:01:14.562] iteration 15418 : loss : 0.113257, loss_ce: 0.011184
[02:01:14.866] iteration 15419 : loss : 0.057987, loss_ce: 0.025015
[02:01:15.170] iteration 15420 : loss : 0.056362, loss_ce: 0.012863
[02:01:15.511] iteration 15421 : loss : 0.102320, loss_ce: 0.008405
[02:01:15.820] iteration 15422 : loss : 0.100308, loss_ce: 0.007259
[02:01:16.125] iteration 15423 : loss : 0.055452, loss_ce: 0.011086
[02:01:16.435] iteration 15424 : loss : 0.062818, loss_ce: 0.013935
[02:01:16.746] iteration 15425 : loss : 0.042572, loss_ce: 0.013207
[02:01:17.052] iteration 15426 : loss : 0.049303, loss_ce: 0.013553
[02:01:17.363] iteration 15427 : loss : 0.052247, loss_ce: 0.009085
[02:01:17.671] iteration 15428 : loss : 0.049521, loss_ce: 0.017662
[02:01:17.758] iteration 15429 : loss : 0.431338, loss_ce: 0.003471
[02:01:36.291] iteration 15430 : loss : 0.035688, loss_ce: 0.007597
[02:01:36.592] iteration 15431 : loss : 0.047507, loss_ce: 0.021835
[02:01:36.892] iteration 15432 : loss : 0.044588, loss_ce: 0.019513
[02:01:37.195] iteration 15433 : loss : 0.054349, loss_ce: 0.014255
[02:01:37.496] iteration 15434 : loss : 0.054207, loss_ce: 0.014746
[02:01:37.796] iteration 15435 : loss : 0.046130, loss_ce: 0.015663
[02:01:38.093] iteration 15436 : loss : 0.058178, loss_ce: 0.010850
[02:01:38.394] iteration 15437 : loss : 0.058406, loss_ce: 0.022983
[02:01:38.689] iteration 15438 : loss : 0.053534, loss_ce: 0.021854
[02:01:38.983] iteration 15439 : loss : 0.044905, loss_ce: 0.010207
[02:01:39.279] iteration 15440 : loss : 0.063788, loss_ce: 0.011125
[02:01:39.592] iteration 15441 : loss : 0.045827, loss_ce: 0.024529
[02:01:39.887] iteration 15442 : loss : 0.105123, loss_ce: 0.014993
[02:01:40.185] iteration 15443 : loss : 0.041610, loss_ce: 0.017400
[02:01:40.480] iteration 15444 : loss : 0.042811, loss_ce: 0.016616
[02:01:40.779] iteration 15445 : loss : 0.053407, loss_ce: 0.016706
[02:01:41.079] iteration 15446 : loss : 0.045695, loss_ce: 0.012964
[02:01:41.373] iteration 15447 : loss : 0.107418, loss_ce: 0.013827
[02:01:41.667] iteration 15448 : loss : 0.103960, loss_ce: 0.011280
[02:01:41.964] iteration 15449 : loss : 0.035124, loss_ce: 0.006031
[02:01:42.260] iteration 15450 : loss : 0.044065, loss_ce: 0.013937
[02:01:42.556] iteration 15451 : loss : 0.044022, loss_ce: 0.020279
[02:01:42.855] iteration 15452 : loss : 0.041599, loss_ce: 0.015817
[02:01:43.153] iteration 15453 : loss : 0.045860, loss_ce: 0.020633
[02:01:43.449] iteration 15454 : loss : 0.037553, loss_ce: 0.010871
[02:01:43.751] iteration 15455 : loss : 0.053644, loss_ce: 0.014754
[02:01:44.048] iteration 15456 : loss : 0.147993, loss_ce: 0.003353
[02:01:44.352] iteration 15457 : loss : 0.053864, loss_ce: 0.016962
[02:01:44.656] iteration 15458 : loss : 0.154692, loss_ce: 0.009118
[02:01:44.961] iteration 15459 : loss : 0.095287, loss_ce: 0.007486
[02:01:45.265] iteration 15460 : loss : 0.070137, loss_ce: 0.013134
[02:01:45.582] iteration 15461 : loss : 0.059367, loss_ce: 0.015898
[02:01:45.889] iteration 15462 : loss : 0.048549, loss_ce: 0.010337
[02:01:46.193] iteration 15463 : loss : 0.046856, loss_ce: 0.021750
[02:01:46.495] iteration 15464 : loss : 0.103146, loss_ce: 0.009431
[02:01:46.792] iteration 15465 : loss : 0.045702, loss_ce: 0.015831
[02:01:47.090] iteration 15466 : loss : 0.045340, loss_ce: 0.008159
[02:01:47.388] iteration 15467 : loss : 0.115673, loss_ce: 0.008435
[02:01:47.688] iteration 15468 : loss : 0.102323, loss_ce: 0.008267
[02:01:47.989] iteration 15469 : loss : 0.047696, loss_ce: 0.019031
[02:01:48.284] iteration 15470 : loss : 0.070613, loss_ce: 0.013312
[02:01:48.582] iteration 15471 : loss : 0.281718, loss_ce: 0.009247
[02:01:48.883] iteration 15472 : loss : 0.054854, loss_ce: 0.012266
[02:01:49.181] iteration 15473 : loss : 0.103390, loss_ce: 0.006196
[02:01:49.478] iteration 15474 : loss : 0.046733, loss_ce: 0.011046
[02:01:49.779] iteration 15475 : loss : 0.041033, loss_ce: 0.009122
[02:01:50.077] iteration 15476 : loss : 0.051374, loss_ce: 0.014697
[02:01:50.383] iteration 15477 : loss : 0.052409, loss_ce: 0.017777
[02:01:50.683] iteration 15478 : loss : 0.054884, loss_ce: 0.011228
[02:01:50.979] iteration 15479 : loss : 0.047559, loss_ce: 0.017186
[02:01:51.276] iteration 15480 : loss : 0.048544, loss_ce: 0.007693
[02:01:51.588] iteration 15481 : loss : 0.044626, loss_ce: 0.014017
[02:01:51.890] iteration 15482 : loss : 0.057599, loss_ce: 0.016538
[02:01:52.187] iteration 15483 : loss : 0.055140, loss_ce: 0.009346
[02:01:52.491] iteration 15484 : loss : 0.107402, loss_ce: 0.014336
[02:01:52.793] iteration 15485 : loss : 0.051199, loss_ce: 0.009148
[02:01:53.092] iteration 15486 : loss : 0.044879, loss_ce: 0.009094
[02:01:53.387] iteration 15487 : loss : 0.060342, loss_ce: 0.012238
[02:01:53.682] iteration 15488 : loss : 0.049777, loss_ce: 0.017489
[02:01:53.986] iteration 15489 : loss : 0.046313, loss_ce: 0.020096
[02:01:54.284] iteration 15490 : loss : 0.041519, loss_ce: 0.009386
[02:01:54.581] iteration 15491 : loss : 0.045518, loss_ce: 0.016778
[02:01:54.884] iteration 15492 : loss : 0.044236, loss_ce: 0.018064
[02:01:55.179] iteration 15493 : loss : 0.033979, loss_ce: 0.008694
[02:01:55.477] iteration 15494 : loss : 0.048418, loss_ce: 0.019651
[02:01:55.779] iteration 15495 : loss : 0.105245, loss_ce: 0.009998
[02:01:56.080] iteration 15496 : loss : 0.063421, loss_ce: 0.008946
[02:01:56.382] iteration 15497 : loss : 0.049706, loss_ce: 0.019790
[02:01:56.682] iteration 15498 : loss : 0.123198, loss_ce: 0.005815
[02:01:56.981] iteration 15499 : loss : 0.054687, loss_ce: 0.009188
[02:01:57.282] iteration 15500 : loss : 0.053091, loss_ce: 0.007507
[02:01:57.606] iteration 15501 : loss : 0.039051, loss_ce: 0.016926
[02:01:57.906] iteration 15502 : loss : 0.047051, loss_ce: 0.014108
[02:01:58.208] iteration 15503 : loss : 0.100179, loss_ce: 0.007378
[02:01:58.510] iteration 15504 : loss : 0.064845, loss_ce: 0.013688
[02:01:58.810] iteration 15505 : loss : 0.052321, loss_ce: 0.020661
[02:01:59.110] iteration 15506 : loss : 0.046481, loss_ce: 0.017248
[02:01:59.412] iteration 15507 : loss : 0.104438, loss_ce: 0.006676
[02:01:59.712] iteration 15508 : loss : 0.078297, loss_ce: 0.013838
[02:02:00.014] iteration 15509 : loss : 0.039989, loss_ce: 0.014600
[02:02:00.315] iteration 15510 : loss : 0.060028, loss_ce: 0.015251
[02:02:00.614] iteration 15511 : loss : 0.061827, loss_ce: 0.015478
[02:02:00.918] iteration 15512 : loss : 0.043205, loss_ce: 0.016132
[02:02:01.221] iteration 15513 : loss : 0.045850, loss_ce: 0.011189
[02:02:01.518] iteration 15514 : loss : 0.053504, loss_ce: 0.016011
[02:02:01.816] iteration 15515 : loss : 0.057958, loss_ce: 0.022589
[02:02:02.121] iteration 15516 : loss : 0.046412, loss_ce: 0.015636
[02:02:02.426] iteration 15517 : loss : 0.044746, loss_ce: 0.009599
[02:02:02.729] iteration 15518 : loss : 0.042758, loss_ce: 0.019820
[02:02:03.030] iteration 15519 : loss : 0.037514, loss_ce: 0.010485
[02:02:03.331] iteration 15520 : loss : 0.052199, loss_ce: 0.017375
[02:02:03.647] iteration 15521 : loss : 0.040585, loss_ce: 0.017741
[02:02:03.948] iteration 15522 : loss : 0.067591, loss_ce: 0.011245
[02:02:04.254] iteration 15523 : loss : 0.048708, loss_ce: 0.020633
[02:02:04.559] iteration 15524 : loss : 0.057686, loss_ce: 0.011005
[02:02:04.863] iteration 15525 : loss : 0.050110, loss_ce: 0.010262
[02:02:05.163] iteration 15526 : loss : 0.105352, loss_ce: 0.010944
[02:02:05.466] iteration 15527 : loss : 0.049301, loss_ce: 0.022910
[02:02:05.771] iteration 15528 : loss : 0.040433, loss_ce: 0.014991
[02:02:06.073] iteration 15529 : loss : 0.106621, loss_ce: 0.011962
[02:02:06.378] iteration 15530 : loss : 0.068836, loss_ce: 0.025518
[02:02:06.687] iteration 15531 : loss : 0.169160, loss_ce: 0.009291
[02:02:06.987] iteration 15532 : loss : 0.125930, loss_ce: 0.011844
[02:02:07.293] iteration 15533 : loss : 0.042599, loss_ce: 0.019641
[02:02:07.600] iteration 15534 : loss : 0.100745, loss_ce: 0.011271
[02:02:07.907] iteration 15535 : loss : 0.054116, loss_ce: 0.015316
[02:02:08.216] iteration 15536 : loss : 0.049008, loss_ce: 0.017372
[02:02:08.517] iteration 15537 : loss : 0.045459, loss_ce: 0.015936
[02:02:08.817] iteration 15538 : loss : 0.057161, loss_ce: 0.020951
[02:02:09.121] iteration 15539 : loss : 0.037475, loss_ce: 0.012236
[02:02:09.426] iteration 15540 : loss : 0.045811, loss_ce: 0.016522
[02:02:09.748] iteration 15541 : loss : 0.042385, loss_ce: 0.012711
[02:02:10.047] iteration 15542 : loss : 0.166315, loss_ce: 0.006117
[02:02:10.350] iteration 15543 : loss : 0.052660, loss_ce: 0.023440
[02:02:10.656] iteration 15544 : loss : 0.032066, loss_ce: 0.012151
[02:02:10.960] iteration 15545 : loss : 0.045678, loss_ce: 0.016021
[02:02:11.264] iteration 15546 : loss : 0.055525, loss_ce: 0.008959
[02:02:11.566] iteration 15547 : loss : 0.047584, loss_ce: 0.017732
[02:02:11.871] iteration 15548 : loss : 0.051564, loss_ce: 0.013984
[02:02:12.183] iteration 15549 : loss : 0.054685, loss_ce: 0.017224
[02:02:12.487] iteration 15550 : loss : 0.063925, loss_ce: 0.018589
[02:02:12.792] iteration 15551 : loss : 0.062252, loss_ce: 0.010751
[02:02:13.096] iteration 15552 : loss : 0.046756, loss_ce: 0.016416
[02:02:13.409] iteration 15553 : loss : 0.044039, loss_ce: 0.015506
[02:02:13.715] iteration 15554 : loss : 0.106130, loss_ce: 0.010305
[02:02:14.019] iteration 15555 : loss : 0.154678, loss_ce: 0.005829
[02:02:14.319] iteration 15556 : loss : 0.040863, loss_ce: 0.018833
[02:02:14.631] iteration 15557 : loss : 0.046192, loss_ce: 0.018031
[02:02:14.938] iteration 15558 : loss : 0.050618, loss_ce: 0.017891
[02:02:15.249] iteration 15559 : loss : 0.042090, loss_ce: 0.011602
[02:02:15.558] iteration 15560 : loss : 0.054885, loss_ce: 0.009707
[02:02:15.905] iteration 15561 : loss : 0.110463, loss_ce: 0.016834
[02:02:16.212] iteration 15562 : loss : 0.119397, loss_ce: 0.011170
[02:02:16.522] iteration 15563 : loss : 0.101854, loss_ce: 0.012583
[02:02:16.836] iteration 15564 : loss : 0.043461, loss_ce: 0.008697
[02:02:17.145] iteration 15565 : loss : 0.104016, loss_ce: 0.014305
[02:02:17.455] iteration 15566 : loss : 0.100904, loss_ce: 0.014819
[02:02:17.768] iteration 15567 : loss : 0.108896, loss_ce: 0.012661
[02:02:17.844] iteration 15568 : loss : 0.407021, loss_ce: 0.005795
[02:02:36.670] iteration 15569 : loss : 0.059445, loss_ce: 0.020850
[02:02:36.970] iteration 15570 : loss : 0.109441, loss_ce: 0.009837
[02:02:37.272] iteration 15571 : loss : 0.064238, loss_ce: 0.011038
[02:02:37.577] iteration 15572 : loss : 0.046850, loss_ce: 0.019128
[02:02:37.880] iteration 15573 : loss : 0.106312, loss_ce: 0.017297
[02:02:38.176] iteration 15574 : loss : 0.112287, loss_ce: 0.017919
[02:02:38.473] iteration 15575 : loss : 0.049197, loss_ce: 0.012554
[02:02:38.773] iteration 15576 : loss : 0.060422, loss_ce: 0.011302
[02:02:39.074] iteration 15577 : loss : 0.046714, loss_ce: 0.019815
[02:02:39.371] iteration 15578 : loss : 0.110035, loss_ce: 0.017401
[02:02:39.669] iteration 15579 : loss : 0.156290, loss_ce: 0.014149
[02:02:39.965] iteration 15580 : loss : 0.103844, loss_ce: 0.015078
[02:02:40.274] iteration 15581 : loss : 0.050543, loss_ce: 0.020176
[02:02:40.573] iteration 15582 : loss : 0.044745, loss_ce: 0.021623
[02:02:40.873] iteration 15583 : loss : 0.103331, loss_ce: 0.009697
[02:02:41.171] iteration 15584 : loss : 0.050890, loss_ce: 0.008532
[02:02:41.467] iteration 15585 : loss : 0.049042, loss_ce: 0.021631
[02:02:41.763] iteration 15586 : loss : 0.102485, loss_ce: 0.010198
[02:02:42.071] iteration 15587 : loss : 0.055915, loss_ce: 0.029445
[02:02:42.365] iteration 15588 : loss : 0.045313, loss_ce: 0.016446
[02:02:42.670] iteration 15589 : loss : 0.061553, loss_ce: 0.009506
[02:02:42.963] iteration 15590 : loss : 0.039413, loss_ce: 0.008010
[02:02:43.260] iteration 15591 : loss : 0.045068, loss_ce: 0.007189
[02:02:43.554] iteration 15592 : loss : 0.047006, loss_ce: 0.006499
[02:02:43.855] iteration 15593 : loss : 0.036753, loss_ce: 0.010351
[02:02:44.153] iteration 15594 : loss : 0.041724, loss_ce: 0.015026
[02:02:44.452] iteration 15595 : loss : 0.046463, loss_ce: 0.010730
[02:02:44.751] iteration 15596 : loss : 0.046611, loss_ce: 0.018497
[02:02:45.049] iteration 15597 : loss : 0.042607, loss_ce: 0.013919
[02:02:45.345] iteration 15598 : loss : 0.035961, loss_ce: 0.008702
[02:02:45.647] iteration 15599 : loss : 0.045159, loss_ce: 0.011963
[02:02:45.940] iteration 15600 : loss : 0.047831, loss_ce: 0.017364
[02:02:46.260] iteration 15601 : loss : 0.108222, loss_ce: 0.023972
[02:02:46.559] iteration 15602 : loss : 0.044591, loss_ce: 0.018658
[02:02:46.857] iteration 15603 : loss : 0.053083, loss_ce: 0.010018
[02:02:47.155] iteration 15604 : loss : 0.056280, loss_ce: 0.009397
[02:02:47.452] iteration 15605 : loss : 0.057101, loss_ce: 0.011419
[02:02:47.748] iteration 15606 : loss : 0.048824, loss_ce: 0.014884
[02:02:48.042] iteration 15607 : loss : 0.042721, loss_ce: 0.013593
[02:02:48.338] iteration 15608 : loss : 0.055517, loss_ce: 0.017728
[02:02:48.636] iteration 15609 : loss : 0.051437, loss_ce: 0.011920
[02:02:48.931] iteration 15610 : loss : 0.059274, loss_ce: 0.008662
[02:02:49.230] iteration 15611 : loss : 0.064804, loss_ce: 0.024546
[02:02:49.536] iteration 15612 : loss : 0.346016, loss_ce: 0.003726
[02:02:49.838] iteration 15613 : loss : 0.065296, loss_ce: 0.010091
[02:02:50.137] iteration 15614 : loss : 0.051725, loss_ce: 0.011235
[02:02:50.440] iteration 15615 : loss : 0.043315, loss_ce: 0.010353
[02:02:50.746] iteration 15616 : loss : 0.049662, loss_ce: 0.020503
[02:02:51.052] iteration 15617 : loss : 0.223777, loss_ce: 0.004924
[02:02:51.354] iteration 15618 : loss : 0.044451, loss_ce: 0.012996
[02:02:51.655] iteration 15619 : loss : 0.102218, loss_ce: 0.019908
[02:02:51.959] iteration 15620 : loss : 0.047997, loss_ce: 0.021188
[02:02:52.280] iteration 15621 : loss : 0.047123, loss_ce: 0.009361
[02:02:52.579] iteration 15622 : loss : 0.050546, loss_ce: 0.020540
[02:02:52.883] iteration 15623 : loss : 0.039232, loss_ce: 0.016092
[02:02:53.186] iteration 15624 : loss : 0.037588, loss_ce: 0.016879
[02:02:53.484] iteration 15625 : loss : 0.169736, loss_ce: 0.005304
[02:02:53.789] iteration 15626 : loss : 0.049593, loss_ce: 0.015629
[02:02:54.098] iteration 15627 : loss : 0.037976, loss_ce: 0.007758
[02:02:54.398] iteration 15628 : loss : 0.045575, loss_ce: 0.015780
[02:02:54.700] iteration 15629 : loss : 0.046583, loss_ce: 0.018222
[02:02:55.006] iteration 15630 : loss : 0.061280, loss_ce: 0.012288
[02:02:55.308] iteration 15631 : loss : 0.049148, loss_ce: 0.011213
[02:02:55.607] iteration 15632 : loss : 0.038587, loss_ce: 0.016837
[02:02:55.912] iteration 15633 : loss : 0.112480, loss_ce: 0.012100
[02:02:56.215] iteration 15634 : loss : 0.053112, loss_ce: 0.018366
[02:02:56.518] iteration 15635 : loss : 0.107433, loss_ce: 0.013263
[02:02:56.821] iteration 15636 : loss : 0.051821, loss_ce: 0.016769
[02:02:57.124] iteration 15637 : loss : 0.041195, loss_ce: 0.005390
[02:02:57.427] iteration 15638 : loss : 0.051071, loss_ce: 0.017198
[02:02:57.729] iteration 15639 : loss : 0.173740, loss_ce: 0.008963
[02:02:58.035] iteration 15640 : loss : 0.050318, loss_ce: 0.016884
[02:02:58.356] iteration 15641 : loss : 0.051506, loss_ce: 0.018595
[02:02:58.655] iteration 15642 : loss : 0.053307, loss_ce: 0.021746
[02:02:58.957] iteration 15643 : loss : 0.099854, loss_ce: 0.008339
[02:02:59.255] iteration 15644 : loss : 0.101494, loss_ce: 0.009200
[02:02:59.561] iteration 15645 : loss : 0.050512, loss_ce: 0.011476
[02:02:59.865] iteration 15646 : loss : 0.101845, loss_ce: 0.011797
[02:03:00.171] iteration 15647 : loss : 0.043564, loss_ce: 0.014211
[02:03:00.474] iteration 15648 : loss : 0.052800, loss_ce: 0.014461
[02:03:00.778] iteration 15649 : loss : 0.049170, loss_ce: 0.021168
[02:03:01.086] iteration 15650 : loss : 0.053427, loss_ce: 0.016792
[02:03:01.387] iteration 15651 : loss : 0.040001, loss_ce: 0.018531
[02:03:01.689] iteration 15652 : loss : 0.070843, loss_ce: 0.019688
[02:03:01.995] iteration 15653 : loss : 0.037148, loss_ce: 0.004996
[02:03:02.298] iteration 15654 : loss : 0.133537, loss_ce: 0.012113
[02:03:02.603] iteration 15655 : loss : 0.047357, loss_ce: 0.019340
[02:03:02.905] iteration 15656 : loss : 0.047357, loss_ce: 0.016241
[02:03:03.209] iteration 15657 : loss : 0.044783, loss_ce: 0.018238
[02:03:03.514] iteration 15658 : loss : 0.049078, loss_ce: 0.017243
[02:03:03.815] iteration 15659 : loss : 0.108458, loss_ce: 0.019961
[02:03:04.114] iteration 15660 : loss : 0.045733, loss_ce: 0.013462
[02:03:04.432] iteration 15661 : loss : 0.048927, loss_ce: 0.014899
[02:03:04.731] iteration 15662 : loss : 0.037906, loss_ce: 0.013877
[02:03:05.035] iteration 15663 : loss : 0.102502, loss_ce: 0.016489
[02:03:05.343] iteration 15664 : loss : 0.046831, loss_ce: 0.021098
[02:03:05.643] iteration 15665 : loss : 0.064388, loss_ce: 0.014280
[02:03:05.949] iteration 15666 : loss : 0.043197, loss_ce: 0.010746
[02:03:06.251] iteration 15667 : loss : 0.112774, loss_ce: 0.009581
[02:03:06.551] iteration 15668 : loss : 0.080274, loss_ce: 0.011164
[02:03:06.853] iteration 15669 : loss : 0.123344, loss_ce: 0.010783
[02:03:07.160] iteration 15670 : loss : 0.109233, loss_ce: 0.007129
[02:03:07.462] iteration 15671 : loss : 0.039651, loss_ce: 0.014219
[02:03:07.766] iteration 15672 : loss : 0.040804, loss_ce: 0.011026
[02:03:08.073] iteration 15673 : loss : 0.050345, loss_ce: 0.017827
[02:03:08.373] iteration 15674 : loss : 0.045904, loss_ce: 0.009397
[02:03:08.674] iteration 15675 : loss : 0.114303, loss_ce: 0.006003
[02:03:08.978] iteration 15676 : loss : 0.059050, loss_ce: 0.021149
[02:03:09.284] iteration 15677 : loss : 0.083990, loss_ce: 0.009526
[02:03:09.587] iteration 15678 : loss : 0.037054, loss_ce: 0.012974
[02:03:09.896] iteration 15679 : loss : 0.043931, loss_ce: 0.010064
[02:03:10.202] iteration 15680 : loss : 0.044200, loss_ce: 0.017240
[02:03:10.522] iteration 15681 : loss : 0.046078, loss_ce: 0.016258
[02:03:10.822] iteration 15682 : loss : 0.039891, loss_ce: 0.012572
[02:03:11.122] iteration 15683 : loss : 0.045741, loss_ce: 0.011371
[02:03:11.422] iteration 15684 : loss : 0.068517, loss_ce: 0.011032
[02:03:11.720] iteration 15685 : loss : 0.046125, loss_ce: 0.011580
[02:03:12.019] iteration 15686 : loss : 0.100745, loss_ce: 0.006589
[02:03:12.314] iteration 15687 : loss : 0.057085, loss_ce: 0.013389
[02:03:12.614] iteration 15688 : loss : 0.061204, loss_ce: 0.014926
[02:03:12.912] iteration 15689 : loss : 0.037921, loss_ce: 0.013154
[02:03:13.210] iteration 15690 : loss : 0.050849, loss_ce: 0.010505
[02:03:13.514] iteration 15691 : loss : 0.045134, loss_ce: 0.015459
[02:03:13.818] iteration 15692 : loss : 0.104766, loss_ce: 0.009231
[02:03:14.123] iteration 15693 : loss : 0.044688, loss_ce: 0.013622
[02:03:14.435] iteration 15694 : loss : 0.085427, loss_ce: 0.024549
[02:03:14.742] iteration 15695 : loss : 0.047474, loss_ce: 0.020446
[02:03:15.043] iteration 15696 : loss : 0.109115, loss_ce: 0.011655
[02:03:15.344] iteration 15697 : loss : 0.042182, loss_ce: 0.020359
[02:03:15.648] iteration 15698 : loss : 0.074207, loss_ce: 0.011848
[02:03:15.954] iteration 15699 : loss : 0.047350, loss_ce: 0.016793
[02:03:16.260] iteration 15700 : loss : 0.090584, loss_ce: 0.003862
[02:03:16.605] iteration 15701 : loss : 0.046704, loss_ce: 0.016834
[02:03:16.912] iteration 15702 : loss : 0.049933, loss_ce: 0.010259
[02:03:17.217] iteration 15703 : loss : 0.049899, loss_ce: 0.015242
[02:03:17.526] iteration 15704 : loss : 0.040796, loss_ce: 0.017260
[02:03:17.831] iteration 15705 : loss : 0.049027, loss_ce: 0.009024
[02:03:18.135] iteration 15706 : loss : 0.057222, loss_ce: 0.013015
[02:03:18.219] iteration 15707 : loss : 0.045637, loss_ce: 0.000013
[02:03:35.937] iteration 15708 : loss : 0.089464, loss_ce: 0.003781
[02:03:36.239] iteration 15709 : loss : 0.051888, loss_ce: 0.012138
[02:03:36.538] iteration 15710 : loss : 0.044357, loss_ce: 0.012835
[02:03:36.839] iteration 15711 : loss : 0.111123, loss_ce: 0.009595
[02:03:37.137] iteration 15712 : loss : 0.058576, loss_ce: 0.015175
[02:03:37.439] iteration 15713 : loss : 0.156435, loss_ce: 0.009987
[02:03:37.740] iteration 15714 : loss : 0.061688, loss_ce: 0.011567
[02:03:38.040] iteration 15715 : loss : 0.100999, loss_ce: 0.011292
[02:03:38.346] iteration 15716 : loss : 0.099929, loss_ce: 0.016013
[02:03:38.651] iteration 15717 : loss : 0.045655, loss_ce: 0.022388
[02:03:38.952] iteration 15718 : loss : 0.049412, loss_ce: 0.006464
[02:03:39.256] iteration 15719 : loss : 0.043358, loss_ce: 0.020012
[02:03:39.558] iteration 15720 : loss : 0.164530, loss_ce: 0.010414
[02:03:39.888] iteration 15721 : loss : 0.057921, loss_ce: 0.018623
[02:03:40.191] iteration 15722 : loss : 0.051064, loss_ce: 0.016187
[02:03:40.499] iteration 15723 : loss : 0.106843, loss_ce: 0.012984
[02:03:40.807] iteration 15724 : loss : 0.112229, loss_ce: 0.012716
[02:03:41.114] iteration 15725 : loss : 0.050483, loss_ce: 0.019920
[02:03:41.417] iteration 15726 : loss : 0.066953, loss_ce: 0.011503
[02:03:41.718] iteration 15727 : loss : 0.054888, loss_ce: 0.008509
[02:03:42.022] iteration 15728 : loss : 0.059392, loss_ce: 0.015109
[02:03:42.319] iteration 15729 : loss : 0.052000, loss_ce: 0.021129
[02:03:42.619] iteration 15730 : loss : 0.047585, loss_ce: 0.014276
[02:03:42.920] iteration 15731 : loss : 0.047335, loss_ce: 0.015962
[02:03:43.225] iteration 15732 : loss : 0.050521, loss_ce: 0.006905
[02:03:43.532] iteration 15733 : loss : 0.046849, loss_ce: 0.014039
[02:03:43.835] iteration 15734 : loss : 0.040561, loss_ce: 0.005466
[02:03:44.140] iteration 15735 : loss : 0.106089, loss_ce: 0.009090
[02:03:44.438] iteration 15736 : loss : 0.036552, loss_ce: 0.012532
[02:03:44.738] iteration 15737 : loss : 0.109112, loss_ce: 0.016623
[02:03:45.041] iteration 15738 : loss : 0.060523, loss_ce: 0.016553
[02:03:45.339] iteration 15739 : loss : 0.064505, loss_ce: 0.016222
[02:03:45.644] iteration 15740 : loss : 0.042986, loss_ce: 0.009320
[02:03:45.964] iteration 15741 : loss : 0.040336, loss_ce: 0.006794
[02:03:46.258] iteration 15742 : loss : 0.062085, loss_ce: 0.011569
[02:03:46.555] iteration 15743 : loss : 0.049513, loss_ce: 0.016550
[02:03:46.856] iteration 15744 : loss : 0.041743, loss_ce: 0.010141
[02:03:47.155] iteration 15745 : loss : 0.048860, loss_ce: 0.011713
[02:03:47.455] iteration 15746 : loss : 0.040753, loss_ce: 0.015870
[02:03:47.751] iteration 15747 : loss : 0.041199, loss_ce: 0.016232
[02:03:48.048] iteration 15748 : loss : 0.054655, loss_ce: 0.024565
[02:03:48.344] iteration 15749 : loss : 0.049479, loss_ce: 0.020022
[02:03:48.641] iteration 15750 : loss : 0.104836, loss_ce: 0.013989
[02:03:48.936] iteration 15751 : loss : 0.050338, loss_ce: 0.014219
[02:03:49.237] iteration 15752 : loss : 0.040745, loss_ce: 0.009977
[02:03:49.534] iteration 15753 : loss : 0.122982, loss_ce: 0.005091
[02:03:49.836] iteration 15754 : loss : 0.160922, loss_ce: 0.005688
[02:03:50.133] iteration 15755 : loss : 0.105392, loss_ce: 0.006590
[02:03:50.432] iteration 15756 : loss : 0.064168, loss_ce: 0.013072
[02:03:50.730] iteration 15757 : loss : 0.102885, loss_ce: 0.010673
[02:03:51.030] iteration 15758 : loss : 0.038420, loss_ce: 0.012501
[02:03:51.330] iteration 15759 : loss : 0.038163, loss_ce: 0.015846
[02:03:51.626] iteration 15760 : loss : 0.047965, loss_ce: 0.027372
[02:03:51.944] iteration 15761 : loss : 0.047756, loss_ce: 0.015012
[02:03:52.240] iteration 15762 : loss : 0.040342, loss_ce: 0.012144
[02:03:52.533] iteration 15763 : loss : 0.042362, loss_ce: 0.013248
[02:03:52.832] iteration 15764 : loss : 0.043290, loss_ce: 0.015569
[02:03:53.126] iteration 15765 : loss : 0.052645, loss_ce: 0.015861
[02:03:53.423] iteration 15766 : loss : 0.114226, loss_ce: 0.014598
[02:03:53.722] iteration 15767 : loss : 0.053871, loss_ce: 0.015799
[02:03:54.022] iteration 15768 : loss : 0.075041, loss_ce: 0.011153
[02:03:54.325] iteration 15769 : loss : 0.035879, loss_ce: 0.006217
[02:03:54.634] iteration 15770 : loss : 0.055865, loss_ce: 0.023959
[02:03:54.932] iteration 15771 : loss : 0.047888, loss_ce: 0.016107
[02:03:55.235] iteration 15772 : loss : 0.097613, loss_ce: 0.014634
[02:03:55.537] iteration 15773 : loss : 0.052018, loss_ce: 0.011515
[02:03:55.835] iteration 15774 : loss : 0.045835, loss_ce: 0.016456
[02:03:56.137] iteration 15775 : loss : 0.039799, loss_ce: 0.015199
[02:03:56.437] iteration 15776 : loss : 0.057910, loss_ce: 0.014808
[02:03:56.739] iteration 15777 : loss : 0.162241, loss_ce: 0.015183
[02:03:57.044] iteration 15778 : loss : 0.039152, loss_ce: 0.016907
[02:03:57.348] iteration 15779 : loss : 0.042325, loss_ce: 0.008752
[02:03:57.647] iteration 15780 : loss : 0.055774, loss_ce: 0.009022
[02:03:57.969] iteration 15781 : loss : 0.042916, loss_ce: 0.010142
[02:03:58.272] iteration 15782 : loss : 0.060239, loss_ce: 0.010293
[02:03:58.575] iteration 15783 : loss : 0.045875, loss_ce: 0.017181
[02:03:58.886] iteration 15784 : loss : 0.042002, loss_ce: 0.017885
[02:03:59.189] iteration 15785 : loss : 0.101278, loss_ce: 0.012301
[02:03:59.492] iteration 15786 : loss : 0.044805, loss_ce: 0.014439
[02:03:59.792] iteration 15787 : loss : 0.044239, loss_ce: 0.007652
[02:04:00.093] iteration 15788 : loss : 0.044165, loss_ce: 0.015123
[02:04:00.393] iteration 15789 : loss : 0.043117, loss_ce: 0.016060
[02:04:00.700] iteration 15790 : loss : 0.053048, loss_ce: 0.016442
[02:04:01.000] iteration 15791 : loss : 0.043728, loss_ce: 0.014468
[02:04:01.300] iteration 15792 : loss : 0.059156, loss_ce: 0.017425
[02:04:01.601] iteration 15793 : loss : 0.046663, loss_ce: 0.022098
[02:04:01.908] iteration 15794 : loss : 0.056485, loss_ce: 0.014333
[02:04:02.206] iteration 15795 : loss : 0.038765, loss_ce: 0.013285
[02:04:02.509] iteration 15796 : loss : 0.035083, loss_ce: 0.018925
[02:04:02.815] iteration 15797 : loss : 0.048603, loss_ce: 0.014458
[02:04:03.117] iteration 15798 : loss : 0.044790, loss_ce: 0.011186
[02:04:03.418] iteration 15799 : loss : 0.061201, loss_ce: 0.016855
[02:04:03.720] iteration 15800 : loss : 0.056039, loss_ce: 0.008175
[02:04:04.040] iteration 15801 : loss : 0.040109, loss_ce: 0.013800
[02:04:04.338] iteration 15802 : loss : 0.044578, loss_ce: 0.009678
[02:04:04.642] iteration 15803 : loss : 0.049889, loss_ce: 0.012006
[02:04:04.945] iteration 15804 : loss : 0.043396, loss_ce: 0.017480
[02:04:05.247] iteration 15805 : loss : 0.055421, loss_ce: 0.014482
[02:04:05.552] iteration 15806 : loss : 0.061883, loss_ce: 0.018452
[02:04:05.853] iteration 15807 : loss : 0.037268, loss_ce: 0.017966
[02:04:06.155] iteration 15808 : loss : 0.047320, loss_ce: 0.015891
[02:04:06.461] iteration 15809 : loss : 0.056181, loss_ce: 0.015758
[02:04:06.765] iteration 15810 : loss : 0.047884, loss_ce: 0.016670
[02:04:07.068] iteration 15811 : loss : 0.101779, loss_ce: 0.010089
[02:04:07.369] iteration 15812 : loss : 0.040245, loss_ce: 0.019278
[02:04:07.671] iteration 15813 : loss : 0.111732, loss_ce: 0.012430
[02:04:07.979] iteration 15814 : loss : 0.038614, loss_ce: 0.011664
[02:04:08.281] iteration 15815 : loss : 0.047216, loss_ce: 0.019748
[02:04:08.586] iteration 15816 : loss : 0.101001, loss_ce: 0.006321
[02:04:08.887] iteration 15817 : loss : 0.045962, loss_ce: 0.013107
[02:04:09.190] iteration 15818 : loss : 0.043079, loss_ce: 0.017450
[02:04:09.492] iteration 15819 : loss : 0.051945, loss_ce: 0.017911
[02:04:09.797] iteration 15820 : loss : 0.113578, loss_ce: 0.007805
[02:04:10.112] iteration 15821 : loss : 0.039508, loss_ce: 0.013260
[02:04:10.417] iteration 15822 : loss : 0.154216, loss_ce: 0.009023
[02:04:10.717] iteration 15823 : loss : 0.042996, loss_ce: 0.013616
[02:04:11.017] iteration 15824 : loss : 0.042563, loss_ce: 0.016335
[02:04:11.321] iteration 15825 : loss : 0.161710, loss_ce: 0.006169
[02:04:11.618] iteration 15826 : loss : 0.105697, loss_ce: 0.016897
[02:04:11.922] iteration 15827 : loss : 0.041600, loss_ce: 0.013269
[02:04:12.229] iteration 15828 : loss : 0.042991, loss_ce: 0.017447
[02:04:12.533] iteration 15829 : loss : 0.050790, loss_ce: 0.012727
[02:04:12.842] iteration 15830 : loss : 0.045092, loss_ce: 0.009817
[02:04:13.152] iteration 15831 : loss : 0.054441, loss_ce: 0.010661
[02:04:13.458] iteration 15832 : loss : 0.044995, loss_ce: 0.011512
[02:04:13.771] iteration 15833 : loss : 0.070003, loss_ce: 0.017732
[02:04:14.072] iteration 15834 : loss : 0.281157, loss_ce: 0.005946
[02:04:14.386] iteration 15835 : loss : 0.096414, loss_ce: 0.006078
[02:04:14.697] iteration 15836 : loss : 0.040648, loss_ce: 0.016931
[02:04:15.009] iteration 15837 : loss : 0.157938, loss_ce: 0.006072
[02:04:15.322] iteration 15838 : loss : 0.044705, loss_ce: 0.009924
[02:04:15.632] iteration 15839 : loss : 0.045965, loss_ce: 0.018623
[02:04:15.939] iteration 15840 : loss : 0.047493, loss_ce: 0.013405
[02:04:16.288] iteration 15841 : loss : 0.043729, loss_ce: 0.016120
[02:04:16.593] iteration 15842 : loss : 0.048985, loss_ce: 0.018874
[02:04:16.895] iteration 15843 : loss : 0.053968, loss_ce: 0.016930
[02:04:17.201] iteration 15844 : loss : 0.042720, loss_ce: 0.010008
[02:04:17.505] iteration 15845 : loss : 0.102029, loss_ce: 0.010492
[02:04:17.581] iteration 15846 : loss : 0.058498, loss_ce: 0.018606
[02:04:37.778] iteration 15847 : loss : 0.037080, loss_ce: 0.007340
[02:04:38.083] iteration 15848 : loss : 0.059091, loss_ce: 0.014099
[02:04:38.387] iteration 15849 : loss : 0.045575, loss_ce: 0.014447
[02:04:38.691] iteration 15850 : loss : 0.057932, loss_ce: 0.021930
[02:04:38.990] iteration 15851 : loss : 0.038838, loss_ce: 0.009844
[02:04:39.287] iteration 15852 : loss : 0.048372, loss_ce: 0.015252
[02:04:39.583] iteration 15853 : loss : 0.112165, loss_ce: 0.011025
[02:04:39.878] iteration 15854 : loss : 0.048502, loss_ce: 0.009856
[02:04:40.177] iteration 15855 : loss : 0.099187, loss_ce: 0.010180
[02:04:40.474] iteration 15856 : loss : 0.044054, loss_ce: 0.008614
[02:04:40.771] iteration 15857 : loss : 0.045575, loss_ce: 0.010748
[02:04:41.062] iteration 15858 : loss : 0.050679, loss_ce: 0.011496
[02:04:41.359] iteration 15859 : loss : 0.051568, loss_ce: 0.019042
[02:04:41.657] iteration 15860 : loss : 0.166902, loss_ce: 0.005793
[02:04:41.971] iteration 15861 : loss : 0.106537, loss_ce: 0.008224
[02:04:42.273] iteration 15862 : loss : 0.042367, loss_ce: 0.019243
[02:04:42.568] iteration 15863 : loss : 0.044901, loss_ce: 0.014953
[02:04:42.862] iteration 15864 : loss : 0.048046, loss_ce: 0.008966
[02:04:43.155] iteration 15865 : loss : 0.036964, loss_ce: 0.015647
[02:04:43.453] iteration 15866 : loss : 0.044593, loss_ce: 0.007849
[02:04:43.753] iteration 15867 : loss : 0.103059, loss_ce: 0.008444
[02:04:44.050] iteration 15868 : loss : 0.043502, loss_ce: 0.016076
[02:04:44.353] iteration 15869 : loss : 0.041296, loss_ce: 0.011761
[02:04:44.665] iteration 15870 : loss : 0.038934, loss_ce: 0.016065
[02:04:44.968] iteration 15871 : loss : 0.050146, loss_ce: 0.013166
[02:04:45.271] iteration 15872 : loss : 0.049627, loss_ce: 0.019038
[02:04:45.568] iteration 15873 : loss : 0.042948, loss_ce: 0.014754
[02:04:45.872] iteration 15874 : loss : 0.036259, loss_ce: 0.013146
[02:04:46.176] iteration 15875 : loss : 0.054518, loss_ce: 0.021893
[02:04:46.474] iteration 15876 : loss : 0.040863, loss_ce: 0.013050
[02:04:46.771] iteration 15877 : loss : 0.043125, loss_ce: 0.008392
[02:04:47.069] iteration 15878 : loss : 0.049229, loss_ce: 0.012358
[02:04:47.368] iteration 15879 : loss : 0.043831, loss_ce: 0.014509
[02:04:47.667] iteration 15880 : loss : 0.042883, loss_ce: 0.012120
[02:04:47.983] iteration 15881 : loss : 0.059644, loss_ce: 0.012427
[02:04:48.278] iteration 15882 : loss : 0.044068, loss_ce: 0.018778
[02:04:48.576] iteration 15883 : loss : 0.049865, loss_ce: 0.009126
[02:04:48.872] iteration 15884 : loss : 0.106737, loss_ce: 0.008380
[02:04:49.168] iteration 15885 : loss : 0.053528, loss_ce: 0.016527
[02:04:49.467] iteration 15886 : loss : 0.102961, loss_ce: 0.013847
[02:04:49.768] iteration 15887 : loss : 0.055849, loss_ce: 0.015915
[02:04:50.063] iteration 15888 : loss : 0.042034, loss_ce: 0.015974
[02:04:50.361] iteration 15889 : loss : 0.050186, loss_ce: 0.015997
[02:04:50.659] iteration 15890 : loss : 0.049218, loss_ce: 0.019218
[02:04:50.956] iteration 15891 : loss : 0.111082, loss_ce: 0.018578
[02:04:51.253] iteration 15892 : loss : 0.063689, loss_ce: 0.021834
[02:04:51.553] iteration 15893 : loss : 0.039761, loss_ce: 0.006541
[02:04:51.853] iteration 15894 : loss : 0.049042, loss_ce: 0.015180
[02:04:52.153] iteration 15895 : loss : 0.155550, loss_ce: 0.003449
[02:04:52.449] iteration 15896 : loss : 0.056456, loss_ce: 0.017799
[02:04:52.744] iteration 15897 : loss : 0.046033, loss_ce: 0.017419
[02:04:53.043] iteration 15898 : loss : 0.043980, loss_ce: 0.019437
[02:04:53.339] iteration 15899 : loss : 0.099204, loss_ce: 0.010781
[02:04:53.633] iteration 15900 : loss : 0.055902, loss_ce: 0.029007
[02:04:53.943] iteration 15901 : loss : 0.048886, loss_ce: 0.011688
[02:04:54.237] iteration 15902 : loss : 0.043910, loss_ce: 0.017901
[02:04:54.543] iteration 15903 : loss : 0.102269, loss_ce: 0.012798
[02:04:54.844] iteration 15904 : loss : 0.044108, loss_ce: 0.016943
[02:04:55.141] iteration 15905 : loss : 0.041906, loss_ce: 0.015534
[02:04:55.444] iteration 15906 : loss : 0.042173, loss_ce: 0.014516
[02:04:55.740] iteration 15907 : loss : 0.050468, loss_ce: 0.012071
[02:04:56.038] iteration 15908 : loss : 0.043770, loss_ce: 0.018170
[02:04:56.338] iteration 15909 : loss : 0.046646, loss_ce: 0.013840
[02:04:56.640] iteration 15910 : loss : 0.098964, loss_ce: 0.009106
[02:04:56.940] iteration 15911 : loss : 0.061799, loss_ce: 0.010652
[02:04:57.234] iteration 15912 : loss : 0.057479, loss_ce: 0.009742
[02:04:57.534] iteration 15913 : loss : 0.044838, loss_ce: 0.016503
[02:04:57.837] iteration 15914 : loss : 0.046605, loss_ce: 0.015097
[02:04:58.139] iteration 15915 : loss : 0.068127, loss_ce: 0.010262
[02:04:58.443] iteration 15916 : loss : 0.056139, loss_ce: 0.013398
[02:04:58.739] iteration 15917 : loss : 0.047668, loss_ce: 0.008103
[02:04:59.038] iteration 15918 : loss : 0.048121, loss_ce: 0.015596
[02:04:59.340] iteration 15919 : loss : 0.043771, loss_ce: 0.011878
[02:04:59.638] iteration 15920 : loss : 0.099176, loss_ce: 0.014941
[02:04:59.949] iteration 15921 : loss : 0.070422, loss_ce: 0.019306
[02:05:00.250] iteration 15922 : loss : 0.046510, loss_ce: 0.017473
[02:05:00.548] iteration 15923 : loss : 0.054899, loss_ce: 0.014409
[02:05:00.850] iteration 15924 : loss : 0.048603, loss_ce: 0.015178
[02:05:01.149] iteration 15925 : loss : 0.046381, loss_ce: 0.012319
[02:05:01.449] iteration 15926 : loss : 0.048332, loss_ce: 0.017957
[02:05:01.751] iteration 15927 : loss : 0.127681, loss_ce: 0.010485
[02:05:02.054] iteration 15928 : loss : 0.057693, loss_ce: 0.015939
[02:05:02.357] iteration 15929 : loss : 0.045520, loss_ce: 0.015410
[02:05:02.662] iteration 15930 : loss : 0.109422, loss_ce: 0.015766
[02:05:02.966] iteration 15931 : loss : 0.040914, loss_ce: 0.011915
[02:05:03.270] iteration 15932 : loss : 0.056388, loss_ce: 0.008888
[02:05:03.575] iteration 15933 : loss : 0.040836, loss_ce: 0.009055
[02:05:03.881] iteration 15934 : loss : 0.109540, loss_ce: 0.016413
[02:05:04.181] iteration 15935 : loss : 0.043549, loss_ce: 0.008642
[02:05:04.485] iteration 15936 : loss : 0.041714, loss_ce: 0.013929
[02:05:04.786] iteration 15937 : loss : 0.108725, loss_ce: 0.019276
[02:05:05.085] iteration 15938 : loss : 0.039005, loss_ce: 0.011696
[02:05:05.387] iteration 15939 : loss : 0.038666, loss_ce: 0.012232
[02:05:05.693] iteration 15940 : loss : 0.051186, loss_ce: 0.011132
[02:05:06.022] iteration 15941 : loss : 0.038814, loss_ce: 0.012180
[02:05:06.325] iteration 15942 : loss : 0.048925, loss_ce: 0.014805
[02:05:06.624] iteration 15943 : loss : 0.044043, loss_ce: 0.015727
[02:05:06.930] iteration 15944 : loss : 0.041860, loss_ce: 0.010710
[02:05:07.233] iteration 15945 : loss : 0.047979, loss_ce: 0.020758
[02:05:07.535] iteration 15946 : loss : 0.049495, loss_ce: 0.010361
[02:05:07.842] iteration 15947 : loss : 0.166953, loss_ce: 0.002673
[02:05:08.141] iteration 15948 : loss : 0.052052, loss_ce: 0.013502
[02:05:08.442] iteration 15949 : loss : 0.064062, loss_ce: 0.018138
[02:05:08.750] iteration 15950 : loss : 0.042491, loss_ce: 0.019967
[02:05:09.055] iteration 15951 : loss : 0.049161, loss_ce: 0.016457
[02:05:09.358] iteration 15952 : loss : 0.048017, loss_ce: 0.010252
[02:05:09.665] iteration 15953 : loss : 0.055104, loss_ce: 0.010459
[02:05:09.972] iteration 15954 : loss : 0.037568, loss_ce: 0.014086
[02:05:10.275] iteration 15955 : loss : 0.040769, loss_ce: 0.008661
[02:05:10.575] iteration 15956 : loss : 0.044628, loss_ce: 0.015381
[02:05:10.881] iteration 15957 : loss : 0.078218, loss_ce: 0.009391
[02:05:11.186] iteration 15958 : loss : 0.104751, loss_ce: 0.007144
[02:05:11.489] iteration 15959 : loss : 0.065238, loss_ce: 0.009552
[02:05:11.789] iteration 15960 : loss : 0.101311, loss_ce: 0.010555
[02:05:12.100] iteration 15961 : loss : 0.053730, loss_ce: 0.025450
[02:05:12.400] iteration 15962 : loss : 0.049611, loss_ce: 0.018468
[02:05:12.699] iteration 15963 : loss : 0.102283, loss_ce: 0.008075
[02:05:13.001] iteration 15964 : loss : 0.038620, loss_ce: 0.013445
[02:05:13.301] iteration 15965 : loss : 0.041648, loss_ce: 0.012924
[02:05:13.607] iteration 15966 : loss : 0.042992, loss_ce: 0.012086
[02:05:13.911] iteration 15967 : loss : 0.098848, loss_ce: 0.011714
[02:05:14.215] iteration 15968 : loss : 0.102803, loss_ce: 0.011695
[02:05:14.526] iteration 15969 : loss : 0.055704, loss_ce: 0.012417
[02:05:14.835] iteration 15970 : loss : 0.044324, loss_ce: 0.010965
[02:05:15.140] iteration 15971 : loss : 0.052310, loss_ce: 0.015235
[02:05:15.453] iteration 15972 : loss : 0.100235, loss_ce: 0.010761
[02:05:15.771] iteration 15973 : loss : 0.045584, loss_ce: 0.019396
[02:05:16.077] iteration 15974 : loss : 0.033449, loss_ce: 0.008871
[02:05:16.387] iteration 15975 : loss : 0.052819, loss_ce: 0.018351
[02:05:16.697] iteration 15976 : loss : 0.042258, loss_ce: 0.011218
[02:05:17.004] iteration 15977 : loss : 0.043242, loss_ce: 0.015063
[02:05:17.312] iteration 15978 : loss : 0.056416, loss_ce: 0.017542
[02:05:17.621] iteration 15979 : loss : 0.050014, loss_ce: 0.013911
[02:05:17.929] iteration 15980 : loss : 0.058274, loss_ce: 0.012267
[02:05:18.255] iteration 15981 : loss : 0.046401, loss_ce: 0.012915
[02:05:18.566] iteration 15982 : loss : 0.102196, loss_ce: 0.013270
[02:05:18.876] iteration 15983 : loss : 0.176497, loss_ce: 0.008499
[02:05:19.188] iteration 15984 : loss : 0.042266, loss_ce: 0.015230
[02:05:19.282] iteration 15985 : loss : 0.281614, loss_ce: 0.015899
[02:05:38.038] iteration 15986 : loss : 0.041066, loss_ce: 0.013954
[02:05:38.342] iteration 15987 : loss : 0.041004, loss_ce: 0.013797
[02:05:38.642] iteration 15988 : loss : 0.051172, loss_ce: 0.014009
[02:05:38.936] iteration 15989 : loss : 0.103016, loss_ce: 0.006066
[02:05:39.238] iteration 15990 : loss : 0.046959, loss_ce: 0.016548
[02:05:39.535] iteration 15991 : loss : 0.051055, loss_ce: 0.007932
[02:05:39.830] iteration 15992 : loss : 0.044030, loss_ce: 0.010682
[02:05:40.130] iteration 15993 : loss : 0.128748, loss_ce: 0.005505
[02:05:40.426] iteration 15994 : loss : 0.114682, loss_ce: 0.006489
[02:05:40.727] iteration 15995 : loss : 0.106511, loss_ce: 0.006866
[02:05:41.023] iteration 15996 : loss : 0.057946, loss_ce: 0.022793
[02:05:41.317] iteration 15997 : loss : 0.100582, loss_ce: 0.008382
[02:05:41.616] iteration 15998 : loss : 0.039459, loss_ce: 0.008706
[02:05:41.914] iteration 15999 : loss : 0.049704, loss_ce: 0.016211
[02:05:42.213] iteration 16000 : loss : 0.047934, loss_ce: 0.011851
[02:05:42.530] iteration 16001 : loss : 0.050494, loss_ce: 0.024817
[02:05:42.826] iteration 16002 : loss : 0.049090, loss_ce: 0.022460
[02:05:43.129] iteration 16003 : loss : 0.052550, loss_ce: 0.007247
[02:05:43.430] iteration 16004 : loss : 0.054791, loss_ce: 0.023834
[02:05:43.722] iteration 16005 : loss : 0.047482, loss_ce: 0.015543
[02:05:44.023] iteration 16006 : loss : 0.104514, loss_ce: 0.014199
[02:05:44.321] iteration 16007 : loss : 0.044814, loss_ce: 0.019921
[02:05:44.622] iteration 16008 : loss : 0.165171, loss_ce: 0.009373
[02:05:44.920] iteration 16009 : loss : 0.040838, loss_ce: 0.009730
[02:05:45.212] iteration 16010 : loss : 0.051313, loss_ce: 0.018670
[02:05:45.510] iteration 16011 : loss : 0.040081, loss_ce: 0.015022
[02:05:45.805] iteration 16012 : loss : 0.040559, loss_ce: 0.012127
[02:05:46.100] iteration 16013 : loss : 0.039434, loss_ce: 0.005813
[02:05:46.401] iteration 16014 : loss : 0.045274, loss_ce: 0.013620
[02:05:46.698] iteration 16015 : loss : 0.047458, loss_ce: 0.012295
[02:05:46.995] iteration 16016 : loss : 0.040524, loss_ce: 0.010783
[02:05:47.297] iteration 16017 : loss : 0.044701, loss_ce: 0.013918
[02:05:47.594] iteration 16018 : loss : 0.041885, loss_ce: 0.012412
[02:05:47.895] iteration 16019 : loss : 0.042876, loss_ce: 0.011538
[02:05:48.193] iteration 16020 : loss : 0.055013, loss_ce: 0.022379
[02:05:48.505] iteration 16021 : loss : 0.056751, loss_ce: 0.021189
[02:05:48.800] iteration 16022 : loss : 0.053281, loss_ce: 0.015587
[02:05:49.097] iteration 16023 : loss : 0.107775, loss_ce: 0.010404
[02:05:49.398] iteration 16024 : loss : 0.048107, loss_ce: 0.017037
[02:05:49.697] iteration 16025 : loss : 0.050814, loss_ce: 0.010495
[02:05:49.997] iteration 16026 : loss : 0.044198, loss_ce: 0.013592
[02:05:50.308] iteration 16027 : loss : 0.045433, loss_ce: 0.017336
[02:05:50.608] iteration 16028 : loss : 0.092927, loss_ce: 0.024048
[02:05:50.909] iteration 16029 : loss : 0.040719, loss_ce: 0.008875
[02:05:51.210] iteration 16030 : loss : 0.044710, loss_ce: 0.018686
[02:05:51.509] iteration 16031 : loss : 0.044575, loss_ce: 0.012073
[02:05:51.810] iteration 16032 : loss : 0.054973, loss_ce: 0.021657
[02:05:52.112] iteration 16033 : loss : 0.036265, loss_ce: 0.013694
[02:05:52.413] iteration 16034 : loss : 0.043712, loss_ce: 0.018012
[02:05:52.719] iteration 16035 : loss : 0.056452, loss_ce: 0.007190
[02:05:53.025] iteration 16036 : loss : 0.104063, loss_ce: 0.006482
[02:05:53.328] iteration 16037 : loss : 0.049304, loss_ce: 0.016741
[02:05:53.629] iteration 16038 : loss : 0.042786, loss_ce: 0.018344
[02:05:53.934] iteration 16039 : loss : 0.057244, loss_ce: 0.015602
[02:05:54.234] iteration 16040 : loss : 0.104219, loss_ce: 0.004564
[02:05:54.550] iteration 16041 : loss : 0.046313, loss_ce: 0.016961
[02:05:54.849] iteration 16042 : loss : 0.049670, loss_ce: 0.013652
[02:05:55.154] iteration 16043 : loss : 0.045151, loss_ce: 0.015884
[02:05:55.455] iteration 16044 : loss : 0.052667, loss_ce: 0.017577
[02:05:55.759] iteration 16045 : loss : 0.098632, loss_ce: 0.011834
[02:05:56.059] iteration 16046 : loss : 0.042711, loss_ce: 0.013605
[02:05:56.359] iteration 16047 : loss : 0.046594, loss_ce: 0.009970
[02:05:56.658] iteration 16048 : loss : 0.106485, loss_ce: 0.010996
[02:05:56.959] iteration 16049 : loss : 0.105869, loss_ce: 0.011933
[02:05:57.261] iteration 16050 : loss : 0.097944, loss_ce: 0.008800
[02:05:57.563] iteration 16051 : loss : 0.099866, loss_ce: 0.007096
[02:05:57.868] iteration 16052 : loss : 0.050477, loss_ce: 0.016479
[02:05:58.170] iteration 16053 : loss : 0.045528, loss_ce: 0.008103
[02:05:58.474] iteration 16054 : loss : 0.044791, loss_ce: 0.006650
[02:05:58.779] iteration 16055 : loss : 0.043355, loss_ce: 0.006945
[02:05:59.084] iteration 16056 : loss : 0.048162, loss_ce: 0.017791
[02:05:59.389] iteration 16057 : loss : 0.095397, loss_ce: 0.010258
[02:05:59.688] iteration 16058 : loss : 0.099673, loss_ce: 0.004103
[02:05:59.989] iteration 16059 : loss : 0.045442, loss_ce: 0.015514
[02:06:00.294] iteration 16060 : loss : 0.097794, loss_ce: 0.009982
[02:06:00.610] iteration 16061 : loss : 0.037267, loss_ce: 0.013088
[02:06:00.912] iteration 16062 : loss : 0.050025, loss_ce: 0.010811
[02:06:01.216] iteration 16063 : loss : 0.039776, loss_ce: 0.007220
[02:06:01.520] iteration 16064 : loss : 0.109012, loss_ce: 0.015818
[02:06:01.824] iteration 16065 : loss : 0.046025, loss_ce: 0.015544
[02:06:02.123] iteration 16066 : loss : 0.107547, loss_ce: 0.012507
[02:06:02.424] iteration 16067 : loss : 0.047286, loss_ce: 0.014738
[02:06:02.728] iteration 16068 : loss : 0.101154, loss_ce: 0.013919
[02:06:03.030] iteration 16069 : loss : 0.044359, loss_ce: 0.011477
[02:06:03.334] iteration 16070 : loss : 0.054576, loss_ce: 0.007591
[02:06:03.637] iteration 16071 : loss : 0.108551, loss_ce: 0.010110
[02:06:03.944] iteration 16072 : loss : 0.045908, loss_ce: 0.015333
[02:06:04.248] iteration 16073 : loss : 0.063215, loss_ce: 0.014982
[02:06:04.550] iteration 16074 : loss : 0.097330, loss_ce: 0.014160
[02:06:04.858] iteration 16075 : loss : 0.039112, loss_ce: 0.014903
[02:06:05.164] iteration 16076 : loss : 0.274636, loss_ce: 0.005031
[02:06:05.468] iteration 16077 : loss : 0.113448, loss_ce: 0.016857
[02:06:05.766] iteration 16078 : loss : 0.034848, loss_ce: 0.009748
[02:06:06.075] iteration 16079 : loss : 0.050754, loss_ce: 0.021270
[02:06:06.376] iteration 16080 : loss : 0.040135, loss_ce: 0.011725
[02:06:06.690] iteration 16081 : loss : 0.086514, loss_ce: 0.006859
[02:06:06.995] iteration 16082 : loss : 0.048506, loss_ce: 0.027044
[02:06:07.295] iteration 16083 : loss : 0.033153, loss_ce: 0.006721
[02:06:07.600] iteration 16084 : loss : 0.042331, loss_ce: 0.017423
[02:06:07.906] iteration 16085 : loss : 0.045988, loss_ce: 0.019761
[02:06:08.208] iteration 16086 : loss : 0.044383, loss_ce: 0.013375
[02:06:08.508] iteration 16087 : loss : 0.084664, loss_ce: 0.011227
[02:06:08.812] iteration 16088 : loss : 0.044482, loss_ce: 0.007960
[02:06:09.119] iteration 16089 : loss : 0.164579, loss_ce: 0.003399
[02:06:09.418] iteration 16090 : loss : 0.045741, loss_ce: 0.016610
[02:06:09.725] iteration 16091 : loss : 0.041230, loss_ce: 0.012772
[02:06:10.028] iteration 16092 : loss : 0.049502, loss_ce: 0.021177
[02:06:10.327] iteration 16093 : loss : 0.045421, loss_ce: 0.019964
[02:06:10.632] iteration 16094 : loss : 0.040622, loss_ce: 0.011300
[02:06:10.934] iteration 16095 : loss : 0.051995, loss_ce: 0.012118
[02:06:11.234] iteration 16096 : loss : 0.108455, loss_ce: 0.016862
[02:06:11.534] iteration 16097 : loss : 0.065427, loss_ce: 0.016035
[02:06:11.828] iteration 16098 : loss : 0.104204, loss_ce: 0.010167
[02:06:12.128] iteration 16099 : loss : 0.058320, loss_ce: 0.014585
[02:06:12.427] iteration 16100 : loss : 0.058386, loss_ce: 0.010369
[02:06:12.741] iteration 16101 : loss : 0.049567, loss_ce: 0.018108
[02:06:13.036] iteration 16102 : loss : 0.045127, loss_ce: 0.010018
[02:06:13.339] iteration 16103 : loss : 0.109214, loss_ce: 0.009028
[02:06:13.633] iteration 16104 : loss : 0.044095, loss_ce: 0.015173
[02:06:13.927] iteration 16105 : loss : 0.045642, loss_ce: 0.015699
[02:06:14.224] iteration 16106 : loss : 0.037330, loss_ce: 0.011573
[02:06:14.523] iteration 16107 : loss : 0.058825, loss_ce: 0.011002
[02:06:14.827] iteration 16108 : loss : 0.105503, loss_ce: 0.013763
[02:06:15.131] iteration 16109 : loss : 0.040063, loss_ce: 0.011917
[02:06:15.432] iteration 16110 : loss : 0.096579, loss_ce: 0.007819
[02:06:15.732] iteration 16111 : loss : 0.033954, loss_ce: 0.012617
[02:06:16.033] iteration 16112 : loss : 0.050637, loss_ce: 0.014075
[02:06:16.334] iteration 16113 : loss : 0.283740, loss_ce: 0.009634
[02:06:16.635] iteration 16114 : loss : 0.046564, loss_ce: 0.017997
[02:06:16.934] iteration 16115 : loss : 0.050242, loss_ce: 0.026143
[02:06:17.231] iteration 16116 : loss : 0.045425, loss_ce: 0.015366
[02:06:17.535] iteration 16117 : loss : 0.051287, loss_ce: 0.019694
[02:06:17.836] iteration 16118 : loss : 0.036277, loss_ce: 0.011305
[02:06:18.137] iteration 16119 : loss : 0.042477, loss_ce: 0.014166
[02:06:18.432] iteration 16120 : loss : 0.060132, loss_ce: 0.012649
[02:06:18.751] iteration 16121 : loss : 0.047985, loss_ce: 0.019151
[02:06:19.056] iteration 16122 : loss : 0.049354, loss_ce: 0.014543
[02:06:19.359] iteration 16123 : loss : 0.107736, loss_ce: 0.011904
[02:06:19.435] iteration 16124 : loss : 0.099134, loss_ce: 0.030165
[02:06:36.899] iteration 16125 : loss : 0.047820, loss_ce: 0.024561
[02:06:37.200] iteration 16126 : loss : 0.033833, loss_ce: 0.015205
[02:06:37.499] iteration 16127 : loss : 0.051930, loss_ce: 0.016866
[02:06:37.803] iteration 16128 : loss : 0.048332, loss_ce: 0.013533
[02:06:38.100] iteration 16129 : loss : 0.102852, loss_ce: 0.012306
[02:06:38.401] iteration 16130 : loss : 0.061118, loss_ce: 0.017458
[02:06:38.699] iteration 16131 : loss : 0.104594, loss_ce: 0.012990
[02:06:38.999] iteration 16132 : loss : 0.039156, loss_ce: 0.011706
[02:06:39.298] iteration 16133 : loss : 0.043162, loss_ce: 0.010224
[02:06:39.597] iteration 16134 : loss : 0.037450, loss_ce: 0.010679
[02:06:39.899] iteration 16135 : loss : 0.062019, loss_ce: 0.006367
[02:06:40.207] iteration 16136 : loss : 0.038173, loss_ce: 0.018884
[02:06:40.509] iteration 16137 : loss : 0.035273, loss_ce: 0.012449
[02:06:40.812] iteration 16138 : loss : 0.044076, loss_ce: 0.018133
[02:06:41.115] iteration 16139 : loss : 0.053411, loss_ce: 0.012798
[02:06:41.416] iteration 16140 : loss : 0.047029, loss_ce: 0.016015
[02:06:41.729] iteration 16141 : loss : 0.040881, loss_ce: 0.018509
[02:06:42.030] iteration 16142 : loss : 0.044398, loss_ce: 0.014398
[02:06:42.327] iteration 16143 : loss : 0.048153, loss_ce: 0.020215
[02:06:42.626] iteration 16144 : loss : 0.050192, loss_ce: 0.009863
[02:06:42.926] iteration 16145 : loss : 0.043268, loss_ce: 0.010933
[02:06:43.224] iteration 16146 : loss : 0.042292, loss_ce: 0.013540
[02:06:43.524] iteration 16147 : loss : 0.285689, loss_ce: 0.014220
[02:06:43.820] iteration 16148 : loss : 0.105530, loss_ce: 0.008061
[02:06:44.116] iteration 16149 : loss : 0.050097, loss_ce: 0.007741
[02:06:44.412] iteration 16150 : loss : 0.050136, loss_ce: 0.012998
[02:06:44.711] iteration 16151 : loss : 0.043474, loss_ce: 0.009435
[02:06:45.013] iteration 16152 : loss : 0.104465, loss_ce: 0.008890
[02:06:45.311] iteration 16153 : loss : 0.047159, loss_ce: 0.007469
[02:06:45.611] iteration 16154 : loss : 0.043871, loss_ce: 0.013797
[02:06:45.907] iteration 16155 : loss : 0.047598, loss_ce: 0.017481
[02:06:46.201] iteration 16156 : loss : 0.047803, loss_ce: 0.012072
[02:06:46.499] iteration 16157 : loss : 0.038128, loss_ce: 0.010028
[02:06:46.794] iteration 16158 : loss : 0.054477, loss_ce: 0.015741
[02:06:47.091] iteration 16159 : loss : 0.043647, loss_ce: 0.007506
[02:06:47.386] iteration 16160 : loss : 0.041826, loss_ce: 0.014040
[02:06:47.700] iteration 16161 : loss : 0.035222, loss_ce: 0.015392
[02:06:48.002] iteration 16162 : loss : 0.049375, loss_ce: 0.015877
[02:06:48.302] iteration 16163 : loss : 0.040655, loss_ce: 0.011465
[02:06:48.602] iteration 16164 : loss : 0.047022, loss_ce: 0.017786
[02:06:48.900] iteration 16165 : loss : 0.052142, loss_ce: 0.016404
[02:06:49.199] iteration 16166 : loss : 0.056210, loss_ce: 0.012660
[02:06:49.496] iteration 16167 : loss : 0.102158, loss_ce: 0.003511
[02:06:49.795] iteration 16168 : loss : 0.042862, loss_ce: 0.009409
[02:06:50.097] iteration 16169 : loss : 0.037535, loss_ce: 0.011726
[02:06:50.397] iteration 16170 : loss : 0.041641, loss_ce: 0.007288
[02:06:50.699] iteration 16171 : loss : 0.042766, loss_ce: 0.015856
[02:06:50.995] iteration 16172 : loss : 0.044264, loss_ce: 0.017572
[02:06:51.298] iteration 16173 : loss : 0.036514, loss_ce: 0.011184
[02:06:51.595] iteration 16174 : loss : 0.278419, loss_ce: 0.003119
[02:06:51.894] iteration 16175 : loss : 0.045782, loss_ce: 0.013797
[02:06:52.194] iteration 16176 : loss : 0.101812, loss_ce: 0.005185
[02:06:52.493] iteration 16177 : loss : 0.098899, loss_ce: 0.012249
[02:06:52.791] iteration 16178 : loss : 0.057525, loss_ce: 0.013455
[02:06:53.086] iteration 16179 : loss : 0.043292, loss_ce: 0.009541
[02:06:53.385] iteration 16180 : loss : 0.043380, loss_ce: 0.020365
[02:06:53.701] iteration 16181 : loss : 0.051291, loss_ce: 0.018791
[02:06:53.996] iteration 16182 : loss : 0.040204, loss_ce: 0.005645
[02:06:54.300] iteration 16183 : loss : 0.045498, loss_ce: 0.019725
[02:06:54.604] iteration 16184 : loss : 0.034261, loss_ce: 0.013232
[02:06:54.908] iteration 16185 : loss : 0.043042, loss_ce: 0.014114
[02:06:55.210] iteration 16186 : loss : 0.050046, loss_ce: 0.020003
[02:06:55.517] iteration 16187 : loss : 0.049560, loss_ce: 0.017525
[02:06:55.820] iteration 16188 : loss : 0.044485, loss_ce: 0.023147
[02:06:56.128] iteration 16189 : loss : 0.115004, loss_ce: 0.006992
[02:06:56.426] iteration 16190 : loss : 0.093163, loss_ce: 0.004872
[02:06:56.727] iteration 16191 : loss : 0.049720, loss_ce: 0.019716
[02:06:57.028] iteration 16192 : loss : 0.070781, loss_ce: 0.011370
[02:06:57.328] iteration 16193 : loss : 0.044023, loss_ce: 0.019939
[02:06:57.627] iteration 16194 : loss : 0.047514, loss_ce: 0.013695
[02:06:57.928] iteration 16195 : loss : 0.101392, loss_ce: 0.008605
[02:06:58.230] iteration 16196 : loss : 0.077769, loss_ce: 0.010416
[02:06:58.528] iteration 16197 : loss : 0.049306, loss_ce: 0.022809
[02:06:58.825] iteration 16198 : loss : 0.102572, loss_ce: 0.014289
[02:06:59.121] iteration 16199 : loss : 0.043092, loss_ce: 0.014224
[02:06:59.423] iteration 16200 : loss : 0.156862, loss_ce: 0.007360
[02:06:59.733] iteration 16201 : loss : 0.050491, loss_ce: 0.015855
[02:07:00.036] iteration 16202 : loss : 0.041270, loss_ce: 0.020092
[02:07:00.334] iteration 16203 : loss : 0.048141, loss_ce: 0.010218
[02:07:00.636] iteration 16204 : loss : 0.164420, loss_ce: 0.003601
[02:07:00.939] iteration 16205 : loss : 0.051873, loss_ce: 0.013520
[02:07:01.235] iteration 16206 : loss : 0.048011, loss_ce: 0.019562
[02:07:01.533] iteration 16207 : loss : 0.039743, loss_ce: 0.009075
[02:07:01.830] iteration 16208 : loss : 0.052885, loss_ce: 0.017276
[02:07:02.127] iteration 16209 : loss : 0.156819, loss_ce: 0.009896
[02:07:02.424] iteration 16210 : loss : 0.052221, loss_ce: 0.016206
[02:07:02.719] iteration 16211 : loss : 0.100024, loss_ce: 0.010794
[02:07:03.014] iteration 16212 : loss : 0.037613, loss_ce: 0.012506
[02:07:03.310] iteration 16213 : loss : 0.034589, loss_ce: 0.012962
[02:07:03.613] iteration 16214 : loss : 0.041283, loss_ce: 0.016167
[02:07:03.912] iteration 16215 : loss : 0.050626, loss_ce: 0.005865
[02:07:04.208] iteration 16216 : loss : 0.047834, loss_ce: 0.016338
[02:07:04.511] iteration 16217 : loss : 0.064000, loss_ce: 0.013773
[02:07:04.809] iteration 16218 : loss : 0.098518, loss_ce: 0.014013
[02:07:05.110] iteration 16219 : loss : 0.067707, loss_ce: 0.009574
[02:07:05.407] iteration 16220 : loss : 0.051451, loss_ce: 0.016058
[02:07:05.727] iteration 16221 : loss : 0.053850, loss_ce: 0.008428
[02:07:06.025] iteration 16222 : loss : 0.046015, loss_ce: 0.008702
[02:07:06.323] iteration 16223 : loss : 0.041411, loss_ce: 0.016630
[02:07:06.623] iteration 16224 : loss : 0.045796, loss_ce: 0.010889
[02:07:06.922] iteration 16225 : loss : 0.047485, loss_ce: 0.023003
[02:07:07.221] iteration 16226 : loss : 0.044246, loss_ce: 0.017587
[02:07:07.519] iteration 16227 : loss : 0.101479, loss_ce: 0.010829
[02:07:07.820] iteration 16228 : loss : 0.041459, loss_ce: 0.015780
[02:07:08.118] iteration 16229 : loss : 0.037328, loss_ce: 0.009677
[02:07:08.419] iteration 16230 : loss : 0.061129, loss_ce: 0.018792
[02:07:08.715] iteration 16231 : loss : 0.046414, loss_ce: 0.013548
[02:07:09.013] iteration 16232 : loss : 0.058396, loss_ce: 0.010286
[02:07:09.314] iteration 16233 : loss : 0.053116, loss_ce: 0.011716
[02:07:09.619] iteration 16234 : loss : 0.043128, loss_ce: 0.012354
[02:07:09.919] iteration 16235 : loss : 0.066350, loss_ce: 0.012091
[02:07:10.221] iteration 16236 : loss : 0.039498, loss_ce: 0.008596
[02:07:10.521] iteration 16237 : loss : 0.048105, loss_ce: 0.012874
[02:07:10.821] iteration 16238 : loss : 0.052828, loss_ce: 0.015559
[02:07:11.118] iteration 16239 : loss : 0.038053, loss_ce: 0.010451
[02:07:11.425] iteration 16240 : loss : 0.045804, loss_ce: 0.019760
[02:07:11.745] iteration 16241 : loss : 0.044075, loss_ce: 0.016231
[02:07:12.046] iteration 16242 : loss : 0.042739, loss_ce: 0.010234
[02:07:12.349] iteration 16243 : loss : 0.050425, loss_ce: 0.005262
[02:07:12.648] iteration 16244 : loss : 0.172771, loss_ce: 0.003900
[02:07:12.951] iteration 16245 : loss : 0.040286, loss_ce: 0.016098
[02:07:13.258] iteration 16246 : loss : 0.039741, loss_ce: 0.014583
[02:07:13.561] iteration 16247 : loss : 0.091363, loss_ce: 0.005775
[02:07:13.865] iteration 16248 : loss : 0.104062, loss_ce: 0.017837
[02:07:14.172] iteration 16249 : loss : 0.046376, loss_ce: 0.019008
[02:07:14.478] iteration 16250 : loss : 0.101369, loss_ce: 0.012343
[02:07:14.788] iteration 16251 : loss : 0.053598, loss_ce: 0.013394
[02:07:15.088] iteration 16252 : loss : 0.060132, loss_ce: 0.013850
[02:07:15.395] iteration 16253 : loss : 0.060793, loss_ce: 0.023030
[02:07:15.703] iteration 16254 : loss : 0.064830, loss_ce: 0.011318
[02:07:16.011] iteration 16255 : loss : 0.109216, loss_ce: 0.012057
[02:07:16.314] iteration 16256 : loss : 0.044538, loss_ce: 0.010063
[02:07:16.623] iteration 16257 : loss : 0.117694, loss_ce: 0.009571
[02:07:16.935] iteration 16258 : loss : 0.096384, loss_ce: 0.007624
[02:07:17.236] iteration 16259 : loss : 0.049313, loss_ce: 0.014320
[02:07:17.547] iteration 16260 : loss : 0.056829, loss_ce: 0.019316
[02:07:17.880] iteration 16261 : loss : 0.050762, loss_ce: 0.024941
[02:07:18.188] iteration 16262 : loss : 0.050843, loss_ce: 0.017741
[02:07:18.283] iteration 16263 : loss : 0.165676, loss_ce: 0.011354
[02:07:35.324] iteration 16264 : loss : 0.044395, loss_ce: 0.016950
[02:07:35.626] iteration 16265 : loss : 0.047582, loss_ce: 0.008682
[02:07:35.928] iteration 16266 : loss : 0.046008, loss_ce: 0.010240
[02:07:36.241] iteration 16267 : loss : 0.053575, loss_ce: 0.011695
[02:07:36.540] iteration 16268 : loss : 0.057330, loss_ce: 0.008516
[02:07:36.840] iteration 16269 : loss : 0.043396, loss_ce: 0.016334
[02:07:37.134] iteration 16270 : loss : 0.104799, loss_ce: 0.011370
[02:07:37.434] iteration 16271 : loss : 0.034547, loss_ce: 0.009052
[02:07:37.731] iteration 16272 : loss : 0.043695, loss_ce: 0.004405
[02:07:38.030] iteration 16273 : loss : 0.047307, loss_ce: 0.015476
[02:07:38.326] iteration 16274 : loss : 0.103519, loss_ce: 0.013625
[02:07:38.626] iteration 16275 : loss : 0.041343, loss_ce: 0.013700
[02:07:38.923] iteration 16276 : loss : 0.043707, loss_ce: 0.015767
[02:07:39.229] iteration 16277 : loss : 0.111725, loss_ce: 0.011480
[02:07:39.526] iteration 16278 : loss : 0.049447, loss_ce: 0.010578
[02:07:39.820] iteration 16279 : loss : 0.045865, loss_ce: 0.015608
[02:07:40.114] iteration 16280 : loss : 0.046208, loss_ce: 0.016167
[02:07:40.435] iteration 16281 : loss : 0.045744, loss_ce: 0.011058
[02:07:40.734] iteration 16282 : loss : 0.105338, loss_ce: 0.009101
[02:07:41.026] iteration 16283 : loss : 0.042585, loss_ce: 0.015200
[02:07:41.323] iteration 16284 : loss : 0.048175, loss_ce: 0.016414
[02:07:41.621] iteration 16285 : loss : 0.038782, loss_ce: 0.015206
[02:07:41.917] iteration 16286 : loss : 0.052701, loss_ce: 0.013675
[02:07:42.215] iteration 16287 : loss : 0.050570, loss_ce: 0.018474
[02:07:42.512] iteration 16288 : loss : 0.048408, loss_ce: 0.017310
[02:07:42.817] iteration 16289 : loss : 0.049185, loss_ce: 0.009481
[02:07:43.116] iteration 16290 : loss : 0.053369, loss_ce: 0.014407
[02:07:43.417] iteration 16291 : loss : 0.071891, loss_ce: 0.018048
[02:07:43.712] iteration 16292 : loss : 0.342305, loss_ce: 0.001096
[02:07:44.009] iteration 16293 : loss : 0.049540, loss_ce: 0.018049
[02:07:44.313] iteration 16294 : loss : 0.053354, loss_ce: 0.020840
[02:07:44.616] iteration 16295 : loss : 0.039508, loss_ce: 0.014972
[02:07:44.922] iteration 16296 : loss : 0.050676, loss_ce: 0.007090
[02:07:45.225] iteration 16297 : loss : 0.104515, loss_ce: 0.013362
[02:07:45.532] iteration 16298 : loss : 0.033310, loss_ce: 0.015953
[02:07:45.833] iteration 16299 : loss : 0.039010, loss_ce: 0.015526
[02:07:46.137] iteration 16300 : loss : 0.041412, loss_ce: 0.016046
[02:07:46.447] iteration 16301 : loss : 0.050326, loss_ce: 0.012126
[02:07:46.745] iteration 16302 : loss : 0.051849, loss_ce: 0.022788
[02:07:47.043] iteration 16303 : loss : 0.046799, loss_ce: 0.021672
[02:07:47.338] iteration 16304 : loss : 0.056128, loss_ce: 0.021816
[02:07:47.636] iteration 16305 : loss : 0.045792, loss_ce: 0.017422
[02:07:47.935] iteration 16306 : loss : 0.056142, loss_ce: 0.019589
[02:07:48.237] iteration 16307 : loss : 0.100096, loss_ce: 0.016874
[02:07:48.534] iteration 16308 : loss : 0.051944, loss_ce: 0.022218
[02:07:48.833] iteration 16309 : loss : 0.039364, loss_ce: 0.023068
[02:07:49.133] iteration 16310 : loss : 0.050332, loss_ce: 0.015341
[02:07:49.431] iteration 16311 : loss : 0.038745, loss_ce: 0.005946
[02:07:49.730] iteration 16312 : loss : 0.102629, loss_ce: 0.010565
[02:07:50.032] iteration 16313 : loss : 0.048935, loss_ce: 0.017103
[02:07:50.327] iteration 16314 : loss : 0.119144, loss_ce: 0.006776
[02:07:50.623] iteration 16315 : loss : 0.038516, loss_ce: 0.012199
[02:07:50.920] iteration 16316 : loss : 0.102633, loss_ce: 0.012957
[02:07:51.221] iteration 16317 : loss : 0.044680, loss_ce: 0.013456
[02:07:51.515] iteration 16318 : loss : 0.044184, loss_ce: 0.008363
[02:07:51.815] iteration 16319 : loss : 0.041168, loss_ce: 0.014144
[02:07:52.115] iteration 16320 : loss : 0.109417, loss_ce: 0.015338
[02:07:52.431] iteration 16321 : loss : 0.053162, loss_ce: 0.016024
[02:07:52.725] iteration 16322 : loss : 0.064286, loss_ce: 0.013084
[02:07:53.027] iteration 16323 : loss : 0.051350, loss_ce: 0.013021
[02:07:53.326] iteration 16324 : loss : 0.040528, loss_ce: 0.014460
[02:07:53.629] iteration 16325 : loss : 0.042775, loss_ce: 0.018917
[02:07:53.928] iteration 16326 : loss : 0.048250, loss_ce: 0.009668
[02:07:54.226] iteration 16327 : loss : 0.033892, loss_ce: 0.009795
[02:07:54.523] iteration 16328 : loss : 0.048677, loss_ce: 0.013840
[02:07:54.821] iteration 16329 : loss : 0.041348, loss_ce: 0.013350
[02:07:55.116] iteration 16330 : loss : 0.053329, loss_ce: 0.006364
[02:07:55.412] iteration 16331 : loss : 0.100040, loss_ce: 0.005716
[02:07:55.709] iteration 16332 : loss : 0.039627, loss_ce: 0.006929
[02:07:56.009] iteration 16333 : loss : 0.035578, loss_ce: 0.009646
[02:07:56.306] iteration 16334 : loss : 0.047520, loss_ce: 0.015122
[02:07:56.601] iteration 16335 : loss : 0.042238, loss_ce: 0.019788
[02:07:56.898] iteration 16336 : loss : 0.098565, loss_ce: 0.008251
[02:07:57.199] iteration 16337 : loss : 0.067928, loss_ce: 0.012343
[02:07:57.497] iteration 16338 : loss : 0.159161, loss_ce: 0.010511
[02:07:57.796] iteration 16339 : loss : 0.046855, loss_ce: 0.015206
[02:07:58.093] iteration 16340 : loss : 0.041097, loss_ce: 0.015387
[02:07:58.413] iteration 16341 : loss : 0.057875, loss_ce: 0.021385
[02:07:58.716] iteration 16342 : loss : 0.048495, loss_ce: 0.007588
[02:07:59.019] iteration 16343 : loss : 0.046845, loss_ce: 0.016446
[02:07:59.321] iteration 16344 : loss : 0.044109, loss_ce: 0.014614
[02:07:59.619] iteration 16345 : loss : 0.105619, loss_ce: 0.015040
[02:07:59.921] iteration 16346 : loss : 0.051028, loss_ce: 0.016735
[02:08:00.222] iteration 16347 : loss : 0.155461, loss_ce: 0.009238
[02:08:00.521] iteration 16348 : loss : 0.048514, loss_ce: 0.015095
[02:08:00.822] iteration 16349 : loss : 0.046570, loss_ce: 0.014807
[02:08:01.126] iteration 16350 : loss : 0.060878, loss_ce: 0.009887
[02:08:01.427] iteration 16351 : loss : 0.105892, loss_ce: 0.015282
[02:08:01.734] iteration 16352 : loss : 0.283619, loss_ce: 0.003886
[02:08:02.044] iteration 16353 : loss : 0.062589, loss_ce: 0.015153
[02:08:02.347] iteration 16354 : loss : 0.047217, loss_ce: 0.015270
[02:08:02.649] iteration 16355 : loss : 0.046827, loss_ce: 0.013587
[02:08:02.954] iteration 16356 : loss : 0.062291, loss_ce: 0.010516
[02:08:03.256] iteration 16357 : loss : 0.103191, loss_ce: 0.015794
[02:08:03.565] iteration 16358 : loss : 0.043553, loss_ce: 0.012513
[02:08:03.868] iteration 16359 : loss : 0.038991, loss_ce: 0.009182
[02:08:04.169] iteration 16360 : loss : 0.041755, loss_ce: 0.012968
[02:08:04.490] iteration 16361 : loss : 0.097132, loss_ce: 0.011865
[02:08:04.796] iteration 16362 : loss : 0.040935, loss_ce: 0.010159
[02:08:05.103] iteration 16363 : loss : 0.079726, loss_ce: 0.009677
[02:08:05.410] iteration 16364 : loss : 0.054707, loss_ce: 0.013283
[02:08:05.715] iteration 16365 : loss : 0.060056, loss_ce: 0.015594
[02:08:06.018] iteration 16366 : loss : 0.044144, loss_ce: 0.009766
[02:08:06.319] iteration 16367 : loss : 0.042899, loss_ce: 0.014829
[02:08:06.624] iteration 16368 : loss : 0.045615, loss_ce: 0.015408
[02:08:06.925] iteration 16369 : loss : 0.044300, loss_ce: 0.014155
[02:08:07.231] iteration 16370 : loss : 0.128083, loss_ce: 0.005249
[02:08:07.533] iteration 16371 : loss : 0.039097, loss_ce: 0.016631
[02:08:07.833] iteration 16372 : loss : 0.107117, loss_ce: 0.009470
[02:08:08.141] iteration 16373 : loss : 0.118127, loss_ce: 0.007623
[02:08:08.442] iteration 16374 : loss : 0.107932, loss_ce: 0.007919
[02:08:08.747] iteration 16375 : loss : 0.043030, loss_ce: 0.009782
[02:08:09.054] iteration 16376 : loss : 0.057037, loss_ce: 0.022192
[02:08:09.359] iteration 16377 : loss : 0.050372, loss_ce: 0.015494
[02:08:09.665] iteration 16378 : loss : 0.111568, loss_ce: 0.009414
[02:08:09.971] iteration 16379 : loss : 0.046830, loss_ce: 0.009294
[02:08:10.274] iteration 16380 : loss : 0.037848, loss_ce: 0.015718
[02:08:10.594] iteration 16381 : loss : 0.063327, loss_ce: 0.022806
[02:08:10.897] iteration 16382 : loss : 0.049701, loss_ce: 0.013487
[02:08:11.203] iteration 16383 : loss : 0.104233, loss_ce: 0.013628
[02:08:11.506] iteration 16384 : loss : 0.054902, loss_ce: 0.017724
[02:08:11.814] iteration 16385 : loss : 0.048787, loss_ce: 0.014230
[02:08:12.125] iteration 16386 : loss : 0.053394, loss_ce: 0.016110
[02:08:12.435] iteration 16387 : loss : 0.053131, loss_ce: 0.015340
[02:08:12.745] iteration 16388 : loss : 0.038084, loss_ce: 0.013840
[02:08:13.051] iteration 16389 : loss : 0.105561, loss_ce: 0.007309
[02:08:13.361] iteration 16390 : loss : 0.049668, loss_ce: 0.009749
[02:08:13.669] iteration 16391 : loss : 0.040876, loss_ce: 0.016044
[02:08:13.975] iteration 16392 : loss : 0.118521, loss_ce: 0.015879
[02:08:14.283] iteration 16393 : loss : 0.042523, loss_ce: 0.007188
[02:08:14.592] iteration 16394 : loss : 0.055713, loss_ce: 0.019855
[02:08:14.893] iteration 16395 : loss : 0.079152, loss_ce: 0.009268
[02:08:15.198] iteration 16396 : loss : 0.055621, loss_ce: 0.013123
[02:08:15.503] iteration 16397 : loss : 0.050722, loss_ce: 0.011121
[02:08:15.811] iteration 16398 : loss : 0.045822, loss_ce: 0.020155
[02:08:16.112] iteration 16399 : loss : 0.048474, loss_ce: 0.019829
[02:08:16.417] iteration 16400 : loss : 0.036283, loss_ce: 0.012798
[02:08:16.740] iteration 16401 : loss : 0.044382, loss_ce: 0.014865
[02:08:16.821] iteration 16402 : loss : 0.012763, loss_ce: 0.000007
[02:08:34.843] iteration 16403 : loss : 0.050742, loss_ce: 0.023769
[02:08:35.149] iteration 16404 : loss : 0.107311, loss_ce: 0.016543
[02:08:35.459] iteration 16405 : loss : 0.046634, loss_ce: 0.009312
[02:08:35.768] iteration 16406 : loss : 0.048486, loss_ce: 0.023882
[02:08:36.067] iteration 16407 : loss : 0.045057, loss_ce: 0.021633
[02:08:36.362] iteration 16408 : loss : 0.038969, loss_ce: 0.013258
[02:08:36.658] iteration 16409 : loss : 0.047140, loss_ce: 0.016008
[02:08:36.961] iteration 16410 : loss : 0.044357, loss_ce: 0.011286
[02:08:37.256] iteration 16411 : loss : 0.040717, loss_ce: 0.021127
[02:08:37.552] iteration 16412 : loss : 0.039726, loss_ce: 0.014261
[02:08:37.851] iteration 16413 : loss : 0.054064, loss_ce: 0.009708
[02:08:38.146] iteration 16414 : loss : 0.060685, loss_ce: 0.019248
[02:08:38.440] iteration 16415 : loss : 0.040048, loss_ce: 0.015834
[02:08:38.738] iteration 16416 : loss : 0.047590, loss_ce: 0.012752
[02:08:39.035] iteration 16417 : loss : 0.046448, loss_ce: 0.008993
[02:08:39.333] iteration 16418 : loss : 0.042838, loss_ce: 0.013453
[02:08:39.633] iteration 16419 : loss : 0.110747, loss_ce: 0.016170
[02:08:39.931] iteration 16420 : loss : 0.090048, loss_ce: 0.006782
[02:08:40.241] iteration 16421 : loss : 0.110431, loss_ce: 0.013943
[02:08:40.537] iteration 16422 : loss : 0.043735, loss_ce: 0.013944
[02:08:40.834] iteration 16423 : loss : 0.167294, loss_ce: 0.008912
[02:08:41.136] iteration 16424 : loss : 0.094798, loss_ce: 0.008446
[02:08:41.435] iteration 16425 : loss : 0.056385, loss_ce: 0.013311
[02:08:41.729] iteration 16426 : loss : 0.052934, loss_ce: 0.020363
[02:08:42.027] iteration 16427 : loss : 0.049256, loss_ce: 0.017481
[02:08:42.323] iteration 16428 : loss : 0.114126, loss_ce: 0.012880
[02:08:42.621] iteration 16429 : loss : 0.043498, loss_ce: 0.007561
[02:08:42.921] iteration 16430 : loss : 0.104690, loss_ce: 0.015529
[02:08:43.222] iteration 16431 : loss : 0.051225, loss_ce: 0.016442
[02:08:43.525] iteration 16432 : loss : 0.058044, loss_ce: 0.006874
[02:08:43.820] iteration 16433 : loss : 0.047308, loss_ce: 0.014028
[02:08:44.121] iteration 16434 : loss : 0.060139, loss_ce: 0.023148
[02:08:44.416] iteration 16435 : loss : 0.291404, loss_ce: 0.004741
[02:08:44.714] iteration 16436 : loss : 0.068279, loss_ce: 0.009415
[02:08:45.013] iteration 16437 : loss : 0.040812, loss_ce: 0.008895
[02:08:45.310] iteration 16438 : loss : 0.048968, loss_ce: 0.010328
[02:08:45.607] iteration 16439 : loss : 0.055114, loss_ce: 0.017875
[02:08:45.906] iteration 16440 : loss : 0.051564, loss_ce: 0.018081
[02:08:46.220] iteration 16441 : loss : 0.050850, loss_ce: 0.009677
[02:08:46.518] iteration 16442 : loss : 0.065344, loss_ce: 0.010497
[02:08:46.815] iteration 16443 : loss : 0.044045, loss_ce: 0.016051
[02:08:47.110] iteration 16444 : loss : 0.057817, loss_ce: 0.013859
[02:08:47.411] iteration 16445 : loss : 0.049520, loss_ce: 0.013958
[02:08:47.709] iteration 16446 : loss : 0.102474, loss_ce: 0.006386
[02:08:48.012] iteration 16447 : loss : 0.044679, loss_ce: 0.014111
[02:08:48.310] iteration 16448 : loss : 0.045828, loss_ce: 0.009363
[02:08:48.610] iteration 16449 : loss : 0.043393, loss_ce: 0.018381
[02:08:48.909] iteration 16450 : loss : 0.104244, loss_ce: 0.018048
[02:08:49.206] iteration 16451 : loss : 0.049312, loss_ce: 0.021547
[02:08:49.514] iteration 16452 : loss : 0.040368, loss_ce: 0.012276
[02:08:49.809] iteration 16453 : loss : 0.050672, loss_ce: 0.020972
[02:08:50.111] iteration 16454 : loss : 0.048441, loss_ce: 0.017051
[02:08:50.410] iteration 16455 : loss : 0.050923, loss_ce: 0.008078
[02:08:50.710] iteration 16456 : loss : 0.036893, loss_ce: 0.009725
[02:08:51.008] iteration 16457 : loss : 0.046773, loss_ce: 0.004434
[02:08:51.311] iteration 16458 : loss : 0.036284, loss_ce: 0.011848
[02:08:51.612] iteration 16459 : loss : 0.104736, loss_ce: 0.009996
[02:08:51.911] iteration 16460 : loss : 0.167939, loss_ce: 0.007165
[02:08:52.227] iteration 16461 : loss : 0.038209, loss_ce: 0.012201
[02:08:52.530] iteration 16462 : loss : 0.101726, loss_ce: 0.009818
[02:08:52.829] iteration 16463 : loss : 0.060120, loss_ce: 0.011176
[02:08:53.129] iteration 16464 : loss : 0.043724, loss_ce: 0.009863
[02:08:53.433] iteration 16465 : loss : 0.119554, loss_ce: 0.012323
[02:08:53.736] iteration 16466 : loss : 0.042820, loss_ce: 0.004569
[02:08:54.039] iteration 16467 : loss : 0.041092, loss_ce: 0.012476
[02:08:54.342] iteration 16468 : loss : 0.051130, loss_ce: 0.014383
[02:08:54.646] iteration 16469 : loss : 0.038189, loss_ce: 0.013301
[02:08:54.951] iteration 16470 : loss : 0.048015, loss_ce: 0.017686
[02:08:55.258] iteration 16471 : loss : 0.040745, loss_ce: 0.015488
[02:08:55.564] iteration 16472 : loss : 0.042928, loss_ce: 0.010757
[02:08:55.863] iteration 16473 : loss : 0.047390, loss_ce: 0.014428
[02:08:56.166] iteration 16474 : loss : 0.045959, loss_ce: 0.012071
[02:08:56.466] iteration 16475 : loss : 0.044706, loss_ce: 0.011708
[02:08:56.771] iteration 16476 : loss : 0.159479, loss_ce: 0.010777
[02:08:57.073] iteration 16477 : loss : 0.057572, loss_ce: 0.015791
[02:08:57.377] iteration 16478 : loss : 0.129903, loss_ce: 0.008648
[02:08:57.681] iteration 16479 : loss : 0.044257, loss_ce: 0.017173
[02:08:57.981] iteration 16480 : loss : 0.036626, loss_ce: 0.016814
[02:08:58.299] iteration 16481 : loss : 0.047275, loss_ce: 0.013171
[02:08:58.605] iteration 16482 : loss : 0.038504, loss_ce: 0.017438
[02:08:58.904] iteration 16483 : loss : 0.046599, loss_ce: 0.009617
[02:08:59.211] iteration 16484 : loss : 0.043186, loss_ce: 0.014077
[02:08:59.518] iteration 16485 : loss : 0.037617, loss_ce: 0.012893
[02:08:59.818] iteration 16486 : loss : 0.054131, loss_ce: 0.010193
[02:09:00.122] iteration 16487 : loss : 0.057507, loss_ce: 0.006559
[02:09:00.423] iteration 16488 : loss : 0.178327, loss_ce: 0.007562
[02:09:00.723] iteration 16489 : loss : 0.108152, loss_ce: 0.007280
[02:09:01.031] iteration 16490 : loss : 0.078215, loss_ce: 0.008645
[02:09:01.332] iteration 16491 : loss : 0.039116, loss_ce: 0.008030
[02:09:01.634] iteration 16492 : loss : 0.059289, loss_ce: 0.019073
[02:09:01.937] iteration 16493 : loss : 0.041732, loss_ce: 0.013216
[02:09:02.239] iteration 16494 : loss : 0.102084, loss_ce: 0.006292
[02:09:02.542] iteration 16495 : loss : 0.119213, loss_ce: 0.012105
[02:09:02.846] iteration 16496 : loss : 0.051883, loss_ce: 0.021617
[02:09:03.151] iteration 16497 : loss : 0.103458, loss_ce: 0.008422
[02:09:03.452] iteration 16498 : loss : 0.162257, loss_ce: 0.014877
[02:09:03.753] iteration 16499 : loss : 0.045112, loss_ce: 0.013439
[02:09:04.059] iteration 16500 : loss : 0.048501, loss_ce: 0.014088
[02:09:04.382] iteration 16501 : loss : 0.122763, loss_ce: 0.012666
[02:09:04.686] iteration 16502 : loss : 0.103194, loss_ce: 0.007792
[02:09:04.991] iteration 16503 : loss : 0.103544, loss_ce: 0.012414
[02:09:05.295] iteration 16504 : loss : 0.041465, loss_ce: 0.018225
[02:09:05.598] iteration 16505 : loss : 0.046593, loss_ce: 0.019814
[02:09:05.899] iteration 16506 : loss : 0.043757, loss_ce: 0.013492
[02:09:06.202] iteration 16507 : loss : 0.045631, loss_ce: 0.009556
[02:09:06.503] iteration 16508 : loss : 0.108104, loss_ce: 0.007780
[02:09:06.810] iteration 16509 : loss : 0.064693, loss_ce: 0.015914
[02:09:07.114] iteration 16510 : loss : 0.039258, loss_ce: 0.008975
[02:09:07.418] iteration 16511 : loss : 0.050959, loss_ce: 0.017831
[02:09:07.722] iteration 16512 : loss : 0.043317, loss_ce: 0.012060
[02:09:08.022] iteration 16513 : loss : 0.061729, loss_ce: 0.017142
[02:09:08.323] iteration 16514 : loss : 0.045616, loss_ce: 0.016982
[02:09:08.624] iteration 16515 : loss : 0.049228, loss_ce: 0.010814
[02:09:08.926] iteration 16516 : loss : 0.044589, loss_ce: 0.013495
[02:09:09.234] iteration 16517 : loss : 0.093816, loss_ce: 0.010785
[02:09:09.541] iteration 16518 : loss : 0.052138, loss_ce: 0.017998
[02:09:09.839] iteration 16519 : loss : 0.040235, loss_ce: 0.018768
[02:09:10.143] iteration 16520 : loss : 0.056313, loss_ce: 0.014749
[02:09:10.461] iteration 16521 : loss : 0.047090, loss_ce: 0.014152
[02:09:10.765] iteration 16522 : loss : 0.037743, loss_ce: 0.013577
[02:09:11.068] iteration 16523 : loss : 0.043231, loss_ce: 0.021682
[02:09:11.369] iteration 16524 : loss : 0.054022, loss_ce: 0.013344
[02:09:11.668] iteration 16525 : loss : 0.037671, loss_ce: 0.010019
[02:09:11.971] iteration 16526 : loss : 0.043545, loss_ce: 0.012005
[02:09:12.275] iteration 16527 : loss : 0.034409, loss_ce: 0.010753
[02:09:12.575] iteration 16528 : loss : 0.048352, loss_ce: 0.016035
[02:09:12.882] iteration 16529 : loss : 0.124527, loss_ce: 0.019693
[02:09:13.185] iteration 16530 : loss : 0.066559, loss_ce: 0.020745
[02:09:13.483] iteration 16531 : loss : 0.046695, loss_ce: 0.016379
[02:09:13.788] iteration 16532 : loss : 0.174637, loss_ce: 0.012293
[02:09:14.091] iteration 16533 : loss : 0.043899, loss_ce: 0.018285
[02:09:14.390] iteration 16534 : loss : 0.108335, loss_ce: 0.017500
[02:09:14.691] iteration 16535 : loss : 0.049623, loss_ce: 0.010731
[02:09:15.000] iteration 16536 : loss : 0.042627, loss_ce: 0.015774
[02:09:15.301] iteration 16537 : loss : 0.048600, loss_ce: 0.015477
[02:09:15.605] iteration 16538 : loss : 0.116119, loss_ce: 0.009693
[02:09:15.912] iteration 16539 : loss : 0.045556, loss_ce: 0.021121
[02:09:16.221] iteration 16540 : loss : 0.099515, loss_ce: 0.007720
[02:09:16.349] iteration 16541 : loss : 0.284227, loss_ce: 0.015719
[02:09:36.252] iteration 16542 : loss : 0.039348, loss_ce: 0.010878
[02:09:36.553] iteration 16543 : loss : 0.115741, loss_ce: 0.009114
[02:09:36.857] iteration 16544 : loss : 0.044827, loss_ce: 0.009723
[02:09:37.156] iteration 16545 : loss : 0.035664, loss_ce: 0.013765
[02:09:37.456] iteration 16546 : loss : 0.040325, loss_ce: 0.011554
[02:09:37.755] iteration 16547 : loss : 0.036468, loss_ce: 0.010986
[02:09:38.051] iteration 16548 : loss : 0.041876, loss_ce: 0.008610
[02:09:38.348] iteration 16549 : loss : 0.047946, loss_ce: 0.015523
[02:09:38.645] iteration 16550 : loss : 0.041029, loss_ce: 0.015852
[02:09:38.942] iteration 16551 : loss : 0.045374, loss_ce: 0.014164
[02:09:39.245] iteration 16552 : loss : 0.056230, loss_ce: 0.020652
[02:09:39.549] iteration 16553 : loss : 0.111319, loss_ce: 0.012576
[02:09:39.851] iteration 16554 : loss : 0.050387, loss_ce: 0.012637
[02:09:40.151] iteration 16555 : loss : 0.049844, loss_ce: 0.013751
[02:09:40.458] iteration 16556 : loss : 0.044588, loss_ce: 0.016607
[02:09:40.759] iteration 16557 : loss : 0.035631, loss_ce: 0.008937
[02:09:41.060] iteration 16558 : loss : 0.045599, loss_ce: 0.018288
[02:09:41.360] iteration 16559 : loss : 0.047646, loss_ce: 0.021360
[02:09:41.658] iteration 16560 : loss : 0.048719, loss_ce: 0.017587
[02:09:41.979] iteration 16561 : loss : 0.040249, loss_ce: 0.012435
[02:09:42.286] iteration 16562 : loss : 0.038846, loss_ce: 0.016145
[02:09:42.583] iteration 16563 : loss : 0.044425, loss_ce: 0.010273
[02:09:42.880] iteration 16564 : loss : 0.051465, loss_ce: 0.016503
[02:09:43.182] iteration 16565 : loss : 0.042784, loss_ce: 0.012234
[02:09:43.479] iteration 16566 : loss : 0.040891, loss_ce: 0.010763
[02:09:43.773] iteration 16567 : loss : 0.048813, loss_ce: 0.007562
[02:09:44.077] iteration 16568 : loss : 0.042761, loss_ce: 0.010717
[02:09:44.373] iteration 16569 : loss : 0.040744, loss_ce: 0.014422
[02:09:44.673] iteration 16570 : loss : 0.049612, loss_ce: 0.015057
[02:09:44.970] iteration 16571 : loss : 0.067043, loss_ce: 0.011347
[02:09:45.267] iteration 16572 : loss : 0.044454, loss_ce: 0.015652
[02:09:45.561] iteration 16573 : loss : 0.072097, loss_ce: 0.014812
[02:09:45.861] iteration 16574 : loss : 0.101367, loss_ce: 0.006457
[02:09:46.155] iteration 16575 : loss : 0.051531, loss_ce: 0.013347
[02:09:46.452] iteration 16576 : loss : 0.042897, loss_ce: 0.007210
[02:09:46.747] iteration 16577 : loss : 0.044371, loss_ce: 0.022219
[02:09:47.039] iteration 16578 : loss : 0.052355, loss_ce: 0.018308
[02:09:47.342] iteration 16579 : loss : 0.054783, loss_ce: 0.019426
[02:09:47.642] iteration 16580 : loss : 0.088406, loss_ce: 0.012284
[02:09:47.960] iteration 16581 : loss : 0.097104, loss_ce: 0.009874
[02:09:48.256] iteration 16582 : loss : 0.049399, loss_ce: 0.006384
[02:09:48.561] iteration 16583 : loss : 0.039951, loss_ce: 0.009403
[02:09:48.857] iteration 16584 : loss : 0.044894, loss_ce: 0.016701
[02:09:49.153] iteration 16585 : loss : 0.047377, loss_ce: 0.016367
[02:09:49.455] iteration 16586 : loss : 0.118679, loss_ce: 0.011607
[02:09:49.752] iteration 16587 : loss : 0.057363, loss_ce: 0.016209
[02:09:50.048] iteration 16588 : loss : 0.048056, loss_ce: 0.017556
[02:09:50.345] iteration 16589 : loss : 0.043478, loss_ce: 0.012460
[02:09:50.646] iteration 16590 : loss : 0.106700, loss_ce: 0.012070
[02:09:50.948] iteration 16591 : loss : 0.099699, loss_ce: 0.008556
[02:09:51.244] iteration 16592 : loss : 0.046558, loss_ce: 0.010962
[02:09:51.545] iteration 16593 : loss : 0.054709, loss_ce: 0.025574
[02:09:51.842] iteration 16594 : loss : 0.041644, loss_ce: 0.016401
[02:09:52.141] iteration 16595 : loss : 0.044442, loss_ce: 0.012706
[02:09:52.438] iteration 16596 : loss : 0.057631, loss_ce: 0.013819
[02:09:52.738] iteration 16597 : loss : 0.051961, loss_ce: 0.010191
[02:09:53.036] iteration 16598 : loss : 0.046333, loss_ce: 0.019534
[02:09:53.336] iteration 16599 : loss : 0.043891, loss_ce: 0.016976
[02:09:53.631] iteration 16600 : loss : 0.103581, loss_ce: 0.013506
[02:09:53.945] iteration 16601 : loss : 0.049522, loss_ce: 0.007606
[02:09:54.244] iteration 16602 : loss : 0.036209, loss_ce: 0.012744
[02:09:54.549] iteration 16603 : loss : 0.115680, loss_ce: 0.013455
[02:09:54.850] iteration 16604 : loss : 0.053676, loss_ce: 0.008046
[02:09:55.148] iteration 16605 : loss : 0.044858, loss_ce: 0.015590
[02:09:55.447] iteration 16606 : loss : 0.055845, loss_ce: 0.011879
[02:09:55.752] iteration 16607 : loss : 0.043539, loss_ce: 0.017330
[02:09:56.052] iteration 16608 : loss : 0.049528, loss_ce: 0.022884
[02:09:56.357] iteration 16609 : loss : 0.103102, loss_ce: 0.009932
[02:09:56.661] iteration 16610 : loss : 0.043574, loss_ce: 0.013901
[02:09:56.963] iteration 16611 : loss : 0.040994, loss_ce: 0.010779
[02:09:57.266] iteration 16612 : loss : 0.037846, loss_ce: 0.004661
[02:09:57.571] iteration 16613 : loss : 0.057032, loss_ce: 0.012539
[02:09:57.874] iteration 16614 : loss : 0.062702, loss_ce: 0.014296
[02:09:58.180] iteration 16615 : loss : 0.046370, loss_ce: 0.014543
[02:09:58.481] iteration 16616 : loss : 0.043261, loss_ce: 0.018059
[02:09:58.785] iteration 16617 : loss : 0.043387, loss_ce: 0.020964
[02:09:59.091] iteration 16618 : loss : 0.048727, loss_ce: 0.012871
[02:09:59.393] iteration 16619 : loss : 0.042104, loss_ce: 0.008077
[02:09:59.699] iteration 16620 : loss : 0.049250, loss_ce: 0.023115
[02:10:00.020] iteration 16621 : loss : 0.084822, loss_ce: 0.022787
[02:10:00.324] iteration 16622 : loss : 0.097180, loss_ce: 0.013860
[02:10:00.630] iteration 16623 : loss : 0.044038, loss_ce: 0.005796
[02:10:00.934] iteration 16624 : loss : 0.046833, loss_ce: 0.013060
[02:10:01.237] iteration 16625 : loss : 0.042099, loss_ce: 0.009882
[02:10:01.542] iteration 16626 : loss : 0.044878, loss_ce: 0.016650
[02:10:01.844] iteration 16627 : loss : 0.100259, loss_ce: 0.007500
[02:10:02.147] iteration 16628 : loss : 0.220016, loss_ce: 0.005231
[02:10:02.451] iteration 16629 : loss : 0.042166, loss_ce: 0.020219
[02:10:02.753] iteration 16630 : loss : 0.041838, loss_ce: 0.010295
[02:10:03.054] iteration 16631 : loss : 0.057409, loss_ce: 0.016590
[02:10:03.352] iteration 16632 : loss : 0.061754, loss_ce: 0.017839
[02:10:03.658] iteration 16633 : loss : 0.048225, loss_ce: 0.015461
[02:10:03.960] iteration 16634 : loss : 0.041872, loss_ce: 0.006952
[02:10:04.257] iteration 16635 : loss : 0.038256, loss_ce: 0.016008
[02:10:04.564] iteration 16636 : loss : 0.043480, loss_ce: 0.008436
[02:10:04.865] iteration 16637 : loss : 0.048773, loss_ce: 0.008748
[02:10:05.165] iteration 16638 : loss : 0.067178, loss_ce: 0.025619
[02:10:05.468] iteration 16639 : loss : 0.110760, loss_ce: 0.011620
[02:10:05.772] iteration 16640 : loss : 0.113774, loss_ce: 0.009032
[02:10:06.086] iteration 16641 : loss : 0.049321, loss_ce: 0.015546
[02:10:06.390] iteration 16642 : loss : 0.035715, loss_ce: 0.010330
[02:10:06.692] iteration 16643 : loss : 0.047425, loss_ce: 0.009771
[02:10:06.998] iteration 16644 : loss : 0.103024, loss_ce: 0.006390
[02:10:07.300] iteration 16645 : loss : 0.050357, loss_ce: 0.016395
[02:10:07.608] iteration 16646 : loss : 0.103030, loss_ce: 0.015298
[02:10:07.909] iteration 16647 : loss : 0.112901, loss_ce: 0.008719
[02:10:08.212] iteration 16648 : loss : 0.102878, loss_ce: 0.015637
[02:10:08.512] iteration 16649 : loss : 0.054240, loss_ce: 0.011746
[02:10:08.811] iteration 16650 : loss : 0.047562, loss_ce: 0.016716
[02:10:09.115] iteration 16651 : loss : 0.099230, loss_ce: 0.009183
[02:10:09.418] iteration 16652 : loss : 0.101998, loss_ce: 0.013554
[02:10:09.721] iteration 16653 : loss : 0.059268, loss_ce: 0.011336
[02:10:10.023] iteration 16654 : loss : 0.044345, loss_ce: 0.015775
[02:10:10.323] iteration 16655 : loss : 0.055227, loss_ce: 0.017993
[02:10:10.626] iteration 16656 : loss : 0.041925, loss_ce: 0.007572
[02:10:10.927] iteration 16657 : loss : 0.038302, loss_ce: 0.011346
[02:10:11.232] iteration 16658 : loss : 0.043206, loss_ce: 0.016750
[02:10:11.534] iteration 16659 : loss : 0.049535, loss_ce: 0.016579
[02:10:11.838] iteration 16660 : loss : 0.041640, loss_ce: 0.012978
[02:10:12.159] iteration 16661 : loss : 0.048910, loss_ce: 0.022664
[02:10:12.461] iteration 16662 : loss : 0.136424, loss_ce: 0.003347
[02:10:12.764] iteration 16663 : loss : 0.049089, loss_ce: 0.019738
[02:10:13.068] iteration 16664 : loss : 0.113809, loss_ce: 0.008331
[02:10:13.374] iteration 16665 : loss : 0.103218, loss_ce: 0.017287
[02:10:13.678] iteration 16666 : loss : 0.113124, loss_ce: 0.013579
[02:10:13.984] iteration 16667 : loss : 0.046542, loss_ce: 0.015545
[02:10:14.292] iteration 16668 : loss : 0.041280, loss_ce: 0.016113
[02:10:14.595] iteration 16669 : loss : 0.174577, loss_ce: 0.012740
[02:10:14.911] iteration 16670 : loss : 0.040780, loss_ce: 0.012382
[02:10:15.215] iteration 16671 : loss : 0.050124, loss_ce: 0.008066
[02:10:15.516] iteration 16672 : loss : 0.052467, loss_ce: 0.020266
[02:10:15.824] iteration 16673 : loss : 0.103970, loss_ce: 0.006685
[02:10:16.131] iteration 16674 : loss : 0.042125, loss_ce: 0.020402
[02:10:16.433] iteration 16675 : loss : 0.097779, loss_ce: 0.007205
[02:10:16.735] iteration 16676 : loss : 0.057372, loss_ce: 0.017971
[02:10:17.039] iteration 16677 : loss : 0.108397, loss_ce: 0.012804
[02:10:17.336] iteration 16678 : loss : 0.108238, loss_ce: 0.013685
[02:10:17.636] iteration 16679 : loss : 0.040477, loss_ce: 0.014109
[02:10:17.714] iteration 16680 : loss : 0.106396, loss_ce: 0.020718
[02:10:34.996] iteration 16681 : loss : 0.046064, loss_ce: 0.012446
[02:10:35.297] iteration 16682 : loss : 0.033890, loss_ce: 0.006423
[02:10:35.604] iteration 16683 : loss : 0.053068, loss_ce: 0.011007
[02:10:35.906] iteration 16684 : loss : 0.119743, loss_ce: 0.007774
[02:10:36.208] iteration 16685 : loss : 0.052755, loss_ce: 0.014937
[02:10:36.499] iteration 16686 : loss : 0.046521, loss_ce: 0.019399
[02:10:36.804] iteration 16687 : loss : 0.055621, loss_ce: 0.017799
[02:10:37.100] iteration 16688 : loss : 0.044417, loss_ce: 0.014403
[02:10:37.398] iteration 16689 : loss : 0.042058, loss_ce: 0.009042
[02:10:37.690] iteration 16690 : loss : 0.098756, loss_ce: 0.009765
[02:10:37.983] iteration 16691 : loss : 0.043864, loss_ce: 0.014102
[02:10:38.283] iteration 16692 : loss : 0.039048, loss_ce: 0.021360
[02:10:38.580] iteration 16693 : loss : 0.042353, loss_ce: 0.013329
[02:10:38.877] iteration 16694 : loss : 0.057647, loss_ce: 0.017975
[02:10:39.176] iteration 16695 : loss : 0.061016, loss_ce: 0.011333
[02:10:39.477] iteration 16696 : loss : 0.218039, loss_ce: 0.003322
[02:10:39.778] iteration 16697 : loss : 0.046365, loss_ce: 0.014125
[02:10:40.073] iteration 16698 : loss : 0.038095, loss_ce: 0.013807
[02:10:40.368] iteration 16699 : loss : 0.047428, loss_ce: 0.011866
[02:10:40.661] iteration 16700 : loss : 0.052452, loss_ce: 0.009643
[02:10:40.979] iteration 16701 : loss : 0.043364, loss_ce: 0.014947
[02:10:41.276] iteration 16702 : loss : 0.044570, loss_ce: 0.009121
[02:10:41.574] iteration 16703 : loss : 0.067234, loss_ce: 0.016966
[02:10:41.874] iteration 16704 : loss : 0.038968, loss_ce: 0.012175
[02:10:42.170] iteration 16705 : loss : 0.047140, loss_ce: 0.016494
[02:10:42.469] iteration 16706 : loss : 0.102141, loss_ce: 0.011711
[02:10:42.768] iteration 16707 : loss : 0.040817, loss_ce: 0.009379
[02:10:43.070] iteration 16708 : loss : 0.044849, loss_ce: 0.011635
[02:10:43.367] iteration 16709 : loss : 0.035002, loss_ce: 0.012502
[02:10:43.661] iteration 16710 : loss : 0.059231, loss_ce: 0.010441
[02:10:43.960] iteration 16711 : loss : 0.041483, loss_ce: 0.005855
[02:10:44.258] iteration 16712 : loss : 0.059273, loss_ce: 0.021763
[02:10:44.556] iteration 16713 : loss : 0.063908, loss_ce: 0.011623
[02:10:44.859] iteration 16714 : loss : 0.041981, loss_ce: 0.014782
[02:10:45.160] iteration 16715 : loss : 0.037643, loss_ce: 0.010548
[02:10:45.458] iteration 16716 : loss : 0.040943, loss_ce: 0.017887
[02:10:45.760] iteration 16717 : loss : 0.104497, loss_ce: 0.011944
[02:10:46.060] iteration 16718 : loss : 0.045211, loss_ce: 0.011950
[02:10:46.361] iteration 16719 : loss : 0.056041, loss_ce: 0.020837
[02:10:46.664] iteration 16720 : loss : 0.052320, loss_ce: 0.010928
[02:10:46.980] iteration 16721 : loss : 0.044674, loss_ce: 0.017872
[02:10:47.282] iteration 16722 : loss : 0.037166, loss_ce: 0.009576
[02:10:47.585] iteration 16723 : loss : 0.044492, loss_ce: 0.017573
[02:10:47.888] iteration 16724 : loss : 0.046601, loss_ce: 0.017208
[02:10:48.195] iteration 16725 : loss : 0.051890, loss_ce: 0.015791
[02:10:48.497] iteration 16726 : loss : 0.037460, loss_ce: 0.009118
[02:10:48.802] iteration 16727 : loss : 0.035270, loss_ce: 0.008690
[02:10:49.102] iteration 16728 : loss : 0.044510, loss_ce: 0.016494
[02:10:49.405] iteration 16729 : loss : 0.039170, loss_ce: 0.010209
[02:10:49.713] iteration 16730 : loss : 0.049504, loss_ce: 0.020039
[02:10:50.015] iteration 16731 : loss : 0.048033, loss_ce: 0.021177
[02:10:50.315] iteration 16732 : loss : 0.104545, loss_ce: 0.012839
[02:10:50.619] iteration 16733 : loss : 0.058386, loss_ce: 0.020530
[02:10:50.921] iteration 16734 : loss : 0.037275, loss_ce: 0.012332
[02:10:51.227] iteration 16735 : loss : 0.051846, loss_ce: 0.015416
[02:10:51.527] iteration 16736 : loss : 0.096604, loss_ce: 0.007778
[02:10:51.827] iteration 16737 : loss : 0.046812, loss_ce: 0.013779
[02:10:52.131] iteration 16738 : loss : 0.047480, loss_ce: 0.013581
[02:10:52.432] iteration 16739 : loss : 0.055486, loss_ce: 0.016281
[02:10:52.731] iteration 16740 : loss : 0.113458, loss_ce: 0.017187
[02:10:53.051] iteration 16741 : loss : 0.061888, loss_ce: 0.013297
[02:10:53.352] iteration 16742 : loss : 0.040827, loss_ce: 0.016022
[02:10:53.659] iteration 16743 : loss : 0.048754, loss_ce: 0.009365
[02:10:53.960] iteration 16744 : loss : 0.045441, loss_ce: 0.010578
[02:10:54.264] iteration 16745 : loss : 0.037708, loss_ce: 0.009162
[02:10:54.564] iteration 16746 : loss : 0.044283, loss_ce: 0.018150
[02:10:54.867] iteration 16747 : loss : 0.044662, loss_ce: 0.012999
[02:10:55.167] iteration 16748 : loss : 0.043242, loss_ce: 0.006199
[02:10:55.470] iteration 16749 : loss : 0.034148, loss_ce: 0.013290
[02:10:55.775] iteration 16750 : loss : 0.046407, loss_ce: 0.012841
[02:10:56.081] iteration 16751 : loss : 0.101742, loss_ce: 0.011821
[02:10:56.381] iteration 16752 : loss : 0.072785, loss_ce: 0.012451
[02:10:56.687] iteration 16753 : loss : 0.046865, loss_ce: 0.013289
[02:10:56.991] iteration 16754 : loss : 0.048350, loss_ce: 0.012056
[02:10:57.296] iteration 16755 : loss : 0.100450, loss_ce: 0.012317
[02:10:57.598] iteration 16756 : loss : 0.080032, loss_ce: 0.014904
[02:10:57.898] iteration 16757 : loss : 0.042503, loss_ce: 0.008457
[02:10:58.203] iteration 16758 : loss : 0.052616, loss_ce: 0.015601
[02:10:58.508] iteration 16759 : loss : 0.108114, loss_ce: 0.013741
[02:10:58.808] iteration 16760 : loss : 0.052507, loss_ce: 0.014394
[02:10:59.124] iteration 16761 : loss : 0.054230, loss_ce: 0.017871
[02:10:59.426] iteration 16762 : loss : 0.040081, loss_ce: 0.020580
[02:10:59.728] iteration 16763 : loss : 0.041897, loss_ce: 0.009035
[02:11:00.027] iteration 16764 : loss : 0.077596, loss_ce: 0.007923
[02:11:00.334] iteration 16765 : loss : 0.166898, loss_ce: 0.005134
[02:11:00.634] iteration 16766 : loss : 0.056781, loss_ce: 0.011365
[02:11:00.942] iteration 16767 : loss : 0.101334, loss_ce: 0.012510
[02:11:01.245] iteration 16768 : loss : 0.037333, loss_ce: 0.011173
[02:11:01.548] iteration 16769 : loss : 0.040567, loss_ce: 0.005455
[02:11:01.849] iteration 16770 : loss : 0.049824, loss_ce: 0.011741
[02:11:02.147] iteration 16771 : loss : 0.060555, loss_ce: 0.025390
[02:11:02.449] iteration 16772 : loss : 0.058095, loss_ce: 0.019836
[02:11:02.748] iteration 16773 : loss : 0.046304, loss_ce: 0.014924
[02:11:03.049] iteration 16774 : loss : 0.107883, loss_ce: 0.015929
[02:11:03.354] iteration 16775 : loss : 0.047394, loss_ce: 0.014545
[02:11:03.656] iteration 16776 : loss : 0.056403, loss_ce: 0.008636
[02:11:03.958] iteration 16777 : loss : 0.035999, loss_ce: 0.013121
[02:11:04.266] iteration 16778 : loss : 0.103315, loss_ce: 0.015700
[02:11:04.568] iteration 16779 : loss : 0.038892, loss_ce: 0.011004
[02:11:04.871] iteration 16780 : loss : 0.042175, loss_ce: 0.005615
[02:11:05.192] iteration 16781 : loss : 0.051995, loss_ce: 0.020690
[02:11:05.491] iteration 16782 : loss : 0.051800, loss_ce: 0.019350
[02:11:05.797] iteration 16783 : loss : 0.055743, loss_ce: 0.020902
[02:11:06.098] iteration 16784 : loss : 0.107070, loss_ce: 0.014158
[02:11:06.399] iteration 16785 : loss : 0.090536, loss_ce: 0.019269
[02:11:06.698] iteration 16786 : loss : 0.043774, loss_ce: 0.011808
[02:11:06.998] iteration 16787 : loss : 0.044926, loss_ce: 0.008940
[02:11:07.298] iteration 16788 : loss : 0.091555, loss_ce: 0.003432
[02:11:07.599] iteration 16789 : loss : 0.056150, loss_ce: 0.015221
[02:11:07.896] iteration 16790 : loss : 0.051127, loss_ce: 0.021474
[02:11:08.196] iteration 16791 : loss : 0.031440, loss_ce: 0.005264
[02:11:08.494] iteration 16792 : loss : 0.050818, loss_ce: 0.017185
[02:11:08.795] iteration 16793 : loss : 0.046344, loss_ce: 0.018484
[02:11:09.091] iteration 16794 : loss : 0.046721, loss_ce: 0.009018
[02:11:09.388] iteration 16795 : loss : 0.110525, loss_ce: 0.019889
[02:11:09.693] iteration 16796 : loss : 0.039365, loss_ce: 0.012636
[02:11:09.994] iteration 16797 : loss : 0.039461, loss_ce: 0.015372
[02:11:10.293] iteration 16798 : loss : 0.044617, loss_ce: 0.014365
[02:11:10.594] iteration 16799 : loss : 0.105226, loss_ce: 0.009465
[02:11:10.891] iteration 16800 : loss : 0.040778, loss_ce: 0.009603
[02:11:11.205] iteration 16801 : loss : 0.035559, loss_ce: 0.012818
[02:11:11.505] iteration 16802 : loss : 0.074001, loss_ce: 0.006309
[02:11:11.804] iteration 16803 : loss : 0.101579, loss_ce: 0.013626
[02:11:12.102] iteration 16804 : loss : 0.044711, loss_ce: 0.010256
[02:11:12.401] iteration 16805 : loss : 0.049539, loss_ce: 0.020071
[02:11:12.702] iteration 16806 : loss : 0.041407, loss_ce: 0.014715
[02:11:13.003] iteration 16807 : loss : 0.057474, loss_ce: 0.016313
[02:11:13.303] iteration 16808 : loss : 0.107130, loss_ce: 0.013436
[02:11:13.602] iteration 16809 : loss : 0.043144, loss_ce: 0.014303
[02:11:13.906] iteration 16810 : loss : 0.047101, loss_ce: 0.022817
[02:11:14.207] iteration 16811 : loss : 0.045575, loss_ce: 0.015710
[02:11:14.509] iteration 16812 : loss : 0.056988, loss_ce: 0.008438
[02:11:14.814] iteration 16813 : loss : 0.058748, loss_ce: 0.016882
[02:11:15.122] iteration 16814 : loss : 0.035297, loss_ce: 0.011823
[02:11:15.433] iteration 16815 : loss : 0.048723, loss_ce: 0.016584
[02:11:15.734] iteration 16816 : loss : 0.078378, loss_ce: 0.009177
[02:11:16.043] iteration 16817 : loss : 0.040213, loss_ce: 0.008161
[02:11:16.346] iteration 16818 : loss : 0.044027, loss_ce: 0.015120
[02:11:16.430] iteration 16819 : loss : 0.347558, loss_ce: 0.011607
[02:11:35.601] iteration 16820 : loss : 0.048217, loss_ce: 0.021435
[02:11:35.937] iteration 16821 : loss : 0.094754, loss_ce: 0.004229
[02:11:36.249] iteration 16822 : loss : 0.036846, loss_ce: 0.007275
[02:11:36.554] iteration 16823 : loss : 0.104178, loss_ce: 0.014425
[02:11:36.859] iteration 16824 : loss : 0.060898, loss_ce: 0.011382
[02:11:37.157] iteration 16825 : loss : 0.038609, loss_ce: 0.013199
[02:11:37.456] iteration 16826 : loss : 0.173953, loss_ce: 0.010241
[02:11:37.753] iteration 16827 : loss : 0.038799, loss_ce: 0.016486
[02:11:38.051] iteration 16828 : loss : 0.047269, loss_ce: 0.018150
[02:11:38.346] iteration 16829 : loss : 0.061489, loss_ce: 0.016274
[02:11:38.645] iteration 16830 : loss : 0.050368, loss_ce: 0.011040
[02:11:38.942] iteration 16831 : loss : 0.042354, loss_ce: 0.014809
[02:11:39.237] iteration 16832 : loss : 0.043312, loss_ce: 0.012405
[02:11:39.532] iteration 16833 : loss : 0.057620, loss_ce: 0.023391
[02:11:39.833] iteration 16834 : loss : 0.100374, loss_ce: 0.004298
[02:11:40.126] iteration 16835 : loss : 0.052478, loss_ce: 0.014542
[02:11:40.424] iteration 16836 : loss : 0.100369, loss_ce: 0.013017
[02:11:40.721] iteration 16837 : loss : 0.110527, loss_ce: 0.016915
[02:11:41.017] iteration 16838 : loss : 0.048558, loss_ce: 0.020049
[02:11:41.312] iteration 16839 : loss : 0.101625, loss_ce: 0.008728
[02:11:41.614] iteration 16840 : loss : 0.103894, loss_ce: 0.007374
[02:11:41.926] iteration 16841 : loss : 0.035787, loss_ce: 0.007669
[02:11:42.227] iteration 16842 : loss : 0.043915, loss_ce: 0.008750
[02:11:42.526] iteration 16843 : loss : 0.054100, loss_ce: 0.016023
[02:11:42.827] iteration 16844 : loss : 0.106043, loss_ce: 0.008101
[02:11:43.123] iteration 16845 : loss : 0.046998, loss_ce: 0.016200
[02:11:43.419] iteration 16846 : loss : 0.041128, loss_ce: 0.012123
[02:11:43.718] iteration 16847 : loss : 0.054324, loss_ce: 0.007434
[02:11:44.017] iteration 16848 : loss : 0.054503, loss_ce: 0.014922
[02:11:44.316] iteration 16849 : loss : 0.045927, loss_ce: 0.018014
[02:11:44.615] iteration 16850 : loss : 0.042461, loss_ce: 0.013572
[02:11:44.913] iteration 16851 : loss : 0.095192, loss_ce: 0.005962
[02:11:45.210] iteration 16852 : loss : 0.044004, loss_ce: 0.016193
[02:11:45.510] iteration 16853 : loss : 0.056981, loss_ce: 0.027345
[02:11:45.814] iteration 16854 : loss : 0.218360, loss_ce: 0.011332
[02:11:46.111] iteration 16855 : loss : 0.098560, loss_ce: 0.011599
[02:11:46.412] iteration 16856 : loss : 0.108519, loss_ce: 0.016525
[02:11:46.710] iteration 16857 : loss : 0.043392, loss_ce: 0.019908
[02:11:47.008] iteration 16858 : loss : 0.042214, loss_ce: 0.015899
[02:11:47.310] iteration 16859 : loss : 0.042571, loss_ce: 0.008820
[02:11:47.609] iteration 16860 : loss : 0.047412, loss_ce: 0.015730
[02:11:47.929] iteration 16861 : loss : 0.122660, loss_ce: 0.006335
[02:11:48.227] iteration 16862 : loss : 0.047768, loss_ce: 0.015075
[02:11:48.522] iteration 16863 : loss : 0.041016, loss_ce: 0.013466
[02:11:48.817] iteration 16864 : loss : 0.060220, loss_ce: 0.007600
[02:11:49.118] iteration 16865 : loss : 0.056928, loss_ce: 0.006949
[02:11:49.421] iteration 16866 : loss : 0.046209, loss_ce: 0.015188
[02:11:49.727] iteration 16867 : loss : 0.040151, loss_ce: 0.015603
[02:11:50.031] iteration 16868 : loss : 0.107856, loss_ce: 0.007055
[02:11:50.334] iteration 16869 : loss : 0.045049, loss_ce: 0.006509
[02:11:50.634] iteration 16870 : loss : 0.039880, loss_ce: 0.010779
[02:11:50.969] iteration 16871 : loss : 0.051620, loss_ce: 0.020284
[02:11:51.290] iteration 16872 : loss : 0.101412, loss_ce: 0.009051
[02:11:51.623] iteration 16873 : loss : 0.050127, loss_ce: 0.022448
[02:11:51.953] iteration 16874 : loss : 0.049608, loss_ce: 0.013733
[02:11:52.285] iteration 16875 : loss : 0.043113, loss_ce: 0.016689
[02:11:52.612] iteration 16876 : loss : 0.043322, loss_ce: 0.013010
[02:11:52.943] iteration 16877 : loss : 0.045861, loss_ce: 0.013828
[02:11:53.266] iteration 16878 : loss : 0.058418, loss_ce: 0.018325
[02:11:53.604] iteration 16879 : loss : 0.035484, loss_ce: 0.008032
[02:11:53.937] iteration 16880 : loss : 0.056188, loss_ce: 0.018302
[02:11:54.284] iteration 16881 : loss : 0.055816, loss_ce: 0.006656
[02:11:54.616] iteration 16882 : loss : 0.107672, loss_ce: 0.010311
[02:11:54.940] iteration 16883 : loss : 0.034440, loss_ce: 0.012539
[02:11:55.268] iteration 16884 : loss : 0.043926, loss_ce: 0.008799
[02:11:55.595] iteration 16885 : loss : 0.096060, loss_ce: 0.008708
[02:11:55.920] iteration 16886 : loss : 0.046254, loss_ce: 0.018231
[02:11:56.249] iteration 16887 : loss : 0.042220, loss_ce: 0.015108
[02:11:56.577] iteration 16888 : loss : 0.036016, loss_ce: 0.006933
[02:11:56.898] iteration 16889 : loss : 0.041662, loss_ce: 0.017674
[02:11:57.195] iteration 16890 : loss : 0.050306, loss_ce: 0.011304
[02:11:57.496] iteration 16891 : loss : 0.039518, loss_ce: 0.008831
[02:11:57.797] iteration 16892 : loss : 0.051144, loss_ce: 0.018784
[02:11:58.093] iteration 16893 : loss : 0.047726, loss_ce: 0.019225
[02:11:58.396] iteration 16894 : loss : 0.041757, loss_ce: 0.007087
[02:11:58.696] iteration 16895 : loss : 0.055418, loss_ce: 0.025920
[02:11:58.991] iteration 16896 : loss : 0.040048, loss_ce: 0.016101
[02:11:59.286] iteration 16897 : loss : 0.039960, loss_ce: 0.010424
[02:11:59.582] iteration 16898 : loss : 0.096422, loss_ce: 0.010624
[02:11:59.877] iteration 16899 : loss : 0.037660, loss_ce: 0.014147
[02:12:00.178] iteration 16900 : loss : 0.041941, loss_ce: 0.015363
[02:12:00.492] iteration 16901 : loss : 0.056293, loss_ce: 0.012523
[02:12:00.789] iteration 16902 : loss : 0.222297, loss_ce: 0.009528
[02:12:01.091] iteration 16903 : loss : 0.046224, loss_ce: 0.012396
[02:12:01.388] iteration 16904 : loss : 0.053814, loss_ce: 0.013505
[02:12:01.684] iteration 16905 : loss : 0.048414, loss_ce: 0.015109
[02:12:01.982] iteration 16906 : loss : 0.040393, loss_ce: 0.019905
[02:12:02.288] iteration 16907 : loss : 0.099750, loss_ce: 0.009562
[02:12:02.584] iteration 16908 : loss : 0.048135, loss_ce: 0.021236
[02:12:02.879] iteration 16909 : loss : 0.054485, loss_ce: 0.024310
[02:12:03.177] iteration 16910 : loss : 0.050318, loss_ce: 0.015103
[02:12:03.474] iteration 16911 : loss : 0.036495, loss_ce: 0.009227
[02:12:03.772] iteration 16912 : loss : 0.046014, loss_ce: 0.013429
[02:12:04.068] iteration 16913 : loss : 0.042017, loss_ce: 0.020334
[02:12:04.371] iteration 16914 : loss : 0.063328, loss_ce: 0.014741
[02:12:04.669] iteration 16915 : loss : 0.040750, loss_ce: 0.004969
[02:12:04.967] iteration 16916 : loss : 0.046616, loss_ce: 0.020094
[02:12:05.273] iteration 16917 : loss : 0.059799, loss_ce: 0.011878
[02:12:05.577] iteration 16918 : loss : 0.052478, loss_ce: 0.009181
[02:12:05.881] iteration 16919 : loss : 0.046006, loss_ce: 0.005945
[02:12:06.183] iteration 16920 : loss : 0.040613, loss_ce: 0.013314
[02:12:06.499] iteration 16921 : loss : 0.126002, loss_ce: 0.026755
[02:12:06.803] iteration 16922 : loss : 0.055213, loss_ce: 0.010701
[02:12:07.106] iteration 16923 : loss : 0.052956, loss_ce: 0.019294
[02:12:07.405] iteration 16924 : loss : 0.049111, loss_ce: 0.012935
[02:12:07.708] iteration 16925 : loss : 0.039886, loss_ce: 0.010464
[02:12:08.008] iteration 16926 : loss : 0.093722, loss_ce: 0.007477
[02:12:08.310] iteration 16927 : loss : 0.036801, loss_ce: 0.011411
[02:12:08.618] iteration 16928 : loss : 0.057891, loss_ce: 0.022894
[02:12:08.923] iteration 16929 : loss : 0.045629, loss_ce: 0.019351
[02:12:09.228] iteration 16930 : loss : 0.036085, loss_ce: 0.009786
[02:12:09.531] iteration 16931 : loss : 0.048182, loss_ce: 0.014462
[02:12:09.836] iteration 16932 : loss : 0.034455, loss_ce: 0.004306
[02:12:10.137] iteration 16933 : loss : 0.036413, loss_ce: 0.013556
[02:12:10.440] iteration 16934 : loss : 0.042187, loss_ce: 0.009709
[02:12:10.745] iteration 16935 : loss : 0.048376, loss_ce: 0.012689
[02:12:11.043] iteration 16936 : loss : 0.045559, loss_ce: 0.016048
[02:12:11.348] iteration 16937 : loss : 0.044353, loss_ce: 0.008923
[02:12:11.654] iteration 16938 : loss : 0.039346, loss_ce: 0.012726
[02:12:11.953] iteration 16939 : loss : 0.040069, loss_ce: 0.010776
[02:12:12.259] iteration 16940 : loss : 0.036100, loss_ce: 0.016189
[02:12:12.582] iteration 16941 : loss : 0.054513, loss_ce: 0.022718
[02:12:12.889] iteration 16942 : loss : 0.045878, loss_ce: 0.010363
[02:12:13.194] iteration 16943 : loss : 0.099764, loss_ce: 0.007906
[02:12:13.493] iteration 16944 : loss : 0.103549, loss_ce: 0.007066
[02:12:13.795] iteration 16945 : loss : 0.044362, loss_ce: 0.012921
[02:12:14.098] iteration 16946 : loss : 0.109506, loss_ce: 0.007571
[02:12:14.406] iteration 16947 : loss : 0.036844, loss_ce: 0.007999
[02:12:14.712] iteration 16948 : loss : 0.050067, loss_ce: 0.016951
[02:12:15.021] iteration 16949 : loss : 0.041648, loss_ce: 0.014935
[02:12:15.328] iteration 16950 : loss : 0.036980, loss_ce: 0.008865
[02:12:15.632] iteration 16951 : loss : 0.036509, loss_ce: 0.013649
[02:12:15.939] iteration 16952 : loss : 0.042801, loss_ce: 0.014524
[02:12:16.244] iteration 16953 : loss : 0.043871, loss_ce: 0.011572
[02:12:16.544] iteration 16954 : loss : 0.044521, loss_ce: 0.016449
[02:12:16.843] iteration 16955 : loss : 0.039620, loss_ce: 0.018914
[02:12:17.151] iteration 16956 : loss : 0.106652, loss_ce: 0.012561
[02:12:17.459] iteration 16957 : loss : 0.047091, loss_ce: 0.019654
[02:12:17.537] iteration 16958 : loss : 0.406580, loss_ce: 0.005619
[02:12:36.489] iteration 16959 : loss : 0.044824, loss_ce: 0.012781
[02:12:36.800] iteration 16960 : loss : 0.112690, loss_ce: 0.008974
[02:12:37.117] iteration 16961 : loss : 0.113199, loss_ce: 0.010581
[02:12:37.423] iteration 16962 : loss : 0.040043, loss_ce: 0.012934
[02:12:37.732] iteration 16963 : loss : 0.044320, loss_ce: 0.023635
[02:12:38.030] iteration 16964 : loss : 0.046947, loss_ce: 0.019569
[02:12:38.325] iteration 16965 : loss : 0.055068, loss_ce: 0.010933
[02:12:38.624] iteration 16966 : loss : 0.055349, loss_ce: 0.013223
[02:12:38.922] iteration 16967 : loss : 0.048516, loss_ce: 0.016988
[02:12:39.223] iteration 16968 : loss : 0.055263, loss_ce: 0.008747
[02:12:39.526] iteration 16969 : loss : 0.043663, loss_ce: 0.011005
[02:12:39.830] iteration 16970 : loss : 0.061370, loss_ce: 0.008786
[02:12:40.136] iteration 16971 : loss : 0.032882, loss_ce: 0.010269
[02:12:40.440] iteration 16972 : loss : 0.043696, loss_ce: 0.014432
[02:12:40.743] iteration 16973 : loss : 0.096881, loss_ce: 0.010849
[02:12:41.047] iteration 16974 : loss : 0.049204, loss_ce: 0.018444
[02:12:41.342] iteration 16975 : loss : 0.042194, loss_ce: 0.015454
[02:12:41.641] iteration 16976 : loss : 0.043733, loss_ce: 0.015987
[02:12:41.936] iteration 16977 : loss : 0.052206, loss_ce: 0.018780
[02:12:42.235] iteration 16978 : loss : 0.111309, loss_ce: 0.010000
[02:12:42.531] iteration 16979 : loss : 0.035476, loss_ce: 0.014124
[02:12:42.828] iteration 16980 : loss : 0.041374, loss_ce: 0.013887
[02:12:43.140] iteration 16981 : loss : 0.037069, loss_ce: 0.012386
[02:12:43.439] iteration 16982 : loss : 0.062171, loss_ce: 0.019900
[02:12:43.733] iteration 16983 : loss : 0.042819, loss_ce: 0.009507
[02:12:44.032] iteration 16984 : loss : 0.044445, loss_ce: 0.016849
[02:12:44.332] iteration 16985 : loss : 0.106576, loss_ce: 0.013896
[02:12:44.627] iteration 16986 : loss : 0.225664, loss_ce: 0.002282
[02:12:44.930] iteration 16987 : loss : 0.037019, loss_ce: 0.011790
[02:12:45.229] iteration 16988 : loss : 0.039563, loss_ce: 0.016098
[02:12:45.528] iteration 16989 : loss : 0.102826, loss_ce: 0.012201
[02:12:45.827] iteration 16990 : loss : 0.031358, loss_ce: 0.005638
[02:12:46.128] iteration 16991 : loss : 0.054294, loss_ce: 0.020827
[02:12:46.427] iteration 16992 : loss : 0.103061, loss_ce: 0.012165
[02:12:46.725] iteration 16993 : loss : 0.046361, loss_ce: 0.019637
[02:12:47.026] iteration 16994 : loss : 0.040400, loss_ce: 0.015832
[02:12:47.325] iteration 16995 : loss : 0.044538, loss_ce: 0.021343
[02:12:47.623] iteration 16996 : loss : 0.165881, loss_ce: 0.014709
[02:12:47.920] iteration 16997 : loss : 0.175318, loss_ce: 0.006190
[02:12:48.215] iteration 16998 : loss : 0.040756, loss_ce: 0.009988
[02:12:48.512] iteration 16999 : loss : 0.057828, loss_ce: 0.009519
[02:12:48.808] iteration 17000 : loss : 0.060159, loss_ce: 0.020331
[02:12:49.124] iteration 17001 : loss : 0.043654, loss_ce: 0.014244
[02:12:49.423] iteration 17002 : loss : 0.047663, loss_ce: 0.010641
[02:12:49.725] iteration 17003 : loss : 0.051932, loss_ce: 0.012639
[02:12:50.021] iteration 17004 : loss : 0.043952, loss_ce: 0.014242
[02:12:50.318] iteration 17005 : loss : 0.094710, loss_ce: 0.007541
[02:12:50.614] iteration 17006 : loss : 0.053956, loss_ce: 0.020225
[02:12:50.912] iteration 17007 : loss : 0.052754, loss_ce: 0.008934
[02:12:51.213] iteration 17008 : loss : 0.103905, loss_ce: 0.007326
[02:12:51.509] iteration 17009 : loss : 0.037148, loss_ce: 0.008112
[02:12:51.802] iteration 17010 : loss : 0.105164, loss_ce: 0.006242
[02:12:52.101] iteration 17011 : loss : 0.037120, loss_ce: 0.007619
[02:12:52.400] iteration 17012 : loss : 0.040105, loss_ce: 0.012085
[02:12:52.699] iteration 17013 : loss : 0.045991, loss_ce: 0.019085
[02:12:52.998] iteration 17014 : loss : 0.038697, loss_ce: 0.018781
[02:12:53.294] iteration 17015 : loss : 0.072157, loss_ce: 0.007329
[02:12:53.592] iteration 17016 : loss : 0.043506, loss_ce: 0.010110
[02:12:53.890] iteration 17017 : loss : 0.055181, loss_ce: 0.025980
[02:12:54.189] iteration 17018 : loss : 0.043401, loss_ce: 0.009376
[02:12:54.493] iteration 17019 : loss : 0.043886, loss_ce: 0.015891
[02:12:54.798] iteration 17020 : loss : 0.040509, loss_ce: 0.003723
[02:12:55.124] iteration 17021 : loss : 0.154947, loss_ce: 0.003623
[02:12:55.427] iteration 17022 : loss : 0.034213, loss_ce: 0.012285
[02:12:55.735] iteration 17023 : loss : 0.102190, loss_ce: 0.006739
[02:12:56.042] iteration 17024 : loss : 0.112384, loss_ce: 0.009151
[02:12:56.344] iteration 17025 : loss : 0.043778, loss_ce: 0.015818
[02:12:56.647] iteration 17026 : loss : 0.040448, loss_ce: 0.018679
[02:12:56.949] iteration 17027 : loss : 0.059582, loss_ce: 0.019508
[02:12:57.248] iteration 17028 : loss : 0.044969, loss_ce: 0.015690
[02:12:57.548] iteration 17029 : loss : 0.047690, loss_ce: 0.015174
[02:12:57.851] iteration 17030 : loss : 0.082144, loss_ce: 0.012400
[02:12:58.154] iteration 17031 : loss : 0.045831, loss_ce: 0.012086
[02:12:58.452] iteration 17032 : loss : 0.040326, loss_ce: 0.015388
[02:12:58.747] iteration 17033 : loss : 0.049934, loss_ce: 0.021050
[02:12:59.046] iteration 17034 : loss : 0.093388, loss_ce: 0.015045
[02:12:59.339] iteration 17035 : loss : 0.155588, loss_ce: 0.008296
[02:12:59.635] iteration 17036 : loss : 0.133201, loss_ce: 0.010709
[02:12:59.933] iteration 17037 : loss : 0.098250, loss_ce: 0.015663
[02:13:00.232] iteration 17038 : loss : 0.050441, loss_ce: 0.014404
[02:13:00.529] iteration 17039 : loss : 0.037110, loss_ce: 0.011215
[02:13:00.827] iteration 17040 : loss : 0.042178, loss_ce: 0.021978
[02:13:01.144] iteration 17041 : loss : 0.035733, loss_ce: 0.008807
[02:13:01.443] iteration 17042 : loss : 0.040387, loss_ce: 0.012717
[02:13:01.740] iteration 17043 : loss : 0.036471, loss_ce: 0.010444
[02:13:02.039] iteration 17044 : loss : 0.034970, loss_ce: 0.009400
[02:13:02.335] iteration 17045 : loss : 0.035188, loss_ce: 0.013708
[02:13:02.634] iteration 17046 : loss : 0.044275, loss_ce: 0.012439
[02:13:02.932] iteration 17047 : loss : 0.044690, loss_ce: 0.015469
[02:13:03.233] iteration 17048 : loss : 0.036837, loss_ce: 0.010077
[02:13:03.536] iteration 17049 : loss : 0.044513, loss_ce: 0.009921
[02:13:03.838] iteration 17050 : loss : 0.055352, loss_ce: 0.021696
[02:13:04.140] iteration 17051 : loss : 0.046601, loss_ce: 0.016119
[02:13:04.439] iteration 17052 : loss : 0.058081, loss_ce: 0.022623
[02:13:04.742] iteration 17053 : loss : 0.097619, loss_ce: 0.012360
[02:13:05.042] iteration 17054 : loss : 0.040676, loss_ce: 0.018408
[02:13:05.341] iteration 17055 : loss : 0.083816, loss_ce: 0.006759
[02:13:05.645] iteration 17056 : loss : 0.031997, loss_ce: 0.010214
[02:13:05.944] iteration 17057 : loss : 0.046503, loss_ce: 0.006747
[02:13:06.241] iteration 17058 : loss : 0.113919, loss_ce: 0.009457
[02:13:06.545] iteration 17059 : loss : 0.103420, loss_ce: 0.019391
[02:13:06.841] iteration 17060 : loss : 0.045588, loss_ce: 0.013189
[02:13:07.159] iteration 17061 : loss : 0.048626, loss_ce: 0.012518
[02:13:07.459] iteration 17062 : loss : 0.041292, loss_ce: 0.007683
[02:13:07.756] iteration 17063 : loss : 0.106646, loss_ce: 0.009200
[02:13:08.061] iteration 17064 : loss : 0.050480, loss_ce: 0.025330
[02:13:08.360] iteration 17065 : loss : 0.039123, loss_ce: 0.013121
[02:13:08.657] iteration 17066 : loss : 0.042390, loss_ce: 0.011671
[02:13:08.959] iteration 17067 : loss : 0.055836, loss_ce: 0.010586
[02:13:09.269] iteration 17068 : loss : 0.055445, loss_ce: 0.013380
[02:13:09.571] iteration 17069 : loss : 0.036713, loss_ce: 0.008186
[02:13:09.876] iteration 17070 : loss : 0.049396, loss_ce: 0.020907
[02:13:10.180] iteration 17071 : loss : 0.062768, loss_ce: 0.022062
[02:13:10.482] iteration 17072 : loss : 0.232511, loss_ce: 0.004171
[02:13:10.787] iteration 17073 : loss : 0.051716, loss_ce: 0.022564
[02:13:11.092] iteration 17074 : loss : 0.106033, loss_ce: 0.007702
[02:13:11.391] iteration 17075 : loss : 0.048680, loss_ce: 0.011128
[02:13:11.689] iteration 17076 : loss : 0.045693, loss_ce: 0.022735
[02:13:11.994] iteration 17077 : loss : 0.061742, loss_ce: 0.009519
[02:13:12.295] iteration 17078 : loss : 0.056568, loss_ce: 0.011722
[02:13:12.593] iteration 17079 : loss : 0.095812, loss_ce: 0.008988
[02:13:12.895] iteration 17080 : loss : 0.053654, loss_ce: 0.011399
[02:13:13.212] iteration 17081 : loss : 0.041526, loss_ce: 0.017565
[02:13:13.511] iteration 17082 : loss : 0.050235, loss_ce: 0.018794
[02:13:13.814] iteration 17083 : loss : 0.045984, loss_ce: 0.016437
[02:13:14.114] iteration 17084 : loss : 0.164933, loss_ce: 0.008862
[02:13:14.415] iteration 17085 : loss : 0.050758, loss_ce: 0.010491
[02:13:14.714] iteration 17086 : loss : 0.032364, loss_ce: 0.011919
[02:13:15.012] iteration 17087 : loss : 0.059660, loss_ce: 0.019979
[02:13:15.321] iteration 17088 : loss : 0.050810, loss_ce: 0.010983
[02:13:15.627] iteration 17089 : loss : 0.040238, loss_ce: 0.014111
[02:13:15.926] iteration 17090 : loss : 0.039220, loss_ce: 0.013578
[02:13:16.236] iteration 17091 : loss : 0.046252, loss_ce: 0.007703
[02:13:16.544] iteration 17092 : loss : 0.061374, loss_ce: 0.006938
[02:13:16.851] iteration 17093 : loss : 0.066919, loss_ce: 0.005751
[02:13:17.157] iteration 17094 : loss : 0.043595, loss_ce: 0.012783
[02:13:17.466] iteration 17095 : loss : 0.035417, loss_ce: 0.012216
[02:13:17.771] iteration 17096 : loss : 0.045632, loss_ce: 0.013444
[02:13:17.853] iteration 17097 : loss : 0.173304, loss_ce: 0.024577
[02:13:37.405] iteration 17098 : loss : 0.039136, loss_ce: 0.008483
[02:13:37.711] iteration 17099 : loss : 0.112533, loss_ce: 0.005988
[02:13:38.022] iteration 17100 : loss : 0.056923, loss_ce: 0.013268
[02:13:38.343] iteration 17101 : loss : 0.078429, loss_ce: 0.010465
[02:13:38.641] iteration 17102 : loss : 0.045329, loss_ce: 0.010953
[02:13:38.945] iteration 17103 : loss : 0.052692, loss_ce: 0.015090
[02:13:39.247] iteration 17104 : loss : 0.039070, loss_ce: 0.017606
[02:13:39.544] iteration 17105 : loss : 0.071358, loss_ce: 0.018770
[02:13:39.847] iteration 17106 : loss : 0.112563, loss_ce: 0.005939
[02:13:40.153] iteration 17107 : loss : 0.038788, loss_ce: 0.011219
[02:13:40.455] iteration 17108 : loss : 0.045497, loss_ce: 0.017609
[02:13:40.755] iteration 17109 : loss : 0.042107, loss_ce: 0.016010
[02:13:41.061] iteration 17110 : loss : 0.041553, loss_ce: 0.014640
[02:13:41.363] iteration 17111 : loss : 0.049112, loss_ce: 0.012784
[02:13:41.666] iteration 17112 : loss : 0.037351, loss_ce: 0.016473
[02:13:41.965] iteration 17113 : loss : 0.104002, loss_ce: 0.008659
[02:13:42.269] iteration 17114 : loss : 0.048832, loss_ce: 0.012773
[02:13:42.572] iteration 17115 : loss : 0.046692, loss_ce: 0.010198
[02:13:42.876] iteration 17116 : loss : 0.041545, loss_ce: 0.013999
[02:13:43.177] iteration 17117 : loss : 0.059439, loss_ce: 0.012071
[02:13:43.479] iteration 17118 : loss : 0.041199, loss_ce: 0.017248
[02:13:43.788] iteration 17119 : loss : 0.050427, loss_ce: 0.021460
[02:13:44.091] iteration 17120 : loss : 0.053077, loss_ce: 0.013365
[02:13:44.408] iteration 17121 : loss : 0.049724, loss_ce: 0.016888
[02:13:44.709] iteration 17122 : loss : 0.115205, loss_ce: 0.008339
[02:13:45.011] iteration 17123 : loss : 0.053579, loss_ce: 0.012917
[02:13:45.316] iteration 17124 : loss : 0.049007, loss_ce: 0.013392
[02:13:45.618] iteration 17125 : loss : 0.105939, loss_ce: 0.009717
[02:13:45.922] iteration 17126 : loss : 0.099233, loss_ce: 0.009876
[02:13:46.222] iteration 17127 : loss : 0.098555, loss_ce: 0.009334
[02:13:46.518] iteration 17128 : loss : 0.039083, loss_ce: 0.008239
[02:13:46.816] iteration 17129 : loss : 0.033946, loss_ce: 0.010159
[02:13:47.117] iteration 17130 : loss : 0.073199, loss_ce: 0.005267
[02:13:47.421] iteration 17131 : loss : 0.052451, loss_ce: 0.011855
[02:13:47.719] iteration 17132 : loss : 0.045234, loss_ce: 0.011261
[02:13:48.016] iteration 17133 : loss : 0.035725, loss_ce: 0.006888
[02:13:48.313] iteration 17134 : loss : 0.041077, loss_ce: 0.010641
[02:13:48.609] iteration 17135 : loss : 0.096276, loss_ce: 0.008273
[02:13:48.907] iteration 17136 : loss : 0.039820, loss_ce: 0.009094
[02:13:49.206] iteration 17137 : loss : 0.047669, loss_ce: 0.006738
[02:13:49.502] iteration 17138 : loss : 0.054684, loss_ce: 0.014611
[02:13:49.803] iteration 17139 : loss : 0.032704, loss_ce: 0.009946
[02:13:50.105] iteration 17140 : loss : 0.098980, loss_ce: 0.011874
[02:13:50.424] iteration 17141 : loss : 0.106811, loss_ce: 0.010419
[02:13:50.718] iteration 17142 : loss : 0.048641, loss_ce: 0.011236
[02:13:51.017] iteration 17143 : loss : 0.035819, loss_ce: 0.010083
[02:13:51.317] iteration 17144 : loss : 0.044850, loss_ce: 0.008653
[02:13:51.614] iteration 17145 : loss : 0.040442, loss_ce: 0.008923
[02:13:51.913] iteration 17146 : loss : 0.109101, loss_ce: 0.008494
[02:13:52.211] iteration 17147 : loss : 0.111403, loss_ce: 0.008123
[02:13:52.509] iteration 17148 : loss : 0.051475, loss_ce: 0.013697
[02:13:52.803] iteration 17149 : loss : 0.045048, loss_ce: 0.024014
[02:13:53.100] iteration 17150 : loss : 0.047069, loss_ce: 0.013367
[02:13:53.401] iteration 17151 : loss : 0.100762, loss_ce: 0.009481
[02:13:53.700] iteration 17152 : loss : 0.062033, loss_ce: 0.016757
[02:13:54.004] iteration 17153 : loss : 0.054322, loss_ce: 0.017164
[02:13:54.302] iteration 17154 : loss : 0.040353, loss_ce: 0.017458
[02:13:54.601] iteration 17155 : loss : 0.103676, loss_ce: 0.017087
[02:13:54.901] iteration 17156 : loss : 0.050833, loss_ce: 0.019219
[02:13:55.205] iteration 17157 : loss : 0.045816, loss_ce: 0.021629
[02:13:55.500] iteration 17158 : loss : 0.040173, loss_ce: 0.013582
[02:13:55.797] iteration 17159 : loss : 0.049815, loss_ce: 0.013546
[02:13:56.100] iteration 17160 : loss : 0.043995, loss_ce: 0.006518
[02:13:56.416] iteration 17161 : loss : 0.042871, loss_ce: 0.018300
[02:13:56.716] iteration 17162 : loss : 0.045175, loss_ce: 0.014146
[02:13:57.017] iteration 17163 : loss : 0.047906, loss_ce: 0.013801
[02:13:57.312] iteration 17164 : loss : 0.039920, loss_ce: 0.016228
[02:13:57.609] iteration 17165 : loss : 0.051069, loss_ce: 0.016989
[02:13:57.909] iteration 17166 : loss : 0.042305, loss_ce: 0.019526
[02:13:58.207] iteration 17167 : loss : 0.041136, loss_ce: 0.015148
[02:13:58.505] iteration 17168 : loss : 0.037889, loss_ce: 0.009147
[02:13:58.803] iteration 17169 : loss : 0.036701, loss_ce: 0.015127
[02:13:59.100] iteration 17170 : loss : 0.053649, loss_ce: 0.013228
[02:13:59.403] iteration 17171 : loss : 0.103966, loss_ce: 0.014287
[02:13:59.707] iteration 17172 : loss : 0.036814, loss_ce: 0.013908
[02:14:00.017] iteration 17173 : loss : 0.053357, loss_ce: 0.014171
[02:14:00.320] iteration 17174 : loss : 0.047379, loss_ce: 0.013047
[02:14:00.624] iteration 17175 : loss : 0.065338, loss_ce: 0.016363
[02:14:00.926] iteration 17176 : loss : 0.038511, loss_ce: 0.006887
[02:14:01.226] iteration 17177 : loss : 0.047465, loss_ce: 0.017178
[02:14:01.530] iteration 17178 : loss : 0.048475, loss_ce: 0.014438
[02:14:01.830] iteration 17179 : loss : 0.043116, loss_ce: 0.009121
[02:14:02.130] iteration 17180 : loss : 0.042176, loss_ce: 0.007255
[02:14:02.447] iteration 17181 : loss : 0.039885, loss_ce: 0.015092
[02:14:02.745] iteration 17182 : loss : 0.040311, loss_ce: 0.011030
[02:14:03.044] iteration 17183 : loss : 0.045930, loss_ce: 0.011229
[02:14:03.343] iteration 17184 : loss : 0.041207, loss_ce: 0.016984
[02:14:03.642] iteration 17185 : loss : 0.155775, loss_ce: 0.007703
[02:14:03.941] iteration 17186 : loss : 0.106625, loss_ce: 0.019077
[02:14:04.243] iteration 17187 : loss : 0.044727, loss_ce: 0.014406
[02:14:04.546] iteration 17188 : loss : 0.047111, loss_ce: 0.018371
[02:14:04.845] iteration 17189 : loss : 0.046414, loss_ce: 0.013196
[02:14:05.146] iteration 17190 : loss : 0.043495, loss_ce: 0.016685
[02:14:05.446] iteration 17191 : loss : 0.039058, loss_ce: 0.009277
[02:14:05.749] iteration 17192 : loss : 0.113637, loss_ce: 0.016088
[02:14:06.051] iteration 17193 : loss : 0.047825, loss_ce: 0.024690
[02:14:06.350] iteration 17194 : loss : 0.055500, loss_ce: 0.016043
[02:14:06.650] iteration 17195 : loss : 0.054461, loss_ce: 0.013098
[02:14:06.950] iteration 17196 : loss : 0.051823, loss_ce: 0.018157
[02:14:07.250] iteration 17197 : loss : 0.047327, loss_ce: 0.017262
[02:14:07.551] iteration 17198 : loss : 0.057919, loss_ce: 0.019049
[02:14:07.850] iteration 17199 : loss : 0.041840, loss_ce: 0.010424
[02:14:08.147] iteration 17200 : loss : 0.039196, loss_ce: 0.012179
[02:14:08.461] iteration 17201 : loss : 0.051793, loss_ce: 0.014447
[02:14:08.763] iteration 17202 : loss : 0.095378, loss_ce: 0.010798
[02:14:09.063] iteration 17203 : loss : 0.105087, loss_ce: 0.012315
[02:14:09.364] iteration 17204 : loss : 0.107609, loss_ce: 0.007384
[02:14:09.662] iteration 17205 : loss : 0.054069, loss_ce: 0.015756
[02:14:09.960] iteration 17206 : loss : 0.042090, loss_ce: 0.016430
[02:14:10.257] iteration 17207 : loss : 0.098337, loss_ce: 0.007781
[02:14:10.553] iteration 17208 : loss : 0.097963, loss_ce: 0.009457
[02:14:10.855] iteration 17209 : loss : 0.057830, loss_ce: 0.015263
[02:14:11.152] iteration 17210 : loss : 0.103210, loss_ce: 0.012357
[02:14:11.449] iteration 17211 : loss : 0.098865, loss_ce: 0.008359
[02:14:11.750] iteration 17212 : loss : 0.057153, loss_ce: 0.018598
[02:14:12.049] iteration 17213 : loss : 0.038172, loss_ce: 0.013635
[02:14:12.348] iteration 17214 : loss : 0.050317, loss_ce: 0.014718
[02:14:12.644] iteration 17215 : loss : 0.047107, loss_ce: 0.024443
[02:14:12.941] iteration 17216 : loss : 0.048609, loss_ce: 0.017230
[02:14:13.241] iteration 17217 : loss : 0.106005, loss_ce: 0.008827
[02:14:13.539] iteration 17218 : loss : 0.046959, loss_ce: 0.011953
[02:14:13.839] iteration 17219 : loss : 0.050200, loss_ce: 0.014572
[02:14:14.142] iteration 17220 : loss : 0.040059, loss_ce: 0.016630
[02:14:14.466] iteration 17221 : loss : 0.039647, loss_ce: 0.009236
[02:14:14.773] iteration 17222 : loss : 0.037868, loss_ce: 0.011765
[02:14:15.082] iteration 17223 : loss : 0.095541, loss_ce: 0.008039
[02:14:15.387] iteration 17224 : loss : 0.049144, loss_ce: 0.008233
[02:14:15.692] iteration 17225 : loss : 0.156806, loss_ce: 0.008698
[02:14:16.001] iteration 17226 : loss : 0.167143, loss_ce: 0.005773
[02:14:16.304] iteration 17227 : loss : 0.042949, loss_ce: 0.011409
[02:14:16.609] iteration 17228 : loss : 0.042436, loss_ce: 0.007847
[02:14:16.914] iteration 17229 : loss : 0.048694, loss_ce: 0.022793
[02:14:17.214] iteration 17230 : loss : 0.054498, loss_ce: 0.012910
[02:14:17.513] iteration 17231 : loss : 0.050623, loss_ce: 0.022989
[02:14:17.820] iteration 17232 : loss : 0.048726, loss_ce: 0.013868
[02:14:18.126] iteration 17233 : loss : 0.105470, loss_ce: 0.011331
[02:14:18.425] iteration 17234 : loss : 0.047919, loss_ce: 0.016326
[02:14:18.730] iteration 17235 : loss : 0.039494, loss_ce: 0.009902
[02:14:18.806] iteration 17236 : loss : 0.142445, loss_ce: 0.019024
[02:14:37.393] iteration 17237 : loss : 0.050689, loss_ce: 0.017994
[02:14:37.699] iteration 17238 : loss : 0.051431, loss_ce: 0.021962
[02:14:38.003] iteration 17239 : loss : 0.067751, loss_ce: 0.011399
[02:14:38.307] iteration 17240 : loss : 0.043142, loss_ce: 0.012366
[02:14:38.617] iteration 17241 : loss : 0.114664, loss_ce: 0.012517
[02:14:38.915] iteration 17242 : loss : 0.041465, loss_ce: 0.016971
[02:14:39.210] iteration 17243 : loss : 0.060372, loss_ce: 0.005745
[02:14:39.513] iteration 17244 : loss : 0.043135, loss_ce: 0.020058
[02:14:39.811] iteration 17245 : loss : 0.048570, loss_ce: 0.013392
[02:14:40.103] iteration 17246 : loss : 0.071026, loss_ce: 0.016235
[02:14:40.399] iteration 17247 : loss : 0.040054, loss_ce: 0.011228
[02:14:40.695] iteration 17248 : loss : 0.044728, loss_ce: 0.018250
[02:14:40.998] iteration 17249 : loss : 0.040657, loss_ce: 0.013151
[02:14:41.295] iteration 17250 : loss : 0.112172, loss_ce: 0.008531
[02:14:41.594] iteration 17251 : loss : 0.030864, loss_ce: 0.010369
[02:14:41.893] iteration 17252 : loss : 0.042630, loss_ce: 0.026070
[02:14:42.193] iteration 17253 : loss : 0.043111, loss_ce: 0.015769
[02:14:42.496] iteration 17254 : loss : 0.049155, loss_ce: 0.014898
[02:14:42.793] iteration 17255 : loss : 0.102911, loss_ce: 0.016014
[02:14:43.091] iteration 17256 : loss : 0.094507, loss_ce: 0.010262
[02:14:43.388] iteration 17257 : loss : 0.099323, loss_ce: 0.007373
[02:14:43.683] iteration 17258 : loss : 0.039789, loss_ce: 0.012722
[02:14:43.980] iteration 17259 : loss : 0.099339, loss_ce: 0.010799
[02:14:44.276] iteration 17260 : loss : 0.046521, loss_ce: 0.016776
[02:14:44.596] iteration 17261 : loss : 0.063083, loss_ce: 0.010670
[02:14:44.901] iteration 17262 : loss : 0.158137, loss_ce: 0.008675
[02:14:45.198] iteration 17263 : loss : 0.044570, loss_ce: 0.008556
[02:14:45.496] iteration 17264 : loss : 0.040066, loss_ce: 0.019109
[02:14:45.802] iteration 17265 : loss : 0.045132, loss_ce: 0.016719
[02:14:46.102] iteration 17266 : loss : 0.053149, loss_ce: 0.017876
[02:14:46.411] iteration 17267 : loss : 0.051122, loss_ce: 0.015146
[02:14:46.715] iteration 17268 : loss : 0.103844, loss_ce: 0.007822
[02:14:47.009] iteration 17269 : loss : 0.039598, loss_ce: 0.006126
[02:14:47.314] iteration 17270 : loss : 0.097687, loss_ce: 0.012547
[02:14:47.616] iteration 17271 : loss : 0.046345, loss_ce: 0.011092
[02:14:47.916] iteration 17272 : loss : 0.044490, loss_ce: 0.015608
[02:14:48.218] iteration 17273 : loss : 0.044444, loss_ce: 0.008659
[02:14:48.521] iteration 17274 : loss : 0.048265, loss_ce: 0.020224
[02:14:48.822] iteration 17275 : loss : 0.046235, loss_ce: 0.013775
[02:14:49.120] iteration 17276 : loss : 0.102551, loss_ce: 0.011819
[02:14:49.423] iteration 17277 : loss : 0.052734, loss_ce: 0.014345
[02:14:49.725] iteration 17278 : loss : 0.041888, loss_ce: 0.014089
[02:14:50.025] iteration 17279 : loss : 0.042027, loss_ce: 0.019648
[02:14:50.330] iteration 17280 : loss : 0.046176, loss_ce: 0.012816
[02:14:50.650] iteration 17281 : loss : 0.053612, loss_ce: 0.012904
[02:14:50.950] iteration 17282 : loss : 0.112639, loss_ce: 0.014915
[02:14:51.251] iteration 17283 : loss : 0.042508, loss_ce: 0.014446
[02:14:51.549] iteration 17284 : loss : 0.045937, loss_ce: 0.016367
[02:14:51.853] iteration 17285 : loss : 0.041532, loss_ce: 0.014615
[02:14:52.155] iteration 17286 : loss : 0.052756, loss_ce: 0.008104
[02:14:52.459] iteration 17287 : loss : 0.040067, loss_ce: 0.011330
[02:14:52.765] iteration 17288 : loss : 0.095259, loss_ce: 0.005323
[02:14:53.069] iteration 17289 : loss : 0.110613, loss_ce: 0.011769
[02:14:53.371] iteration 17290 : loss : 0.049313, loss_ce: 0.012290
[02:14:53.672] iteration 17291 : loss : 0.044007, loss_ce: 0.013056
[02:14:53.974] iteration 17292 : loss : 0.038524, loss_ce: 0.007848
[02:14:54.275] iteration 17293 : loss : 0.045628, loss_ce: 0.012108
[02:14:54.582] iteration 17294 : loss : 0.043660, loss_ce: 0.010052
[02:14:54.885] iteration 17295 : loss : 0.056123, loss_ce: 0.013343
[02:14:55.187] iteration 17296 : loss : 0.052357, loss_ce: 0.017928
[02:14:55.495] iteration 17297 : loss : 0.035108, loss_ce: 0.009215
[02:14:55.798] iteration 17298 : loss : 0.048952, loss_ce: 0.013625
[02:14:56.101] iteration 17299 : loss : 0.095082, loss_ce: 0.010647
[02:14:56.402] iteration 17300 : loss : 0.038261, loss_ce: 0.017523
[02:14:56.725] iteration 17301 : loss : 0.040221, loss_ce: 0.020368
[02:14:57.021] iteration 17302 : loss : 0.035778, loss_ce: 0.008523
[02:14:57.322] iteration 17303 : loss : 0.048078, loss_ce: 0.016167
[02:14:57.627] iteration 17304 : loss : 0.101137, loss_ce: 0.004617
[02:14:57.930] iteration 17305 : loss : 0.097796, loss_ce: 0.009010
[02:14:58.233] iteration 17306 : loss : 0.042892, loss_ce: 0.013999
[02:14:58.533] iteration 17307 : loss : 0.110819, loss_ce: 0.005959
[02:14:58.835] iteration 17308 : loss : 0.047386, loss_ce: 0.014970
[02:14:59.137] iteration 17309 : loss : 0.104004, loss_ce: 0.016420
[02:14:59.444] iteration 17310 : loss : 0.047402, loss_ce: 0.013314
[02:14:59.749] iteration 17311 : loss : 0.071780, loss_ce: 0.012533
[02:15:00.052] iteration 17312 : loss : 0.054838, loss_ce: 0.016203
[02:15:00.358] iteration 17313 : loss : 0.052931, loss_ce: 0.011799
[02:15:00.661] iteration 17314 : loss : 0.041589, loss_ce: 0.018381
[02:15:00.971] iteration 17315 : loss : 0.095003, loss_ce: 0.007047
[02:15:01.276] iteration 17316 : loss : 0.045423, loss_ce: 0.011548
[02:15:01.577] iteration 17317 : loss : 0.108634, loss_ce: 0.012363
[02:15:01.878] iteration 17318 : loss : 0.044328, loss_ce: 0.024710
[02:15:02.181] iteration 17319 : loss : 0.103778, loss_ce: 0.010093
[02:15:02.484] iteration 17320 : loss : 0.044510, loss_ce: 0.012896
[02:15:02.807] iteration 17321 : loss : 0.041143, loss_ce: 0.022359
[02:15:03.106] iteration 17322 : loss : 0.051348, loss_ce: 0.015471
[02:15:03.406] iteration 17323 : loss : 0.032088, loss_ce: 0.009803
[02:15:03.708] iteration 17324 : loss : 0.045417, loss_ce: 0.015892
[02:15:04.012] iteration 17325 : loss : 0.099842, loss_ce: 0.014016
[02:15:04.315] iteration 17326 : loss : 0.055729, loss_ce: 0.018059
[02:15:04.615] iteration 17327 : loss : 0.053659, loss_ce: 0.016960
[02:15:04.917] iteration 17328 : loss : 0.045662, loss_ce: 0.012894
[02:15:05.219] iteration 17329 : loss : 0.040503, loss_ce: 0.008082
[02:15:05.524] iteration 17330 : loss : 0.050742, loss_ce: 0.011753
[02:15:05.829] iteration 17331 : loss : 0.062687, loss_ce: 0.031090
[02:15:06.136] iteration 17332 : loss : 0.061191, loss_ce: 0.018714
[02:15:06.433] iteration 17333 : loss : 0.035734, loss_ce: 0.005229
[02:15:06.737] iteration 17334 : loss : 0.035805, loss_ce: 0.012795
[02:15:07.038] iteration 17335 : loss : 0.057685, loss_ce: 0.011979
[02:15:07.342] iteration 17336 : loss : 0.048853, loss_ce: 0.018542
[02:15:07.644] iteration 17337 : loss : 0.106828, loss_ce: 0.009449
[02:15:07.944] iteration 17338 : loss : 0.036727, loss_ce: 0.005626
[02:15:08.249] iteration 17339 : loss : 0.059771, loss_ce: 0.016533
[02:15:08.546] iteration 17340 : loss : 0.060283, loss_ce: 0.013145
[02:15:08.857] iteration 17341 : loss : 0.040997, loss_ce: 0.013027
[02:15:09.156] iteration 17342 : loss : 0.037620, loss_ce: 0.016703
[02:15:09.458] iteration 17343 : loss : 0.110687, loss_ce: 0.014421
[02:15:09.759] iteration 17344 : loss : 0.044108, loss_ce: 0.005742
[02:15:10.058] iteration 17345 : loss : 0.048636, loss_ce: 0.013007
[02:15:10.358] iteration 17346 : loss : 0.094641, loss_ce: 0.011093
[02:15:10.656] iteration 17347 : loss : 0.046498, loss_ce: 0.014736
[02:15:10.956] iteration 17348 : loss : 0.063959, loss_ce: 0.014698
[02:15:11.255] iteration 17349 : loss : 0.050930, loss_ce: 0.016893
[02:15:11.554] iteration 17350 : loss : 0.041798, loss_ce: 0.009464
[02:15:11.856] iteration 17351 : loss : 0.108286, loss_ce: 0.015988
[02:15:12.152] iteration 17352 : loss : 0.047915, loss_ce: 0.017179
[02:15:12.451] iteration 17353 : loss : 0.097765, loss_ce: 0.008658
[02:15:12.752] iteration 17354 : loss : 0.038385, loss_ce: 0.010072
[02:15:13.046] iteration 17355 : loss : 0.035374, loss_ce: 0.007696
[02:15:13.344] iteration 17356 : loss : 0.044008, loss_ce: 0.017355
[02:15:13.642] iteration 17357 : loss : 0.036578, loss_ce: 0.010363
[02:15:13.943] iteration 17358 : loss : 0.060399, loss_ce: 0.010083
[02:15:14.251] iteration 17359 : loss : 0.052519, loss_ce: 0.015471
[02:15:14.553] iteration 17360 : loss : 0.058538, loss_ce: 0.015204
[02:15:14.875] iteration 17361 : loss : 0.045913, loss_ce: 0.020842
[02:15:15.179] iteration 17362 : loss : 0.043413, loss_ce: 0.012628
[02:15:15.479] iteration 17363 : loss : 0.169326, loss_ce: 0.004136
[02:15:15.780] iteration 17364 : loss : 0.035315, loss_ce: 0.012828
[02:15:16.084] iteration 17365 : loss : 0.047692, loss_ce: 0.016932
[02:15:16.386] iteration 17366 : loss : 0.044086, loss_ce: 0.010481
[02:15:16.689] iteration 17367 : loss : 0.161175, loss_ce: 0.005392
[02:15:16.992] iteration 17368 : loss : 0.060398, loss_ce: 0.010153
[02:15:17.294] iteration 17369 : loss : 0.045547, loss_ce: 0.010213
[02:15:17.599] iteration 17370 : loss : 0.081875, loss_ce: 0.007530
[02:15:17.897] iteration 17371 : loss : 0.041905, loss_ce: 0.013587
[02:15:18.200] iteration 17372 : loss : 0.043593, loss_ce: 0.009600
[02:15:18.502] iteration 17373 : loss : 0.098455, loss_ce: 0.008990
[02:15:18.811] iteration 17374 : loss : 0.052317, loss_ce: 0.012560
[02:15:18.889] iteration 17375 : loss : 0.057171, loss_ce: 0.042088
[02:15:37.765] iteration 17376 : loss : 0.040858, loss_ce: 0.009278
[02:15:38.067] iteration 17377 : loss : 0.044079, loss_ce: 0.015458
[02:15:38.369] iteration 17378 : loss : 0.047628, loss_ce: 0.013713
[02:15:38.672] iteration 17379 : loss : 0.036433, loss_ce: 0.012288
[02:15:38.973] iteration 17380 : loss : 0.042948, loss_ce: 0.012175
[02:15:39.285] iteration 17381 : loss : 0.048730, loss_ce: 0.009087
[02:15:39.582] iteration 17382 : loss : 0.051082, loss_ce: 0.022195
[02:15:39.882] iteration 17383 : loss : 0.047445, loss_ce: 0.025148
[02:15:40.180] iteration 17384 : loss : 0.044413, loss_ce: 0.010668
[02:15:40.478] iteration 17385 : loss : 0.159337, loss_ce: 0.010303
[02:15:40.778] iteration 17386 : loss : 0.113374, loss_ce: 0.019306
[02:15:41.068] iteration 17387 : loss : 0.037289, loss_ce: 0.013062
[02:15:41.366] iteration 17388 : loss : 0.043188, loss_ce: 0.011991
[02:15:41.665] iteration 17389 : loss : 0.043433, loss_ce: 0.013389
[02:15:41.961] iteration 17390 : loss : 0.040895, loss_ce: 0.013028
[02:15:42.266] iteration 17391 : loss : 0.037022, loss_ce: 0.008101
[02:15:42.562] iteration 17392 : loss : 0.055476, loss_ce: 0.016736
[02:15:42.860] iteration 17393 : loss : 0.051106, loss_ce: 0.011310
[02:15:43.157] iteration 17394 : loss : 0.048840, loss_ce: 0.011889
[02:15:43.458] iteration 17395 : loss : 0.058996, loss_ce: 0.016097
[02:15:43.760] iteration 17396 : loss : 0.048054, loss_ce: 0.013480
[02:15:44.056] iteration 17397 : loss : 0.043252, loss_ce: 0.016306
[02:15:44.353] iteration 17398 : loss : 0.043933, loss_ce: 0.010312
[02:15:44.651] iteration 17399 : loss : 0.080913, loss_ce: 0.013212
[02:15:44.949] iteration 17400 : loss : 0.039366, loss_ce: 0.010889
[02:15:45.266] iteration 17401 : loss : 0.047265, loss_ce: 0.010445
[02:15:45.562] iteration 17402 : loss : 0.040287, loss_ce: 0.017757
[02:15:45.860] iteration 17403 : loss : 0.069928, loss_ce: 0.011420
[02:15:46.161] iteration 17404 : loss : 0.035882, loss_ce: 0.009959
[02:15:46.454] iteration 17405 : loss : 0.050861, loss_ce: 0.015581
[02:15:46.751] iteration 17406 : loss : 0.048475, loss_ce: 0.013705
[02:15:47.053] iteration 17407 : loss : 0.115277, loss_ce: 0.007523
[02:15:47.355] iteration 17408 : loss : 0.040213, loss_ce: 0.010526
[02:15:47.652] iteration 17409 : loss : 0.052731, loss_ce: 0.019752
[02:15:47.948] iteration 17410 : loss : 0.045788, loss_ce: 0.017752
[02:15:48.244] iteration 17411 : loss : 0.053910, loss_ce: 0.014715
[02:15:48.538] iteration 17412 : loss : 0.041800, loss_ce: 0.017081
[02:15:48.835] iteration 17413 : loss : 0.039845, loss_ce: 0.015115
[02:15:49.135] iteration 17414 : loss : 0.037315, loss_ce: 0.008943
[02:15:49.438] iteration 17415 : loss : 0.069342, loss_ce: 0.010633
[02:15:49.741] iteration 17416 : loss : 0.040865, loss_ce: 0.014178
[02:15:50.041] iteration 17417 : loss : 0.153745, loss_ce: 0.006466
[02:15:50.348] iteration 17418 : loss : 0.054306, loss_ce: 0.008922
[02:15:50.652] iteration 17419 : loss : 0.047969, loss_ce: 0.016843
[02:15:50.958] iteration 17420 : loss : 0.043704, loss_ce: 0.012252
[02:15:51.278] iteration 17421 : loss : 0.065389, loss_ce: 0.018713
[02:15:51.579] iteration 17422 : loss : 0.108716, loss_ce: 0.014629
[02:15:51.877] iteration 17423 : loss : 0.046060, loss_ce: 0.023940
[02:15:52.174] iteration 17424 : loss : 0.047792, loss_ce: 0.015185
[02:15:52.476] iteration 17425 : loss : 0.063660, loss_ce: 0.012599
[02:15:52.774] iteration 17426 : loss : 0.042481, loss_ce: 0.013988
[02:15:53.066] iteration 17427 : loss : 0.116226, loss_ce: 0.012601
[02:15:53.365] iteration 17428 : loss : 0.053256, loss_ce: 0.013628
[02:15:53.663] iteration 17429 : loss : 0.100767, loss_ce: 0.014500
[02:15:53.967] iteration 17430 : loss : 0.043339, loss_ce: 0.018908
[02:15:54.270] iteration 17431 : loss : 0.036960, loss_ce: 0.011365
[02:15:54.566] iteration 17432 : loss : 0.051687, loss_ce: 0.023765
[02:15:54.869] iteration 17433 : loss : 0.054846, loss_ce: 0.014327
[02:15:55.168] iteration 17434 : loss : 0.041057, loss_ce: 0.018026
[02:15:55.470] iteration 17435 : loss : 0.044183, loss_ce: 0.019028
[02:15:55.764] iteration 17436 : loss : 0.280692, loss_ce: 0.006077
[02:15:56.065] iteration 17437 : loss : 0.099985, loss_ce: 0.017004
[02:15:56.360] iteration 17438 : loss : 0.037210, loss_ce: 0.011737
[02:15:56.657] iteration 17439 : loss : 0.040645, loss_ce: 0.018575
[02:15:56.956] iteration 17440 : loss : 0.048718, loss_ce: 0.016126
[02:15:57.274] iteration 17441 : loss : 0.040403, loss_ce: 0.010517
[02:15:57.569] iteration 17442 : loss : 0.045196, loss_ce: 0.016795
[02:15:57.866] iteration 17443 : loss : 0.098767, loss_ce: 0.010874
[02:15:58.164] iteration 17444 : loss : 0.155706, loss_ce: 0.007773
[02:15:58.465] iteration 17445 : loss : 0.045472, loss_ce: 0.015706
[02:15:58.762] iteration 17446 : loss : 0.035293, loss_ce: 0.004813
[02:15:59.055] iteration 17447 : loss : 0.056377, loss_ce: 0.017249
[02:15:59.351] iteration 17448 : loss : 0.103624, loss_ce: 0.008805
[02:15:59.651] iteration 17449 : loss : 0.047468, loss_ce: 0.008757
[02:15:59.952] iteration 17450 : loss : 0.159136, loss_ce: 0.005760
[02:16:00.254] iteration 17451 : loss : 0.040435, loss_ce: 0.015805
[02:16:00.553] iteration 17452 : loss : 0.036449, loss_ce: 0.011683
[02:16:00.852] iteration 17453 : loss : 0.049652, loss_ce: 0.018605
[02:16:01.152] iteration 17454 : loss : 0.051885, loss_ce: 0.016754
[02:16:01.446] iteration 17455 : loss : 0.078980, loss_ce: 0.015053
[02:16:01.746] iteration 17456 : loss : 0.093790, loss_ce: 0.009440
[02:16:02.047] iteration 17457 : loss : 0.048722, loss_ce: 0.019391
[02:16:02.350] iteration 17458 : loss : 0.036114, loss_ce: 0.013819
[02:16:02.645] iteration 17459 : loss : 0.124675, loss_ce: 0.012300
[02:16:02.942] iteration 17460 : loss : 0.042277, loss_ce: 0.021148
[02:16:03.263] iteration 17461 : loss : 0.036114, loss_ce: 0.014281
[02:16:03.563] iteration 17462 : loss : 0.038085, loss_ce: 0.013257
[02:16:03.859] iteration 17463 : loss : 0.042552, loss_ce: 0.009421
[02:16:04.154] iteration 17464 : loss : 0.113728, loss_ce: 0.012760
[02:16:04.452] iteration 17465 : loss : 0.098468, loss_ce: 0.008647
[02:16:04.752] iteration 17466 : loss : 0.099558, loss_ce: 0.008259
[02:16:05.052] iteration 17467 : loss : 0.047185, loss_ce: 0.016134
[02:16:05.353] iteration 17468 : loss : 0.036110, loss_ce: 0.017402
[02:16:05.652] iteration 17469 : loss : 0.050414, loss_ce: 0.016243
[02:16:05.951] iteration 17470 : loss : 0.068928, loss_ce: 0.010292
[02:16:06.253] iteration 17471 : loss : 0.038647, loss_ce: 0.006354
[02:16:06.555] iteration 17472 : loss : 0.079636, loss_ce: 0.006663
[02:16:06.861] iteration 17473 : loss : 0.066054, loss_ce: 0.016979
[02:16:07.160] iteration 17474 : loss : 0.102417, loss_ce: 0.010406
[02:16:07.462] iteration 17475 : loss : 0.101663, loss_ce: 0.012062
[02:16:07.761] iteration 17476 : loss : 0.105365, loss_ce: 0.010571
[02:16:08.063] iteration 17477 : loss : 0.046016, loss_ce: 0.013252
[02:16:08.368] iteration 17478 : loss : 0.035184, loss_ce: 0.011097
[02:16:08.669] iteration 17479 : loss : 0.044373, loss_ce: 0.009611
[02:16:08.977] iteration 17480 : loss : 0.055588, loss_ce: 0.013858
[02:16:09.305] iteration 17481 : loss : 0.107557, loss_ce: 0.010009
[02:16:09.603] iteration 17482 : loss : 0.035938, loss_ce: 0.007895
[02:16:09.906] iteration 17483 : loss : 0.157232, loss_ce: 0.007119
[02:16:10.209] iteration 17484 : loss : 0.105101, loss_ce: 0.011544
[02:16:10.508] iteration 17485 : loss : 0.050667, loss_ce: 0.021285
[02:16:10.810] iteration 17486 : loss : 0.097016, loss_ce: 0.008543
[02:16:11.109] iteration 17487 : loss : 0.040891, loss_ce: 0.010411
[02:16:11.409] iteration 17488 : loss : 0.039543, loss_ce: 0.013139
[02:16:11.714] iteration 17489 : loss : 0.039088, loss_ce: 0.011024
[02:16:12.018] iteration 17490 : loss : 0.051051, loss_ce: 0.011156
[02:16:12.321] iteration 17491 : loss : 0.037681, loss_ce: 0.012548
[02:16:12.623] iteration 17492 : loss : 0.052955, loss_ce: 0.018476
[02:16:12.930] iteration 17493 : loss : 0.050399, loss_ce: 0.014005
[02:16:13.230] iteration 17494 : loss : 0.043095, loss_ce: 0.010902
[02:16:13.532] iteration 17495 : loss : 0.102115, loss_ce: 0.013338
[02:16:13.838] iteration 17496 : loss : 0.102697, loss_ce: 0.007982
[02:16:14.135] iteration 17497 : loss : 0.043931, loss_ce: 0.009901
[02:16:14.435] iteration 17498 : loss : 0.049855, loss_ce: 0.017562
[02:16:14.744] iteration 17499 : loss : 0.039177, loss_ce: 0.015207
[02:16:15.052] iteration 17500 : loss : 0.052019, loss_ce: 0.023011
[02:16:15.390] iteration 17501 : loss : 0.051882, loss_ce: 0.021518
[02:16:15.692] iteration 17502 : loss : 0.039687, loss_ce: 0.017170
[02:16:16.000] iteration 17503 : loss : 0.055445, loss_ce: 0.015412
[02:16:16.309] iteration 17504 : loss : 0.044697, loss_ce: 0.012472
[02:16:16.613] iteration 17505 : loss : 0.046093, loss_ce: 0.021013
[02:16:16.921] iteration 17506 : loss : 0.053922, loss_ce: 0.016854
[02:16:17.226] iteration 17507 : loss : 0.042250, loss_ce: 0.014013
[02:16:17.534] iteration 17508 : loss : 0.103162, loss_ce: 0.007444
[02:16:17.839] iteration 17509 : loss : 0.221202, loss_ce: 0.007759
[02:16:18.144] iteration 17510 : loss : 0.054295, loss_ce: 0.006975
[02:16:18.451] iteration 17511 : loss : 0.045241, loss_ce: 0.011141
[02:16:18.759] iteration 17512 : loss : 0.150908, loss_ce: 0.005668
[02:16:19.066] iteration 17513 : loss : 0.046181, loss_ce: 0.021780
[02:16:19.153] iteration 17514 : loss : 0.170373, loss_ce: 0.013001
[02:16:38.358] iteration 17515 : loss : 0.281051, loss_ce: 0.006289
[02:16:38.659] iteration 17516 : loss : 0.102337, loss_ce: 0.011585
[02:16:38.962] iteration 17517 : loss : 0.103116, loss_ce: 0.014086
[02:16:39.279] iteration 17518 : loss : 0.036442, loss_ce: 0.011938
[02:16:39.593] iteration 17519 : loss : 0.034304, loss_ce: 0.009584
[02:16:39.897] iteration 17520 : loss : 0.039315, loss_ce: 0.011078
[02:16:40.221] iteration 17521 : loss : 0.105912, loss_ce: 0.016502
[02:16:40.526] iteration 17522 : loss : 0.037789, loss_ce: 0.012467
[02:16:40.829] iteration 17523 : loss : 0.099460, loss_ce: 0.008055
[02:16:41.129] iteration 17524 : loss : 0.059089, loss_ce: 0.008096
[02:16:41.429] iteration 17525 : loss : 0.281051, loss_ce: 0.004511
[02:16:41.725] iteration 17526 : loss : 0.046553, loss_ce: 0.007190
[02:16:42.022] iteration 17527 : loss : 0.041765, loss_ce: 0.009382
[02:16:42.321] iteration 17528 : loss : 0.037076, loss_ce: 0.014343
[02:16:42.620] iteration 17529 : loss : 0.103483, loss_ce: 0.007672
[02:16:42.918] iteration 17530 : loss : 0.049612, loss_ce: 0.014651
[02:16:43.214] iteration 17531 : loss : 0.036028, loss_ce: 0.010391
[02:16:43.508] iteration 17532 : loss : 0.039275, loss_ce: 0.014677
[02:16:43.810] iteration 17533 : loss : 0.047319, loss_ce: 0.018029
[02:16:44.107] iteration 17534 : loss : 0.106336, loss_ce: 0.008225
[02:16:44.405] iteration 17535 : loss : 0.102691, loss_ce: 0.008896
[02:16:44.705] iteration 17536 : loss : 0.040673, loss_ce: 0.013794
[02:16:44.999] iteration 17537 : loss : 0.188298, loss_ce: 0.009501
[02:16:45.302] iteration 17538 : loss : 0.050638, loss_ce: 0.026417
[02:16:45.604] iteration 17539 : loss : 0.050258, loss_ce: 0.018713
[02:16:45.903] iteration 17540 : loss : 0.040380, loss_ce: 0.010229
[02:16:46.220] iteration 17541 : loss : 0.153787, loss_ce: 0.010657
[02:16:46.518] iteration 17542 : loss : 0.037351, loss_ce: 0.007868
[02:16:46.811] iteration 17543 : loss : 0.065582, loss_ce: 0.013187
[02:16:47.111] iteration 17544 : loss : 0.037735, loss_ce: 0.006538
[02:16:47.411] iteration 17545 : loss : 0.104258, loss_ce: 0.016095
[02:16:47.707] iteration 17546 : loss : 0.052435, loss_ce: 0.014457
[02:16:48.002] iteration 17547 : loss : 0.044934, loss_ce: 0.020395
[02:16:48.300] iteration 17548 : loss : 0.039952, loss_ce: 0.017352
[02:16:48.599] iteration 17549 : loss : 0.035313, loss_ce: 0.006556
[02:16:48.895] iteration 17550 : loss : 0.052990, loss_ce: 0.014141
[02:16:49.189] iteration 17551 : loss : 0.052028, loss_ce: 0.010727
[02:16:49.485] iteration 17552 : loss : 0.042286, loss_ce: 0.017968
[02:16:49.784] iteration 17553 : loss : 0.103899, loss_ce: 0.010629
[02:16:50.080] iteration 17554 : loss : 0.045975, loss_ce: 0.016697
[02:16:50.378] iteration 17555 : loss : 0.042962, loss_ce: 0.016680
[02:16:50.675] iteration 17556 : loss : 0.048288, loss_ce: 0.008941
[02:16:50.980] iteration 17557 : loss : 0.055222, loss_ce: 0.014987
[02:16:51.281] iteration 17558 : loss : 0.037580, loss_ce: 0.012091
[02:16:51.579] iteration 17559 : loss : 0.073419, loss_ce: 0.019055
[02:16:51.874] iteration 17560 : loss : 0.034641, loss_ce: 0.014699
[02:16:52.187] iteration 17561 : loss : 0.106200, loss_ce: 0.009981
[02:16:52.482] iteration 17562 : loss : 0.046587, loss_ce: 0.016604
[02:16:52.781] iteration 17563 : loss : 0.084652, loss_ce: 0.016105
[02:16:53.083] iteration 17564 : loss : 0.104203, loss_ce: 0.009132
[02:16:53.375] iteration 17565 : loss : 0.111801, loss_ce: 0.008934
[02:16:53.676] iteration 17566 : loss : 0.042460, loss_ce: 0.009700
[02:16:53.970] iteration 17567 : loss : 0.046685, loss_ce: 0.021969
[02:16:54.272] iteration 17568 : loss : 0.210038, loss_ce: 0.012512
[02:16:54.574] iteration 17569 : loss : 0.047574, loss_ce: 0.020196
[02:16:54.878] iteration 17570 : loss : 0.096784, loss_ce: 0.007365
[02:16:55.182] iteration 17571 : loss : 0.039750, loss_ce: 0.015749
[02:16:55.490] iteration 17572 : loss : 0.046217, loss_ce: 0.017146
[02:16:55.794] iteration 17573 : loss : 0.050256, loss_ce: 0.013984
[02:16:56.100] iteration 17574 : loss : 0.052631, loss_ce: 0.014556
[02:16:56.397] iteration 17575 : loss : 0.099459, loss_ce: 0.008574
[02:16:56.699] iteration 17576 : loss : 0.091364, loss_ce: 0.007300
[02:16:56.995] iteration 17577 : loss : 0.056348, loss_ce: 0.019061
[02:16:57.290] iteration 17578 : loss : 0.095980, loss_ce: 0.005225
[02:16:57.591] iteration 17579 : loss : 0.052971, loss_ce: 0.016944
[02:16:57.894] iteration 17580 : loss : 0.039539, loss_ce: 0.006073
[02:16:58.216] iteration 17581 : loss : 0.101158, loss_ce: 0.010949
[02:16:58.519] iteration 17582 : loss : 0.052388, loss_ce: 0.013117
[02:16:58.816] iteration 17583 : loss : 0.037308, loss_ce: 0.013894
[02:16:59.116] iteration 17584 : loss : 0.047989, loss_ce: 0.023835
[02:16:59.412] iteration 17585 : loss : 0.045174, loss_ce: 0.016364
[02:16:59.710] iteration 17586 : loss : 0.058315, loss_ce: 0.010266
[02:17:00.012] iteration 17587 : loss : 0.164799, loss_ce: 0.012163
[02:17:00.309] iteration 17588 : loss : 0.045450, loss_ce: 0.008496
[02:17:00.612] iteration 17589 : loss : 0.038704, loss_ce: 0.012254
[02:17:00.910] iteration 17590 : loss : 0.050180, loss_ce: 0.019056
[02:17:01.208] iteration 17591 : loss : 0.093432, loss_ce: 0.007251
[02:17:01.506] iteration 17592 : loss : 0.047724, loss_ce: 0.018740
[02:17:01.806] iteration 17593 : loss : 0.047433, loss_ce: 0.013243
[02:17:02.106] iteration 17594 : loss : 0.040636, loss_ce: 0.015365
[02:17:02.404] iteration 17595 : loss : 0.039564, loss_ce: 0.015256
[02:17:02.704] iteration 17596 : loss : 0.050875, loss_ce: 0.017133
[02:17:03.003] iteration 17597 : loss : 0.043645, loss_ce: 0.016407
[02:17:03.301] iteration 17598 : loss : 0.143729, loss_ce: 0.016045
[02:17:03.598] iteration 17599 : loss : 0.042150, loss_ce: 0.016189
[02:17:03.899] iteration 17600 : loss : 0.045856, loss_ce: 0.013083
[02:17:04.219] iteration 17601 : loss : 0.048489, loss_ce: 0.012377
[02:17:04.519] iteration 17602 : loss : 0.052524, loss_ce: 0.014330
[02:17:04.825] iteration 17603 : loss : 0.032862, loss_ce: 0.013721
[02:17:05.128] iteration 17604 : loss : 0.041346, loss_ce: 0.022475
[02:17:05.427] iteration 17605 : loss : 0.048559, loss_ce: 0.011366
[02:17:05.727] iteration 17606 : loss : 0.053341, loss_ce: 0.014076
[02:17:06.027] iteration 17607 : loss : 0.048659, loss_ce: 0.026807
[02:17:06.325] iteration 17608 : loss : 0.060136, loss_ce: 0.021254
[02:17:06.630] iteration 17609 : loss : 0.129341, loss_ce: 0.010877
[02:17:06.928] iteration 17610 : loss : 0.043844, loss_ce: 0.017412
[02:17:07.226] iteration 17611 : loss : 0.056485, loss_ce: 0.011830
[02:17:07.526] iteration 17612 : loss : 0.047440, loss_ce: 0.012124
[02:17:07.824] iteration 17613 : loss : 0.037905, loss_ce: 0.012337
[02:17:08.128] iteration 17614 : loss : 0.053123, loss_ce: 0.006702
[02:17:08.424] iteration 17615 : loss : 0.042423, loss_ce: 0.011176
[02:17:08.723] iteration 17616 : loss : 0.078588, loss_ce: 0.023116
[02:17:09.018] iteration 17617 : loss : 0.100781, loss_ce: 0.009600
[02:17:09.321] iteration 17618 : loss : 0.063889, loss_ce: 0.014966
[02:17:09.625] iteration 17619 : loss : 0.050762, loss_ce: 0.014203
[02:17:09.926] iteration 17620 : loss : 0.042869, loss_ce: 0.020490
[02:17:10.245] iteration 17621 : loss : 0.056679, loss_ce: 0.012371
[02:17:10.549] iteration 17622 : loss : 0.046626, loss_ce: 0.015943
[02:17:10.851] iteration 17623 : loss : 0.070473, loss_ce: 0.012584
[02:17:11.156] iteration 17624 : loss : 0.041935, loss_ce: 0.010835
[02:17:11.456] iteration 17625 : loss : 0.042945, loss_ce: 0.013477
[02:17:11.753] iteration 17626 : loss : 0.063588, loss_ce: 0.014141
[02:17:12.055] iteration 17627 : loss : 0.113922, loss_ce: 0.010698
[02:17:12.353] iteration 17628 : loss : 0.160510, loss_ce: 0.002666
[02:17:12.652] iteration 17629 : loss : 0.042891, loss_ce: 0.015007
[02:17:12.948] iteration 17630 : loss : 0.052027, loss_ce: 0.012327
[02:17:13.251] iteration 17631 : loss : 0.046836, loss_ce: 0.017356
[02:17:13.551] iteration 17632 : loss : 0.077223, loss_ce: 0.007683
[02:17:13.850] iteration 17633 : loss : 0.055190, loss_ce: 0.012808
[02:17:14.153] iteration 17634 : loss : 0.045371, loss_ce: 0.019026
[02:17:14.450] iteration 17635 : loss : 0.096623, loss_ce: 0.009176
[02:17:14.747] iteration 17636 : loss : 0.045962, loss_ce: 0.015854
[02:17:15.048] iteration 17637 : loss : 0.048761, loss_ce: 0.014087
[02:17:15.349] iteration 17638 : loss : 0.063238, loss_ce: 0.018288
[02:17:15.658] iteration 17639 : loss : 0.050571, loss_ce: 0.015859
[02:17:15.960] iteration 17640 : loss : 0.039598, loss_ce: 0.012538
[02:17:16.285] iteration 17641 : loss : 0.048011, loss_ce: 0.019336
[02:17:16.585] iteration 17642 : loss : 0.036972, loss_ce: 0.017113
[02:17:16.887] iteration 17643 : loss : 0.106329, loss_ce: 0.015720
[02:17:17.189] iteration 17644 : loss : 0.128246, loss_ce: 0.008412
[02:17:17.493] iteration 17645 : loss : 0.053629, loss_ce: 0.019889
[02:17:17.795] iteration 17646 : loss : 0.038376, loss_ce: 0.005740
[02:17:18.100] iteration 17647 : loss : 0.040684, loss_ce: 0.017989
[02:17:18.400] iteration 17648 : loss : 0.126885, loss_ce: 0.011062
[02:17:18.702] iteration 17649 : loss : 0.078808, loss_ce: 0.014637
[02:17:19.007] iteration 17650 : loss : 0.049779, loss_ce: 0.013453
[02:17:19.307] iteration 17651 : loss : 0.040348, loss_ce: 0.017566
[02:17:19.606] iteration 17652 : loss : 0.110309, loss_ce: 0.008021
[02:17:19.692] iteration 17653 : loss : 0.062063, loss_ce: 0.025446
[02:17:37.486] iteration 17654 : loss : 0.042653, loss_ce: 0.014330
[02:17:37.790] iteration 17655 : loss : 0.060075, loss_ce: 0.014626
[02:17:38.102] iteration 17656 : loss : 0.035973, loss_ce: 0.010533
[02:17:38.410] iteration 17657 : loss : 0.099511, loss_ce: 0.014784
[02:17:38.716] iteration 17658 : loss : 0.042748, loss_ce: 0.010871
[02:17:39.018] iteration 17659 : loss : 0.107996, loss_ce: 0.007797
[02:17:39.320] iteration 17660 : loss : 0.055631, loss_ce: 0.016868
[02:17:39.636] iteration 17661 : loss : 0.043683, loss_ce: 0.016605
[02:17:39.942] iteration 17662 : loss : 0.047388, loss_ce: 0.015958
[02:17:40.242] iteration 17663 : loss : 0.155373, loss_ce: 0.008597
[02:17:40.545] iteration 17664 : loss : 0.052390, loss_ce: 0.012614
[02:17:40.848] iteration 17665 : loss : 0.038686, loss_ce: 0.016741
[02:17:41.149] iteration 17666 : loss : 0.035996, loss_ce: 0.006629
[02:17:41.454] iteration 17667 : loss : 0.040336, loss_ce: 0.014883
[02:17:41.756] iteration 17668 : loss : 0.103276, loss_ce: 0.018231
[02:17:42.061] iteration 17669 : loss : 0.038488, loss_ce: 0.007622
[02:17:42.363] iteration 17670 : loss : 0.035687, loss_ce: 0.011288
[02:17:42.669] iteration 17671 : loss : 0.046415, loss_ce: 0.018341
[02:17:42.970] iteration 17672 : loss : 0.038636, loss_ce: 0.013417
[02:17:43.272] iteration 17673 : loss : 0.110345, loss_ce: 0.011313
[02:17:43.573] iteration 17674 : loss : 0.103160, loss_ce: 0.007446
[02:17:43.873] iteration 17675 : loss : 0.042180, loss_ce: 0.020536
[02:17:44.181] iteration 17676 : loss : 0.087354, loss_ce: 0.011566
[02:17:44.486] iteration 17677 : loss : 0.052950, loss_ce: 0.016424
[02:17:44.788] iteration 17678 : loss : 0.105821, loss_ce: 0.009508
[02:17:45.094] iteration 17679 : loss : 0.059846, loss_ce: 0.023555
[02:17:45.399] iteration 17680 : loss : 0.031932, loss_ce: 0.009774
[02:17:45.721] iteration 17681 : loss : 0.039269, loss_ce: 0.011482
[02:17:46.024] iteration 17682 : loss : 0.048973, loss_ce: 0.013544
[02:17:46.326] iteration 17683 : loss : 0.046496, loss_ce: 0.022927
[02:17:46.625] iteration 17684 : loss : 0.056658, loss_ce: 0.012516
[02:17:46.926] iteration 17685 : loss : 0.112547, loss_ce: 0.016234
[02:17:47.226] iteration 17686 : loss : 0.053450, loss_ce: 0.016453
[02:17:47.525] iteration 17687 : loss : 0.097658, loss_ce: 0.006584
[02:17:47.824] iteration 17688 : loss : 0.045021, loss_ce: 0.015644
[02:17:48.128] iteration 17689 : loss : 0.036270, loss_ce: 0.016252
[02:17:48.425] iteration 17690 : loss : 0.045478, loss_ce: 0.013902
[02:17:48.729] iteration 17691 : loss : 0.039312, loss_ce: 0.012990
[02:17:49.026] iteration 17692 : loss : 0.054708, loss_ce: 0.011610
[02:17:49.322] iteration 17693 : loss : 0.098210, loss_ce: 0.014352
[02:17:49.620] iteration 17694 : loss : 0.100476, loss_ce: 0.013017
[02:17:49.919] iteration 17695 : loss : 0.097693, loss_ce: 0.009634
[02:17:50.217] iteration 17696 : loss : 0.060331, loss_ce: 0.017117
[02:17:50.517] iteration 17697 : loss : 0.062822, loss_ce: 0.015420
[02:17:50.812] iteration 17698 : loss : 0.051836, loss_ce: 0.011898
[02:17:51.112] iteration 17699 : loss : 0.031541, loss_ce: 0.008706
[02:17:51.411] iteration 17700 : loss : 0.044597, loss_ce: 0.008822
[02:17:51.738] iteration 17701 : loss : 0.039306, loss_ce: 0.014782
[02:17:52.035] iteration 17702 : loss : 0.096505, loss_ce: 0.007998
[02:17:52.336] iteration 17703 : loss : 0.103305, loss_ce: 0.009745
[02:17:52.633] iteration 17704 : loss : 0.058921, loss_ce: 0.011472
[02:17:52.929] iteration 17705 : loss : 0.045574, loss_ce: 0.014468
[02:17:53.226] iteration 17706 : loss : 0.046372, loss_ce: 0.010073
[02:17:53.526] iteration 17707 : loss : 0.051033, loss_ce: 0.011655
[02:17:53.826] iteration 17708 : loss : 0.045524, loss_ce: 0.019273
[02:17:54.123] iteration 17709 : loss : 0.107013, loss_ce: 0.013441
[02:17:54.417] iteration 17710 : loss : 0.044158, loss_ce: 0.016157
[02:17:54.717] iteration 17711 : loss : 0.054336, loss_ce: 0.012978
[02:17:55.015] iteration 17712 : loss : 0.035354, loss_ce: 0.014785
[02:17:55.315] iteration 17713 : loss : 0.111045, loss_ce: 0.010207
[02:17:55.613] iteration 17714 : loss : 0.103948, loss_ce: 0.008336
[02:17:55.916] iteration 17715 : loss : 0.035176, loss_ce: 0.016168
[02:17:56.211] iteration 17716 : loss : 0.040057, loss_ce: 0.012224
[02:17:56.509] iteration 17717 : loss : 0.109738, loss_ce: 0.014730
[02:17:56.811] iteration 17718 : loss : 0.074071, loss_ce: 0.006629
[02:17:57.110] iteration 17719 : loss : 0.094737, loss_ce: 0.006817
[02:17:57.412] iteration 17720 : loss : 0.038974, loss_ce: 0.010822
[02:17:57.725] iteration 17721 : loss : 0.043655, loss_ce: 0.015598
[02:17:58.022] iteration 17722 : loss : 0.101806, loss_ce: 0.011220
[02:17:58.321] iteration 17723 : loss : 0.080870, loss_ce: 0.010345
[02:17:58.621] iteration 17724 : loss : 0.038445, loss_ce: 0.010471
[02:17:58.919] iteration 17725 : loss : 0.103989, loss_ce: 0.007595
[02:17:59.222] iteration 17726 : loss : 0.053987, loss_ce: 0.022190
[02:17:59.527] iteration 17727 : loss : 0.055823, loss_ce: 0.015261
[02:17:59.836] iteration 17728 : loss : 0.046613, loss_ce: 0.018203
[02:18:00.137] iteration 17729 : loss : 0.045939, loss_ce: 0.017434
[02:18:00.440] iteration 17730 : loss : 0.093954, loss_ce: 0.010949
[02:18:00.745] iteration 17731 : loss : 0.042301, loss_ce: 0.015100
[02:18:01.046] iteration 17732 : loss : 0.055255, loss_ce: 0.015066
[02:18:01.345] iteration 17733 : loss : 0.065738, loss_ce: 0.010680
[02:18:01.647] iteration 17734 : loss : 0.043141, loss_ce: 0.015493
[02:18:01.942] iteration 17735 : loss : 0.034585, loss_ce: 0.006271
[02:18:02.244] iteration 17736 : loss : 0.042774, loss_ce: 0.013318
[02:18:02.543] iteration 17737 : loss : 0.051478, loss_ce: 0.013163
[02:18:02.840] iteration 17738 : loss : 0.044445, loss_ce: 0.014218
[02:18:03.137] iteration 17739 : loss : 0.163490, loss_ce: 0.013522
[02:18:03.430] iteration 17740 : loss : 0.108479, loss_ce: 0.010039
[02:18:03.746] iteration 17741 : loss : 0.046005, loss_ce: 0.016051
[02:18:04.045] iteration 17742 : loss : 0.059071, loss_ce: 0.020450
[02:18:04.345] iteration 17743 : loss : 0.105298, loss_ce: 0.013842
[02:18:04.645] iteration 17744 : loss : 0.090680, loss_ce: 0.007396
[02:18:04.949] iteration 17745 : loss : 0.074693, loss_ce: 0.008127
[02:18:05.246] iteration 17746 : loss : 0.061657, loss_ce: 0.009386
[02:18:05.547] iteration 17747 : loss : 0.044842, loss_ce: 0.017635
[02:18:05.848] iteration 17748 : loss : 0.048897, loss_ce: 0.013552
[02:18:06.143] iteration 17749 : loss : 0.044267, loss_ce: 0.014781
[02:18:06.441] iteration 17750 : loss : 0.045393, loss_ce: 0.018518
[02:18:06.742] iteration 17751 : loss : 0.049142, loss_ce: 0.011617
[02:18:07.037] iteration 17752 : loss : 0.109550, loss_ce: 0.015864
[02:18:07.335] iteration 17753 : loss : 0.055205, loss_ce: 0.017670
[02:18:07.638] iteration 17754 : loss : 0.040847, loss_ce: 0.012834
[02:18:07.940] iteration 17755 : loss : 0.035881, loss_ce: 0.009155
[02:18:08.236] iteration 17756 : loss : 0.045639, loss_ce: 0.016916
[02:18:08.535] iteration 17757 : loss : 0.040266, loss_ce: 0.020935
[02:18:08.833] iteration 17758 : loss : 0.056172, loss_ce: 0.018822
[02:18:09.129] iteration 17759 : loss : 0.044953, loss_ce: 0.009940
[02:18:09.426] iteration 17760 : loss : 0.044782, loss_ce: 0.014807
[02:18:09.744] iteration 17761 : loss : 0.107103, loss_ce: 0.009309
[02:18:10.044] iteration 17762 : loss : 0.036405, loss_ce: 0.012044
[02:18:10.342] iteration 17763 : loss : 0.050741, loss_ce: 0.022640
[02:18:10.639] iteration 17764 : loss : 0.034003, loss_ce: 0.011718
[02:18:10.939] iteration 17765 : loss : 0.048579, loss_ce: 0.013181
[02:18:11.244] iteration 17766 : loss : 0.053180, loss_ce: 0.017471
[02:18:11.541] iteration 17767 : loss : 0.048255, loss_ce: 0.013743
[02:18:11.839] iteration 17768 : loss : 0.099221, loss_ce: 0.007465
[02:18:12.139] iteration 17769 : loss : 0.043644, loss_ce: 0.015104
[02:18:12.438] iteration 17770 : loss : 0.042269, loss_ce: 0.008620
[02:18:12.741] iteration 17771 : loss : 0.108189, loss_ce: 0.007551
[02:18:13.043] iteration 17772 : loss : 0.061716, loss_ce: 0.025708
[02:18:13.339] iteration 17773 : loss : 0.050414, loss_ce: 0.013603
[02:18:13.639] iteration 17774 : loss : 0.043828, loss_ce: 0.016190
[02:18:13.936] iteration 17775 : loss : 0.044684, loss_ce: 0.011253
[02:18:14.235] iteration 17776 : loss : 0.056725, loss_ce: 0.021337
[02:18:14.542] iteration 17777 : loss : 0.093389, loss_ce: 0.006215
[02:18:14.849] iteration 17778 : loss : 0.168515, loss_ce: 0.009102
[02:18:15.151] iteration 17779 : loss : 0.069023, loss_ce: 0.024122
[02:18:15.454] iteration 17780 : loss : 0.045082, loss_ce: 0.016067
[02:18:15.780] iteration 17781 : loss : 0.041101, loss_ce: 0.008177
[02:18:16.080] iteration 17782 : loss : 0.047526, loss_ce: 0.012269
[02:18:16.385] iteration 17783 : loss : 0.039932, loss_ce: 0.006146
[02:18:16.688] iteration 17784 : loss : 0.042213, loss_ce: 0.014869
[02:18:16.988] iteration 17785 : loss : 0.047191, loss_ce: 0.006638
[02:18:17.294] iteration 17786 : loss : 0.044783, loss_ce: 0.011016
[02:18:17.601] iteration 17787 : loss : 0.045252, loss_ce: 0.016658
[02:18:17.909] iteration 17788 : loss : 0.040844, loss_ce: 0.009803
[02:18:18.213] iteration 17789 : loss : 0.040168, loss_ce: 0.012615
[02:18:18.518] iteration 17790 : loss : 0.037382, loss_ce: 0.006150
[02:18:18.830] iteration 17791 : loss : 0.280809, loss_ce: 0.010358
[02:18:18.908] iteration 17792 : loss : 0.192823, loss_ce: 0.026519
[02:18:37.598] iteration 17793 : loss : 0.047801, loss_ce: 0.013654
[02:18:37.904] iteration 17794 : loss : 0.048483, loss_ce: 0.011586
[02:18:38.208] iteration 17795 : loss : 0.052173, loss_ce: 0.012014
[02:18:38.512] iteration 17796 : loss : 0.042743, loss_ce: 0.017349
[02:18:38.818] iteration 17797 : loss : 0.045365, loss_ce: 0.015717
[02:18:39.115] iteration 17798 : loss : 0.107650, loss_ce: 0.007035
[02:18:39.414] iteration 17799 : loss : 0.042497, loss_ce: 0.018445
[02:18:39.713] iteration 17800 : loss : 0.055984, loss_ce: 0.015276
[02:18:40.024] iteration 17801 : loss : 0.038408, loss_ce: 0.010976
[02:18:40.321] iteration 17802 : loss : 0.042422, loss_ce: 0.012291
[02:18:40.621] iteration 17803 : loss : 0.028855, loss_ce: 0.007849
[02:18:40.919] iteration 17804 : loss : 0.040715, loss_ce: 0.012141
[02:18:41.212] iteration 17805 : loss : 0.099180, loss_ce: 0.011155
[02:18:41.510] iteration 17806 : loss : 0.053348, loss_ce: 0.014215
[02:18:41.808] iteration 17807 : loss : 0.042174, loss_ce: 0.010574
[02:18:42.103] iteration 17808 : loss : 0.041759, loss_ce: 0.017328
[02:18:42.400] iteration 17809 : loss : 0.039945, loss_ce: 0.019205
[02:18:42.695] iteration 17810 : loss : 0.038227, loss_ce: 0.013699
[02:18:42.994] iteration 17811 : loss : 0.101116, loss_ce: 0.016269
[02:18:43.292] iteration 17812 : loss : 0.033914, loss_ce: 0.008663
[02:18:43.593] iteration 17813 : loss : 0.112438, loss_ce: 0.013294
[02:18:43.891] iteration 17814 : loss : 0.040799, loss_ce: 0.016587
[02:18:44.191] iteration 17815 : loss : 0.065903, loss_ce: 0.013316
[02:18:44.485] iteration 17816 : loss : 0.046890, loss_ce: 0.017606
[02:18:44.786] iteration 17817 : loss : 0.056985, loss_ce: 0.022432
[02:18:45.085] iteration 17818 : loss : 0.049864, loss_ce: 0.016254
[02:18:45.381] iteration 17819 : loss : 0.045518, loss_ce: 0.016929
[02:18:45.677] iteration 17820 : loss : 0.043525, loss_ce: 0.007542
[02:18:45.992] iteration 17821 : loss : 0.030510, loss_ce: 0.007752
[02:18:46.291] iteration 17822 : loss : 0.037537, loss_ce: 0.009378
[02:18:46.587] iteration 17823 : loss : 0.079762, loss_ce: 0.012839
[02:18:46.885] iteration 17824 : loss : 0.044551, loss_ce: 0.010474
[02:18:47.181] iteration 17825 : loss : 0.057774, loss_ce: 0.016615
[02:18:47.478] iteration 17826 : loss : 0.054453, loss_ce: 0.012136
[02:18:47.781] iteration 17827 : loss : 0.038159, loss_ce: 0.016857
[02:18:48.083] iteration 17828 : loss : 0.104712, loss_ce: 0.009862
[02:18:48.380] iteration 17829 : loss : 0.045754, loss_ce: 0.012378
[02:18:48.678] iteration 17830 : loss : 0.099052, loss_ce: 0.015364
[02:18:48.978] iteration 17831 : loss : 0.042873, loss_ce: 0.012427
[02:18:49.283] iteration 17832 : loss : 0.048645, loss_ce: 0.011666
[02:18:49.587] iteration 17833 : loss : 0.040505, loss_ce: 0.017494
[02:18:49.894] iteration 17834 : loss : 0.047032, loss_ce: 0.012870
[02:18:50.196] iteration 17835 : loss : 0.048591, loss_ce: 0.019573
[02:18:50.500] iteration 17836 : loss : 0.094542, loss_ce: 0.006377
[02:18:50.803] iteration 17837 : loss : 0.039319, loss_ce: 0.007446
[02:18:51.104] iteration 17838 : loss : 0.050021, loss_ce: 0.007102
[02:18:51.404] iteration 17839 : loss : 0.037639, loss_ce: 0.012664
[02:18:51.700] iteration 17840 : loss : 0.048899, loss_ce: 0.018239
[02:18:52.017] iteration 17841 : loss : 0.039511, loss_ce: 0.015420
[02:18:52.313] iteration 17842 : loss : 0.082161, loss_ce: 0.013539
[02:18:52.612] iteration 17843 : loss : 0.062622, loss_ce: 0.021470
[02:18:52.910] iteration 17844 : loss : 0.051363, loss_ce: 0.012484
[02:18:53.211] iteration 17845 : loss : 0.039098, loss_ce: 0.006145
[02:18:53.508] iteration 17846 : loss : 0.156889, loss_ce: 0.006009
[02:18:53.807] iteration 17847 : loss : 0.046637, loss_ce: 0.018486
[02:18:54.107] iteration 17848 : loss : 0.067455, loss_ce: 0.007761
[02:18:54.408] iteration 17849 : loss : 0.032354, loss_ce: 0.011674
[02:18:54.705] iteration 17850 : loss : 0.061487, loss_ce: 0.016171
[02:18:55.006] iteration 17851 : loss : 0.040916, loss_ce: 0.013980
[02:18:55.302] iteration 17852 : loss : 0.050799, loss_ce: 0.012922
[02:18:55.598] iteration 17853 : loss : 0.037620, loss_ce: 0.013977
[02:18:55.896] iteration 17854 : loss : 0.097783, loss_ce: 0.003945
[02:18:56.194] iteration 17855 : loss : 0.058754, loss_ce: 0.015850
[02:18:56.493] iteration 17856 : loss : 0.109299, loss_ce: 0.010659
[02:18:56.790] iteration 17857 : loss : 0.097014, loss_ce: 0.010344
[02:18:57.083] iteration 17858 : loss : 0.044457, loss_ce: 0.015199
[02:18:57.379] iteration 17859 : loss : 0.041622, loss_ce: 0.014295
[02:18:57.677] iteration 17860 : loss : 0.053781, loss_ce: 0.018418
[02:18:57.991] iteration 17861 : loss : 0.044102, loss_ce: 0.018005
[02:18:58.290] iteration 17862 : loss : 0.058268, loss_ce: 0.009950
[02:18:58.590] iteration 17863 : loss : 0.040455, loss_ce: 0.010908
[02:18:58.888] iteration 17864 : loss : 0.041803, loss_ce: 0.009982
[02:18:59.188] iteration 17865 : loss : 0.101065, loss_ce: 0.005307
[02:18:59.488] iteration 17866 : loss : 0.056784, loss_ce: 0.018948
[02:18:59.787] iteration 17867 : loss : 0.100253, loss_ce: 0.016095
[02:19:00.088] iteration 17868 : loss : 0.038783, loss_ce: 0.017997
[02:19:00.384] iteration 17869 : loss : 0.033395, loss_ce: 0.011981
[02:19:00.678] iteration 17870 : loss : 0.045497, loss_ce: 0.017365
[02:19:00.980] iteration 17871 : loss : 0.101940, loss_ce: 0.008343
[02:19:01.280] iteration 17872 : loss : 0.062109, loss_ce: 0.012223
[02:19:01.581] iteration 17873 : loss : 0.100275, loss_ce: 0.011308
[02:19:01.879] iteration 17874 : loss : 0.038485, loss_ce: 0.018974
[02:19:02.179] iteration 17875 : loss : 0.060579, loss_ce: 0.014762
[02:19:02.480] iteration 17876 : loss : 0.042239, loss_ce: 0.013912
[02:19:02.778] iteration 17877 : loss : 0.411850, loss_ce: 0.000471
[02:19:03.076] iteration 17878 : loss : 0.045194, loss_ce: 0.021262
[02:19:03.373] iteration 17879 : loss : 0.049475, loss_ce: 0.017995
[02:19:03.670] iteration 17880 : loss : 0.045677, loss_ce: 0.015870
[02:19:03.983] iteration 17881 : loss : 0.113890, loss_ce: 0.006466
[02:19:04.287] iteration 17882 : loss : 0.038951, loss_ce: 0.012399
[02:19:04.590] iteration 17883 : loss : 0.069005, loss_ce: 0.010178
[02:19:04.895] iteration 17884 : loss : 0.044708, loss_ce: 0.011195
[02:19:05.203] iteration 17885 : loss : 0.049770, loss_ce: 0.025087
[02:19:05.507] iteration 17886 : loss : 0.053915, loss_ce: 0.015741
[02:19:05.811] iteration 17887 : loss : 0.039421, loss_ce: 0.009153
[02:19:06.118] iteration 17888 : loss : 0.129638, loss_ce: 0.014062
[02:19:06.412] iteration 17889 : loss : 0.051408, loss_ce: 0.023587
[02:19:06.712] iteration 17890 : loss : 0.057628, loss_ce: 0.016077
[02:19:07.011] iteration 17891 : loss : 0.046299, loss_ce: 0.016646
[02:19:07.310] iteration 17892 : loss : 0.109227, loss_ce: 0.008224
[02:19:07.611] iteration 17893 : loss : 0.063189, loss_ce: 0.016353
[02:19:07.908] iteration 17894 : loss : 0.056819, loss_ce: 0.013129
[02:19:08.208] iteration 17895 : loss : 0.043237, loss_ce: 0.011536
[02:19:08.506] iteration 17896 : loss : 0.121412, loss_ce: 0.015067
[02:19:08.806] iteration 17897 : loss : 0.055061, loss_ce: 0.019471
[02:19:09.100] iteration 17898 : loss : 0.096587, loss_ce: 0.006267
[02:19:09.397] iteration 17899 : loss : 0.052004, loss_ce: 0.012067
[02:19:09.696] iteration 17900 : loss : 0.057043, loss_ce: 0.012172
[02:19:10.015] iteration 17901 : loss : 0.043086, loss_ce: 0.010858
[02:19:10.308] iteration 17902 : loss : 0.056666, loss_ce: 0.018416
[02:19:10.607] iteration 17903 : loss : 0.052111, loss_ce: 0.016818
[02:19:10.905] iteration 17904 : loss : 0.046880, loss_ce: 0.017042
[02:19:11.202] iteration 17905 : loss : 0.039552, loss_ce: 0.011471
[02:19:11.503] iteration 17906 : loss : 0.110551, loss_ce: 0.015781
[02:19:11.801] iteration 17907 : loss : 0.038696, loss_ce: 0.009688
[02:19:12.101] iteration 17908 : loss : 0.043531, loss_ce: 0.016848
[02:19:12.397] iteration 17909 : loss : 0.031129, loss_ce: 0.012114
[02:19:12.694] iteration 17910 : loss : 0.050192, loss_ce: 0.022714
[02:19:12.994] iteration 17911 : loss : 0.105448, loss_ce: 0.007722
[02:19:13.291] iteration 17912 : loss : 0.046835, loss_ce: 0.014217
[02:19:13.589] iteration 17913 : loss : 0.055027, loss_ce: 0.019498
[02:19:13.887] iteration 17914 : loss : 0.077306, loss_ce: 0.014083
[02:19:14.188] iteration 17915 : loss : 0.046624, loss_ce: 0.020231
[02:19:14.488] iteration 17916 : loss : 0.052196, loss_ce: 0.015656
[02:19:14.795] iteration 17917 : loss : 0.102130, loss_ce: 0.016789
[02:19:15.095] iteration 17918 : loss : 0.062024, loss_ce: 0.015796
[02:19:15.394] iteration 17919 : loss : 0.108017, loss_ce: 0.014496
[02:19:15.704] iteration 17920 : loss : 0.046627, loss_ce: 0.012868
[02:19:16.036] iteration 17921 : loss : 0.096636, loss_ce: 0.006051
[02:19:16.337] iteration 17922 : loss : 0.041101, loss_ce: 0.010557
[02:19:16.641] iteration 17923 : loss : 0.054787, loss_ce: 0.016708
[02:19:16.939] iteration 17924 : loss : 0.083871, loss_ce: 0.016752
[02:19:17.241] iteration 17925 : loss : 0.041555, loss_ce: 0.010696
[02:19:17.546] iteration 17926 : loss : 0.033127, loss_ce: 0.011629
[02:19:17.848] iteration 17927 : loss : 0.221513, loss_ce: 0.006893
[02:19:18.155] iteration 17928 : loss : 0.060106, loss_ce: 0.010339
[02:19:18.454] iteration 17929 : loss : 0.115596, loss_ce: 0.010481
[02:19:18.758] iteration 17930 : loss : 0.056842, loss_ce: 0.026527
[02:19:18.849] iteration 17931 : loss : 0.059958, loss_ce: 0.022216
[02:19:38.802] iteration 17932 : loss : 0.029518, loss_ce: 0.006913
[02:19:39.112] iteration 17933 : loss : 0.164265, loss_ce: 0.009355
[02:19:39.417] iteration 17934 : loss : 0.095904, loss_ce: 0.017250
[02:19:39.725] iteration 17935 : loss : 0.041940, loss_ce: 0.018998
[02:19:40.028] iteration 17936 : loss : 0.046161, loss_ce: 0.023392
[02:19:40.328] iteration 17937 : loss : 0.041172, loss_ce: 0.017409
[02:19:40.630] iteration 17938 : loss : 0.042324, loss_ce: 0.010159
[02:19:40.934] iteration 17939 : loss : 0.047886, loss_ce: 0.015133
[02:19:41.236] iteration 17940 : loss : 0.042568, loss_ce: 0.012541
[02:19:41.550] iteration 17941 : loss : 0.054728, loss_ce: 0.013007
[02:19:41.849] iteration 17942 : loss : 0.045881, loss_ce: 0.015125
[02:19:42.154] iteration 17943 : loss : 0.051069, loss_ce: 0.011279
[02:19:42.459] iteration 17944 : loss : 0.059031, loss_ce: 0.012337
[02:19:42.766] iteration 17945 : loss : 0.057476, loss_ce: 0.013046
[02:19:43.066] iteration 17946 : loss : 0.120248, loss_ce: 0.012614
[02:19:43.366] iteration 17947 : loss : 0.046582, loss_ce: 0.016525
[02:19:43.675] iteration 17948 : loss : 0.075858, loss_ce: 0.019562
[02:19:43.974] iteration 17949 : loss : 0.072003, loss_ce: 0.008448
[02:19:44.274] iteration 17950 : loss : 0.038574, loss_ce: 0.013842
[02:19:44.579] iteration 17951 : loss : 0.047639, loss_ce: 0.007471
[02:19:44.881] iteration 17952 : loss : 0.040836, loss_ce: 0.017355
[02:19:45.184] iteration 17953 : loss : 0.047876, loss_ce: 0.015170
[02:19:45.488] iteration 17954 : loss : 0.043794, loss_ce: 0.015047
[02:19:45.792] iteration 17955 : loss : 0.109305, loss_ce: 0.008559
[02:19:46.095] iteration 17956 : loss : 0.159675, loss_ce: 0.002945
[02:19:46.392] iteration 17957 : loss : 0.045024, loss_ce: 0.015375
[02:19:46.697] iteration 17958 : loss : 0.041397, loss_ce: 0.009219
[02:19:47.004] iteration 17959 : loss : 0.044664, loss_ce: 0.018898
[02:19:47.307] iteration 17960 : loss : 0.061376, loss_ce: 0.019839
[02:19:47.630] iteration 17961 : loss : 0.035018, loss_ce: 0.010006
[02:19:47.935] iteration 17962 : loss : 0.047703, loss_ce: 0.021563
[02:19:48.239] iteration 17963 : loss : 0.029749, loss_ce: 0.006737
[02:19:48.542] iteration 17964 : loss : 0.099845, loss_ce: 0.011973
[02:19:48.842] iteration 17965 : loss : 0.054733, loss_ce: 0.023209
[02:19:49.148] iteration 17966 : loss : 0.041009, loss_ce: 0.016702
[02:19:49.450] iteration 17967 : loss : 0.159622, loss_ce: 0.007428
[02:19:49.755] iteration 17968 : loss : 0.051103, loss_ce: 0.014207
[02:19:50.054] iteration 17969 : loss : 0.044115, loss_ce: 0.019783
[02:19:50.359] iteration 17970 : loss : 0.037928, loss_ce: 0.013035
[02:19:50.657] iteration 17971 : loss : 0.113305, loss_ce: 0.022504
[02:19:50.958] iteration 17972 : loss : 0.060902, loss_ce: 0.024294
[02:19:51.260] iteration 17973 : loss : 0.054065, loss_ce: 0.015130
[02:19:51.561] iteration 17974 : loss : 0.108349, loss_ce: 0.012401
[02:19:51.865] iteration 17975 : loss : 0.039512, loss_ce: 0.015163
[02:19:52.170] iteration 17976 : loss : 0.066484, loss_ce: 0.005811
[02:19:52.472] iteration 17977 : loss : 0.044191, loss_ce: 0.018930
[02:19:52.777] iteration 17978 : loss : 0.105884, loss_ce: 0.006044
[02:19:53.078] iteration 17979 : loss : 0.106696, loss_ce: 0.013877
[02:19:53.380] iteration 17980 : loss : 0.049179, loss_ce: 0.019022
[02:19:53.696] iteration 17981 : loss : 0.045782, loss_ce: 0.015433
[02:19:53.993] iteration 17982 : loss : 0.048541, loss_ce: 0.011549
[02:19:54.297] iteration 17983 : loss : 0.046775, loss_ce: 0.008430
[02:19:54.599] iteration 17984 : loss : 0.043414, loss_ce: 0.013816
[02:19:54.903] iteration 17985 : loss : 0.056232, loss_ce: 0.017969
[02:19:55.207] iteration 17986 : loss : 0.053235, loss_ce: 0.016448
[02:19:55.508] iteration 17987 : loss : 0.039667, loss_ce: 0.009331
[02:19:55.810] iteration 17988 : loss : 0.044724, loss_ce: 0.016954
[02:19:56.118] iteration 17989 : loss : 0.039400, loss_ce: 0.015438
[02:19:56.423] iteration 17990 : loss : 0.046122, loss_ce: 0.015720
[02:19:56.718] iteration 17991 : loss : 0.041009, loss_ce: 0.015261
[02:19:57.017] iteration 17992 : loss : 0.037368, loss_ce: 0.013212
[02:19:57.320] iteration 17993 : loss : 0.040717, loss_ce: 0.007792
[02:19:57.618] iteration 17994 : loss : 0.041533, loss_ce: 0.013988
[02:19:57.915] iteration 17995 : loss : 0.033923, loss_ce: 0.007369
[02:19:58.212] iteration 17996 : loss : 0.103011, loss_ce: 0.014053
[02:19:58.512] iteration 17997 : loss : 0.041488, loss_ce: 0.009263
[02:19:58.810] iteration 17998 : loss : 0.042675, loss_ce: 0.014584
[02:19:59.108] iteration 17999 : loss : 0.039788, loss_ce: 0.019020
[02:19:59.407] iteration 18000 : loss : 0.046909, loss_ce: 0.020983
[02:19:59.721] iteration 18001 : loss : 0.109167, loss_ce: 0.008171
[02:20:00.020] iteration 18002 : loss : 0.110956, loss_ce: 0.010460
[02:20:00.326] iteration 18003 : loss : 0.047981, loss_ce: 0.016551
[02:20:00.622] iteration 18004 : loss : 0.102350, loss_ce: 0.013105
[02:20:00.926] iteration 18005 : loss : 0.107293, loss_ce: 0.010396
[02:20:01.228] iteration 18006 : loss : 0.139742, loss_ce: 0.009438
[02:20:01.525] iteration 18007 : loss : 0.044698, loss_ce: 0.010034
[02:20:01.823] iteration 18008 : loss : 0.044877, loss_ce: 0.008721
[02:20:02.121] iteration 18009 : loss : 0.048414, loss_ce: 0.022138
[02:20:02.416] iteration 18010 : loss : 0.113263, loss_ce: 0.010561
[02:20:02.713] iteration 18011 : loss : 0.102928, loss_ce: 0.010640
[02:20:03.016] iteration 18012 : loss : 0.045565, loss_ce: 0.009947
[02:20:03.314] iteration 18013 : loss : 0.041805, loss_ce: 0.013511
[02:20:03.611] iteration 18014 : loss : 0.040346, loss_ce: 0.011643
[02:20:03.911] iteration 18015 : loss : 0.174968, loss_ce: 0.008451
[02:20:04.206] iteration 18016 : loss : 0.057460, loss_ce: 0.014579
[02:20:04.505] iteration 18017 : loss : 0.042867, loss_ce: 0.014412
[02:20:04.804] iteration 18018 : loss : 0.049324, loss_ce: 0.011605
[02:20:05.106] iteration 18019 : loss : 0.052700, loss_ce: 0.016580
[02:20:05.404] iteration 18020 : loss : 0.040840, loss_ce: 0.011873
[02:20:05.726] iteration 18021 : loss : 0.063750, loss_ce: 0.016484
[02:20:06.028] iteration 18022 : loss : 0.039837, loss_ce: 0.012027
[02:20:06.327] iteration 18023 : loss : 0.043351, loss_ce: 0.012204
[02:20:06.622] iteration 18024 : loss : 0.108740, loss_ce: 0.013973
[02:20:06.922] iteration 18025 : loss : 0.050321, loss_ce: 0.019172
[02:20:07.218] iteration 18026 : loss : 0.051399, loss_ce: 0.019397
[02:20:07.513] iteration 18027 : loss : 0.045006, loss_ce: 0.011987
[02:20:07.815] iteration 18028 : loss : 0.046133, loss_ce: 0.014953
[02:20:08.109] iteration 18029 : loss : 0.039503, loss_ce: 0.015735
[02:20:08.414] iteration 18030 : loss : 0.050201, loss_ce: 0.011831
[02:20:08.715] iteration 18031 : loss : 0.055459, loss_ce: 0.014969
[02:20:09.013] iteration 18032 : loss : 0.047808, loss_ce: 0.013070
[02:20:09.317] iteration 18033 : loss : 0.038339, loss_ce: 0.007905
[02:20:09.621] iteration 18034 : loss : 0.041275, loss_ce: 0.015324
[02:20:09.926] iteration 18035 : loss : 0.051085, loss_ce: 0.016946
[02:20:10.232] iteration 18036 : loss : 0.055301, loss_ce: 0.010344
[02:20:10.539] iteration 18037 : loss : 0.094076, loss_ce: 0.009888
[02:20:10.844] iteration 18038 : loss : 0.044326, loss_ce: 0.016665
[02:20:11.146] iteration 18039 : loss : 0.099698, loss_ce: 0.007265
[02:20:11.447] iteration 18040 : loss : 0.061498, loss_ce: 0.015623
[02:20:11.760] iteration 18041 : loss : 0.053212, loss_ce: 0.025344
[02:20:12.059] iteration 18042 : loss : 0.044542, loss_ce: 0.015313
[02:20:12.362] iteration 18043 : loss : 0.040027, loss_ce: 0.012696
[02:20:12.663] iteration 18044 : loss : 0.045032, loss_ce: 0.009020
[02:20:12.961] iteration 18045 : loss : 0.112832, loss_ce: 0.007887
[02:20:13.262] iteration 18046 : loss : 0.057405, loss_ce: 0.011481
[02:20:13.557] iteration 18047 : loss : 0.051121, loss_ce: 0.012102
[02:20:13.858] iteration 18048 : loss : 0.062899, loss_ce: 0.019679
[02:20:14.157] iteration 18049 : loss : 0.035450, loss_ce: 0.013921
[02:20:14.459] iteration 18050 : loss : 0.046145, loss_ce: 0.008524
[02:20:14.761] iteration 18051 : loss : 0.101088, loss_ce: 0.009181
[02:20:15.061] iteration 18052 : loss : 0.051625, loss_ce: 0.014533
[02:20:15.364] iteration 18053 : loss : 0.036539, loss_ce: 0.009963
[02:20:15.667] iteration 18054 : loss : 0.050602, loss_ce: 0.012675
[02:20:15.969] iteration 18055 : loss : 0.085767, loss_ce: 0.009827
[02:20:16.272] iteration 18056 : loss : 0.038658, loss_ce: 0.008326
[02:20:16.572] iteration 18057 : loss : 0.057008, loss_ce: 0.015497
[02:20:16.875] iteration 18058 : loss : 0.041637, loss_ce: 0.015231
[02:20:17.176] iteration 18059 : loss : 0.038926, loss_ce: 0.008925
[02:20:17.484] iteration 18060 : loss : 0.046778, loss_ce: 0.020181
[02:20:17.806] iteration 18061 : loss : 0.040293, loss_ce: 0.009375
[02:20:18.106] iteration 18062 : loss : 0.105855, loss_ce: 0.008842
[02:20:18.415] iteration 18063 : loss : 0.058338, loss_ce: 0.007846
[02:20:18.720] iteration 18064 : loss : 0.050426, loss_ce: 0.010385
[02:20:19.021] iteration 18065 : loss : 0.042900, loss_ce: 0.019226
[02:20:19.325] iteration 18066 : loss : 0.039946, loss_ce: 0.015377
[02:20:19.627] iteration 18067 : loss : 0.038536, loss_ce: 0.013370
[02:20:19.930] iteration 18068 : loss : 0.101218, loss_ce: 0.009882
[02:20:20.236] iteration 18069 : loss : 0.047729, loss_ce: 0.013656
[02:20:20.314] iteration 18070 : loss : 0.372345, loss_ce: 0.001594
[02:20:38.982] iteration 18071 : loss : 0.073310, loss_ce: 0.004833
[02:20:39.286] iteration 18072 : loss : 0.100713, loss_ce: 0.011902
[02:20:39.594] iteration 18073 : loss : 0.102662, loss_ce: 0.011808
[02:20:39.897] iteration 18074 : loss : 0.046733, loss_ce: 0.013268
[02:20:40.200] iteration 18075 : loss : 0.050457, loss_ce: 0.012337
[02:20:40.497] iteration 18076 : loss : 0.058145, loss_ce: 0.017693
[02:20:40.800] iteration 18077 : loss : 0.038515, loss_ce: 0.013381
[02:20:41.098] iteration 18078 : loss : 0.047694, loss_ce: 0.012351
[02:20:41.391] iteration 18079 : loss : 0.108029, loss_ce: 0.013228
[02:20:41.697] iteration 18080 : loss : 0.043294, loss_ce: 0.011724
[02:20:42.019] iteration 18081 : loss : 0.045319, loss_ce: 0.012579
[02:20:42.322] iteration 18082 : loss : 0.124192, loss_ce: 0.012646
[02:20:42.628] iteration 18083 : loss : 0.046783, loss_ce: 0.012654
[02:20:42.940] iteration 18084 : loss : 0.039983, loss_ce: 0.019933
[02:20:43.240] iteration 18085 : loss : 0.054695, loss_ce: 0.016501
[02:20:43.545] iteration 18086 : loss : 0.036179, loss_ce: 0.010584
[02:20:43.848] iteration 18087 : loss : 0.043281, loss_ce: 0.014097
[02:20:44.147] iteration 18088 : loss : 0.054072, loss_ce: 0.015415
[02:20:44.449] iteration 18089 : loss : 0.049010, loss_ce: 0.020700
[02:20:44.757] iteration 18090 : loss : 0.074934, loss_ce: 0.021055
[02:20:45.064] iteration 18091 : loss : 0.045523, loss_ce: 0.015151
[02:20:45.370] iteration 18092 : loss : 0.042841, loss_ce: 0.016067
[02:20:45.673] iteration 18093 : loss : 0.042968, loss_ce: 0.017180
[02:20:45.976] iteration 18094 : loss : 0.039782, loss_ce: 0.011759
[02:20:46.277] iteration 18095 : loss : 0.042946, loss_ce: 0.016354
[02:20:46.582] iteration 18096 : loss : 0.044980, loss_ce: 0.019420
[02:20:46.886] iteration 18097 : loss : 0.101234, loss_ce: 0.010650
[02:20:47.187] iteration 18098 : loss : 0.165472, loss_ce: 0.012383
[02:20:47.495] iteration 18099 : loss : 0.046025, loss_ce: 0.011259
[02:20:47.793] iteration 18100 : loss : 0.098613, loss_ce: 0.011467
[02:20:48.124] iteration 18101 : loss : 0.053346, loss_ce: 0.015406
[02:20:48.427] iteration 18102 : loss : 0.044785, loss_ce: 0.012196
[02:20:48.731] iteration 18103 : loss : 0.046960, loss_ce: 0.017242
[02:20:49.036] iteration 18104 : loss : 0.055853, loss_ce: 0.015283
[02:20:49.336] iteration 18105 : loss : 0.041351, loss_ce: 0.017476
[02:20:49.640] iteration 18106 : loss : 0.050766, loss_ce: 0.018589
[02:20:49.941] iteration 18107 : loss : 0.038217, loss_ce: 0.019619
[02:20:50.244] iteration 18108 : loss : 0.043531, loss_ce: 0.017785
[02:20:50.546] iteration 18109 : loss : 0.047773, loss_ce: 0.016993
[02:20:50.850] iteration 18110 : loss : 0.043949, loss_ce: 0.008213
[02:20:51.150] iteration 18111 : loss : 0.044867, loss_ce: 0.018806
[02:20:51.454] iteration 18112 : loss : 0.044039, loss_ce: 0.016418
[02:20:51.757] iteration 18113 : loss : 0.106478, loss_ce: 0.006024
[02:20:52.063] iteration 18114 : loss : 0.042428, loss_ce: 0.016957
[02:20:52.367] iteration 18115 : loss : 0.039643, loss_ce: 0.016174
[02:20:52.665] iteration 18116 : loss : 0.104517, loss_ce: 0.012879
[02:20:52.970] iteration 18117 : loss : 0.057423, loss_ce: 0.015967
[02:20:53.270] iteration 18118 : loss : 0.100481, loss_ce: 0.005337
[02:20:53.574] iteration 18119 : loss : 0.098179, loss_ce: 0.012259
[02:20:53.881] iteration 18120 : loss : 0.104090, loss_ce: 0.015442
[02:20:54.203] iteration 18121 : loss : 0.038165, loss_ce: 0.010595
[02:20:54.503] iteration 18122 : loss : 0.044463, loss_ce: 0.015042
[02:20:54.806] iteration 18123 : loss : 0.033620, loss_ce: 0.009311
[02:20:55.110] iteration 18124 : loss : 0.040564, loss_ce: 0.011798
[02:20:55.413] iteration 18125 : loss : 0.049218, loss_ce: 0.017907
[02:20:55.711] iteration 18126 : loss : 0.042117, loss_ce: 0.012409
[02:20:56.017] iteration 18127 : loss : 0.063923, loss_ce: 0.019322
[02:20:56.320] iteration 18128 : loss : 0.056657, loss_ce: 0.012835
[02:20:56.619] iteration 18129 : loss : 0.166139, loss_ce: 0.017975
[02:20:56.920] iteration 18130 : loss : 0.090598, loss_ce: 0.016250
[02:20:57.227] iteration 18131 : loss : 0.037287, loss_ce: 0.015946
[02:20:57.532] iteration 18132 : loss : 0.041366, loss_ce: 0.021316
[02:20:57.834] iteration 18133 : loss : 0.102448, loss_ce: 0.009183
[02:20:58.136] iteration 18134 : loss : 0.039135, loss_ce: 0.012835
[02:20:58.439] iteration 18135 : loss : 0.034042, loss_ce: 0.010808
[02:20:58.739] iteration 18136 : loss : 0.115933, loss_ce: 0.005078
[02:20:59.039] iteration 18137 : loss : 0.035203, loss_ce: 0.012161
[02:20:59.347] iteration 18138 : loss : 0.041618, loss_ce: 0.016833
[02:20:59.650] iteration 18139 : loss : 0.050264, loss_ce: 0.016754
[02:20:59.954] iteration 18140 : loss : 0.046021, loss_ce: 0.012907
[02:21:00.269] iteration 18141 : loss : 0.159474, loss_ce: 0.011551
[02:21:00.571] iteration 18142 : loss : 0.035321, loss_ce: 0.008710
[02:21:00.874] iteration 18143 : loss : 0.046790, loss_ce: 0.015634
[02:21:01.179] iteration 18144 : loss : 0.044946, loss_ce: 0.018831
[02:21:01.480] iteration 18145 : loss : 0.044353, loss_ce: 0.013814
[02:21:01.774] iteration 18146 : loss : 0.109614, loss_ce: 0.005686
[02:21:02.069] iteration 18147 : loss : 0.107461, loss_ce: 0.013479
[02:21:02.366] iteration 18148 : loss : 0.040383, loss_ce: 0.009496
[02:21:02.667] iteration 18149 : loss : 0.044089, loss_ce: 0.010190
[02:21:02.963] iteration 18150 : loss : 0.040884, loss_ce: 0.017025
[02:21:03.256] iteration 18151 : loss : 0.046243, loss_ce: 0.014823
[02:21:03.556] iteration 18152 : loss : 0.057533, loss_ce: 0.015563
[02:21:03.856] iteration 18153 : loss : 0.052780, loss_ce: 0.011194
[02:21:04.150] iteration 18154 : loss : 0.103305, loss_ce: 0.007625
[02:21:04.448] iteration 18155 : loss : 0.035220, loss_ce: 0.014226
[02:21:04.749] iteration 18156 : loss : 0.048155, loss_ce: 0.022682
[02:21:05.048] iteration 18157 : loss : 0.049215, loss_ce: 0.015272
[02:21:05.342] iteration 18158 : loss : 0.048332, loss_ce: 0.007702
[02:21:05.640] iteration 18159 : loss : 0.107035, loss_ce: 0.018855
[02:21:05.935] iteration 18160 : loss : 0.055285, loss_ce: 0.007496
[02:21:06.249] iteration 18161 : loss : 0.052298, loss_ce: 0.014431
[02:21:06.548] iteration 18162 : loss : 0.104291, loss_ce: 0.009234
[02:21:06.845] iteration 18163 : loss : 0.033847, loss_ce: 0.009421
[02:21:07.146] iteration 18164 : loss : 0.050422, loss_ce: 0.017658
[02:21:07.441] iteration 18165 : loss : 0.059486, loss_ce: 0.018030
[02:21:07.736] iteration 18166 : loss : 0.094311, loss_ce: 0.016289
[02:21:08.037] iteration 18167 : loss : 0.062788, loss_ce: 0.007221
[02:21:08.335] iteration 18168 : loss : 0.106518, loss_ce: 0.008968
[02:21:08.638] iteration 18169 : loss : 0.047328, loss_ce: 0.015668
[02:21:08.938] iteration 18170 : loss : 0.041335, loss_ce: 0.018096
[02:21:09.240] iteration 18171 : loss : 0.054489, loss_ce: 0.010933
[02:21:09.544] iteration 18172 : loss : 0.058929, loss_ce: 0.010050
[02:21:09.838] iteration 18173 : loss : 0.054054, loss_ce: 0.011174
[02:21:10.138] iteration 18174 : loss : 0.100595, loss_ce: 0.009938
[02:21:10.436] iteration 18175 : loss : 0.048831, loss_ce: 0.012289
[02:21:10.736] iteration 18176 : loss : 0.060634, loss_ce: 0.014840
[02:21:11.036] iteration 18177 : loss : 0.041493, loss_ce: 0.011103
[02:21:11.333] iteration 18178 : loss : 0.105899, loss_ce: 0.015953
[02:21:11.637] iteration 18179 : loss : 0.041283, loss_ce: 0.012465
[02:21:11.936] iteration 18180 : loss : 0.105172, loss_ce: 0.007323
[02:21:12.255] iteration 18181 : loss : 0.056022, loss_ce: 0.007065
[02:21:12.549] iteration 18182 : loss : 0.050408, loss_ce: 0.011543
[02:21:12.849] iteration 18183 : loss : 0.109603, loss_ce: 0.013716
[02:21:13.148] iteration 18184 : loss : 0.046567, loss_ce: 0.010703
[02:21:13.449] iteration 18185 : loss : 0.046333, loss_ce: 0.021940
[02:21:13.749] iteration 18186 : loss : 0.040500, loss_ce: 0.016922
[02:21:14.052] iteration 18187 : loss : 0.051958, loss_ce: 0.014118
[02:21:14.359] iteration 18188 : loss : 0.096765, loss_ce: 0.013260
[02:21:14.663] iteration 18189 : loss : 0.034279, loss_ce: 0.006526
[02:21:14.967] iteration 18190 : loss : 0.097891, loss_ce: 0.008398
[02:21:15.271] iteration 18191 : loss : 0.421589, loss_ce: 0.000316
[02:21:15.577] iteration 18192 : loss : 0.102659, loss_ce: 0.009651
[02:21:15.886] iteration 18193 : loss : 0.056535, loss_ce: 0.013308
[02:21:16.191] iteration 18194 : loss : 0.043385, loss_ce: 0.010615
[02:21:16.496] iteration 18195 : loss : 0.051402, loss_ce: 0.011772
[02:21:16.799] iteration 18196 : loss : 0.038750, loss_ce: 0.016502
[02:21:17.107] iteration 18197 : loss : 0.047077, loss_ce: 0.015500
[02:21:17.416] iteration 18198 : loss : 0.041951, loss_ce: 0.018738
[02:21:17.718] iteration 18199 : loss : 0.057105, loss_ce: 0.014356
[02:21:18.016] iteration 18200 : loss : 0.047290, loss_ce: 0.015482
[02:21:18.336] iteration 18201 : loss : 0.050108, loss_ce: 0.010850
[02:21:18.638] iteration 18202 : loss : 0.098516, loss_ce: 0.013500
[02:21:18.944] iteration 18203 : loss : 0.053332, loss_ce: 0.010279
[02:21:19.243] iteration 18204 : loss : 0.059878, loss_ce: 0.020119
[02:21:19.552] iteration 18205 : loss : 0.099609, loss_ce: 0.004158
[02:21:19.859] iteration 18206 : loss : 0.056919, loss_ce: 0.013729
[02:21:20.165] iteration 18207 : loss : 0.045722, loss_ce: 0.010513
[02:21:20.468] iteration 18208 : loss : 0.157992, loss_ce: 0.010376
[02:21:20.551] iteration 18209 : loss : 0.045781, loss_ce: 0.000008
[02:21:39.590] iteration 18210 : loss : 0.046577, loss_ce: 0.007616
[02:21:39.890] iteration 18211 : loss : 0.045313, loss_ce: 0.020876
[02:21:40.198] iteration 18212 : loss : 0.041365, loss_ce: 0.016703
[02:21:40.500] iteration 18213 : loss : 0.069952, loss_ce: 0.021461
[02:21:40.805] iteration 18214 : loss : 0.042179, loss_ce: 0.008493
[02:21:41.098] iteration 18215 : loss : 0.103908, loss_ce: 0.013825
[02:21:41.393] iteration 18216 : loss : 0.057732, loss_ce: 0.011820
[02:21:41.693] iteration 18217 : loss : 0.042661, loss_ce: 0.015157
[02:21:41.990] iteration 18218 : loss : 0.041164, loss_ce: 0.015810
[02:21:42.284] iteration 18219 : loss : 0.154343, loss_ce: 0.007998
[02:21:42.582] iteration 18220 : loss : 0.165968, loss_ce: 0.005380
[02:21:42.903] iteration 18221 : loss : 0.038830, loss_ce: 0.012475
[02:21:43.204] iteration 18222 : loss : 0.050756, loss_ce: 0.011440
[02:21:43.503] iteration 18223 : loss : 0.065930, loss_ce: 0.015004
[02:21:43.799] iteration 18224 : loss : 0.096178, loss_ce: 0.013651
[02:21:44.098] iteration 18225 : loss : 0.029640, loss_ce: 0.008912
[02:21:44.399] iteration 18226 : loss : 0.035853, loss_ce: 0.011717
[02:21:44.702] iteration 18227 : loss : 0.039526, loss_ce: 0.011394
[02:21:44.999] iteration 18228 : loss : 0.050150, loss_ce: 0.012822
[02:21:45.297] iteration 18229 : loss : 0.052920, loss_ce: 0.012869
[02:21:45.595] iteration 18230 : loss : 0.047455, loss_ce: 0.018557
[02:21:45.892] iteration 18231 : loss : 0.103126, loss_ce: 0.008731
[02:21:46.189] iteration 18232 : loss : 0.034426, loss_ce: 0.022974
[02:21:46.491] iteration 18233 : loss : 0.228586, loss_ce: 0.008821
[02:21:46.796] iteration 18234 : loss : 0.112278, loss_ce: 0.011608
[02:21:47.102] iteration 18235 : loss : 0.047735, loss_ce: 0.012925
[02:21:47.402] iteration 18236 : loss : 0.043938, loss_ce: 0.015995
[02:21:47.707] iteration 18237 : loss : 0.037195, loss_ce: 0.011574
[02:21:48.017] iteration 18238 : loss : 0.041177, loss_ce: 0.013559
[02:21:48.316] iteration 18239 : loss : 0.161917, loss_ce: 0.011178
[02:21:48.620] iteration 18240 : loss : 0.047513, loss_ce: 0.024432
[02:21:48.945] iteration 18241 : loss : 0.034465, loss_ce: 0.011173
[02:21:49.244] iteration 18242 : loss : 0.044554, loss_ce: 0.016104
[02:21:49.546] iteration 18243 : loss : 0.057317, loss_ce: 0.017845
[02:21:49.852] iteration 18244 : loss : 0.047061, loss_ce: 0.010756
[02:21:50.156] iteration 18245 : loss : 0.042828, loss_ce: 0.010518
[02:21:50.459] iteration 18246 : loss : 0.046526, loss_ce: 0.010392
[02:21:50.759] iteration 18247 : loss : 0.048620, loss_ce: 0.016885
[02:21:51.061] iteration 18248 : loss : 0.040500, loss_ce: 0.012836
[02:21:51.366] iteration 18249 : loss : 0.043139, loss_ce: 0.014515
[02:21:51.670] iteration 18250 : loss : 0.042393, loss_ce: 0.021275
[02:21:51.973] iteration 18251 : loss : 0.042330, loss_ce: 0.016872
[02:21:52.277] iteration 18252 : loss : 0.092332, loss_ce: 0.012284
[02:21:52.576] iteration 18253 : loss : 0.070202, loss_ce: 0.012489
[02:21:52.882] iteration 18254 : loss : 0.033741, loss_ce: 0.007131
[02:21:53.185] iteration 18255 : loss : 0.043042, loss_ce: 0.015053
[02:21:53.489] iteration 18256 : loss : 0.099059, loss_ce: 0.010160
[02:21:53.793] iteration 18257 : loss : 0.052693, loss_ce: 0.013403
[02:21:54.097] iteration 18258 : loss : 0.041167, loss_ce: 0.007312
[02:21:54.401] iteration 18259 : loss : 0.100040, loss_ce: 0.007771
[02:21:54.702] iteration 18260 : loss : 0.050928, loss_ce: 0.019216
[02:21:55.030] iteration 18261 : loss : 0.056317, loss_ce: 0.007906
[02:21:55.331] iteration 18262 : loss : 0.035814, loss_ce: 0.011745
[02:21:55.635] iteration 18263 : loss : 0.040278, loss_ce: 0.010175
[02:21:55.939] iteration 18264 : loss : 0.049840, loss_ce: 0.009859
[02:21:56.243] iteration 18265 : loss : 0.046802, loss_ce: 0.016180
[02:21:56.549] iteration 18266 : loss : 0.111551, loss_ce: 0.010214
[02:21:56.855] iteration 18267 : loss : 0.044579, loss_ce: 0.020217
[02:21:57.159] iteration 18268 : loss : 0.044276, loss_ce: 0.015365
[02:21:57.465] iteration 18269 : loss : 0.058040, loss_ce: 0.012571
[02:21:57.766] iteration 18270 : loss : 0.049633, loss_ce: 0.018166
[02:21:58.069] iteration 18271 : loss : 0.052805, loss_ce: 0.015902
[02:21:58.373] iteration 18272 : loss : 0.039783, loss_ce: 0.015292
[02:21:58.672] iteration 18273 : loss : 0.047926, loss_ce: 0.017600
[02:21:58.976] iteration 18274 : loss : 0.049080, loss_ce: 0.008852
[02:21:59.278] iteration 18275 : loss : 0.070312, loss_ce: 0.008446
[02:21:59.584] iteration 18276 : loss : 0.052171, loss_ce: 0.012216
[02:21:59.890] iteration 18277 : loss : 0.049184, loss_ce: 0.010289
[02:22:00.193] iteration 18278 : loss : 0.105048, loss_ce: 0.008760
[02:22:00.501] iteration 18279 : loss : 0.053794, loss_ce: 0.017738
[02:22:00.804] iteration 18280 : loss : 0.046237, loss_ce: 0.020410
[02:22:01.130] iteration 18281 : loss : 0.041829, loss_ce: 0.011215
[02:22:01.434] iteration 18282 : loss : 0.039857, loss_ce: 0.013457
[02:22:01.740] iteration 18283 : loss : 0.048479, loss_ce: 0.008116
[02:22:02.045] iteration 18284 : loss : 0.036374, loss_ce: 0.017668
[02:22:02.349] iteration 18285 : loss : 0.044407, loss_ce: 0.021837
[02:22:02.650] iteration 18286 : loss : 0.056641, loss_ce: 0.015461
[02:22:02.949] iteration 18287 : loss : 0.064889, loss_ce: 0.008046
[02:22:03.256] iteration 18288 : loss : 0.103630, loss_ce: 0.004893
[02:22:03.554] iteration 18289 : loss : 0.037825, loss_ce: 0.010677
[02:22:03.864] iteration 18290 : loss : 0.042295, loss_ce: 0.010172
[02:22:04.166] iteration 18291 : loss : 0.046096, loss_ce: 0.017173
[02:22:04.470] iteration 18292 : loss : 0.040135, loss_ce: 0.017791
[02:22:04.776] iteration 18293 : loss : 0.031671, loss_ce: 0.007376
[02:22:05.079] iteration 18294 : loss : 0.036076, loss_ce: 0.010160
[02:22:05.382] iteration 18295 : loss : 0.040696, loss_ce: 0.010392
[02:22:05.684] iteration 18296 : loss : 0.041835, loss_ce: 0.009454
[02:22:05.988] iteration 18297 : loss : 0.049105, loss_ce: 0.015463
[02:22:06.289] iteration 18298 : loss : 0.044786, loss_ce: 0.013040
[02:22:06.588] iteration 18299 : loss : 0.041329, loss_ce: 0.010912
[02:22:06.884] iteration 18300 : loss : 0.046886, loss_ce: 0.007035
[02:22:07.198] iteration 18301 : loss : 0.048600, loss_ce: 0.019733
[02:22:07.493] iteration 18302 : loss : 0.046768, loss_ce: 0.021944
[02:22:07.789] iteration 18303 : loss : 0.048812, loss_ce: 0.010012
[02:22:08.088] iteration 18304 : loss : 0.068629, loss_ce: 0.009714
[02:22:08.387] iteration 18305 : loss : 0.046652, loss_ce: 0.013369
[02:22:08.689] iteration 18306 : loss : 0.069611, loss_ce: 0.013457
[02:22:08.989] iteration 18307 : loss : 0.152546, loss_ce: 0.005633
[02:22:09.288] iteration 18308 : loss : 0.042481, loss_ce: 0.011283
[02:22:09.585] iteration 18309 : loss : 0.047695, loss_ce: 0.022209
[02:22:09.884] iteration 18310 : loss : 0.044102, loss_ce: 0.020719
[02:22:10.182] iteration 18311 : loss : 0.045244, loss_ce: 0.012497
[02:22:10.479] iteration 18312 : loss : 0.046550, loss_ce: 0.015450
[02:22:10.778] iteration 18313 : loss : 0.054880, loss_ce: 0.014986
[02:22:11.078] iteration 18314 : loss : 0.052835, loss_ce: 0.026450
[02:22:11.379] iteration 18315 : loss : 0.050937, loss_ce: 0.016193
[02:22:11.677] iteration 18316 : loss : 0.119483, loss_ce: 0.009756
[02:22:11.980] iteration 18317 : loss : 0.037975, loss_ce: 0.010766
[02:22:12.281] iteration 18318 : loss : 0.053634, loss_ce: 0.009883
[02:22:12.578] iteration 18319 : loss : 0.070629, loss_ce: 0.007561
[02:22:12.874] iteration 18320 : loss : 0.044292, loss_ce: 0.012494
[02:22:13.195] iteration 18321 : loss : 0.038263, loss_ce: 0.013015
[02:22:13.494] iteration 18322 : loss : 0.088718, loss_ce: 0.008620
[02:22:13.796] iteration 18323 : loss : 0.046309, loss_ce: 0.019945
[02:22:14.095] iteration 18324 : loss : 0.047099, loss_ce: 0.012959
[02:22:14.393] iteration 18325 : loss : 0.043360, loss_ce: 0.012858
[02:22:14.689] iteration 18326 : loss : 0.048866, loss_ce: 0.009529
[02:22:14.987] iteration 18327 : loss : 0.049987, loss_ce: 0.019765
[02:22:15.287] iteration 18328 : loss : 0.043846, loss_ce: 0.018243
[02:22:15.584] iteration 18329 : loss : 0.054646, loss_ce: 0.014501
[02:22:15.881] iteration 18330 : loss : 0.099102, loss_ce: 0.009912
[02:22:16.179] iteration 18331 : loss : 0.038574, loss_ce: 0.009780
[02:22:16.485] iteration 18332 : loss : 0.045077, loss_ce: 0.014908
[02:22:16.793] iteration 18333 : loss : 0.040544, loss_ce: 0.010165
[02:22:17.091] iteration 18334 : loss : 0.104164, loss_ce: 0.003117
[02:22:17.391] iteration 18335 : loss : 0.037718, loss_ce: 0.010262
[02:22:17.691] iteration 18336 : loss : 0.047637, loss_ce: 0.016751
[02:22:17.990] iteration 18337 : loss : 0.050058, loss_ce: 0.020482
[02:22:18.289] iteration 18338 : loss : 0.042342, loss_ce: 0.012195
[02:22:18.591] iteration 18339 : loss : 0.042680, loss_ce: 0.011403
[02:22:18.892] iteration 18340 : loss : 0.104136, loss_ce: 0.016141
[02:22:19.239] iteration 18341 : loss : 0.042386, loss_ce: 0.013475
[02:22:19.545] iteration 18342 : loss : 0.045214, loss_ce: 0.012027
[02:22:19.853] iteration 18343 : loss : 0.039107, loss_ce: 0.005340
[02:22:20.162] iteration 18344 : loss : 0.050347, loss_ce: 0.017185
[02:22:20.470] iteration 18345 : loss : 0.061432, loss_ce: 0.010510
[02:22:20.777] iteration 18346 : loss : 0.047743, loss_ce: 0.015879
[02:22:21.088] iteration 18347 : loss : 0.051815, loss_ce: 0.013906
[02:22:21.164] iteration 18348 : loss : 0.289184, loss_ce: 0.003288
[02:22:38.607] iteration 18349 : loss : 0.031708, loss_ce: 0.014098
[02:22:38.908] iteration 18350 : loss : 0.041727, loss_ce: 0.013217
[02:22:39.212] iteration 18351 : loss : 0.047330, loss_ce: 0.018471
[02:22:39.515] iteration 18352 : loss : 0.055280, loss_ce: 0.013417
[02:22:39.813] iteration 18353 : loss : 0.094421, loss_ce: 0.008481
[02:22:40.113] iteration 18354 : loss : 0.035439, loss_ce: 0.016076
[02:22:40.416] iteration 18355 : loss : 0.048538, loss_ce: 0.014159
[02:22:40.715] iteration 18356 : loss : 0.034206, loss_ce: 0.005280
[02:22:41.014] iteration 18357 : loss : 0.047688, loss_ce: 0.011302
[02:22:41.310] iteration 18358 : loss : 0.042705, loss_ce: 0.012759
[02:22:41.607] iteration 18359 : loss : 0.043024, loss_ce: 0.009780
[02:22:41.901] iteration 18360 : loss : 0.038599, loss_ce: 0.006518
[02:22:42.214] iteration 18361 : loss : 0.110960, loss_ce: 0.004578
[02:22:42.510] iteration 18362 : loss : 0.039671, loss_ce: 0.013156
[02:22:42.808] iteration 18363 : loss : 0.053836, loss_ce: 0.012833
[02:22:43.103] iteration 18364 : loss : 0.068914, loss_ce: 0.028105
[02:22:43.400] iteration 18365 : loss : 0.044126, loss_ce: 0.009156
[02:22:43.696] iteration 18366 : loss : 0.048917, loss_ce: 0.025863
[02:22:43.995] iteration 18367 : loss : 0.092832, loss_ce: 0.010420
[02:22:44.292] iteration 18368 : loss : 0.052717, loss_ce: 0.018198
[02:22:44.589] iteration 18369 : loss : 0.042082, loss_ce: 0.013178
[02:22:44.887] iteration 18370 : loss : 0.036708, loss_ce: 0.013641
[02:22:45.182] iteration 18371 : loss : 0.053127, loss_ce: 0.016535
[02:22:45.482] iteration 18372 : loss : 0.106463, loss_ce: 0.005687
[02:22:45.780] iteration 18373 : loss : 0.157019, loss_ce: 0.004751
[02:22:46.083] iteration 18374 : loss : 0.043992, loss_ce: 0.017928
[02:22:46.379] iteration 18375 : loss : 0.042029, loss_ce: 0.011010
[02:22:46.683] iteration 18376 : loss : 0.040325, loss_ce: 0.012653
[02:22:46.982] iteration 18377 : loss : 0.053532, loss_ce: 0.009100
[02:22:47.279] iteration 18378 : loss : 0.045138, loss_ce: 0.016553
[02:22:47.577] iteration 18379 : loss : 0.046836, loss_ce: 0.011397
[02:22:47.878] iteration 18380 : loss : 0.046532, loss_ce: 0.014552
[02:22:48.198] iteration 18381 : loss : 0.041180, loss_ce: 0.007707
[02:22:48.496] iteration 18382 : loss : 0.051893, loss_ce: 0.015511
[02:22:48.795] iteration 18383 : loss : 0.040405, loss_ce: 0.017863
[02:22:49.094] iteration 18384 : loss : 0.049860, loss_ce: 0.009166
[02:22:49.404] iteration 18385 : loss : 0.044616, loss_ce: 0.016063
[02:22:49.704] iteration 18386 : loss : 0.097649, loss_ce: 0.010931
[02:22:50.008] iteration 18387 : loss : 0.040140, loss_ce: 0.010642
[02:22:50.311] iteration 18388 : loss : 0.036396, loss_ce: 0.015941
[02:22:50.613] iteration 18389 : loss : 0.054459, loss_ce: 0.009897
[02:22:50.920] iteration 18390 : loss : 0.052203, loss_ce: 0.015430
[02:22:51.222] iteration 18391 : loss : 0.041783, loss_ce: 0.012086
[02:22:51.526] iteration 18392 : loss : 0.045872, loss_ce: 0.013660
[02:22:51.827] iteration 18393 : loss : 0.049592, loss_ce: 0.013148
[02:22:52.122] iteration 18394 : loss : 0.038586, loss_ce: 0.017987
[02:22:52.426] iteration 18395 : loss : 0.047124, loss_ce: 0.015139
[02:22:52.727] iteration 18396 : loss : 0.051793, loss_ce: 0.015640
[02:22:53.025] iteration 18397 : loss : 0.047068, loss_ce: 0.022436
[02:22:53.321] iteration 18398 : loss : 0.051225, loss_ce: 0.020743
[02:22:53.619] iteration 18399 : loss : 0.113897, loss_ce: 0.010886
[02:22:53.916] iteration 18400 : loss : 0.045669, loss_ce: 0.012133
[02:22:54.230] iteration 18401 : loss : 0.046388, loss_ce: 0.020017
[02:22:54.528] iteration 18402 : loss : 0.063380, loss_ce: 0.011522
[02:22:54.825] iteration 18403 : loss : 0.104323, loss_ce: 0.006509
[02:22:55.124] iteration 18404 : loss : 0.047422, loss_ce: 0.013296
[02:22:55.419] iteration 18405 : loss : 0.046955, loss_ce: 0.017524
[02:22:55.715] iteration 18406 : loss : 0.095932, loss_ce: 0.010943
[02:22:56.012] iteration 18407 : loss : 0.043333, loss_ce: 0.011374
[02:22:56.310] iteration 18408 : loss : 0.046134, loss_ce: 0.022597
[02:22:56.606] iteration 18409 : loss : 0.045007, loss_ce: 0.012806
[02:22:56.906] iteration 18410 : loss : 0.045834, loss_ce: 0.012513
[02:22:57.203] iteration 18411 : loss : 0.038710, loss_ce: 0.009318
[02:22:57.503] iteration 18412 : loss : 0.031902, loss_ce: 0.015136
[02:22:57.800] iteration 18413 : loss : 0.101629, loss_ce: 0.009385
[02:22:58.097] iteration 18414 : loss : 0.168793, loss_ce: 0.009178
[02:22:58.396] iteration 18415 : loss : 0.039301, loss_ce: 0.016350
[02:22:58.695] iteration 18416 : loss : 0.101676, loss_ce: 0.011352
[02:22:58.994] iteration 18417 : loss : 0.036870, loss_ce: 0.011894
[02:22:59.293] iteration 18418 : loss : 0.044512, loss_ce: 0.011702
[02:22:59.597] iteration 18419 : loss : 0.044715, loss_ce: 0.015974
[02:22:59.895] iteration 18420 : loss : 0.033998, loss_ce: 0.012242
[02:23:00.217] iteration 18421 : loss : 0.038914, loss_ce: 0.015216
[02:23:00.513] iteration 18422 : loss : 0.045365, loss_ce: 0.018709
[02:23:00.819] iteration 18423 : loss : 0.050253, loss_ce: 0.012257
[02:23:01.120] iteration 18424 : loss : 0.041373, loss_ce: 0.017055
[02:23:01.423] iteration 18425 : loss : 0.046797, loss_ce: 0.008779
[02:23:01.721] iteration 18426 : loss : 0.055920, loss_ce: 0.016591
[02:23:02.019] iteration 18427 : loss : 0.040155, loss_ce: 0.013265
[02:23:02.317] iteration 18428 : loss : 0.049841, loss_ce: 0.017737
[02:23:02.614] iteration 18429 : loss : 0.048721, loss_ce: 0.014107
[02:23:02.914] iteration 18430 : loss : 0.223501, loss_ce: 0.010194
[02:23:03.210] iteration 18431 : loss : 0.040289, loss_ce: 0.011472
[02:23:03.507] iteration 18432 : loss : 0.050553, loss_ce: 0.018042
[02:23:03.804] iteration 18433 : loss : 0.059418, loss_ce: 0.013769
[02:23:04.101] iteration 18434 : loss : 0.045887, loss_ce: 0.016520
[02:23:04.398] iteration 18435 : loss : 0.108565, loss_ce: 0.013054
[02:23:04.700] iteration 18436 : loss : 0.050245, loss_ce: 0.011146
[02:23:05.000] iteration 18437 : loss : 0.042844, loss_ce: 0.013348
[02:23:05.301] iteration 18438 : loss : 0.106409, loss_ce: 0.006428
[02:23:05.599] iteration 18439 : loss : 0.041785, loss_ce: 0.013403
[02:23:05.903] iteration 18440 : loss : 0.036453, loss_ce: 0.014760
[02:23:06.219] iteration 18441 : loss : 0.045381, loss_ce: 0.012007
[02:23:06.520] iteration 18442 : loss : 0.115053, loss_ce: 0.004715
[02:23:06.827] iteration 18443 : loss : 0.045234, loss_ce: 0.009917
[02:23:07.130] iteration 18444 : loss : 0.058823, loss_ce: 0.010744
[02:23:07.429] iteration 18445 : loss : 0.048282, loss_ce: 0.009521
[02:23:07.737] iteration 18446 : loss : 0.057565, loss_ce: 0.015415
[02:23:08.039] iteration 18447 : loss : 0.051978, loss_ce: 0.007626
[02:23:08.341] iteration 18448 : loss : 0.052226, loss_ce: 0.010887
[02:23:08.643] iteration 18449 : loss : 0.049926, loss_ce: 0.010622
[02:23:08.944] iteration 18450 : loss : 0.048404, loss_ce: 0.017740
[02:23:09.245] iteration 18451 : loss : 0.048385, loss_ce: 0.007359
[02:23:09.554] iteration 18452 : loss : 0.040901, loss_ce: 0.020687
[02:23:09.853] iteration 18453 : loss : 0.034920, loss_ce: 0.012596
[02:23:10.156] iteration 18454 : loss : 0.061148, loss_ce: 0.019708
[02:23:10.459] iteration 18455 : loss : 0.037341, loss_ce: 0.012421
[02:23:10.763] iteration 18456 : loss : 0.098541, loss_ce: 0.009221
[02:23:11.069] iteration 18457 : loss : 0.034036, loss_ce: 0.009843
[02:23:11.375] iteration 18458 : loss : 0.038650, loss_ce: 0.016316
[02:23:11.678] iteration 18459 : loss : 0.039445, loss_ce: 0.012224
[02:23:11.980] iteration 18460 : loss : 0.062598, loss_ce: 0.013845
[02:23:12.299] iteration 18461 : loss : 0.050065, loss_ce: 0.018712
[02:23:12.605] iteration 18462 : loss : 0.039163, loss_ce: 0.010031
[02:23:12.908] iteration 18463 : loss : 0.044198, loss_ce: 0.022380
[02:23:13.210] iteration 18464 : loss : 0.102645, loss_ce: 0.012357
[02:23:13.513] iteration 18465 : loss : 0.039892, loss_ce: 0.013836
[02:23:13.818] iteration 18466 : loss : 0.084720, loss_ce: 0.011339
[02:23:14.120] iteration 18467 : loss : 0.043462, loss_ce: 0.015322
[02:23:14.424] iteration 18468 : loss : 0.040918, loss_ce: 0.011581
[02:23:14.721] iteration 18469 : loss : 0.137749, loss_ce: 0.009831
[02:23:15.028] iteration 18470 : loss : 0.041458, loss_ce: 0.019096
[02:23:15.337] iteration 18471 : loss : 0.109363, loss_ce: 0.012968
[02:23:15.640] iteration 18472 : loss : 0.115542, loss_ce: 0.008370
[02:23:15.951] iteration 18473 : loss : 0.101545, loss_ce: 0.008279
[02:23:16.254] iteration 18474 : loss : 0.057115, loss_ce: 0.014589
[02:23:16.558] iteration 18475 : loss : 0.049067, loss_ce: 0.014055
[02:23:16.862] iteration 18476 : loss : 0.047728, loss_ce: 0.008941
[02:23:17.173] iteration 18477 : loss : 0.034965, loss_ce: 0.011031
[02:23:17.485] iteration 18478 : loss : 0.043740, loss_ce: 0.012668
[02:23:17.793] iteration 18479 : loss : 0.035369, loss_ce: 0.016515
[02:23:18.104] iteration 18480 : loss : 0.042493, loss_ce: 0.012355
[02:23:18.437] iteration 18481 : loss : 0.050565, loss_ce: 0.014295
[02:23:18.747] iteration 18482 : loss : 0.050162, loss_ce: 0.016421
[02:23:19.059] iteration 18483 : loss : 0.049080, loss_ce: 0.009824
[02:23:19.360] iteration 18484 : loss : 0.044203, loss_ce: 0.017648
[02:23:19.669] iteration 18485 : loss : 0.065547, loss_ce: 0.004781
[02:23:19.979] iteration 18486 : loss : 0.044547, loss_ce: 0.008845
[02:23:20.062] iteration 18487 : loss : 0.404901, loss_ce: 0.005331
[02:23:37.770] iteration 18488 : loss : 0.174408, loss_ce: 0.005530
[02:23:38.073] iteration 18489 : loss : 0.049168, loss_ce: 0.016919
[02:23:38.375] iteration 18490 : loss : 0.042563, loss_ce: 0.014987
[02:23:38.682] iteration 18491 : loss : 0.040539, loss_ce: 0.009549
[02:23:38.988] iteration 18492 : loss : 0.050180, loss_ce: 0.008116
[02:23:39.287] iteration 18493 : loss : 0.041836, loss_ce: 0.012259
[02:23:39.583] iteration 18494 : loss : 0.040395, loss_ce: 0.010434
[02:23:39.890] iteration 18495 : loss : 0.050296, loss_ce: 0.013159
[02:23:40.193] iteration 18496 : loss : 0.036023, loss_ce: 0.016849
[02:23:40.493] iteration 18497 : loss : 0.040890, loss_ce: 0.011080
[02:23:40.797] iteration 18498 : loss : 0.041860, loss_ce: 0.012307
[02:23:41.099] iteration 18499 : loss : 0.057453, loss_ce: 0.021391
[02:23:41.396] iteration 18500 : loss : 0.055658, loss_ce: 0.015174
[02:23:41.712] iteration 18501 : loss : 0.037070, loss_ce: 0.009817
[02:23:42.010] iteration 18502 : loss : 0.161330, loss_ce: 0.014841
[02:23:42.306] iteration 18503 : loss : 0.037703, loss_ce: 0.011032
[02:23:42.599] iteration 18504 : loss : 0.041349, loss_ce: 0.013251
[02:23:42.901] iteration 18505 : loss : 0.053882, loss_ce: 0.007606
[02:23:43.198] iteration 18506 : loss : 0.051754, loss_ce: 0.020550
[02:23:43.495] iteration 18507 : loss : 0.046743, loss_ce: 0.015866
[02:23:43.787] iteration 18508 : loss : 0.041163, loss_ce: 0.018877
[02:23:44.086] iteration 18509 : loss : 0.041802, loss_ce: 0.011856
[02:23:44.385] iteration 18510 : loss : 0.050000, loss_ce: 0.018025
[02:23:44.684] iteration 18511 : loss : 0.042200, loss_ce: 0.013009
[02:23:44.981] iteration 18512 : loss : 0.043998, loss_ce: 0.013326
[02:23:45.276] iteration 18513 : loss : 0.048517, loss_ce: 0.008999
[02:23:45.567] iteration 18514 : loss : 0.038375, loss_ce: 0.015022
[02:23:45.867] iteration 18515 : loss : 0.052485, loss_ce: 0.019594
[02:23:46.162] iteration 18516 : loss : 0.033304, loss_ce: 0.010061
[02:23:46.466] iteration 18517 : loss : 0.048937, loss_ce: 0.015115
[02:23:46.767] iteration 18518 : loss : 0.108742, loss_ce: 0.003499
[02:23:47.065] iteration 18519 : loss : 0.046847, loss_ce: 0.017153
[02:23:47.360] iteration 18520 : loss : 0.040322, loss_ce: 0.013564
[02:23:47.679] iteration 18521 : loss : 0.099008, loss_ce: 0.011349
[02:23:47.979] iteration 18522 : loss : 0.043200, loss_ce: 0.013228
[02:23:48.279] iteration 18523 : loss : 0.102783, loss_ce: 0.008162
[02:23:48.577] iteration 18524 : loss : 0.039364, loss_ce: 0.016797
[02:23:48.874] iteration 18525 : loss : 0.048997, loss_ce: 0.013405
[02:23:49.169] iteration 18526 : loss : 0.040516, loss_ce: 0.014413
[02:23:49.468] iteration 18527 : loss : 0.049566, loss_ce: 0.014702
[02:23:49.767] iteration 18528 : loss : 0.036155, loss_ce: 0.009249
[02:23:50.062] iteration 18529 : loss : 0.094743, loss_ce: 0.010062
[02:23:50.363] iteration 18530 : loss : 0.092619, loss_ce: 0.012287
[02:23:50.665] iteration 18531 : loss : 0.044002, loss_ce: 0.015420
[02:23:50.962] iteration 18532 : loss : 0.054463, loss_ce: 0.011521
[02:23:51.258] iteration 18533 : loss : 0.041929, loss_ce: 0.017993
[02:23:51.557] iteration 18534 : loss : 0.046825, loss_ce: 0.013504
[02:23:51.855] iteration 18535 : loss : 0.034865, loss_ce: 0.009110
[02:23:52.150] iteration 18536 : loss : 0.099616, loss_ce: 0.005407
[02:23:52.449] iteration 18537 : loss : 0.029250, loss_ce: 0.002929
[02:23:52.743] iteration 18538 : loss : 0.037258, loss_ce: 0.014881
[02:23:53.043] iteration 18539 : loss : 0.040253, loss_ce: 0.011446
[02:23:53.343] iteration 18540 : loss : 0.046187, loss_ce: 0.014888
[02:23:53.655] iteration 18541 : loss : 0.109557, loss_ce: 0.014379
[02:23:53.957] iteration 18542 : loss : 0.068235, loss_ce: 0.010704
[02:23:54.255] iteration 18543 : loss : 0.046708, loss_ce: 0.007467
[02:23:54.555] iteration 18544 : loss : 0.048195, loss_ce: 0.007095
[02:23:54.862] iteration 18545 : loss : 0.038850, loss_ce: 0.011392
[02:23:55.158] iteration 18546 : loss : 0.046464, loss_ce: 0.020509
[02:23:55.455] iteration 18547 : loss : 0.100165, loss_ce: 0.010288
[02:23:55.754] iteration 18548 : loss : 0.038690, loss_ce: 0.010021
[02:23:56.052] iteration 18549 : loss : 0.037036, loss_ce: 0.007475
[02:23:56.350] iteration 18550 : loss : 0.100560, loss_ce: 0.014084
[02:23:56.653] iteration 18551 : loss : 0.104812, loss_ce: 0.015604
[02:23:56.958] iteration 18552 : loss : 0.043915, loss_ce: 0.010548
[02:23:57.260] iteration 18553 : loss : 0.181932, loss_ce: 0.006493
[02:23:57.562] iteration 18554 : loss : 0.031570, loss_ce: 0.017564
[02:23:57.865] iteration 18555 : loss : 0.114486, loss_ce: 0.010960
[02:23:58.173] iteration 18556 : loss : 0.047956, loss_ce: 0.014942
[02:23:58.474] iteration 18557 : loss : 0.041885, loss_ce: 0.005885
[02:23:58.780] iteration 18558 : loss : 0.047983, loss_ce: 0.018468
[02:23:59.087] iteration 18559 : loss : 0.098515, loss_ce: 0.009120
[02:23:59.388] iteration 18560 : loss : 0.047402, loss_ce: 0.020127
[02:23:59.708] iteration 18561 : loss : 0.044983, loss_ce: 0.018922
[02:24:00.008] iteration 18562 : loss : 0.039611, loss_ce: 0.013864
[02:24:00.309] iteration 18563 : loss : 0.036648, loss_ce: 0.011742
[02:24:00.617] iteration 18564 : loss : 0.044667, loss_ce: 0.015948
[02:24:00.922] iteration 18565 : loss : 0.156935, loss_ce: 0.008664
[02:24:01.227] iteration 18566 : loss : 0.043830, loss_ce: 0.014025
[02:24:01.531] iteration 18567 : loss : 0.064055, loss_ce: 0.018205
[02:24:01.831] iteration 18568 : loss : 0.228536, loss_ce: 0.010124
[02:24:02.133] iteration 18569 : loss : 0.043266, loss_ce: 0.015696
[02:24:02.436] iteration 18570 : loss : 0.039896, loss_ce: 0.016485
[02:24:02.739] iteration 18571 : loss : 0.099256, loss_ce: 0.008480
[02:24:03.042] iteration 18572 : loss : 0.099689, loss_ce: 0.006763
[02:24:03.345] iteration 18573 : loss : 0.052493, loss_ce: 0.020630
[02:24:03.646] iteration 18574 : loss : 0.045588, loss_ce: 0.016423
[02:24:03.952] iteration 18575 : loss : 0.158020, loss_ce: 0.004554
[02:24:04.254] iteration 18576 : loss : 0.043286, loss_ce: 0.019690
[02:24:04.554] iteration 18577 : loss : 0.033657, loss_ce: 0.012222
[02:24:04.855] iteration 18578 : loss : 0.042843, loss_ce: 0.012125
[02:24:05.156] iteration 18579 : loss : 0.101194, loss_ce: 0.016220
[02:24:05.459] iteration 18580 : loss : 0.039851, loss_ce: 0.011641
[02:24:05.777] iteration 18581 : loss : 0.042548, loss_ce: 0.016726
[02:24:06.078] iteration 18582 : loss : 0.100942, loss_ce: 0.014054
[02:24:06.383] iteration 18583 : loss : 0.051970, loss_ce: 0.022079
[02:24:06.683] iteration 18584 : loss : 0.054157, loss_ce: 0.016797
[02:24:06.989] iteration 18585 : loss : 0.108258, loss_ce: 0.006484
[02:24:07.289] iteration 18586 : loss : 0.049470, loss_ce: 0.018841
[02:24:07.593] iteration 18587 : loss : 0.113503, loss_ce: 0.009723
[02:24:07.898] iteration 18588 : loss : 0.043211, loss_ce: 0.015107
[02:24:08.203] iteration 18589 : loss : 0.055468, loss_ce: 0.008658
[02:24:08.502] iteration 18590 : loss : 0.041179, loss_ce: 0.020513
[02:24:08.800] iteration 18591 : loss : 0.054102, loss_ce: 0.014924
[02:24:09.098] iteration 18592 : loss : 0.100288, loss_ce: 0.006283
[02:24:09.403] iteration 18593 : loss : 0.041789, loss_ce: 0.020234
[02:24:09.701] iteration 18594 : loss : 0.038769, loss_ce: 0.011589
[02:24:10.006] iteration 18595 : loss : 0.042238, loss_ce: 0.011219
[02:24:10.303] iteration 18596 : loss : 0.040887, loss_ce: 0.015973
[02:24:10.609] iteration 18597 : loss : 0.043847, loss_ce: 0.014789
[02:24:10.912] iteration 18598 : loss : 0.042525, loss_ce: 0.016127
[02:24:11.210] iteration 18599 : loss : 0.100497, loss_ce: 0.006590
[02:24:11.515] iteration 18600 : loss : 0.044095, loss_ce: 0.007961
[02:24:11.834] iteration 18601 : loss : 0.041421, loss_ce: 0.013197
[02:24:12.135] iteration 18602 : loss : 0.045978, loss_ce: 0.019972
[02:24:12.444] iteration 18603 : loss : 0.052317, loss_ce: 0.010894
[02:24:12.743] iteration 18604 : loss : 0.045117, loss_ce: 0.010898
[02:24:13.048] iteration 18605 : loss : 0.065479, loss_ce: 0.010899
[02:24:13.348] iteration 18606 : loss : 0.052058, loss_ce: 0.015387
[02:24:13.653] iteration 18607 : loss : 0.054882, loss_ce: 0.025229
[02:24:13.956] iteration 18608 : loss : 0.048734, loss_ce: 0.015624
[02:24:14.262] iteration 18609 : loss : 0.124428, loss_ce: 0.006963
[02:24:14.571] iteration 18610 : loss : 0.041866, loss_ce: 0.013571
[02:24:14.881] iteration 18611 : loss : 0.103642, loss_ce: 0.010803
[02:24:15.193] iteration 18612 : loss : 0.108975, loss_ce: 0.011181
[02:24:15.495] iteration 18613 : loss : 0.049513, loss_ce: 0.008816
[02:24:15.798] iteration 18614 : loss : 0.046178, loss_ce: 0.012566
[02:24:16.104] iteration 18615 : loss : 0.040925, loss_ce: 0.009966
[02:24:16.405] iteration 18616 : loss : 0.096726, loss_ce: 0.011740
[02:24:16.704] iteration 18617 : loss : 0.044897, loss_ce: 0.014669
[02:24:17.000] iteration 18618 : loss : 0.042137, loss_ce: 0.009325
[02:24:17.301] iteration 18619 : loss : 0.067689, loss_ce: 0.012217
[02:24:17.602] iteration 18620 : loss : 0.066083, loss_ce: 0.006707
[02:24:17.922] iteration 18621 : loss : 0.101792, loss_ce: 0.009168
[02:24:18.225] iteration 18622 : loss : 0.054565, loss_ce: 0.016245
[02:24:18.526] iteration 18623 : loss : 0.042614, loss_ce: 0.010182
[02:24:18.824] iteration 18624 : loss : 0.042292, loss_ce: 0.009436
[02:24:19.126] iteration 18625 : loss : 0.100974, loss_ce: 0.016296
[02:24:19.207] iteration 18626 : loss : 0.106617, loss_ce: 0.015215
[02:24:37.548] iteration 18627 : loss : 0.050946, loss_ce: 0.015495
[02:24:37.849] iteration 18628 : loss : 0.035848, loss_ce: 0.014553
[02:24:38.152] iteration 18629 : loss : 0.051579, loss_ce: 0.009690
[02:24:38.450] iteration 18630 : loss : 0.214148, loss_ce: 0.004152
[02:24:38.751] iteration 18631 : loss : 0.049301, loss_ce: 0.010325
[02:24:39.052] iteration 18632 : loss : 0.046778, loss_ce: 0.018163
[02:24:39.349] iteration 18633 : loss : 0.101400, loss_ce: 0.010891
[02:24:39.647] iteration 18634 : loss : 0.043939, loss_ce: 0.013939
[02:24:39.941] iteration 18635 : loss : 0.055144, loss_ce: 0.012144
[02:24:40.239] iteration 18636 : loss : 0.100994, loss_ce: 0.013683
[02:24:40.540] iteration 18637 : loss : 0.046952, loss_ce: 0.014909
[02:24:40.836] iteration 18638 : loss : 0.050860, loss_ce: 0.023085
[02:24:41.134] iteration 18639 : loss : 0.046932, loss_ce: 0.011517
[02:24:41.431] iteration 18640 : loss : 0.041407, loss_ce: 0.012298
[02:24:41.747] iteration 18641 : loss : 0.047504, loss_ce: 0.019627
[02:24:42.043] iteration 18642 : loss : 0.039402, loss_ce: 0.005761
[02:24:42.342] iteration 18643 : loss : 0.047600, loss_ce: 0.014509
[02:24:42.638] iteration 18644 : loss : 0.042631, loss_ce: 0.017190
[02:24:42.941] iteration 18645 : loss : 0.059581, loss_ce: 0.010816
[02:24:43.236] iteration 18646 : loss : 0.047464, loss_ce: 0.020859
[02:24:43.534] iteration 18647 : loss : 0.039744, loss_ce: 0.014643
[02:24:43.829] iteration 18648 : loss : 0.044371, loss_ce: 0.010876
[02:24:44.125] iteration 18649 : loss : 0.050008, loss_ce: 0.015649
[02:24:44.425] iteration 18650 : loss : 0.096910, loss_ce: 0.010095
[02:24:44.723] iteration 18651 : loss : 0.039880, loss_ce: 0.010972
[02:24:45.025] iteration 18652 : loss : 0.098738, loss_ce: 0.004453
[02:24:45.326] iteration 18653 : loss : 0.047378, loss_ce: 0.021392
[02:24:45.622] iteration 18654 : loss : 0.066484, loss_ce: 0.022526
[02:24:45.919] iteration 18655 : loss : 0.052304, loss_ce: 0.016142
[02:24:46.217] iteration 18656 : loss : 0.100312, loss_ce: 0.008770
[02:24:46.522] iteration 18657 : loss : 0.048307, loss_ce: 0.012997
[02:24:46.821] iteration 18658 : loss : 0.045927, loss_ce: 0.010082
[02:24:47.120] iteration 18659 : loss : 0.044648, loss_ce: 0.017065
[02:24:47.420] iteration 18660 : loss : 0.031862, loss_ce: 0.007637
[02:24:47.740] iteration 18661 : loss : 0.047014, loss_ce: 0.019279
[02:24:48.037] iteration 18662 : loss : 0.040952, loss_ce: 0.016281
[02:24:48.344] iteration 18663 : loss : 0.048554, loss_ce: 0.018182
[02:24:48.643] iteration 18664 : loss : 0.044135, loss_ce: 0.012884
[02:24:48.941] iteration 18665 : loss : 0.050730, loss_ce: 0.013868
[02:24:49.247] iteration 18666 : loss : 0.049361, loss_ce: 0.019791
[02:24:49.547] iteration 18667 : loss : 0.067140, loss_ce: 0.019160
[02:24:49.846] iteration 18668 : loss : 0.041927, loss_ce: 0.017235
[02:24:50.149] iteration 18669 : loss : 0.043306, loss_ce: 0.019924
[02:24:50.454] iteration 18670 : loss : 0.042282, loss_ce: 0.015206
[02:24:50.756] iteration 18671 : loss : 0.046073, loss_ce: 0.011659
[02:24:51.058] iteration 18672 : loss : 0.039717, loss_ce: 0.016303
[02:24:51.357] iteration 18673 : loss : 0.040673, loss_ce: 0.013069
[02:24:51.659] iteration 18674 : loss : 0.041094, loss_ce: 0.014216
[02:24:51.957] iteration 18675 : loss : 0.031624, loss_ce: 0.008798
[02:24:52.261] iteration 18676 : loss : 0.041365, loss_ce: 0.012473
[02:24:52.561] iteration 18677 : loss : 0.039186, loss_ce: 0.008107
[02:24:52.860] iteration 18678 : loss : 0.056761, loss_ce: 0.011677
[02:24:53.164] iteration 18679 : loss : 0.053801, loss_ce: 0.015519
[02:24:53.468] iteration 18680 : loss : 0.038875, loss_ce: 0.013577
[02:24:53.784] iteration 18681 : loss : 0.063424, loss_ce: 0.023387
[02:24:54.084] iteration 18682 : loss : 0.040072, loss_ce: 0.012301
[02:24:54.388] iteration 18683 : loss : 0.103917, loss_ce: 0.015177
[02:24:54.690] iteration 18684 : loss : 0.099586, loss_ce: 0.004629
[02:24:54.999] iteration 18685 : loss : 0.079801, loss_ce: 0.020682
[02:24:55.299] iteration 18686 : loss : 0.056724, loss_ce: 0.020075
[02:24:55.603] iteration 18687 : loss : 0.043296, loss_ce: 0.012112
[02:24:55.903] iteration 18688 : loss : 0.101480, loss_ce: 0.006787
[02:24:56.200] iteration 18689 : loss : 0.045366, loss_ce: 0.016175
[02:24:56.504] iteration 18690 : loss : 0.054938, loss_ce: 0.015197
[02:24:56.804] iteration 18691 : loss : 0.106718, loss_ce: 0.005958
[02:24:57.105] iteration 18692 : loss : 0.111225, loss_ce: 0.019705
[02:24:57.406] iteration 18693 : loss : 0.044365, loss_ce: 0.010003
[02:24:57.712] iteration 18694 : loss : 0.046946, loss_ce: 0.015810
[02:24:58.017] iteration 18695 : loss : 0.052781, loss_ce: 0.012035
[02:24:58.316] iteration 18696 : loss : 0.040541, loss_ce: 0.013328
[02:24:58.622] iteration 18697 : loss : 0.031307, loss_ce: 0.009270
[02:24:58.920] iteration 18698 : loss : 0.043870, loss_ce: 0.011807
[02:24:59.225] iteration 18699 : loss : 0.040651, loss_ce: 0.007713
[02:24:59.528] iteration 18700 : loss : 0.039350, loss_ce: 0.018420
[02:24:59.844] iteration 18701 : loss : 0.102229, loss_ce: 0.010580
[02:25:00.141] iteration 18702 : loss : 0.047570, loss_ce: 0.011167
[02:25:00.442] iteration 18703 : loss : 0.102054, loss_ce: 0.010102
[02:25:00.742] iteration 18704 : loss : 0.034003, loss_ce: 0.010575
[02:25:01.045] iteration 18705 : loss : 0.049364, loss_ce: 0.015477
[02:25:01.349] iteration 18706 : loss : 0.042299, loss_ce: 0.015117
[02:25:01.651] iteration 18707 : loss : 0.182845, loss_ce: 0.010030
[02:25:01.955] iteration 18708 : loss : 0.050767, loss_ce: 0.010822
[02:25:02.255] iteration 18709 : loss : 0.051584, loss_ce: 0.013265
[02:25:02.556] iteration 18710 : loss : 0.065753, loss_ce: 0.009610
[02:25:02.864] iteration 18711 : loss : 0.038970, loss_ce: 0.012991
[02:25:03.166] iteration 18712 : loss : 0.048790, loss_ce: 0.019297
[02:25:03.466] iteration 18713 : loss : 0.053434, loss_ce: 0.009157
[02:25:03.765] iteration 18714 : loss : 0.107534, loss_ce: 0.009418
[02:25:04.067] iteration 18715 : loss : 0.044628, loss_ce: 0.017737
[02:25:04.370] iteration 18716 : loss : 0.057015, loss_ce: 0.007643
[02:25:04.683] iteration 18717 : loss : 0.056382, loss_ce: 0.014772
[02:25:04.991] iteration 18718 : loss : 0.046115, loss_ce: 0.027171
[02:25:05.294] iteration 18719 : loss : 0.044307, loss_ce: 0.017785
[02:25:05.597] iteration 18720 : loss : 0.048530, loss_ce: 0.014487
[02:25:05.911] iteration 18721 : loss : 0.111504, loss_ce: 0.009265
[02:25:06.211] iteration 18722 : loss : 0.045394, loss_ce: 0.014373
[02:25:06.505] iteration 18723 : loss : 0.050741, loss_ce: 0.012879
[02:25:06.798] iteration 18724 : loss : 0.050286, loss_ce: 0.014622
[02:25:07.096] iteration 18725 : loss : 0.052739, loss_ce: 0.019839
[02:25:07.394] iteration 18726 : loss : 0.044821, loss_ce: 0.013504
[02:25:07.693] iteration 18727 : loss : 0.058256, loss_ce: 0.010274
[02:25:07.988] iteration 18728 : loss : 0.110203, loss_ce: 0.005087
[02:25:08.288] iteration 18729 : loss : 0.044766, loss_ce: 0.011298
[02:25:08.589] iteration 18730 : loss : 0.102422, loss_ce: 0.005443
[02:25:08.884] iteration 18731 : loss : 0.043302, loss_ce: 0.008498
[02:25:09.186] iteration 18732 : loss : 0.040173, loss_ce: 0.006717
[02:25:09.484] iteration 18733 : loss : 0.052227, loss_ce: 0.022156
[02:25:09.784] iteration 18734 : loss : 0.040181, loss_ce: 0.006164
[02:25:10.084] iteration 18735 : loss : 0.049460, loss_ce: 0.019239
[02:25:10.383] iteration 18736 : loss : 0.043005, loss_ce: 0.006760
[02:25:10.676] iteration 18737 : loss : 0.039631, loss_ce: 0.009353
[02:25:10.974] iteration 18738 : loss : 0.110736, loss_ce: 0.011265
[02:25:11.268] iteration 18739 : loss : 0.161303, loss_ce: 0.008435
[02:25:11.562] iteration 18740 : loss : 0.039122, loss_ce: 0.013714
[02:25:11.877] iteration 18741 : loss : 0.046065, loss_ce: 0.012067
[02:25:12.172] iteration 18742 : loss : 0.042784, loss_ce: 0.011508
[02:25:12.469] iteration 18743 : loss : 0.047337, loss_ce: 0.010454
[02:25:12.767] iteration 18744 : loss : 0.040785, loss_ce: 0.016160
[02:25:13.067] iteration 18745 : loss : 0.101654, loss_ce: 0.011947
[02:25:13.363] iteration 18746 : loss : 0.036352, loss_ce: 0.007546
[02:25:13.660] iteration 18747 : loss : 0.166557, loss_ce: 0.006233
[02:25:13.962] iteration 18748 : loss : 0.064975, loss_ce: 0.007938
[02:25:14.265] iteration 18749 : loss : 0.057718, loss_ce: 0.014527
[02:25:14.566] iteration 18750 : loss : 0.045459, loss_ce: 0.007552
[02:25:14.867] iteration 18751 : loss : 0.110252, loss_ce: 0.009227
[02:25:15.168] iteration 18752 : loss : 0.101241, loss_ce: 0.008366
[02:25:15.469] iteration 18753 : loss : 0.045544, loss_ce: 0.017483
[02:25:15.774] iteration 18754 : loss : 0.032920, loss_ce: 0.011760
[02:25:16.078] iteration 18755 : loss : 0.049945, loss_ce: 0.015774
[02:25:16.380] iteration 18756 : loss : 0.040299, loss_ce: 0.019097
[02:25:16.689] iteration 18757 : loss : 0.048323, loss_ce: 0.010333
[02:25:16.988] iteration 18758 : loss : 0.041805, loss_ce: 0.009805
[02:25:17.286] iteration 18759 : loss : 0.160706, loss_ce: 0.012078
[02:25:17.591] iteration 18760 : loss : 0.051431, loss_ce: 0.017317
[02:25:17.911] iteration 18761 : loss : 0.104758, loss_ce: 0.012905
[02:25:18.214] iteration 18762 : loss : 0.038572, loss_ce: 0.021318
[02:25:18.519] iteration 18763 : loss : 0.041568, loss_ce: 0.009391
[02:25:18.822] iteration 18764 : loss : 0.049672, loss_ce: 0.020102
[02:25:18.913] iteration 18765 : loss : 0.328694, loss_ce: 0.001916
[02:25:39.582] iteration 18766 : loss : 0.042468, loss_ce: 0.016824
[02:25:39.883] iteration 18767 : loss : 0.105780, loss_ce: 0.004373
[02:25:40.190] iteration 18768 : loss : 0.057748, loss_ce: 0.024471
[02:25:40.495] iteration 18769 : loss : 0.051686, loss_ce: 0.018372
[02:25:40.793] iteration 18770 : loss : 0.049690, loss_ce: 0.016503
[02:25:41.082] iteration 18771 : loss : 0.088150, loss_ce: 0.013039
[02:25:41.384] iteration 18772 : loss : 0.049766, loss_ce: 0.021799
[02:25:41.681] iteration 18773 : loss : 0.050497, loss_ce: 0.012377
[02:25:41.979] iteration 18774 : loss : 0.046863, loss_ce: 0.013007
[02:25:42.277] iteration 18775 : loss : 0.050518, loss_ce: 0.014846
[02:25:42.571] iteration 18776 : loss : 0.040635, loss_ce: 0.014697
[02:25:42.863] iteration 18777 : loss : 0.038854, loss_ce: 0.011613
[02:25:43.158] iteration 18778 : loss : 0.044184, loss_ce: 0.013009
[02:25:43.454] iteration 18779 : loss : 0.048982, loss_ce: 0.023607
[02:25:43.748] iteration 18780 : loss : 0.045840, loss_ce: 0.011289
[02:25:44.065] iteration 18781 : loss : 0.115608, loss_ce: 0.006596
[02:25:44.360] iteration 18782 : loss : 0.046444, loss_ce: 0.018305
[02:25:44.657] iteration 18783 : loss : 0.040915, loss_ce: 0.012932
[02:25:44.953] iteration 18784 : loss : 0.047730, loss_ce: 0.018853
[02:25:45.249] iteration 18785 : loss : 0.059032, loss_ce: 0.015712
[02:25:45.542] iteration 18786 : loss : 0.111724, loss_ce: 0.006668
[02:25:45.842] iteration 18787 : loss : 0.045004, loss_ce: 0.016374
[02:25:46.137] iteration 18788 : loss : 0.092921, loss_ce: 0.008447
[02:25:46.431] iteration 18789 : loss : 0.043582, loss_ce: 0.014874
[02:25:46.729] iteration 18790 : loss : 0.042251, loss_ce: 0.016535
[02:25:47.027] iteration 18791 : loss : 0.048945, loss_ce: 0.026292
[02:25:47.322] iteration 18792 : loss : 0.040109, loss_ce: 0.015871
[02:25:47.621] iteration 18793 : loss : 0.038845, loss_ce: 0.012187
[02:25:47.917] iteration 18794 : loss : 0.040394, loss_ce: 0.010154
[02:25:48.215] iteration 18795 : loss : 0.044033, loss_ce: 0.022157
[02:25:48.512] iteration 18796 : loss : 0.049379, loss_ce: 0.015409
[02:25:48.809] iteration 18797 : loss : 0.052127, loss_ce: 0.013668
[02:25:49.107] iteration 18798 : loss : 0.149904, loss_ce: 0.006127
[02:25:49.412] iteration 18799 : loss : 0.036269, loss_ce: 0.014383
[02:25:49.711] iteration 18800 : loss : 0.033733, loss_ce: 0.015830
[02:25:50.031] iteration 18801 : loss : 0.065254, loss_ce: 0.014669
[02:25:50.339] iteration 18802 : loss : 0.223963, loss_ce: 0.008994
[02:25:50.640] iteration 18803 : loss : 0.044669, loss_ce: 0.014790
[02:25:50.940] iteration 18804 : loss : 0.053623, loss_ce: 0.014845
[02:25:51.238] iteration 18805 : loss : 0.059502, loss_ce: 0.008835
[02:25:51.534] iteration 18806 : loss : 0.224984, loss_ce: 0.004619
[02:25:51.834] iteration 18807 : loss : 0.042226, loss_ce: 0.014741
[02:25:52.127] iteration 18808 : loss : 0.171112, loss_ce: 0.003732
[02:25:52.425] iteration 18809 : loss : 0.048796, loss_ce: 0.014549
[02:25:52.722] iteration 18810 : loss : 0.101707, loss_ce: 0.018079
[02:25:53.019] iteration 18811 : loss : 0.166268, loss_ce: 0.012022
[02:25:53.315] iteration 18812 : loss : 0.055336, loss_ce: 0.015351
[02:25:53.613] iteration 18813 : loss : 0.056273, loss_ce: 0.010400
[02:25:53.909] iteration 18814 : loss : 0.055942, loss_ce: 0.022958
[02:25:54.206] iteration 18815 : loss : 0.048884, loss_ce: 0.016108
[02:25:54.504] iteration 18816 : loss : 0.110375, loss_ce: 0.010976
[02:25:54.802] iteration 18817 : loss : 0.039067, loss_ce: 0.015649
[02:25:55.099] iteration 18818 : loss : 0.104853, loss_ce: 0.009849
[02:25:55.400] iteration 18819 : loss : 0.039246, loss_ce: 0.016960
[02:25:55.699] iteration 18820 : loss : 0.161810, loss_ce: 0.008477
[02:25:56.012] iteration 18821 : loss : 0.047144, loss_ce: 0.013198
[02:25:56.310] iteration 18822 : loss : 0.110437, loss_ce: 0.013318
[02:25:56.603] iteration 18823 : loss : 0.046407, loss_ce: 0.021926
[02:25:56.897] iteration 18824 : loss : 0.046706, loss_ce: 0.020816
[02:25:57.193] iteration 18825 : loss : 0.106435, loss_ce: 0.011924
[02:25:57.492] iteration 18826 : loss : 0.073805, loss_ce: 0.011272
[02:25:57.785] iteration 18827 : loss : 0.045026, loss_ce: 0.012734
[02:25:58.084] iteration 18828 : loss : 0.041824, loss_ce: 0.015479
[02:25:58.383] iteration 18829 : loss : 0.040695, loss_ce: 0.020350
[02:25:58.680] iteration 18830 : loss : 0.107364, loss_ce: 0.015747
[02:25:58.983] iteration 18831 : loss : 0.048702, loss_ce: 0.012030
[02:25:59.278] iteration 18832 : loss : 0.054293, loss_ce: 0.010011
[02:25:59.576] iteration 18833 : loss : 0.041947, loss_ce: 0.011321
[02:25:59.875] iteration 18834 : loss : 0.039266, loss_ce: 0.011218
[02:26:00.169] iteration 18835 : loss : 0.053321, loss_ce: 0.016363
[02:26:00.466] iteration 18836 : loss : 0.039129, loss_ce: 0.010492
[02:26:00.768] iteration 18837 : loss : 0.037558, loss_ce: 0.008874
[02:26:01.070] iteration 18838 : loss : 0.043683, loss_ce: 0.015888
[02:26:01.369] iteration 18839 : loss : 0.043895, loss_ce: 0.016943
[02:26:01.667] iteration 18840 : loss : 0.047391, loss_ce: 0.019571
[02:26:01.982] iteration 18841 : loss : 0.045307, loss_ce: 0.015385
[02:26:02.282] iteration 18842 : loss : 0.043143, loss_ce: 0.010016
[02:26:02.580] iteration 18843 : loss : 0.041434, loss_ce: 0.013339
[02:26:02.874] iteration 18844 : loss : 0.099008, loss_ce: 0.008185
[02:26:03.170] iteration 18845 : loss : 0.041086, loss_ce: 0.019749
[02:26:03.468] iteration 18846 : loss : 0.105490, loss_ce: 0.011898
[02:26:03.771] iteration 18847 : loss : 0.043579, loss_ce: 0.017903
[02:26:04.068] iteration 18848 : loss : 0.102659, loss_ce: 0.008861
[02:26:04.374] iteration 18849 : loss : 0.041810, loss_ce: 0.015823
[02:26:04.671] iteration 18850 : loss : 0.048909, loss_ce: 0.012546
[02:26:04.976] iteration 18851 : loss : 0.038048, loss_ce: 0.012572
[02:26:05.278] iteration 18852 : loss : 0.038624, loss_ce: 0.017186
[02:26:05.576] iteration 18853 : loss : 0.046289, loss_ce: 0.007388
[02:26:05.876] iteration 18854 : loss : 0.044023, loss_ce: 0.009553
[02:26:06.182] iteration 18855 : loss : 0.048156, loss_ce: 0.011147
[02:26:06.483] iteration 18856 : loss : 0.076339, loss_ce: 0.017130
[02:26:06.784] iteration 18857 : loss : 0.220061, loss_ce: 0.007481
[02:26:07.087] iteration 18858 : loss : 0.047065, loss_ce: 0.011462
[02:26:07.387] iteration 18859 : loss : 0.038416, loss_ce: 0.010608
[02:26:07.692] iteration 18860 : loss : 0.052441, loss_ce: 0.013334
[02:26:08.011] iteration 18861 : loss : 0.098665, loss_ce: 0.012441
[02:26:08.308] iteration 18862 : loss : 0.042836, loss_ce: 0.006989
[02:26:08.610] iteration 18863 : loss : 0.099025, loss_ce: 0.013003
[02:26:08.913] iteration 18864 : loss : 0.051192, loss_ce: 0.022532
[02:26:09.214] iteration 18865 : loss : 0.052860, loss_ce: 0.006436
[02:26:09.515] iteration 18866 : loss : 0.047721, loss_ce: 0.009265
[02:26:09.817] iteration 18867 : loss : 0.037453, loss_ce: 0.014826
[02:26:10.122] iteration 18868 : loss : 0.066991, loss_ce: 0.012461
[02:26:10.421] iteration 18869 : loss : 0.029788, loss_ce: 0.007888
[02:26:10.722] iteration 18870 : loss : 0.041506, loss_ce: 0.009842
[02:26:11.024] iteration 18871 : loss : 0.041986, loss_ce: 0.012697
[02:26:11.328] iteration 18872 : loss : 0.036599, loss_ce: 0.011948
[02:26:11.631] iteration 18873 : loss : 0.042840, loss_ce: 0.009672
[02:26:11.932] iteration 18874 : loss : 0.113152, loss_ce: 0.003335
[02:26:12.236] iteration 18875 : loss : 0.047362, loss_ce: 0.011045
[02:26:12.541] iteration 18876 : loss : 0.110321, loss_ce: 0.017319
[02:26:12.841] iteration 18877 : loss : 0.047083, loss_ce: 0.011662
[02:26:13.146] iteration 18878 : loss : 0.054181, loss_ce: 0.017029
[02:26:13.450] iteration 18879 : loss : 0.038787, loss_ce: 0.007782
[02:26:13.752] iteration 18880 : loss : 0.041737, loss_ce: 0.010771
[02:26:14.069] iteration 18881 : loss : 0.044208, loss_ce: 0.012219
[02:26:14.372] iteration 18882 : loss : 0.047609, loss_ce: 0.007134
[02:26:14.679] iteration 18883 : loss : 0.052693, loss_ce: 0.014334
[02:26:14.982] iteration 18884 : loss : 0.034955, loss_ce: 0.014413
[02:26:15.281] iteration 18885 : loss : 0.093806, loss_ce: 0.007794
[02:26:15.583] iteration 18886 : loss : 0.041157, loss_ce: 0.013102
[02:26:15.883] iteration 18887 : loss : 0.041335, loss_ce: 0.012410
[02:26:16.184] iteration 18888 : loss : 0.042285, loss_ce: 0.013077
[02:26:16.493] iteration 18889 : loss : 0.048361, loss_ce: 0.016871
[02:26:16.796] iteration 18890 : loss : 0.038499, loss_ce: 0.009200
[02:26:17.100] iteration 18891 : loss : 0.167723, loss_ce: 0.016398
[02:26:17.402] iteration 18892 : loss : 0.041555, loss_ce: 0.009382
[02:26:17.712] iteration 18893 : loss : 0.038147, loss_ce: 0.011828
[02:26:18.010] iteration 18894 : loss : 0.038627, loss_ce: 0.013507
[02:26:18.312] iteration 18895 : loss : 0.041399, loss_ce: 0.013927
[02:26:18.613] iteration 18896 : loss : 0.049738, loss_ce: 0.009349
[02:26:18.922] iteration 18897 : loss : 0.049806, loss_ce: 0.017331
[02:26:19.231] iteration 18898 : loss : 0.040950, loss_ce: 0.005186
[02:26:19.536] iteration 18899 : loss : 0.055530, loss_ce: 0.012792
[02:26:19.836] iteration 18900 : loss : 0.060347, loss_ce: 0.014033
[02:26:20.179] iteration 18901 : loss : 0.037238, loss_ce: 0.015965
[02:26:20.483] iteration 18902 : loss : 0.045025, loss_ce: 0.011051
[02:26:20.787] iteration 18903 : loss : 0.056509, loss_ce: 0.012873
[02:26:20.871] iteration 18904 : loss : 0.020535, loss_ce: 0.000007
[02:26:40.324] iteration 18905 : loss : 0.041623, loss_ce: 0.018149
[02:26:40.631] iteration 18906 : loss : 0.046519, loss_ce: 0.017337
[02:26:40.939] iteration 18907 : loss : 0.046094, loss_ce: 0.017046
[02:26:41.238] iteration 18908 : loss : 0.048633, loss_ce: 0.010015
[02:26:41.538] iteration 18909 : loss : 0.041052, loss_ce: 0.013906
[02:26:41.831] iteration 18910 : loss : 0.054422, loss_ce: 0.010442
[02:26:42.134] iteration 18911 : loss : 0.058023, loss_ce: 0.018825
[02:26:42.433] iteration 18912 : loss : 0.094232, loss_ce: 0.007299
[02:26:42.729] iteration 18913 : loss : 0.046001, loss_ce: 0.018100
[02:26:43.028] iteration 18914 : loss : 0.039069, loss_ce: 0.008740
[02:26:43.323] iteration 18915 : loss : 0.045339, loss_ce: 0.014572
[02:26:43.619] iteration 18916 : loss : 0.076631, loss_ce: 0.013467
[02:26:43.918] iteration 18917 : loss : 0.050463, loss_ce: 0.010335
[02:26:44.216] iteration 18918 : loss : 0.106507, loss_ce: 0.007713
[02:26:44.510] iteration 18919 : loss : 0.037899, loss_ce: 0.016853
[02:26:44.808] iteration 18920 : loss : 0.039994, loss_ce: 0.012791
[02:26:45.122] iteration 18921 : loss : 0.111996, loss_ce: 0.006335
[02:26:45.416] iteration 18922 : loss : 0.041389, loss_ce: 0.013797
[02:26:45.712] iteration 18923 : loss : 0.047558, loss_ce: 0.016933
[02:26:46.010] iteration 18924 : loss : 0.049375, loss_ce: 0.012779
[02:26:46.306] iteration 18925 : loss : 0.058721, loss_ce: 0.010884
[02:26:46.605] iteration 18926 : loss : 0.218457, loss_ce: 0.007840
[02:26:46.900] iteration 18927 : loss : 0.060744, loss_ce: 0.017734
[02:26:47.196] iteration 18928 : loss : 0.038994, loss_ce: 0.014381
[02:26:47.492] iteration 18929 : loss : 0.048448, loss_ce: 0.010022
[02:26:47.789] iteration 18930 : loss : 0.100215, loss_ce: 0.009957
[02:26:48.087] iteration 18931 : loss : 0.131774, loss_ce: 0.006318
[02:26:48.391] iteration 18932 : loss : 0.038004, loss_ce: 0.013497
[02:26:48.688] iteration 18933 : loss : 0.150225, loss_ce: 0.007518
[02:26:48.984] iteration 18934 : loss : 0.065411, loss_ce: 0.017173
[02:26:49.281] iteration 18935 : loss : 0.112588, loss_ce: 0.009912
[02:26:49.577] iteration 18936 : loss : 0.166774, loss_ce: 0.002856
[02:26:49.871] iteration 18937 : loss : 0.239399, loss_ce: 0.002147
[02:26:50.169] iteration 18938 : loss : 0.051411, loss_ce: 0.012039
[02:26:50.458] iteration 18939 : loss : 0.058561, loss_ce: 0.015114
[02:26:50.758] iteration 18940 : loss : 0.103212, loss_ce: 0.005531
[02:26:51.074] iteration 18941 : loss : 0.047224, loss_ce: 0.011938
[02:26:51.371] iteration 18942 : loss : 0.053823, loss_ce: 0.010543
[02:26:51.668] iteration 18943 : loss : 0.041762, loss_ce: 0.023365
[02:26:51.965] iteration 18944 : loss : 0.040931, loss_ce: 0.009600
[02:26:52.264] iteration 18945 : loss : 0.100000, loss_ce: 0.006379
[02:26:52.561] iteration 18946 : loss : 0.055586, loss_ce: 0.017430
[02:26:52.859] iteration 18947 : loss : 0.103927, loss_ce: 0.008221
[02:26:53.153] iteration 18948 : loss : 0.043256, loss_ce: 0.007025
[02:26:53.452] iteration 18949 : loss : 0.219559, loss_ce: 0.011067
[02:26:53.748] iteration 18950 : loss : 0.039388, loss_ce: 0.019812
[02:26:54.044] iteration 18951 : loss : 0.042982, loss_ce: 0.011172
[02:26:54.348] iteration 18952 : loss : 0.090305, loss_ce: 0.013054
[02:26:54.654] iteration 18953 : loss : 0.032097, loss_ce: 0.012036
[02:26:54.956] iteration 18954 : loss : 0.039605, loss_ce: 0.013210
[02:26:55.266] iteration 18955 : loss : 0.038440, loss_ce: 0.014464
[02:26:55.569] iteration 18956 : loss : 0.039202, loss_ce: 0.010701
[02:26:55.873] iteration 18957 : loss : 0.072036, loss_ce: 0.021644
[02:26:56.176] iteration 18958 : loss : 0.105570, loss_ce: 0.012349
[02:26:56.484] iteration 18959 : loss : 0.052229, loss_ce: 0.013185
[02:26:56.778] iteration 18960 : loss : 0.046350, loss_ce: 0.022738
[02:26:57.094] iteration 18961 : loss : 0.107129, loss_ce: 0.011916
[02:26:57.389] iteration 18962 : loss : 0.049867, loss_ce: 0.017672
[02:26:57.687] iteration 18963 : loss : 0.047561, loss_ce: 0.007949
[02:26:57.986] iteration 18964 : loss : 0.037420, loss_ce: 0.014271
[02:26:58.287] iteration 18965 : loss : 0.036986, loss_ce: 0.013475
[02:26:58.585] iteration 18966 : loss : 0.039025, loss_ce: 0.019930
[02:26:58.884] iteration 18967 : loss : 0.040172, loss_ce: 0.012282
[02:26:59.182] iteration 18968 : loss : 0.043156, loss_ce: 0.013075
[02:26:59.479] iteration 18969 : loss : 0.101666, loss_ce: 0.013387
[02:26:59.777] iteration 18970 : loss : 0.041118, loss_ce: 0.014641
[02:27:00.077] iteration 18971 : loss : 0.034452, loss_ce: 0.011343
[02:27:00.376] iteration 18972 : loss : 0.049693, loss_ce: 0.027047
[02:27:00.677] iteration 18973 : loss : 0.044989, loss_ce: 0.011305
[02:27:00.976] iteration 18974 : loss : 0.061081, loss_ce: 0.021380
[02:27:01.277] iteration 18975 : loss : 0.053704, loss_ce: 0.016139
[02:27:01.586] iteration 18976 : loss : 0.050828, loss_ce: 0.016361
[02:27:01.889] iteration 18977 : loss : 0.042642, loss_ce: 0.018260
[02:27:02.192] iteration 18978 : loss : 0.109779, loss_ce: 0.010903
[02:27:02.492] iteration 18979 : loss : 0.159115, loss_ce: 0.010237
[02:27:02.800] iteration 18980 : loss : 0.037919, loss_ce: 0.008601
[02:27:03.122] iteration 18981 : loss : 0.100169, loss_ce: 0.002584
[02:27:03.433] iteration 18982 : loss : 0.035186, loss_ce: 0.007798
[02:27:03.735] iteration 18983 : loss : 0.053207, loss_ce: 0.014694
[02:27:04.041] iteration 18984 : loss : 0.043201, loss_ce: 0.011446
[02:27:04.342] iteration 18985 : loss : 0.154961, loss_ce: 0.010842
[02:27:04.650] iteration 18986 : loss : 0.041600, loss_ce: 0.016135
[02:27:04.956] iteration 18987 : loss : 0.047103, loss_ce: 0.021609
[02:27:05.261] iteration 18988 : loss : 0.089752, loss_ce: 0.004626
[02:27:05.568] iteration 18989 : loss : 0.041956, loss_ce: 0.007301
[02:27:05.871] iteration 18990 : loss : 0.111034, loss_ce: 0.010568
[02:27:06.174] iteration 18991 : loss : 0.046091, loss_ce: 0.016543
[02:27:06.484] iteration 18992 : loss : 0.036875, loss_ce: 0.010620
[02:27:06.789] iteration 18993 : loss : 0.036364, loss_ce: 0.015142
[02:27:07.119] iteration 18994 : loss : 0.042265, loss_ce: 0.011517
[02:27:07.416] iteration 18995 : loss : 0.048733, loss_ce: 0.015778
[02:27:07.714] iteration 18996 : loss : 0.059810, loss_ce: 0.014901
[02:27:08.013] iteration 18997 : loss : 0.218520, loss_ce: 0.008470
[02:27:08.315] iteration 18998 : loss : 0.048019, loss_ce: 0.013564
[02:27:08.616] iteration 18999 : loss : 0.045531, loss_ce: 0.016840
[02:27:08.912] iteration 19000 : loss : 0.045570, loss_ce: 0.021963
[02:27:09.237] iteration 19001 : loss : 0.099372, loss_ce: 0.008034
[02:27:09.539] iteration 19002 : loss : 0.040267, loss_ce: 0.013524
[02:27:09.840] iteration 19003 : loss : 0.049936, loss_ce: 0.015240
[02:27:10.147] iteration 19004 : loss : 0.037408, loss_ce: 0.018543
[02:27:10.449] iteration 19005 : loss : 0.034609, loss_ce: 0.015366
[02:27:10.746] iteration 19006 : loss : 0.041513, loss_ce: 0.014530
[02:27:11.047] iteration 19007 : loss : 0.052815, loss_ce: 0.015915
[02:27:11.350] iteration 19008 : loss : 0.048881, loss_ce: 0.020570
[02:27:11.654] iteration 19009 : loss : 0.065777, loss_ce: 0.013722
[02:27:11.955] iteration 19010 : loss : 0.057045, loss_ce: 0.009403
[02:27:12.260] iteration 19011 : loss : 0.039028, loss_ce: 0.014932
[02:27:12.559] iteration 19012 : loss : 0.044644, loss_ce: 0.011155
[02:27:12.861] iteration 19013 : loss : 0.056973, loss_ce: 0.010020
[02:27:13.167] iteration 19014 : loss : 0.055487, loss_ce: 0.013243
[02:27:13.470] iteration 19015 : loss : 0.049225, loss_ce: 0.020578
[02:27:13.772] iteration 19016 : loss : 0.046636, loss_ce: 0.011764
[02:27:14.073] iteration 19017 : loss : 0.103187, loss_ce: 0.012419
[02:27:14.381] iteration 19018 : loss : 0.081765, loss_ce: 0.015646
[02:27:14.683] iteration 19019 : loss : 0.050107, loss_ce: 0.017304
[02:27:14.987] iteration 19020 : loss : 0.037437, loss_ce: 0.009348
[02:27:15.312] iteration 19021 : loss : 0.036486, loss_ce: 0.012887
[02:27:15.614] iteration 19022 : loss : 0.041494, loss_ce: 0.015387
[02:27:15.919] iteration 19023 : loss : 0.043418, loss_ce: 0.009852
[02:27:16.223] iteration 19024 : loss : 0.037850, loss_ce: 0.016915
[02:27:16.526] iteration 19025 : loss : 0.063804, loss_ce: 0.010597
[02:27:16.831] iteration 19026 : loss : 0.099827, loss_ce: 0.011583
[02:27:17.139] iteration 19027 : loss : 0.052896, loss_ce: 0.019063
[02:27:17.449] iteration 19028 : loss : 0.041317, loss_ce: 0.011773
[02:27:17.762] iteration 19029 : loss : 0.039121, loss_ce: 0.008125
[02:27:18.065] iteration 19030 : loss : 0.070466, loss_ce: 0.020366
[02:27:18.373] iteration 19031 : loss : 0.044067, loss_ce: 0.014303
[02:27:18.679] iteration 19032 : loss : 0.092728, loss_ce: 0.005328
[02:27:18.987] iteration 19033 : loss : 0.035314, loss_ce: 0.014462
[02:27:19.297] iteration 19034 : loss : 0.048865, loss_ce: 0.009701
[02:27:19.606] iteration 19035 : loss : 0.040483, loss_ce: 0.010789
[02:27:19.910] iteration 19036 : loss : 0.107696, loss_ce: 0.013163
[02:27:20.223] iteration 19037 : loss : 0.047879, loss_ce: 0.008296
[02:27:20.527] iteration 19038 : loss : 0.039132, loss_ce: 0.013519
[02:27:20.829] iteration 19039 : loss : 0.111953, loss_ce: 0.021038
[02:27:21.145] iteration 19040 : loss : 0.067809, loss_ce: 0.010290
[02:27:21.471] iteration 19041 : loss : 0.045209, loss_ce: 0.017766
[02:27:21.788] iteration 19042 : loss : 0.113527, loss_ce: 0.011616
[02:27:21.873] iteration 19043 : loss : 0.045277, loss_ce: 0.027805
[02:27:40.525] iteration 19044 : loss : 0.040252, loss_ce: 0.014871
[02:27:40.828] iteration 19045 : loss : 0.039325, loss_ce: 0.010628
[02:27:41.131] iteration 19046 : loss : 0.054513, loss_ce: 0.016691
[02:27:41.433] iteration 19047 : loss : 0.046257, loss_ce: 0.020358
[02:27:41.736] iteration 19048 : loss : 0.041584, loss_ce: 0.015613
[02:27:42.038] iteration 19049 : loss : 0.036286, loss_ce: 0.016922
[02:27:42.339] iteration 19050 : loss : 0.045022, loss_ce: 0.014081
[02:27:42.642] iteration 19051 : loss : 0.042797, loss_ce: 0.011361
[02:27:42.938] iteration 19052 : loss : 0.045997, loss_ce: 0.017330
[02:27:43.233] iteration 19053 : loss : 0.051902, loss_ce: 0.010991
[02:27:43.530] iteration 19054 : loss : 0.037508, loss_ce: 0.019728
[02:27:43.823] iteration 19055 : loss : 0.052787, loss_ce: 0.015822
[02:27:44.118] iteration 19056 : loss : 0.041177, loss_ce: 0.012620
[02:27:44.418] iteration 19057 : loss : 0.064827, loss_ce: 0.021410
[02:27:44.721] iteration 19058 : loss : 0.047687, loss_ce: 0.015707
[02:27:45.023] iteration 19059 : loss : 0.046064, loss_ce: 0.013691
[02:27:45.333] iteration 19060 : loss : 0.039601, loss_ce: 0.012347
[02:27:45.647] iteration 19061 : loss : 0.095459, loss_ce: 0.013502
[02:27:45.949] iteration 19062 : loss : 0.154806, loss_ce: 0.008849
[02:27:46.250] iteration 19063 : loss : 0.046711, loss_ce: 0.012850
[02:27:46.547] iteration 19064 : loss : 0.058813, loss_ce: 0.021765
[02:27:46.844] iteration 19065 : loss : 0.049941, loss_ce: 0.016698
[02:27:47.143] iteration 19066 : loss : 0.034253, loss_ce: 0.010022
[02:27:47.444] iteration 19067 : loss : 0.099691, loss_ce: 0.006437
[02:27:47.740] iteration 19068 : loss : 0.034974, loss_ce: 0.010035
[02:27:48.035] iteration 19069 : loss : 0.039090, loss_ce: 0.006844
[02:27:48.333] iteration 19070 : loss : 0.038055, loss_ce: 0.019781
[02:27:48.630] iteration 19071 : loss : 0.041264, loss_ce: 0.005157
[02:27:48.925] iteration 19072 : loss : 0.045292, loss_ce: 0.020755
[02:27:49.223] iteration 19073 : loss : 0.046426, loss_ce: 0.020251
[02:27:49.517] iteration 19074 : loss : 0.098838, loss_ce: 0.011150
[02:27:49.816] iteration 19075 : loss : 0.047799, loss_ce: 0.015318
[02:27:50.118] iteration 19076 : loss : 0.043796, loss_ce: 0.013000
[02:27:50.416] iteration 19077 : loss : 0.039929, loss_ce: 0.012216
[02:27:50.714] iteration 19078 : loss : 0.047457, loss_ce: 0.011536
[02:27:51.010] iteration 19079 : loss : 0.060346, loss_ce: 0.019104
[02:27:51.303] iteration 19080 : loss : 0.106283, loss_ce: 0.006709
[02:27:51.619] iteration 19081 : loss : 0.037959, loss_ce: 0.007259
[02:27:51.916] iteration 19082 : loss : 0.041361, loss_ce: 0.005472
[02:27:52.212] iteration 19083 : loss : 0.045759, loss_ce: 0.011858
[02:27:52.511] iteration 19084 : loss : 0.052674, loss_ce: 0.014873
[02:27:52.804] iteration 19085 : loss : 0.037937, loss_ce: 0.016374
[02:27:53.105] iteration 19086 : loss : 0.045217, loss_ce: 0.018444
[02:27:53.402] iteration 19087 : loss : 0.043593, loss_ce: 0.012955
[02:27:53.698] iteration 19088 : loss : 0.103625, loss_ce: 0.007052
[02:27:53.999] iteration 19089 : loss : 0.046213, loss_ce: 0.017304
[02:27:54.293] iteration 19090 : loss : 0.050429, loss_ce: 0.016248
[02:27:54.589] iteration 19091 : loss : 0.098666, loss_ce: 0.006384
[02:27:54.886] iteration 19092 : loss : 0.032846, loss_ce: 0.011161
[02:27:55.186] iteration 19093 : loss : 0.046411, loss_ce: 0.016156
[02:27:55.480] iteration 19094 : loss : 0.104548, loss_ce: 0.011332
[02:27:55.778] iteration 19095 : loss : 0.047567, loss_ce: 0.013967
[02:27:56.074] iteration 19096 : loss : 0.105452, loss_ce: 0.015409
[02:27:56.370] iteration 19097 : loss : 0.040797, loss_ce: 0.014769
[02:27:56.662] iteration 19098 : loss : 0.037606, loss_ce: 0.011297
[02:27:56.964] iteration 19099 : loss : 0.048494, loss_ce: 0.017098
[02:27:57.266] iteration 19100 : loss : 0.040384, loss_ce: 0.018770
[02:27:57.578] iteration 19101 : loss : 0.040253, loss_ce: 0.008350
[02:27:57.873] iteration 19102 : loss : 0.038152, loss_ce: 0.006583
[02:27:58.170] iteration 19103 : loss : 0.112035, loss_ce: 0.011357
[02:27:58.466] iteration 19104 : loss : 0.099751, loss_ce: 0.007699
[02:27:58.762] iteration 19105 : loss : 0.035619, loss_ce: 0.014388
[02:27:59.060] iteration 19106 : loss : 0.050139, loss_ce: 0.019347
[02:27:59.364] iteration 19107 : loss : 0.045352, loss_ce: 0.018461
[02:27:59.669] iteration 19108 : loss : 0.164362, loss_ce: 0.009049
[02:27:59.976] iteration 19109 : loss : 0.034316, loss_ce: 0.008484
[02:28:00.276] iteration 19110 : loss : 0.083017, loss_ce: 0.012856
[02:28:00.578] iteration 19111 : loss : 0.051447, loss_ce: 0.012144
[02:28:00.882] iteration 19112 : loss : 0.038053, loss_ce: 0.010271
[02:28:01.178] iteration 19113 : loss : 0.056349, loss_ce: 0.016478
[02:28:01.480] iteration 19114 : loss : 0.040324, loss_ce: 0.013087
[02:28:01.775] iteration 19115 : loss : 0.040820, loss_ce: 0.019485
[02:28:02.072] iteration 19116 : loss : 0.045990, loss_ce: 0.004532
[02:28:02.369] iteration 19117 : loss : 0.036293, loss_ce: 0.011308
[02:28:02.664] iteration 19118 : loss : 0.045345, loss_ce: 0.013087
[02:28:02.964] iteration 19119 : loss : 0.059985, loss_ce: 0.031680
[02:28:03.266] iteration 19120 : loss : 0.043265, loss_ce: 0.019950
[02:28:03.582] iteration 19121 : loss : 0.159436, loss_ce: 0.009568
[02:28:03.882] iteration 19122 : loss : 0.058691, loss_ce: 0.019307
[02:28:04.183] iteration 19123 : loss : 0.104953, loss_ce: 0.007311
[02:28:04.478] iteration 19124 : loss : 0.047653, loss_ce: 0.012104
[02:28:04.773] iteration 19125 : loss : 0.042291, loss_ce: 0.015978
[02:28:05.074] iteration 19126 : loss : 0.037870, loss_ce: 0.005529
[02:28:05.371] iteration 19127 : loss : 0.052867, loss_ce: 0.015730
[02:28:05.671] iteration 19128 : loss : 0.042983, loss_ce: 0.011869
[02:28:05.969] iteration 19129 : loss : 0.046971, loss_ce: 0.009607
[02:28:06.266] iteration 19130 : loss : 0.051395, loss_ce: 0.013893
[02:28:06.559] iteration 19131 : loss : 0.039435, loss_ce: 0.015848
[02:28:06.853] iteration 19132 : loss : 0.045921, loss_ce: 0.009533
[02:28:07.157] iteration 19133 : loss : 0.046415, loss_ce: 0.005828
[02:28:07.451] iteration 19134 : loss : 0.046995, loss_ce: 0.014487
[02:28:07.750] iteration 19135 : loss : 0.104732, loss_ce: 0.005651
[02:28:08.047] iteration 19136 : loss : 0.111454, loss_ce: 0.011438
[02:28:08.345] iteration 19137 : loss : 0.125759, loss_ce: 0.015436
[02:28:08.647] iteration 19138 : loss : 0.049522, loss_ce: 0.015933
[02:28:08.941] iteration 19139 : loss : 0.106277, loss_ce: 0.008363
[02:28:09.240] iteration 19140 : loss : 0.050614, loss_ce: 0.010531
[02:28:09.553] iteration 19141 : loss : 0.033891, loss_ce: 0.010756
[02:28:09.853] iteration 19142 : loss : 0.104243, loss_ce: 0.011898
[02:28:10.152] iteration 19143 : loss : 0.122824, loss_ce: 0.011327
[02:28:10.448] iteration 19144 : loss : 0.065305, loss_ce: 0.014778
[02:28:10.744] iteration 19145 : loss : 0.045986, loss_ce: 0.010246
[02:28:11.040] iteration 19146 : loss : 0.046757, loss_ce: 0.012817
[02:28:11.337] iteration 19147 : loss : 0.031089, loss_ce: 0.010304
[02:28:11.638] iteration 19148 : loss : 0.050433, loss_ce: 0.015115
[02:28:11.931] iteration 19149 : loss : 0.041440, loss_ce: 0.011008
[02:28:12.229] iteration 19150 : loss : 0.058611, loss_ce: 0.018345
[02:28:12.524] iteration 19151 : loss : 0.041281, loss_ce: 0.013419
[02:28:12.823] iteration 19152 : loss : 0.062640, loss_ce: 0.007463
[02:28:13.120] iteration 19153 : loss : 0.037269, loss_ce: 0.009432
[02:28:13.418] iteration 19154 : loss : 0.041725, loss_ce: 0.010512
[02:28:13.714] iteration 19155 : loss : 0.121465, loss_ce: 0.009086
[02:28:14.017] iteration 19156 : loss : 0.046166, loss_ce: 0.016493
[02:28:14.314] iteration 19157 : loss : 0.041320, loss_ce: 0.007364
[02:28:14.615] iteration 19158 : loss : 0.101327, loss_ce: 0.013173
[02:28:14.918] iteration 19159 : loss : 0.045713, loss_ce: 0.011946
[02:28:15.222] iteration 19160 : loss : 0.096289, loss_ce: 0.006151
[02:28:15.546] iteration 19161 : loss : 0.045033, loss_ce: 0.017540
[02:28:15.848] iteration 19162 : loss : 0.050857, loss_ce: 0.011227
[02:28:16.156] iteration 19163 : loss : 0.161314, loss_ce: 0.007424
[02:28:16.456] iteration 19164 : loss : 0.035236, loss_ce: 0.006709
[02:28:16.752] iteration 19165 : loss : 0.052848, loss_ce: 0.009714
[02:28:17.052] iteration 19166 : loss : 0.041170, loss_ce: 0.013735
[02:28:17.358] iteration 19167 : loss : 0.038937, loss_ce: 0.011492
[02:28:17.659] iteration 19168 : loss : 0.049284, loss_ce: 0.011061
[02:28:17.957] iteration 19169 : loss : 0.045881, loss_ce: 0.017728
[02:28:18.262] iteration 19170 : loss : 0.052564, loss_ce: 0.017140
[02:28:18.563] iteration 19171 : loss : 0.047323, loss_ce: 0.012620
[02:28:18.864] iteration 19172 : loss : 0.106045, loss_ce: 0.010380
[02:28:19.166] iteration 19173 : loss : 0.042705, loss_ce: 0.011787
[02:28:19.469] iteration 19174 : loss : 0.036920, loss_ce: 0.019221
[02:28:19.771] iteration 19175 : loss : 0.057048, loss_ce: 0.019300
[02:28:20.070] iteration 19176 : loss : 0.121178, loss_ce: 0.009158
[02:28:20.375] iteration 19177 : loss : 0.042056, loss_ce: 0.020850
[02:28:20.672] iteration 19178 : loss : 0.033466, loss_ce: 0.013920
[02:28:20.976] iteration 19179 : loss : 0.035958, loss_ce: 0.010375
[02:28:21.277] iteration 19180 : loss : 0.101252, loss_ce: 0.011536
[02:28:21.601] iteration 19181 : loss : 0.058268, loss_ce: 0.012142
[02:28:21.683] iteration 19182 : loss : 0.332757, loss_ce: 0.001940
[02:28:39.507] iteration 19183 : loss : 0.046586, loss_ce: 0.015500
[02:28:39.815] iteration 19184 : loss : 0.057291, loss_ce: 0.014342
[02:28:40.123] iteration 19185 : loss : 0.107968, loss_ce: 0.013269
[02:28:40.432] iteration 19186 : loss : 0.042940, loss_ce: 0.011038
[02:28:40.733] iteration 19187 : loss : 0.071480, loss_ce: 0.008497
[02:28:41.036] iteration 19188 : loss : 0.042423, loss_ce: 0.016944
[02:28:41.337] iteration 19189 : loss : 0.054593, loss_ce: 0.007926
[02:28:41.638] iteration 19190 : loss : 0.093418, loss_ce: 0.006222
[02:28:41.936] iteration 19191 : loss : 0.050553, loss_ce: 0.010846
[02:28:42.239] iteration 19192 : loss : 0.038206, loss_ce: 0.009992
[02:28:42.542] iteration 19193 : loss : 0.049911, loss_ce: 0.013289
[02:28:42.841] iteration 19194 : loss : 0.046265, loss_ce: 0.014577
[02:28:43.137] iteration 19195 : loss : 0.096063, loss_ce: 0.006069
[02:28:43.438] iteration 19196 : loss : 0.044573, loss_ce: 0.020813
[02:28:43.740] iteration 19197 : loss : 0.051849, loss_ce: 0.021640
[02:28:44.036] iteration 19198 : loss : 0.046550, loss_ce: 0.017123
[02:28:44.337] iteration 19199 : loss : 0.033702, loss_ce: 0.008354
[02:28:44.638] iteration 19200 : loss : 0.031605, loss_ce: 0.005954
[02:28:44.952] iteration 19201 : loss : 0.039778, loss_ce: 0.012079
[02:28:45.255] iteration 19202 : loss : 0.115967, loss_ce: 0.007460
[02:28:45.554] iteration 19203 : loss : 0.047715, loss_ce: 0.017985
[02:28:45.856] iteration 19204 : loss : 0.151563, loss_ce: 0.007097
[02:28:46.162] iteration 19205 : loss : 0.048726, loss_ce: 0.014385
[02:28:46.465] iteration 19206 : loss : 0.040469, loss_ce: 0.014016
[02:28:46.767] iteration 19207 : loss : 0.060754, loss_ce: 0.011152
[02:28:47.069] iteration 19208 : loss : 0.042494, loss_ce: 0.015823
[02:28:47.369] iteration 19209 : loss : 0.039468, loss_ce: 0.018771
[02:28:47.675] iteration 19210 : loss : 0.043929, loss_ce: 0.012399
[02:28:47.979] iteration 19211 : loss : 0.043311, loss_ce: 0.018022
[02:28:48.282] iteration 19212 : loss : 0.046608, loss_ce: 0.024483
[02:28:48.582] iteration 19213 : loss : 0.044823, loss_ce: 0.008452
[02:28:48.884] iteration 19214 : loss : 0.098206, loss_ce: 0.009509
[02:28:49.187] iteration 19215 : loss : 0.108346, loss_ce: 0.010114
[02:28:49.497] iteration 19216 : loss : 0.047512, loss_ce: 0.014477
[02:28:49.800] iteration 19217 : loss : 0.102380, loss_ce: 0.011440
[02:28:50.100] iteration 19218 : loss : 0.047057, loss_ce: 0.015492
[02:28:50.402] iteration 19219 : loss : 0.032472, loss_ce: 0.011741
[02:28:50.705] iteration 19220 : loss : 0.044845, loss_ce: 0.015653
[02:28:51.026] iteration 19221 : loss : 0.039409, loss_ce: 0.014322
[02:28:51.329] iteration 19222 : loss : 0.036627, loss_ce: 0.010377
[02:28:51.626] iteration 19223 : loss : 0.047939, loss_ce: 0.014434
[02:28:51.923] iteration 19224 : loss : 0.038973, loss_ce: 0.017443
[02:28:52.220] iteration 19225 : loss : 0.101047, loss_ce: 0.015356
[02:28:52.522] iteration 19226 : loss : 0.103314, loss_ce: 0.005688
[02:28:52.820] iteration 19227 : loss : 0.044218, loss_ce: 0.019788
[02:28:53.114] iteration 19228 : loss : 0.070119, loss_ce: 0.014699
[02:28:53.407] iteration 19229 : loss : 0.054515, loss_ce: 0.025311
[02:28:53.707] iteration 19230 : loss : 0.039929, loss_ce: 0.015716
[02:28:54.001] iteration 19231 : loss : 0.060497, loss_ce: 0.005810
[02:28:54.300] iteration 19232 : loss : 0.228933, loss_ce: 0.009948
[02:28:54.599] iteration 19233 : loss : 0.043371, loss_ce: 0.018027
[02:28:54.896] iteration 19234 : loss : 0.044993, loss_ce: 0.013611
[02:28:55.194] iteration 19235 : loss : 0.048511, loss_ce: 0.019058
[02:28:55.486] iteration 19236 : loss : 0.046855, loss_ce: 0.012537
[02:28:55.790] iteration 19237 : loss : 0.052642, loss_ce: 0.010865
[02:28:56.085] iteration 19238 : loss : 0.041957, loss_ce: 0.005945
[02:28:56.382] iteration 19239 : loss : 0.155523, loss_ce: 0.016731
[02:28:56.679] iteration 19240 : loss : 0.035285, loss_ce: 0.007555
[02:28:56.994] iteration 19241 : loss : 0.284835, loss_ce: 0.006739
[02:28:57.289] iteration 19242 : loss : 0.045680, loss_ce: 0.006602
[02:28:57.587] iteration 19243 : loss : 0.108891, loss_ce: 0.007059
[02:28:57.879] iteration 19244 : loss : 0.054005, loss_ce: 0.015912
[02:28:58.176] iteration 19245 : loss : 0.035472, loss_ce: 0.016969
[02:28:58.476] iteration 19246 : loss : 0.057313, loss_ce: 0.014461
[02:28:58.772] iteration 19247 : loss : 0.103621, loss_ce: 0.008547
[02:28:59.073] iteration 19248 : loss : 0.051943, loss_ce: 0.009484
[02:28:59.370] iteration 19249 : loss : 0.032384, loss_ce: 0.009070
[02:28:59.669] iteration 19250 : loss : 0.043903, loss_ce: 0.013703
[02:28:59.964] iteration 19251 : loss : 0.039367, loss_ce: 0.014593
[02:29:00.258] iteration 19252 : loss : 0.055677, loss_ce: 0.023083
[02:29:00.561] iteration 19253 : loss : 0.039277, loss_ce: 0.013529
[02:29:00.860] iteration 19254 : loss : 0.055485, loss_ce: 0.017396
[02:29:01.158] iteration 19255 : loss : 0.118609, loss_ce: 0.009163
[02:29:01.460] iteration 19256 : loss : 0.054259, loss_ce: 0.012545
[02:29:01.758] iteration 19257 : loss : 0.110397, loss_ce: 0.014123
[02:29:02.056] iteration 19258 : loss : 0.098366, loss_ce: 0.010323
[02:29:02.356] iteration 19259 : loss : 0.044512, loss_ce: 0.015454
[02:29:02.652] iteration 19260 : loss : 0.048775, loss_ce: 0.015493
[02:29:02.970] iteration 19261 : loss : 0.033295, loss_ce: 0.008338
[02:29:03.272] iteration 19262 : loss : 0.045808, loss_ce: 0.019080
[02:29:03.570] iteration 19263 : loss : 0.044960, loss_ce: 0.014666
[02:29:03.866] iteration 19264 : loss : 0.041798, loss_ce: 0.012293
[02:29:04.163] iteration 19265 : loss : 0.051962, loss_ce: 0.009241
[02:29:04.464] iteration 19266 : loss : 0.039992, loss_ce: 0.012004
[02:29:04.767] iteration 19267 : loss : 0.094673, loss_ce: 0.006812
[02:29:05.070] iteration 19268 : loss : 0.053005, loss_ce: 0.019465
[02:29:05.378] iteration 19269 : loss : 0.108627, loss_ce: 0.012037
[02:29:05.686] iteration 19270 : loss : 0.043173, loss_ce: 0.013869
[02:29:05.993] iteration 19271 : loss : 0.053844, loss_ce: 0.016242
[02:29:06.294] iteration 19272 : loss : 0.046853, loss_ce: 0.019518
[02:29:06.594] iteration 19273 : loss : 0.041421, loss_ce: 0.017459
[02:29:06.892] iteration 19274 : loss : 0.046692, loss_ce: 0.010056
[02:29:07.189] iteration 19275 : loss : 0.048388, loss_ce: 0.013636
[02:29:07.484] iteration 19276 : loss : 0.076884, loss_ce: 0.015419
[02:29:07.779] iteration 19277 : loss : 0.054599, loss_ce: 0.022583
[02:29:08.078] iteration 19278 : loss : 0.102730, loss_ce: 0.013764
[02:29:08.375] iteration 19279 : loss : 0.040614, loss_ce: 0.011327
[02:29:08.672] iteration 19280 : loss : 0.039506, loss_ce: 0.009270
[02:29:08.991] iteration 19281 : loss : 0.042543, loss_ce: 0.014913
[02:29:09.281] iteration 19282 : loss : 0.050034, loss_ce: 0.011604
[02:29:09.579] iteration 19283 : loss : 0.102194, loss_ce: 0.011392
[02:29:09.877] iteration 19284 : loss : 0.057781, loss_ce: 0.014615
[02:29:10.178] iteration 19285 : loss : 0.121910, loss_ce: 0.007825
[02:29:10.482] iteration 19286 : loss : 0.038809, loss_ce: 0.013800
[02:29:10.776] iteration 19287 : loss : 0.059845, loss_ce: 0.019221
[02:29:11.073] iteration 19288 : loss : 0.046278, loss_ce: 0.009702
[02:29:11.371] iteration 19289 : loss : 0.043179, loss_ce: 0.021045
[02:29:11.666] iteration 19290 : loss : 0.026927, loss_ce: 0.006667
[02:29:11.963] iteration 19291 : loss : 0.040219, loss_ce: 0.016877
[02:29:12.266] iteration 19292 : loss : 0.039007, loss_ce: 0.016269
[02:29:12.566] iteration 19293 : loss : 0.058235, loss_ce: 0.019392
[02:29:12.864] iteration 19294 : loss : 0.153840, loss_ce: 0.006502
[02:29:13.159] iteration 19295 : loss : 0.032467, loss_ce: 0.009696
[02:29:13.460] iteration 19296 : loss : 0.048549, loss_ce: 0.012154
[02:29:13.757] iteration 19297 : loss : 0.099090, loss_ce: 0.008429
[02:29:14.054] iteration 19298 : loss : 0.047030, loss_ce: 0.013112
[02:29:14.350] iteration 19299 : loss : 0.164746, loss_ce: 0.011918
[02:29:14.647] iteration 19300 : loss : 0.049418, loss_ce: 0.009776
[02:29:14.961] iteration 19301 : loss : 0.056853, loss_ce: 0.011544
[02:29:15.258] iteration 19302 : loss : 0.040012, loss_ce: 0.008578
[02:29:15.557] iteration 19303 : loss : 0.039483, loss_ce: 0.017945
[02:29:15.856] iteration 19304 : loss : 0.047938, loss_ce: 0.012153
[02:29:16.161] iteration 19305 : loss : 0.049724, loss_ce: 0.013573
[02:29:16.465] iteration 19306 : loss : 0.047281, loss_ce: 0.011119
[02:29:16.767] iteration 19307 : loss : 0.050472, loss_ce: 0.007131
[02:29:17.075] iteration 19308 : loss : 0.048037, loss_ce: 0.014436
[02:29:17.376] iteration 19309 : loss : 0.113083, loss_ce: 0.010668
[02:29:17.677] iteration 19310 : loss : 0.094907, loss_ce: 0.005823
[02:29:17.978] iteration 19311 : loss : 0.107939, loss_ce: 0.010623
[02:29:18.286] iteration 19312 : loss : 0.038805, loss_ce: 0.009083
[02:29:18.589] iteration 19313 : loss : 0.095637, loss_ce: 0.007690
[02:29:18.891] iteration 19314 : loss : 0.099559, loss_ce: 0.013040
[02:29:19.199] iteration 19315 : loss : 0.040274, loss_ce: 0.018252
[02:29:19.506] iteration 19316 : loss : 0.101566, loss_ce: 0.015876
[02:29:19.809] iteration 19317 : loss : 0.043832, loss_ce: 0.013784
[02:29:20.118] iteration 19318 : loss : 0.041342, loss_ce: 0.013828
[02:29:20.425] iteration 19319 : loss : 0.048763, loss_ce: 0.016081
[02:29:20.734] iteration 19320 : loss : 0.032138, loss_ce: 0.011088
[02:29:20.830] iteration 19321 : loss : 0.102018, loss_ce: 0.020353
[02:29:39.479] iteration 19322 : loss : 0.042100, loss_ce: 0.013640
[02:29:39.783] iteration 19323 : loss : 0.112151, loss_ce: 0.012550
[02:29:40.091] iteration 19324 : loss : 0.101566, loss_ce: 0.011372
[02:29:40.398] iteration 19325 : loss : 0.104778, loss_ce: 0.013374
[02:29:40.699] iteration 19326 : loss : 0.047588, loss_ce: 0.011115
[02:29:40.995] iteration 19327 : loss : 0.100158, loss_ce: 0.012553
[02:29:41.292] iteration 19328 : loss : 0.044552, loss_ce: 0.007379
[02:29:41.593] iteration 19329 : loss : 0.033934, loss_ce: 0.014967
[02:29:41.892] iteration 19330 : loss : 0.058342, loss_ce: 0.015180
[02:29:42.191] iteration 19331 : loss : 0.282408, loss_ce: 0.004073
[02:29:42.489] iteration 19332 : loss : 0.041889, loss_ce: 0.017137
[02:29:42.783] iteration 19333 : loss : 0.044592, loss_ce: 0.021663
[02:29:43.076] iteration 19334 : loss : 0.038337, loss_ce: 0.006956
[02:29:43.380] iteration 19335 : loss : 0.051729, loss_ce: 0.014809
[02:29:43.675] iteration 19336 : loss : 0.098515, loss_ce: 0.015837
[02:29:43.973] iteration 19337 : loss : 0.048195, loss_ce: 0.009878
[02:29:44.277] iteration 19338 : loss : 0.111826, loss_ce: 0.008791
[02:29:44.573] iteration 19339 : loss : 0.041043, loss_ce: 0.014698
[02:29:44.868] iteration 19340 : loss : 0.030857, loss_ce: 0.008553
[02:29:45.195] iteration 19341 : loss : 0.055526, loss_ce: 0.011956
[02:29:45.488] iteration 19342 : loss : 0.051135, loss_ce: 0.015593
[02:29:45.788] iteration 19343 : loss : 0.033306, loss_ce: 0.013952
[02:29:46.085] iteration 19344 : loss : 0.104128, loss_ce: 0.007591
[02:29:46.383] iteration 19345 : loss : 0.065345, loss_ce: 0.016517
[02:29:46.682] iteration 19346 : loss : 0.037372, loss_ce: 0.015981
[02:29:46.983] iteration 19347 : loss : 0.056243, loss_ce: 0.022347
[02:29:47.280] iteration 19348 : loss : 0.100869, loss_ce: 0.009720
[02:29:47.578] iteration 19349 : loss : 0.038768, loss_ce: 0.008909
[02:29:47.879] iteration 19350 : loss : 0.228885, loss_ce: 0.001875
[02:29:48.179] iteration 19351 : loss : 0.046703, loss_ce: 0.011970
[02:29:48.475] iteration 19352 : loss : 0.048929, loss_ce: 0.014838
[02:29:48.771] iteration 19353 : loss : 0.053683, loss_ce: 0.012202
[02:29:49.065] iteration 19354 : loss : 0.050288, loss_ce: 0.020981
[02:29:49.361] iteration 19355 : loss : 0.174677, loss_ce: 0.008907
[02:29:49.663] iteration 19356 : loss : 0.038220, loss_ce: 0.017563
[02:29:49.961] iteration 19357 : loss : 0.037472, loss_ce: 0.014345
[02:29:50.258] iteration 19358 : loss : 0.050996, loss_ce: 0.014720
[02:29:50.559] iteration 19359 : loss : 0.048463, loss_ce: 0.013448
[02:29:50.857] iteration 19360 : loss : 0.040522, loss_ce: 0.013953
[02:29:51.169] iteration 19361 : loss : 0.043249, loss_ce: 0.009096
[02:29:51.470] iteration 19362 : loss : 0.046089, loss_ce: 0.015956
[02:29:51.771] iteration 19363 : loss : 0.037956, loss_ce: 0.016785
[02:29:52.068] iteration 19364 : loss : 0.048428, loss_ce: 0.008743
[02:29:52.375] iteration 19365 : loss : 0.041070, loss_ce: 0.005832
[02:29:52.675] iteration 19366 : loss : 0.035854, loss_ce: 0.008844
[02:29:52.979] iteration 19367 : loss : 0.046953, loss_ce: 0.016468
[02:29:53.282] iteration 19368 : loss : 0.039056, loss_ce: 0.009332
[02:29:53.587] iteration 19369 : loss : 0.044403, loss_ce: 0.007174
[02:29:53.889] iteration 19370 : loss : 0.064054, loss_ce: 0.010578
[02:29:54.190] iteration 19371 : loss : 0.051848, loss_ce: 0.013725
[02:29:54.494] iteration 19372 : loss : 0.099991, loss_ce: 0.010165
[02:29:54.790] iteration 19373 : loss : 0.045759, loss_ce: 0.023458
[02:29:55.090] iteration 19374 : loss : 0.050569, loss_ce: 0.009552
[02:29:55.389] iteration 19375 : loss : 0.034940, loss_ce: 0.010863
[02:29:55.692] iteration 19376 : loss : 0.058249, loss_ce: 0.041585
[02:29:55.995] iteration 19377 : loss : 0.106134, loss_ce: 0.019247
[02:29:56.298] iteration 19378 : loss : 0.039994, loss_ce: 0.015683
[02:29:56.599] iteration 19379 : loss : 0.040802, loss_ce: 0.010657
[02:29:56.905] iteration 19380 : loss : 0.046317, loss_ce: 0.009146
[02:29:57.224] iteration 19381 : loss : 0.044785, loss_ce: 0.011659
[02:29:57.529] iteration 19382 : loss : 0.036649, loss_ce: 0.012072
[02:29:57.826] iteration 19383 : loss : 0.049305, loss_ce: 0.020714
[02:29:58.127] iteration 19384 : loss : 0.053543, loss_ce: 0.010828
[02:29:58.429] iteration 19385 : loss : 0.092062, loss_ce: 0.003567
[02:29:58.730] iteration 19386 : loss : 0.103536, loss_ce: 0.013424
[02:29:59.030] iteration 19387 : loss : 0.097704, loss_ce: 0.005810
[02:29:59.331] iteration 19388 : loss : 0.053111, loss_ce: 0.013356
[02:29:59.636] iteration 19389 : loss : 0.040868, loss_ce: 0.015670
[02:29:59.939] iteration 19390 : loss : 0.044637, loss_ce: 0.011947
[02:30:00.242] iteration 19391 : loss : 0.038187, loss_ce: 0.012474
[02:30:00.542] iteration 19392 : loss : 0.045120, loss_ce: 0.012731
[02:30:00.844] iteration 19393 : loss : 0.034817, loss_ce: 0.008497
[02:30:01.152] iteration 19394 : loss : 0.036897, loss_ce: 0.012445
[02:30:01.453] iteration 19395 : loss : 0.093591, loss_ce: 0.004786
[02:30:01.749] iteration 19396 : loss : 0.049392, loss_ce: 0.017175
[02:30:02.052] iteration 19397 : loss : 0.039709, loss_ce: 0.008950
[02:30:02.349] iteration 19398 : loss : 0.047834, loss_ce: 0.021189
[02:30:02.649] iteration 19399 : loss : 0.042772, loss_ce: 0.015584
[02:30:02.950] iteration 19400 : loss : 0.048124, loss_ce: 0.015874
[02:30:03.277] iteration 19401 : loss : 0.066325, loss_ce: 0.010291
[02:30:03.578] iteration 19402 : loss : 0.040203, loss_ce: 0.007237
[02:30:03.878] iteration 19403 : loss : 0.039416, loss_ce: 0.010270
[02:30:04.180] iteration 19404 : loss : 0.050175, loss_ce: 0.010214
[02:30:04.483] iteration 19405 : loss : 0.039171, loss_ce: 0.007778
[02:30:04.788] iteration 19406 : loss : 0.039562, loss_ce: 0.011100
[02:30:05.091] iteration 19407 : loss : 0.159586, loss_ce: 0.009043
[02:30:05.394] iteration 19408 : loss : 0.037774, loss_ce: 0.012271
[02:30:05.692] iteration 19409 : loss : 0.047361, loss_ce: 0.018106
[02:30:05.999] iteration 19410 : loss : 0.043424, loss_ce: 0.014866
[02:30:06.298] iteration 19411 : loss : 0.045099, loss_ce: 0.015622
[02:30:06.603] iteration 19412 : loss : 0.054648, loss_ce: 0.014943
[02:30:06.905] iteration 19413 : loss : 0.040759, loss_ce: 0.016351
[02:30:07.201] iteration 19414 : loss : 0.103735, loss_ce: 0.014656
[02:30:07.505] iteration 19415 : loss : 0.051072, loss_ce: 0.011547
[02:30:07.804] iteration 19416 : loss : 0.058829, loss_ce: 0.009470
[02:30:08.109] iteration 19417 : loss : 0.117571, loss_ce: 0.010636
[02:30:08.408] iteration 19418 : loss : 0.039838, loss_ce: 0.014438
[02:30:08.712] iteration 19419 : loss : 0.046690, loss_ce: 0.020241
[02:30:09.014] iteration 19420 : loss : 0.046769, loss_ce: 0.023800
[02:30:09.338] iteration 19421 : loss : 0.047186, loss_ce: 0.022252
[02:30:09.643] iteration 19422 : loss : 0.050599, loss_ce: 0.013983
[02:30:09.949] iteration 19423 : loss : 0.047204, loss_ce: 0.017114
[02:30:10.251] iteration 19424 : loss : 0.049412, loss_ce: 0.010377
[02:30:10.556] iteration 19425 : loss : 0.049728, loss_ce: 0.010306
[02:30:10.860] iteration 19426 : loss : 0.078466, loss_ce: 0.020453
[02:30:11.158] iteration 19427 : loss : 0.109004, loss_ce: 0.013324
[02:30:11.460] iteration 19428 : loss : 0.041832, loss_ce: 0.014125
[02:30:11.764] iteration 19429 : loss : 0.036974, loss_ce: 0.008506
[02:30:12.063] iteration 19430 : loss : 0.047169, loss_ce: 0.014338
[02:30:12.363] iteration 19431 : loss : 0.035706, loss_ce: 0.014183
[02:30:12.662] iteration 19432 : loss : 0.161542, loss_ce: 0.006338
[02:30:12.960] iteration 19433 : loss : 0.094584, loss_ce: 0.008364
[02:30:13.257] iteration 19434 : loss : 0.045946, loss_ce: 0.014260
[02:30:13.557] iteration 19435 : loss : 0.044005, loss_ce: 0.019301
[02:30:13.854] iteration 19436 : loss : 0.046354, loss_ce: 0.012011
[02:30:14.150] iteration 19437 : loss : 0.037271, loss_ce: 0.011210
[02:30:14.448] iteration 19438 : loss : 0.110492, loss_ce: 0.017569
[02:30:14.752] iteration 19439 : loss : 0.044232, loss_ce: 0.017353
[02:30:15.050] iteration 19440 : loss : 0.035590, loss_ce: 0.009945
[02:30:15.365] iteration 19441 : loss : 0.055479, loss_ce: 0.018376
[02:30:15.661] iteration 19442 : loss : 0.097125, loss_ce: 0.006663
[02:30:15.962] iteration 19443 : loss : 0.046573, loss_ce: 0.020317
[02:30:16.264] iteration 19444 : loss : 0.035623, loss_ce: 0.009709
[02:30:16.564] iteration 19445 : loss : 0.039845, loss_ce: 0.017754
[02:30:16.866] iteration 19446 : loss : 0.102301, loss_ce: 0.009737
[02:30:17.166] iteration 19447 : loss : 0.108316, loss_ce: 0.006915
[02:30:17.463] iteration 19448 : loss : 0.048696, loss_ce: 0.014276
[02:30:17.766] iteration 19449 : loss : 0.093723, loss_ce: 0.006192
[02:30:18.063] iteration 19450 : loss : 0.044644, loss_ce: 0.017912
[02:30:18.363] iteration 19451 : loss : 0.047955, loss_ce: 0.011908
[02:30:18.662] iteration 19452 : loss : 0.036092, loss_ce: 0.009452
[02:30:18.961] iteration 19453 : loss : 0.038665, loss_ce: 0.011102
[02:30:19.263] iteration 19454 : loss : 0.049255, loss_ce: 0.016985
[02:30:19.563] iteration 19455 : loss : 0.223510, loss_ce: 0.010069
[02:30:19.865] iteration 19456 : loss : 0.045621, loss_ce: 0.018818
[02:30:20.163] iteration 19457 : loss : 0.050688, loss_ce: 0.018579
[02:30:20.468] iteration 19458 : loss : 0.050676, loss_ce: 0.015505
[02:30:20.767] iteration 19459 : loss : 0.043703, loss_ce: 0.014951
[02:30:20.846] iteration 19460 : loss : 0.226350, loss_ce: 0.019799
[02:30:39.699] iteration 19461 : loss : 0.050395, loss_ce: 0.017222
[02:30:40.006] iteration 19462 : loss : 0.041042, loss_ce: 0.011656
[02:30:40.311] iteration 19463 : loss : 0.111903, loss_ce: 0.014368
[02:30:40.620] iteration 19464 : loss : 0.046540, loss_ce: 0.014140
[02:30:40.928] iteration 19465 : loss : 0.057250, loss_ce: 0.030097
[02:30:41.228] iteration 19466 : loss : 0.045985, loss_ce: 0.012350
[02:30:41.524] iteration 19467 : loss : 0.038564, loss_ce: 0.008193
[02:30:41.822] iteration 19468 : loss : 0.100122, loss_ce: 0.008320
[02:30:42.118] iteration 19469 : loss : 0.029942, loss_ce: 0.007810
[02:30:42.415] iteration 19470 : loss : 0.068330, loss_ce: 0.008718
[02:30:42.710] iteration 19471 : loss : 0.042407, loss_ce: 0.014127
[02:30:43.003] iteration 19472 : loss : 0.180976, loss_ce: 0.007354
[02:30:43.299] iteration 19473 : loss : 0.044789, loss_ce: 0.006042
[02:30:43.596] iteration 19474 : loss : 0.036604, loss_ce: 0.009921
[02:30:43.898] iteration 19475 : loss : 0.043537, loss_ce: 0.016263
[02:30:44.190] iteration 19476 : loss : 0.044460, loss_ce: 0.014093
[02:30:44.487] iteration 19477 : loss : 0.038006, loss_ce: 0.008772
[02:30:44.783] iteration 19478 : loss : 0.107874, loss_ce: 0.004477
[02:30:45.080] iteration 19479 : loss : 0.097957, loss_ce: 0.015873
[02:30:45.378] iteration 19480 : loss : 0.041021, loss_ce: 0.018537
[02:30:45.694] iteration 19481 : loss : 0.105172, loss_ce: 0.010823
[02:30:45.994] iteration 19482 : loss : 0.041847, loss_ce: 0.020743
[02:30:46.291] iteration 19483 : loss : 0.102098, loss_ce: 0.009054
[02:30:46.588] iteration 19484 : loss : 0.037080, loss_ce: 0.012670
[02:30:46.884] iteration 19485 : loss : 0.046157, loss_ce: 0.017081
[02:30:47.183] iteration 19486 : loss : 0.049677, loss_ce: 0.010248
[02:30:47.477] iteration 19487 : loss : 0.039144, loss_ce: 0.010167
[02:30:47.772] iteration 19488 : loss : 0.054726, loss_ce: 0.014565
[02:30:48.068] iteration 19489 : loss : 0.051116, loss_ce: 0.012326
[02:30:48.366] iteration 19490 : loss : 0.105186, loss_ce: 0.005888
[02:30:48.663] iteration 19491 : loss : 0.099244, loss_ce: 0.006683
[02:30:48.959] iteration 19492 : loss : 0.102101, loss_ce: 0.009261
[02:30:49.254] iteration 19493 : loss : 0.040323, loss_ce: 0.010055
[02:30:49.553] iteration 19494 : loss : 0.039552, loss_ce: 0.019796
[02:30:49.846] iteration 19495 : loss : 0.045218, loss_ce: 0.016401
[02:30:50.142] iteration 19496 : loss : 0.074761, loss_ce: 0.011751
[02:30:50.438] iteration 19497 : loss : 0.042279, loss_ce: 0.007536
[02:30:50.737] iteration 19498 : loss : 0.045693, loss_ce: 0.020187
[02:30:51.036] iteration 19499 : loss : 0.045766, loss_ce: 0.013252
[02:30:51.329] iteration 19500 : loss : 0.103106, loss_ce: 0.012829
[02:30:51.649] iteration 19501 : loss : 0.104963, loss_ce: 0.010319
[02:30:51.943] iteration 19502 : loss : 0.039010, loss_ce: 0.010259
[02:30:52.236] iteration 19503 : loss : 0.044327, loss_ce: 0.007325
[02:30:52.535] iteration 19504 : loss : 0.041206, loss_ce: 0.009929
[02:30:52.831] iteration 19505 : loss : 0.042210, loss_ce: 0.018627
[02:30:53.129] iteration 19506 : loss : 0.037742, loss_ce: 0.014677
[02:30:53.427] iteration 19507 : loss : 0.099756, loss_ce: 0.008647
[02:30:53.720] iteration 19508 : loss : 0.064723, loss_ce: 0.011364
[02:30:54.014] iteration 19509 : loss : 0.035836, loss_ce: 0.004965
[02:30:54.310] iteration 19510 : loss : 0.210311, loss_ce: 0.002703
[02:30:54.606] iteration 19511 : loss : 0.039212, loss_ce: 0.014964
[02:30:54.905] iteration 19512 : loss : 0.162585, loss_ce: 0.007991
[02:30:55.204] iteration 19513 : loss : 0.108429, loss_ce: 0.008004
[02:30:55.501] iteration 19514 : loss : 0.053486, loss_ce: 0.013655
[02:30:55.799] iteration 19515 : loss : 0.050768, loss_ce: 0.014713
[02:30:56.099] iteration 19516 : loss : 0.060753, loss_ce: 0.027382
[02:30:56.399] iteration 19517 : loss : 0.032234, loss_ce: 0.009695
[02:30:56.696] iteration 19518 : loss : 0.054149, loss_ce: 0.012639
[02:30:56.997] iteration 19519 : loss : 0.044774, loss_ce: 0.015675
[02:30:57.298] iteration 19520 : loss : 0.052211, loss_ce: 0.019642
[02:30:57.619] iteration 19521 : loss : 0.104370, loss_ce: 0.007089
[02:30:57.916] iteration 19522 : loss : 0.040271, loss_ce: 0.012305
[02:30:58.223] iteration 19523 : loss : 0.034084, loss_ce: 0.010794
[02:30:58.525] iteration 19524 : loss : 0.047855, loss_ce: 0.013251
[02:30:58.827] iteration 19525 : loss : 0.055925, loss_ce: 0.017887
[02:30:59.128] iteration 19526 : loss : 0.042838, loss_ce: 0.020842
[02:30:59.439] iteration 19527 : loss : 0.049439, loss_ce: 0.014693
[02:30:59.737] iteration 19528 : loss : 0.102241, loss_ce: 0.009865
[02:31:00.043] iteration 19529 : loss : 0.040817, loss_ce: 0.011039
[02:31:00.344] iteration 19530 : loss : 0.044271, loss_ce: 0.014267
[02:31:00.649] iteration 19531 : loss : 0.039292, loss_ce: 0.013111
[02:31:00.952] iteration 19532 : loss : 0.132940, loss_ce: 0.009739
[02:31:01.253] iteration 19533 : loss : 0.042625, loss_ce: 0.009342
[02:31:01.552] iteration 19534 : loss : 0.051912, loss_ce: 0.017719
[02:31:01.855] iteration 19535 : loss : 0.042307, loss_ce: 0.009162
[02:31:02.163] iteration 19536 : loss : 0.035610, loss_ce: 0.008305
[02:31:02.464] iteration 19537 : loss : 0.037562, loss_ce: 0.013532
[02:31:02.765] iteration 19538 : loss : 0.042662, loss_ce: 0.016002
[02:31:03.068] iteration 19539 : loss : 0.045854, loss_ce: 0.011698
[02:31:03.371] iteration 19540 : loss : 0.098146, loss_ce: 0.010518
[02:31:03.685] iteration 19541 : loss : 0.100188, loss_ce: 0.014577
[02:31:03.990] iteration 19542 : loss : 0.103456, loss_ce: 0.010004
[02:31:04.292] iteration 19543 : loss : 0.046858, loss_ce: 0.011761
[02:31:04.595] iteration 19544 : loss : 0.034455, loss_ce: 0.007070
[02:31:04.898] iteration 19545 : loss : 0.050268, loss_ce: 0.015524
[02:31:05.203] iteration 19546 : loss : 0.043066, loss_ce: 0.020892
[02:31:05.506] iteration 19547 : loss : 0.055943, loss_ce: 0.008157
[02:31:05.808] iteration 19548 : loss : 0.052224, loss_ce: 0.019363
[02:31:06.110] iteration 19549 : loss : 0.053738, loss_ce: 0.011353
[02:31:06.410] iteration 19550 : loss : 0.047027, loss_ce: 0.015065
[02:31:06.708] iteration 19551 : loss : 0.042485, loss_ce: 0.011788
[02:31:07.006] iteration 19552 : loss : 0.048651, loss_ce: 0.020067
[02:31:07.304] iteration 19553 : loss : 0.097644, loss_ce: 0.010233
[02:31:07.606] iteration 19554 : loss : 0.071697, loss_ce: 0.021402
[02:31:07.907] iteration 19555 : loss : 0.051764, loss_ce: 0.012783
[02:31:08.205] iteration 19556 : loss : 0.104843, loss_ce: 0.008907
[02:31:08.506] iteration 19557 : loss : 0.040991, loss_ce: 0.015610
[02:31:08.812] iteration 19558 : loss : 0.037586, loss_ce: 0.010434
[02:31:09.114] iteration 19559 : loss : 0.046270, loss_ce: 0.014919
[02:31:09.418] iteration 19560 : loss : 0.111759, loss_ce: 0.010066
[02:31:09.736] iteration 19561 : loss : 0.041905, loss_ce: 0.014603
[02:31:10.041] iteration 19562 : loss : 0.048653, loss_ce: 0.017334
[02:31:10.346] iteration 19563 : loss : 0.044060, loss_ce: 0.011518
[02:31:10.645] iteration 19564 : loss : 0.040841, loss_ce: 0.018239
[02:31:10.943] iteration 19565 : loss : 0.042026, loss_ce: 0.013717
[02:31:11.244] iteration 19566 : loss : 0.048989, loss_ce: 0.010713
[02:31:11.545] iteration 19567 : loss : 0.049805, loss_ce: 0.023273
[02:31:11.844] iteration 19568 : loss : 0.056667, loss_ce: 0.009204
[02:31:12.145] iteration 19569 : loss : 0.048302, loss_ce: 0.014966
[02:31:12.448] iteration 19570 : loss : 0.048164, loss_ce: 0.022655
[02:31:12.753] iteration 19571 : loss : 0.037065, loss_ce: 0.011195
[02:31:13.054] iteration 19572 : loss : 0.098032, loss_ce: 0.010246
[02:31:13.355] iteration 19573 : loss : 0.044670, loss_ce: 0.010989
[02:31:13.656] iteration 19574 : loss : 0.045777, loss_ce: 0.016069
[02:31:13.961] iteration 19575 : loss : 0.037845, loss_ce: 0.014331
[02:31:14.261] iteration 19576 : loss : 0.042891, loss_ce: 0.010816
[02:31:14.564] iteration 19577 : loss : 0.034737, loss_ce: 0.009310
[02:31:14.866] iteration 19578 : loss : 0.114029, loss_ce: 0.006248
[02:31:15.172] iteration 19579 : loss : 0.044933, loss_ce: 0.013775
[02:31:15.483] iteration 19580 : loss : 0.055424, loss_ce: 0.007787
[02:31:15.803] iteration 19581 : loss : 0.037014, loss_ce: 0.012628
[02:31:16.109] iteration 19582 : loss : 0.286793, loss_ce: 0.010704
[02:31:16.411] iteration 19583 : loss : 0.045253, loss_ce: 0.018099
[02:31:16.714] iteration 19584 : loss : 0.044249, loss_ce: 0.013650
[02:31:17.023] iteration 19585 : loss : 0.082948, loss_ce: 0.017187
[02:31:17.325] iteration 19586 : loss : 0.047218, loss_ce: 0.009342
[02:31:17.635] iteration 19587 : loss : 0.049397, loss_ce: 0.016314
[02:31:17.945] iteration 19588 : loss : 0.037378, loss_ce: 0.011979
[02:31:18.251] iteration 19589 : loss : 0.047532, loss_ce: 0.010185
[02:31:18.556] iteration 19590 : loss : 0.057448, loss_ce: 0.019291
[02:31:18.861] iteration 19591 : loss : 0.039014, loss_ce: 0.013768
[02:31:19.164] iteration 19592 : loss : 0.104943, loss_ce: 0.012599
[02:31:19.471] iteration 19593 : loss : 0.051135, loss_ce: 0.013745
[02:31:19.771] iteration 19594 : loss : 0.046525, loss_ce: 0.017270
[02:31:20.080] iteration 19595 : loss : 0.042971, loss_ce: 0.013353
[02:31:20.382] iteration 19596 : loss : 0.043534, loss_ce: 0.018390
[02:31:20.687] iteration 19597 : loss : 0.035925, loss_ce: 0.015589
[02:31:20.993] iteration 19598 : loss : 0.043521, loss_ce: 0.013273
[02:31:21.079] iteration 19599 : loss : 0.104152, loss_ce: 0.018548
[02:31:39.969] iteration 19600 : loss : 0.050545, loss_ce: 0.013938
[02:31:40.301] iteration 19601 : loss : 0.041792, loss_ce: 0.011117
[02:31:40.603] iteration 19602 : loss : 0.048725, loss_ce: 0.016366
[02:31:40.901] iteration 19603 : loss : 0.053048, loss_ce: 0.013859
[02:31:41.198] iteration 19604 : loss : 0.148340, loss_ce: 0.011393
[02:31:41.502] iteration 19605 : loss : 0.051262, loss_ce: 0.011114
[02:31:41.804] iteration 19606 : loss : 0.055919, loss_ce: 0.015498
[02:31:42.096] iteration 19607 : loss : 0.091141, loss_ce: 0.007275
[02:31:42.396] iteration 19608 : loss : 0.040846, loss_ce: 0.015093
[02:31:42.688] iteration 19609 : loss : 0.050244, loss_ce: 0.012719
[02:31:42.986] iteration 19610 : loss : 0.046380, loss_ce: 0.019818
[02:31:43.284] iteration 19611 : loss : 0.037515, loss_ce: 0.007645
[02:31:43.578] iteration 19612 : loss : 0.067614, loss_ce: 0.015723
[02:31:43.878] iteration 19613 : loss : 0.048723, loss_ce: 0.013631
[02:31:44.175] iteration 19614 : loss : 0.104283, loss_ce: 0.010794
[02:31:44.475] iteration 19615 : loss : 0.043179, loss_ce: 0.013069
[02:31:44.773] iteration 19616 : loss : 0.035966, loss_ce: 0.010520
[02:31:45.075] iteration 19617 : loss : 0.081476, loss_ce: 0.011317
[02:31:45.372] iteration 19618 : loss : 0.159756, loss_ce: 0.011369
[02:31:45.673] iteration 19619 : loss : 0.097934, loss_ce: 0.007826
[02:31:45.970] iteration 19620 : loss : 0.061009, loss_ce: 0.012177
[02:31:46.287] iteration 19621 : loss : 0.044607, loss_ce: 0.014955
[02:31:46.590] iteration 19622 : loss : 0.034441, loss_ce: 0.009810
[02:31:46.890] iteration 19623 : loss : 0.038300, loss_ce: 0.010356
[02:31:47.192] iteration 19624 : loss : 0.048672, loss_ce: 0.008969
[02:31:47.489] iteration 19625 : loss : 0.109180, loss_ce: 0.009951
[02:31:47.786] iteration 19626 : loss : 0.036020, loss_ce: 0.016743
[02:31:48.088] iteration 19627 : loss : 0.049297, loss_ce: 0.015861
[02:31:48.390] iteration 19628 : loss : 0.056771, loss_ce: 0.019114
[02:31:48.695] iteration 19629 : loss : 0.037437, loss_ce: 0.017338
[02:31:49.001] iteration 19630 : loss : 0.103669, loss_ce: 0.013283
[02:31:49.310] iteration 19631 : loss : 0.045634, loss_ce: 0.015472
[02:31:49.608] iteration 19632 : loss : 0.044761, loss_ce: 0.019125
[02:31:49.908] iteration 19633 : loss : 0.043710, loss_ce: 0.012090
[02:31:50.207] iteration 19634 : loss : 0.032927, loss_ce: 0.005499
[02:31:50.512] iteration 19635 : loss : 0.043451, loss_ce: 0.008183
[02:31:50.812] iteration 19636 : loss : 0.111137, loss_ce: 0.018249
[02:31:51.116] iteration 19637 : loss : 0.155254, loss_ce: 0.004150
[02:31:51.415] iteration 19638 : loss : 0.038676, loss_ce: 0.011022
[02:31:51.716] iteration 19639 : loss : 0.098883, loss_ce: 0.010496
[02:31:52.016] iteration 19640 : loss : 0.047219, loss_ce: 0.019737
[02:31:52.333] iteration 19641 : loss : 0.114770, loss_ce: 0.011401
[02:31:52.633] iteration 19642 : loss : 0.044762, loss_ce: 0.015869
[02:31:52.932] iteration 19643 : loss : 0.107015, loss_ce: 0.010218
[02:31:53.233] iteration 19644 : loss : 0.058616, loss_ce: 0.016120
[02:31:53.536] iteration 19645 : loss : 0.047354, loss_ce: 0.013432
[02:31:53.843] iteration 19646 : loss : 0.056709, loss_ce: 0.009939
[02:31:54.145] iteration 19647 : loss : 0.042370, loss_ce: 0.021608
[02:31:54.450] iteration 19648 : loss : 0.048761, loss_ce: 0.010467
[02:31:54.753] iteration 19649 : loss : 0.042696, loss_ce: 0.012922
[02:31:55.057] iteration 19650 : loss : 0.045197, loss_ce: 0.009519
[02:31:55.355] iteration 19651 : loss : 0.039815, loss_ce: 0.018017
[02:31:55.660] iteration 19652 : loss : 0.028167, loss_ce: 0.006946
[02:31:55.964] iteration 19653 : loss : 0.046024, loss_ce: 0.014937
[02:31:56.262] iteration 19654 : loss : 0.037322, loss_ce: 0.016018
[02:31:56.567] iteration 19655 : loss : 0.047691, loss_ce: 0.012795
[02:31:56.869] iteration 19656 : loss : 0.044565, loss_ce: 0.022219
[02:31:57.172] iteration 19657 : loss : 0.048335, loss_ce: 0.018343
[02:31:57.478] iteration 19658 : loss : 0.043016, loss_ce: 0.007249
[02:31:57.781] iteration 19659 : loss : 0.044893, loss_ce: 0.017564
[02:31:58.085] iteration 19660 : loss : 0.166262, loss_ce: 0.012581
[02:31:58.401] iteration 19661 : loss : 0.051798, loss_ce: 0.011494
[02:31:58.698] iteration 19662 : loss : 0.103009, loss_ce: 0.010959
[02:31:59.001] iteration 19663 : loss : 0.034840, loss_ce: 0.007244
[02:31:59.308] iteration 19664 : loss : 0.048541, loss_ce: 0.013111
[02:31:59.609] iteration 19665 : loss : 0.059199, loss_ce: 0.011364
[02:31:59.911] iteration 19666 : loss : 0.045814, loss_ce: 0.014773
[02:32:00.214] iteration 19667 : loss : 0.039647, loss_ce: 0.019114
[02:32:00.516] iteration 19668 : loss : 0.037872, loss_ce: 0.016799
[02:32:00.820] iteration 19669 : loss : 0.048869, loss_ce: 0.014098
[02:32:01.123] iteration 19670 : loss : 0.044741, loss_ce: 0.011420
[02:32:01.430] iteration 19671 : loss : 0.047383, loss_ce: 0.013376
[02:32:01.732] iteration 19672 : loss : 0.046095, loss_ce: 0.009996
[02:32:02.038] iteration 19673 : loss : 0.038661, loss_ce: 0.011104
[02:32:02.343] iteration 19674 : loss : 0.044656, loss_ce: 0.018978
[02:32:02.644] iteration 19675 : loss : 0.043470, loss_ce: 0.015180
[02:32:02.944] iteration 19676 : loss : 0.052340, loss_ce: 0.014537
[02:32:03.245] iteration 19677 : loss : 0.050418, loss_ce: 0.017230
[02:32:03.547] iteration 19678 : loss : 0.051332, loss_ce: 0.014332
[02:32:03.850] iteration 19679 : loss : 0.097619, loss_ce: 0.008111
[02:32:04.156] iteration 19680 : loss : 0.076973, loss_ce: 0.011900
[02:32:04.479] iteration 19681 : loss : 0.052823, loss_ce: 0.010097
[02:32:04.783] iteration 19682 : loss : 0.112869, loss_ce: 0.016586
[02:32:05.087] iteration 19683 : loss : 0.046633, loss_ce: 0.015143
[02:32:05.390] iteration 19684 : loss : 0.041449, loss_ce: 0.016931
[02:32:05.696] iteration 19685 : loss : 0.091382, loss_ce: 0.002332
[02:32:05.996] iteration 19686 : loss : 0.095123, loss_ce: 0.007801
[02:32:06.297] iteration 19687 : loss : 0.040507, loss_ce: 0.009483
[02:32:06.592] iteration 19688 : loss : 0.092376, loss_ce: 0.008722
[02:32:06.890] iteration 19689 : loss : 0.103202, loss_ce: 0.008778
[02:32:07.189] iteration 19690 : loss : 0.043589, loss_ce: 0.017731
[02:32:07.489] iteration 19691 : loss : 0.034080, loss_ce: 0.006216
[02:32:07.788] iteration 19692 : loss : 0.048343, loss_ce: 0.018352
[02:32:08.082] iteration 19693 : loss : 0.168825, loss_ce: 0.013164
[02:32:08.381] iteration 19694 : loss : 0.047941, loss_ce: 0.010269
[02:32:08.679] iteration 19695 : loss : 0.041537, loss_ce: 0.012890
[02:32:08.979] iteration 19696 : loss : 0.052336, loss_ce: 0.014358
[02:32:09.279] iteration 19697 : loss : 0.034677, loss_ce: 0.011791
[02:32:09.578] iteration 19698 : loss : 0.044797, loss_ce: 0.014878
[02:32:09.877] iteration 19699 : loss : 0.165183, loss_ce: 0.007964
[02:32:10.181] iteration 19700 : loss : 0.052901, loss_ce: 0.006602
[02:32:10.496] iteration 19701 : loss : 0.220137, loss_ce: 0.011432
[02:32:10.791] iteration 19702 : loss : 0.052283, loss_ce: 0.016220
[02:32:11.089] iteration 19703 : loss : 0.049792, loss_ce: 0.013231
[02:32:11.384] iteration 19704 : loss : 0.094638, loss_ce: 0.017947
[02:32:11.683] iteration 19705 : loss : 0.035771, loss_ce: 0.012614
[02:32:11.985] iteration 19706 : loss : 0.037587, loss_ce: 0.009886
[02:32:12.286] iteration 19707 : loss : 0.158565, loss_ce: 0.011860
[02:32:12.586] iteration 19708 : loss : 0.055967, loss_ce: 0.012098
[02:32:12.888] iteration 19709 : loss : 0.047109, loss_ce: 0.018863
[02:32:13.183] iteration 19710 : loss : 0.225196, loss_ce: 0.013789
[02:32:13.482] iteration 19711 : loss : 0.041405, loss_ce: 0.018180
[02:32:13.775] iteration 19712 : loss : 0.092819, loss_ce: 0.010817
[02:32:14.076] iteration 19713 : loss : 0.048212, loss_ce: 0.011433
[02:32:14.375] iteration 19714 : loss : 0.044365, loss_ce: 0.013891
[02:32:14.668] iteration 19715 : loss : 0.149635, loss_ce: 0.007343
[02:32:14.967] iteration 19716 : loss : 0.051157, loss_ce: 0.015665
[02:32:15.266] iteration 19717 : loss : 0.157170, loss_ce: 0.004796
[02:32:15.566] iteration 19718 : loss : 0.046459, loss_ce: 0.022356
[02:32:15.865] iteration 19719 : loss : 0.049474, loss_ce: 0.017078
[02:32:16.164] iteration 19720 : loss : 0.044404, loss_ce: 0.016727
[02:32:16.477] iteration 19721 : loss : 0.049375, loss_ce: 0.014582
[02:32:16.776] iteration 19722 : loss : 0.047025, loss_ce: 0.025711
[02:32:17.078] iteration 19723 : loss : 0.048563, loss_ce: 0.019109
[02:32:17.377] iteration 19724 : loss : 0.100084, loss_ce: 0.004583
[02:32:17.680] iteration 19725 : loss : 0.102544, loss_ce: 0.008568
[02:32:17.979] iteration 19726 : loss : 0.046480, loss_ce: 0.014625
[02:32:18.281] iteration 19727 : loss : 0.034954, loss_ce: 0.006858
[02:32:18.579] iteration 19728 : loss : 0.045998, loss_ce: 0.019702
[02:32:18.878] iteration 19729 : loss : 0.060989, loss_ce: 0.016371
[02:32:19.180] iteration 19730 : loss : 0.065336, loss_ce: 0.014590
[02:32:19.489] iteration 19731 : loss : 0.045018, loss_ce: 0.008422
[02:32:19.795] iteration 19732 : loss : 0.040771, loss_ce: 0.013873
[02:32:20.101] iteration 19733 : loss : 0.040741, loss_ce: 0.008566
[02:32:20.410] iteration 19734 : loss : 0.038208, loss_ce: 0.006771
[02:32:20.712] iteration 19735 : loss : 0.128722, loss_ce: 0.033506
[02:32:21.019] iteration 19736 : loss : 0.036160, loss_ce: 0.009412
[02:32:21.326] iteration 19737 : loss : 0.106479, loss_ce: 0.016461
[02:32:21.411] iteration 19738 : loss : 0.025001, loss_ce: 0.000008
[02:32:39.363] iteration 19739 : loss : 0.038646, loss_ce: 0.012127
[02:32:39.672] iteration 19740 : loss : 0.049309, loss_ce: 0.011543
[02:32:39.999] iteration 19741 : loss : 0.041922, loss_ce: 0.012522
[02:32:40.303] iteration 19742 : loss : 0.049885, loss_ce: 0.020063
[02:32:40.613] iteration 19743 : loss : 0.099445, loss_ce: 0.003757
[02:32:40.914] iteration 19744 : loss : 0.044916, loss_ce: 0.017210
[02:32:41.212] iteration 19745 : loss : 0.105778, loss_ce: 0.004356
[02:32:41.515] iteration 19746 : loss : 0.163292, loss_ce: 0.007297
[02:32:41.815] iteration 19747 : loss : 0.045014, loss_ce: 0.019645
[02:32:42.112] iteration 19748 : loss : 0.120365, loss_ce: 0.010387
[02:32:42.412] iteration 19749 : loss : 0.065451, loss_ce: 0.016747
[02:32:42.715] iteration 19750 : loss : 0.066287, loss_ce: 0.010901
[02:32:43.012] iteration 19751 : loss : 0.042299, loss_ce: 0.008175
[02:32:43.314] iteration 19752 : loss : 0.054798, loss_ce: 0.019140
[02:32:43.617] iteration 19753 : loss : 0.048796, loss_ce: 0.015532
[02:32:43.919] iteration 19754 : loss : 0.102730, loss_ce: 0.016246
[02:32:44.225] iteration 19755 : loss : 0.047696, loss_ce: 0.014090
[02:32:44.525] iteration 19756 : loss : 0.049511, loss_ce: 0.012185
[02:32:44.830] iteration 19757 : loss : 0.046563, loss_ce: 0.007034
[02:32:45.130] iteration 19758 : loss : 0.044182, loss_ce: 0.019237
[02:32:45.432] iteration 19759 : loss : 0.047659, loss_ce: 0.011812
[02:32:45.731] iteration 19760 : loss : 0.040631, loss_ce: 0.015772
[02:32:46.045] iteration 19761 : loss : 0.054036, loss_ce: 0.015807
[02:32:46.345] iteration 19762 : loss : 0.034088, loss_ce: 0.013221
[02:32:46.646] iteration 19763 : loss : 0.047951, loss_ce: 0.007743
[02:32:46.950] iteration 19764 : loss : 0.046154, loss_ce: 0.017109
[02:32:47.251] iteration 19765 : loss : 0.040342, loss_ce: 0.014330
[02:32:47.552] iteration 19766 : loss : 0.042191, loss_ce: 0.010832
[02:32:47.852] iteration 19767 : loss : 0.035607, loss_ce: 0.008912
[02:32:48.154] iteration 19768 : loss : 0.045513, loss_ce: 0.011231
[02:32:48.452] iteration 19769 : loss : 0.041973, loss_ce: 0.016086
[02:32:48.750] iteration 19770 : loss : 0.042377, loss_ce: 0.014176
[02:32:49.051] iteration 19771 : loss : 0.035195, loss_ce: 0.006715
[02:32:49.352] iteration 19772 : loss : 0.042468, loss_ce: 0.012903
[02:32:49.651] iteration 19773 : loss : 0.029906, loss_ce: 0.010743
[02:32:49.949] iteration 19774 : loss : 0.104947, loss_ce: 0.013606
[02:32:50.254] iteration 19775 : loss : 0.096648, loss_ce: 0.012249
[02:32:50.554] iteration 19776 : loss : 0.037416, loss_ce: 0.012250
[02:32:50.858] iteration 19777 : loss : 0.283253, loss_ce: 0.008721
[02:32:51.155] iteration 19778 : loss : 0.047180, loss_ce: 0.012611
[02:32:51.457] iteration 19779 : loss : 0.046871, loss_ce: 0.013534
[02:32:51.756] iteration 19780 : loss : 0.099047, loss_ce: 0.010641
[02:32:52.070] iteration 19781 : loss : 0.045831, loss_ce: 0.017056
[02:32:52.380] iteration 19782 : loss : 0.051169, loss_ce: 0.012501
[02:32:52.682] iteration 19783 : loss : 0.037999, loss_ce: 0.008017
[02:32:52.985] iteration 19784 : loss : 0.216408, loss_ce: 0.008989
[02:32:53.289] iteration 19785 : loss : 0.044900, loss_ce: 0.011876
[02:32:53.592] iteration 19786 : loss : 0.042438, loss_ce: 0.018167
[02:32:53.891] iteration 19787 : loss : 0.039781, loss_ce: 0.010613
[02:32:54.201] iteration 19788 : loss : 0.038728, loss_ce: 0.005565
[02:32:54.499] iteration 19789 : loss : 0.044512, loss_ce: 0.015535
[02:32:54.804] iteration 19790 : loss : 0.103605, loss_ce: 0.012330
[02:32:55.111] iteration 19791 : loss : 0.042353, loss_ce: 0.015481
[02:32:55.412] iteration 19792 : loss : 0.049359, loss_ce: 0.015729
[02:32:55.711] iteration 19793 : loss : 0.224214, loss_ce: 0.007682
[02:32:56.015] iteration 19794 : loss : 0.048577, loss_ce: 0.012689
[02:32:56.312] iteration 19795 : loss : 0.225490, loss_ce: 0.008978
[02:32:56.613] iteration 19796 : loss : 0.041601, loss_ce: 0.014317
[02:32:56.909] iteration 19797 : loss : 0.044536, loss_ce: 0.014064
[02:32:57.205] iteration 19798 : loss : 0.097414, loss_ce: 0.011286
[02:32:57.505] iteration 19799 : loss : 0.048127, loss_ce: 0.016412
[02:32:57.808] iteration 19800 : loss : 0.039527, loss_ce: 0.014317
[02:32:58.118] iteration 19801 : loss : 0.113025, loss_ce: 0.011492
[02:32:58.414] iteration 19802 : loss : 0.105620, loss_ce: 0.004804
[02:32:58.711] iteration 19803 : loss : 0.043644, loss_ce: 0.015807
[02:32:59.008] iteration 19804 : loss : 0.038918, loss_ce: 0.012807
[02:32:59.308] iteration 19805 : loss : 0.048893, loss_ce: 0.022782
[02:32:59.602] iteration 19806 : loss : 0.051675, loss_ce: 0.012012
[02:32:59.899] iteration 19807 : loss : 0.040627, loss_ce: 0.015934
[02:33:00.194] iteration 19808 : loss : 0.036168, loss_ce: 0.009996
[02:33:00.494] iteration 19809 : loss : 0.041796, loss_ce: 0.016398
[02:33:00.789] iteration 19810 : loss : 0.043419, loss_ce: 0.010840
[02:33:01.087] iteration 19811 : loss : 0.041710, loss_ce: 0.013014
[02:33:01.384] iteration 19812 : loss : 0.100819, loss_ce: 0.011319
[02:33:01.687] iteration 19813 : loss : 0.046805, loss_ce: 0.009043
[02:33:01.989] iteration 19814 : loss : 0.050180, loss_ce: 0.009513
[02:33:02.289] iteration 19815 : loss : 0.040385, loss_ce: 0.012290
[02:33:02.583] iteration 19816 : loss : 0.051493, loss_ce: 0.013824
[02:33:02.885] iteration 19817 : loss : 0.099797, loss_ce: 0.011114
[02:33:03.180] iteration 19818 : loss : 0.102642, loss_ce: 0.010735
[02:33:03.476] iteration 19819 : loss : 0.042457, loss_ce: 0.015584
[02:33:03.778] iteration 19820 : loss : 0.038858, loss_ce: 0.009665
[02:33:04.102] iteration 19821 : loss : 0.031037, loss_ce: 0.005427
[02:33:04.403] iteration 19822 : loss : 0.050289, loss_ce: 0.017458
[02:33:04.700] iteration 19823 : loss : 0.044652, loss_ce: 0.010779
[02:33:04.999] iteration 19824 : loss : 0.041826, loss_ce: 0.017095
[02:33:05.292] iteration 19825 : loss : 0.097727, loss_ce: 0.008994
[02:33:05.589] iteration 19826 : loss : 0.034657, loss_ce: 0.011366
[02:33:05.884] iteration 19827 : loss : 0.047950, loss_ce: 0.015508
[02:33:06.183] iteration 19828 : loss : 0.046736, loss_ce: 0.007979
[02:33:06.481] iteration 19829 : loss : 0.171607, loss_ce: 0.016348
[02:33:06.778] iteration 19830 : loss : 0.062616, loss_ce: 0.014182
[02:33:07.080] iteration 19831 : loss : 0.048444, loss_ce: 0.008705
[02:33:07.380] iteration 19832 : loss : 0.035331, loss_ce: 0.012229
[02:33:07.677] iteration 19833 : loss : 0.049739, loss_ce: 0.018052
[02:33:07.976] iteration 19834 : loss : 0.050877, loss_ce: 0.013395
[02:33:08.274] iteration 19835 : loss : 0.101600, loss_ce: 0.017298
[02:33:08.570] iteration 19836 : loss : 0.044656, loss_ce: 0.011683
[02:33:08.868] iteration 19837 : loss : 0.048282, loss_ce: 0.013845
[02:33:09.172] iteration 19838 : loss : 0.049351, loss_ce: 0.013420
[02:33:09.475] iteration 19839 : loss : 0.038233, loss_ce: 0.013057
[02:33:09.781] iteration 19840 : loss : 0.046513, loss_ce: 0.012985
[02:33:10.103] iteration 19841 : loss : 0.045817, loss_ce: 0.019489
[02:33:10.404] iteration 19842 : loss : 0.041532, loss_ce: 0.009099
[02:33:10.707] iteration 19843 : loss : 0.040799, loss_ce: 0.020526
[02:33:11.010] iteration 19844 : loss : 0.150845, loss_ce: 0.002686
[02:33:11.309] iteration 19845 : loss : 0.098158, loss_ce: 0.010549
[02:33:11.608] iteration 19846 : loss : 0.107539, loss_ce: 0.012437
[02:33:11.909] iteration 19847 : loss : 0.034036, loss_ce: 0.009236
[02:33:12.207] iteration 19848 : loss : 0.103479, loss_ce: 0.014199
[02:33:12.506] iteration 19849 : loss : 0.049610, loss_ce: 0.019608
[02:33:12.804] iteration 19850 : loss : 0.042444, loss_ce: 0.015548
[02:33:13.105] iteration 19851 : loss : 0.039714, loss_ce: 0.012423
[02:33:13.402] iteration 19852 : loss : 0.045824, loss_ce: 0.010828
[02:33:13.699] iteration 19853 : loss : 0.058129, loss_ce: 0.008638
[02:33:13.995] iteration 19854 : loss : 0.044313, loss_ce: 0.008183
[02:33:14.293] iteration 19855 : loss : 0.045810, loss_ce: 0.011584
[02:33:14.591] iteration 19856 : loss : 0.102766, loss_ce: 0.011981
[02:33:14.889] iteration 19857 : loss : 0.036142, loss_ce: 0.013235
[02:33:15.185] iteration 19858 : loss : 0.101913, loss_ce: 0.011630
[02:33:15.482] iteration 19859 : loss : 0.043783, loss_ce: 0.016078
[02:33:15.782] iteration 19860 : loss : 0.038812, loss_ce: 0.011727
[02:33:16.098] iteration 19861 : loss : 0.049845, loss_ce: 0.007392
[02:33:16.403] iteration 19862 : loss : 0.040572, loss_ce: 0.015109
[02:33:16.702] iteration 19863 : loss : 0.046331, loss_ce: 0.012832
[02:33:17.003] iteration 19864 : loss : 0.047710, loss_ce: 0.016546
[02:33:17.309] iteration 19865 : loss : 0.044539, loss_ce: 0.013591
[02:33:17.613] iteration 19866 : loss : 0.045235, loss_ce: 0.015903
[02:33:17.917] iteration 19867 : loss : 0.055636, loss_ce: 0.020188
[02:33:18.220] iteration 19868 : loss : 0.045099, loss_ce: 0.015296
[02:33:18.525] iteration 19869 : loss : 0.044826, loss_ce: 0.025667
[02:33:18.826] iteration 19870 : loss : 0.054868, loss_ce: 0.017064
[02:33:19.128] iteration 19871 : loss : 0.041250, loss_ce: 0.007108
[02:33:19.432] iteration 19872 : loss : 0.043834, loss_ce: 0.017323
[02:33:19.732] iteration 19873 : loss : 0.036438, loss_ce: 0.009126
[02:33:20.038] iteration 19874 : loss : 0.046242, loss_ce: 0.012637
[02:33:20.341] iteration 19875 : loss : 0.150686, loss_ce: 0.006413
[02:33:20.646] iteration 19876 : loss : 0.048948, loss_ce: 0.018243
[02:33:20.736] iteration 19877 : loss : 0.340832, loss_ce: 0.007108
[02:33:40.121] iteration 19878 : loss : 0.044301, loss_ce: 0.015371
[02:33:40.428] iteration 19879 : loss : 0.045870, loss_ce: 0.015744
[02:33:40.731] iteration 19880 : loss : 0.056146, loss_ce: 0.009235
[02:33:41.050] iteration 19881 : loss : 0.041255, loss_ce: 0.014565
[02:33:41.358] iteration 19882 : loss : 0.044228, loss_ce: 0.010794
[02:33:41.665] iteration 19883 : loss : 0.048124, loss_ce: 0.008969
[02:33:41.968] iteration 19884 : loss : 0.040771, loss_ce: 0.008782
[02:33:42.270] iteration 19885 : loss : 0.033817, loss_ce: 0.013771
[02:33:42.571] iteration 19886 : loss : 0.032507, loss_ce: 0.013514
[02:33:42.873] iteration 19887 : loss : 0.041463, loss_ce: 0.014844
[02:33:43.170] iteration 19888 : loss : 0.041789, loss_ce: 0.016924
[02:33:43.467] iteration 19889 : loss : 0.041973, loss_ce: 0.016624
[02:33:43.768] iteration 19890 : loss : 0.051615, loss_ce: 0.016487
[02:33:44.071] iteration 19891 : loss : 0.041627, loss_ce: 0.014778
[02:33:44.377] iteration 19892 : loss : 0.049695, loss_ce: 0.010968
[02:33:44.677] iteration 19893 : loss : 0.046032, loss_ce: 0.021136
[02:33:44.975] iteration 19894 : loss : 0.046407, loss_ce: 0.010909
[02:33:45.276] iteration 19895 : loss : 0.042911, loss_ce: 0.010634
[02:33:45.573] iteration 19896 : loss : 0.116445, loss_ce: 0.010080
[02:33:45.872] iteration 19897 : loss : 0.048599, loss_ce: 0.016053
[02:33:46.173] iteration 19898 : loss : 0.041476, loss_ce: 0.009942
[02:33:46.476] iteration 19899 : loss : 0.041472, loss_ce: 0.017777
[02:33:46.773] iteration 19900 : loss : 0.032379, loss_ce: 0.008560
[02:33:47.089] iteration 19901 : loss : 0.055410, loss_ce: 0.011445
[02:33:47.392] iteration 19902 : loss : 0.052220, loss_ce: 0.010358
[02:33:47.694] iteration 19903 : loss : 0.049977, loss_ce: 0.024279
[02:33:47.993] iteration 19904 : loss : 0.053038, loss_ce: 0.006781
[02:33:48.295] iteration 19905 : loss : 0.078882, loss_ce: 0.018950
[02:33:48.599] iteration 19906 : loss : 0.042394, loss_ce: 0.015138
[02:33:48.900] iteration 19907 : loss : 0.096310, loss_ce: 0.009421
[02:33:49.203] iteration 19908 : loss : 0.032599, loss_ce: 0.008807
[02:33:49.501] iteration 19909 : loss : 0.052442, loss_ce: 0.024259
[02:33:49.799] iteration 19910 : loss : 0.042779, loss_ce: 0.017958
[02:33:50.101] iteration 19911 : loss : 0.045939, loss_ce: 0.017666
[02:33:50.403] iteration 19912 : loss : 0.037948, loss_ce: 0.009943
[02:33:50.701] iteration 19913 : loss : 0.034683, loss_ce: 0.010372
[02:33:51.003] iteration 19914 : loss : 0.032049, loss_ce: 0.010259
[02:33:51.302] iteration 19915 : loss : 0.053771, loss_ce: 0.007695
[02:33:51.603] iteration 19916 : loss : 0.035982, loss_ce: 0.016384
[02:33:51.904] iteration 19917 : loss : 0.100373, loss_ce: 0.004426
[02:33:52.205] iteration 19918 : loss : 0.044518, loss_ce: 0.015170
[02:33:52.508] iteration 19919 : loss : 0.041048, loss_ce: 0.016444
[02:33:52.812] iteration 19920 : loss : 0.174476, loss_ce: 0.011394
[02:33:53.138] iteration 19921 : loss : 0.112850, loss_ce: 0.005797
[02:33:53.439] iteration 19922 : loss : 0.047605, loss_ce: 0.016295
[02:33:53.742] iteration 19923 : loss : 0.043780, loss_ce: 0.019900
[02:33:54.045] iteration 19924 : loss : 0.044556, loss_ce: 0.018203
[02:33:54.349] iteration 19925 : loss : 0.049549, loss_ce: 0.021892
[02:33:54.651] iteration 19926 : loss : 0.029839, loss_ce: 0.010756
[02:33:54.949] iteration 19927 : loss : 0.054716, loss_ce: 0.014683
[02:33:55.252] iteration 19928 : loss : 0.047094, loss_ce: 0.016257
[02:33:55.551] iteration 19929 : loss : 0.045770, loss_ce: 0.017154
[02:33:55.852] iteration 19930 : loss : 0.058517, loss_ce: 0.019546
[02:33:56.148] iteration 19931 : loss : 0.045552, loss_ce: 0.012845
[02:33:56.447] iteration 19932 : loss : 0.103438, loss_ce: 0.007761
[02:33:56.749] iteration 19933 : loss : 0.050394, loss_ce: 0.016219
[02:33:57.051] iteration 19934 : loss : 0.104392, loss_ce: 0.015761
[02:33:57.355] iteration 19935 : loss : 0.054230, loss_ce: 0.020689
[02:33:57.659] iteration 19936 : loss : 0.046301, loss_ce: 0.011782
[02:33:57.960] iteration 19937 : loss : 0.107695, loss_ce: 0.008072
[02:33:58.262] iteration 19938 : loss : 0.049364, loss_ce: 0.013540
[02:33:58.564] iteration 19939 : loss : 0.040939, loss_ce: 0.013928
[02:33:58.866] iteration 19940 : loss : 0.039432, loss_ce: 0.009526
[02:33:59.190] iteration 19941 : loss : 0.044806, loss_ce: 0.009515
[02:33:59.488] iteration 19942 : loss : 0.107062, loss_ce: 0.010225
[02:33:59.786] iteration 19943 : loss : 0.048253, loss_ce: 0.021997
[02:34:00.092] iteration 19944 : loss : 0.101418, loss_ce: 0.006890
[02:34:00.396] iteration 19945 : loss : 0.046331, loss_ce: 0.010649
[02:34:00.695] iteration 19946 : loss : 0.039134, loss_ce: 0.013207
[02:34:00.996] iteration 19947 : loss : 0.041266, loss_ce: 0.013178
[02:34:01.293] iteration 19948 : loss : 0.084389, loss_ce: 0.005996
[02:34:01.590] iteration 19949 : loss : 0.042676, loss_ce: 0.011516
[02:34:01.884] iteration 19950 : loss : 0.105842, loss_ce: 0.006858
[02:34:02.177] iteration 19951 : loss : 0.048832, loss_ce: 0.014021
[02:34:02.475] iteration 19952 : loss : 0.048727, loss_ce: 0.019492
[02:34:02.771] iteration 19953 : loss : 0.037399, loss_ce: 0.009903
[02:34:03.070] iteration 19954 : loss : 0.047989, loss_ce: 0.021326
[02:34:03.371] iteration 19955 : loss : 0.156916, loss_ce: 0.008350
[02:34:03.664] iteration 19956 : loss : 0.041380, loss_ce: 0.017695
[02:34:03.962] iteration 19957 : loss : 0.223066, loss_ce: 0.001617
[02:34:04.266] iteration 19958 : loss : 0.038064, loss_ce: 0.015859
[02:34:04.563] iteration 19959 : loss : 0.055487, loss_ce: 0.008884
[02:34:04.862] iteration 19960 : loss : 0.049516, loss_ce: 0.013583
[02:34:05.183] iteration 19961 : loss : 0.220592, loss_ce: 0.003274
[02:34:05.483] iteration 19962 : loss : 0.100773, loss_ce: 0.008390
[02:34:05.775] iteration 19963 : loss : 0.040808, loss_ce: 0.011360
[02:34:06.071] iteration 19964 : loss : 0.102333, loss_ce: 0.011212
[02:34:06.366] iteration 19965 : loss : 0.054062, loss_ce: 0.012767
[02:34:06.663] iteration 19966 : loss : 0.032588, loss_ce: 0.010213
[02:34:06.959] iteration 19967 : loss : 0.037811, loss_ce: 0.011130
[02:34:07.258] iteration 19968 : loss : 0.040569, loss_ce: 0.011433
[02:34:07.558] iteration 19969 : loss : 0.042074, loss_ce: 0.010220
[02:34:07.862] iteration 19970 : loss : 0.043109, loss_ce: 0.016013
[02:34:08.162] iteration 19971 : loss : 0.036088, loss_ce: 0.014588
[02:34:08.460] iteration 19972 : loss : 0.057823, loss_ce: 0.008782
[02:34:08.756] iteration 19973 : loss : 0.046649, loss_ce: 0.023505
[02:34:09.058] iteration 19974 : loss : 0.036594, loss_ce: 0.010104
[02:34:09.353] iteration 19975 : loss : 0.049226, loss_ce: 0.024168
[02:34:09.649] iteration 19976 : loss : 0.068267, loss_ce: 0.014385
[02:34:09.950] iteration 19977 : loss : 0.044296, loss_ce: 0.014896
[02:34:10.252] iteration 19978 : loss : 0.038506, loss_ce: 0.018114
[02:34:10.550] iteration 19979 : loss : 0.154264, loss_ce: 0.006054
[02:34:10.851] iteration 19980 : loss : 0.044805, loss_ce: 0.013107
[02:34:11.167] iteration 19981 : loss : 0.115117, loss_ce: 0.014795
[02:34:11.461] iteration 19982 : loss : 0.090812, loss_ce: 0.006305
[02:34:11.759] iteration 19983 : loss : 0.056822, loss_ce: 0.011119
[02:34:12.056] iteration 19984 : loss : 0.098579, loss_ce: 0.010936
[02:34:12.358] iteration 19985 : loss : 0.040377, loss_ce: 0.014578
[02:34:12.654] iteration 19986 : loss : 0.053579, loss_ce: 0.007105
[02:34:12.953] iteration 19987 : loss : 0.043709, loss_ce: 0.012566
[02:34:13.249] iteration 19988 : loss : 0.036523, loss_ce: 0.015268
[02:34:13.546] iteration 19989 : loss : 0.040387, loss_ce: 0.014425
[02:34:13.843] iteration 19990 : loss : 0.116701, loss_ce: 0.005894
[02:34:14.146] iteration 19991 : loss : 0.048920, loss_ce: 0.017889
[02:34:14.451] iteration 19992 : loss : 0.057277, loss_ce: 0.019915
[02:34:14.756] iteration 19993 : loss : 0.100097, loss_ce: 0.009590
[02:34:15.057] iteration 19994 : loss : 0.110157, loss_ce: 0.010418
[02:34:15.365] iteration 19995 : loss : 0.037003, loss_ce: 0.006846
[02:34:15.672] iteration 19996 : loss : 0.047248, loss_ce: 0.006719
[02:34:15.972] iteration 19997 : loss : 0.038876, loss_ce: 0.013612
[02:34:16.275] iteration 19998 : loss : 0.099061, loss_ce: 0.009193
[02:34:16.577] iteration 19999 : loss : 0.059020, loss_ce: 0.012399
[02:34:16.876] iteration 20000 : loss : 0.126619, loss_ce: 0.012480
[02:34:17.221] iteration 20001 : loss : 0.051391, loss_ce: 0.015442
[02:34:17.519] iteration 20002 : loss : 0.043383, loss_ce: 0.014496
[02:34:17.832] iteration 20003 : loss : 0.045699, loss_ce: 0.010078
[02:34:18.136] iteration 20004 : loss : 0.050991, loss_ce: 0.024657
[02:34:18.434] iteration 20005 : loss : 0.108964, loss_ce: 0.012708
[02:34:18.734] iteration 20006 : loss : 0.045453, loss_ce: 0.018480
[02:34:19.033] iteration 20007 : loss : 0.045384, loss_ce: 0.016982
[02:34:19.328] iteration 20008 : loss : 0.117106, loss_ce: 0.012785
[02:34:19.627] iteration 20009 : loss : 0.043680, loss_ce: 0.009193
[02:34:19.923] iteration 20010 : loss : 0.048338, loss_ce: 0.014391
[02:34:20.225] iteration 20011 : loss : 0.101500, loss_ce: 0.012152
[02:34:20.527] iteration 20012 : loss : 0.100739, loss_ce: 0.006050
[02:34:20.823] iteration 20013 : loss : 0.064506, loss_ce: 0.012110
[02:34:21.122] iteration 20014 : loss : 0.052151, loss_ce: 0.017329
[02:34:21.418] iteration 20015 : loss : 0.041818, loss_ce: 0.008456
[02:34:21.494] iteration 20016 : loss : 0.311858, loss_ce: 0.005180
[02:34:39.305] iteration 20017 : loss : 0.047755, loss_ce: 0.019372
[02:34:39.601] iteration 20018 : loss : 0.032855, loss_ce: 0.008023
[02:34:39.905] iteration 20019 : loss : 0.039870, loss_ce: 0.018016
[02:34:40.209] iteration 20020 : loss : 0.101883, loss_ce: 0.011769
[02:34:40.530] iteration 20021 : loss : 0.050394, loss_ce: 0.017585
[02:34:40.824] iteration 20022 : loss : 0.039448, loss_ce: 0.017565
[02:34:41.125] iteration 20023 : loss : 0.042303, loss_ce: 0.018304
[02:34:41.420] iteration 20024 : loss : 0.030324, loss_ce: 0.013209
[02:34:41.713] iteration 20025 : loss : 0.038827, loss_ce: 0.014674
[02:34:42.010] iteration 20026 : loss : 0.035581, loss_ce: 0.009835
[02:34:42.308] iteration 20027 : loss : 0.101146, loss_ce: 0.017266
[02:34:42.601] iteration 20028 : loss : 0.031542, loss_ce: 0.010876
[02:34:42.900] iteration 20029 : loss : 0.102530, loss_ce: 0.012066
[02:34:43.197] iteration 20030 : loss : 0.050831, loss_ce: 0.021524
[02:34:43.491] iteration 20031 : loss : 0.047961, loss_ce: 0.012034
[02:34:43.787] iteration 20032 : loss : 0.044075, loss_ce: 0.012172
[02:34:44.081] iteration 20033 : loss : 0.051568, loss_ce: 0.016531
[02:34:44.386] iteration 20034 : loss : 0.103882, loss_ce: 0.006163
[02:34:44.690] iteration 20035 : loss : 0.092530, loss_ce: 0.005341
[02:34:44.990] iteration 20036 : loss : 0.111733, loss_ce: 0.011734
[02:34:45.292] iteration 20037 : loss : 0.045750, loss_ce: 0.017562
[02:34:45.594] iteration 20038 : loss : 0.041215, loss_ce: 0.015321
[02:34:45.893] iteration 20039 : loss : 0.040215, loss_ce: 0.017595
[02:34:46.197] iteration 20040 : loss : 0.046925, loss_ce: 0.008458
[02:34:46.513] iteration 20041 : loss : 0.035368, loss_ce: 0.010919
[02:34:46.810] iteration 20042 : loss : 0.040236, loss_ce: 0.013581
[02:34:47.106] iteration 20043 : loss : 0.117451, loss_ce: 0.009806
[02:34:47.404] iteration 20044 : loss : 0.397138, loss_ce: 0.001262
[02:34:47.700] iteration 20045 : loss : 0.038897, loss_ce: 0.008764
[02:34:47.998] iteration 20046 : loss : 0.040971, loss_ce: 0.017286
[02:34:48.293] iteration 20047 : loss : 0.051904, loss_ce: 0.017223
[02:34:48.589] iteration 20048 : loss : 0.096209, loss_ce: 0.004173
[02:34:48.883] iteration 20049 : loss : 0.049351, loss_ce: 0.011563
[02:34:49.179] iteration 20050 : loss : 0.149770, loss_ce: 0.003212
[02:34:49.475] iteration 20051 : loss : 0.047611, loss_ce: 0.011001
[02:34:49.773] iteration 20052 : loss : 0.048787, loss_ce: 0.012576
[02:34:50.077] iteration 20053 : loss : 0.048094, loss_ce: 0.011804
[02:34:50.375] iteration 20054 : loss : 0.112516, loss_ce: 0.011217
[02:34:50.674] iteration 20055 : loss : 0.100297, loss_ce: 0.012716
[02:34:50.973] iteration 20056 : loss : 0.104132, loss_ce: 0.007343
[02:34:51.276] iteration 20057 : loss : 0.038763, loss_ce: 0.012788
[02:34:51.574] iteration 20058 : loss : 0.038354, loss_ce: 0.010126
[02:34:51.870] iteration 20059 : loss : 0.044013, loss_ce: 0.010038
[02:34:52.170] iteration 20060 : loss : 0.057860, loss_ce: 0.010663
[02:34:52.494] iteration 20061 : loss : 0.053815, loss_ce: 0.013491
[02:34:52.793] iteration 20062 : loss : 0.039825, loss_ce: 0.018404
[02:34:53.092] iteration 20063 : loss : 0.046024, loss_ce: 0.006814
[02:34:53.397] iteration 20064 : loss : 0.045135, loss_ce: 0.014568
[02:34:53.697] iteration 20065 : loss : 0.052056, loss_ce: 0.011822
[02:34:53.995] iteration 20066 : loss : 0.111770, loss_ce: 0.011859
[02:34:54.295] iteration 20067 : loss : 0.049330, loss_ce: 0.016990
[02:34:54.592] iteration 20068 : loss : 0.036971, loss_ce: 0.010293
[02:34:54.884] iteration 20069 : loss : 0.032540, loss_ce: 0.012774
[02:34:55.182] iteration 20070 : loss : 0.033850, loss_ce: 0.009627
[02:34:55.482] iteration 20071 : loss : 0.100734, loss_ce: 0.012601
[02:34:55.781] iteration 20072 : loss : 0.045402, loss_ce: 0.018584
[02:34:56.078] iteration 20073 : loss : 0.038166, loss_ce: 0.007729
[02:34:56.375] iteration 20074 : loss : 0.154882, loss_ce: 0.006485
[02:34:56.669] iteration 20075 : loss : 0.048933, loss_ce: 0.012501
[02:34:56.962] iteration 20076 : loss : 0.119484, loss_ce: 0.006349
[02:34:57.260] iteration 20077 : loss : 0.035471, loss_ce: 0.009355
[02:34:57.556] iteration 20078 : loss : 0.041340, loss_ce: 0.007818
[02:34:57.857] iteration 20079 : loss : 0.043233, loss_ce: 0.016400
[02:34:58.155] iteration 20080 : loss : 0.046078, loss_ce: 0.018243
[02:34:58.466] iteration 20081 : loss : 0.072010, loss_ce: 0.009054
[02:34:58.762] iteration 20082 : loss : 0.054773, loss_ce: 0.011934
[02:34:59.063] iteration 20083 : loss : 0.049615, loss_ce: 0.019439
[02:34:59.362] iteration 20084 : loss : 0.055392, loss_ce: 0.017859
[02:34:59.664] iteration 20085 : loss : 0.047978, loss_ce: 0.015630
[02:34:59.960] iteration 20086 : loss : 0.045292, loss_ce: 0.007235
[02:35:00.261] iteration 20087 : loss : 0.044524, loss_ce: 0.010389
[02:35:00.566] iteration 20088 : loss : 0.046395, loss_ce: 0.010215
[02:35:00.863] iteration 20089 : loss : 0.047681, loss_ce: 0.012239
[02:35:01.164] iteration 20090 : loss : 0.059193, loss_ce: 0.014761
[02:35:01.466] iteration 20091 : loss : 0.098929, loss_ce: 0.009279
[02:35:01.765] iteration 20092 : loss : 0.048076, loss_ce: 0.023764
[02:35:02.063] iteration 20093 : loss : 0.033228, loss_ce: 0.009811
[02:35:02.365] iteration 20094 : loss : 0.040028, loss_ce: 0.019016
[02:35:02.672] iteration 20095 : loss : 0.103798, loss_ce: 0.009227
[02:35:02.973] iteration 20096 : loss : 0.044959, loss_ce: 0.018269
[02:35:03.275] iteration 20097 : loss : 0.099596, loss_ce: 0.012982
[02:35:03.579] iteration 20098 : loss : 0.164928, loss_ce: 0.006007
[02:35:03.879] iteration 20099 : loss : 0.054631, loss_ce: 0.016476
[02:35:04.182] iteration 20100 : loss : 0.035065, loss_ce: 0.011484
[02:35:04.503] iteration 20101 : loss : 0.040438, loss_ce: 0.018400
[02:35:04.805] iteration 20102 : loss : 0.046838, loss_ce: 0.014413
[02:35:05.107] iteration 20103 : loss : 0.044795, loss_ce: 0.018962
[02:35:05.408] iteration 20104 : loss : 0.049722, loss_ce: 0.021632
[02:35:05.710] iteration 20105 : loss : 0.041789, loss_ce: 0.006498
[02:35:06.015] iteration 20106 : loss : 0.105622, loss_ce: 0.010591
[02:35:06.313] iteration 20107 : loss : 0.044904, loss_ce: 0.017257
[02:35:06.614] iteration 20108 : loss : 0.104919, loss_ce: 0.011116
[02:35:06.918] iteration 20109 : loss : 0.043840, loss_ce: 0.014959
[02:35:07.218] iteration 20110 : loss : 0.040956, loss_ce: 0.009697
[02:35:07.522] iteration 20111 : loss : 0.045629, loss_ce: 0.014904
[02:35:07.825] iteration 20112 : loss : 0.040094, loss_ce: 0.013612
[02:35:08.128] iteration 20113 : loss : 0.046366, loss_ce: 0.011400
[02:35:08.426] iteration 20114 : loss : 0.046361, loss_ce: 0.016080
[02:35:08.733] iteration 20115 : loss : 0.125986, loss_ce: 0.011400
[02:35:09.034] iteration 20116 : loss : 0.042740, loss_ce: 0.010439
[02:35:09.332] iteration 20117 : loss : 0.046596, loss_ce: 0.022105
[02:35:09.633] iteration 20118 : loss : 0.050804, loss_ce: 0.014446
[02:35:09.935] iteration 20119 : loss : 0.045279, loss_ce: 0.019089
[02:35:10.235] iteration 20120 : loss : 0.094462, loss_ce: 0.008149
[02:35:10.556] iteration 20121 : loss : 0.034314, loss_ce: 0.011805
[02:35:10.861] iteration 20122 : loss : 0.224764, loss_ce: 0.002226
[02:35:11.161] iteration 20123 : loss : 0.040316, loss_ce: 0.015416
[02:35:11.463] iteration 20124 : loss : 0.054705, loss_ce: 0.004321
[02:35:11.766] iteration 20125 : loss : 0.106261, loss_ce: 0.017554
[02:35:12.066] iteration 20126 : loss : 0.042327, loss_ce: 0.013935
[02:35:12.369] iteration 20127 : loss : 0.048382, loss_ce: 0.010830
[02:35:12.675] iteration 20128 : loss : 0.046557, loss_ce: 0.014504
[02:35:12.974] iteration 20129 : loss : 0.103716, loss_ce: 0.013153
[02:35:13.278] iteration 20130 : loss : 0.031905, loss_ce: 0.004365
[02:35:13.581] iteration 20131 : loss : 0.040548, loss_ce: 0.018172
[02:35:13.882] iteration 20132 : loss : 0.042363, loss_ce: 0.011115
[02:35:14.185] iteration 20133 : loss : 0.032814, loss_ce: 0.011832
[02:35:14.486] iteration 20134 : loss : 0.032064, loss_ce: 0.011547
[02:35:14.789] iteration 20135 : loss : 0.033717, loss_ce: 0.014841
[02:35:15.091] iteration 20136 : loss : 0.054416, loss_ce: 0.016468
[02:35:15.392] iteration 20137 : loss : 0.043289, loss_ce: 0.006714
[02:35:15.694] iteration 20138 : loss : 0.044093, loss_ce: 0.025522
[02:35:15.997] iteration 20139 : loss : 0.034907, loss_ce: 0.008688
[02:35:16.303] iteration 20140 : loss : 0.042021, loss_ce: 0.017142
[02:35:16.639] iteration 20141 : loss : 0.118991, loss_ce: 0.007225
[02:35:16.944] iteration 20142 : loss : 0.048642, loss_ce: 0.013634
[02:35:17.254] iteration 20143 : loss : 0.109087, loss_ce: 0.005879
[02:35:17.558] iteration 20144 : loss : 0.041355, loss_ce: 0.012351
[02:35:17.861] iteration 20145 : loss : 0.043088, loss_ce: 0.011759
[02:35:18.168] iteration 20146 : loss : 0.052904, loss_ce: 0.014606
[02:35:18.478] iteration 20147 : loss : 0.053486, loss_ce: 0.013956
[02:35:18.781] iteration 20148 : loss : 0.046121, loss_ce: 0.016881
[02:35:19.088] iteration 20149 : loss : 0.036409, loss_ce: 0.012530
[02:35:19.401] iteration 20150 : loss : 0.050088, loss_ce: 0.015153
[02:35:19.708] iteration 20151 : loss : 0.080311, loss_ce: 0.022233
[02:35:20.015] iteration 20152 : loss : 0.045811, loss_ce: 0.013680
[02:35:20.321] iteration 20153 : loss : 0.042124, loss_ce: 0.013595
[02:35:20.630] iteration 20154 : loss : 0.039876, loss_ce: 0.009146
[02:35:20.706] iteration 20155 : loss : 0.284296, loss_ce: 0.010467
[02:35:38.177] iteration 20156 : loss : 0.037849, loss_ce: 0.016062
[02:35:38.478] iteration 20157 : loss : 0.060275, loss_ce: 0.013984
[02:35:38.782] iteration 20158 : loss : 0.048352, loss_ce: 0.015021
[02:35:39.085] iteration 20159 : loss : 0.046876, loss_ce: 0.014490
[02:35:39.384] iteration 20160 : loss : 0.047963, loss_ce: 0.010222
[02:35:39.701] iteration 20161 : loss : 0.044552, loss_ce: 0.007967
[02:35:39.998] iteration 20162 : loss : 0.047800, loss_ce: 0.019276
[02:35:40.296] iteration 20163 : loss : 0.043571, loss_ce: 0.014407
[02:35:40.596] iteration 20164 : loss : 0.041131, loss_ce: 0.013968
[02:35:40.891] iteration 20165 : loss : 0.044639, loss_ce: 0.008107
[02:35:41.192] iteration 20166 : loss : 0.038270, loss_ce: 0.015224
[02:35:41.491] iteration 20167 : loss : 0.052144, loss_ce: 0.010362
[02:35:41.789] iteration 20168 : loss : 0.106757, loss_ce: 0.007913
[02:35:42.087] iteration 20169 : loss : 0.050201, loss_ce: 0.015074
[02:35:42.390] iteration 20170 : loss : 0.095444, loss_ce: 0.025249
[02:35:42.688] iteration 20171 : loss : 0.107627, loss_ce: 0.009982
[02:35:42.982] iteration 20172 : loss : 0.108295, loss_ce: 0.012043
[02:35:43.280] iteration 20173 : loss : 0.113018, loss_ce: 0.010337
[02:35:43.574] iteration 20174 : loss : 0.051434, loss_ce: 0.014484
[02:35:43.873] iteration 20175 : loss : 0.036192, loss_ce: 0.011300
[02:35:44.173] iteration 20176 : loss : 0.037194, loss_ce: 0.013698
[02:35:44.480] iteration 20177 : loss : 0.101598, loss_ce: 0.010558
[02:35:44.776] iteration 20178 : loss : 0.052885, loss_ce: 0.007568
[02:35:45.078] iteration 20179 : loss : 0.159254, loss_ce: 0.008693
[02:35:45.375] iteration 20180 : loss : 0.040658, loss_ce: 0.016452
[02:35:45.686] iteration 20181 : loss : 0.030582, loss_ce: 0.007840
[02:35:45.980] iteration 20182 : loss : 0.042275, loss_ce: 0.009937
[02:35:46.276] iteration 20183 : loss : 0.285135, loss_ce: 0.004430
[02:35:46.571] iteration 20184 : loss : 0.048192, loss_ce: 0.014252
[02:35:46.871] iteration 20185 : loss : 0.038322, loss_ce: 0.018405
[02:35:47.167] iteration 20186 : loss : 0.078447, loss_ce: 0.013306
[02:35:47.465] iteration 20187 : loss : 0.126951, loss_ce: 0.010784
[02:35:47.767] iteration 20188 : loss : 0.054709, loss_ce: 0.009063
[02:35:48.065] iteration 20189 : loss : 0.182250, loss_ce: 0.004997
[02:35:48.362] iteration 20190 : loss : 0.037924, loss_ce: 0.005963
[02:35:48.664] iteration 20191 : loss : 0.099296, loss_ce: 0.012601
[02:35:48.960] iteration 20192 : loss : 0.035088, loss_ce: 0.009418
[02:35:49.260] iteration 20193 : loss : 0.049277, loss_ce: 0.015425
[02:35:49.560] iteration 20194 : loss : 0.039707, loss_ce: 0.012960
[02:35:49.858] iteration 20195 : loss : 0.094484, loss_ce: 0.013067
[02:35:50.159] iteration 20196 : loss : 0.038472, loss_ce: 0.013649
[02:35:50.456] iteration 20197 : loss : 0.046685, loss_ce: 0.006358
[02:35:50.753] iteration 20198 : loss : 0.050402, loss_ce: 0.011235
[02:35:51.049] iteration 20199 : loss : 0.047423, loss_ce: 0.008795
[02:35:51.350] iteration 20200 : loss : 0.037355, loss_ce: 0.015863
[02:35:51.665] iteration 20201 : loss : 0.043263, loss_ce: 0.013448
[02:35:51.961] iteration 20202 : loss : 0.040164, loss_ce: 0.008007
[02:35:52.266] iteration 20203 : loss : 0.042004, loss_ce: 0.008060
[02:35:52.569] iteration 20204 : loss : 0.096636, loss_ce: 0.013882
[02:35:52.870] iteration 20205 : loss : 0.050707, loss_ce: 0.022311
[02:35:53.174] iteration 20206 : loss : 0.045683, loss_ce: 0.013798
[02:35:53.480] iteration 20207 : loss : 0.042324, loss_ce: 0.021020
[02:35:53.780] iteration 20208 : loss : 0.041183, loss_ce: 0.014240
[02:35:54.081] iteration 20209 : loss : 0.047345, loss_ce: 0.010772
[02:35:54.389] iteration 20210 : loss : 0.046722, loss_ce: 0.015795
[02:35:54.693] iteration 20211 : loss : 0.128427, loss_ce: 0.012346
[02:35:55.001] iteration 20212 : loss : 0.046329, loss_ce: 0.008709
[02:35:55.301] iteration 20213 : loss : 0.048258, loss_ce: 0.015269
[02:35:55.604] iteration 20214 : loss : 0.051961, loss_ce: 0.007091
[02:35:55.908] iteration 20215 : loss : 0.047946, loss_ce: 0.006715
[02:35:56.207] iteration 20216 : loss : 0.047664, loss_ce: 0.009468
[02:35:56.512] iteration 20217 : loss : 0.050539, loss_ce: 0.007916
[02:35:56.820] iteration 20218 : loss : 0.099810, loss_ce: 0.005854
[02:35:57.120] iteration 20219 : loss : 0.038461, loss_ce: 0.014827
[02:35:57.419] iteration 20220 : loss : 0.159117, loss_ce: 0.006401
[02:35:57.736] iteration 20221 : loss : 0.044181, loss_ce: 0.019431
[02:35:58.038] iteration 20222 : loss : 0.062110, loss_ce: 0.019136
[02:35:58.340] iteration 20223 : loss : 0.034716, loss_ce: 0.005549
[02:35:58.647] iteration 20224 : loss : 0.056304, loss_ce: 0.018627
[02:35:58.949] iteration 20225 : loss : 0.052174, loss_ce: 0.012520
[02:35:59.252] iteration 20226 : loss : 0.103719, loss_ce: 0.009887
[02:35:59.558] iteration 20227 : loss : 0.052501, loss_ce: 0.015037
[02:35:59.858] iteration 20228 : loss : 0.046619, loss_ce: 0.019231
[02:36:00.158] iteration 20229 : loss : 0.046617, loss_ce: 0.014511
[02:36:00.458] iteration 20230 : loss : 0.101760, loss_ce: 0.019529
[02:36:00.760] iteration 20231 : loss : 0.045463, loss_ce: 0.013581
[02:36:01.062] iteration 20232 : loss : 0.055598, loss_ce: 0.013653
[02:36:01.370] iteration 20233 : loss : 0.089452, loss_ce: 0.013509
[02:36:01.674] iteration 20234 : loss : 0.048622, loss_ce: 0.015466
[02:36:01.974] iteration 20235 : loss : 0.047104, loss_ce: 0.019816
[02:36:02.279] iteration 20236 : loss : 0.044100, loss_ce: 0.008454
[02:36:02.582] iteration 20237 : loss : 0.037142, loss_ce: 0.010371
[02:36:02.883] iteration 20238 : loss : 0.041829, loss_ce: 0.007764
[02:36:03.184] iteration 20239 : loss : 0.047377, loss_ce: 0.011304
[02:36:03.487] iteration 20240 : loss : 0.034569, loss_ce: 0.007794
[02:36:03.809] iteration 20241 : loss : 0.103254, loss_ce: 0.011344
[02:36:04.115] iteration 20242 : loss : 0.280283, loss_ce: 0.004998
[02:36:04.423] iteration 20243 : loss : 0.037615, loss_ce: 0.013612
[02:36:04.727] iteration 20244 : loss : 0.103420, loss_ce: 0.009544
[02:36:05.028] iteration 20245 : loss : 0.099706, loss_ce: 0.005914
[02:36:05.329] iteration 20246 : loss : 0.045070, loss_ce: 0.016206
[02:36:05.636] iteration 20247 : loss : 0.035458, loss_ce: 0.007853
[02:36:05.936] iteration 20248 : loss : 0.155784, loss_ce: 0.011776
[02:36:06.239] iteration 20249 : loss : 0.049225, loss_ce: 0.011153
[02:36:06.546] iteration 20250 : loss : 0.049109, loss_ce: 0.019357
[02:36:06.849] iteration 20251 : loss : 0.110646, loss_ce: 0.010211
[02:36:07.154] iteration 20252 : loss : 0.042002, loss_ce: 0.017339
[02:36:07.454] iteration 20253 : loss : 0.111440, loss_ce: 0.009750
[02:36:07.758] iteration 20254 : loss : 0.043496, loss_ce: 0.014862
[02:36:08.060] iteration 20255 : loss : 0.054898, loss_ce: 0.015361
[02:36:08.360] iteration 20256 : loss : 0.057198, loss_ce: 0.012923
[02:36:08.668] iteration 20257 : loss : 0.059090, loss_ce: 0.016618
[02:36:08.972] iteration 20258 : loss : 0.036989, loss_ce: 0.010723
[02:36:09.273] iteration 20259 : loss : 0.040888, loss_ce: 0.019865
[02:36:09.579] iteration 20260 : loss : 0.039550, loss_ce: 0.014001
[02:36:09.900] iteration 20261 : loss : 0.046400, loss_ce: 0.017104
[02:36:10.202] iteration 20262 : loss : 0.041945, loss_ce: 0.014425
[02:36:10.505] iteration 20263 : loss : 0.042158, loss_ce: 0.021208
[02:36:10.810] iteration 20264 : loss : 0.047355, loss_ce: 0.018369
[02:36:11.115] iteration 20265 : loss : 0.164718, loss_ce: 0.005522
[02:36:11.414] iteration 20266 : loss : 0.043512, loss_ce: 0.019879
[02:36:11.715] iteration 20267 : loss : 0.034554, loss_ce: 0.007995
[02:36:12.007] iteration 20268 : loss : 0.037217, loss_ce: 0.010512
[02:36:12.308] iteration 20269 : loss : 0.039489, loss_ce: 0.009049
[02:36:12.606] iteration 20270 : loss : 0.044461, loss_ce: 0.009428
[02:36:12.904] iteration 20271 : loss : 0.051396, loss_ce: 0.015323
[02:36:13.206] iteration 20272 : loss : 0.053312, loss_ce: 0.016687
[02:36:13.504] iteration 20273 : loss : 0.092929, loss_ce: 0.012160
[02:36:13.800] iteration 20274 : loss : 0.035067, loss_ce: 0.014057
[02:36:14.098] iteration 20275 : loss : 0.042115, loss_ce: 0.014189
[02:36:14.399] iteration 20276 : loss : 0.061050, loss_ce: 0.016680
[02:36:14.698] iteration 20277 : loss : 0.046042, loss_ce: 0.015223
[02:36:15.003] iteration 20278 : loss : 0.047084, loss_ce: 0.021996
[02:36:15.304] iteration 20279 : loss : 0.036843, loss_ce: 0.009990
[02:36:15.607] iteration 20280 : loss : 0.038527, loss_ce: 0.014919
[02:36:15.935] iteration 20281 : loss : 0.172065, loss_ce: 0.007738
[02:36:16.234] iteration 20282 : loss : 0.040482, loss_ce: 0.013063
[02:36:16.536] iteration 20283 : loss : 0.046325, loss_ce: 0.013060
[02:36:16.840] iteration 20284 : loss : 0.049958, loss_ce: 0.020555
[02:36:17.141] iteration 20285 : loss : 0.048064, loss_ce: 0.019055
[02:36:17.448] iteration 20286 : loss : 0.043128, loss_ce: 0.016389
[02:36:17.748] iteration 20287 : loss : 0.045048, loss_ce: 0.015687
[02:36:18.045] iteration 20288 : loss : 0.040783, loss_ce: 0.023454
[02:36:18.352] iteration 20289 : loss : 0.144565, loss_ce: 0.010574
[02:36:18.648] iteration 20290 : loss : 0.039758, loss_ce: 0.016186
[02:36:18.952] iteration 20291 : loss : 0.051089, loss_ce: 0.018879
[02:36:19.251] iteration 20292 : loss : 0.041530, loss_ce: 0.012876
[02:36:19.557] iteration 20293 : loss : 0.037161, loss_ce: 0.008905
[02:36:19.634] iteration 20294 : loss : 0.236309, loss_ce: 0.008570
[02:36:38.607] iteration 20295 : loss : 0.151419, loss_ce: 0.004908
[02:36:38.914] iteration 20296 : loss : 0.059778, loss_ce: 0.013857
[02:36:39.223] iteration 20297 : loss : 0.115538, loss_ce: 0.010575
[02:36:39.530] iteration 20298 : loss : 0.097139, loss_ce: 0.008388
[02:36:39.837] iteration 20299 : loss : 0.041552, loss_ce: 0.006773
[02:36:40.144] iteration 20300 : loss : 0.050151, loss_ce: 0.017936
[02:36:40.460] iteration 20301 : loss : 0.046385, loss_ce: 0.017140
[02:36:40.760] iteration 20302 : loss : 0.040227, loss_ce: 0.017699
[02:36:41.063] iteration 20303 : loss : 0.039637, loss_ce: 0.009441
[02:36:41.358] iteration 20304 : loss : 0.036170, loss_ce: 0.010068
[02:36:41.659] iteration 20305 : loss : 0.051433, loss_ce: 0.015301
[02:36:41.957] iteration 20306 : loss : 0.050956, loss_ce: 0.013437
[02:36:42.254] iteration 20307 : loss : 0.054040, loss_ce: 0.020436
[02:36:42.550] iteration 20308 : loss : 0.053551, loss_ce: 0.013412
[02:36:42.845] iteration 20309 : loss : 0.040665, loss_ce: 0.009263
[02:36:43.144] iteration 20310 : loss : 0.043277, loss_ce: 0.014003
[02:36:43.449] iteration 20311 : loss : 0.047399, loss_ce: 0.016334
[02:36:43.751] iteration 20312 : loss : 0.094262, loss_ce: 0.010507
[02:36:44.048] iteration 20313 : loss : 0.102471, loss_ce: 0.005783
[02:36:44.345] iteration 20314 : loss : 0.049522, loss_ce: 0.014667
[02:36:44.641] iteration 20315 : loss : 0.039835, loss_ce: 0.007772
[02:36:44.945] iteration 20316 : loss : 0.037993, loss_ce: 0.008278
[02:36:45.244] iteration 20317 : loss : 0.288862, loss_ce: 0.005299
[02:36:45.539] iteration 20318 : loss : 0.095007, loss_ce: 0.012474
[02:36:45.841] iteration 20319 : loss : 0.107016, loss_ce: 0.014303
[02:36:46.137] iteration 20320 : loss : 0.046885, loss_ce: 0.016663
[02:36:46.454] iteration 20321 : loss : 0.038454, loss_ce: 0.016749
[02:36:46.747] iteration 20322 : loss : 0.038160, loss_ce: 0.013146
[02:36:47.045] iteration 20323 : loss : 0.052647, loss_ce: 0.019384
[02:36:47.343] iteration 20324 : loss : 0.047893, loss_ce: 0.011646
[02:36:47.644] iteration 20325 : loss : 0.045327, loss_ce: 0.014301
[02:36:47.938] iteration 20326 : loss : 0.034065, loss_ce: 0.011368
[02:36:48.235] iteration 20327 : loss : 0.105250, loss_ce: 0.006414
[02:36:48.531] iteration 20328 : loss : 0.040123, loss_ce: 0.021019
[02:36:48.829] iteration 20329 : loss : 0.038969, loss_ce: 0.012422
[02:36:49.126] iteration 20330 : loss : 0.038302, loss_ce: 0.017831
[02:36:49.423] iteration 20331 : loss : 0.045829, loss_ce: 0.015386
[02:36:49.725] iteration 20332 : loss : 0.037350, loss_ce: 0.008448
[02:36:50.016] iteration 20333 : loss : 0.054175, loss_ce: 0.011354
[02:36:50.313] iteration 20334 : loss : 0.044077, loss_ce: 0.014079
[02:36:50.616] iteration 20335 : loss : 0.033536, loss_ce: 0.012380
[02:36:50.913] iteration 20336 : loss : 0.038025, loss_ce: 0.006607
[02:36:51.211] iteration 20337 : loss : 0.044881, loss_ce: 0.014313
[02:36:51.507] iteration 20338 : loss : 0.035188, loss_ce: 0.008704
[02:36:51.810] iteration 20339 : loss : 0.032861, loss_ce: 0.011407
[02:36:52.106] iteration 20340 : loss : 0.054106, loss_ce: 0.020879
[02:36:52.420] iteration 20341 : loss : 0.035950, loss_ce: 0.006957
[02:36:52.718] iteration 20342 : loss : 0.044718, loss_ce: 0.015148
[02:36:53.018] iteration 20343 : loss : 0.132984, loss_ce: 0.009495
[02:36:53.318] iteration 20344 : loss : 0.044975, loss_ce: 0.009476
[02:36:53.616] iteration 20345 : loss : 0.043405, loss_ce: 0.020118
[02:36:53.919] iteration 20346 : loss : 0.107410, loss_ce: 0.020507
[02:36:54.223] iteration 20347 : loss : 0.099820, loss_ce: 0.006083
[02:36:54.526] iteration 20348 : loss : 0.048873, loss_ce: 0.010258
[02:36:54.832] iteration 20349 : loss : 0.046240, loss_ce: 0.018620
[02:36:55.138] iteration 20350 : loss : 0.040793, loss_ce: 0.018976
[02:36:55.440] iteration 20351 : loss : 0.100777, loss_ce: 0.013424
[02:36:55.744] iteration 20352 : loss : 0.042959, loss_ce: 0.014621
[02:36:56.053] iteration 20353 : loss : 0.098820, loss_ce: 0.011239
[02:36:56.355] iteration 20354 : loss : 0.035199, loss_ce: 0.015094
[02:36:56.656] iteration 20355 : loss : 0.041048, loss_ce: 0.014224
[02:36:56.947] iteration 20356 : loss : 0.101801, loss_ce: 0.009053
[02:36:57.240] iteration 20357 : loss : 0.043457, loss_ce: 0.017598
[02:36:57.538] iteration 20358 : loss : 0.099821, loss_ce: 0.010805
[02:36:57.835] iteration 20359 : loss : 0.035501, loss_ce: 0.014206
[02:36:58.131] iteration 20360 : loss : 0.051251, loss_ce: 0.011234
[02:36:58.446] iteration 20361 : loss : 0.274176, loss_ce: 0.006928
[02:36:58.747] iteration 20362 : loss : 0.118076, loss_ce: 0.006793
[02:36:59.041] iteration 20363 : loss : 0.041350, loss_ce: 0.010189
[02:36:59.340] iteration 20364 : loss : 0.043264, loss_ce: 0.015103
[02:36:59.641] iteration 20365 : loss : 0.038231, loss_ce: 0.008369
[02:36:59.938] iteration 20366 : loss : 0.044255, loss_ce: 0.014926
[02:37:00.233] iteration 20367 : loss : 0.053766, loss_ce: 0.014285
[02:37:00.535] iteration 20368 : loss : 0.035350, loss_ce: 0.010857
[02:37:00.834] iteration 20369 : loss : 0.047028, loss_ce: 0.014947
[02:37:01.137] iteration 20370 : loss : 0.040933, loss_ce: 0.014735
[02:37:01.433] iteration 20371 : loss : 0.043446, loss_ce: 0.009839
[02:37:01.728] iteration 20372 : loss : 0.049291, loss_ce: 0.003593
[02:37:02.028] iteration 20373 : loss : 0.042048, loss_ce: 0.017221
[02:37:02.331] iteration 20374 : loss : 0.041242, loss_ce: 0.009301
[02:37:02.629] iteration 20375 : loss : 0.054027, loss_ce: 0.015124
[02:37:02.924] iteration 20376 : loss : 0.039341, loss_ce: 0.009362
[02:37:03.222] iteration 20377 : loss : 0.106537, loss_ce: 0.007111
[02:37:03.521] iteration 20378 : loss : 0.034618, loss_ce: 0.010639
[02:37:03.825] iteration 20379 : loss : 0.100013, loss_ce: 0.012596
[02:37:04.121] iteration 20380 : loss : 0.043784, loss_ce: 0.015190
[02:37:04.441] iteration 20381 : loss : 0.040491, loss_ce: 0.011091
[02:37:04.740] iteration 20382 : loss : 0.104643, loss_ce: 0.010368
[02:37:05.036] iteration 20383 : loss : 0.043524, loss_ce: 0.015420
[02:37:05.337] iteration 20384 : loss : 0.043721, loss_ce: 0.008276
[02:37:05.637] iteration 20385 : loss : 0.057815, loss_ce: 0.018100
[02:37:05.934] iteration 20386 : loss : 0.047550, loss_ce: 0.019487
[02:37:06.226] iteration 20387 : loss : 0.046048, loss_ce: 0.010295
[02:37:06.531] iteration 20388 : loss : 0.158097, loss_ce: 0.008894
[02:37:06.829] iteration 20389 : loss : 0.038162, loss_ce: 0.010271
[02:37:07.124] iteration 20390 : loss : 0.039188, loss_ce: 0.008879
[02:37:07.420] iteration 20391 : loss : 0.038720, loss_ce: 0.012204
[02:37:07.718] iteration 20392 : loss : 0.048915, loss_ce: 0.012758
[02:37:08.018] iteration 20393 : loss : 0.043494, loss_ce: 0.011606
[02:37:08.312] iteration 20394 : loss : 0.105390, loss_ce: 0.007617
[02:37:08.616] iteration 20395 : loss : 0.044068, loss_ce: 0.022425
[02:37:08.918] iteration 20396 : loss : 0.049427, loss_ce: 0.017532
[02:37:09.214] iteration 20397 : loss : 0.045017, loss_ce: 0.019530
[02:37:09.517] iteration 20398 : loss : 0.214833, loss_ce: 0.003930
[02:37:09.819] iteration 20399 : loss : 0.034576, loss_ce: 0.005800
[02:37:10.125] iteration 20400 : loss : 0.039310, loss_ce: 0.013807
[02:37:10.437] iteration 20401 : loss : 0.052646, loss_ce: 0.017597
[02:37:10.740] iteration 20402 : loss : 0.059968, loss_ce: 0.016341
[02:37:11.039] iteration 20403 : loss : 0.042375, loss_ce: 0.012096
[02:37:11.336] iteration 20404 : loss : 0.124987, loss_ce: 0.007707
[02:37:11.637] iteration 20405 : loss : 0.042070, loss_ce: 0.016448
[02:37:11.949] iteration 20406 : loss : 0.105475, loss_ce: 0.013652
[02:37:12.251] iteration 20407 : loss : 0.038577, loss_ce: 0.016755
[02:37:12.555] iteration 20408 : loss : 0.281726, loss_ce: 0.005408
[02:37:12.858] iteration 20409 : loss : 0.042216, loss_ce: 0.013706
[02:37:13.162] iteration 20410 : loss : 0.041486, loss_ce: 0.013428
[02:37:13.464] iteration 20411 : loss : 0.051537, loss_ce: 0.016328
[02:37:13.772] iteration 20412 : loss : 0.037870, loss_ce: 0.011866
[02:37:14.074] iteration 20413 : loss : 0.046461, loss_ce: 0.009193
[02:37:14.379] iteration 20414 : loss : 0.043108, loss_ce: 0.017740
[02:37:14.685] iteration 20415 : loss : 0.037401, loss_ce: 0.014183
[02:37:14.985] iteration 20416 : loss : 0.062211, loss_ce: 0.018040
[02:37:15.286] iteration 20417 : loss : 0.040853, loss_ce: 0.016640
[02:37:15.599] iteration 20418 : loss : 0.043733, loss_ce: 0.018611
[02:37:15.909] iteration 20419 : loss : 0.053301, loss_ce: 0.016673
[02:37:16.214] iteration 20420 : loss : 0.040833, loss_ce: 0.018032
[02:37:16.543] iteration 20421 : loss : 0.050886, loss_ce: 0.015515
[02:37:16.860] iteration 20422 : loss : 0.048110, loss_ce: 0.018159
[02:37:17.162] iteration 20423 : loss : 0.107697, loss_ce: 0.015536
[02:37:17.472] iteration 20424 : loss : 0.090098, loss_ce: 0.010803
[02:37:17.777] iteration 20425 : loss : 0.047233, loss_ce: 0.007322
[02:37:18.080] iteration 20426 : loss : 0.155368, loss_ce: 0.005501
[02:37:18.388] iteration 20427 : loss : 0.050496, loss_ce: 0.022159
[02:37:18.696] iteration 20428 : loss : 0.031420, loss_ce: 0.008830
[02:37:19.003] iteration 20429 : loss : 0.049316, loss_ce: 0.025543
[02:37:19.311] iteration 20430 : loss : 0.045064, loss_ce: 0.009631
[02:37:19.622] iteration 20431 : loss : 0.038723, loss_ce: 0.013756
[02:37:19.929] iteration 20432 : loss : 0.048849, loss_ce: 0.013819
[02:37:20.009] iteration 20433 : loss : 0.342507, loss_ce: 0.001581
[02:37:37.344] iteration 20434 : loss : 0.035978, loss_ce: 0.012487
[02:37:37.650] iteration 20435 : loss : 0.040269, loss_ce: 0.011521
[02:37:37.953] iteration 20436 : loss : 0.058685, loss_ce: 0.017507
[02:37:38.260] iteration 20437 : loss : 0.045664, loss_ce: 0.018613
[02:37:38.561] iteration 20438 : loss : 0.050470, loss_ce: 0.010613
[02:37:38.862] iteration 20439 : loss : 0.046570, loss_ce: 0.007504
[02:37:39.164] iteration 20440 : loss : 0.038822, loss_ce: 0.014304
[02:37:39.486] iteration 20441 : loss : 0.096161, loss_ce: 0.006329
[02:37:39.782] iteration 20442 : loss : 0.050142, loss_ce: 0.018036
[02:37:40.084] iteration 20443 : loss : 0.043290, loss_ce: 0.015614
[02:37:40.381] iteration 20444 : loss : 0.041250, loss_ce: 0.014402
[02:37:40.677] iteration 20445 : loss : 0.044600, loss_ce: 0.016034
[02:37:40.973] iteration 20446 : loss : 0.052349, loss_ce: 0.025919
[02:37:41.269] iteration 20447 : loss : 0.097316, loss_ce: 0.011656
[02:37:41.563] iteration 20448 : loss : 0.046194, loss_ce: 0.014103
[02:37:41.859] iteration 20449 : loss : 0.044324, loss_ce: 0.009216
[02:37:42.156] iteration 20450 : loss : 0.034533, loss_ce: 0.013141
[02:37:42.455] iteration 20451 : loss : 0.098414, loss_ce: 0.012266
[02:37:42.752] iteration 20452 : loss : 0.039865, loss_ce: 0.014582
[02:37:43.050] iteration 20453 : loss : 0.064602, loss_ce: 0.010521
[02:37:43.350] iteration 20454 : loss : 0.049107, loss_ce: 0.015125
[02:37:43.647] iteration 20455 : loss : 0.059362, loss_ce: 0.010476
[02:37:43.944] iteration 20456 : loss : 0.043021, loss_ce: 0.016264
[02:37:44.245] iteration 20457 : loss : 0.045719, loss_ce: 0.016078
[02:37:44.546] iteration 20458 : loss : 0.043590, loss_ce: 0.016131
[02:37:44.849] iteration 20459 : loss : 0.035949, loss_ce: 0.006504
[02:37:45.156] iteration 20460 : loss : 0.039567, loss_ce: 0.010397
[02:37:45.476] iteration 20461 : loss : 0.047721, loss_ce: 0.012268
[02:37:45.782] iteration 20462 : loss : 0.036519, loss_ce: 0.014321
[02:37:46.082] iteration 20463 : loss : 0.040189, loss_ce: 0.008556
[02:37:46.383] iteration 20464 : loss : 0.054026, loss_ce: 0.010539
[02:37:46.675] iteration 20465 : loss : 0.046430, loss_ce: 0.020634
[02:37:46.975] iteration 20466 : loss : 0.044605, loss_ce: 0.012190
[02:37:47.271] iteration 20467 : loss : 0.039142, loss_ce: 0.013412
[02:37:47.572] iteration 20468 : loss : 0.039801, loss_ce: 0.013116
[02:37:47.871] iteration 20469 : loss : 0.042561, loss_ce: 0.011278
[02:37:48.171] iteration 20470 : loss : 0.037620, loss_ce: 0.016648
[02:37:48.470] iteration 20471 : loss : 0.060662, loss_ce: 0.010097
[02:37:48.768] iteration 20472 : loss : 0.038049, loss_ce: 0.012626
[02:37:49.064] iteration 20473 : loss : 0.037220, loss_ce: 0.016869
[02:37:49.359] iteration 20474 : loss : 0.044556, loss_ce: 0.020126
[02:37:49.658] iteration 20475 : loss : 0.051983, loss_ce: 0.010575
[02:37:49.955] iteration 20476 : loss : 0.042682, loss_ce: 0.018219
[02:37:50.253] iteration 20477 : loss : 0.050548, loss_ce: 0.013083
[02:37:50.555] iteration 20478 : loss : 0.056246, loss_ce: 0.011560
[02:37:50.856] iteration 20479 : loss : 0.048067, loss_ce: 0.009897
[02:37:51.152] iteration 20480 : loss : 0.041218, loss_ce: 0.013173
[02:37:51.468] iteration 20481 : loss : 0.043422, loss_ce: 0.012663
[02:37:51.763] iteration 20482 : loss : 0.046645, loss_ce: 0.021900
[02:37:52.064] iteration 20483 : loss : 0.098644, loss_ce: 0.010040
[02:37:52.356] iteration 20484 : loss : 0.044045, loss_ce: 0.007490
[02:37:52.654] iteration 20485 : loss : 0.115869, loss_ce: 0.010617
[02:37:52.950] iteration 20486 : loss : 0.047405, loss_ce: 0.011337
[02:37:53.246] iteration 20487 : loss : 0.102604, loss_ce: 0.008386
[02:37:53.544] iteration 20488 : loss : 0.056484, loss_ce: 0.010052
[02:37:53.841] iteration 20489 : loss : 0.097379, loss_ce: 0.007467
[02:37:54.143] iteration 20490 : loss : 0.044374, loss_ce: 0.011711
[02:37:54.442] iteration 20491 : loss : 0.049133, loss_ce: 0.018853
[02:37:54.736] iteration 20492 : loss : 0.033782, loss_ce: 0.005157
[02:37:55.044] iteration 20493 : loss : 0.096466, loss_ce: 0.007354
[02:37:55.343] iteration 20494 : loss : 0.126150, loss_ce: 0.016738
[02:37:55.641] iteration 20495 : loss : 0.053690, loss_ce: 0.014333
[02:37:55.937] iteration 20496 : loss : 0.094106, loss_ce: 0.008275
[02:37:56.234] iteration 20497 : loss : 0.034124, loss_ce: 0.012943
[02:37:56.530] iteration 20498 : loss : 0.045611, loss_ce: 0.019274
[02:37:56.836] iteration 20499 : loss : 0.035352, loss_ce: 0.010093
[02:37:57.135] iteration 20500 : loss : 0.043199, loss_ce: 0.016702
[02:37:57.455] iteration 20501 : loss : 0.040845, loss_ce: 0.014537
[02:37:57.755] iteration 20502 : loss : 0.048349, loss_ce: 0.025612
[02:37:58.049] iteration 20503 : loss : 0.072343, loss_ce: 0.014018
[02:37:58.349] iteration 20504 : loss : 0.099941, loss_ce: 0.009855
[02:37:58.650] iteration 20505 : loss : 0.039516, loss_ce: 0.009315
[02:37:58.944] iteration 20506 : loss : 0.042400, loss_ce: 0.008594
[02:37:59.246] iteration 20507 : loss : 0.042341, loss_ce: 0.011445
[02:37:59.550] iteration 20508 : loss : 0.100139, loss_ce: 0.006764
[02:37:59.852] iteration 20509 : loss : 0.057510, loss_ce: 0.014634
[02:38:00.161] iteration 20510 : loss : 0.052553, loss_ce: 0.013515
[02:38:00.464] iteration 20511 : loss : 0.058262, loss_ce: 0.010168
[02:38:00.765] iteration 20512 : loss : 0.041764, loss_ce: 0.010235
[02:38:01.067] iteration 20513 : loss : 0.047516, loss_ce: 0.012217
[02:38:01.370] iteration 20514 : loss : 0.041824, loss_ce: 0.016706
[02:38:01.666] iteration 20515 : loss : 0.037097, loss_ce: 0.007499
[02:38:01.966] iteration 20516 : loss : 0.048805, loss_ce: 0.011772
[02:38:02.262] iteration 20517 : loss : 0.047172, loss_ce: 0.009523
[02:38:02.559] iteration 20518 : loss : 0.033585, loss_ce: 0.010372
[02:38:02.859] iteration 20519 : loss : 0.040053, loss_ce: 0.018108
[02:38:03.157] iteration 20520 : loss : 0.041647, loss_ce: 0.013643
[02:38:03.475] iteration 20521 : loss : 0.039180, loss_ce: 0.020413
[02:38:03.766] iteration 20522 : loss : 0.101786, loss_ce: 0.003801
[02:38:04.063] iteration 20523 : loss : 0.105923, loss_ce: 0.011887
[02:38:04.360] iteration 20524 : loss : 0.055457, loss_ce: 0.012707
[02:38:04.658] iteration 20525 : loss : 0.042540, loss_ce: 0.022863
[02:38:04.954] iteration 20526 : loss : 0.036778, loss_ce: 0.008337
[02:38:05.251] iteration 20527 : loss : 0.104221, loss_ce: 0.009583
[02:38:05.543] iteration 20528 : loss : 0.050933, loss_ce: 0.023060
[02:38:05.843] iteration 20529 : loss : 0.051015, loss_ce: 0.017003
[02:38:06.142] iteration 20530 : loss : 0.100360, loss_ce: 0.013068
[02:38:06.440] iteration 20531 : loss : 0.043384, loss_ce: 0.010260
[02:38:06.739] iteration 20532 : loss : 0.047899, loss_ce: 0.006427
[02:38:07.034] iteration 20533 : loss : 0.045778, loss_ce: 0.011137
[02:38:07.334] iteration 20534 : loss : 0.050453, loss_ce: 0.013375
[02:38:07.633] iteration 20535 : loss : 0.096426, loss_ce: 0.008566
[02:38:07.927] iteration 20536 : loss : 0.044926, loss_ce: 0.013214
[02:38:08.226] iteration 20537 : loss : 0.039644, loss_ce: 0.009046
[02:38:08.533] iteration 20538 : loss : 0.041869, loss_ce: 0.021975
[02:38:08.831] iteration 20539 : loss : 0.040679, loss_ce: 0.011156
[02:38:09.130] iteration 20540 : loss : 0.110893, loss_ce: 0.008869
[02:38:09.450] iteration 20541 : loss : 0.046049, loss_ce: 0.017105
[02:38:09.742] iteration 20542 : loss : 0.118013, loss_ce: 0.009637
[02:38:10.040] iteration 20543 : loss : 0.111544, loss_ce: 0.009135
[02:38:10.339] iteration 20544 : loss : 0.101538, loss_ce: 0.008132
[02:38:10.638] iteration 20545 : loss : 0.044285, loss_ce: 0.009106
[02:38:10.935] iteration 20546 : loss : 0.044901, loss_ce: 0.023072
[02:38:11.229] iteration 20547 : loss : 0.051993, loss_ce: 0.008161
[02:38:11.524] iteration 20548 : loss : 0.039654, loss_ce: 0.015848
[02:38:11.818] iteration 20549 : loss : 0.041755, loss_ce: 0.016284
[02:38:12.118] iteration 20550 : loss : 0.044966, loss_ce: 0.019455
[02:38:12.414] iteration 20551 : loss : 0.118320, loss_ce: 0.004642
[02:38:12.708] iteration 20552 : loss : 0.100337, loss_ce: 0.008746
[02:38:13.002] iteration 20553 : loss : 0.039864, loss_ce: 0.014578
[02:38:13.303] iteration 20554 : loss : 0.047913, loss_ce: 0.009747
[02:38:13.596] iteration 20555 : loss : 0.110247, loss_ce: 0.010134
[02:38:13.897] iteration 20556 : loss : 0.102933, loss_ce: 0.006529
[02:38:14.205] iteration 20557 : loss : 0.058118, loss_ce: 0.013718
[02:38:14.508] iteration 20558 : loss : 0.046617, loss_ce: 0.010794
[02:38:14.806] iteration 20559 : loss : 0.054689, loss_ce: 0.016172
[02:38:15.106] iteration 20560 : loss : 0.061687, loss_ce: 0.019875
[02:38:15.422] iteration 20561 : loss : 0.027072, loss_ce: 0.006128
[02:38:15.724] iteration 20562 : loss : 0.044259, loss_ce: 0.022186
[02:38:16.030] iteration 20563 : loss : 0.039372, loss_ce: 0.009682
[02:38:16.330] iteration 20564 : loss : 0.052647, loss_ce: 0.014450
[02:38:16.642] iteration 20565 : loss : 0.049730, loss_ce: 0.018525
[02:38:16.944] iteration 20566 : loss : 0.043443, loss_ce: 0.013838
[02:38:17.247] iteration 20567 : loss : 0.043889, loss_ce: 0.013276
[02:38:17.547] iteration 20568 : loss : 0.043636, loss_ce: 0.011431
[02:38:17.852] iteration 20569 : loss : 0.037124, loss_ce: 0.009456
[02:38:18.160] iteration 20570 : loss : 0.040614, loss_ce: 0.008528
[02:38:18.459] iteration 20571 : loss : 0.046174, loss_ce: 0.017280
[02:38:18.537] iteration 20572 : loss : 0.051129, loss_ce: 0.022788
[02:38:37.718] iteration 20573 : loss : 0.046630, loss_ce: 0.015624
[02:38:38.024] iteration 20574 : loss : 0.103346, loss_ce: 0.007361
[02:38:38.325] iteration 20575 : loss : 0.047527, loss_ce: 0.014129
[02:38:38.628] iteration 20576 : loss : 0.101101, loss_ce: 0.019600
[02:38:38.928] iteration 20577 : loss : 0.171161, loss_ce: 0.018913
[02:38:39.229] iteration 20578 : loss : 0.073978, loss_ce: 0.015525
[02:38:39.526] iteration 20579 : loss : 0.069872, loss_ce: 0.015249
[02:38:39.823] iteration 20580 : loss : 0.034544, loss_ce: 0.009540
[02:38:40.134] iteration 20581 : loss : 0.059946, loss_ce: 0.008741
[02:38:40.435] iteration 20582 : loss : 0.044159, loss_ce: 0.021606
[02:38:40.731] iteration 20583 : loss : 0.051244, loss_ce: 0.010532
[02:38:41.026] iteration 20584 : loss : 0.035811, loss_ce: 0.013546
[02:38:41.323] iteration 20585 : loss : 0.042238, loss_ce: 0.014197
[02:38:41.622] iteration 20586 : loss : 0.042401, loss_ce: 0.018104
[02:38:41.919] iteration 20587 : loss : 0.042139, loss_ce: 0.009934
[02:38:42.218] iteration 20588 : loss : 0.085626, loss_ce: 0.011048
[02:38:42.511] iteration 20589 : loss : 0.049854, loss_ce: 0.009806
[02:38:42.809] iteration 20590 : loss : 0.048778, loss_ce: 0.005730
[02:38:43.106] iteration 20591 : loss : 0.047704, loss_ce: 0.012363
[02:38:43.405] iteration 20592 : loss : 0.047349, loss_ce: 0.015389
[02:38:43.708] iteration 20593 : loss : 0.107377, loss_ce: 0.009099
[02:38:44.011] iteration 20594 : loss : 0.033428, loss_ce: 0.008763
[02:38:44.312] iteration 20595 : loss : 0.077343, loss_ce: 0.007884
[02:38:44.610] iteration 20596 : loss : 0.050039, loss_ce: 0.017119
[02:38:44.908] iteration 20597 : loss : 0.110284, loss_ce: 0.008184
[02:38:45.204] iteration 20598 : loss : 0.100492, loss_ce: 0.016022
[02:38:45.495] iteration 20599 : loss : 0.041768, loss_ce: 0.010811
[02:38:45.790] iteration 20600 : loss : 0.033739, loss_ce: 0.010063
[02:38:46.101] iteration 20601 : loss : 0.040602, loss_ce: 0.020366
[02:38:46.396] iteration 20602 : loss : 0.041813, loss_ce: 0.016462
[02:38:46.697] iteration 20603 : loss : 0.072061, loss_ce: 0.009991
[02:38:46.997] iteration 20604 : loss : 0.044166, loss_ce: 0.010995
[02:38:47.294] iteration 20605 : loss : 0.034602, loss_ce: 0.008678
[02:38:47.596] iteration 20606 : loss : 0.052546, loss_ce: 0.019030
[02:38:47.897] iteration 20607 : loss : 0.095462, loss_ce: 0.011882
[02:38:48.194] iteration 20608 : loss : 0.071105, loss_ce: 0.021592
[02:38:48.496] iteration 20609 : loss : 0.042680, loss_ce: 0.012250
[02:38:48.789] iteration 20610 : loss : 0.043086, loss_ce: 0.013549
[02:38:49.089] iteration 20611 : loss : 0.043707, loss_ce: 0.019355
[02:38:49.390] iteration 20612 : loss : 0.056108, loss_ce: 0.008250
[02:38:49.694] iteration 20613 : loss : 0.037535, loss_ce: 0.010724
[02:38:49.999] iteration 20614 : loss : 0.039300, loss_ce: 0.015957
[02:38:50.302] iteration 20615 : loss : 0.040317, loss_ce: 0.015365
[02:38:50.605] iteration 20616 : loss : 0.159716, loss_ce: 0.010844
[02:38:50.916] iteration 20617 : loss : 0.062141, loss_ce: 0.017432
[02:38:51.221] iteration 20618 : loss : 0.135331, loss_ce: 0.010745
[02:38:51.517] iteration 20619 : loss : 0.057538, loss_ce: 0.018687
[02:38:51.818] iteration 20620 : loss : 0.034140, loss_ce: 0.006021
[02:38:52.136] iteration 20621 : loss : 0.039112, loss_ce: 0.008584
[02:38:52.434] iteration 20622 : loss : 0.034923, loss_ce: 0.011885
[02:38:52.729] iteration 20623 : loss : 0.043086, loss_ce: 0.014598
[02:38:53.029] iteration 20624 : loss : 0.038673, loss_ce: 0.008661
[02:38:53.330] iteration 20625 : loss : 0.044537, loss_ce: 0.024476
[02:38:53.628] iteration 20626 : loss : 0.067503, loss_ce: 0.014879
[02:38:53.926] iteration 20627 : loss : 0.103748, loss_ce: 0.009136
[02:38:54.222] iteration 20628 : loss : 0.051125, loss_ce: 0.006678
[02:38:54.520] iteration 20629 : loss : 0.108931, loss_ce: 0.015940
[02:38:54.820] iteration 20630 : loss : 0.042517, loss_ce: 0.017672
[02:38:55.114] iteration 20631 : loss : 0.106758, loss_ce: 0.014960
[02:38:55.410] iteration 20632 : loss : 0.043728, loss_ce: 0.009435
[02:38:55.708] iteration 20633 : loss : 0.118612, loss_ce: 0.009863
[02:38:56.002] iteration 20634 : loss : 0.040411, loss_ce: 0.014266
[02:38:56.298] iteration 20635 : loss : 0.281894, loss_ce: 0.006812
[02:38:56.597] iteration 20636 : loss : 0.045509, loss_ce: 0.013891
[02:38:56.892] iteration 20637 : loss : 0.040474, loss_ce: 0.017314
[02:38:57.196] iteration 20638 : loss : 0.043610, loss_ce: 0.012730
[02:38:57.493] iteration 20639 : loss : 0.050500, loss_ce: 0.012422
[02:38:57.790] iteration 20640 : loss : 0.036620, loss_ce: 0.016260
[02:38:58.109] iteration 20641 : loss : 0.040002, loss_ce: 0.013275
[02:38:58.405] iteration 20642 : loss : 0.048649, loss_ce: 0.017747
[02:38:58.701] iteration 20643 : loss : 0.049285, loss_ce: 0.014404
[02:38:58.998] iteration 20644 : loss : 0.156313, loss_ce: 0.011174
[02:38:59.295] iteration 20645 : loss : 0.098999, loss_ce: 0.005153
[02:38:59.591] iteration 20646 : loss : 0.049318, loss_ce: 0.012620
[02:38:59.891] iteration 20647 : loss : 0.041535, loss_ce: 0.012295
[02:39:00.198] iteration 20648 : loss : 0.160491, loss_ce: 0.007439
[02:39:00.496] iteration 20649 : loss : 0.048309, loss_ce: 0.009759
[02:39:00.795] iteration 20650 : loss : 0.044647, loss_ce: 0.005396
[02:39:01.095] iteration 20651 : loss : 0.046717, loss_ce: 0.013925
[02:39:01.396] iteration 20652 : loss : 0.056831, loss_ce: 0.012009
[02:39:01.696] iteration 20653 : loss : 0.094881, loss_ce: 0.010815
[02:39:01.997] iteration 20654 : loss : 0.043602, loss_ce: 0.014735
[02:39:02.299] iteration 20655 : loss : 0.050030, loss_ce: 0.015163
[02:39:02.598] iteration 20656 : loss : 0.049478, loss_ce: 0.008183
[02:39:02.895] iteration 20657 : loss : 0.046796, loss_ce: 0.012170
[02:39:03.197] iteration 20658 : loss : 0.040103, loss_ce: 0.019086
[02:39:03.498] iteration 20659 : loss : 0.043776, loss_ce: 0.011652
[02:39:03.797] iteration 20660 : loss : 0.045786, loss_ce: 0.016923
[02:39:04.110] iteration 20661 : loss : 0.040487, loss_ce: 0.013866
[02:39:04.412] iteration 20662 : loss : 0.044121, loss_ce: 0.010900
[02:39:04.715] iteration 20663 : loss : 0.049049, loss_ce: 0.017595
[02:39:05.019] iteration 20664 : loss : 0.042784, loss_ce: 0.018456
[02:39:05.324] iteration 20665 : loss : 0.341537, loss_ce: 0.002244
[02:39:05.627] iteration 20666 : loss : 0.102621, loss_ce: 0.009203
[02:39:05.933] iteration 20667 : loss : 0.112860, loss_ce: 0.006506
[02:39:06.233] iteration 20668 : loss : 0.046743, loss_ce: 0.023608
[02:39:06.531] iteration 20669 : loss : 0.053250, loss_ce: 0.020409
[02:39:06.827] iteration 20670 : loss : 0.038794, loss_ce: 0.006634
[02:39:07.126] iteration 20671 : loss : 0.043994, loss_ce: 0.018811
[02:39:07.427] iteration 20672 : loss : 0.038888, loss_ce: 0.012447
[02:39:07.724] iteration 20673 : loss : 0.036308, loss_ce: 0.012395
[02:39:08.021] iteration 20674 : loss : 0.057543, loss_ce: 0.024987
[02:39:08.320] iteration 20675 : loss : 0.056324, loss_ce: 0.011637
[02:39:08.617] iteration 20676 : loss : 0.034346, loss_ce: 0.010615
[02:39:08.915] iteration 20677 : loss : 0.038903, loss_ce: 0.014415
[02:39:09.211] iteration 20678 : loss : 0.039179, loss_ce: 0.007829
[02:39:09.510] iteration 20679 : loss : 0.050328, loss_ce: 0.020796
[02:39:09.808] iteration 20680 : loss : 0.108509, loss_ce: 0.007949
[02:39:10.131] iteration 20681 : loss : 0.052143, loss_ce: 0.019056
[02:39:10.430] iteration 20682 : loss : 0.054332, loss_ce: 0.018261
[02:39:10.726] iteration 20683 : loss : 0.056649, loss_ce: 0.016015
[02:39:11.026] iteration 20684 : loss : 0.058265, loss_ce: 0.013125
[02:39:11.322] iteration 20685 : loss : 0.155052, loss_ce: 0.009338
[02:39:11.620] iteration 20686 : loss : 0.039703, loss_ce: 0.018705
[02:39:11.915] iteration 20687 : loss : 0.157293, loss_ce: 0.008669
[02:39:12.213] iteration 20688 : loss : 0.127798, loss_ce: 0.007562
[02:39:12.516] iteration 20689 : loss : 0.036760, loss_ce: 0.003206
[02:39:12.816] iteration 20690 : loss : 0.048960, loss_ce: 0.010982
[02:39:13.112] iteration 20691 : loss : 0.103724, loss_ce: 0.022718
[02:39:13.409] iteration 20692 : loss : 0.050059, loss_ce: 0.022214
[02:39:13.708] iteration 20693 : loss : 0.036125, loss_ce: 0.011676
[02:39:14.006] iteration 20694 : loss : 0.105155, loss_ce: 0.011281
[02:39:14.312] iteration 20695 : loss : 0.042641, loss_ce: 0.017089
[02:39:14.618] iteration 20696 : loss : 0.046790, loss_ce: 0.013853
[02:39:14.924] iteration 20697 : loss : 0.043984, loss_ce: 0.007703
[02:39:15.229] iteration 20698 : loss : 0.046632, loss_ce: 0.014295
[02:39:15.530] iteration 20699 : loss : 0.057793, loss_ce: 0.010180
[02:39:15.834] iteration 20700 : loss : 0.103932, loss_ce: 0.010564
[02:39:16.157] iteration 20701 : loss : 0.110529, loss_ce: 0.006448
[02:39:16.456] iteration 20702 : loss : 0.039924, loss_ce: 0.012767
[02:39:16.757] iteration 20703 : loss : 0.046534, loss_ce: 0.014307
[02:39:17.061] iteration 20704 : loss : 0.112997, loss_ce: 0.012657
[02:39:17.362] iteration 20705 : loss : 0.044777, loss_ce: 0.010669
[02:39:17.661] iteration 20706 : loss : 0.047241, loss_ce: 0.021608
[02:39:17.970] iteration 20707 : loss : 0.042930, loss_ce: 0.014416
[02:39:18.272] iteration 20708 : loss : 0.068343, loss_ce: 0.018966
[02:39:18.577] iteration 20709 : loss : 0.160137, loss_ce: 0.013090
[02:39:18.879] iteration 20710 : loss : 0.041729, loss_ce: 0.008190
[02:39:18.962] iteration 20711 : loss : 0.064455, loss_ce: 0.000010
[02:39:37.004] iteration 20712 : loss : 0.044858, loss_ce: 0.014562
[02:39:37.310] iteration 20713 : loss : 0.048838, loss_ce: 0.014393
[02:39:37.619] iteration 20714 : loss : 0.044478, loss_ce: 0.015746
[02:39:37.931] iteration 20715 : loss : 0.043366, loss_ce: 0.014674
[02:39:38.236] iteration 20716 : loss : 0.042972, loss_ce: 0.013953
[02:39:38.537] iteration 20717 : loss : 0.098429, loss_ce: 0.009285
[02:39:38.840] iteration 20718 : loss : 0.101336, loss_ce: 0.007970
[02:39:39.146] iteration 20719 : loss : 0.175999, loss_ce: 0.015379
[02:39:39.446] iteration 20720 : loss : 0.096324, loss_ce: 0.011272
[02:39:39.772] iteration 20721 : loss : 0.119006, loss_ce: 0.016003
[02:39:40.073] iteration 20722 : loss : 0.037539, loss_ce: 0.012082
[02:39:40.372] iteration 20723 : loss : 0.039573, loss_ce: 0.012908
[02:39:40.681] iteration 20724 : loss : 0.042534, loss_ce: 0.010884
[02:39:40.981] iteration 20725 : loss : 0.111439, loss_ce: 0.023683
[02:39:41.280] iteration 20726 : loss : 0.035646, loss_ce: 0.008154
[02:39:41.576] iteration 20727 : loss : 0.040246, loss_ce: 0.010481
[02:39:41.877] iteration 20728 : loss : 0.035350, loss_ce: 0.013336
[02:39:42.176] iteration 20729 : loss : 0.033955, loss_ce: 0.015422
[02:39:42.480] iteration 20730 : loss : 0.044748, loss_ce: 0.023062
[02:39:42.780] iteration 20731 : loss : 0.107245, loss_ce: 0.015100
[02:39:43.078] iteration 20732 : loss : 0.052093, loss_ce: 0.009938
[02:39:43.381] iteration 20733 : loss : 0.167370, loss_ce: 0.007480
[02:39:43.681] iteration 20734 : loss : 0.047182, loss_ce: 0.014520
[02:39:43.980] iteration 20735 : loss : 0.047774, loss_ce: 0.019285
[02:39:44.277] iteration 20736 : loss : 0.109227, loss_ce: 0.014548
[02:39:44.571] iteration 20737 : loss : 0.042534, loss_ce: 0.015362
[02:39:44.873] iteration 20738 : loss : 0.041731, loss_ce: 0.009365
[02:39:45.172] iteration 20739 : loss : 0.040776, loss_ce: 0.016318
[02:39:45.471] iteration 20740 : loss : 0.056016, loss_ce: 0.016644
[02:39:45.782] iteration 20741 : loss : 0.036987, loss_ce: 0.010654
[02:39:46.076] iteration 20742 : loss : 0.035890, loss_ce: 0.010427
[02:39:46.376] iteration 20743 : loss : 0.040121, loss_ce: 0.006241
[02:39:46.675] iteration 20744 : loss : 0.045172, loss_ce: 0.018846
[02:39:46.968] iteration 20745 : loss : 0.041820, loss_ce: 0.014501
[02:39:47.265] iteration 20746 : loss : 0.042493, loss_ce: 0.014687
[02:39:47.566] iteration 20747 : loss : 0.046884, loss_ce: 0.012716
[02:39:47.863] iteration 20748 : loss : 0.040976, loss_ce: 0.020728
[02:39:48.160] iteration 20749 : loss : 0.050411, loss_ce: 0.010799
[02:39:48.458] iteration 20750 : loss : 0.041491, loss_ce: 0.010702
[02:39:48.756] iteration 20751 : loss : 0.110226, loss_ce: 0.011298
[02:39:49.054] iteration 20752 : loss : 0.034779, loss_ce: 0.016485
[02:39:49.354] iteration 20753 : loss : 0.031101, loss_ce: 0.010811
[02:39:49.654] iteration 20754 : loss : 0.070021, loss_ce: 0.011175
[02:39:49.953] iteration 20755 : loss : 0.038368, loss_ce: 0.015808
[02:39:50.253] iteration 20756 : loss : 0.037551, loss_ce: 0.006455
[02:39:50.548] iteration 20757 : loss : 0.052562, loss_ce: 0.011458
[02:39:50.847] iteration 20758 : loss : 0.057585, loss_ce: 0.016732
[02:39:51.144] iteration 20759 : loss : 0.072745, loss_ce: 0.008311
[02:39:51.441] iteration 20760 : loss : 0.103565, loss_ce: 0.010993
[02:39:51.771] iteration 20761 : loss : 0.130685, loss_ce: 0.008077
[02:39:52.073] iteration 20762 : loss : 0.097545, loss_ce: 0.013235
[02:39:52.368] iteration 20763 : loss : 0.056671, loss_ce: 0.018677
[02:39:52.666] iteration 20764 : loss : 0.043479, loss_ce: 0.018256
[02:39:52.963] iteration 20765 : loss : 0.035855, loss_ce: 0.012754
[02:39:53.266] iteration 20766 : loss : 0.046883, loss_ce: 0.023343
[02:39:53.562] iteration 20767 : loss : 0.044069, loss_ce: 0.006711
[02:39:53.858] iteration 20768 : loss : 0.040664, loss_ce: 0.012482
[02:39:54.160] iteration 20769 : loss : 0.047750, loss_ce: 0.010958
[02:39:54.461] iteration 20770 : loss : 0.050596, loss_ce: 0.012884
[02:39:54.764] iteration 20771 : loss : 0.048224, loss_ce: 0.019593
[02:39:55.069] iteration 20772 : loss : 0.035073, loss_ce: 0.010186
[02:39:55.370] iteration 20773 : loss : 0.043421, loss_ce: 0.015377
[02:39:55.672] iteration 20774 : loss : 0.223041, loss_ce: 0.005509
[02:39:55.978] iteration 20775 : loss : 0.042070, loss_ce: 0.011718
[02:39:56.281] iteration 20776 : loss : 0.040390, loss_ce: 0.007239
[02:39:56.585] iteration 20777 : loss : 0.051095, loss_ce: 0.012697
[02:39:56.883] iteration 20778 : loss : 0.041764, loss_ce: 0.013293
[02:39:57.181] iteration 20779 : loss : 0.039859, loss_ce: 0.019391
[02:39:57.478] iteration 20780 : loss : 0.049948, loss_ce: 0.016389
[02:39:57.796] iteration 20781 : loss : 0.046839, loss_ce: 0.024228
[02:39:58.094] iteration 20782 : loss : 0.038393, loss_ce: 0.010152
[02:39:58.399] iteration 20783 : loss : 0.050079, loss_ce: 0.013379
[02:39:58.700] iteration 20784 : loss : 0.051080, loss_ce: 0.009303
[02:39:58.998] iteration 20785 : loss : 0.045180, loss_ce: 0.010725
[02:39:59.299] iteration 20786 : loss : 0.106998, loss_ce: 0.014960
[02:39:59.599] iteration 20787 : loss : 0.057813, loss_ce: 0.005677
[02:39:59.897] iteration 20788 : loss : 0.036313, loss_ce: 0.016713
[02:40:00.195] iteration 20789 : loss : 0.032997, loss_ce: 0.007555
[02:40:00.489] iteration 20790 : loss : 0.098560, loss_ce: 0.012420
[02:40:00.790] iteration 20791 : loss : 0.052493, loss_ce: 0.016082
[02:40:01.095] iteration 20792 : loss : 0.048698, loss_ce: 0.010806
[02:40:01.395] iteration 20793 : loss : 0.049537, loss_ce: 0.016193
[02:40:01.694] iteration 20794 : loss : 0.057270, loss_ce: 0.014480
[02:40:01.993] iteration 20795 : loss : 0.039299, loss_ce: 0.009254
[02:40:02.294] iteration 20796 : loss : 0.048561, loss_ce: 0.015841
[02:40:02.598] iteration 20797 : loss : 0.041277, loss_ce: 0.014320
[02:40:02.899] iteration 20798 : loss : 0.034557, loss_ce: 0.006603
[02:40:03.200] iteration 20799 : loss : 0.045694, loss_ce: 0.019036
[02:40:03.495] iteration 20800 : loss : 0.036626, loss_ce: 0.013660
[02:40:03.812] iteration 20801 : loss : 0.106897, loss_ce: 0.018436
[02:40:04.115] iteration 20802 : loss : 0.049479, loss_ce: 0.013128
[02:40:04.413] iteration 20803 : loss : 0.101686, loss_ce: 0.012983
[02:40:04.710] iteration 20804 : loss : 0.108512, loss_ce: 0.011601
[02:40:05.010] iteration 20805 : loss : 0.041137, loss_ce: 0.016594
[02:40:05.305] iteration 20806 : loss : 0.053356, loss_ce: 0.015601
[02:40:05.603] iteration 20807 : loss : 0.043793, loss_ce: 0.016158
[02:40:05.902] iteration 20808 : loss : 0.107671, loss_ce: 0.005934
[02:40:06.202] iteration 20809 : loss : 0.111667, loss_ce: 0.012312
[02:40:06.505] iteration 20810 : loss : 0.046824, loss_ce: 0.011497
[02:40:06.804] iteration 20811 : loss : 0.154699, loss_ce: 0.006775
[02:40:07.101] iteration 20812 : loss : 0.043623, loss_ce: 0.017911
[02:40:07.398] iteration 20813 : loss : 0.037461, loss_ce: 0.012589
[02:40:07.697] iteration 20814 : loss : 0.058430, loss_ce: 0.012055
[02:40:07.998] iteration 20815 : loss : 0.109656, loss_ce: 0.008658
[02:40:08.295] iteration 20816 : loss : 0.102625, loss_ce: 0.006713
[02:40:08.597] iteration 20817 : loss : 0.046777, loss_ce: 0.014153
[02:40:08.894] iteration 20818 : loss : 0.036528, loss_ce: 0.009354
[02:40:09.190] iteration 20819 : loss : 0.036467, loss_ce: 0.015499
[02:40:09.489] iteration 20820 : loss : 0.064107, loss_ce: 0.009931
[02:40:09.807] iteration 20821 : loss : 0.036765, loss_ce: 0.013614
[02:40:10.110] iteration 20822 : loss : 0.047398, loss_ce: 0.020135
[02:40:10.411] iteration 20823 : loss : 0.108046, loss_ce: 0.009637
[02:40:10.709] iteration 20824 : loss : 0.040264, loss_ce: 0.011898
[02:40:11.007] iteration 20825 : loss : 0.047264, loss_ce: 0.007458
[02:40:11.310] iteration 20826 : loss : 0.041809, loss_ce: 0.018582
[02:40:11.612] iteration 20827 : loss : 0.045240, loss_ce: 0.009618
[02:40:11.911] iteration 20828 : loss : 0.060831, loss_ce: 0.006949
[02:40:12.213] iteration 20829 : loss : 0.036267, loss_ce: 0.012341
[02:40:12.512] iteration 20830 : loss : 0.096684, loss_ce: 0.006664
[02:40:12.820] iteration 20831 : loss : 0.036844, loss_ce: 0.010987
[02:40:13.121] iteration 20832 : loss : 0.223508, loss_ce: 0.006847
[02:40:13.421] iteration 20833 : loss : 0.042075, loss_ce: 0.008988
[02:40:13.721] iteration 20834 : loss : 0.048074, loss_ce: 0.016716
[02:40:14.028] iteration 20835 : loss : 0.092807, loss_ce: 0.009580
[02:40:14.336] iteration 20836 : loss : 0.048415, loss_ce: 0.015598
[02:40:14.637] iteration 20837 : loss : 0.048450, loss_ce: 0.019434
[02:40:14.944] iteration 20838 : loss : 0.109134, loss_ce: 0.007905
[02:40:15.248] iteration 20839 : loss : 0.051315, loss_ce: 0.010966
[02:40:15.555] iteration 20840 : loss : 0.082710, loss_ce: 0.014887
[02:40:15.895] iteration 20841 : loss : 0.154959, loss_ce: 0.011365
[02:40:16.198] iteration 20842 : loss : 0.050991, loss_ce: 0.005044
[02:40:16.508] iteration 20843 : loss : 0.051527, loss_ce: 0.017287
[02:40:16.813] iteration 20844 : loss : 0.044158, loss_ce: 0.012309
[02:40:17.117] iteration 20845 : loss : 0.037564, loss_ce: 0.011645
[02:40:17.423] iteration 20846 : loss : 0.039685, loss_ce: 0.007672
[02:40:17.726] iteration 20847 : loss : 0.046069, loss_ce: 0.013460
[02:40:18.023] iteration 20848 : loss : 0.037008, loss_ce: 0.017750
[02:40:18.329] iteration 20849 : loss : 0.037840, loss_ce: 0.011042
[02:40:18.409] iteration 20850 : loss : 0.025589, loss_ce: 0.000009
[02:40:18.976] save model to D:\data/output\epoch_149.pth
[02:40:19.178] save model to D:\data/output\epoch_149.pth
[23:33:10.109] Namespace(root_path='D:\\data/Synapse/train', dataset='Synapse', list_dir='./lists/lists_Synapse', num_classes=9, output_dir='./logs/swin_unet', max_iterations=30000, max_epochs=200, batch_size=14, n_gpu=1, deterministic=1, base_lr=0.01, img_size=224, seed=1234, cfg='configs/swin_tiny_patch4_window7_224_lite.yaml', net='swin_unet', opts=None, zip=False, cache_mode='part', resume='epoch_149.pth', accumulation_steps=None, use_checkpoint=False, amp_opt_level='O1', tag=None, eval=False, throughput=False)
[23:33:10.125] 158 iterations per epoch. 31600 max iterations 
[23:33:33.069] iteration 1 : loss : 1.466303, loss_ce: 2.233166
[23:33:33.600] iteration 2 : loss : 1.358121, loss_ce: 2.024380
[23:33:33.854] iteration 3 : loss : 1.209762, loss_ce: 1.640700
[23:33:34.106] iteration 4 : loss : 1.057872, loss_ce: 1.308028
[23:33:34.372] iteration 5 : loss : 0.846764, loss_ce: 0.807372
[23:33:34.624] iteration 6 : loss : 0.730725, loss_ce: 0.533517
[23:33:34.877] iteration 7 : loss : 0.695085, loss_ce: 0.436156
[23:33:35.145] iteration 8 : loss : 0.655025, loss_ce: 0.334015
[23:33:35.395] iteration 9 : loss : 0.687352, loss_ce: 0.412487
[23:33:35.655] iteration 10 : loss : 0.668089, loss_ce: 0.350224
[23:33:35.905] iteration 11 : loss : 0.627399, loss_ce: 0.242163
[23:33:36.156] iteration 12 : loss : 0.678642, loss_ce: 0.366035
[23:33:36.407] iteration 13 : loss : 0.610333, loss_ce: 0.197081
[23:33:36.667] iteration 14 : loss : 0.640596, loss_ce: 0.270652
[23:33:36.926] iteration 15 : loss : 0.650297, loss_ce: 0.293735
[23:33:37.175] iteration 16 : loss : 0.640014, loss_ce: 0.267810
[23:57:35.065] Namespace(root_path='D:\\data/Synapse/train', dataset='Synapse', list_dir='./lists/lists_Synapse', num_classes=9, output_dir='./logs/swin_unet', max_iterations=30000, max_epochs=200, batch_size=14, n_gpu=1, deterministic=1, base_lr=0.01, img_size=224, seed=8979, cfg='configs/swin_tiny_patch4_window7_224_lite.yaml', net='swin_unet', opts=None, zip=False, cache_mode='part', resume=None, accumulation_steps=None, use_checkpoint=False, amp_opt_level='O2', tag=None, eval=False, throughput=False)
[23:57:35.072] 158 iterations per epoch. 31600 max iterations 
[23:58:01.566] Namespace(root_path='D:\\data/Synapse/train', dataset='Synapse', list_dir='./lists/lists_Synapse', num_classes=9, output_dir='./logs/swin_unet', max_iterations=30000, max_epochs=200, batch_size=16, n_gpu=1, deterministic=1, base_lr=0.01, img_size=224, seed=8979, cfg='configs/swin_tiny_patch4_window7_224_lite.yaml', net='swin_unet', opts=None, zip=False, cache_mode='part', resume=None, accumulation_steps=None, use_checkpoint=False, amp_opt_level='O2', tag=None, eval=False, throughput=False)
[23:58:01.571] 139 iterations per epoch. 27800 max iterations 
[23:58:22.449] iteration 1 : loss : 1.516479, loss_ce: 2.391239
[23:58:23.104] iteration 2 : loss : 1.428575, loss_ce: 2.168324
[23:58:23.386] iteration 3 : loss : 1.280670, loss_ce: 1.840875
[23:58:23.671] iteration 4 : loss : 1.089229, loss_ce: 1.348837
[23:58:23.963] iteration 5 : loss : 0.917736, loss_ce: 0.973823
[23:58:24.246] iteration 6 : loss : 0.811681, loss_ce: 0.741430
[23:58:24.533] iteration 7 : loss : 0.684335, loss_ce: 0.413411
[23:58:24.819] iteration 8 : loss : 0.658275, loss_ce: 0.331729
[23:58:25.110] iteration 9 : loss : 0.603147, loss_ce: 0.194346
[23:58:25.400] iteration 10 : loss : 0.628287, loss_ce: 0.249719
[23:58:25.692] iteration 11 : loss : 0.631040, loss_ce: 0.251490
[23:58:25.993] iteration 12 : loss : 0.646097, loss_ce: 0.285766
[23:58:26.280] iteration 13 : loss : 0.674196, loss_ce: 0.353319
[23:58:26.571] iteration 14 : loss : 0.672993, loss_ce: 0.349354
[23:58:26.858] iteration 15 : loss : 0.553166, loss_ce: 0.052084
[23:58:27.142] iteration 16 : loss : 0.684651, loss_ce: 0.376814
[23:58:27.428] iteration 17 : loss : 0.718180, loss_ce: 0.459564
[23:58:27.714] iteration 18 : loss : 0.734799, loss_ce: 0.500391
[23:58:27.998] iteration 19 : loss : 0.676581, loss_ce: 0.356633
[23:58:28.295] iteration 20 : loss : 0.620511, loss_ce: 0.217947
[23:58:28.620] iteration 21 : loss : 0.724318, loss_ce: 0.474441
[23:58:28.906] iteration 22 : loss : 0.569536, loss_ce: 0.092163
[23:58:29.197] iteration 23 : loss : 0.640644, loss_ce: 0.268138
[23:58:29.487] iteration 24 : loss : 0.659818, loss_ce: 0.315642
[23:58:29.775] iteration 25 : loss : 0.579184, loss_ce: 0.116629
[23:58:30.060] iteration 26 : loss : 0.661232, loss_ce: 0.319666
[23:58:30.348] iteration 27 : loss : 0.696134, loss_ce: 0.406088
[23:58:30.633] iteration 28 : loss : 0.676740, loss_ce: 0.359063
[23:58:30.919] iteration 29 : loss : 0.575054, loss_ce: 0.108865
[23:58:31.205] iteration 30 : loss : 0.632921, loss_ce: 0.253127
[23:58:31.495] iteration 31 : loss : 0.674282, loss_ce: 0.355324
[23:58:31.783] iteration 32 : loss : 0.630287, loss_ce: 0.252212
[23:58:32.090] iteration 33 : loss : 0.643739, loss_ce: 0.283644
[23:58:32.376] iteration 34 : loss : 0.626298, loss_ce: 0.243049
[23:58:32.666] iteration 35 : loss : 0.665653, loss_ce: 0.342593
[23:58:32.950] iteration 36 : loss : 0.646319, loss_ce: 0.298710
[23:58:33.236] iteration 37 : loss : 0.652377, loss_ce: 0.318574
[23:58:33.526] iteration 38 : loss : 0.618053, loss_ce: 0.241415
[23:58:33.817] iteration 39 : loss : 0.636052, loss_ce: 0.292407
[23:58:34.105] iteration 40 : loss : 0.631546, loss_ce: 0.275641
[23:58:34.407] iteration 41 : loss : 0.622173, loss_ce: 0.253249
[23:58:34.692] iteration 42 : loss : 0.618673, loss_ce: 0.247348
[23:58:34.984] iteration 43 : loss : 0.642077, loss_ce: 0.303031
[23:58:35.272] iteration 44 : loss : 0.611412, loss_ce: 0.226522
[23:58:35.560] iteration 45 : loss : 0.613800, loss_ce: 0.229699
[23:58:35.846] iteration 46 : loss : 0.622577, loss_ce: 0.252384
[23:58:36.135] iteration 47 : loss : 0.564805, loss_ce: 0.105007
[23:58:36.423] iteration 48 : loss : 0.624131, loss_ce: 0.252485
[23:58:36.713] iteration 49 : loss : 0.594227, loss_ce: 0.181542
[23:58:36.998] iteration 50 : loss : 0.601941, loss_ce: 0.194011
[23:58:37.288] iteration 51 : loss : 0.611002, loss_ce: 0.221687
[23:58:37.576] iteration 52 : loss : 0.609473, loss_ce: 0.217302
[23:58:37.861] iteration 53 : loss : 0.629380, loss_ce: 0.269556
[23:58:38.151] iteration 54 : loss : 0.627632, loss_ce: 0.271647
[23:58:38.438] iteration 55 : loss : 0.613577, loss_ce: 0.249466
[23:58:38.728] iteration 56 : loss : 0.576854, loss_ce: 0.157891
[23:58:39.016] iteration 57 : loss : 0.584360, loss_ce: 0.190646
[23:58:39.300] iteration 58 : loss : 0.619611, loss_ce: 0.298472
[23:58:39.587] iteration 59 : loss : 0.608140, loss_ce: 0.280985
[23:58:39.879] iteration 60 : loss : 0.602077, loss_ce: 0.265159
[23:58:40.182] iteration 61 : loss : 0.584133, loss_ce: 0.228998
[23:58:40.468] iteration 62 : loss : 0.616388, loss_ce: 0.325953
[23:58:40.756] iteration 63 : loss : 0.590689, loss_ce: 0.247276
[23:58:41.043] iteration 64 : loss : 0.605196, loss_ce: 0.259030
[23:58:41.328] iteration 65 : loss : 0.576562, loss_ce: 0.194555
[23:58:41.616] iteration 66 : loss : 0.556214, loss_ce: 0.138576
[23:58:41.922] iteration 67 : loss : 0.584150, loss_ce: 0.214054
[23:58:42.213] iteration 68 : loss : 0.588305, loss_ce: 0.262043
[23:58:42.512] iteration 69 : loss : 0.575307, loss_ce: 0.188468
[23:58:42.800] iteration 70 : loss : 0.571190, loss_ce: 0.153730
[23:58:43.088] iteration 71 : loss : 0.571691, loss_ce: 0.182419
[23:58:43.377] iteration 72 : loss : 0.557103, loss_ce: 0.119752
[23:58:43.674] iteration 73 : loss : 0.581974, loss_ce: 0.205983
[23:58:43.961] iteration 74 : loss : 0.572692, loss_ce: 0.189185
[23:58:44.248] iteration 75 : loss : 0.557134, loss_ce: 0.150691
[23:58:44.538] iteration 76 : loss : 0.595553, loss_ce: 0.255432
[23:58:44.824] iteration 77 : loss : 0.578320, loss_ce: 0.210564
[23:58:45.111] iteration 78 : loss : 0.567114, loss_ce: 0.213416
[23:58:45.404] iteration 79 : loss : 0.580097, loss_ce: 0.239664
[23:58:45.701] iteration 80 : loss : 0.592281, loss_ce: 0.288719
[23:58:46.018] iteration 81 : loss : 0.581089, loss_ce: 0.256417
[23:58:46.305] iteration 82 : loss : 0.564032, loss_ce: 0.204222
[23:58:46.596] iteration 83 : loss : 0.559445, loss_ce: 0.166003
[23:58:46.881] iteration 84 : loss : 0.559770, loss_ce: 0.155623
[23:58:47.168] iteration 85 : loss : 0.590429, loss_ce: 0.232502
[23:58:47.459] iteration 86 : loss : 0.561407, loss_ce: 0.145211
[23:58:47.745] iteration 87 : loss : 0.559385, loss_ce: 0.138733
[23:58:48.033] iteration 88 : loss : 0.559131, loss_ce: 0.159571
[23:58:48.320] iteration 89 : loss : 0.568127, loss_ce: 0.193457
[23:58:48.610] iteration 90 : loss : 0.558511, loss_ce: 0.171214
[23:58:48.900] iteration 91 : loss : 0.589577, loss_ce: 0.268283
[23:58:49.194] iteration 92 : loss : 0.578621, loss_ce: 0.190769
[23:58:49.482] iteration 93 : loss : 0.559660, loss_ce: 0.183267
[23:58:49.784] iteration 94 : loss : 0.554047, loss_ce: 0.140698
[23:58:50.070] iteration 95 : loss : 0.563027, loss_ce: 0.148531
[23:58:50.358] iteration 96 : loss : 0.560396, loss_ce: 0.170674
[23:58:50.650] iteration 97 : loss : 0.577999, loss_ce: 0.189949
[23:58:50.949] iteration 98 : loss : 0.564426, loss_ce: 0.140956
[23:58:51.254] iteration 99 : loss : 0.558851, loss_ce: 0.137910
[23:58:51.553] iteration 100 : loss : 0.563031, loss_ce: 0.176585
[23:58:51.873] iteration 101 : loss : 0.562284, loss_ce: 0.193036
[23:58:52.168] iteration 102 : loss : 0.576635, loss_ce: 0.230197
[23:58:52.503] iteration 103 : loss : 0.556976, loss_ce: 0.188688
[23:58:52.797] iteration 104 : loss : 0.573259, loss_ce: 0.250257
[23:58:53.098] iteration 105 : loss : 0.587502, loss_ce: 0.231056
[23:58:53.395] iteration 106 : loss : 0.552049, loss_ce: 0.181698
[23:58:53.686] iteration 107 : loss : 0.588448, loss_ce: 0.243262
[23:58:53.977] iteration 108 : loss : 0.562326, loss_ce: 0.156124
[23:58:54.269] iteration 109 : loss : 0.607175, loss_ce: 0.282536
[23:58:54.560] iteration 110 : loss : 0.552219, loss_ce: 0.144947
[23:58:54.895] iteration 111 : loss : 0.581177, loss_ce: 0.233805
[23:58:55.197] iteration 112 : loss : 0.541358, loss_ce: 0.158246
[23:58:55.500] iteration 113 : loss : 0.567521, loss_ce: 0.250809
[23:58:55.788] iteration 114 : loss : 0.568951, loss_ce: 0.225025
[23:58:56.085] iteration 115 : loss : 0.557528, loss_ce: 0.187807
[23:58:56.374] iteration 116 : loss : 0.535538, loss_ce: 0.118152
[23:58:56.662] iteration 117 : loss : 0.575347, loss_ce: 0.203860
[23:58:56.962] iteration 118 : loss : 0.556335, loss_ce: 0.160207
[23:58:57.323] iteration 119 : loss : 0.573081, loss_ce: 0.188024
[23:58:57.686] iteration 120 : loss : 0.543638, loss_ce: 0.136597
[23:58:58.073] iteration 121 : loss : 0.563441, loss_ce: 0.206605
[23:58:58.438] iteration 122 : loss : 0.580695, loss_ce: 0.272545
[23:58:58.733] iteration 123 : loss : 0.568092, loss_ce: 0.232334
[23:58:59.029] iteration 124 : loss : 0.566717, loss_ce: 0.225484
[23:58:59.318] iteration 125 : loss : 0.579710, loss_ce: 0.257608
[23:58:59.604] iteration 126 : loss : 0.561539, loss_ce: 0.195175
[23:58:59.898] iteration 127 : loss : 0.558304, loss_ce: 0.150241
[23:59:00.189] iteration 128 : loss : 0.565003, loss_ce: 0.163531
[23:59:00.484] iteration 129 : loss : 0.565914, loss_ce: 0.177635
[23:59:00.777] iteration 130 : loss : 0.570613, loss_ce: 0.201156
[23:59:01.070] iteration 131 : loss : 0.547698, loss_ce: 0.202692
[23:59:01.364] iteration 132 : loss : 0.554305, loss_ce: 0.211756
[23:59:01.655] iteration 133 : loss : 0.558531, loss_ce: 0.223546
[23:59:01.950] iteration 134 : loss : 0.546099, loss_ce: 0.187950
[23:59:02.243] iteration 135 : loss : 0.548637, loss_ce: 0.179915
[23:59:02.535] iteration 136 : loss : 0.525434, loss_ce: 0.068562
[23:59:02.826] iteration 137 : loss : 0.570383, loss_ce: 0.165170
[23:59:03.120] iteration 138 : loss : 0.569039, loss_ce: 0.182341
[23:59:03.213] iteration 139 : loss : 0.548494, loss_ce: 0.068486
[23:59:20.114] Namespace(root_path='D:\\data/Synapse/train', dataset='Synapse', list_dir='./lists/lists_Synapse', num_classes=9, output_dir='./logs/swin_unet', max_iterations=30000, max_epochs=150, batch_size=16, n_gpu=1, deterministic=1, base_lr=0.01, img_size=224, seed=8979, cfg='configs/swin_tiny_patch4_window7_224_lite.yaml', net='swin_unet', opts=None, zip=False, cache_mode='part', resume=None, accumulation_steps=None, use_checkpoint=False, amp_opt_level='O2', tag=None, eval=False, throughput=False)
[23:59:20.129] 139 iterations per epoch. 20850 max iterations 
[23:59:40.690] iteration 1 : loss : 1.516479, loss_ce: 2.391239
[23:59:41.313] iteration 2 : loss : 1.428575, loss_ce: 2.168324
[23:59:41.615] iteration 3 : loss : 1.280671, loss_ce: 1.840875
[23:59:41.902] iteration 4 : loss : 1.089231, loss_ce: 1.348841
[23:59:42.193] iteration 5 : loss : 0.917740, loss_ce: 0.973832
[23:59:42.491] iteration 6 : loss : 0.811687, loss_ce: 0.741444
[23:59:42.780] iteration 7 : loss : 0.684341, loss_ce: 0.413427
[23:59:43.087] iteration 8 : loss : 0.658278, loss_ce: 0.331738
[23:59:43.390] iteration 9 : loss : 0.603149, loss_ce: 0.194352
[23:59:43.677] iteration 10 : loss : 0.628287, loss_ce: 0.249720
[23:59:43.984] iteration 11 : loss : 0.631040, loss_ce: 0.251490
[23:59:44.286] iteration 12 : loss : 0.646095, loss_ce: 0.285762
[23:59:44.573] iteration 13 : loss : 0.674194, loss_ce: 0.353313
[23:59:44.877] iteration 14 : loss : 0.672990, loss_ce: 0.349347
[23:59:45.198] iteration 15 : loss : 0.553166, loss_ce: 0.052085
[23:59:45.761] iteration 16 : loss : 0.684648, loss_ce: 0.376807
[23:59:46.054] iteration 17 : loss : 0.718176, loss_ce: 0.459555
[23:59:46.348] iteration 18 : loss : 0.734794, loss_ce: 0.500381
[23:59:46.640] iteration 19 : loss : 0.676578, loss_ce: 0.356627
[23:59:46.925] iteration 20 : loss : 0.620510, loss_ce: 0.217944
[23:59:47.244] iteration 21 : loss : 0.724315, loss_ce: 0.474435
[23:59:47.530] iteration 22 : loss : 0.569536, loss_ce: 0.092163
[23:59:47.820] iteration 23 : loss : 0.640643, loss_ce: 0.268137
[23:59:48.111] iteration 24 : loss : 0.659818, loss_ce: 0.315642
[23:59:48.413] iteration 25 : loss : 0.579184, loss_ce: 0.116629
[23:59:48.708] iteration 26 : loss : 0.661233, loss_ce: 0.319668
[23:59:49.006] iteration 27 : loss : 0.696137, loss_ce: 0.406095
[23:59:49.300] iteration 28 : loss : 0.676743, loss_ce: 0.359071
[23:59:49.603] iteration 29 : loss : 0.575054, loss_ce: 0.108865
[23:59:49.909] iteration 30 : loss : 0.632925, loss_ce: 0.253135
[23:59:50.230] iteration 31 : loss : 0.674289, loss_ce: 0.355340
[23:59:50.575] iteration 32 : loss : 0.630292, loss_ce: 0.252220
[23:59:50.895] iteration 33 : loss : 0.643746, loss_ce: 0.283655
[23:59:51.214] iteration 34 : loss : 0.626301, loss_ce: 0.243049
[23:59:51.538] iteration 35 : loss : 0.665660, loss_ce: 0.342601
[23:59:51.859] iteration 36 : loss : 0.646325, loss_ce: 0.298712
[23:59:52.160] iteration 37 : loss : 0.652384, loss_ce: 0.318575
[23:59:52.462] iteration 38 : loss : 0.618051, loss_ce: 0.241392
[23:59:52.776] iteration 39 : loss : 0.636054, loss_ce: 0.292392
[23:59:53.093] iteration 40 : loss : 0.631547, loss_ce: 0.275632
[23:59:53.423] iteration 41 : loss : 0.622174, loss_ce: 0.253244
[23:59:53.740] iteration 42 : loss : 0.618680, loss_ce: 0.247361
[23:59:54.066] iteration 43 : loss : 0.642086, loss_ce: 0.303055
[23:59:54.377] iteration 44 : loss : 0.611420, loss_ce: 0.226546
[23:59:54.702] iteration 45 : loss : 0.613809, loss_ce: 0.229726
[23:59:55.049] iteration 46 : loss : 0.622582, loss_ce: 0.252403
[23:59:55.410] iteration 47 : loss : 0.564813, loss_ce: 0.105029
[23:59:55.727] iteration 48 : loss : 0.624137, loss_ce: 0.252503
[23:59:56.044] iteration 49 : loss : 0.594232, loss_ce: 0.181557
[23:59:56.354] iteration 50 : loss : 0.601948, loss_ce: 0.194026
[23:59:56.639] iteration 51 : loss : 0.611010, loss_ce: 0.221701
[23:59:56.925] iteration 52 : loss : 0.609483, loss_ce: 0.217316
[23:59:57.211] iteration 53 : loss : 0.629399, loss_ce: 0.269583
[23:59:57.498] iteration 54 : loss : 0.627656, loss_ce: 0.271674
[23:59:57.782] iteration 55 : loss : 0.613611, loss_ce: 0.249489
[23:59:58.066] iteration 56 : loss : 0.576857, loss_ce: 0.157837
[23:59:58.350] iteration 57 : loss : 0.584361, loss_ce: 0.190573
[23:59:58.638] iteration 58 : loss : 0.619650, loss_ce: 0.298459
[23:59:58.983] iteration 59 : loss : 0.608170, loss_ce: 0.280970
[23:59:59.322] iteration 60 : loss : 0.602085, loss_ce: 0.265136
[23:59:59.638] iteration 61 : loss : 0.584155, loss_ce: 0.229029
[23:59:59.924] iteration 62 : loss : 0.616421, loss_ce: 0.326045
[00:00:00.216] iteration 63 : loss : 0.590720, loss_ce: 0.247388
[00:00:00.507] iteration 64 : loss : 0.605202, loss_ce: 0.259094
[00:00:00.794] iteration 65 : loss : 0.576570, loss_ce: 0.194604
[00:00:01.082] iteration 66 : loss : 0.556228, loss_ce: 0.138606
[00:00:01.371] iteration 67 : loss : 0.584174, loss_ce: 0.214069
[00:00:01.658] iteration 68 : loss : 0.588330, loss_ce: 0.262023
[00:00:01.946] iteration 69 : loss : 0.575318, loss_ce: 0.188415
[00:00:02.244] iteration 70 : loss : 0.571156, loss_ce: 0.153621
[00:00:02.551] iteration 71 : loss : 0.571685, loss_ce: 0.182383
[00:00:02.846] iteration 72 : loss : 0.557112, loss_ce: 0.119782
[00:00:03.152] iteration 73 : loss : 0.581963, loss_ce: 0.206019
[00:00:03.474] iteration 74 : loss : 0.572693, loss_ce: 0.189247
[00:00:03.765] iteration 75 : loss : 0.557131, loss_ce: 0.150742
[00:00:04.055] iteration 76 : loss : 0.595547, loss_ce: 0.255455
[00:00:04.348] iteration 77 : loss : 0.578322, loss_ce: 0.210570
[00:00:04.635] iteration 78 : loss : 0.567120, loss_ce: 0.213401
[00:00:04.930] iteration 79 : loss : 0.580113, loss_ce: 0.239659
[00:00:05.222] iteration 80 : loss : 0.592295, loss_ce: 0.288715
[00:00:05.523] iteration 81 : loss : 0.581093, loss_ce: 0.256414
[00:00:05.818] iteration 82 : loss : 0.564048, loss_ce: 0.204262
[00:00:06.105] iteration 83 : loss : 0.559457, loss_ce: 0.166050
[00:00:06.393] iteration 84 : loss : 0.559772, loss_ce: 0.155666
[00:00:06.679] iteration 85 : loss : 0.590425, loss_ce: 0.232530
[00:00:06.968] iteration 86 : loss : 0.561412, loss_ce: 0.145237
[00:00:07.254] iteration 87 : loss : 0.559391, loss_ce: 0.138744
[00:00:07.542] iteration 88 : loss : 0.559137, loss_ce: 0.159570
[00:00:07.827] iteration 89 : loss : 0.568139, loss_ce: 0.193448
[00:00:08.117] iteration 90 : loss : 0.558527, loss_ce: 0.171208
[00:00:08.407] iteration 91 : loss : 0.589585, loss_ce: 0.268270
[00:00:08.709] iteration 92 : loss : 0.578623, loss_ce: 0.190768
[00:00:09.021] iteration 93 : loss : 0.559664, loss_ce: 0.183282
[00:00:09.353] iteration 94 : loss : 0.554058, loss_ce: 0.140737
[00:00:09.667] iteration 95 : loss : 0.563051, loss_ce: 0.148597
[00:00:09.966] iteration 96 : loss : 0.560384, loss_ce: 0.170691
[00:00:10.262] iteration 97 : loss : 0.577994, loss_ce: 0.189965
[00:00:10.553] iteration 98 : loss : 0.564428, loss_ce: 0.140966
[00:00:10.866] iteration 99 : loss : 0.558857, loss_ce: 0.137913
[00:00:11.160] iteration 100 : loss : 0.563051, loss_ce: 0.176587
[00:00:11.473] iteration 101 : loss : 0.562302, loss_ce: 0.193027
[00:00:11.760] iteration 102 : loss : 0.576638, loss_ce: 0.230163
[00:00:12.055] iteration 103 : loss : 0.556974, loss_ce: 0.188658
[00:00:12.339] iteration 104 : loss : 0.573265, loss_ce: 0.250270
[00:00:12.628] iteration 105 : loss : 0.587540, loss_ce: 0.231161
[00:00:12.920] iteration 106 : loss : 0.552069, loss_ce: 0.181796
[00:00:13.208] iteration 107 : loss : 0.588424, loss_ce: 0.243289
[00:00:13.502] iteration 108 : loss : 0.562317, loss_ce: 0.156158
[00:00:13.801] iteration 109 : loss : 0.607174, loss_ce: 0.282536
[00:00:14.096] iteration 110 : loss : 0.552226, loss_ce: 0.144912
[00:00:14.390] iteration 111 : loss : 0.581220, loss_ce: 0.233787
[00:00:14.680] iteration 112 : loss : 0.541338, loss_ce: 0.158117
[00:00:14.968] iteration 113 : loss : 0.567510, loss_ce: 0.250710
[00:00:15.253] iteration 114 : loss : 0.568957, loss_ce: 0.225022
[00:00:15.561] iteration 115 : loss : 0.557586, loss_ce: 0.187954
[00:00:15.857] iteration 116 : loss : 0.535582, loss_ce: 0.118311
[00:00:16.148] iteration 117 : loss : 0.575276, loss_ce: 0.203850
[00:00:16.438] iteration 118 : loss : 0.556326, loss_ce: 0.160250
[00:00:16.727] iteration 119 : loss : 0.573125, loss_ce: 0.188070
[00:00:17.045] iteration 120 : loss : 0.543658, loss_ce: 0.136583
[00:00:17.349] iteration 121 : loss : 0.563449, loss_ce: 0.206495
[00:00:17.644] iteration 122 : loss : 0.580680, loss_ce: 0.272458
[00:00:17.937] iteration 123 : loss : 0.568095, loss_ce: 0.232305
[00:00:18.228] iteration 124 : loss : 0.566749, loss_ce: 0.225577
[00:00:18.515] iteration 125 : loss : 0.579785, loss_ce: 0.257825
[00:00:18.807] iteration 126 : loss : 0.561601, loss_ce: 0.195417
[00:00:19.099] iteration 127 : loss : 0.558270, loss_ce: 0.150283
[00:00:19.389] iteration 128 : loss : 0.564981, loss_ce: 0.163512
[00:00:19.680] iteration 129 : loss : 0.565999, loss_ce: 0.177671
[00:00:19.978] iteration 130 : loss : 0.570719, loss_ce: 0.201154
[00:00:20.281] iteration 131 : loss : 0.547645, loss_ce: 0.202391
[00:00:20.571] iteration 132 : loss : 0.554203, loss_ce: 0.211449
[00:00:20.866] iteration 133 : loss : 0.558578, loss_ce: 0.223644
[00:00:21.159] iteration 134 : loss : 0.546223, loss_ce: 0.188348
[00:00:21.460] iteration 135 : loss : 0.548631, loss_ce: 0.180166
[00:00:21.753] iteration 136 : loss : 0.525466, loss_ce: 0.068683
[00:00:22.049] iteration 137 : loss : 0.570504, loss_ce: 0.165243
[00:00:22.341] iteration 138 : loss : 0.569331, loss_ce: 0.182497
[00:00:22.432] iteration 139 : loss : 0.548455, loss_ce: 0.068197
[00:00:39.299] iteration 140 : loss : 0.569084, loss_ce: 0.241206
[00:00:39.605] iteration 141 : loss : 0.563398, loss_ce: 0.245429
[00:00:39.888] iteration 142 : loss : 0.560529, loss_ce: 0.190936
[00:00:40.175] iteration 143 : loss : 0.558321, loss_ce: 0.168284
[00:00:40.463] iteration 144 : loss : 0.530546, loss_ce: 0.099263
[00:00:40.750] iteration 145 : loss : 0.532523, loss_ce: 0.072494
[00:00:41.036] iteration 146 : loss : 0.567699, loss_ce: 0.166356
[00:00:41.322] iteration 147 : loss : 0.592695, loss_ce: 0.235040
[00:00:41.612] iteration 148 : loss : 0.522486, loss_ce: 0.085024
[00:00:41.904] iteration 149 : loss : 0.546333, loss_ce: 0.162202
[00:00:42.191] iteration 150 : loss : 0.557578, loss_ce: 0.216380
[00:00:42.477] iteration 151 : loss : 0.541228, loss_ce: 0.164409
[00:00:42.769] iteration 152 : loss : 0.539731, loss_ce: 0.154969
[00:00:43.055] iteration 153 : loss : 0.563238, loss_ce: 0.181918
[00:00:43.347] iteration 154 : loss : 0.531893, loss_ce: 0.086342
[00:00:43.639] iteration 155 : loss : 0.530291, loss_ce: 0.149678
[00:00:43.977] iteration 156 : loss : 0.536213, loss_ce: 0.157273
[00:00:44.316] iteration 157 : loss : 0.537796, loss_ce: 0.163210
[00:00:44.612] iteration 158 : loss : 0.520273, loss_ce: 0.133150
[00:00:44.919] iteration 159 : loss : 0.542538, loss_ce: 0.186941
[00:00:45.221] iteration 160 : loss : 0.546849, loss_ce: 0.199165
[00:00:45.525] iteration 161 : loss : 0.536006, loss_ce: 0.178702
[00:00:45.812] iteration 162 : loss : 0.515762, loss_ce: 0.106741
[00:00:46.099] iteration 163 : loss : 0.576436, loss_ce: 0.186356
[00:00:46.389] iteration 164 : loss : 0.557762, loss_ce: 0.173819
[00:00:46.686] iteration 165 : loss : 0.540496, loss_ce: 0.177807
[00:00:46.978] iteration 166 : loss : 0.555952, loss_ce: 0.212595
[00:00:47.279] iteration 167 : loss : 0.529142, loss_ce: 0.169268
[00:00:47.579] iteration 168 : loss : 0.534356, loss_ce: 0.156301
[00:00:47.868] iteration 169 : loss : 0.563013, loss_ce: 0.167555
[00:00:48.155] iteration 170 : loss : 0.514096, loss_ce: 0.130441
[00:00:48.443] iteration 171 : loss : 0.519945, loss_ce: 0.120197
[00:00:48.728] iteration 172 : loss : 0.525607, loss_ce: 0.125989
[00:00:49.013] iteration 173 : loss : 0.515123, loss_ce: 0.104500
[00:00:49.310] iteration 174 : loss : 0.515073, loss_ce: 0.149005
[00:00:49.608] iteration 175 : loss : 0.526862, loss_ce: 0.145362
[00:00:49.900] iteration 176 : loss : 0.546670, loss_ce: 0.167016
[00:00:50.187] iteration 177 : loss : 0.508070, loss_ce: 0.088805
[00:00:50.475] iteration 178 : loss : 0.533191, loss_ce: 0.204436
[00:00:50.764] iteration 179 : loss : 0.549898, loss_ce: 0.226839
[00:00:51.051] iteration 180 : loss : 0.536910, loss_ce: 0.137669
[00:00:51.356] iteration 181 : loss : 0.509385, loss_ce: 0.099814
[00:00:51.644] iteration 182 : loss : 0.503524, loss_ce: 0.101362
[00:00:51.931] iteration 183 : loss : 0.515399, loss_ce: 0.113472
[00:00:52.219] iteration 184 : loss : 0.525325, loss_ce: 0.160913
[00:00:52.517] iteration 185 : loss : 0.541871, loss_ce: 0.225315
[00:00:52.810] iteration 186 : loss : 0.526262, loss_ce: 0.143240
[00:00:53.110] iteration 187 : loss : 0.528019, loss_ce: 0.122446
[00:00:53.405] iteration 188 : loss : 0.550700, loss_ce: 0.208493
[00:00:53.696] iteration 189 : loss : 0.549978, loss_ce: 0.187934
[00:00:53.984] iteration 190 : loss : 0.522158, loss_ce: 0.148382
[00:00:54.280] iteration 191 : loss : 0.510553, loss_ce: 0.124043
[00:00:54.579] iteration 192 : loss : 0.507835, loss_ce: 0.127731
[00:00:54.871] iteration 193 : loss : 0.532419, loss_ce: 0.136168
[00:01:08.837] Namespace(root_path='D:\\data/Synapse/train', dataset='Synapse', list_dir='./lists/lists_Synapse', num_classes=9, output_dir='./logs/swin_unet', max_iterations=30000, max_epochs=150, batch_size=16, n_gpu=1, deterministic=1, base_lr=0.01, img_size=224, seed=8979, cfg='configs/swin_tiny_patch4_window7_224_lite.yaml', net='swin_unet', opts=None, zip=False, cache_mode='part', resume=None, accumulation_steps=None, use_checkpoint=False, amp_opt_level='O2', tag=None, eval=False, throughput=False)
[00:01:08.842] 139 iterations per epoch. 20850 max iterations 
[00:01:29.255] iteration 1 : loss : 1.516479, loss_ce: 2.391239
[00:01:29.882] iteration 2 : loss : 1.428575, loss_ce: 2.168324
[00:01:30.169] iteration 3 : loss : 1.280670, loss_ce: 1.840875
[00:01:30.452] iteration 4 : loss : 1.089231, loss_ce: 1.348841
[00:01:30.739] iteration 5 : loss : 0.917740, loss_ce: 0.973832
[00:01:31.022] iteration 6 : loss : 0.811687, loss_ce: 0.741444
[00:01:31.314] iteration 7 : loss : 0.684341, loss_ce: 0.413427
[00:01:31.600] iteration 8 : loss : 0.658278, loss_ce: 0.331738
[00:01:31.887] iteration 9 : loss : 0.603149, loss_ce: 0.194352
[00:01:32.175] iteration 10 : loss : 0.628287, loss_ce: 0.249720
[00:01:32.463] iteration 11 : loss : 0.631040, loss_ce: 0.251490
[00:01:32.750] iteration 12 : loss : 0.646095, loss_ce: 0.285762
[00:01:33.037] iteration 13 : loss : 0.674194, loss_ce: 0.353313
[00:01:33.324] iteration 14 : loss : 0.672990, loss_ce: 0.349347
[00:01:33.609] iteration 15 : loss : 0.553166, loss_ce: 0.052085
[00:01:33.895] iteration 16 : loss : 0.684648, loss_ce: 0.376807
[00:01:34.182] iteration 17 : loss : 0.718176, loss_ce: 0.459555
[00:01:34.470] iteration 18 : loss : 0.734794, loss_ce: 0.500381
[00:01:34.758] iteration 19 : loss : 0.676578, loss_ce: 0.356627
[00:01:35.046] iteration 20 : loss : 0.620510, loss_ce: 0.217944
[00:01:35.352] iteration 21 : loss : 0.724315, loss_ce: 0.474435
[00:01:35.640] iteration 22 : loss : 0.569536, loss_ce: 0.092163
[00:01:35.927] iteration 23 : loss : 0.640643, loss_ce: 0.268137
[00:01:36.215] iteration 24 : loss : 0.659818, loss_ce: 0.315642
[00:01:36.502] iteration 25 : loss : 0.579184, loss_ce: 0.116629
[00:01:36.788] iteration 26 : loss : 0.661233, loss_ce: 0.319668
[00:01:37.076] iteration 27 : loss : 0.696137, loss_ce: 0.406095
[00:01:37.363] iteration 28 : loss : 0.676744, loss_ce: 0.359071
[00:01:37.647] iteration 29 : loss : 0.575054, loss_ce: 0.108865
[00:01:37.931] iteration 30 : loss : 0.632925, loss_ce: 0.253135
[00:01:38.224] iteration 31 : loss : 0.674289, loss_ce: 0.355340
[00:01:38.510] iteration 32 : loss : 0.630292, loss_ce: 0.252220
[00:01:38.795] iteration 33 : loss : 0.643746, loss_ce: 0.283655
[00:01:39.084] iteration 34 : loss : 0.626301, loss_ce: 0.243049
[00:01:39.375] iteration 35 : loss : 0.665660, loss_ce: 0.342601
[00:01:39.667] iteration 36 : loss : 0.646325, loss_ce: 0.298712
[00:01:39.958] iteration 37 : loss : 0.652384, loss_ce: 0.318575
[00:01:40.246] iteration 38 : loss : 0.618051, loss_ce: 0.241392
[00:01:40.531] iteration 39 : loss : 0.636054, loss_ce: 0.292392
[00:01:40.817] iteration 40 : loss : 0.631547, loss_ce: 0.275632
[00:01:41.121] iteration 41 : loss : 0.622174, loss_ce: 0.253244
[00:01:41.409] iteration 42 : loss : 0.618680, loss_ce: 0.247361
[00:01:41.697] iteration 43 : loss : 0.642086, loss_ce: 0.303055
[00:01:41.984] iteration 44 : loss : 0.611420, loss_ce: 0.226546
[00:01:42.273] iteration 45 : loss : 0.613809, loss_ce: 0.229726
[00:01:42.560] iteration 46 : loss : 0.622582, loss_ce: 0.252403
[00:01:42.845] iteration 47 : loss : 0.564813, loss_ce: 0.105029
[00:01:43.132] iteration 48 : loss : 0.624137, loss_ce: 0.252503
[00:01:43.416] iteration 49 : loss : 0.594232, loss_ce: 0.181557
[00:01:43.703] iteration 50 : loss : 0.601948, loss_ce: 0.194026
[00:01:43.990] iteration 51 : loss : 0.611010, loss_ce: 0.221701
[00:01:44.279] iteration 52 : loss : 0.609483, loss_ce: 0.217316
[00:01:44.566] iteration 53 : loss : 0.629399, loss_ce: 0.269583
[00:01:44.854] iteration 54 : loss : 0.627656, loss_ce: 0.271674
[00:01:45.142] iteration 55 : loss : 0.613611, loss_ce: 0.249489
[00:01:45.427] iteration 56 : loss : 0.576857, loss_ce: 0.157837
[00:01:45.712] iteration 57 : loss : 0.584361, loss_ce: 0.190573
[00:01:46.003] iteration 58 : loss : 0.619650, loss_ce: 0.298459
[00:01:46.290] iteration 59 : loss : 0.608170, loss_ce: 0.280970
[00:01:46.578] iteration 60 : loss : 0.602085, loss_ce: 0.265136
[00:01:46.881] iteration 61 : loss : 0.584155, loss_ce: 0.229029
[00:01:47.167] iteration 62 : loss : 0.616421, loss_ce: 0.326045
[00:01:47.454] iteration 63 : loss : 0.590720, loss_ce: 0.247388
[00:01:47.742] iteration 64 : loss : 0.605202, loss_ce: 0.259094
[00:01:48.028] iteration 65 : loss : 0.576570, loss_ce: 0.194604
[00:01:48.315] iteration 66 : loss : 0.556228, loss_ce: 0.138606
[00:01:48.600] iteration 67 : loss : 0.584174, loss_ce: 0.214069
[00:01:48.887] iteration 68 : loss : 0.588330, loss_ce: 0.262023
[00:01:49.172] iteration 69 : loss : 0.575318, loss_ce: 0.188415
[00:01:49.460] iteration 70 : loss : 0.571156, loss_ce: 0.153621
[00:01:49.748] iteration 71 : loss : 0.571685, loss_ce: 0.182383
[00:01:50.039] iteration 72 : loss : 0.557112, loss_ce: 0.119782
[00:01:50.325] iteration 73 : loss : 0.581963, loss_ce: 0.206019
[00:01:50.615] iteration 74 : loss : 0.572693, loss_ce: 0.189247
[00:01:50.903] iteration 75 : loss : 0.557131, loss_ce: 0.150742
[00:01:51.190] iteration 76 : loss : 0.595547, loss_ce: 0.255455
[00:01:51.478] iteration 77 : loss : 0.578322, loss_ce: 0.210570
[00:01:51.765] iteration 78 : loss : 0.567120, loss_ce: 0.213401
[00:01:52.053] iteration 79 : loss : 0.580113, loss_ce: 0.239659
[00:01:52.341] iteration 80 : loss : 0.592295, loss_ce: 0.288715
[00:01:52.644] iteration 81 : loss : 0.581093, loss_ce: 0.256414
[00:01:52.929] iteration 82 : loss : 0.564048, loss_ce: 0.204262
[00:01:53.219] iteration 83 : loss : 0.559457, loss_ce: 0.166050
[00:01:53.506] iteration 84 : loss : 0.559772, loss_ce: 0.155666
[00:01:53.792] iteration 85 : loss : 0.590425, loss_ce: 0.232530
[00:01:54.079] iteration 86 : loss : 0.561412, loss_ce: 0.145237
[00:01:54.366] iteration 87 : loss : 0.559391, loss_ce: 0.138744
[00:01:54.655] iteration 88 : loss : 0.559137, loss_ce: 0.159570
[00:01:54.941] iteration 89 : loss : 0.568139, loss_ce: 0.193448
[00:01:55.226] iteration 90 : loss : 0.558527, loss_ce: 0.171208
[00:01:55.515] iteration 91 : loss : 0.589585, loss_ce: 0.268270
[00:01:55.800] iteration 92 : loss : 0.578623, loss_ce: 0.190768
[00:01:56.087] iteration 93 : loss : 0.559664, loss_ce: 0.183282
[00:01:56.373] iteration 94 : loss : 0.554058, loss_ce: 0.140737
[00:01:56.662] iteration 95 : loss : 0.563051, loss_ce: 0.148597
[00:01:56.949] iteration 96 : loss : 0.560384, loss_ce: 0.170691
[00:01:57.235] iteration 97 : loss : 0.577994, loss_ce: 0.189965
[00:01:57.524] iteration 98 : loss : 0.564428, loss_ce: 0.140966
[00:01:57.811] iteration 99 : loss : 0.558857, loss_ce: 0.137913
[00:01:58.098] iteration 100 : loss : 0.563051, loss_ce: 0.176587
[00:01:58.405] iteration 101 : loss : 0.562302, loss_ce: 0.193027
[00:01:58.693] iteration 102 : loss : 0.576638, loss_ce: 0.230163
[00:01:58.980] iteration 103 : loss : 0.556974, loss_ce: 0.188658
[00:01:59.267] iteration 104 : loss : 0.573265, loss_ce: 0.250270
[00:01:59.554] iteration 105 : loss : 0.587540, loss_ce: 0.231161
[00:01:59.841] iteration 106 : loss : 0.552069, loss_ce: 0.181796
[00:02:00.129] iteration 107 : loss : 0.588424, loss_ce: 0.243289
[00:02:00.416] iteration 108 : loss : 0.562317, loss_ce: 0.156158
[00:02:00.708] iteration 109 : loss : 0.607174, loss_ce: 0.282536
[00:02:00.998] iteration 110 : loss : 0.552226, loss_ce: 0.144912
[00:02:01.284] iteration 111 : loss : 0.581220, loss_ce: 0.233787
[00:02:01.571] iteration 112 : loss : 0.541338, loss_ce: 0.158117
[00:02:01.863] iteration 113 : loss : 0.567510, loss_ce: 0.250710
[00:02:02.150] iteration 114 : loss : 0.568957, loss_ce: 0.225022
[00:02:02.438] iteration 115 : loss : 0.557586, loss_ce: 0.187954
[00:02:02.726] iteration 116 : loss : 0.535582, loss_ce: 0.118311
[00:02:03.014] iteration 117 : loss : 0.575276, loss_ce: 0.203850
[00:02:03.299] iteration 118 : loss : 0.556326, loss_ce: 0.160250
[00:02:03.585] iteration 119 : loss : 0.573125, loss_ce: 0.188070
[00:02:03.871] iteration 120 : loss : 0.543658, loss_ce: 0.136583
[00:02:04.174] iteration 121 : loss : 0.563449, loss_ce: 0.206495
[00:02:04.463] iteration 122 : loss : 0.580680, loss_ce: 0.272458
[00:02:04.750] iteration 123 : loss : 0.568095, loss_ce: 0.232305
[00:02:05.040] iteration 124 : loss : 0.566749, loss_ce: 0.225577
[00:02:05.330] iteration 125 : loss : 0.579785, loss_ce: 0.257825
[00:02:05.618] iteration 126 : loss : 0.561601, loss_ce: 0.195417
[00:02:05.907] iteration 127 : loss : 0.558270, loss_ce: 0.150283
[00:02:06.199] iteration 128 : loss : 0.564981, loss_ce: 0.163512
[00:02:06.487] iteration 129 : loss : 0.565999, loss_ce: 0.177671
[00:02:06.783] iteration 130 : loss : 0.570719, loss_ce: 0.201154
[00:02:07.071] iteration 131 : loss : 0.547645, loss_ce: 0.202391
[00:02:07.359] iteration 132 : loss : 0.554203, loss_ce: 0.211449
[00:02:07.651] iteration 133 : loss : 0.558578, loss_ce: 0.223644
[00:02:07.940] iteration 134 : loss : 0.546223, loss_ce: 0.188348
[00:02:08.227] iteration 135 : loss : 0.548631, loss_ce: 0.180166
[00:02:08.520] iteration 136 : loss : 0.525466, loss_ce: 0.068683
[00:02:08.816] iteration 137 : loss : 0.570504, loss_ce: 0.165243
[00:02:09.104] iteration 138 : loss : 0.569331, loss_ce: 0.182497
[00:02:09.244] iteration 139 : loss : 0.548455, loss_ce: 0.068197
[00:02:09.826] save model to ./logs/swin_unet\epoch_0.pth
[00:02:26.221] iteration 140 : loss : 0.569084, loss_ce: 0.241206
[00:02:26.522] iteration 141 : loss : 0.563398, loss_ce: 0.245429
[00:02:26.807] iteration 142 : loss : 0.560529, loss_ce: 0.190935
[00:02:27.091] iteration 143 : loss : 0.558321, loss_ce: 0.168284
[00:02:27.379] iteration 144 : loss : 0.530546, loss_ce: 0.099263
[00:02:27.664] iteration 145 : loss : 0.532523, loss_ce: 0.072494
[00:02:27.950] iteration 146 : loss : 0.567699, loss_ce: 0.166356
[00:02:28.237] iteration 147 : loss : 0.592695, loss_ce: 0.235040
[00:02:28.523] iteration 148 : loss : 0.522486, loss_ce: 0.085024
[00:02:28.809] iteration 149 : loss : 0.546333, loss_ce: 0.162202
[00:02:29.094] iteration 150 : loss : 0.557578, loss_ce: 0.216380
[00:02:29.383] iteration 151 : loss : 0.541228, loss_ce: 0.164409
[00:02:29.670] iteration 152 : loss : 0.539731, loss_ce: 0.154969
[00:02:29.957] iteration 153 : loss : 0.563238, loss_ce: 0.181918
[00:02:30.245] iteration 154 : loss : 0.531893, loss_ce: 0.086342
[00:02:30.533] iteration 155 : loss : 0.530291, loss_ce: 0.149678
[00:02:30.820] iteration 156 : loss : 0.536213, loss_ce: 0.157273
[00:02:31.104] iteration 157 : loss : 0.537796, loss_ce: 0.163210
[00:02:31.390] iteration 158 : loss : 0.520273, loss_ce: 0.133150
[00:02:31.677] iteration 159 : loss : 0.542538, loss_ce: 0.186941
[00:02:31.964] iteration 160 : loss : 0.546849, loss_ce: 0.199165
[00:02:32.265] iteration 161 : loss : 0.536006, loss_ce: 0.178702
[00:02:32.551] iteration 162 : loss : 0.515762, loss_ce: 0.106741
[00:02:32.838] iteration 163 : loss : 0.576436, loss_ce: 0.186356
[00:02:33.128] iteration 164 : loss : 0.557762, loss_ce: 0.173819
[00:02:33.412] iteration 165 : loss : 0.540496, loss_ce: 0.177807
[00:02:33.698] iteration 166 : loss : 0.555952, loss_ce: 0.212595
[00:02:33.985] iteration 167 : loss : 0.529142, loss_ce: 0.169268
[00:02:34.270] iteration 168 : loss : 0.534356, loss_ce: 0.156301
[00:02:34.558] iteration 169 : loss : 0.563013, loss_ce: 0.167555
[00:02:34.846] iteration 170 : loss : 0.514096, loss_ce: 0.130441
[00:02:35.134] iteration 171 : loss : 0.519945, loss_ce: 0.120197
[00:02:35.419] iteration 172 : loss : 0.525607, loss_ce: 0.125989
[00:02:35.705] iteration 173 : loss : 0.515123, loss_ce: 0.104500
[00:02:35.994] iteration 174 : loss : 0.515073, loss_ce: 0.149005
[00:02:36.281] iteration 175 : loss : 0.526862, loss_ce: 0.145362
[00:02:36.566] iteration 176 : loss : 0.546670, loss_ce: 0.167016
[00:02:36.851] iteration 177 : loss : 0.508070, loss_ce: 0.088806
[00:02:37.139] iteration 178 : loss : 0.533191, loss_ce: 0.204436
[00:02:37.428] iteration 179 : loss : 0.549898, loss_ce: 0.226839
[00:02:37.713] iteration 180 : loss : 0.536910, loss_ce: 0.137669
[00:02:38.016] iteration 181 : loss : 0.509385, loss_ce: 0.099814
[00:02:38.303] iteration 182 : loss : 0.503524, loss_ce: 0.101362
[00:02:38.589] iteration 183 : loss : 0.515399, loss_ce: 0.113472
[00:02:38.876] iteration 184 : loss : 0.525325, loss_ce: 0.160913
[00:02:39.164] iteration 185 : loss : 0.541871, loss_ce: 0.225315
[00:02:39.451] iteration 186 : loss : 0.526262, loss_ce: 0.143240
[00:02:39.736] iteration 187 : loss : 0.528019, loss_ce: 0.122446
[00:02:40.025] iteration 188 : loss : 0.550700, loss_ce: 0.208493
[00:02:40.312] iteration 189 : loss : 0.549978, loss_ce: 0.187934
[00:02:40.603] iteration 190 : loss : 0.522158, loss_ce: 0.148382
[00:02:40.888] iteration 191 : loss : 0.510553, loss_ce: 0.124043
[00:02:41.176] iteration 192 : loss : 0.507835, loss_ce: 0.127731
[00:02:41.467] iteration 193 : loss : 0.532419, loss_ce: 0.136168
[00:02:41.759] iteration 194 : loss : 0.516523, loss_ce: 0.155458
[00:02:42.045] iteration 195 : loss : 0.539856, loss_ce: 0.195494
[00:02:42.335] iteration 196 : loss : 0.517870, loss_ce: 0.114971
[00:02:42.620] iteration 197 : loss : 0.542701, loss_ce: 0.152870
[00:02:42.906] iteration 198 : loss : 0.531957, loss_ce: 0.166261
[00:02:43.191] iteration 199 : loss : 0.520632, loss_ce: 0.137661
[00:02:43.482] iteration 200 : loss : 0.500101, loss_ce: 0.131834
[00:02:43.786] iteration 201 : loss : 0.522784, loss_ce: 0.146849
[00:02:44.072] iteration 202 : loss : 0.544588, loss_ce: 0.229713
[00:02:44.359] iteration 203 : loss : 0.517900, loss_ce: 0.138040
[00:02:44.648] iteration 204 : loss : 0.503793, loss_ce: 0.104387
[00:02:44.937] iteration 205 : loss : 0.521588, loss_ce: 0.116352
[00:02:45.223] iteration 206 : loss : 0.519015, loss_ce: 0.159837
[00:02:45.511] iteration 207 : loss : 0.509938, loss_ce: 0.143939
[00:02:45.801] iteration 208 : loss : 0.501821, loss_ce: 0.102689
[00:02:46.088] iteration 209 : loss : 0.523285, loss_ce: 0.165909
[00:02:46.375] iteration 210 : loss : 0.518535, loss_ce: 0.131758
[00:02:46.661] iteration 211 : loss : 0.508978, loss_ce: 0.120429
[00:02:46.946] iteration 212 : loss : 0.522228, loss_ce: 0.162155
[00:02:47.234] iteration 213 : loss : 0.525802, loss_ce: 0.163066
[00:02:47.523] iteration 214 : loss : 0.518430, loss_ce: 0.156809
[00:02:47.811] iteration 215 : loss : 0.507510, loss_ce: 0.114658
[00:02:48.099] iteration 216 : loss : 0.515282, loss_ce: 0.126649
[00:02:48.384] iteration 217 : loss : 0.499309, loss_ce: 0.085751
[00:02:48.672] iteration 218 : loss : 0.499879, loss_ce: 0.125613
[00:02:48.958] iteration 219 : loss : 0.516885, loss_ce: 0.150513
[00:02:49.248] iteration 220 : loss : 0.528899, loss_ce: 0.169946
[00:02:49.550] iteration 221 : loss : 0.538146, loss_ce: 0.210191
[00:02:49.836] iteration 222 : loss : 0.503710, loss_ce: 0.129583
[00:02:50.126] iteration 223 : loss : 0.535974, loss_ce: 0.189006
[00:02:50.414] iteration 224 : loss : 0.516172, loss_ce: 0.171779
[00:02:50.705] iteration 225 : loss : 0.518945, loss_ce: 0.140140
[00:02:50.995] iteration 226 : loss : 0.504924, loss_ce: 0.137907
[00:02:51.284] iteration 227 : loss : 0.519574, loss_ce: 0.153896
[00:02:51.573] iteration 228 : loss : 0.508264, loss_ce: 0.136542
[00:02:51.863] iteration 229 : loss : 0.511056, loss_ce: 0.155194
[00:02:52.155] iteration 230 : loss : 0.508873, loss_ce: 0.141755
[00:02:52.444] iteration 231 : loss : 0.501489, loss_ce: 0.127482
[00:02:52.733] iteration 232 : loss : 0.507400, loss_ce: 0.117112
[00:02:53.021] iteration 233 : loss : 0.496799, loss_ce: 0.086186
[00:02:53.311] iteration 234 : loss : 0.528732, loss_ce: 0.135484
[00:02:53.597] iteration 235 : loss : 0.509027, loss_ce: 0.112298
[00:02:53.888] iteration 236 : loss : 0.514918, loss_ce: 0.160018
[00:02:54.177] iteration 237 : loss : 0.545890, loss_ce: 0.222416
[00:02:54.462] iteration 238 : loss : 0.508386, loss_ce: 0.138352
[00:02:54.755] iteration 239 : loss : 0.527789, loss_ce: 0.117367
[00:02:55.046] iteration 240 : loss : 0.566436, loss_ce: 0.190479
[00:02:55.351] iteration 241 : loss : 0.528245, loss_ce: 0.156995
[00:02:55.638] iteration 242 : loss : 0.530323, loss_ce: 0.151714
[00:02:55.928] iteration 243 : loss : 0.529851, loss_ce: 0.184423
[00:02:56.217] iteration 244 : loss : 0.516171, loss_ce: 0.149839
[00:02:56.509] iteration 245 : loss : 0.520000, loss_ce: 0.158104
[00:02:56.797] iteration 246 : loss : 0.506820, loss_ce: 0.112648
[00:02:57.088] iteration 247 : loss : 0.532832, loss_ce: 0.159551
[00:02:57.377] iteration 248 : loss : 0.500529, loss_ce: 0.065964
[00:02:57.665] iteration 249 : loss : 0.498308, loss_ce: 0.084851
[00:02:57.956] iteration 250 : loss : 0.510020, loss_ce: 0.150358
[00:02:58.244] iteration 251 : loss : 0.517170, loss_ce: 0.152018
[00:02:58.532] iteration 252 : loss : 0.525615, loss_ce: 0.162357
[00:02:58.821] iteration 253 : loss : 0.506997, loss_ce: 0.139996
[00:02:59.110] iteration 254 : loss : 0.529565, loss_ce: 0.200602
[00:02:59.398] iteration 255 : loss : 0.523277, loss_ce: 0.133571
[00:02:59.687] iteration 256 : loss : 0.515140, loss_ce: 0.158183
[00:02:59.977] iteration 257 : loss : 0.511966, loss_ce: 0.126427
[00:03:00.266] iteration 258 : loss : 0.516404, loss_ce: 0.160735
[00:03:00.560] iteration 259 : loss : 0.525104, loss_ce: 0.176913
[00:03:00.852] iteration 260 : loss : 0.516700, loss_ce: 0.168440
[00:03:01.158] iteration 261 : loss : 0.496967, loss_ce: 0.098517
[00:03:01.450] iteration 262 : loss : 0.512336, loss_ce: 0.115885
[00:03:01.745] iteration 263 : loss : 0.534617, loss_ce: 0.127555
[00:03:02.038] iteration 264 : loss : 0.520379, loss_ce: 0.136267
[00:03:02.333] iteration 265 : loss : 0.495204, loss_ce: 0.113286
[00:03:02.623] iteration 266 : loss : 0.555907, loss_ce: 0.271576
[00:03:02.919] iteration 267 : loss : 0.530450, loss_ce: 0.198953
[00:03:03.214] iteration 268 : loss : 0.521212, loss_ce: 0.172048
[00:03:03.509] iteration 269 : loss : 0.514704, loss_ce: 0.086018
[00:03:03.803] iteration 270 : loss : 0.502787, loss_ce: 0.106499
[00:03:04.100] iteration 271 : loss : 0.543383, loss_ce: 0.200994
[00:03:04.392] iteration 272 : loss : 0.522930, loss_ce: 0.177995
[00:03:04.688] iteration 273 : loss : 0.506666, loss_ce: 0.121162
[00:03:04.982] iteration 274 : loss : 0.505133, loss_ce: 0.117140
[00:03:05.275] iteration 275 : loss : 0.494155, loss_ce: 0.114297
[00:03:05.568] iteration 276 : loss : 0.501545, loss_ce: 0.118935
[00:03:05.864] iteration 277 : loss : 0.512020, loss_ce: 0.149969
[00:03:05.952] iteration 278 : loss : 0.508182, loss_ce: 0.043417
[00:03:22.818] iteration 279 : loss : 0.496646, loss_ce: 0.117102
[00:03:23.102] iteration 280 : loss : 0.493102, loss_ce: 0.093232
[00:03:23.402] iteration 281 : loss : 0.511534, loss_ce: 0.159402
[00:03:23.689] iteration 282 : loss : 0.519667, loss_ce: 0.172933
[00:03:23.975] iteration 283 : loss : 0.524968, loss_ce: 0.180915
[00:03:24.263] iteration 284 : loss : 0.502605, loss_ce: 0.107443
[00:03:24.550] iteration 285 : loss : 0.492167, loss_ce: 0.111767
[00:03:24.838] iteration 286 : loss : 0.507013, loss_ce: 0.085886
[00:03:25.126] iteration 287 : loss : 0.492408, loss_ce: 0.107278
[00:03:25.414] iteration 288 : loss : 0.507727, loss_ce: 0.129260
[00:03:25.699] iteration 289 : loss : 0.493385, loss_ce: 0.121139
[00:03:25.985] iteration 290 : loss : 0.527439, loss_ce: 0.198928
[00:03:26.270] iteration 291 : loss : 0.510663, loss_ce: 0.154568
[00:03:26.556] iteration 292 : loss : 0.506058, loss_ce: 0.143584
[00:03:26.844] iteration 293 : loss : 0.537444, loss_ce: 0.176879
[00:03:27.131] iteration 294 : loss : 0.509669, loss_ce: 0.134537
[00:03:27.418] iteration 295 : loss : 0.507870, loss_ce: 0.129083
[00:03:27.702] iteration 296 : loss : 0.523699, loss_ce: 0.123780
[00:03:27.990] iteration 297 : loss : 0.510114, loss_ce: 0.168155
[00:03:28.278] iteration 298 : loss : 0.511291, loss_ce: 0.163378
[00:03:28.563] iteration 299 : loss : 0.482454, loss_ce: 0.112529
[00:03:28.851] iteration 300 : loss : 0.490513, loss_ce: 0.093270
[00:03:29.163] iteration 301 : loss : 0.512659, loss_ce: 0.120005
[00:03:29.448] iteration 302 : loss : 0.514948, loss_ce: 0.133170
[00:03:29.737] iteration 303 : loss : 0.506807, loss_ce: 0.149365
[00:03:30.026] iteration 304 : loss : 0.502328, loss_ce: 0.147963
[00:03:30.313] iteration 305 : loss : 0.515727, loss_ce: 0.160805
[00:03:30.599] iteration 306 : loss : 0.490585, loss_ce: 0.121892
[00:03:30.885] iteration 307 : loss : 0.488286, loss_ce: 0.063972
[00:03:31.172] iteration 308 : loss : 0.503535, loss_ce: 0.088091
[00:03:31.459] iteration 309 : loss : 0.497053, loss_ce: 0.083424
[00:03:31.746] iteration 310 : loss : 0.494276, loss_ce: 0.115560
[00:03:32.035] iteration 311 : loss : 0.504227, loss_ce: 0.161677
[00:03:32.324] iteration 312 : loss : 0.526582, loss_ce: 0.199603
[00:03:32.613] iteration 313 : loss : 0.513510, loss_ce: 0.188309
[00:03:32.901] iteration 314 : loss : 0.485114, loss_ce: 0.097189
[00:03:33.186] iteration 315 : loss : 0.480770, loss_ce: 0.109853
[00:03:33.473] iteration 316 : loss : 0.498446, loss_ce: 0.116257
[00:03:33.762] iteration 317 : loss : 0.515008, loss_ce: 0.106984
[00:03:34.049] iteration 318 : loss : 0.488045, loss_ce: 0.107795
[00:03:34.336] iteration 319 : loss : 0.506908, loss_ce: 0.153597
[00:03:34.623] iteration 320 : loss : 0.493383, loss_ce: 0.082043
[00:03:34.923] iteration 321 : loss : 0.488297, loss_ce: 0.083836
[00:03:35.209] iteration 322 : loss : 0.486212, loss_ce: 0.074565
[00:03:35.497] iteration 323 : loss : 0.469073, loss_ce: 0.057793
[00:03:35.784] iteration 324 : loss : 0.503537, loss_ce: 0.162817
[00:03:36.071] iteration 325 : loss : 0.504809, loss_ce: 0.148451
[00:03:36.357] iteration 326 : loss : 0.510804, loss_ce: 0.161913
[00:03:36.645] iteration 327 : loss : 0.499431, loss_ce: 0.135212
[00:03:36.929] iteration 328 : loss : 0.528517, loss_ce: 0.228817
[00:03:37.219] iteration 329 : loss : 0.501236, loss_ce: 0.157568
[00:03:37.507] iteration 330 : loss : 0.511179, loss_ce: 0.172349
[00:03:37.793] iteration 331 : loss : 0.489936, loss_ce: 0.130820
[00:03:38.082] iteration 332 : loss : 0.497955, loss_ce: 0.135330
[00:03:38.371] iteration 333 : loss : 0.505445, loss_ce: 0.134947
[00:03:38.660] iteration 334 : loss : 0.496987, loss_ce: 0.152859
[00:03:38.949] iteration 335 : loss : 0.494979, loss_ce: 0.140725
[00:03:39.237] iteration 336 : loss : 0.476710, loss_ce: 0.080768
[00:03:39.523] iteration 337 : loss : 0.484687, loss_ce: 0.079462
[00:03:39.811] iteration 338 : loss : 0.507454, loss_ce: 0.150252
[00:03:40.099] iteration 339 : loss : 0.499367, loss_ce: 0.143423
[00:03:40.390] iteration 340 : loss : 0.493049, loss_ce: 0.138343
[00:03:40.696] iteration 341 : loss : 0.491748, loss_ce: 0.140474
[00:03:40.981] iteration 342 : loss : 0.512427, loss_ce: 0.159794
[00:03:41.270] iteration 343 : loss : 0.501670, loss_ce: 0.154531
[00:03:41.558] iteration 344 : loss : 0.496271, loss_ce: 0.118349
[00:03:41.847] iteration 345 : loss : 0.484735, loss_ce: 0.110800
[00:03:42.133] iteration 346 : loss : 0.520435, loss_ce: 0.139644
[00:03:42.419] iteration 347 : loss : 0.507863, loss_ce: 0.170635
[00:03:42.710] iteration 348 : loss : 0.500687, loss_ce: 0.188535
[00:03:42.997] iteration 349 : loss : 0.492385, loss_ce: 0.122194
[00:03:43.282] iteration 350 : loss : 0.502185, loss_ce: 0.145235
[00:03:43.571] iteration 351 : loss : 0.506355, loss_ce: 0.084096
[00:03:43.858] iteration 352 : loss : 0.509621, loss_ce: 0.171332
[00:03:44.148] iteration 353 : loss : 0.495594, loss_ce: 0.117375
[00:03:44.438] iteration 354 : loss : 0.498579, loss_ce: 0.117212
[00:03:44.723] iteration 355 : loss : 0.503553, loss_ce: 0.171050
[00:03:45.011] iteration 356 : loss : 0.505673, loss_ce: 0.156714
[00:03:45.301] iteration 357 : loss : 0.498818, loss_ce: 0.168696
[00:03:45.591] iteration 358 : loss : 0.514708, loss_ce: 0.210280
[00:03:45.878] iteration 359 : loss : 0.540017, loss_ce: 0.080487
[00:03:46.164] iteration 360 : loss : 0.526009, loss_ce: 0.215564
[00:03:46.470] iteration 361 : loss : 0.486493, loss_ce: 0.142522
[00:03:46.757] iteration 362 : loss : 0.493055, loss_ce: 0.171816
[00:03:47.045] iteration 363 : loss : 0.500984, loss_ce: 0.182480
[00:03:47.334] iteration 364 : loss : 0.502752, loss_ce: 0.083562
[00:03:47.622] iteration 365 : loss : 0.485646, loss_ce: 0.108669
[00:03:47.909] iteration 366 : loss : 0.499563, loss_ce: 0.142075
[00:03:48.196] iteration 367 : loss : 0.480299, loss_ce: 0.096803
[00:03:48.482] iteration 368 : loss : 0.492438, loss_ce: 0.157449
[00:03:48.769] iteration 369 : loss : 0.477906, loss_ce: 0.098571
[00:03:49.057] iteration 370 : loss : 0.494694, loss_ce: 0.131719
[00:03:49.343] iteration 371 : loss : 0.503971, loss_ce: 0.137485
[00:03:49.629] iteration 372 : loss : 0.489562, loss_ce: 0.156226
[00:03:49.916] iteration 373 : loss : 0.506870, loss_ce: 0.190382
[00:03:50.203] iteration 374 : loss : 0.476692, loss_ce: 0.131496
[00:03:50.492] iteration 375 : loss : 0.499383, loss_ce: 0.091872
[00:03:50.783] iteration 376 : loss : 0.492258, loss_ce: 0.144136
[00:03:51.070] iteration 377 : loss : 0.490611, loss_ce: 0.103531
[00:03:51.358] iteration 378 : loss : 0.512635, loss_ce: 0.149054
[00:03:51.645] iteration 379 : loss : 0.508452, loss_ce: 0.167215
[00:03:51.936] iteration 380 : loss : 0.510248, loss_ce: 0.078322
[00:03:52.236] iteration 381 : loss : 0.533805, loss_ce: 0.234903
[00:03:52.525] iteration 382 : loss : 0.504681, loss_ce: 0.163517
[00:03:52.812] iteration 383 : loss : 0.486107, loss_ce: 0.130941
[00:03:53.099] iteration 384 : loss : 0.508970, loss_ce: 0.128224
[00:03:53.387] iteration 385 : loss : 0.503243, loss_ce: 0.119123
[00:03:53.674] iteration 386 : loss : 0.495627, loss_ce: 0.121158
[00:03:53.962] iteration 387 : loss : 0.480992, loss_ce: 0.131545
[00:03:54.249] iteration 388 : loss : 0.489068, loss_ce: 0.156406
[00:03:54.536] iteration 389 : loss : 0.501035, loss_ce: 0.166982
[00:03:54.825] iteration 390 : loss : 0.501623, loss_ce: 0.172018
[00:03:55.113] iteration 391 : loss : 0.512675, loss_ce: 0.192615
[00:03:55.399] iteration 392 : loss : 0.500981, loss_ce: 0.172412
[00:03:55.686] iteration 393 : loss : 0.516334, loss_ce: 0.113171
[00:03:55.975] iteration 394 : loss : 0.485224, loss_ce: 0.109148
[00:03:56.262] iteration 395 : loss : 0.487869, loss_ce: 0.145394
[00:03:56.548] iteration 396 : loss : 0.487789, loss_ce: 0.157336
[00:03:56.834] iteration 397 : loss : 0.479663, loss_ce: 0.119934
[00:03:57.122] iteration 398 : loss : 0.496746, loss_ce: 0.141875
[00:03:57.409] iteration 399 : loss : 0.496620, loss_ce: 0.166325
[00:03:57.695] iteration 400 : loss : 0.491053, loss_ce: 0.097191
[00:03:58.001] iteration 401 : loss : 0.515806, loss_ce: 0.139831
[00:03:58.290] iteration 402 : loss : 0.480980, loss_ce: 0.136835
[00:03:58.579] iteration 403 : loss : 0.460731, loss_ce: 0.111297
[00:03:58.868] iteration 404 : loss : 0.483582, loss_ce: 0.151358
[00:03:59.156] iteration 405 : loss : 0.489348, loss_ce: 0.126647
[00:03:59.449] iteration 406 : loss : 0.482005, loss_ce: 0.139813
[00:03:59.741] iteration 407 : loss : 0.509659, loss_ce: 0.155900
[00:04:00.032] iteration 408 : loss : 0.473462, loss_ce: 0.138689
[00:04:00.322] iteration 409 : loss : 0.465491, loss_ce: 0.091785
[00:04:00.616] iteration 410 : loss : 0.469902, loss_ce: 0.135035
[00:04:00.909] iteration 411 : loss : 0.488661, loss_ce: 0.060343
[00:04:01.199] iteration 412 : loss : 0.478503, loss_ce: 0.094127
[00:04:01.488] iteration 413 : loss : 0.490453, loss_ce: 0.133273
[00:04:01.777] iteration 414 : loss : 0.508478, loss_ce: 0.172390
[00:04:02.066] iteration 415 : loss : 0.474020, loss_ce: 0.114954
[00:04:02.355] iteration 416 : loss : 0.490265, loss_ce: 0.125659
[00:04:02.430] iteration 417 : loss : 0.475581, loss_ce: 0.130298
[00:04:18.942] iteration 418 : loss : 0.483536, loss_ce: 0.141215
[00:04:19.226] iteration 419 : loss : 0.499438, loss_ce: 0.179636
[00:04:19.513] iteration 420 : loss : 0.501665, loss_ce: 0.096203
[00:04:19.812] iteration 421 : loss : 0.487701, loss_ce: 0.188594
[00:04:20.099] iteration 422 : loss : 0.478017, loss_ce: 0.154822
[00:04:20.386] iteration 423 : loss : 0.451008, loss_ce: 0.054498
[00:04:20.673] iteration 424 : loss : 0.480860, loss_ce: 0.108280
[00:04:20.959] iteration 425 : loss : 0.454912, loss_ce: 0.128400
[00:04:21.244] iteration 426 : loss : 0.479756, loss_ce: 0.129809
[00:04:21.531] iteration 427 : loss : 0.476994, loss_ce: 0.045027
[00:04:21.817] iteration 428 : loss : 0.469965, loss_ce: 0.076359
[00:04:22.102] iteration 429 : loss : 0.472763, loss_ce: 0.122419
[00:04:22.389] iteration 430 : loss : 0.496100, loss_ce: 0.180081
[00:04:22.675] iteration 431 : loss : 0.484894, loss_ce: 0.191076
[00:04:22.961] iteration 432 : loss : 0.474125, loss_ce: 0.088908
[00:04:23.249] iteration 433 : loss : 0.454834, loss_ce: 0.097083
[00:04:23.538] iteration 434 : loss : 0.471449, loss_ce: 0.122884
[00:04:23.824] iteration 435 : loss : 0.472679, loss_ce: 0.125047
[00:04:24.110] iteration 436 : loss : 0.484135, loss_ce: 0.084316
[00:04:24.396] iteration 437 : loss : 0.466648, loss_ce: 0.119492
[00:04:24.683] iteration 438 : loss : 0.483051, loss_ce: 0.143087
[00:04:24.971] iteration 439 : loss : 0.463603, loss_ce: 0.138374
[00:04:25.260] iteration 440 : loss : 0.463242, loss_ce: 0.106845
[00:04:25.559] iteration 441 : loss : 0.456419, loss_ce: 0.115296
[00:04:25.847] iteration 442 : loss : 0.480450, loss_ce: 0.135146
[00:04:26.134] iteration 443 : loss : 0.448085, loss_ce: 0.108860
[00:04:26.420] iteration 444 : loss : 0.490336, loss_ce: 0.179186
[00:04:26.706] iteration 445 : loss : 0.454901, loss_ce: 0.112938
[00:04:26.993] iteration 446 : loss : 0.460321, loss_ce: 0.080407
[00:04:27.281] iteration 447 : loss : 0.482565, loss_ce: 0.121378
[00:04:27.567] iteration 448 : loss : 0.493962, loss_ce: 0.189143
[00:04:27.855] iteration 449 : loss : 0.477942, loss_ce: 0.155995
[00:04:28.141] iteration 450 : loss : 0.448852, loss_ce: 0.069307
[00:04:28.427] iteration 451 : loss : 0.470252, loss_ce: 0.125895
[00:04:28.716] iteration 452 : loss : 0.508753, loss_ce: 0.257931
[00:04:29.003] iteration 453 : loss : 0.467820, loss_ce: 0.111860
[00:04:29.290] iteration 454 : loss : 0.467651, loss_ce: 0.096432
[00:04:29.574] iteration 455 : loss : 0.473619, loss_ce: 0.132309
[00:04:29.861] iteration 456 : loss : 0.458417, loss_ce: 0.123336
[00:04:30.149] iteration 457 : loss : 0.471770, loss_ce: 0.160209
[00:04:30.436] iteration 458 : loss : 0.489755, loss_ce: 0.191550
[00:04:30.722] iteration 459 : loss : 0.453519, loss_ce: 0.134241
[00:04:31.008] iteration 460 : loss : 0.465737, loss_ce: 0.108811
[00:04:31.311] iteration 461 : loss : 0.435666, loss_ce: 0.078066
[00:04:31.597] iteration 462 : loss : 0.493711, loss_ce: 0.104223
[00:04:31.884] iteration 463 : loss : 0.469914, loss_ce: 0.152721
[00:04:32.171] iteration 464 : loss : 0.479017, loss_ce: 0.145265
[00:04:32.457] iteration 465 : loss : 0.475972, loss_ce: 0.157453
[00:04:32.743] iteration 466 : loss : 0.453262, loss_ce: 0.133495
[00:04:33.030] iteration 467 : loss : 0.442826, loss_ce: 0.089117
[00:04:33.317] iteration 468 : loss : 0.477372, loss_ce: 0.068951
[00:04:33.603] iteration 469 : loss : 0.442647, loss_ce: 0.095645
[00:04:33.891] iteration 470 : loss : 0.486718, loss_ce: 0.089316
[00:04:34.176] iteration 471 : loss : 0.496552, loss_ce: 0.201339
[00:04:34.463] iteration 472 : loss : 0.491599, loss_ce: 0.183269
[00:04:34.751] iteration 473 : loss : 0.460846, loss_ce: 0.120165
[00:04:35.040] iteration 474 : loss : 0.472079, loss_ce: 0.156251
[00:04:35.328] iteration 475 : loss : 0.442751, loss_ce: 0.066639
[00:04:35.615] iteration 476 : loss : 0.470529, loss_ce: 0.091290
[00:04:35.902] iteration 477 : loss : 0.499633, loss_ce: 0.152704
[00:04:36.190] iteration 478 : loss : 0.473812, loss_ce: 0.135636
[00:04:36.476] iteration 479 : loss : 0.464002, loss_ce: 0.142892
[00:04:36.762] iteration 480 : loss : 0.462558, loss_ce: 0.099271
[00:04:37.063] iteration 481 : loss : 0.476112, loss_ce: 0.135885
[00:04:37.350] iteration 482 : loss : 0.438097, loss_ce: 0.085616
[00:04:37.639] iteration 483 : loss : 0.487598, loss_ce: 0.034308
[00:04:37.928] iteration 484 : loss : 0.475735, loss_ce: 0.129974
[00:04:38.214] iteration 485 : loss : 0.497820, loss_ce: 0.235499
[00:04:38.502] iteration 486 : loss : 0.475156, loss_ce: 0.145567
[00:04:38.791] iteration 487 : loss : 0.462170, loss_ce: 0.120423
[00:04:39.080] iteration 488 : loss : 0.465542, loss_ce: 0.136836
[00:04:39.368] iteration 489 : loss : 0.462339, loss_ce: 0.153583
[00:04:39.655] iteration 490 : loss : 0.467214, loss_ce: 0.107466
[00:04:39.941] iteration 491 : loss : 0.458059, loss_ce: 0.090084
[00:04:40.229] iteration 492 : loss : 0.465324, loss_ce: 0.120065
[00:04:40.518] iteration 493 : loss : 0.492002, loss_ce: 0.202031
[00:04:40.804] iteration 494 : loss : 0.477925, loss_ce: 0.184653
[00:04:41.092] iteration 495 : loss : 0.475953, loss_ce: 0.124007
[00:04:41.381] iteration 496 : loss : 0.463646, loss_ce: 0.149919
[00:04:41.668] iteration 497 : loss : 0.485984, loss_ce: 0.189019
[00:04:41.955] iteration 498 : loss : 0.462008, loss_ce: 0.162915
[00:04:42.244] iteration 499 : loss : 0.485181, loss_ce: 0.151451
[00:04:42.531] iteration 500 : loss : 0.453611, loss_ce: 0.119431
[00:04:42.834] iteration 501 : loss : 0.456398, loss_ce: 0.151349
[00:04:43.122] iteration 502 : loss : 0.464874, loss_ce: 0.110797
[00:04:43.410] iteration 503 : loss : 0.437852, loss_ce: 0.091267
[00:04:43.701] iteration 504 : loss : 0.465259, loss_ce: 0.144627
[00:04:43.987] iteration 505 : loss : 0.434958, loss_ce: 0.088340
[00:04:44.274] iteration 506 : loss : 0.463121, loss_ce: 0.059741
[00:04:44.561] iteration 507 : loss : 0.462668, loss_ce: 0.147924
[00:04:44.848] iteration 508 : loss : 0.490821, loss_ce: 0.155706
[00:04:45.136] iteration 509 : loss : 0.463213, loss_ce: 0.064487
[00:04:45.424] iteration 510 : loss : 0.447167, loss_ce: 0.124230
[00:04:45.713] iteration 511 : loss : 0.426395, loss_ce: 0.083228
[00:04:46.000] iteration 512 : loss : 0.484193, loss_ce: 0.092151
[00:04:46.288] iteration 513 : loss : 0.486272, loss_ce: 0.190462
[00:04:46.577] iteration 514 : loss : 0.469739, loss_ce: 0.117318
[00:04:46.864] iteration 515 : loss : 0.472406, loss_ce: 0.160577
[00:04:47.151] iteration 516 : loss : 0.510780, loss_ce: 0.107561
[00:04:47.437] iteration 517 : loss : 0.491510, loss_ce: 0.229138
[00:04:47.726] iteration 518 : loss : 0.462262, loss_ce: 0.119908
[00:04:48.015] iteration 519 : loss : 0.488302, loss_ce: 0.160732
[00:04:48.305] iteration 520 : loss : 0.502748, loss_ce: 0.132420
[00:04:48.609] iteration 521 : loss : 0.461079, loss_ce: 0.112900
[00:04:48.898] iteration 522 : loss : 0.463654, loss_ce: 0.143340
[00:04:49.184] iteration 523 : loss : 0.480068, loss_ce: 0.145130
[00:04:49.473] iteration 524 : loss : 0.470128, loss_ce: 0.165815
[00:04:49.760] iteration 525 : loss : 0.489752, loss_ce: 0.161301
[00:04:50.050] iteration 526 : loss : 0.445406, loss_ce: 0.117644
[00:04:50.341] iteration 527 : loss : 0.451588, loss_ce: 0.083490
[00:04:50.632] iteration 528 : loss : 0.427727, loss_ce: 0.063628
[00:04:50.925] iteration 529 : loss : 0.446898, loss_ce: 0.114020
[00:04:51.213] iteration 530 : loss : 0.452964, loss_ce: 0.115135
[00:04:51.502] iteration 531 : loss : 0.449973, loss_ce: 0.164905
[00:04:51.792] iteration 532 : loss : 0.457145, loss_ce: 0.133236
[00:04:52.084] iteration 533 : loss : 0.474911, loss_ce: 0.175599
[00:04:52.371] iteration 534 : loss : 0.445232, loss_ce: 0.168828
[00:04:52.659] iteration 535 : loss : 0.492981, loss_ce: 0.138582
[00:04:52.948] iteration 536 : loss : 0.473790, loss_ce: 0.110081
[00:04:53.239] iteration 537 : loss : 0.445838, loss_ce: 0.119655
[00:04:53.529] iteration 538 : loss : 0.447473, loss_ce: 0.119183
[00:04:53.818] iteration 539 : loss : 0.463198, loss_ce: 0.044793
[00:04:54.112] iteration 540 : loss : 0.455849, loss_ce: 0.168879
[00:04:54.435] iteration 541 : loss : 0.449513, loss_ce: 0.108689
[00:04:54.723] iteration 542 : loss : 0.447254, loss_ce: 0.152185
[00:04:55.012] iteration 543 : loss : 0.419139, loss_ce: 0.081565
[00:04:55.308] iteration 544 : loss : 0.459955, loss_ce: 0.160941
[00:04:55.598] iteration 545 : loss : 0.438166, loss_ce: 0.042793
[00:04:55.894] iteration 546 : loss : 0.435161, loss_ce: 0.125938
[00:04:56.185] iteration 547 : loss : 0.453903, loss_ce: 0.135947
[00:04:56.476] iteration 548 : loss : 0.441727, loss_ce: 0.153086
[00:04:56.770] iteration 549 : loss : 0.446231, loss_ce: 0.136911
[00:04:57.063] iteration 550 : loss : 0.442085, loss_ce: 0.143710
[00:04:57.354] iteration 551 : loss : 0.443969, loss_ce: 0.159319
[00:04:57.646] iteration 552 : loss : 0.410930, loss_ce: 0.056356
[00:04:57.940] iteration 553 : loss : 0.440122, loss_ce: 0.107022
[00:04:58.234] iteration 554 : loss : 0.449805, loss_ce: 0.126230
[00:04:58.529] iteration 555 : loss : 0.432647, loss_ce: 0.144359
[00:04:58.616] iteration 556 : loss : 0.523503, loss_ce: 0.031166
[00:05:14.686] iteration 557 : loss : 0.437160, loss_ce: 0.093912
[00:05:14.971] iteration 558 : loss : 0.443114, loss_ce: 0.131332
[00:05:15.255] iteration 559 : loss : 0.464921, loss_ce: 0.105941
[00:05:15.542] iteration 560 : loss : 0.438873, loss_ce: 0.133278
[00:05:15.844] iteration 561 : loss : 0.467958, loss_ce: 0.158577
[00:05:16.132] iteration 562 : loss : 0.464741, loss_ce: 0.104702
[00:05:16.417] iteration 563 : loss : 0.517189, loss_ce: 0.294591
[00:05:16.703] iteration 564 : loss : 0.437201, loss_ce: 0.119482
[00:05:16.990] iteration 565 : loss : 0.438775, loss_ce: 0.122794
[00:05:17.278] iteration 566 : loss : 0.445094, loss_ce: 0.165747
[00:05:17.566] iteration 567 : loss : 0.454282, loss_ce: 0.162143
[00:05:17.854] iteration 568 : loss : 0.450231, loss_ce: 0.101912
[00:05:18.145] iteration 569 : loss : 0.447999, loss_ce: 0.108217
[00:05:18.436] iteration 570 : loss : 0.466980, loss_ce: 0.065009
[00:05:18.725] iteration 571 : loss : 0.432831, loss_ce: 0.105233
[00:05:19.013] iteration 572 : loss : 0.444851, loss_ce: 0.150932
[00:05:19.300] iteration 573 : loss : 0.424092, loss_ce: 0.159239
[00:05:19.589] iteration 574 : loss : 0.413955, loss_ce: 0.096304
[00:05:19.880] iteration 575 : loss : 0.437575, loss_ce: 0.141380
[00:05:20.172] iteration 576 : loss : 0.454620, loss_ce: 0.130111
[00:05:20.461] iteration 577 : loss : 0.470800, loss_ce: 0.091741
[00:05:20.746] iteration 578 : loss : 0.436877, loss_ce: 0.154536
[00:05:21.035] iteration 579 : loss : 0.397423, loss_ce: 0.071492
[00:05:21.320] iteration 580 : loss : 0.457634, loss_ce: 0.163862
[00:05:21.625] iteration 581 : loss : 0.425751, loss_ce: 0.117512
[00:05:21.913] iteration 582 : loss : 0.445879, loss_ce: 0.091418
[00:05:22.202] iteration 583 : loss : 0.478806, loss_ce: 0.120293
[00:05:22.489] iteration 584 : loss : 0.432756, loss_ce: 0.110042
[00:05:22.776] iteration 585 : loss : 0.457947, loss_ce: 0.149120
[00:05:23.065] iteration 586 : loss : 0.445856, loss_ce: 0.182882
[00:05:23.351] iteration 587 : loss : 0.432585, loss_ce: 0.125978
[00:05:23.639] iteration 588 : loss : 0.417000, loss_ce: 0.129203
[00:05:23.925] iteration 589 : loss : 0.443147, loss_ce: 0.086228
[00:05:24.214] iteration 590 : loss : 0.442503, loss_ce: 0.103353
[00:05:24.502] iteration 591 : loss : 0.404307, loss_ce: 0.062740
[00:05:24.790] iteration 592 : loss : 0.467645, loss_ce: 0.221710
[00:05:25.078] iteration 593 : loss : 0.431390, loss_ce: 0.113965
[00:05:25.365] iteration 594 : loss : 0.408073, loss_ce: 0.065747
[00:05:25.652] iteration 595 : loss : 0.421428, loss_ce: 0.099965
[00:05:25.937] iteration 596 : loss : 0.406438, loss_ce: 0.071911
[00:05:26.226] iteration 597 : loss : 0.421951, loss_ce: 0.120997
[00:05:26.515] iteration 598 : loss : 0.429396, loss_ce: 0.147996
[00:05:26.800] iteration 599 : loss : 0.435638, loss_ce: 0.127180
[00:05:27.087] iteration 600 : loss : 0.449169, loss_ce: 0.114417
[00:05:27.393] iteration 601 : loss : 0.449477, loss_ce: 0.100940
[00:05:27.678] iteration 602 : loss : 0.437613, loss_ce: 0.097524
[00:05:27.965] iteration 603 : loss : 0.457901, loss_ce: 0.083514
[00:05:28.254] iteration 604 : loss : 0.420228, loss_ce: 0.092028
[00:05:28.544] iteration 605 : loss : 0.400543, loss_ce: 0.096379
[00:05:28.831] iteration 606 : loss : 0.404448, loss_ce: 0.113479
[00:05:29.121] iteration 607 : loss : 0.414921, loss_ce: 0.091716
[00:05:29.409] iteration 608 : loss : 0.462166, loss_ce: 0.106035
[00:05:29.697] iteration 609 : loss : 0.429548, loss_ce: 0.127735
[00:05:29.983] iteration 610 : loss : 0.461605, loss_ce: 0.114128
[00:05:30.271] iteration 611 : loss : 0.470212, loss_ce: 0.063396
[00:05:30.562] iteration 612 : loss : 0.433014, loss_ce: 0.080673
[00:05:30.849] iteration 613 : loss : 0.442056, loss_ce: 0.165672
[00:05:31.140] iteration 614 : loss : 0.451668, loss_ce: 0.132181
[00:05:31.429] iteration 615 : loss : 0.420426, loss_ce: 0.106591
[00:05:31.717] iteration 616 : loss : 0.448380, loss_ce: 0.130504
[00:05:32.004] iteration 617 : loss : 0.432581, loss_ce: 0.145287
[00:05:32.293] iteration 618 : loss : 0.468484, loss_ce: 0.168136
[00:05:32.582] iteration 619 : loss : 0.405374, loss_ce: 0.076635
[00:05:32.869] iteration 620 : loss : 0.415703, loss_ce: 0.133362
[00:05:33.176] iteration 621 : loss : 0.446532, loss_ce: 0.153920
[00:05:33.463] iteration 622 : loss : 0.442556, loss_ce: 0.148503
[00:05:33.751] iteration 623 : loss : 0.395167, loss_ce: 0.124934
[00:05:34.039] iteration 624 : loss : 0.428014, loss_ce: 0.100938
[00:05:34.328] iteration 625 : loss : 0.449127, loss_ce: 0.054984
[00:05:34.615] iteration 626 : loss : 0.392763, loss_ce: 0.088578
[00:05:34.903] iteration 627 : loss : 0.427136, loss_ce: 0.089090
[00:05:35.194] iteration 628 : loss : 0.385445, loss_ce: 0.111592
[00:05:35.481] iteration 629 : loss : 0.418048, loss_ce: 0.117359
[00:05:35.769] iteration 630 : loss : 0.436601, loss_ce: 0.134730
[00:05:36.055] iteration 631 : loss : 0.406033, loss_ce: 0.086436
[00:05:36.345] iteration 632 : loss : 0.455629, loss_ce: 0.139789
[00:05:36.632] iteration 633 : loss : 0.385635, loss_ce: 0.120161
[00:05:36.922] iteration 634 : loss : 0.422253, loss_ce: 0.122915
[00:05:37.211] iteration 635 : loss : 0.401758, loss_ce: 0.105875
[00:05:37.498] iteration 636 : loss : 0.438133, loss_ce: 0.104028
[00:05:37.784] iteration 637 : loss : 0.413518, loss_ce: 0.078862
[00:05:38.071] iteration 638 : loss : 0.396976, loss_ce: 0.081837
[00:05:38.360] iteration 639 : loss : 0.413422, loss_ce: 0.136890
[00:05:38.648] iteration 640 : loss : 0.423125, loss_ce: 0.036466
[00:05:38.952] iteration 641 : loss : 0.380069, loss_ce: 0.103621
[00:05:39.239] iteration 642 : loss : 0.426858, loss_ce: 0.106685
[00:05:39.524] iteration 643 : loss : 0.390758, loss_ce: 0.103634
[00:05:39.813] iteration 644 : loss : 0.426666, loss_ce: 0.086425
[00:05:40.102] iteration 645 : loss : 0.390111, loss_ce: 0.129854
[00:05:40.391] iteration 646 : loss : 0.414518, loss_ce: 0.073335
[00:05:40.678] iteration 647 : loss : 0.415051, loss_ce: 0.097868
[00:05:40.966] iteration 648 : loss : 0.433828, loss_ce: 0.132724
[00:05:41.253] iteration 649 : loss : 0.387909, loss_ce: 0.076085
[00:05:41.544] iteration 650 : loss : 0.407614, loss_ce: 0.059848
[00:05:41.830] iteration 651 : loss : 0.442131, loss_ce: 0.152797
[00:05:42.118] iteration 652 : loss : 0.415110, loss_ce: 0.117850
[00:05:42.405] iteration 653 : loss : 0.411066, loss_ce: 0.150915
[00:05:42.694] iteration 654 : loss : 0.422948, loss_ce: 0.129010
[00:05:42.984] iteration 655 : loss : 0.410971, loss_ce: 0.084299
[00:05:43.270] iteration 656 : loss : 0.392043, loss_ce: 0.061011
[00:05:43.558] iteration 657 : loss : 0.414648, loss_ce: 0.137850
[00:05:43.845] iteration 658 : loss : 0.438210, loss_ce: 0.100213
[00:05:44.133] iteration 659 : loss : 0.417993, loss_ce: 0.173584
[00:05:44.422] iteration 660 : loss : 0.403392, loss_ce: 0.126096
[00:05:44.729] iteration 661 : loss : 0.380615, loss_ce: 0.087362
[00:05:45.018] iteration 662 : loss : 0.419430, loss_ce: 0.133169
[00:05:45.305] iteration 663 : loss : 0.423514, loss_ce: 0.146462
[00:05:45.591] iteration 664 : loss : 0.451174, loss_ce: 0.061099
[00:05:45.877] iteration 665 : loss : 0.376589, loss_ce: 0.082099
[00:05:46.164] iteration 666 : loss : 0.355913, loss_ce: 0.067078
[00:05:46.453] iteration 667 : loss : 0.392419, loss_ce: 0.146143
[00:05:46.740] iteration 668 : loss : 0.396690, loss_ce: 0.095852
[00:05:47.028] iteration 669 : loss : 0.395898, loss_ce: 0.104456
[00:05:47.317] iteration 670 : loss : 0.430636, loss_ce: 0.143801
[00:05:47.603] iteration 671 : loss : 0.396317, loss_ce: 0.113164
[00:05:47.890] iteration 672 : loss : 0.452250, loss_ce: 0.084212
[00:05:48.177] iteration 673 : loss : 0.368045, loss_ce: 0.096987
[00:05:48.465] iteration 674 : loss : 0.382224, loss_ce: 0.044168
[00:05:48.755] iteration 675 : loss : 0.407115, loss_ce: 0.136075
[00:05:49.042] iteration 676 : loss : 0.382162, loss_ce: 0.088568
[00:05:49.329] iteration 677 : loss : 0.413480, loss_ce: 0.143758
[00:05:49.619] iteration 678 : loss : 0.394601, loss_ce: 0.119742
[00:05:49.910] iteration 679 : loss : 0.395005, loss_ce: 0.161610
[00:05:50.204] iteration 680 : loss : 0.432272, loss_ce: 0.162387
[00:05:50.518] iteration 681 : loss : 0.358412, loss_ce: 0.083552
[00:05:50.811] iteration 682 : loss : 0.415079, loss_ce: 0.150963
[00:05:51.100] iteration 683 : loss : 0.418188, loss_ce: 0.064389
[00:05:51.390] iteration 684 : loss : 0.382480, loss_ce: 0.116640
[00:05:51.679] iteration 685 : loss : 0.390126, loss_ce: 0.119110
[00:05:51.969] iteration 686 : loss : 0.398841, loss_ce: 0.067129
[00:05:52.259] iteration 687 : loss : 0.348526, loss_ce: 0.079431
[00:05:52.549] iteration 688 : loss : 0.339716, loss_ce: 0.088644
[00:05:52.837] iteration 689 : loss : 0.370255, loss_ce: 0.104623
[00:05:53.124] iteration 690 : loss : 0.376202, loss_ce: 0.087142
[00:05:53.417] iteration 691 : loss : 0.390985, loss_ce: 0.122599
[00:05:53.708] iteration 692 : loss : 0.446739, loss_ce: 0.058667
[00:05:53.997] iteration 693 : loss : 0.381499, loss_ce: 0.089589
[00:05:54.286] iteration 694 : loss : 0.403011, loss_ce: 0.109787
[00:05:54.359] iteration 695 : loss : 0.481575, loss_ce: 0.200171
[00:06:11.618] iteration 696 : loss : 0.411442, loss_ce: 0.138328
[00:06:11.903] iteration 697 : loss : 0.367811, loss_ce: 0.104163
[00:06:12.191] iteration 698 : loss : 0.383309, loss_ce: 0.103145
[00:06:12.477] iteration 699 : loss : 0.387970, loss_ce: 0.120495
[00:06:12.766] iteration 700 : loss : 0.393769, loss_ce: 0.114880
[00:06:13.075] iteration 701 : loss : 0.376876, loss_ce: 0.092703
[00:06:13.362] iteration 702 : loss : 0.368834, loss_ce: 0.135425
[00:06:13.651] iteration 703 : loss : 0.411009, loss_ce: 0.135442
[00:06:13.937] iteration 704 : loss : 0.382936, loss_ce: 0.105428
[00:06:14.222] iteration 705 : loss : 0.366776, loss_ce: 0.045311
[00:06:14.508] iteration 706 : loss : 0.410808, loss_ce: 0.061447
[00:06:14.794] iteration 707 : loss : 0.394366, loss_ce: 0.103047
[00:06:15.081] iteration 708 : loss : 0.377654, loss_ce: 0.067139
[00:06:15.370] iteration 709 : loss : 0.364206, loss_ce: 0.081576
[00:06:15.657] iteration 710 : loss : 0.355819, loss_ce: 0.080815
[00:06:15.943] iteration 711 : loss : 0.374680, loss_ce: 0.094929
[00:06:16.231] iteration 712 : loss : 0.453368, loss_ce: 0.182523
[00:06:16.515] iteration 713 : loss : 0.391079, loss_ce: 0.083636
[00:06:16.799] iteration 714 : loss : 0.382688, loss_ce: 0.103662
[00:06:17.085] iteration 715 : loss : 0.383256, loss_ce: 0.094100
[00:06:17.370] iteration 716 : loss : 0.473019, loss_ce: 0.145243
[00:06:17.658] iteration 717 : loss : 0.381406, loss_ce: 0.062249
[00:06:17.943] iteration 718 : loss : 0.394276, loss_ce: 0.122084
[00:06:18.231] iteration 719 : loss : 0.395311, loss_ce: 0.108005
[00:06:18.516] iteration 720 : loss : 0.441113, loss_ce: 0.110914
[00:06:18.817] iteration 721 : loss : 0.374320, loss_ce: 0.085009
[00:06:19.103] iteration 722 : loss : 0.386716, loss_ce: 0.064518
[00:06:19.389] iteration 723 : loss : 0.370852, loss_ce: 0.055573
[00:06:19.676] iteration 724 : loss : 0.401291, loss_ce: 0.164058
[00:06:19.961] iteration 725 : loss : 0.448753, loss_ce: 0.083932
[00:06:20.251] iteration 726 : loss : 0.352838, loss_ce: 0.086622
[00:06:20.538] iteration 727 : loss : 0.393692, loss_ce: 0.094891
[00:06:20.826] iteration 728 : loss : 0.396160, loss_ce: 0.126561
[00:06:21.113] iteration 729 : loss : 0.413366, loss_ce: 0.121549
[00:06:21.398] iteration 730 : loss : 0.388419, loss_ce: 0.127041
[00:06:21.686] iteration 731 : loss : 0.379788, loss_ce: 0.115461
[00:06:21.976] iteration 732 : loss : 0.368985, loss_ce: 0.068380
[00:06:22.263] iteration 733 : loss : 0.406183, loss_ce: 0.110843
[00:06:22.552] iteration 734 : loss : 0.402811, loss_ce: 0.097214
[00:06:22.839] iteration 735 : loss : 0.327100, loss_ce: 0.044931
[00:06:23.126] iteration 736 : loss : 0.369270, loss_ce: 0.076800
[00:06:23.412] iteration 737 : loss : 0.378337, loss_ce: 0.097955
[00:06:23.698] iteration 738 : loss : 0.430061, loss_ce: 0.048406
[00:06:23.985] iteration 739 : loss : 0.399400, loss_ce: 0.075792
[00:06:24.272] iteration 740 : loss : 0.356709, loss_ce: 0.086033
[00:06:24.576] iteration 741 : loss : 0.379840, loss_ce: 0.121750
[00:06:24.865] iteration 742 : loss : 0.341047, loss_ce: 0.079096
[00:06:25.152] iteration 743 : loss : 0.373039, loss_ce: 0.100132
[00:06:25.440] iteration 744 : loss : 0.388264, loss_ce: 0.048040
[00:06:25.724] iteration 745 : loss : 0.373800, loss_ce: 0.096681
[00:06:26.011] iteration 746 : loss : 0.364250, loss_ce: 0.111996
[00:06:26.299] iteration 747 : loss : 0.398918, loss_ce: 0.178210
[00:06:26.588] iteration 748 : loss : 0.338581, loss_ce: 0.082079
[00:06:26.874] iteration 749 : loss : 0.374675, loss_ce: 0.063535
[00:06:27.160] iteration 750 : loss : 0.402149, loss_ce: 0.087842
[00:06:27.450] iteration 751 : loss : 0.436137, loss_ce: 0.050799
[00:06:27.736] iteration 752 : loss : 0.398334, loss_ce: 0.077814
[00:06:28.025] iteration 753 : loss : 0.446605, loss_ce: 0.101849
[00:06:28.316] iteration 754 : loss : 0.405710, loss_ce: 0.108286
[00:06:28.602] iteration 755 : loss : 0.404079, loss_ce: 0.136384
[00:06:28.889] iteration 756 : loss : 0.397064, loss_ce: 0.152205
[00:06:29.174] iteration 757 : loss : 0.366858, loss_ce: 0.118388
[00:06:29.467] iteration 758 : loss : 0.391365, loss_ce: 0.108233
[00:06:29.757] iteration 759 : loss : 0.333169, loss_ce: 0.101825
[00:06:30.047] iteration 760 : loss : 0.374031, loss_ce: 0.145480
[00:06:30.351] iteration 761 : loss : 0.377349, loss_ce: 0.104935
[00:06:30.638] iteration 762 : loss : 0.376720, loss_ce: 0.109196
[00:06:30.923] iteration 763 : loss : 0.363675, loss_ce: 0.093216
[00:06:31.212] iteration 764 : loss : 0.417076, loss_ce: 0.053715
[00:06:31.498] iteration 765 : loss : 0.320645, loss_ce: 0.063047
[00:06:31.785] iteration 766 : loss : 0.406520, loss_ce: 0.121870
[00:06:32.073] iteration 767 : loss : 0.297484, loss_ce: 0.027662
[00:06:32.365] iteration 768 : loss : 0.333904, loss_ce: 0.122932
[00:06:32.653] iteration 769 : loss : 0.384567, loss_ce: 0.098797
[00:06:32.941] iteration 770 : loss : 0.406023, loss_ce: 0.091151
[00:06:33.228] iteration 771 : loss : 0.374250, loss_ce: 0.121157
[00:06:33.520] iteration 772 : loss : 0.327888, loss_ce: 0.106382
[00:06:33.809] iteration 773 : loss : 0.340292, loss_ce: 0.086094
[00:06:34.094] iteration 774 : loss : 0.386916, loss_ce: 0.051653
[00:06:34.385] iteration 775 : loss : 0.368138, loss_ce: 0.079049
[00:06:34.672] iteration 776 : loss : 0.389206, loss_ce: 0.145769
[00:06:34.960] iteration 777 : loss : 0.373130, loss_ce: 0.139699
[00:06:35.247] iteration 778 : loss : 0.369109, loss_ce: 0.083363
[00:06:35.534] iteration 779 : loss : 0.365650, loss_ce: 0.085385
[00:06:35.820] iteration 780 : loss : 0.339721, loss_ce: 0.094647
[00:06:36.122] iteration 781 : loss : 0.341792, loss_ce: 0.077502
[00:06:36.410] iteration 782 : loss : 0.337733, loss_ce: 0.120192
[00:06:36.697] iteration 783 : loss : 0.368689, loss_ce: 0.174634
[00:06:36.984] iteration 784 : loss : 0.377230, loss_ce: 0.161488
[00:06:37.273] iteration 785 : loss : 0.387618, loss_ce: 0.075412
[00:06:37.563] iteration 786 : loss : 0.400871, loss_ce: 0.094648
[00:06:37.855] iteration 787 : loss : 0.360009, loss_ce: 0.110761
[00:06:38.144] iteration 788 : loss : 0.362067, loss_ce: 0.112964
[00:06:38.434] iteration 789 : loss : 0.375802, loss_ce: 0.102337
[00:06:38.722] iteration 790 : loss : 0.370532, loss_ce: 0.076751
[00:06:39.014] iteration 791 : loss : 0.359037, loss_ce: 0.120336
[00:06:39.306] iteration 792 : loss : 0.401984, loss_ce: 0.115770
[00:06:39.598] iteration 793 : loss : 0.378601, loss_ce: 0.143684
[00:06:39.889] iteration 794 : loss : 0.430945, loss_ce: 0.208115
[00:06:40.176] iteration 795 : loss : 0.343366, loss_ce: 0.096231
[00:06:40.464] iteration 796 : loss : 0.344168, loss_ce: 0.073730
[00:06:40.753] iteration 797 : loss : 0.332528, loss_ce: 0.094427
[00:06:41.040] iteration 798 : loss : 0.388256, loss_ce: 0.054543
[00:06:41.331] iteration 799 : loss : 0.311111, loss_ce: 0.067288
[00:06:41.622] iteration 800 : loss : 0.380258, loss_ce: 0.074404
[00:06:41.929] iteration 801 : loss : 0.370874, loss_ce: 0.103912
[00:06:42.214] iteration 802 : loss : 0.337941, loss_ce: 0.086687
[00:06:42.503] iteration 803 : loss : 0.347085, loss_ce: 0.143237
[00:06:42.794] iteration 804 : loss : 0.360605, loss_ce: 0.047467
[00:06:43.080] iteration 805 : loss : 0.291812, loss_ce: 0.052486
[00:06:43.368] iteration 806 : loss : 0.360433, loss_ce: 0.090175
[00:06:43.659] iteration 807 : loss : 0.332026, loss_ce: 0.068164
[00:06:43.947] iteration 808 : loss : 0.358265, loss_ce: 0.109499
[00:06:44.233] iteration 809 : loss : 0.363433, loss_ce: 0.117806
[00:06:44.522] iteration 810 : loss : 0.367119, loss_ce: 0.108558
[00:06:44.815] iteration 811 : loss : 0.323536, loss_ce: 0.080580
[00:06:45.102] iteration 812 : loss : 0.316608, loss_ce: 0.092826
[00:06:45.388] iteration 813 : loss : 0.377309, loss_ce: 0.116532
[00:06:45.679] iteration 814 : loss : 0.394299, loss_ce: 0.082473
[00:06:45.968] iteration 815 : loss : 0.377139, loss_ce: 0.119202
[00:06:46.255] iteration 816 : loss : 0.362574, loss_ce: 0.044953
[00:06:46.543] iteration 817 : loss : 0.357451, loss_ce: 0.123488
[00:06:46.830] iteration 818 : loss : 0.422444, loss_ce: 0.051862
[00:06:47.121] iteration 819 : loss : 0.368335, loss_ce: 0.096485
[00:06:47.416] iteration 820 : loss : 0.348806, loss_ce: 0.098784
[00:06:47.723] iteration 821 : loss : 0.383049, loss_ce: 0.130580
[00:06:48.017] iteration 822 : loss : 0.318901, loss_ce: 0.086882
[00:06:48.306] iteration 823 : loss : 0.315130, loss_ce: 0.099353
[00:06:48.599] iteration 824 : loss : 0.362184, loss_ce: 0.122190
[00:06:48.891] iteration 825 : loss : 0.354535, loss_ce: 0.087782
[00:06:49.181] iteration 826 : loss : 0.311613, loss_ce: 0.053268
[00:06:49.473] iteration 827 : loss : 0.338300, loss_ce: 0.061457
[00:06:49.763] iteration 828 : loss : 0.348556, loss_ce: 0.073439
[00:06:50.055] iteration 829 : loss : 0.361601, loss_ce: 0.095348
[00:06:50.347] iteration 830 : loss : 0.345656, loss_ce: 0.075532
[00:06:50.639] iteration 831 : loss : 0.339802, loss_ce: 0.116280
[00:06:50.937] iteration 832 : loss : 0.361858, loss_ce: 0.139281
[00:06:51.227] iteration 833 : loss : 0.314764, loss_ce: 0.096438
[00:06:51.304] iteration 834 : loss : 0.443143, loss_ce: 0.118529
[00:07:07.862] iteration 835 : loss : 0.301849, loss_ce: 0.085488
[00:07:08.146] iteration 836 : loss : 0.361326, loss_ce: 0.081949
[00:07:08.432] iteration 837 : loss : 0.349609, loss_ce: 0.060137
[00:07:08.722] iteration 838 : loss : 0.328024, loss_ce: 0.063488
[00:07:09.006] iteration 839 : loss : 0.322435, loss_ce: 0.093294
[00:07:09.293] iteration 840 : loss : 0.395347, loss_ce: 0.061702
[00:07:09.594] iteration 841 : loss : 0.360219, loss_ce: 0.098726
[00:07:09.881] iteration 842 : loss : 0.386663, loss_ce: 0.130242
[00:07:10.167] iteration 843 : loss : 0.327420, loss_ce: 0.100514
[00:07:10.456] iteration 844 : loss : 0.370734, loss_ce: 0.098965
[00:07:10.746] iteration 845 : loss : 0.321257, loss_ce: 0.082667
[00:07:11.037] iteration 846 : loss : 0.378064, loss_ce: 0.061062
[00:07:11.325] iteration 847 : loss : 0.353295, loss_ce: 0.052502
[00:07:11.613] iteration 848 : loss : 0.339875, loss_ce: 0.131385
[00:07:11.901] iteration 849 : loss : 0.332841, loss_ce: 0.108225
[00:07:12.191] iteration 850 : loss : 0.285513, loss_ce: 0.076081
[00:07:12.480] iteration 851 : loss : 0.272005, loss_ce: 0.047719
[00:07:12.770] iteration 852 : loss : 0.353789, loss_ce: 0.084603
[00:07:13.057] iteration 853 : loss : 0.391241, loss_ce: 0.106645
[00:07:13.344] iteration 854 : loss : 0.422436, loss_ce: 0.090573
[00:07:13.631] iteration 855 : loss : 0.275703, loss_ce: 0.037267
[00:07:13.920] iteration 856 : loss : 0.364376, loss_ce: 0.165253
[00:07:14.208] iteration 857 : loss : 0.406041, loss_ce: 0.050851
[00:07:14.498] iteration 858 : loss : 0.382264, loss_ce: 0.162855
[00:07:14.788] iteration 859 : loss : 0.367582, loss_ce: 0.113537
[00:07:15.078] iteration 860 : loss : 0.355878, loss_ce: 0.112509
[00:07:15.381] iteration 861 : loss : 0.385932, loss_ce: 0.136369
[00:07:15.671] iteration 862 : loss : 0.294600, loss_ce: 0.075870
[00:07:15.960] iteration 863 : loss : 0.332259, loss_ce: 0.080882
[00:07:16.250] iteration 864 : loss : 0.292453, loss_ce: 0.063900
[00:07:16.538] iteration 865 : loss : 0.347088, loss_ce: 0.085476
[00:07:16.827] iteration 866 : loss : 0.345588, loss_ce: 0.107888
[00:07:17.119] iteration 867 : loss : 0.356264, loss_ce: 0.084194
[00:07:17.405] iteration 868 : loss : 0.354472, loss_ce: 0.120951
[00:07:17.696] iteration 869 : loss : 0.397650, loss_ce: 0.040904
[00:07:17.985] iteration 870 : loss : 0.383799, loss_ce: 0.090903
[00:07:18.277] iteration 871 : loss : 0.353236, loss_ce: 0.055505
[00:07:18.565] iteration 872 : loss : 0.324974, loss_ce: 0.064961
[00:07:18.853] iteration 873 : loss : 0.382738, loss_ce: 0.064010
[00:07:19.140] iteration 874 : loss : 0.289329, loss_ce: 0.054299
[00:07:19.427] iteration 875 : loss : 0.343963, loss_ce: 0.124672
[00:07:19.718] iteration 876 : loss : 0.320701, loss_ce: 0.137907
[00:07:20.008] iteration 877 : loss : 0.384532, loss_ce: 0.130862
[00:07:20.297] iteration 878 : loss : 0.312782, loss_ce: 0.061435
[00:07:20.583] iteration 879 : loss : 0.388583, loss_ce: 0.066604
[00:07:20.869] iteration 880 : loss : 0.304838, loss_ce: 0.040575
[00:07:21.171] iteration 881 : loss : 0.365541, loss_ce: 0.129164
[00:07:21.461] iteration 882 : loss : 0.285573, loss_ce: 0.084219
[00:07:21.749] iteration 883 : loss : 0.316720, loss_ce: 0.084949
[00:07:22.040] iteration 884 : loss : 0.297711, loss_ce: 0.082292
[00:07:22.327] iteration 885 : loss : 0.292833, loss_ce: 0.038817
[00:07:22.613] iteration 886 : loss : 0.269445, loss_ce: 0.068308
[00:07:22.900] iteration 887 : loss : 0.298466, loss_ce: 0.091889
[00:07:23.191] iteration 888 : loss : 0.310587, loss_ce: 0.094094
[00:07:23.479] iteration 889 : loss : 0.317264, loss_ce: 0.078002
[00:07:23.765] iteration 890 : loss : 0.338939, loss_ce: 0.110005
[00:07:24.055] iteration 891 : loss : 0.345835, loss_ce: 0.141033
[00:07:24.341] iteration 892 : loss : 0.299707, loss_ce: 0.092485
[00:07:24.628] iteration 893 : loss : 0.360047, loss_ce: 0.095397
[00:07:24.916] iteration 894 : loss : 0.368176, loss_ce: 0.057070
[00:07:25.204] iteration 895 : loss : 0.280533, loss_ce: 0.041163
[00:07:25.491] iteration 896 : loss : 0.370021, loss_ce: 0.065964
[00:07:25.779] iteration 897 : loss : 0.344167, loss_ce: 0.101333
[00:07:26.068] iteration 898 : loss : 0.318176, loss_ce: 0.085446
[00:07:26.356] iteration 899 : loss : 0.376515, loss_ce: 0.063643
[00:07:26.642] iteration 900 : loss : 0.321047, loss_ce: 0.114260
[00:07:26.946] iteration 901 : loss : 0.290350, loss_ce: 0.119190
[00:07:27.235] iteration 902 : loss : 0.315307, loss_ce: 0.097918
[00:07:27.523] iteration 903 : loss : 0.338264, loss_ce: 0.065055
[00:07:27.812] iteration 904 : loss : 0.311253, loss_ce: 0.088110
[00:07:28.103] iteration 905 : loss : 0.345484, loss_ce: 0.130064
[00:07:28.387] iteration 906 : loss : 0.346624, loss_ce: 0.090372
[00:07:28.676] iteration 907 : loss : 0.349186, loss_ce: 0.098995
[00:07:28.965] iteration 908 : loss : 0.309378, loss_ce: 0.046183
[00:07:29.255] iteration 909 : loss : 0.266602, loss_ce: 0.051688
[00:07:29.543] iteration 910 : loss : 0.320677, loss_ce: 0.074906
[00:07:29.829] iteration 911 : loss : 0.331946, loss_ce: 0.128720
[00:07:30.120] iteration 912 : loss : 0.281037, loss_ce: 0.036817
[00:07:30.407] iteration 913 : loss : 0.299675, loss_ce: 0.058414
[00:07:30.695] iteration 914 : loss : 0.318942, loss_ce: 0.057598
[00:07:30.983] iteration 915 : loss : 0.322095, loss_ce: 0.058492
[00:07:31.270] iteration 916 : loss : 0.323920, loss_ce: 0.034509
[00:07:31.555] iteration 917 : loss : 0.303110, loss_ce: 0.092148
[00:07:31.845] iteration 918 : loss : 0.318477, loss_ce: 0.101087
[00:07:32.133] iteration 919 : loss : 0.260175, loss_ce: 0.065325
[00:07:32.422] iteration 920 : loss : 0.297998, loss_ce: 0.073867
[00:07:32.729] iteration 921 : loss : 0.282216, loss_ce: 0.046160
[00:07:33.016] iteration 922 : loss : 0.362119, loss_ce: 0.032575
[00:07:33.300] iteration 923 : loss : 0.269859, loss_ce: 0.079447
[00:07:33.587] iteration 924 : loss : 0.307865, loss_ce: 0.075196
[00:07:33.875] iteration 925 : loss : 0.291186, loss_ce: 0.112458
[00:07:34.161] iteration 926 : loss : 0.344283, loss_ce: 0.117995
[00:07:34.447] iteration 927 : loss : 0.272189, loss_ce: 0.076524
[00:07:34.734] iteration 928 : loss : 0.289390, loss_ce: 0.067497
[00:07:35.024] iteration 929 : loss : 0.363734, loss_ce: 0.086702
[00:07:35.313] iteration 930 : loss : 0.346906, loss_ce: 0.158376
[00:07:35.603] iteration 931 : loss : 0.293294, loss_ce: 0.117613
[00:07:35.891] iteration 932 : loss : 0.280871, loss_ce: 0.069366
[00:07:36.180] iteration 933 : loss : 0.353347, loss_ce: 0.051695
[00:07:36.469] iteration 934 : loss : 0.300197, loss_ce: 0.113676
[00:07:36.758] iteration 935 : loss : 0.367961, loss_ce: 0.070269
[00:07:37.044] iteration 936 : loss : 0.327735, loss_ce: 0.131255
[00:07:37.335] iteration 937 : loss : 0.325889, loss_ce: 0.099729
[00:07:37.625] iteration 938 : loss : 0.303070, loss_ce: 0.063474
[00:07:37.912] iteration 939 : loss : 0.239867, loss_ce: 0.077053
[00:07:38.201] iteration 940 : loss : 0.416598, loss_ce: 0.033987
[00:07:38.514] iteration 941 : loss : 0.345822, loss_ce: 0.138838
[00:07:38.802] iteration 942 : loss : 0.293300, loss_ce: 0.120245
[00:07:39.087] iteration 943 : loss : 0.379611, loss_ce: 0.053503
[00:07:39.375] iteration 944 : loss : 0.247793, loss_ce: 0.070514
[00:07:39.665] iteration 945 : loss : 0.254915, loss_ce: 0.087093
[00:07:39.953] iteration 946 : loss : 0.279837, loss_ce: 0.083229
[00:07:40.240] iteration 947 : loss : 0.310608, loss_ce: 0.099957
[00:07:40.527] iteration 948 : loss : 0.309328, loss_ce: 0.073186
[00:07:40.813] iteration 949 : loss : 0.332697, loss_ce: 0.065503
[00:07:41.100] iteration 950 : loss : 0.341650, loss_ce: 0.039379
[00:07:41.388] iteration 951 : loss : 0.271300, loss_ce: 0.081951
[00:07:41.676] iteration 952 : loss : 0.304394, loss_ce: 0.082308
[00:07:41.963] iteration 953 : loss : 0.276390, loss_ce: 0.079317
[00:07:42.251] iteration 954 : loss : 0.283799, loss_ce: 0.074273
[00:07:42.542] iteration 955 : loss : 0.248582, loss_ce: 0.072207
[00:07:42.832] iteration 956 : loss : 0.313271, loss_ce: 0.056466
[00:07:43.123] iteration 957 : loss : 0.274162, loss_ce: 0.091152
[00:07:43.414] iteration 958 : loss : 0.314647, loss_ce: 0.102182
[00:07:43.707] iteration 959 : loss : 0.311409, loss_ce: 0.118250
[00:07:43.997] iteration 960 : loss : 0.338213, loss_ce: 0.083715
[00:07:44.312] iteration 961 : loss : 0.325535, loss_ce: 0.073401
[00:07:44.601] iteration 962 : loss : 0.263354, loss_ce: 0.092796
[00:07:44.894] iteration 963 : loss : 0.384967, loss_ce: 0.043554
[00:07:45.186] iteration 964 : loss : 0.324489, loss_ce: 0.104513
[00:07:45.476] iteration 965 : loss : 0.370373, loss_ce: 0.060206
[00:07:45.768] iteration 966 : loss : 0.331873, loss_ce: 0.106228
[00:07:46.058] iteration 967 : loss : 0.305249, loss_ce: 0.089034
[00:07:46.349] iteration 968 : loss : 0.363810, loss_ce: 0.120230
[00:07:46.640] iteration 969 : loss : 0.304672, loss_ce: 0.085192
[00:07:46.930] iteration 970 : loss : 0.236895, loss_ce: 0.049632
[00:07:47.221] iteration 971 : loss : 0.287303, loss_ce: 0.106194
[00:07:47.513] iteration 972 : loss : 0.295717, loss_ce: 0.064796
[00:07:47.588] iteration 973 : loss : 0.433662, loss_ce: 0.032437
[00:08:04.365] iteration 974 : loss : 0.238494, loss_ce: 0.074789
[00:08:04.649] iteration 975 : loss : 0.298932, loss_ce: 0.064664
[00:08:04.936] iteration 976 : loss : 0.306175, loss_ce: 0.133263
[00:08:05.222] iteration 977 : loss : 0.240211, loss_ce: 0.094710
[00:08:05.512] iteration 978 : loss : 0.284769, loss_ce: 0.062050
[00:08:05.798] iteration 979 : loss : 0.291062, loss_ce: 0.116799
[00:08:06.085] iteration 980 : loss : 0.311965, loss_ce: 0.058917
[00:08:06.385] iteration 981 : loss : 0.256034, loss_ce: 0.121724
[00:08:06.676] iteration 982 : loss : 0.342209, loss_ce: 0.067261
[00:08:06.963] iteration 983 : loss : 0.271267, loss_ce: 0.053276
[00:08:07.247] iteration 984 : loss : 0.285900, loss_ce: 0.064435
[00:08:07.533] iteration 985 : loss : 0.241960, loss_ce: 0.075779
[00:08:07.820] iteration 986 : loss : 0.348483, loss_ce: 0.069035
[00:08:08.107] iteration 987 : loss : 0.296304, loss_ce: 0.111602
[00:08:08.394] iteration 988 : loss : 0.338585, loss_ce: 0.122044
[00:08:08.684] iteration 989 : loss : 0.294545, loss_ce: 0.073548
[00:08:08.968] iteration 990 : loss : 0.251051, loss_ce: 0.075235
[00:08:09.254] iteration 991 : loss : 0.220126, loss_ce: 0.052285
[00:08:09.541] iteration 992 : loss : 0.300440, loss_ce: 0.021657
[00:08:09.828] iteration 993 : loss : 0.313719, loss_ce: 0.066798
[00:08:10.114] iteration 994 : loss : 0.337105, loss_ce: 0.037844
[00:08:10.405] iteration 995 : loss : 0.288192, loss_ce: 0.054993
[00:08:10.692] iteration 996 : loss : 0.311214, loss_ce: 0.117003
[00:08:10.979] iteration 997 : loss : 0.305583, loss_ce: 0.058443
[00:08:11.265] iteration 998 : loss : 0.252644, loss_ce: 0.080696
[00:08:11.551] iteration 999 : loss : 0.287851, loss_ce: 0.087418
[00:08:11.837] iteration 1000 : loss : 0.291692, loss_ce: 0.117084
[00:08:12.142] iteration 1001 : loss : 0.265681, loss_ce: 0.076981
[00:08:12.426] iteration 1002 : loss : 0.315197, loss_ce: 0.068273
[00:08:12.712] iteration 1003 : loss : 0.337616, loss_ce: 0.101650
[00:08:13.002] iteration 1004 : loss : 0.276749, loss_ce: 0.092507
[00:08:13.287] iteration 1005 : loss : 0.306900, loss_ce: 0.091075
[00:08:13.573] iteration 1006 : loss : 0.264100, loss_ce: 0.077352
[00:08:13.861] iteration 1007 : loss : 0.307990, loss_ce: 0.125863
[00:08:14.146] iteration 1008 : loss : 0.260837, loss_ce: 0.067481
[00:08:14.433] iteration 1009 : loss : 0.261893, loss_ce: 0.041391
[00:08:14.720] iteration 1010 : loss : 0.304942, loss_ce: 0.128774
[00:08:15.008] iteration 1011 : loss : 0.233154, loss_ce: 0.083310
[00:08:15.296] iteration 1012 : loss : 0.323041, loss_ce: 0.084176
[00:08:15.582] iteration 1013 : loss : 0.263293, loss_ce: 0.055995
[00:08:15.871] iteration 1014 : loss : 0.264580, loss_ce: 0.111386
[00:08:16.159] iteration 1015 : loss : 0.289369, loss_ce: 0.056202
[00:08:16.443] iteration 1016 : loss : 0.329250, loss_ce: 0.086028
[00:08:16.732] iteration 1017 : loss : 0.381470, loss_ce: 0.018032
[00:08:17.018] iteration 1018 : loss : 0.268725, loss_ce: 0.071067
[00:08:17.304] iteration 1019 : loss : 0.348702, loss_ce: 0.057828
[00:08:17.592] iteration 1020 : loss : 0.308125, loss_ce: 0.077817
[00:08:17.895] iteration 1021 : loss : 0.277230, loss_ce: 0.093508
[00:08:18.182] iteration 1022 : loss : 0.292509, loss_ce: 0.084817
[00:08:18.469] iteration 1023 : loss : 0.305506, loss_ce: 0.086522
[00:08:18.755] iteration 1024 : loss : 0.344505, loss_ce: 0.120506
[00:08:19.041] iteration 1025 : loss : 0.290197, loss_ce: 0.107198
[00:08:19.328] iteration 1026 : loss : 0.266721, loss_ce: 0.038228
[00:08:19.615] iteration 1027 : loss : 0.235063, loss_ce: 0.069803
[00:08:19.902] iteration 1028 : loss : 0.267386, loss_ce: 0.040638
[00:08:20.188] iteration 1029 : loss : 0.304360, loss_ce: 0.104083
[00:08:20.476] iteration 1030 : loss : 0.250650, loss_ce: 0.060058
[00:08:20.762] iteration 1031 : loss : 0.273871, loss_ce: 0.100550
[00:08:21.048] iteration 1032 : loss : 0.300166, loss_ce: 0.057671
[00:08:21.333] iteration 1033 : loss : 0.320072, loss_ce: 0.125026
[00:08:21.623] iteration 1034 : loss : 0.323988, loss_ce: 0.118292
[00:08:21.910] iteration 1035 : loss : 0.326398, loss_ce: 0.108081
[00:08:22.199] iteration 1036 : loss : 0.239740, loss_ce: 0.054086
[00:08:22.485] iteration 1037 : loss : 0.317667, loss_ce: 0.082354
[00:08:22.772] iteration 1038 : loss : 0.294149, loss_ce: 0.081102
[00:08:23.060] iteration 1039 : loss : 0.246760, loss_ce: 0.047842
[00:08:23.346] iteration 1040 : loss : 0.286213, loss_ce: 0.081048
[00:08:23.649] iteration 1041 : loss : 0.294805, loss_ce: 0.062833
[00:08:23.937] iteration 1042 : loss : 0.273763, loss_ce: 0.061344
[00:08:24.225] iteration 1043 : loss : 0.265988, loss_ce: 0.097559
[00:08:24.511] iteration 1044 : loss : 0.284830, loss_ce: 0.047846
[00:08:24.797] iteration 1045 : loss : 0.255060, loss_ce: 0.070102
[00:08:25.088] iteration 1046 : loss : 0.252391, loss_ce: 0.074270
[00:08:25.377] iteration 1047 : loss : 0.259762, loss_ce: 0.092785
[00:08:25.663] iteration 1048 : loss : 0.210295, loss_ce: 0.058095
[00:08:25.953] iteration 1049 : loss : 0.217144, loss_ce: 0.063339
[00:08:26.241] iteration 1050 : loss : 0.223664, loss_ce: 0.047270
[00:08:26.529] iteration 1051 : loss : 0.263574, loss_ce: 0.068184
[00:08:26.815] iteration 1052 : loss : 0.289947, loss_ce: 0.055365
[00:08:27.101] iteration 1053 : loss : 0.254723, loss_ce: 0.056837
[00:08:27.388] iteration 1054 : loss : 0.301611, loss_ce: 0.062791
[00:08:27.678] iteration 1055 : loss : 0.328884, loss_ce: 0.119351
[00:08:27.963] iteration 1056 : loss : 0.170485, loss_ce: 0.040613
[00:08:28.251] iteration 1057 : loss : 0.142662, loss_ce: 0.027686
[00:08:28.538] iteration 1058 : loss : 0.298062, loss_ce: 0.047574
[00:08:28.825] iteration 1059 : loss : 0.255637, loss_ce: 0.059169
[00:08:29.111] iteration 1060 : loss : 0.292587, loss_ce: 0.052408
[00:08:29.413] iteration 1061 : loss : 0.220846, loss_ce: 0.043665
[00:08:29.699] iteration 1062 : loss : 0.239832, loss_ce: 0.045565
[00:08:29.990] iteration 1063 : loss : 0.204754, loss_ce: 0.048525
[00:08:30.282] iteration 1064 : loss : 0.267763, loss_ce: 0.072217
[00:08:30.568] iteration 1065 : loss : 0.392861, loss_ce: 0.070137
[00:08:30.854] iteration 1066 : loss : 0.241292, loss_ce: 0.061625
[00:08:31.142] iteration 1067 : loss : 0.275459, loss_ce: 0.132727
[00:08:31.430] iteration 1068 : loss : 0.257320, loss_ce: 0.067014
[00:08:31.717] iteration 1069 : loss : 0.303689, loss_ce: 0.049938
[00:08:32.003] iteration 1070 : loss : 0.264483, loss_ce: 0.068156
[00:08:32.291] iteration 1071 : loss : 0.217644, loss_ce: 0.092555
[00:08:32.577] iteration 1072 : loss : 0.351839, loss_ce: 0.047956
[00:08:32.864] iteration 1073 : loss : 0.320171, loss_ce: 0.040630
[00:08:33.152] iteration 1074 : loss : 0.219591, loss_ce: 0.023697
[00:08:33.439] iteration 1075 : loss : 0.301512, loss_ce: 0.072974
[00:08:33.725] iteration 1076 : loss : 0.279230, loss_ce: 0.068542
[00:08:34.015] iteration 1077 : loss : 0.311605, loss_ce: 0.036204
[00:08:34.303] iteration 1078 : loss : 0.213602, loss_ce: 0.090348
[00:08:34.592] iteration 1079 : loss : 0.293519, loss_ce: 0.095491
[00:08:34.877] iteration 1080 : loss : 0.369165, loss_ce: 0.034204
[00:08:35.190] iteration 1081 : loss : 0.280278, loss_ce: 0.061529
[00:08:35.477] iteration 1082 : loss : 0.213025, loss_ce: 0.053901
[00:08:35.764] iteration 1083 : loss : 0.230108, loss_ce: 0.085073
[00:08:36.051] iteration 1084 : loss : 0.193971, loss_ce: 0.056055
[00:08:36.338] iteration 1085 : loss : 0.255405, loss_ce: 0.097239
[00:08:36.627] iteration 1086 : loss : 0.195363, loss_ce: 0.035551
[00:08:36.914] iteration 1087 : loss : 0.264848, loss_ce: 0.091702
[00:08:37.199] iteration 1088 : loss : 0.265390, loss_ce: 0.077370
[00:08:37.489] iteration 1089 : loss : 0.305014, loss_ce: 0.062490
[00:08:37.777] iteration 1090 : loss : 0.222492, loss_ce: 0.054813
[00:08:38.064] iteration 1091 : loss : 0.226679, loss_ce: 0.068667
[00:08:38.354] iteration 1092 : loss : 0.241940, loss_ce: 0.061449
[00:08:38.641] iteration 1093 : loss : 0.249056, loss_ce: 0.078836
[00:08:38.934] iteration 1094 : loss : 0.290942, loss_ce: 0.080965
[00:08:39.222] iteration 1095 : loss : 0.271198, loss_ce: 0.086170
[00:08:39.515] iteration 1096 : loss : 0.331263, loss_ce: 0.049355
[00:08:39.804] iteration 1097 : loss : 0.295911, loss_ce: 0.052119
[00:08:40.099] iteration 1098 : loss : 0.296896, loss_ce: 0.082133
[00:08:40.390] iteration 1099 : loss : 0.269085, loss_ce: 0.081775
[00:08:40.679] iteration 1100 : loss : 0.330139, loss_ce: 0.090796
[00:08:40.990] iteration 1101 : loss : 0.327324, loss_ce: 0.066557
[00:08:41.280] iteration 1102 : loss : 0.237402, loss_ce: 0.074344
[00:08:41.571] iteration 1103 : loss : 0.283501, loss_ce: 0.044127
[00:08:41.860] iteration 1104 : loss : 0.349216, loss_ce: 0.081320
[00:08:42.153] iteration 1105 : loss : 0.262706, loss_ce: 0.107939
[00:08:42.444] iteration 1106 : loss : 0.277127, loss_ce: 0.087233
[00:08:42.732] iteration 1107 : loss : 0.254068, loss_ce: 0.094073
[00:08:43.026] iteration 1108 : loss : 0.262071, loss_ce: 0.099559
[00:08:43.320] iteration 1109 : loss : 0.292450, loss_ce: 0.057781
[00:08:43.609] iteration 1110 : loss : 0.250561, loss_ce: 0.056632
[00:08:43.895] iteration 1111 : loss : 0.272315, loss_ce: 0.096246
[00:08:43.976] iteration 1112 : loss : 0.310749, loss_ce: 0.075015
[00:09:00.341] iteration 1113 : loss : 0.312907, loss_ce: 0.060584
[00:09:00.631] iteration 1114 : loss : 0.231805, loss_ce: 0.057593
[00:09:00.919] iteration 1115 : loss : 0.237025, loss_ce: 0.049579
[00:09:01.207] iteration 1116 : loss : 0.227493, loss_ce: 0.098930
[00:09:01.496] iteration 1117 : loss : 0.280628, loss_ce: 0.070626
[00:09:01.782] iteration 1118 : loss : 0.246093, loss_ce: 0.075460
[00:09:02.066] iteration 1119 : loss : 0.247013, loss_ce: 0.060361
[00:09:02.352] iteration 1120 : loss : 0.201693, loss_ce: 0.088470
[00:09:02.652] iteration 1121 : loss : 0.216758, loss_ce: 0.093477
[00:09:02.942] iteration 1122 : loss : 0.303758, loss_ce: 0.060437
[00:09:03.230] iteration 1123 : loss : 0.286430, loss_ce: 0.084506
[00:09:03.517] iteration 1124 : loss : 0.266699, loss_ce: 0.087416
[00:09:03.805] iteration 1125 : loss : 0.251293, loss_ce: 0.074492
[00:09:04.094] iteration 1126 : loss : 0.291337, loss_ce: 0.049006
[00:09:04.383] iteration 1127 : loss : 0.250903, loss_ce: 0.100799
[00:09:04.672] iteration 1128 : loss : 0.224067, loss_ce: 0.032942
[00:09:04.966] iteration 1129 : loss : 0.251119, loss_ce: 0.063267
[00:09:05.255] iteration 1130 : loss : 0.224257, loss_ce: 0.055845
[00:09:05.545] iteration 1131 : loss : 0.322566, loss_ce: 0.057756
[00:09:05.833] iteration 1132 : loss : 0.290228, loss_ce: 0.089107
[00:09:06.124] iteration 1133 : loss : 0.252269, loss_ce: 0.095833
[00:09:06.413] iteration 1134 : loss : 0.214238, loss_ce: 0.064187
[00:09:06.703] iteration 1135 : loss : 0.250865, loss_ce: 0.053561
[00:09:06.994] iteration 1136 : loss : 0.240408, loss_ce: 0.043198
[00:09:07.279] iteration 1137 : loss : 0.261512, loss_ce: 0.061954
[00:09:07.569] iteration 1138 : loss : 0.254237, loss_ce: 0.058910
[00:09:07.866] iteration 1139 : loss : 0.232411, loss_ce: 0.060270
[00:09:08.157] iteration 1140 : loss : 0.294967, loss_ce: 0.098280
[00:09:08.469] iteration 1141 : loss : 0.276330, loss_ce: 0.094349
[00:09:08.758] iteration 1142 : loss : 0.220944, loss_ce: 0.067587
[00:09:09.047] iteration 1143 : loss : 0.217280, loss_ce: 0.070393
[00:09:09.338] iteration 1144 : loss : 0.220679, loss_ce: 0.073777
[00:09:09.624] iteration 1145 : loss : 0.214406, loss_ce: 0.084469
[00:09:09.916] iteration 1146 : loss : 0.229355, loss_ce: 0.073085
[00:09:10.206] iteration 1147 : loss : 0.150377, loss_ce: 0.045060
[00:09:10.495] iteration 1148 : loss : 0.270534, loss_ce: 0.070834
[00:09:10.784] iteration 1149 : loss : 0.270239, loss_ce: 0.054906
[00:09:11.069] iteration 1150 : loss : 0.226573, loss_ce: 0.071227
[00:09:11.360] iteration 1151 : loss : 0.252700, loss_ce: 0.078647
[00:09:11.651] iteration 1152 : loss : 0.235367, loss_ce: 0.091474
[00:09:11.941] iteration 1153 : loss : 0.306198, loss_ce: 0.150168
[00:09:12.227] iteration 1154 : loss : 0.269959, loss_ce: 0.073043
[00:09:12.518] iteration 1155 : loss : 0.240765, loss_ce: 0.045805
[00:09:12.808] iteration 1156 : loss : 0.254568, loss_ce: 0.045747
[00:09:13.098] iteration 1157 : loss : 0.323107, loss_ce: 0.093793
[00:09:13.384] iteration 1158 : loss : 0.271831, loss_ce: 0.067798
[00:09:13.675] iteration 1159 : loss : 0.333042, loss_ce: 0.062689
[00:09:13.967] iteration 1160 : loss : 0.277744, loss_ce: 0.038531
[00:09:14.273] iteration 1161 : loss : 0.205126, loss_ce: 0.027876
[00:09:14.562] iteration 1162 : loss : 0.271013, loss_ce: 0.090152
[00:09:14.851] iteration 1163 : loss : 0.212069, loss_ce: 0.064881
[00:09:15.143] iteration 1164 : loss : 0.310872, loss_ce: 0.064298
[00:09:15.432] iteration 1165 : loss : 0.295524, loss_ce: 0.075658
[00:09:15.721] iteration 1166 : loss : 0.266953, loss_ce: 0.097483
[00:09:16.012] iteration 1167 : loss : 0.226006, loss_ce: 0.086044
[00:09:16.302] iteration 1168 : loss : 0.261251, loss_ce: 0.074026
[00:09:16.593] iteration 1169 : loss : 0.305709, loss_ce: 0.087071
[00:09:16.884] iteration 1170 : loss : 0.290033, loss_ce: 0.034946
[00:09:17.174] iteration 1171 : loss : 0.284930, loss_ce: 0.048798
[00:09:17.464] iteration 1172 : loss : 0.266812, loss_ce: 0.064251
[00:09:17.755] iteration 1173 : loss : 0.243508, loss_ce: 0.073180
[00:09:18.044] iteration 1174 : loss : 0.244517, loss_ce: 0.074231
[00:09:18.333] iteration 1175 : loss : 0.235485, loss_ce: 0.067065
[00:09:18.626] iteration 1176 : loss : 0.228642, loss_ce: 0.055513
[00:09:18.915] iteration 1177 : loss : 0.264421, loss_ce: 0.072007
[00:09:19.203] iteration 1178 : loss : 0.219204, loss_ce: 0.046356
[00:09:19.493] iteration 1179 : loss : 0.240939, loss_ce: 0.076912
[00:09:19.784] iteration 1180 : loss : 0.203418, loss_ce: 0.070838
[00:09:20.088] iteration 1181 : loss : 0.240868, loss_ce: 0.037037
[00:09:20.375] iteration 1182 : loss : 0.237872, loss_ce: 0.052139
[00:09:20.662] iteration 1183 : loss : 0.246390, loss_ce: 0.081865
[00:09:20.954] iteration 1184 : loss : 0.255432, loss_ce: 0.069704
[00:09:21.245] iteration 1185 : loss : 0.234358, loss_ce: 0.078293
[00:09:21.535] iteration 1186 : loss : 0.238818, loss_ce: 0.055638
[00:09:21.826] iteration 1187 : loss : 0.224534, loss_ce: 0.124458
[00:09:22.112] iteration 1188 : loss : 0.232390, loss_ce: 0.040582
[00:09:22.402] iteration 1189 : loss : 0.240863, loss_ce: 0.046597
[00:09:22.691] iteration 1190 : loss : 0.199996, loss_ce: 0.045328
[00:09:22.982] iteration 1191 : loss : 0.243969, loss_ce: 0.041411
[00:09:23.268] iteration 1192 : loss : 0.222515, loss_ce: 0.058109
[00:09:23.555] iteration 1193 : loss : 0.240639, loss_ce: 0.075063
[00:09:23.844] iteration 1194 : loss : 0.200857, loss_ce: 0.042200
[00:09:24.135] iteration 1195 : loss : 0.243854, loss_ce: 0.082224
[00:09:24.421] iteration 1196 : loss : 0.179055, loss_ce: 0.033683
[00:09:24.708] iteration 1197 : loss : 0.167455, loss_ce: 0.054965
[00:09:24.995] iteration 1198 : loss : 0.205175, loss_ce: 0.036664
[00:09:25.285] iteration 1199 : loss : 0.207899, loss_ce: 0.063505
[00:09:25.574] iteration 1200 : loss : 0.242419, loss_ce: 0.061206
[00:09:25.884] iteration 1201 : loss : 0.200611, loss_ce: 0.081638
[00:09:26.174] iteration 1202 : loss : 0.201341, loss_ce: 0.080900
[00:09:26.459] iteration 1203 : loss : 0.369270, loss_ce: 0.075173
[00:09:26.748] iteration 1204 : loss : 0.244721, loss_ce: 0.153256
[00:09:27.036] iteration 1205 : loss : 0.244676, loss_ce: 0.075967
[00:09:27.323] iteration 1206 : loss : 0.229722, loss_ce: 0.058778
[00:09:27.612] iteration 1207 : loss : 0.250287, loss_ce: 0.045077
[00:09:27.901] iteration 1208 : loss : 0.310647, loss_ce: 0.046538
[00:09:28.192] iteration 1209 : loss : 0.303295, loss_ce: 0.048226
[00:09:28.480] iteration 1210 : loss : 0.183601, loss_ce: 0.047100
[00:09:28.770] iteration 1211 : loss : 0.240399, loss_ce: 0.055274
[00:09:29.057] iteration 1212 : loss : 0.222051, loss_ce: 0.071875
[00:09:29.342] iteration 1213 : loss : 0.242975, loss_ce: 0.071152
[00:09:29.630] iteration 1214 : loss : 0.269827, loss_ce: 0.048923
[00:09:29.917] iteration 1215 : loss : 0.223797, loss_ce: 0.067844
[00:09:30.205] iteration 1216 : loss : 0.348831, loss_ce: 0.093532
[00:09:30.494] iteration 1217 : loss : 0.259056, loss_ce: 0.056564
[00:09:30.783] iteration 1218 : loss : 0.225086, loss_ce: 0.056655
[00:09:31.070] iteration 1219 : loss : 0.280774, loss_ce: 0.064494
[00:09:31.356] iteration 1220 : loss : 0.268861, loss_ce: 0.040360
[00:09:31.656] iteration 1221 : loss : 0.240350, loss_ce: 0.072532
[00:09:31.947] iteration 1222 : loss : 0.152085, loss_ce: 0.038966
[00:09:32.237] iteration 1223 : loss : 0.222480, loss_ce: 0.060680
[00:09:32.524] iteration 1224 : loss : 0.180771, loss_ce: 0.043937
[00:09:32.811] iteration 1225 : loss : 0.199267, loss_ce: 0.057893
[00:09:33.102] iteration 1226 : loss : 0.272876, loss_ce: 0.067685
[00:09:33.390] iteration 1227 : loss : 0.253708, loss_ce: 0.105320
[00:09:33.680] iteration 1228 : loss : 0.233106, loss_ce: 0.074648
[00:09:33.969] iteration 1229 : loss : 0.177929, loss_ce: 0.058523
[00:09:34.257] iteration 1230 : loss : 0.208551, loss_ce: 0.068874
[00:09:34.545] iteration 1231 : loss : 0.307652, loss_ce: 0.030350
[00:09:34.832] iteration 1232 : loss : 0.244377, loss_ce: 0.070918
[00:09:35.124] iteration 1233 : loss : 0.259732, loss_ce: 0.084726
[00:09:35.415] iteration 1234 : loss : 0.233477, loss_ce: 0.051297
[00:09:35.707] iteration 1235 : loss : 0.260708, loss_ce: 0.032829
[00:09:35.996] iteration 1236 : loss : 0.256507, loss_ce: 0.102914
[00:09:36.290] iteration 1237 : loss : 0.150089, loss_ce: 0.038814
[00:09:36.581] iteration 1238 : loss : 0.259560, loss_ce: 0.049189
[00:09:36.874] iteration 1239 : loss : 0.272317, loss_ce: 0.042853
[00:09:37.167] iteration 1240 : loss : 0.277460, loss_ce: 0.022031
[00:09:37.487] iteration 1241 : loss : 0.167591, loss_ce: 0.050007
[00:09:37.780] iteration 1242 : loss : 0.342575, loss_ce: 0.021735
[00:09:38.074] iteration 1243 : loss : 0.210791, loss_ce: 0.057819
[00:09:38.364] iteration 1244 : loss : 0.261020, loss_ce: 0.092997
[00:09:38.656] iteration 1245 : loss : 0.233506, loss_ce: 0.080872
[00:09:38.947] iteration 1246 : loss : 0.146382, loss_ce: 0.050722
[00:09:39.239] iteration 1247 : loss : 0.208597, loss_ce: 0.067779
[00:09:39.530] iteration 1248 : loss : 0.247546, loss_ce: 0.085124
[00:09:39.824] iteration 1249 : loss : 0.184606, loss_ce: 0.037012
[00:09:40.117] iteration 1250 : loss : 0.210693, loss_ce: 0.035305
[00:09:40.196] iteration 1251 : loss : 0.404043, loss_ce: 0.060204
[00:09:57.050] iteration 1252 : loss : 0.237868, loss_ce: 0.029494
[00:09:57.338] iteration 1253 : loss : 0.210911, loss_ce: 0.051703
[00:09:57.623] iteration 1254 : loss : 0.220540, loss_ce: 0.103323
[00:09:57.914] iteration 1255 : loss : 0.266549, loss_ce: 0.069872
[00:09:58.199] iteration 1256 : loss : 0.173281, loss_ce: 0.054600
[00:09:58.485] iteration 1257 : loss : 0.209632, loss_ce: 0.064099
[00:09:58.771] iteration 1258 : loss : 0.229672, loss_ce: 0.073252
[00:09:59.060] iteration 1259 : loss : 0.160287, loss_ce: 0.060172
[00:09:59.346] iteration 1260 : loss : 0.242825, loss_ce: 0.073728
[00:09:59.645] iteration 1261 : loss : 0.263144, loss_ce: 0.028738
[00:09:59.931] iteration 1262 : loss : 0.293712, loss_ce: 0.073815
[00:10:00.223] iteration 1263 : loss : 0.256802, loss_ce: 0.019607
[00:10:00.512] iteration 1264 : loss : 0.180506, loss_ce: 0.035308
[00:10:00.802] iteration 1265 : loss : 0.244182, loss_ce: 0.097122
[00:10:01.088] iteration 1266 : loss : 0.249662, loss_ce: 0.039783
[00:10:01.374] iteration 1267 : loss : 0.220866, loss_ce: 0.073350
[00:10:01.665] iteration 1268 : loss : 0.193213, loss_ce: 0.054447
[00:10:01.949] iteration 1269 : loss : 0.165512, loss_ce: 0.067980
[00:10:02.235] iteration 1270 : loss : 0.234336, loss_ce: 0.040345
[00:10:02.520] iteration 1271 : loss : 0.182419, loss_ce: 0.067953
[00:10:02.806] iteration 1272 : loss : 0.186892, loss_ce: 0.060385
[00:10:03.094] iteration 1273 : loss : 0.186261, loss_ce: 0.050481
[00:10:03.383] iteration 1274 : loss : 0.232747, loss_ce: 0.081354
[00:10:03.671] iteration 1275 : loss : 0.176101, loss_ce: 0.040627
[00:10:03.957] iteration 1276 : loss : 0.184577, loss_ce: 0.048894
[00:10:04.245] iteration 1277 : loss : 0.212050, loss_ce: 0.061107
[00:10:04.533] iteration 1278 : loss : 0.231642, loss_ce: 0.060265
[00:10:04.822] iteration 1279 : loss : 0.156096, loss_ce: 0.055620
[00:10:05.115] iteration 1280 : loss : 0.251239, loss_ce: 0.055654
[00:10:05.421] iteration 1281 : loss : 0.238396, loss_ce: 0.038319
[00:10:05.708] iteration 1282 : loss : 0.207419, loss_ce: 0.053523
[00:10:05.994] iteration 1283 : loss : 0.219317, loss_ce: 0.113205
[00:10:06.284] iteration 1284 : loss : 0.203350, loss_ce: 0.046456
[00:10:06.569] iteration 1285 : loss : 0.200871, loss_ce: 0.058994
[00:10:06.856] iteration 1286 : loss : 0.144736, loss_ce: 0.029133
[00:10:07.144] iteration 1287 : loss : 0.333554, loss_ce: 0.045724
[00:10:07.433] iteration 1288 : loss : 0.193004, loss_ce: 0.077831
[00:10:07.719] iteration 1289 : loss : 0.167156, loss_ce: 0.057814
[00:10:08.008] iteration 1290 : loss : 0.256478, loss_ce: 0.083801
[00:10:08.295] iteration 1291 : loss : 0.200031, loss_ce: 0.065270
[00:10:08.581] iteration 1292 : loss : 0.183912, loss_ce: 0.082348
[00:10:08.868] iteration 1293 : loss : 0.211812, loss_ce: 0.040853
[00:10:09.154] iteration 1294 : loss : 0.166648, loss_ce: 0.065400
[00:10:09.442] iteration 1295 : loss : 0.239136, loss_ce: 0.078601
[00:10:09.728] iteration 1296 : loss : 0.204803, loss_ce: 0.068016
[00:10:10.015] iteration 1297 : loss : 0.212070, loss_ce: 0.100199
[00:10:10.304] iteration 1298 : loss : 0.221334, loss_ce: 0.034687
[00:10:10.590] iteration 1299 : loss : 0.284361, loss_ce: 0.039335
[00:10:10.876] iteration 1300 : loss : 0.184126, loss_ce: 0.042638
[00:10:11.184] iteration 1301 : loss : 0.163716, loss_ce: 0.036379
[00:10:11.472] iteration 1302 : loss : 0.196862, loss_ce: 0.079761
[00:10:11.759] iteration 1303 : loss : 0.255006, loss_ce: 0.029570
[00:10:12.049] iteration 1304 : loss : 0.287535, loss_ce: 0.032485
[00:10:12.335] iteration 1305 : loss : 0.232861, loss_ce: 0.075253
[00:10:12.619] iteration 1306 : loss : 0.254026, loss_ce: 0.038664
[00:10:12.911] iteration 1307 : loss : 0.192484, loss_ce: 0.050799
[00:10:13.198] iteration 1308 : loss : 0.171049, loss_ce: 0.028065
[00:10:13.487] iteration 1309 : loss : 0.199741, loss_ce: 0.066850
[00:10:13.774] iteration 1310 : loss : 0.295732, loss_ce: 0.062704
[00:10:14.062] iteration 1311 : loss : 0.194825, loss_ce: 0.069773
[00:10:14.349] iteration 1312 : loss : 0.150725, loss_ce: 0.039587
[00:10:14.635] iteration 1313 : loss : 0.170721, loss_ce: 0.044881
[00:10:14.924] iteration 1314 : loss : 0.160189, loss_ce: 0.038335
[00:10:15.213] iteration 1315 : loss : 0.217324, loss_ce: 0.053525
[00:10:15.501] iteration 1316 : loss : 0.265426, loss_ce: 0.053937
[00:10:15.788] iteration 1317 : loss : 0.225458, loss_ce: 0.050388
[00:10:16.077] iteration 1318 : loss : 0.255756, loss_ce: 0.114275
[00:10:16.366] iteration 1319 : loss : 0.164910, loss_ce: 0.048587
[00:10:16.659] iteration 1320 : loss : 0.208843, loss_ce: 0.081078
[00:10:16.961] iteration 1321 : loss : 0.152665, loss_ce: 0.041044
[00:10:17.249] iteration 1322 : loss : 0.155112, loss_ce: 0.043370
[00:10:17.536] iteration 1323 : loss : 0.214856, loss_ce: 0.054289
[00:10:17.824] iteration 1324 : loss : 0.316471, loss_ce: 0.042599
[00:10:18.111] iteration 1325 : loss : 0.172622, loss_ce: 0.043127
[00:10:18.398] iteration 1326 : loss : 0.212337, loss_ce: 0.034048
[00:10:18.686] iteration 1327 : loss : 0.212411, loss_ce: 0.077956
[00:10:18.974] iteration 1328 : loss : 0.284567, loss_ce: 0.054709
[00:10:19.259] iteration 1329 : loss : 0.226231, loss_ce: 0.072428
[00:10:19.548] iteration 1330 : loss : 0.216416, loss_ce: 0.076583
[00:10:19.835] iteration 1331 : loss : 0.256369, loss_ce: 0.086976
[00:10:20.125] iteration 1332 : loss : 0.301076, loss_ce: 0.055084
[00:10:20.414] iteration 1333 : loss : 0.238808, loss_ce: 0.052807
[00:10:20.701] iteration 1334 : loss : 0.182653, loss_ce: 0.045522
[00:10:20.988] iteration 1335 : loss : 0.262757, loss_ce: 0.027802
[00:10:21.274] iteration 1336 : loss : 0.288129, loss_ce: 0.037541
[00:10:21.564] iteration 1337 : loss : 0.218935, loss_ce: 0.057795
[00:10:21.852] iteration 1338 : loss : 0.202528, loss_ce: 0.056439
[00:10:22.143] iteration 1339 : loss : 0.220958, loss_ce: 0.036951
[00:10:22.430] iteration 1340 : loss : 0.198116, loss_ce: 0.044330
[00:10:22.734] iteration 1341 : loss : 0.175446, loss_ce: 0.076959
[00:10:23.022] iteration 1342 : loss : 0.258638, loss_ce: 0.065163
[00:10:23.309] iteration 1343 : loss : 0.189356, loss_ce: 0.057220
[00:10:23.598] iteration 1344 : loss : 0.206233, loss_ce: 0.058842
[00:10:23.885] iteration 1345 : loss : 0.144732, loss_ce: 0.039366
[00:10:24.173] iteration 1346 : loss : 0.162423, loss_ce: 0.058339
[00:10:24.462] iteration 1347 : loss : 0.236558, loss_ce: 0.030613
[00:10:24.749] iteration 1348 : loss : 0.217813, loss_ce: 0.051273
[00:10:25.037] iteration 1349 : loss : 0.157659, loss_ce: 0.061874
[00:10:25.323] iteration 1350 : loss : 0.210539, loss_ce: 0.057675
[00:10:25.612] iteration 1351 : loss : 0.270894, loss_ce: 0.055098
[00:10:25.902] iteration 1352 : loss : 0.187411, loss_ce: 0.063395
[00:10:26.192] iteration 1353 : loss : 0.241794, loss_ce: 0.042625
[00:10:26.479] iteration 1354 : loss : 0.213498, loss_ce: 0.100478
[00:10:26.768] iteration 1355 : loss : 0.322191, loss_ce: 0.052609
[00:10:27.057] iteration 1356 : loss : 0.190464, loss_ce: 0.032816
[00:10:27.344] iteration 1357 : loss : 0.241967, loss_ce: 0.100448
[00:10:27.636] iteration 1358 : loss : 0.184492, loss_ce: 0.032166
[00:10:27.924] iteration 1359 : loss : 0.256781, loss_ce: 0.078211
[00:10:28.213] iteration 1360 : loss : 0.191352, loss_ce: 0.028247
[00:10:28.513] iteration 1361 : loss : 0.191178, loss_ce: 0.053762
[00:10:28.805] iteration 1362 : loss : 0.189925, loss_ce: 0.057663
[00:10:29.093] iteration 1363 : loss : 0.251756, loss_ce: 0.083214
[00:10:29.380] iteration 1364 : loss : 0.207164, loss_ce: 0.071547
[00:10:29.667] iteration 1365 : loss : 0.180318, loss_ce: 0.058112
[00:10:29.956] iteration 1366 : loss : 0.243017, loss_ce: 0.040056
[00:10:30.243] iteration 1367 : loss : 0.184744, loss_ce: 0.054493
[00:10:30.529] iteration 1368 : loss : 0.216678, loss_ce: 0.061324
[00:10:30.817] iteration 1369 : loss : 0.253316, loss_ce: 0.044896
[00:10:31.107] iteration 1370 : loss : 0.252304, loss_ce: 0.050451
[00:10:31.395] iteration 1371 : loss : 0.228575, loss_ce: 0.066407
[00:10:31.684] iteration 1372 : loss : 0.295734, loss_ce: 0.036288
[00:10:31.973] iteration 1373 : loss : 0.235356, loss_ce: 0.073382
[00:10:32.266] iteration 1374 : loss : 0.240943, loss_ce: 0.059185
[00:10:32.557] iteration 1375 : loss : 0.278035, loss_ce: 0.070225
[00:10:32.846] iteration 1376 : loss : 0.197101, loss_ce: 0.052820
[00:10:33.140] iteration 1377 : loss : 0.320111, loss_ce: 0.053542
[00:10:33.429] iteration 1378 : loss : 0.252924, loss_ce: 0.070167
[00:10:33.718] iteration 1379 : loss : 0.183576, loss_ce: 0.063791
[00:10:34.008] iteration 1380 : loss : 0.188470, loss_ce: 0.062939
[00:10:34.309] iteration 1381 : loss : 0.223219, loss_ce: 0.091160
[00:10:34.605] iteration 1382 : loss : 0.263445, loss_ce: 0.035301
[00:10:34.896] iteration 1383 : loss : 0.209751, loss_ce: 0.071806
[00:10:35.192] iteration 1384 : loss : 0.184722, loss_ce: 0.034480
[00:10:35.482] iteration 1385 : loss : 0.223204, loss_ce: 0.039670
[00:10:35.772] iteration 1386 : loss : 0.191153, loss_ce: 0.047725
[00:10:36.066] iteration 1387 : loss : 0.219044, loss_ce: 0.041106
[00:10:36.367] iteration 1388 : loss : 0.207609, loss_ce: 0.070554
[00:10:36.660] iteration 1389 : loss : 0.389387, loss_ce: 0.027570
[00:10:36.742] iteration 1390 : loss : 0.257068, loss_ce: 0.072753
[00:10:53.355] iteration 1391 : loss : 0.188794, loss_ce: 0.065691
[00:10:53.639] iteration 1392 : loss : 0.194012, loss_ce: 0.081914
[00:10:53.925] iteration 1393 : loss : 0.206610, loss_ce: 0.024571
[00:10:54.215] iteration 1394 : loss : 0.237315, loss_ce: 0.047363
[00:10:54.502] iteration 1395 : loss : 0.227614, loss_ce: 0.069694
[00:10:54.788] iteration 1396 : loss : 0.163145, loss_ce: 0.061470
[00:10:55.076] iteration 1397 : loss : 0.119902, loss_ce: 0.026665
[00:10:55.363] iteration 1398 : loss : 0.148255, loss_ce: 0.054474
[00:10:55.650] iteration 1399 : loss : 0.162218, loss_ce: 0.059914
[00:10:55.940] iteration 1400 : loss : 0.178321, loss_ce: 0.047141
[00:10:56.244] iteration 1401 : loss : 0.151698, loss_ce: 0.053953
[00:10:56.535] iteration 1402 : loss : 0.184450, loss_ce: 0.045688
[00:10:56.824] iteration 1403 : loss : 0.168320, loss_ce: 0.024520
[00:10:57.110] iteration 1404 : loss : 0.268328, loss_ce: 0.049960
[00:10:57.396] iteration 1405 : loss : 0.171171, loss_ce: 0.058756
[00:10:57.683] iteration 1406 : loss : 0.181210, loss_ce: 0.050398
[00:10:57.973] iteration 1407 : loss : 0.191643, loss_ce: 0.038855
[00:10:58.263] iteration 1408 : loss : 0.184822, loss_ce: 0.073817
[00:10:58.551] iteration 1409 : loss : 0.167672, loss_ce: 0.055637
[00:10:58.840] iteration 1410 : loss : 0.244781, loss_ce: 0.051045
[00:10:59.131] iteration 1411 : loss : 0.190085, loss_ce: 0.056733
[00:10:59.416] iteration 1412 : loss : 0.252519, loss_ce: 0.053545
[00:10:59.702] iteration 1413 : loss : 0.198856, loss_ce: 0.041555
[00:10:59.994] iteration 1414 : loss : 0.228068, loss_ce: 0.099053
[00:11:00.286] iteration 1415 : loss : 0.262773, loss_ce: 0.103122
[00:11:00.578] iteration 1416 : loss : 0.190912, loss_ce: 0.067964
[00:11:00.870] iteration 1417 : loss : 0.197797, loss_ce: 0.032040
[00:11:01.160] iteration 1418 : loss : 0.142214, loss_ce: 0.035500
[00:11:01.449] iteration 1419 : loss : 0.220992, loss_ce: 0.077344
[00:11:01.739] iteration 1420 : loss : 0.235435, loss_ce: 0.020390
[00:11:02.040] iteration 1421 : loss : 0.238992, loss_ce: 0.040669
[00:11:02.329] iteration 1422 : loss : 0.174173, loss_ce: 0.060869
[00:11:02.618] iteration 1423 : loss : 0.171081, loss_ce: 0.058053
[00:11:02.907] iteration 1424 : loss : 0.268985, loss_ce: 0.064996
[00:11:03.195] iteration 1425 : loss : 0.176763, loss_ce: 0.078677
[00:11:03.484] iteration 1426 : loss : 0.163572, loss_ce: 0.056036
[00:11:03.774] iteration 1427 : loss : 0.160526, loss_ce: 0.032732
[00:11:04.064] iteration 1428 : loss : 0.156552, loss_ce: 0.046221
[00:11:04.353] iteration 1429 : loss : 0.297917, loss_ce: 0.038400
[00:11:04.642] iteration 1430 : loss : 0.170353, loss_ce: 0.053119
[00:11:04.932] iteration 1431 : loss : 0.220342, loss_ce: 0.039194
[00:11:05.224] iteration 1432 : loss : 0.199009, loss_ce: 0.017700
[00:11:05.510] iteration 1433 : loss : 0.241042, loss_ce: 0.044786
[00:11:05.801] iteration 1434 : loss : 0.219705, loss_ce: 0.084015
[00:11:06.091] iteration 1435 : loss : 0.245536, loss_ce: 0.028581
[00:11:06.378] iteration 1436 : loss : 0.155094, loss_ce: 0.054686
[00:11:06.668] iteration 1437 : loss : 0.184041, loss_ce: 0.050464
[00:11:06.955] iteration 1438 : loss : 0.223004, loss_ce: 0.072008
[00:11:07.244] iteration 1439 : loss : 0.278170, loss_ce: 0.018962
[00:11:07.531] iteration 1440 : loss : 0.211297, loss_ce: 0.030614
[00:11:07.837] iteration 1441 : loss : 0.114195, loss_ce: 0.027124
[00:11:08.127] iteration 1442 : loss : 0.150325, loss_ce: 0.027458
[00:11:08.412] iteration 1443 : loss : 0.167988, loss_ce: 0.020258
[00:11:08.699] iteration 1444 : loss : 0.256705, loss_ce: 0.044944
[00:11:08.990] iteration 1445 : loss : 0.186303, loss_ce: 0.055839
[00:11:09.279] iteration 1446 : loss : 0.163496, loss_ce: 0.043039
[00:11:09.571] iteration 1447 : loss : 0.234535, loss_ce: 0.069999
[00:11:09.859] iteration 1448 : loss : 0.217949, loss_ce: 0.062891
[00:11:10.150] iteration 1449 : loss : 0.213396, loss_ce: 0.044173
[00:11:10.438] iteration 1450 : loss : 0.157269, loss_ce: 0.047027
[00:11:10.729] iteration 1451 : loss : 0.265391, loss_ce: 0.056764
[00:11:11.019] iteration 1452 : loss : 0.155810, loss_ce: 0.042903
[00:11:11.309] iteration 1453 : loss : 0.180632, loss_ce: 0.067881
[00:11:11.600] iteration 1454 : loss : 0.161116, loss_ce: 0.046250
[00:11:11.888] iteration 1455 : loss : 0.185032, loss_ce: 0.040719
[00:11:12.176] iteration 1456 : loss : 0.148887, loss_ce: 0.045596
[00:11:12.467] iteration 1457 : loss : 0.252059, loss_ce: 0.029382
[00:11:12.757] iteration 1458 : loss : 0.143910, loss_ce: 0.033150
[00:11:13.048] iteration 1459 : loss : 0.211713, loss_ce: 0.048817
[00:11:13.336] iteration 1460 : loss : 0.211258, loss_ce: 0.052640
[00:11:13.645] iteration 1461 : loss : 0.163127, loss_ce: 0.048206
[00:11:13.935] iteration 1462 : loss : 0.211091, loss_ce: 0.064277
[00:11:14.228] iteration 1463 : loss : 0.135714, loss_ce: 0.035909
[00:11:14.515] iteration 1464 : loss : 0.210630, loss_ce: 0.038747
[00:11:14.803] iteration 1465 : loss : 0.172204, loss_ce: 0.027036
[00:11:15.096] iteration 1466 : loss : 0.203609, loss_ce: 0.041461
[00:11:15.387] iteration 1467 : loss : 0.154994, loss_ce: 0.062808
[00:11:15.677] iteration 1468 : loss : 0.214895, loss_ce: 0.042082
[00:11:15.965] iteration 1469 : loss : 0.228627, loss_ce: 0.033705
[00:11:16.256] iteration 1470 : loss : 0.260754, loss_ce: 0.043438
[00:11:16.549] iteration 1471 : loss : 0.201933, loss_ce: 0.025768
[00:11:16.838] iteration 1472 : loss : 0.177660, loss_ce: 0.058663
[00:11:17.126] iteration 1473 : loss : 0.212702, loss_ce: 0.036430
[00:11:17.417] iteration 1474 : loss : 0.119815, loss_ce: 0.041063
[00:11:17.708] iteration 1475 : loss : 0.177735, loss_ce: 0.079803
[00:11:17.998] iteration 1476 : loss : 0.212919, loss_ce: 0.056043
[00:11:18.286] iteration 1477 : loss : 0.201016, loss_ce: 0.051476
[00:11:18.573] iteration 1478 : loss : 0.245369, loss_ce: 0.042067
[00:11:18.861] iteration 1479 : loss : 0.241941, loss_ce: 0.061043
[00:11:19.151] iteration 1480 : loss : 0.151932, loss_ce: 0.029079
[00:11:19.459] iteration 1481 : loss : 0.203414, loss_ce: 0.059858
[00:11:19.749] iteration 1482 : loss : 0.238184, loss_ce: 0.041792
[00:11:20.036] iteration 1483 : loss : 0.225460, loss_ce: 0.045516
[00:11:20.328] iteration 1484 : loss : 0.193669, loss_ce: 0.021443
[00:11:20.618] iteration 1485 : loss : 0.229528, loss_ce: 0.064348
[00:11:20.906] iteration 1486 : loss : 0.224690, loss_ce: 0.055605
[00:11:21.196] iteration 1487 : loss : 0.122274, loss_ce: 0.051142
[00:11:21.481] iteration 1488 : loss : 0.261847, loss_ce: 0.035733
[00:11:21.771] iteration 1489 : loss : 0.207116, loss_ce: 0.054338
[00:11:22.059] iteration 1490 : loss : 0.166034, loss_ce: 0.039007
[00:11:22.349] iteration 1491 : loss : 0.231944, loss_ce: 0.080033
[00:11:22.638] iteration 1492 : loss : 0.187027, loss_ce: 0.090419
[00:11:22.925] iteration 1493 : loss : 0.183292, loss_ce: 0.045592
[00:11:23.220] iteration 1494 : loss : 0.141932, loss_ce: 0.043709
[00:11:23.508] iteration 1495 : loss : 0.183009, loss_ce: 0.038325
[00:11:23.796] iteration 1496 : loss : 0.152690, loss_ce: 0.063628
[00:11:24.084] iteration 1497 : loss : 0.192813, loss_ce: 0.065914
[00:11:24.373] iteration 1498 : loss : 0.198299, loss_ce: 0.047299
[00:11:24.659] iteration 1499 : loss : 0.154617, loss_ce: 0.053804
[00:11:24.946] iteration 1500 : loss : 0.156011, loss_ce: 0.024949
[00:11:25.248] iteration 1501 : loss : 0.291848, loss_ce: 0.052193
[00:11:25.535] iteration 1502 : loss : 0.134723, loss_ce: 0.025366
[00:11:25.824] iteration 1503 : loss : 0.180279, loss_ce: 0.060632
[00:11:26.116] iteration 1504 : loss : 0.186930, loss_ce: 0.053756
[00:11:26.403] iteration 1505 : loss : 0.207591, loss_ce: 0.033503
[00:11:26.691] iteration 1506 : loss : 0.245854, loss_ce: 0.053378
[00:11:26.980] iteration 1507 : loss : 0.165947, loss_ce: 0.069923
[00:11:27.269] iteration 1508 : loss : 0.159702, loss_ce: 0.067045
[00:11:27.557] iteration 1509 : loss : 0.195404, loss_ce: 0.070823
[00:11:27.846] iteration 1510 : loss : 0.190416, loss_ce: 0.064869
[00:11:28.138] iteration 1511 : loss : 0.197125, loss_ce: 0.046315
[00:11:28.428] iteration 1512 : loss : 0.183515, loss_ce: 0.035932
[00:11:28.720] iteration 1513 : loss : 0.160958, loss_ce: 0.068201
[00:11:29.019] iteration 1514 : loss : 0.214223, loss_ce: 0.045642
[00:11:29.312] iteration 1515 : loss : 0.270420, loss_ce: 0.043522
[00:11:29.600] iteration 1516 : loss : 0.286791, loss_ce: 0.039783
[00:11:29.894] iteration 1517 : loss : 0.278125, loss_ce: 0.056475
[00:11:30.196] iteration 1518 : loss : 0.163801, loss_ce: 0.092762
[00:11:30.485] iteration 1519 : loss : 0.171243, loss_ce: 0.022022
[00:11:30.779] iteration 1520 : loss : 0.188803, loss_ce: 0.034910
[00:11:31.087] iteration 1521 : loss : 0.242506, loss_ce: 0.055394
[00:11:31.380] iteration 1522 : loss : 0.139555, loss_ce: 0.026996
[00:11:31.672] iteration 1523 : loss : 0.188613, loss_ce: 0.068535
[00:11:31.965] iteration 1524 : loss : 0.210302, loss_ce: 0.060621
[00:11:32.255] iteration 1525 : loss : 0.260844, loss_ce: 0.037679
[00:11:32.545] iteration 1526 : loss : 0.186569, loss_ce: 0.071963
[00:11:32.835] iteration 1527 : loss : 0.181659, loss_ce: 0.046073
[00:11:33.126] iteration 1528 : loss : 0.154759, loss_ce: 0.048780
[00:11:33.200] iteration 1529 : loss : 0.262436, loss_ce: 0.132876
[00:11:49.421] iteration 1530 : loss : 0.182497, loss_ce: 0.024593
[00:11:49.705] iteration 1531 : loss : 0.155794, loss_ce: 0.030932
[00:11:49.993] iteration 1532 : loss : 0.184497, loss_ce: 0.042718
[00:11:50.279] iteration 1533 : loss : 0.222629, loss_ce: 0.056977
[00:11:50.565] iteration 1534 : loss : 0.236078, loss_ce: 0.025785
[00:11:50.852] iteration 1535 : loss : 0.186308, loss_ce: 0.044078
[00:11:51.139] iteration 1536 : loss : 0.159063, loss_ce: 0.041064
[00:11:51.427] iteration 1537 : loss : 0.167438, loss_ce: 0.060007
[00:11:51.714] iteration 1538 : loss : 0.184423, loss_ce: 0.071620
[00:11:52.002] iteration 1539 : loss : 0.304358, loss_ce: 0.058137
[00:11:52.288] iteration 1540 : loss : 0.214230, loss_ce: 0.079018
[00:11:52.590] iteration 1541 : loss : 0.177078, loss_ce: 0.039524
[00:11:52.874] iteration 1542 : loss : 0.210939, loss_ce: 0.094180
[00:11:53.161] iteration 1543 : loss : 0.226812, loss_ce: 0.074486
[00:11:53.450] iteration 1544 : loss : 0.230261, loss_ce: 0.069819
[00:11:53.735] iteration 1545 : loss : 0.171846, loss_ce: 0.062183
[00:11:54.021] iteration 1546 : loss : 0.282386, loss_ce: 0.033711
[00:11:54.306] iteration 1547 : loss : 0.146538, loss_ce: 0.059946
[00:11:54.592] iteration 1548 : loss : 0.172208, loss_ce: 0.028473
[00:11:54.877] iteration 1549 : loss : 0.173954, loss_ce: 0.065495
[00:11:55.168] iteration 1550 : loss : 0.187495, loss_ce: 0.061339
[00:11:55.453] iteration 1551 : loss : 0.177082, loss_ce: 0.034165
[00:11:55.740] iteration 1552 : loss : 0.179731, loss_ce: 0.084923
[00:11:56.025] iteration 1553 : loss : 0.190288, loss_ce: 0.077885
[00:11:56.313] iteration 1554 : loss : 0.192874, loss_ce: 0.052028
[00:11:56.603] iteration 1555 : loss : 0.223006, loss_ce: 0.041713
[00:11:56.891] iteration 1556 : loss : 0.216747, loss_ce: 0.058842
[00:11:57.176] iteration 1557 : loss : 0.206402, loss_ce: 0.053503
[00:11:57.462] iteration 1558 : loss : 0.182111, loss_ce: 0.058730
[00:11:57.748] iteration 1559 : loss : 0.198444, loss_ce: 0.038905
[00:11:58.033] iteration 1560 : loss : 0.234512, loss_ce: 0.078760
[00:11:58.335] iteration 1561 : loss : 0.245181, loss_ce: 0.042542
[00:11:58.623] iteration 1562 : loss : 0.249735, loss_ce: 0.064411
[00:11:58.910] iteration 1563 : loss : 0.106456, loss_ce: 0.034627
[00:11:59.197] iteration 1564 : loss : 0.144865, loss_ce: 0.060439
[00:11:59.483] iteration 1565 : loss : 0.215263, loss_ce: 0.025446
[00:11:59.771] iteration 1566 : loss : 0.169492, loss_ce: 0.064424
[00:12:00.062] iteration 1567 : loss : 0.201402, loss_ce: 0.060861
[00:12:00.349] iteration 1568 : loss : 0.146210, loss_ce: 0.055779
[00:12:00.639] iteration 1569 : loss : 0.222036, loss_ce: 0.069611
[00:12:00.929] iteration 1570 : loss : 0.162069, loss_ce: 0.016827
[00:12:01.215] iteration 1571 : loss : 0.162718, loss_ce: 0.052635
[00:12:01.502] iteration 1572 : loss : 0.233851, loss_ce: 0.008869
[00:12:01.789] iteration 1573 : loss : 0.186547, loss_ce: 0.063299
[00:12:02.078] iteration 1574 : loss : 0.194751, loss_ce: 0.053506
[00:12:02.366] iteration 1575 : loss : 0.170887, loss_ce: 0.054998
[00:12:02.652] iteration 1576 : loss : 0.194953, loss_ce: 0.079201
[00:12:02.939] iteration 1577 : loss : 0.190172, loss_ce: 0.065987
[00:12:03.227] iteration 1578 : loss : 0.158918, loss_ce: 0.037709
[00:12:03.513] iteration 1579 : loss : 0.198172, loss_ce: 0.035371
[00:12:03.800] iteration 1580 : loss : 0.124674, loss_ce: 0.024301
[00:12:04.108] iteration 1581 : loss : 0.200517, loss_ce: 0.032764
[00:12:04.395] iteration 1582 : loss : 0.288626, loss_ce: 0.040681
[00:12:04.682] iteration 1583 : loss : 0.136884, loss_ce: 0.042831
[00:12:04.971] iteration 1584 : loss : 0.130882, loss_ce: 0.036102
[00:12:05.259] iteration 1585 : loss : 0.218318, loss_ce: 0.036986
[00:12:05.549] iteration 1586 : loss : 0.242957, loss_ce: 0.084800
[00:12:05.838] iteration 1587 : loss : 0.156387, loss_ce: 0.036129
[00:12:06.124] iteration 1588 : loss : 0.198889, loss_ce: 0.056696
[00:12:06.410] iteration 1589 : loss : 0.139309, loss_ce: 0.027906
[00:12:06.698] iteration 1590 : loss : 0.198472, loss_ce: 0.038732
[00:12:06.986] iteration 1591 : loss : 0.187629, loss_ce: 0.029396
[00:12:07.272] iteration 1592 : loss : 0.187181, loss_ce: 0.063635
[00:12:07.559] iteration 1593 : loss : 0.180071, loss_ce: 0.047671
[00:12:07.845] iteration 1594 : loss : 0.143167, loss_ce: 0.033809
[00:12:08.135] iteration 1595 : loss : 0.230701, loss_ce: 0.025186
[00:12:08.422] iteration 1596 : loss : 0.152718, loss_ce: 0.045522
[00:12:08.708] iteration 1597 : loss : 0.202040, loss_ce: 0.051477
[00:12:08.996] iteration 1598 : loss : 0.165889, loss_ce: 0.033045
[00:12:09.282] iteration 1599 : loss : 0.179834, loss_ce: 0.034350
[00:12:09.569] iteration 1600 : loss : 0.209661, loss_ce: 0.054161
[00:12:09.871] iteration 1601 : loss : 0.163420, loss_ce: 0.047882
[00:12:10.160] iteration 1602 : loss : 0.155093, loss_ce: 0.037682
[00:12:10.446] iteration 1603 : loss : 0.145618, loss_ce: 0.045244
[00:12:10.733] iteration 1604 : loss : 0.254678, loss_ce: 0.021999
[00:12:11.020] iteration 1605 : loss : 0.150658, loss_ce: 0.055676
[00:12:11.307] iteration 1606 : loss : 0.220827, loss_ce: 0.036357
[00:12:11.595] iteration 1607 : loss : 0.199775, loss_ce: 0.068502
[00:12:11.881] iteration 1608 : loss : 0.182340, loss_ce: 0.045806
[00:12:12.169] iteration 1609 : loss : 0.188560, loss_ce: 0.065939
[00:12:12.457] iteration 1610 : loss : 0.253570, loss_ce: 0.077185
[00:12:12.745] iteration 1611 : loss : 0.184830, loss_ce: 0.029644
[00:12:13.031] iteration 1612 : loss : 0.220559, loss_ce: 0.044686
[00:12:13.319] iteration 1613 : loss : 0.171983, loss_ce: 0.032852
[00:12:13.607] iteration 1614 : loss : 0.199648, loss_ce: 0.036147
[00:12:13.894] iteration 1615 : loss : 0.182152, loss_ce: 0.035392
[00:12:14.184] iteration 1616 : loss : 0.220741, loss_ce: 0.033142
[00:12:14.472] iteration 1617 : loss : 0.213539, loss_ce: 0.046045
[00:12:14.758] iteration 1618 : loss : 0.208317, loss_ce: 0.049260
[00:12:15.046] iteration 1619 : loss : 0.220898, loss_ce: 0.034605
[00:12:15.333] iteration 1620 : loss : 0.176342, loss_ce: 0.054370
[00:12:15.634] iteration 1621 : loss : 0.258847, loss_ce: 0.029846
[00:12:15.922] iteration 1622 : loss : 0.171310, loss_ce: 0.059050
[00:12:16.211] iteration 1623 : loss : 0.158397, loss_ce: 0.033983
[00:12:16.500] iteration 1624 : loss : 0.145228, loss_ce: 0.045792
[00:12:16.786] iteration 1625 : loss : 0.259341, loss_ce: 0.050678
[00:12:17.074] iteration 1626 : loss : 0.276316, loss_ce: 0.115375
[00:12:17.361] iteration 1627 : loss : 0.153252, loss_ce: 0.035983
[00:12:17.647] iteration 1628 : loss : 0.169676, loss_ce: 0.070159
[00:12:17.933] iteration 1629 : loss : 0.146718, loss_ce: 0.064539
[00:12:18.224] iteration 1630 : loss : 0.250449, loss_ce: 0.024299
[00:12:18.512] iteration 1631 : loss : 0.207284, loss_ce: 0.038306
[00:12:18.797] iteration 1632 : loss : 0.240929, loss_ce: 0.055951
[00:12:19.084] iteration 1633 : loss : 0.153817, loss_ce: 0.049923
[00:12:19.373] iteration 1634 : loss : 0.179454, loss_ce: 0.074370
[00:12:19.660] iteration 1635 : loss : 0.134197, loss_ce: 0.046106
[00:12:19.947] iteration 1636 : loss : 0.250239, loss_ce: 0.023729
[00:12:20.235] iteration 1637 : loss : 0.187804, loss_ce: 0.033173
[00:12:20.523] iteration 1638 : loss : 0.139633, loss_ce: 0.039008
[00:12:20.815] iteration 1639 : loss : 0.133040, loss_ce: 0.027142
[00:12:21.102] iteration 1640 : loss : 0.125260, loss_ce: 0.033300
[00:12:21.406] iteration 1641 : loss : 0.191651, loss_ce: 0.021563
[00:12:21.695] iteration 1642 : loss : 0.182647, loss_ce: 0.040747
[00:12:21.982] iteration 1643 : loss : 0.167317, loss_ce: 0.050372
[00:12:22.269] iteration 1644 : loss : 0.126071, loss_ce: 0.038385
[00:12:22.557] iteration 1645 : loss : 0.124700, loss_ce: 0.041080
[00:12:22.843] iteration 1646 : loss : 0.123964, loss_ce: 0.030759
[00:12:23.130] iteration 1647 : loss : 0.139665, loss_ce: 0.042621
[00:12:23.418] iteration 1648 : loss : 0.188186, loss_ce: 0.040932
[00:12:23.704] iteration 1649 : loss : 0.198707, loss_ce: 0.047861
[00:12:23.992] iteration 1650 : loss : 0.226860, loss_ce: 0.061666
[00:12:24.280] iteration 1651 : loss : 0.152550, loss_ce: 0.042138
[00:12:24.569] iteration 1652 : loss : 0.143433, loss_ce: 0.048247
[00:12:24.859] iteration 1653 : loss : 0.163100, loss_ce: 0.054699
[00:12:25.155] iteration 1654 : loss : 0.159222, loss_ce: 0.056565
[00:12:25.450] iteration 1655 : loss : 0.172356, loss_ce: 0.046281
[00:12:25.737] iteration 1656 : loss : 0.132192, loss_ce: 0.037766
[00:12:26.033] iteration 1657 : loss : 0.130115, loss_ce: 0.040621
[00:12:26.326] iteration 1658 : loss : 0.160066, loss_ce: 0.023596
[00:12:26.615] iteration 1659 : loss : 0.206788, loss_ce: 0.042564
[00:12:26.904] iteration 1660 : loss : 0.169411, loss_ce: 0.036166
[00:12:27.209] iteration 1661 : loss : 0.168589, loss_ce: 0.047977
[00:12:27.496] iteration 1662 : loss : 0.140439, loss_ce: 0.045751
[00:12:27.789] iteration 1663 : loss : 0.160094, loss_ce: 0.032015
[00:12:28.080] iteration 1664 : loss : 0.164656, loss_ce: 0.033409
[00:12:28.372] iteration 1665 : loss : 0.158463, loss_ce: 0.031632
[00:12:28.661] iteration 1666 : loss : 0.158450, loss_ce: 0.037299
[00:12:28.955] iteration 1667 : loss : 0.143872, loss_ce: 0.055329
[00:12:29.041] iteration 1668 : loss : 0.510927, loss_ce: 0.019517
[00:12:45.571] iteration 1669 : loss : 0.147283, loss_ce: 0.030874
[00:12:45.856] iteration 1670 : loss : 0.137324, loss_ce: 0.048483
[00:12:46.140] iteration 1671 : loss : 0.154974, loss_ce: 0.015216
[00:12:46.428] iteration 1672 : loss : 0.221947, loss_ce: 0.051425
[00:12:46.713] iteration 1673 : loss : 0.238376, loss_ce: 0.042376
[00:12:46.999] iteration 1674 : loss : 0.179899, loss_ce: 0.063161
[00:12:47.285] iteration 1675 : loss : 0.133589, loss_ce: 0.050712
[00:12:47.575] iteration 1676 : loss : 0.131933, loss_ce: 0.021799
[00:12:47.861] iteration 1677 : loss : 0.169500, loss_ce: 0.073894
[00:12:48.145] iteration 1678 : loss : 0.220898, loss_ce: 0.059800
[00:12:48.432] iteration 1679 : loss : 0.158661, loss_ce: 0.058400
[00:12:48.719] iteration 1680 : loss : 0.094349, loss_ce: 0.029099
[00:12:49.018] iteration 1681 : loss : 0.148006, loss_ce: 0.057730
[00:12:49.304] iteration 1682 : loss : 0.180025, loss_ce: 0.029090
[00:12:49.590] iteration 1683 : loss : 0.146512, loss_ce: 0.029921
[00:12:49.876] iteration 1684 : loss : 0.128790, loss_ce: 0.056733
[00:12:50.165] iteration 1685 : loss : 0.151810, loss_ce: 0.055636
[00:12:50.452] iteration 1686 : loss : 0.123048, loss_ce: 0.030214
[00:12:50.742] iteration 1687 : loss : 0.159815, loss_ce: 0.041449
[00:12:51.031] iteration 1688 : loss : 0.185494, loss_ce: 0.022506
[00:12:51.321] iteration 1689 : loss : 0.139255, loss_ce: 0.045922
[00:12:51.611] iteration 1690 : loss : 0.135009, loss_ce: 0.057919
[00:12:51.900] iteration 1691 : loss : 0.207456, loss_ce: 0.058964
[00:12:52.189] iteration 1692 : loss : 0.181375, loss_ce: 0.035524
[00:12:52.477] iteration 1693 : loss : 0.143245, loss_ce: 0.026031
[00:12:52.766] iteration 1694 : loss : 0.175900, loss_ce: 0.044046
[00:12:53.055] iteration 1695 : loss : 0.122613, loss_ce: 0.026413
[00:12:53.344] iteration 1696 : loss : 0.208080, loss_ce: 0.045168
[00:12:53.631] iteration 1697 : loss : 0.227446, loss_ce: 0.049540
[00:12:53.921] iteration 1698 : loss : 0.124846, loss_ce: 0.031645
[00:12:54.209] iteration 1699 : loss : 0.149319, loss_ce: 0.056608
[00:12:54.500] iteration 1700 : loss : 0.179487, loss_ce: 0.035256
[00:12:54.811] iteration 1701 : loss : 0.125251, loss_ce: 0.026482
[00:12:55.100] iteration 1702 : loss : 0.129007, loss_ce: 0.018994
[00:12:55.387] iteration 1703 : loss : 0.165664, loss_ce: 0.040138
[00:12:55.679] iteration 1704 : loss : 0.150670, loss_ce: 0.070770
[00:12:55.965] iteration 1705 : loss : 0.257896, loss_ce: 0.026321
[00:12:56.255] iteration 1706 : loss : 0.173396, loss_ce: 0.042222
[00:12:56.545] iteration 1707 : loss : 0.186015, loss_ce: 0.041380
[00:12:56.838] iteration 1708 : loss : 0.189167, loss_ce: 0.039398
[00:12:57.129] iteration 1709 : loss : 0.148036, loss_ce: 0.066895
[00:12:57.417] iteration 1710 : loss : 0.133759, loss_ce: 0.063415
[00:12:57.706] iteration 1711 : loss : 0.187976, loss_ce: 0.033635
[00:12:57.994] iteration 1712 : loss : 0.181912, loss_ce: 0.048286
[00:12:58.282] iteration 1713 : loss : 0.212788, loss_ce: 0.071817
[00:12:58.570] iteration 1714 : loss : 0.139797, loss_ce: 0.053903
[00:12:58.859] iteration 1715 : loss : 0.327583, loss_ce: 0.016433
[00:12:59.146] iteration 1716 : loss : 0.115448, loss_ce: 0.024647
[00:12:59.435] iteration 1717 : loss : 0.114909, loss_ce: 0.030624
[00:12:59.725] iteration 1718 : loss : 0.196544, loss_ce: 0.049666
[00:13:00.014] iteration 1719 : loss : 0.180703, loss_ce: 0.054511
[00:13:00.306] iteration 1720 : loss : 0.130741, loss_ce: 0.075531
[00:13:00.619] iteration 1721 : loss : 0.111618, loss_ce: 0.037126
[00:13:00.910] iteration 1722 : loss : 0.125738, loss_ce: 0.038436
[00:13:01.200] iteration 1723 : loss : 0.129646, loss_ce: 0.045670
[00:13:01.492] iteration 1724 : loss : 0.182702, loss_ce: 0.052363
[00:13:01.780] iteration 1725 : loss : 0.170951, loss_ce: 0.065149
[00:13:02.069] iteration 1726 : loss : 0.215697, loss_ce: 0.074093
[00:13:02.359] iteration 1727 : loss : 0.162951, loss_ce: 0.041398
[00:13:02.651] iteration 1728 : loss : 0.126581, loss_ce: 0.035357
[00:13:02.940] iteration 1729 : loss : 0.133667, loss_ce: 0.031556
[00:13:03.228] iteration 1730 : loss : 0.116666, loss_ce: 0.022802
[00:13:03.516] iteration 1731 : loss : 0.169678, loss_ce: 0.036035
[00:13:03.805] iteration 1732 : loss : 0.205818, loss_ce: 0.030432
[00:13:04.096] iteration 1733 : loss : 0.156064, loss_ce: 0.042712
[00:13:04.385] iteration 1734 : loss : 0.178616, loss_ce: 0.028766
[00:13:04.676] iteration 1735 : loss : 0.162329, loss_ce: 0.072153
[00:13:04.963] iteration 1736 : loss : 0.117343, loss_ce: 0.034898
[00:13:05.254] iteration 1737 : loss : 0.204300, loss_ce: 0.034388
[00:13:05.545] iteration 1738 : loss : 0.138585, loss_ce: 0.049859
[00:13:05.834] iteration 1739 : loss : 0.206552, loss_ce: 0.051906
[00:13:06.124] iteration 1740 : loss : 0.168945, loss_ce: 0.031865
[00:13:06.436] iteration 1741 : loss : 0.211410, loss_ce: 0.038332
[00:13:06.724] iteration 1742 : loss : 0.117403, loss_ce: 0.038271
[00:13:07.015] iteration 1743 : loss : 0.144049, loss_ce: 0.031130
[00:13:07.306] iteration 1744 : loss : 0.135615, loss_ce: 0.043313
[00:13:07.595] iteration 1745 : loss : 0.145818, loss_ce: 0.051712
[00:13:07.885] iteration 1746 : loss : 0.187985, loss_ce: 0.052812
[00:13:08.177] iteration 1747 : loss : 0.133829, loss_ce: 0.032128
[00:13:08.464] iteration 1748 : loss : 0.167942, loss_ce: 0.028004
[00:13:08.756] iteration 1749 : loss : 0.150768, loss_ce: 0.036646
[00:13:09.046] iteration 1750 : loss : 0.158145, loss_ce: 0.020041
[00:13:09.338] iteration 1751 : loss : 0.155532, loss_ce: 0.047054
[00:13:09.626] iteration 1752 : loss : 0.142791, loss_ce: 0.052741
[00:13:09.918] iteration 1753 : loss : 0.226174, loss_ce: 0.032279
[00:13:10.209] iteration 1754 : loss : 0.145438, loss_ce: 0.080348
[00:13:10.500] iteration 1755 : loss : 0.243934, loss_ce: 0.070639
[00:13:10.788] iteration 1756 : loss : 0.209934, loss_ce: 0.025296
[00:13:11.080] iteration 1757 : loss : 0.186327, loss_ce: 0.041093
[00:13:11.368] iteration 1758 : loss : 0.111642, loss_ce: 0.029353
[00:13:11.656] iteration 1759 : loss : 0.169898, loss_ce: 0.035840
[00:13:11.943] iteration 1760 : loss : 0.133070, loss_ce: 0.026272
[00:13:12.249] iteration 1761 : loss : 0.124409, loss_ce: 0.025793
[00:13:12.539] iteration 1762 : loss : 0.213555, loss_ce: 0.034171
[00:13:12.826] iteration 1763 : loss : 0.191512, loss_ce: 0.031082
[00:13:13.115] iteration 1764 : loss : 0.172648, loss_ce: 0.034762
[00:13:13.406] iteration 1765 : loss : 0.105953, loss_ce: 0.028687
[00:13:13.694] iteration 1766 : loss : 0.159923, loss_ce: 0.016876
[00:13:13.984] iteration 1767 : loss : 0.144503, loss_ce: 0.040457
[00:13:14.272] iteration 1768 : loss : 0.121594, loss_ce: 0.031542
[00:13:14.562] iteration 1769 : loss : 0.241096, loss_ce: 0.065974
[00:13:14.852] iteration 1770 : loss : 0.219218, loss_ce: 0.042192
[00:13:15.145] iteration 1771 : loss : 0.158066, loss_ce: 0.057470
[00:13:15.434] iteration 1772 : loss : 0.126664, loss_ce: 0.032818
[00:13:15.725] iteration 1773 : loss : 0.227645, loss_ce: 0.062239
[00:13:16.012] iteration 1774 : loss : 0.132442, loss_ce: 0.029444
[00:13:16.301] iteration 1775 : loss : 0.317367, loss_ce: 0.043503
[00:13:16.591] iteration 1776 : loss : 0.255340, loss_ce: 0.025757
[00:13:16.881] iteration 1777 : loss : 0.145390, loss_ce: 0.044744
[00:13:17.170] iteration 1778 : loss : 0.143947, loss_ce: 0.033185
[00:13:17.461] iteration 1779 : loss : 0.232415, loss_ce: 0.065206
[00:13:17.752] iteration 1780 : loss : 0.163899, loss_ce: 0.046721
[00:13:18.066] iteration 1781 : loss : 0.155022, loss_ce: 0.040472
[00:13:18.354] iteration 1782 : loss : 0.169761, loss_ce: 0.052575
[00:13:18.640] iteration 1783 : loss : 0.177812, loss_ce: 0.055773
[00:13:18.929] iteration 1784 : loss : 0.149626, loss_ce: 0.065030
[00:13:19.220] iteration 1785 : loss : 0.146316, loss_ce: 0.046547
[00:13:19.512] iteration 1786 : loss : 0.156616, loss_ce: 0.045845
[00:13:19.804] iteration 1787 : loss : 0.161815, loss_ce: 0.043523
[00:13:20.092] iteration 1788 : loss : 0.142307, loss_ce: 0.031813
[00:13:20.381] iteration 1789 : loss : 0.208221, loss_ce: 0.029996
[00:13:20.667] iteration 1790 : loss : 0.129362, loss_ce: 0.034682
[00:13:20.954] iteration 1791 : loss : 0.193654, loss_ce: 0.039590
[00:13:21.249] iteration 1792 : loss : 0.212562, loss_ce: 0.025036
[00:13:21.543] iteration 1793 : loss : 0.150748, loss_ce: 0.053710
[00:13:21.832] iteration 1794 : loss : 0.154568, loss_ce: 0.043075
[00:13:22.123] iteration 1795 : loss : 0.282978, loss_ce: 0.010343
[00:13:22.411] iteration 1796 : loss : 0.123744, loss_ce: 0.043463
[00:13:22.704] iteration 1797 : loss : 0.161994, loss_ce: 0.040566
[00:13:22.994] iteration 1798 : loss : 0.204943, loss_ce: 0.037275
[00:13:23.280] iteration 1799 : loss : 0.125717, loss_ce: 0.052260
[00:13:23.571] iteration 1800 : loss : 0.203923, loss_ce: 0.034934
[00:13:23.889] iteration 1801 : loss : 0.313608, loss_ce: 0.020297
[00:13:24.181] iteration 1802 : loss : 0.194345, loss_ce: 0.036600
[00:13:24.468] iteration 1803 : loss : 0.144591, loss_ce: 0.053331
[00:13:24.762] iteration 1804 : loss : 0.158277, loss_ce: 0.067435
[00:13:25.055] iteration 1805 : loss : 0.138423, loss_ce: 0.061752
[00:13:25.347] iteration 1806 : loss : 0.167264, loss_ce: 0.044004
[00:13:25.428] iteration 1807 : loss : 0.300385, loss_ce: 0.033778
[00:13:42.523] iteration 1808 : loss : 0.158084, loss_ce: 0.027434
[00:13:42.809] iteration 1809 : loss : 0.158537, loss_ce: 0.067146
[00:13:43.094] iteration 1810 : loss : 0.177875, loss_ce: 0.071159
[00:13:43.383] iteration 1811 : loss : 0.226398, loss_ce: 0.058750
[00:13:43.669] iteration 1812 : loss : 0.140901, loss_ce: 0.064679
[00:13:43.955] iteration 1813 : loss : 0.122278, loss_ce: 0.031229
[00:13:44.241] iteration 1814 : loss : 0.181762, loss_ce: 0.036807
[00:13:44.529] iteration 1815 : loss : 0.160465, loss_ce: 0.055784
[00:13:44.815] iteration 1816 : loss : 0.158541, loss_ce: 0.043785
[00:13:45.101] iteration 1817 : loss : 0.149580, loss_ce: 0.044481
[00:13:45.392] iteration 1818 : loss : 0.224604, loss_ce: 0.029829
[00:13:45.678] iteration 1819 : loss : 0.165767, loss_ce: 0.023685
[00:13:45.964] iteration 1820 : loss : 0.138182, loss_ce: 0.033600
[00:13:46.264] iteration 1821 : loss : 0.170622, loss_ce: 0.026056
[00:13:46.553] iteration 1822 : loss : 0.173028, loss_ce: 0.061921
[00:13:46.840] iteration 1823 : loss : 0.178422, loss_ce: 0.027074
[00:13:47.125] iteration 1824 : loss : 0.175964, loss_ce: 0.037162
[00:13:47.412] iteration 1825 : loss : 0.169612, loss_ce: 0.012371
[00:13:47.702] iteration 1826 : loss : 0.196740, loss_ce: 0.033464
[00:13:47.986] iteration 1827 : loss : 0.210502, loss_ce: 0.071987
[00:13:48.273] iteration 1828 : loss : 0.182001, loss_ce: 0.030921
[00:13:48.561] iteration 1829 : loss : 0.160170, loss_ce: 0.049274
[00:13:48.851] iteration 1830 : loss : 0.128656, loss_ce: 0.057807
[00:13:49.137] iteration 1831 : loss : 0.129455, loss_ce: 0.075172
[00:13:49.420] iteration 1832 : loss : 0.144869, loss_ce: 0.048823
[00:13:49.707] iteration 1833 : loss : 0.160250, loss_ce: 0.031510
[00:13:49.997] iteration 1834 : loss : 0.112233, loss_ce: 0.028340
[00:13:50.283] iteration 1835 : loss : 0.176739, loss_ce: 0.028115
[00:13:50.571] iteration 1836 : loss : 0.254366, loss_ce: 0.066524
[00:13:50.857] iteration 1837 : loss : 0.208412, loss_ce: 0.025098
[00:13:51.146] iteration 1838 : loss : 0.127726, loss_ce: 0.019247
[00:13:51.432] iteration 1839 : loss : 0.182693, loss_ce: 0.030368
[00:13:51.719] iteration 1840 : loss : 0.140733, loss_ce: 0.059365
[00:13:52.024] iteration 1841 : loss : 0.156594, loss_ce: 0.026608
[00:13:52.313] iteration 1842 : loss : 0.131871, loss_ce: 0.017454
[00:13:52.602] iteration 1843 : loss : 0.182328, loss_ce: 0.050898
[00:13:52.889] iteration 1844 : loss : 0.182872, loss_ce: 0.031791
[00:13:53.175] iteration 1845 : loss : 0.132811, loss_ce: 0.053885
[00:13:53.461] iteration 1846 : loss : 0.196751, loss_ce: 0.035208
[00:13:53.748] iteration 1847 : loss : 0.162033, loss_ce: 0.039176
[00:13:54.035] iteration 1848 : loss : 0.211624, loss_ce: 0.032888
[00:13:54.322] iteration 1849 : loss : 0.174865, loss_ce: 0.037797
[00:13:54.612] iteration 1850 : loss : 0.243164, loss_ce: 0.020389
[00:13:54.899] iteration 1851 : loss : 0.170495, loss_ce: 0.072195
[00:13:55.187] iteration 1852 : loss : 0.168567, loss_ce: 0.034057
[00:13:55.474] iteration 1853 : loss : 0.213952, loss_ce: 0.052707
[00:13:55.763] iteration 1854 : loss : 0.164244, loss_ce: 0.054649
[00:13:56.049] iteration 1855 : loss : 0.134040, loss_ce: 0.023845
[00:13:56.336] iteration 1856 : loss : 0.160358, loss_ce: 0.067379
[00:13:56.623] iteration 1857 : loss : 0.171198, loss_ce: 0.031265
[00:13:56.911] iteration 1858 : loss : 0.171009, loss_ce: 0.038698
[00:13:57.196] iteration 1859 : loss : 0.129957, loss_ce: 0.057161
[00:13:57.484] iteration 1860 : loss : 0.136416, loss_ce: 0.034672
[00:13:57.790] iteration 1861 : loss : 0.161206, loss_ce: 0.025117
[00:13:58.080] iteration 1862 : loss : 0.158957, loss_ce: 0.042748
[00:13:58.370] iteration 1863 : loss : 0.202378, loss_ce: 0.034966
[00:13:58.656] iteration 1864 : loss : 0.133050, loss_ce: 0.037247
[00:13:58.942] iteration 1865 : loss : 0.223108, loss_ce: 0.044500
[00:13:59.234] iteration 1866 : loss : 0.141092, loss_ce: 0.061739
[00:13:59.522] iteration 1867 : loss : 0.147409, loss_ce: 0.046538
[00:13:59.809] iteration 1868 : loss : 0.107539, loss_ce: 0.048622
[00:14:00.098] iteration 1869 : loss : 0.285006, loss_ce: 0.039127
[00:14:00.386] iteration 1870 : loss : 0.194656, loss_ce: 0.050894
[00:14:00.676] iteration 1871 : loss : 0.120097, loss_ce: 0.027860
[00:14:00.969] iteration 1872 : loss : 0.189731, loss_ce: 0.065865
[00:14:01.255] iteration 1873 : loss : 0.149003, loss_ce: 0.046799
[00:14:01.546] iteration 1874 : loss : 0.224893, loss_ce: 0.056298
[00:14:01.831] iteration 1875 : loss : 0.130840, loss_ce: 0.058636
[00:14:02.118] iteration 1876 : loss : 0.180999, loss_ce: 0.055011
[00:14:02.410] iteration 1877 : loss : 0.317737, loss_ce: 0.018757
[00:14:02.698] iteration 1878 : loss : 0.162408, loss_ce: 0.034731
[00:14:02.985] iteration 1879 : loss : 0.144259, loss_ce: 0.025659
[00:14:03.272] iteration 1880 : loss : 0.163971, loss_ce: 0.039137
[00:14:03.576] iteration 1881 : loss : 0.095953, loss_ce: 0.029867
[00:14:03.864] iteration 1882 : loss : 0.101876, loss_ce: 0.027587
[00:14:04.152] iteration 1883 : loss : 0.140484, loss_ce: 0.039309
[00:14:04.441] iteration 1884 : loss : 0.116130, loss_ce: 0.019878
[00:14:04.734] iteration 1885 : loss : 0.129849, loss_ce: 0.041477
[00:14:05.023] iteration 1886 : loss : 0.147291, loss_ce: 0.058243
[00:14:05.311] iteration 1887 : loss : 0.172580, loss_ce: 0.041418
[00:14:05.598] iteration 1888 : loss : 0.148066, loss_ce: 0.040219
[00:14:05.888] iteration 1889 : loss : 0.153868, loss_ce: 0.044055
[00:14:06.178] iteration 1890 : loss : 0.167617, loss_ce: 0.069896
[00:14:06.469] iteration 1891 : loss : 0.204603, loss_ce: 0.040462
[00:14:06.755] iteration 1892 : loss : 0.114638, loss_ce: 0.035034
[00:14:07.041] iteration 1893 : loss : 0.223011, loss_ce: 0.053518
[00:14:07.330] iteration 1894 : loss : 0.202011, loss_ce: 0.030957
[00:14:07.617] iteration 1895 : loss : 0.092358, loss_ce: 0.027476
[00:14:07.906] iteration 1896 : loss : 0.152636, loss_ce: 0.032826
[00:14:08.193] iteration 1897 : loss : 0.161104, loss_ce: 0.054113
[00:14:08.481] iteration 1898 : loss : 0.182894, loss_ce: 0.019672
[00:14:08.771] iteration 1899 : loss : 0.228382, loss_ce: 0.028688
[00:14:09.059] iteration 1900 : loss : 0.118859, loss_ce: 0.032407
[00:14:09.367] iteration 1901 : loss : 0.125031, loss_ce: 0.041720
[00:14:09.655] iteration 1902 : loss : 0.126761, loss_ce: 0.048682
[00:14:09.945] iteration 1903 : loss : 0.115236, loss_ce: 0.036188
[00:14:10.234] iteration 1904 : loss : 0.210849, loss_ce: 0.016412
[00:14:10.522] iteration 1905 : loss : 0.135763, loss_ce: 0.045229
[00:14:10.810] iteration 1906 : loss : 0.155842, loss_ce: 0.052241
[00:14:11.098] iteration 1907 : loss : 0.112044, loss_ce: 0.042759
[00:14:11.385] iteration 1908 : loss : 0.177487, loss_ce: 0.030433
[00:14:11.673] iteration 1909 : loss : 0.138248, loss_ce: 0.062326
[00:14:11.963] iteration 1910 : loss : 0.228890, loss_ce: 0.019823
[00:14:12.252] iteration 1911 : loss : 0.128669, loss_ce: 0.029706
[00:14:12.538] iteration 1912 : loss : 0.191836, loss_ce: 0.033993
[00:14:12.828] iteration 1913 : loss : 0.123704, loss_ce: 0.061569
[00:14:13.115] iteration 1914 : loss : 0.123836, loss_ce: 0.042766
[00:14:13.405] iteration 1915 : loss : 0.199141, loss_ce: 0.014033
[00:14:13.691] iteration 1916 : loss : 0.098727, loss_ce: 0.043418
[00:14:13.979] iteration 1917 : loss : 0.115444, loss_ce: 0.036505
[00:14:14.267] iteration 1918 : loss : 0.102561, loss_ce: 0.031691
[00:14:14.553] iteration 1919 : loss : 0.131653, loss_ce: 0.040636
[00:14:14.842] iteration 1920 : loss : 0.219812, loss_ce: 0.046104
[00:14:15.149] iteration 1921 : loss : 0.300089, loss_ce: 0.009304
[00:14:15.436] iteration 1922 : loss : 0.183529, loss_ce: 0.055764
[00:14:15.724] iteration 1923 : loss : 0.129014, loss_ce: 0.045370
[00:14:16.014] iteration 1924 : loss : 0.151916, loss_ce: 0.039086
[00:14:16.304] iteration 1925 : loss : 0.197569, loss_ce: 0.039521
[00:14:16.594] iteration 1926 : loss : 0.156478, loss_ce: 0.045713
[00:14:16.882] iteration 1927 : loss : 0.122328, loss_ce: 0.038626
[00:14:17.169] iteration 1928 : loss : 0.243475, loss_ce: 0.019409
[00:14:17.455] iteration 1929 : loss : 0.138698, loss_ce: 0.071006
[00:14:17.751] iteration 1930 : loss : 0.108155, loss_ce: 0.027035
[00:14:18.044] iteration 1931 : loss : 0.169006, loss_ce: 0.042659
[00:14:18.338] iteration 1932 : loss : 0.397127, loss_ce: 0.015215
[00:14:18.630] iteration 1933 : loss : 0.121426, loss_ce: 0.034713
[00:14:18.923] iteration 1934 : loss : 0.164358, loss_ce: 0.050780
[00:14:19.212] iteration 1935 : loss : 0.139080, loss_ce: 0.024455
[00:14:19.506] iteration 1936 : loss : 0.147778, loss_ce: 0.024096
[00:14:19.795] iteration 1937 : loss : 0.121712, loss_ce: 0.052447
[00:14:20.088] iteration 1938 : loss : 0.132832, loss_ce: 0.031001
[00:14:20.382] iteration 1939 : loss : 0.172699, loss_ce: 0.037210
[00:14:20.675] iteration 1940 : loss : 0.201712, loss_ce: 0.059143
[00:14:20.992] iteration 1941 : loss : 0.177652, loss_ce: 0.028954
[00:14:21.292] iteration 1942 : loss : 0.098909, loss_ce: 0.037701
[00:14:21.580] iteration 1943 : loss : 0.245034, loss_ce: 0.020729
[00:14:21.874] iteration 1944 : loss : 0.160546, loss_ce: 0.032085
[00:14:22.170] iteration 1945 : loss : 0.115888, loss_ce: 0.032079
[00:14:22.248] iteration 1946 : loss : 0.527864, loss_ce: 0.000909
[00:14:38.630] iteration 1947 : loss : 0.112263, loss_ce: 0.035812
[00:14:38.920] iteration 1948 : loss : 0.211248, loss_ce: 0.041234
[00:14:39.204] iteration 1949 : loss : 0.125627, loss_ce: 0.039254
[00:14:39.491] iteration 1950 : loss : 0.165202, loss_ce: 0.014651
[00:14:39.778] iteration 1951 : loss : 0.164279, loss_ce: 0.027161
[00:14:40.071] iteration 1952 : loss : 0.201732, loss_ce: 0.059494
[00:14:40.359] iteration 1953 : loss : 0.100980, loss_ce: 0.031553
[00:14:40.645] iteration 1954 : loss : 0.136386, loss_ce: 0.035023
[00:14:40.937] iteration 1955 : loss : 0.142620, loss_ce: 0.056119
[00:14:41.223] iteration 1956 : loss : 0.159394, loss_ce: 0.063261
[00:14:41.509] iteration 1957 : loss : 0.131283, loss_ce: 0.034071
[00:14:41.799] iteration 1958 : loss : 0.193113, loss_ce: 0.031847
[00:14:42.086] iteration 1959 : loss : 0.137437, loss_ce: 0.040195
[00:14:42.375] iteration 1960 : loss : 0.228353, loss_ce: 0.031260
[00:14:42.676] iteration 1961 : loss : 0.118836, loss_ce: 0.028244
[00:14:42.962] iteration 1962 : loss : 0.124097, loss_ce: 0.015465
[00:14:43.249] iteration 1963 : loss : 0.118224, loss_ce: 0.027449
[00:14:43.539] iteration 1964 : loss : 0.126868, loss_ce: 0.046416
[00:14:43.825] iteration 1965 : loss : 0.142701, loss_ce: 0.021450
[00:14:44.115] iteration 1966 : loss : 0.152518, loss_ce: 0.015228
[00:14:44.401] iteration 1967 : loss : 0.162041, loss_ce: 0.064194
[00:14:44.691] iteration 1968 : loss : 0.165790, loss_ce: 0.029376
[00:14:44.978] iteration 1969 : loss : 0.175809, loss_ce: 0.032626
[00:14:45.264] iteration 1970 : loss : 0.199636, loss_ce: 0.027853
[00:14:45.557] iteration 1971 : loss : 0.158209, loss_ce: 0.023377
[00:14:45.845] iteration 1972 : loss : 0.160544, loss_ce: 0.037723
[00:14:46.134] iteration 1973 : loss : 0.147517, loss_ce: 0.066950
[00:14:46.423] iteration 1974 : loss : 0.162610, loss_ce: 0.034005
[00:14:46.709] iteration 1975 : loss : 0.108580, loss_ce: 0.021529
[00:14:46.997] iteration 1976 : loss : 0.149828, loss_ce: 0.052617
[00:14:47.285] iteration 1977 : loss : 0.228952, loss_ce: 0.034838
[00:14:47.577] iteration 1978 : loss : 0.190501, loss_ce: 0.031200
[00:14:47.864] iteration 1979 : loss : 0.146175, loss_ce: 0.043108
[00:14:48.149] iteration 1980 : loss : 0.194558, loss_ce: 0.038194
[00:14:48.452] iteration 1981 : loss : 0.116607, loss_ce: 0.034254
[00:14:48.741] iteration 1982 : loss : 0.205864, loss_ce: 0.042694
[00:14:49.029] iteration 1983 : loss : 0.123643, loss_ce: 0.036673
[00:14:49.317] iteration 1984 : loss : 0.162411, loss_ce: 0.058753
[00:14:49.604] iteration 1985 : loss : 0.129208, loss_ce: 0.033983
[00:14:49.890] iteration 1986 : loss : 0.157483, loss_ce: 0.041140
[00:14:50.179] iteration 1987 : loss : 0.169592, loss_ce: 0.047990
[00:14:50.472] iteration 1988 : loss : 0.140133, loss_ce: 0.052539
[00:14:50.761] iteration 1989 : loss : 0.126908, loss_ce: 0.030190
[00:14:51.048] iteration 1990 : loss : 0.124893, loss_ce: 0.044147
[00:14:51.339] iteration 1991 : loss : 0.151256, loss_ce: 0.052331
[00:14:51.630] iteration 1992 : loss : 0.140960, loss_ce: 0.053982
[00:14:51.921] iteration 1993 : loss : 0.139840, loss_ce: 0.023426
[00:14:52.210] iteration 1994 : loss : 0.140340, loss_ce: 0.025820
[00:14:52.500] iteration 1995 : loss : 0.133092, loss_ce: 0.041089
[00:14:52.789] iteration 1996 : loss : 0.180124, loss_ce: 0.019543
[00:14:53.080] iteration 1997 : loss : 0.136953, loss_ce: 0.049126
[00:14:53.368] iteration 1998 : loss : 0.140403, loss_ce: 0.035519
[00:14:53.660] iteration 1999 : loss : 0.212551, loss_ce: 0.037151
[00:14:53.948] iteration 2000 : loss : 0.173610, loss_ce: 0.029205
[00:14:54.255] iteration 2001 : loss : 0.126555, loss_ce: 0.042619
[00:14:54.543] iteration 2002 : loss : 0.125692, loss_ce: 0.047470
[00:14:54.829] iteration 2003 : loss : 0.146815, loss_ce: 0.055442
[00:14:55.122] iteration 2004 : loss : 0.168128, loss_ce: 0.050631
[00:14:55.410] iteration 2005 : loss : 0.182946, loss_ce: 0.018660
[00:14:55.700] iteration 2006 : loss : 0.134342, loss_ce: 0.045944
[00:14:55.988] iteration 2007 : loss : 0.144149, loss_ce: 0.048183
[00:14:56.276] iteration 2008 : loss : 0.207824, loss_ce: 0.029756
[00:14:56.564] iteration 2009 : loss : 0.156191, loss_ce: 0.032432
[00:14:56.852] iteration 2010 : loss : 0.142817, loss_ce: 0.032854
[00:14:57.142] iteration 2011 : loss : 0.127171, loss_ce: 0.036641
[00:14:57.431] iteration 2012 : loss : 0.229841, loss_ce: 0.013837
[00:14:57.722] iteration 2013 : loss : 0.180904, loss_ce: 0.028334
[00:14:58.011] iteration 2014 : loss : 0.182137, loss_ce: 0.029480
[00:14:58.300] iteration 2015 : loss : 0.151809, loss_ce: 0.047474
[00:14:58.587] iteration 2016 : loss : 0.138556, loss_ce: 0.038303
[00:14:58.878] iteration 2017 : loss : 0.178387, loss_ce: 0.043884
[00:14:59.167] iteration 2018 : loss : 0.186461, loss_ce: 0.065169
[00:14:59.458] iteration 2019 : loss : 0.182099, loss_ce: 0.051361
[00:14:59.749] iteration 2020 : loss : 0.112230, loss_ce: 0.033691
[00:15:00.055] iteration 2021 : loss : 0.212515, loss_ce: 0.019776
[00:15:00.344] iteration 2022 : loss : 0.131471, loss_ce: 0.034594
[00:15:00.637] iteration 2023 : loss : 0.122915, loss_ce: 0.022394
[00:15:00.929] iteration 2024 : loss : 0.147296, loss_ce: 0.047002
[00:15:01.218] iteration 2025 : loss : 0.144383, loss_ce: 0.046516
[00:15:01.508] iteration 2026 : loss : 0.151583, loss_ce: 0.032285
[00:15:01.797] iteration 2027 : loss : 0.158768, loss_ce: 0.027332
[00:15:02.086] iteration 2028 : loss : 0.114877, loss_ce: 0.027116
[00:15:02.375] iteration 2029 : loss : 0.112658, loss_ce: 0.032985
[00:15:02.668] iteration 2030 : loss : 0.144933, loss_ce: 0.034037
[00:15:02.955] iteration 2031 : loss : 0.162898, loss_ce: 0.033854
[00:15:03.245] iteration 2032 : loss : 0.124910, loss_ce: 0.051465
[00:15:03.534] iteration 2033 : loss : 0.167051, loss_ce: 0.059888
[00:15:03.822] iteration 2034 : loss : 0.097139, loss_ce: 0.018367
[00:15:04.107] iteration 2035 : loss : 0.212876, loss_ce: 0.024712
[00:15:04.398] iteration 2036 : loss : 0.142086, loss_ce: 0.033792
[00:15:04.687] iteration 2037 : loss : 0.200449, loss_ce: 0.020060
[00:15:04.974] iteration 2038 : loss : 0.163975, loss_ce: 0.030050
[00:15:05.267] iteration 2039 : loss : 0.119346, loss_ce: 0.038840
[00:15:05.555] iteration 2040 : loss : 0.105084, loss_ce: 0.042610
[00:15:05.862] iteration 2041 : loss : 0.141373, loss_ce: 0.031125
[00:15:06.153] iteration 2042 : loss : 0.129662, loss_ce: 0.061152
[00:15:06.440] iteration 2043 : loss : 0.126957, loss_ce: 0.052305
[00:15:06.730] iteration 2044 : loss : 0.139681, loss_ce: 0.044549
[00:15:07.020] iteration 2045 : loss : 0.186194, loss_ce: 0.016969
[00:15:07.310] iteration 2046 : loss : 0.119618, loss_ce: 0.021402
[00:15:07.598] iteration 2047 : loss : 0.169943, loss_ce: 0.019206
[00:15:07.891] iteration 2048 : loss : 0.148471, loss_ce: 0.042813
[00:15:08.179] iteration 2049 : loss : 0.216542, loss_ce: 0.021753
[00:15:08.467] iteration 2050 : loss : 0.141643, loss_ce: 0.037283
[00:15:08.756] iteration 2051 : loss : 0.133577, loss_ce: 0.039715
[00:15:09.043] iteration 2052 : loss : 0.131992, loss_ce: 0.041942
[00:15:09.330] iteration 2053 : loss : 0.213923, loss_ce: 0.036404
[00:15:09.619] iteration 2054 : loss : 0.120087, loss_ce: 0.019300
[00:15:09.906] iteration 2055 : loss : 0.159346, loss_ce: 0.056584
[00:15:10.200] iteration 2056 : loss : 0.158728, loss_ce: 0.027116
[00:15:10.492] iteration 2057 : loss : 0.098603, loss_ce: 0.035214
[00:15:10.783] iteration 2058 : loss : 0.141797, loss_ce: 0.041225
[00:15:11.074] iteration 2059 : loss : 0.188495, loss_ce: 0.047148
[00:15:11.364] iteration 2060 : loss : 0.121001, loss_ce: 0.068135
[00:15:11.670] iteration 2061 : loss : 0.145480, loss_ce: 0.047786
[00:15:11.961] iteration 2062 : loss : 0.143272, loss_ce: 0.044021
[00:15:12.249] iteration 2063 : loss : 0.140482, loss_ce: 0.039938
[00:15:12.537] iteration 2064 : loss : 0.115470, loss_ce: 0.058316
[00:15:12.827] iteration 2065 : loss : 0.187803, loss_ce: 0.026318
[00:15:13.117] iteration 2066 : loss : 0.192736, loss_ce: 0.039099
[00:15:13.406] iteration 2067 : loss : 0.175755, loss_ce: 0.045317
[00:15:13.696] iteration 2068 : loss : 0.125874, loss_ce: 0.037509
[00:15:13.988] iteration 2069 : loss : 0.136686, loss_ce: 0.017749
[00:15:14.280] iteration 2070 : loss : 0.138954, loss_ce: 0.034318
[00:15:14.571] iteration 2071 : loss : 0.175066, loss_ce: 0.039437
[00:15:14.863] iteration 2072 : loss : 0.161585, loss_ce: 0.050119
[00:15:15.156] iteration 2073 : loss : 0.161918, loss_ce: 0.013814
[00:15:15.451] iteration 2074 : loss : 0.101094, loss_ce: 0.037884
[00:15:15.742] iteration 2075 : loss : 0.161052, loss_ce: 0.023041
[00:15:16.036] iteration 2076 : loss : 0.204469, loss_ce: 0.028912
[00:15:16.330] iteration 2077 : loss : 0.140945, loss_ce: 0.035191
[00:15:16.623] iteration 2078 : loss : 0.136674, loss_ce: 0.043034
[00:15:16.915] iteration 2079 : loss : 0.143405, loss_ce: 0.028400
[00:15:17.207] iteration 2080 : loss : 0.163266, loss_ce: 0.027091
[00:15:17.520] iteration 2081 : loss : 0.160257, loss_ce: 0.060329
[00:15:17.812] iteration 2082 : loss : 0.311135, loss_ce: 0.017102
[00:15:18.107] iteration 2083 : loss : 0.128269, loss_ce: 0.038940
[00:15:18.401] iteration 2084 : loss : 0.157266, loss_ce: 0.037109
[00:15:18.495] iteration 2085 : loss : 0.164626, loss_ce: 0.059679
[00:15:35.219] iteration 2086 : loss : 0.123286, loss_ce: 0.034443
[00:15:35.506] iteration 2087 : loss : 0.145363, loss_ce: 0.035012
[00:15:35.790] iteration 2088 : loss : 0.106239, loss_ce: 0.025197
[00:15:36.077] iteration 2089 : loss : 0.139610, loss_ce: 0.068145
[00:15:36.367] iteration 2090 : loss : 0.180194, loss_ce: 0.026668
[00:15:36.653] iteration 2091 : loss : 0.121727, loss_ce: 0.047414
[00:15:36.939] iteration 2092 : loss : 0.149115, loss_ce: 0.032678
[00:15:37.225] iteration 2093 : loss : 0.154297, loss_ce: 0.034924
[00:15:37.510] iteration 2094 : loss : 0.154888, loss_ce: 0.016824
[00:15:37.796] iteration 2095 : loss : 0.162872, loss_ce: 0.043950
[00:15:38.083] iteration 2096 : loss : 0.159659, loss_ce: 0.027483
[00:15:38.372] iteration 2097 : loss : 0.291799, loss_ce: 0.011256
[00:15:38.658] iteration 2098 : loss : 0.108563, loss_ce: 0.019237
[00:15:38.942] iteration 2099 : loss : 0.108655, loss_ce: 0.031198
[00:15:39.230] iteration 2100 : loss : 0.188000, loss_ce: 0.039078
[00:15:39.530] iteration 2101 : loss : 0.146179, loss_ce: 0.044252
[00:15:39.814] iteration 2102 : loss : 0.133396, loss_ce: 0.026865
[00:15:40.099] iteration 2103 : loss : 0.180717, loss_ce: 0.021150
[00:15:40.389] iteration 2104 : loss : 0.182935, loss_ce: 0.045174
[00:15:40.673] iteration 2105 : loss : 0.169271, loss_ce: 0.019460
[00:15:40.960] iteration 2106 : loss : 0.146131, loss_ce: 0.039529
[00:15:41.248] iteration 2107 : loss : 0.172187, loss_ce: 0.035504
[00:15:41.534] iteration 2108 : loss : 0.102300, loss_ce: 0.028971
[00:15:41.823] iteration 2109 : loss : 0.309537, loss_ce: 0.027680
[00:15:42.112] iteration 2110 : loss : 0.114338, loss_ce: 0.046279
[00:15:42.402] iteration 2111 : loss : 0.114693, loss_ce: 0.052465
[00:15:42.689] iteration 2112 : loss : 0.130183, loss_ce: 0.037206
[00:15:42.977] iteration 2113 : loss : 0.123157, loss_ce: 0.036654
[00:15:43.265] iteration 2114 : loss : 0.144659, loss_ce: 0.037625
[00:15:43.553] iteration 2115 : loss : 0.118713, loss_ce: 0.047350
[00:15:43.841] iteration 2116 : loss : 0.116383, loss_ce: 0.048276
[00:15:44.129] iteration 2117 : loss : 0.211471, loss_ce: 0.020463
[00:15:44.419] iteration 2118 : loss : 0.118651, loss_ce: 0.042363
[00:15:44.704] iteration 2119 : loss : 0.171545, loss_ce: 0.021810
[00:15:44.994] iteration 2120 : loss : 0.138994, loss_ce: 0.044415
[00:15:45.298] iteration 2121 : loss : 0.211477, loss_ce: 0.078890
[00:15:45.584] iteration 2122 : loss : 0.160549, loss_ce: 0.018028
[00:15:45.875] iteration 2123 : loss : 0.138728, loss_ce: 0.035500
[00:15:46.163] iteration 2124 : loss : 0.127822, loss_ce: 0.036125
[00:15:46.451] iteration 2125 : loss : 0.186949, loss_ce: 0.043626
[00:15:46.739] iteration 2126 : loss : 0.167999, loss_ce: 0.054468
[00:15:47.026] iteration 2127 : loss : 0.134503, loss_ce: 0.042770
[00:15:47.316] iteration 2128 : loss : 0.167598, loss_ce: 0.042738
[00:15:47.603] iteration 2129 : loss : 0.176899, loss_ce: 0.019634
[00:15:47.893] iteration 2130 : loss : 0.144750, loss_ce: 0.026898
[00:15:48.184] iteration 2131 : loss : 0.102885, loss_ce: 0.033302
[00:15:48.472] iteration 2132 : loss : 0.115948, loss_ce: 0.034193
[00:15:48.759] iteration 2133 : loss : 0.172340, loss_ce: 0.024312
[00:15:49.046] iteration 2134 : loss : 0.120879, loss_ce: 0.028984
[00:15:49.337] iteration 2135 : loss : 0.162971, loss_ce: 0.028863
[00:15:49.623] iteration 2136 : loss : 0.159097, loss_ce: 0.018019
[00:15:49.909] iteration 2137 : loss : 0.219336, loss_ce: 0.031833
[00:15:50.199] iteration 2138 : loss : 0.150298, loss_ce: 0.038417
[00:15:50.489] iteration 2139 : loss : 0.164187, loss_ce: 0.029249
[00:15:50.780] iteration 2140 : loss : 0.136318, loss_ce: 0.043053
[00:15:51.080] iteration 2141 : loss : 0.187083, loss_ce: 0.028759
[00:15:51.367] iteration 2142 : loss : 0.141615, loss_ce: 0.057292
[00:15:51.654] iteration 2143 : loss : 0.181407, loss_ce: 0.040570
[00:15:51.942] iteration 2144 : loss : 0.206243, loss_ce: 0.037011
[00:15:52.228] iteration 2145 : loss : 0.126110, loss_ce: 0.041379
[00:15:52.517] iteration 2146 : loss : 0.152764, loss_ce: 0.038566
[00:15:52.805] iteration 2147 : loss : 0.117867, loss_ce: 0.034969
[00:15:53.092] iteration 2148 : loss : 0.111904, loss_ce: 0.029661
[00:15:53.379] iteration 2149 : loss : 0.091241, loss_ce: 0.046154
[00:15:53.664] iteration 2150 : loss : 0.151222, loss_ce: 0.032672
[00:15:53.950] iteration 2151 : loss : 0.144153, loss_ce: 0.044323
[00:15:54.240] iteration 2152 : loss : 0.167056, loss_ce: 0.031899
[00:15:54.528] iteration 2153 : loss : 0.192314, loss_ce: 0.057868
[00:15:54.814] iteration 2154 : loss : 0.114872, loss_ce: 0.024619
[00:15:55.101] iteration 2155 : loss : 0.147347, loss_ce: 0.062789
[00:15:55.388] iteration 2156 : loss : 0.121379, loss_ce: 0.031082
[00:15:55.674] iteration 2157 : loss : 0.134362, loss_ce: 0.049798
[00:15:55.961] iteration 2158 : loss : 0.098828, loss_ce: 0.033600
[00:15:56.251] iteration 2159 : loss : 0.122246, loss_ce: 0.039307
[00:15:56.538] iteration 2160 : loss : 0.221722, loss_ce: 0.021795
[00:15:56.844] iteration 2161 : loss : 0.161095, loss_ce: 0.021132
[00:15:57.132] iteration 2162 : loss : 0.094092, loss_ce: 0.043084
[00:15:57.419] iteration 2163 : loss : 0.175332, loss_ce: 0.013267
[00:15:57.709] iteration 2164 : loss : 0.141065, loss_ce: 0.038125
[00:15:57.998] iteration 2165 : loss : 0.168457, loss_ce: 0.031635
[00:15:58.284] iteration 2166 : loss : 0.153931, loss_ce: 0.029514
[00:15:58.572] iteration 2167 : loss : 0.138714, loss_ce: 0.054034
[00:15:58.859] iteration 2168 : loss : 0.121068, loss_ce: 0.035287
[00:15:59.144] iteration 2169 : loss : 0.134800, loss_ce: 0.030601
[00:15:59.433] iteration 2170 : loss : 0.135337, loss_ce: 0.038983
[00:15:59.720] iteration 2171 : loss : 0.121429, loss_ce: 0.020976
[00:16:00.008] iteration 2172 : loss : 0.143571, loss_ce: 0.041358
[00:16:00.298] iteration 2173 : loss : 0.191733, loss_ce: 0.041822
[00:16:00.586] iteration 2174 : loss : 0.121985, loss_ce: 0.027532
[00:16:00.876] iteration 2175 : loss : 0.139326, loss_ce: 0.049390
[00:16:01.165] iteration 2176 : loss : 0.181789, loss_ce: 0.026888
[00:16:01.452] iteration 2177 : loss : 0.171630, loss_ce: 0.034623
[00:16:01.739] iteration 2178 : loss : 0.171837, loss_ce: 0.018726
[00:16:02.028] iteration 2179 : loss : 0.180258, loss_ce: 0.041685
[00:16:02.316] iteration 2180 : loss : 0.166882, loss_ce: 0.048198
[00:16:02.619] iteration 2181 : loss : 0.142332, loss_ce: 0.048130
[00:16:02.904] iteration 2182 : loss : 0.166253, loss_ce: 0.059640
[00:16:03.189] iteration 2183 : loss : 0.133517, loss_ce: 0.037679
[00:16:03.476] iteration 2184 : loss : 0.115210, loss_ce: 0.047362
[00:16:03.762] iteration 2185 : loss : 0.161867, loss_ce: 0.045519
[00:16:04.048] iteration 2186 : loss : 0.134831, loss_ce: 0.039433
[00:16:04.336] iteration 2187 : loss : 0.163551, loss_ce: 0.033897
[00:16:04.623] iteration 2188 : loss : 0.197311, loss_ce: 0.038302
[00:16:04.909] iteration 2189 : loss : 0.123451, loss_ce: 0.039669
[00:16:05.198] iteration 2190 : loss : 0.105090, loss_ce: 0.031917
[00:16:05.486] iteration 2191 : loss : 0.222746, loss_ce: 0.020150
[00:16:05.773] iteration 2192 : loss : 0.263993, loss_ce: 0.031954
[00:16:06.062] iteration 2193 : loss : 0.157912, loss_ce: 0.054706
[00:16:06.350] iteration 2194 : loss : 0.169204, loss_ce: 0.023955
[00:16:06.636] iteration 2195 : loss : 0.167633, loss_ce: 0.056756
[00:16:06.924] iteration 2196 : loss : 0.277213, loss_ce: 0.032819
[00:16:07.213] iteration 2197 : loss : 0.133372, loss_ce: 0.029613
[00:16:07.499] iteration 2198 : loss : 0.143130, loss_ce: 0.057162
[00:16:07.787] iteration 2199 : loss : 0.193084, loss_ce: 0.026927
[00:16:08.073] iteration 2200 : loss : 0.134485, loss_ce: 0.041492
[00:16:08.377] iteration 2201 : loss : 0.110082, loss_ce: 0.035259
[00:16:08.664] iteration 2202 : loss : 0.148308, loss_ce: 0.033874
[00:16:08.951] iteration 2203 : loss : 0.160807, loss_ce: 0.043463
[00:16:09.240] iteration 2204 : loss : 0.156154, loss_ce: 0.092201
[00:16:09.528] iteration 2205 : loss : 0.227784, loss_ce: 0.037048
[00:16:09.814] iteration 2206 : loss : 0.119743, loss_ce: 0.043525
[00:16:10.102] iteration 2207 : loss : 0.098004, loss_ce: 0.041188
[00:16:10.394] iteration 2208 : loss : 0.144563, loss_ce: 0.051973
[00:16:10.685] iteration 2209 : loss : 0.096263, loss_ce: 0.020402
[00:16:10.976] iteration 2210 : loss : 0.149821, loss_ce: 0.022945
[00:16:11.269] iteration 2211 : loss : 0.162461, loss_ce: 0.052057
[00:16:11.557] iteration 2212 : loss : 0.267985, loss_ce: 0.009994
[00:16:11.847] iteration 2213 : loss : 0.298850, loss_ce: 0.024984
[00:16:12.141] iteration 2214 : loss : 0.150302, loss_ce: 0.044506
[00:16:12.429] iteration 2215 : loss : 0.134543, loss_ce: 0.047688
[00:16:12.722] iteration 2216 : loss : 0.119251, loss_ce: 0.041676
[00:16:13.016] iteration 2217 : loss : 0.155680, loss_ce: 0.033965
[00:16:13.304] iteration 2218 : loss : 0.210982, loss_ce: 0.021778
[00:16:13.596] iteration 2219 : loss : 0.195715, loss_ce: 0.040489
[00:16:13.889] iteration 2220 : loss : 0.236590, loss_ce: 0.023428
[00:16:14.195] iteration 2221 : loss : 0.119240, loss_ce: 0.040306
[00:16:14.485] iteration 2222 : loss : 0.155479, loss_ce: 0.050336
[00:16:14.775] iteration 2223 : loss : 0.121633, loss_ce: 0.047898
[00:16:14.852] iteration 2224 : loss : 0.145733, loss_ce: 0.027515
[00:16:15.421] save model to ./logs/swin_unet\epoch_15.pth
[00:16:31.487] iteration 2225 : loss : 0.106905, loss_ce: 0.029494
[00:16:31.773] iteration 2226 : loss : 0.136241, loss_ce: 0.029084
[00:16:32.057] iteration 2227 : loss : 0.123783, loss_ce: 0.038157
[00:16:32.345] iteration 2228 : loss : 0.123007, loss_ce: 0.025968
[00:16:32.632] iteration 2229 : loss : 0.107634, loss_ce: 0.028311
[00:16:32.920] iteration 2230 : loss : 0.173577, loss_ce: 0.041964
[00:16:33.207] iteration 2231 : loss : 0.106024, loss_ce: 0.042877
[00:16:33.493] iteration 2232 : loss : 0.165030, loss_ce: 0.045919
[00:16:33.780] iteration 2233 : loss : 0.172018, loss_ce: 0.025076
[00:16:34.066] iteration 2234 : loss : 0.180731, loss_ce: 0.039062
[00:16:34.352] iteration 2235 : loss : 0.186462, loss_ce: 0.036464
[00:16:34.637] iteration 2236 : loss : 0.309350, loss_ce: 0.015759
[00:16:34.925] iteration 2237 : loss : 0.187578, loss_ce: 0.023182
[00:16:35.214] iteration 2238 : loss : 0.099873, loss_ce: 0.030138
[00:16:35.499] iteration 2239 : loss : 0.144665, loss_ce: 0.023722
[00:16:35.785] iteration 2240 : loss : 0.125312, loss_ce: 0.051017
[00:16:36.086] iteration 2241 : loss : 0.140897, loss_ce: 0.038964
[00:16:36.373] iteration 2242 : loss : 0.137198, loss_ce: 0.056410
[00:16:36.659] iteration 2243 : loss : 0.150233, loss_ce: 0.038860
[00:16:36.948] iteration 2244 : loss : 0.091424, loss_ce: 0.042694
[00:16:37.233] iteration 2245 : loss : 0.211203, loss_ce: 0.028730
[00:16:37.520] iteration 2246 : loss : 0.139203, loss_ce: 0.044642
[00:16:37.806] iteration 2247 : loss : 0.215759, loss_ce: 0.017890
[00:16:38.093] iteration 2248 : loss : 0.169121, loss_ce: 0.046522
[00:16:38.379] iteration 2249 : loss : 0.117586, loss_ce: 0.039363
[00:16:38.668] iteration 2250 : loss : 0.199898, loss_ce: 0.029576
[00:16:38.953] iteration 2251 : loss : 0.130845, loss_ce: 0.041730
[00:16:39.241] iteration 2252 : loss : 0.134251, loss_ce: 0.036873
[00:16:39.530] iteration 2253 : loss : 0.129192, loss_ce: 0.043862
[00:16:39.817] iteration 2254 : loss : 0.172012, loss_ce: 0.062771
[00:16:40.104] iteration 2255 : loss : 0.172025, loss_ce: 0.027922
[00:16:40.390] iteration 2256 : loss : 0.114181, loss_ce: 0.038273
[00:16:40.679] iteration 2257 : loss : 0.139240, loss_ce: 0.045740
[00:16:40.965] iteration 2258 : loss : 0.200309, loss_ce: 0.019311
[00:16:41.252] iteration 2259 : loss : 0.093397, loss_ce: 0.030589
[00:16:41.539] iteration 2260 : loss : 0.153329, loss_ce: 0.035115
[00:16:41.844] iteration 2261 : loss : 0.123099, loss_ce: 0.035789
[00:16:42.131] iteration 2262 : loss : 0.115570, loss_ce: 0.029615
[00:16:42.416] iteration 2263 : loss : 0.202004, loss_ce: 0.036038
[00:16:42.704] iteration 2264 : loss : 0.176234, loss_ce: 0.018731
[00:16:42.995] iteration 2265 : loss : 0.119572, loss_ce: 0.042489
[00:16:43.280] iteration 2266 : loss : 0.117409, loss_ce: 0.027256
[00:16:43.566] iteration 2267 : loss : 0.178495, loss_ce: 0.041476
[00:16:43.853] iteration 2268 : loss : 0.145627, loss_ce: 0.030568
[00:16:44.139] iteration 2269 : loss : 0.161411, loss_ce: 0.030027
[00:16:44.426] iteration 2270 : loss : 0.166090, loss_ce: 0.022829
[00:16:44.712] iteration 2271 : loss : 0.176389, loss_ce: 0.037180
[00:16:45.000] iteration 2272 : loss : 0.102944, loss_ce: 0.036276
[00:16:45.290] iteration 2273 : loss : 0.097269, loss_ce: 0.027980
[00:16:45.578] iteration 2274 : loss : 0.154123, loss_ce: 0.023144
[00:16:45.865] iteration 2275 : loss : 0.094558, loss_ce: 0.024245
[00:16:46.150] iteration 2276 : loss : 0.150132, loss_ce: 0.047853
[00:16:46.440] iteration 2277 : loss : 0.154567, loss_ce: 0.050425
[00:16:46.729] iteration 2278 : loss : 0.123187, loss_ce: 0.060329
[00:16:47.016] iteration 2279 : loss : 0.121757, loss_ce: 0.026810
[00:16:47.304] iteration 2280 : loss : 0.122503, loss_ce: 0.043078
[00:16:47.605] iteration 2281 : loss : 0.114816, loss_ce: 0.048887
[00:16:47.893] iteration 2282 : loss : 0.135224, loss_ce: 0.019184
[00:16:48.179] iteration 2283 : loss : 0.100702, loss_ce: 0.029614
[00:16:48.467] iteration 2284 : loss : 0.122243, loss_ce: 0.030184
[00:16:48.756] iteration 2285 : loss : 0.122330, loss_ce: 0.025473
[00:16:49.041] iteration 2286 : loss : 0.243936, loss_ce: 0.038014
[00:16:49.329] iteration 2287 : loss : 0.150456, loss_ce: 0.035397
[00:16:49.616] iteration 2288 : loss : 0.181033, loss_ce: 0.026819
[00:16:49.905] iteration 2289 : loss : 0.114875, loss_ce: 0.032807
[00:16:50.197] iteration 2290 : loss : 0.119131, loss_ce: 0.040039
[00:16:50.485] iteration 2291 : loss : 0.160830, loss_ce: 0.033793
[00:16:50.776] iteration 2292 : loss : 0.211440, loss_ce: 0.021331
[00:16:51.062] iteration 2293 : loss : 0.166746, loss_ce: 0.024667
[00:16:51.352] iteration 2294 : loss : 0.110566, loss_ce: 0.034157
[00:16:51.642] iteration 2295 : loss : 0.163054, loss_ce: 0.050115
[00:16:51.934] iteration 2296 : loss : 0.123864, loss_ce: 0.037346
[00:16:52.223] iteration 2297 : loss : 0.119060, loss_ce: 0.030498
[00:16:52.513] iteration 2298 : loss : 0.197646, loss_ce: 0.022019
[00:16:52.802] iteration 2299 : loss : 0.088611, loss_ce: 0.024441
[00:16:53.093] iteration 2300 : loss : 0.119961, loss_ce: 0.040129
[00:16:53.399] iteration 2301 : loss : 0.122334, loss_ce: 0.045817
[00:16:53.690] iteration 2302 : loss : 0.074057, loss_ce: 0.015960
[00:16:53.981] iteration 2303 : loss : 0.167031, loss_ce: 0.025506
[00:16:54.271] iteration 2304 : loss : 0.100763, loss_ce: 0.021939
[00:16:54.562] iteration 2305 : loss : 0.119064, loss_ce: 0.040944
[00:16:54.851] iteration 2306 : loss : 0.108665, loss_ce: 0.036874
[00:16:55.142] iteration 2307 : loss : 0.157798, loss_ce: 0.070832
[00:16:55.434] iteration 2308 : loss : 0.158384, loss_ce: 0.030190
[00:16:55.722] iteration 2309 : loss : 0.111981, loss_ce: 0.028373
[00:16:56.014] iteration 2310 : loss : 0.155810, loss_ce: 0.026242
[00:16:56.304] iteration 2311 : loss : 0.214626, loss_ce: 0.019996
[00:16:56.590] iteration 2312 : loss : 0.148169, loss_ce: 0.021377
[00:16:56.881] iteration 2313 : loss : 0.304472, loss_ce: 0.020274
[00:16:57.168] iteration 2314 : loss : 0.077306, loss_ce: 0.018576
[00:16:57.458] iteration 2315 : loss : 0.150436, loss_ce: 0.011075
[00:16:57.747] iteration 2316 : loss : 0.130888, loss_ce: 0.032956
[00:16:58.035] iteration 2317 : loss : 0.082995, loss_ce: 0.025534
[00:16:58.327] iteration 2318 : loss : 0.170666, loss_ce: 0.028422
[00:16:58.615] iteration 2319 : loss : 0.196605, loss_ce: 0.036956
[00:16:58.906] iteration 2320 : loss : 0.119867, loss_ce: 0.038480
[00:16:59.207] iteration 2321 : loss : 0.215807, loss_ce: 0.032923
[00:16:59.498] iteration 2322 : loss : 0.134347, loss_ce: 0.052581
[00:16:59.791] iteration 2323 : loss : 0.218301, loss_ce: 0.014868
[00:17:00.083] iteration 2324 : loss : 0.167172, loss_ce: 0.021406
[00:17:00.376] iteration 2325 : loss : 0.074874, loss_ce: 0.030369
[00:17:00.667] iteration 2326 : loss : 0.110060, loss_ce: 0.043341
[00:17:00.956] iteration 2327 : loss : 0.151283, loss_ce: 0.023654
[00:17:01.247] iteration 2328 : loss : 0.194841, loss_ce: 0.039413
[00:17:01.534] iteration 2329 : loss : 0.139881, loss_ce: 0.056575
[00:17:01.821] iteration 2330 : loss : 0.105089, loss_ce: 0.042047
[00:17:02.112] iteration 2331 : loss : 0.095939, loss_ce: 0.026988
[00:17:02.404] iteration 2332 : loss : 0.124046, loss_ce: 0.031772
[00:17:02.694] iteration 2333 : loss : 0.129184, loss_ce: 0.046039
[00:17:02.984] iteration 2334 : loss : 0.164292, loss_ce: 0.049118
[00:17:03.275] iteration 2335 : loss : 0.097997, loss_ce: 0.037075
[00:17:03.563] iteration 2336 : loss : 0.099328, loss_ce: 0.034116
[00:17:03.855] iteration 2337 : loss : 0.178640, loss_ce: 0.039229
[00:17:04.147] iteration 2338 : loss : 0.155569, loss_ce: 0.019497
[00:17:04.438] iteration 2339 : loss : 0.111855, loss_ce: 0.020951
[00:17:04.728] iteration 2340 : loss : 0.094497, loss_ce: 0.026416
[00:17:05.033] iteration 2341 : loss : 0.133088, loss_ce: 0.016516
[00:17:05.327] iteration 2342 : loss : 0.127736, loss_ce: 0.045456
[00:17:05.620] iteration 2343 : loss : 0.118282, loss_ce: 0.043998
[00:17:05.911] iteration 2344 : loss : 0.126300, loss_ce: 0.044693
[00:17:06.199] iteration 2345 : loss : 0.110642, loss_ce: 0.039742
[00:17:06.488] iteration 2346 : loss : 0.125866, loss_ce: 0.048300
[00:17:06.786] iteration 2347 : loss : 0.171128, loss_ce: 0.046291
[00:17:07.079] iteration 2348 : loss : 0.141595, loss_ce: 0.034364
[00:17:07.374] iteration 2349 : loss : 0.098638, loss_ce: 0.024027
[00:17:07.666] iteration 2350 : loss : 0.118379, loss_ce: 0.044509
[00:17:07.960] iteration 2351 : loss : 0.351055, loss_ce: 0.010008
[00:17:08.252] iteration 2352 : loss : 0.095004, loss_ce: 0.036650
[00:17:08.545] iteration 2353 : loss : 0.206577, loss_ce: 0.025067
[00:17:08.843] iteration 2354 : loss : 0.137773, loss_ce: 0.033110
[00:17:09.136] iteration 2355 : loss : 0.119266, loss_ce: 0.020169
[00:17:09.425] iteration 2356 : loss : 0.123241, loss_ce: 0.026157
[00:17:09.721] iteration 2357 : loss : 0.141639, loss_ce: 0.051065
[00:17:10.016] iteration 2358 : loss : 0.144797, loss_ce: 0.054314
[00:17:10.315] iteration 2359 : loss : 0.104697, loss_ce: 0.043779
[00:17:10.606] iteration 2360 : loss : 0.169267, loss_ce: 0.054573
[00:17:10.927] iteration 2361 : loss : 0.111881, loss_ce: 0.040958
[00:17:11.216] iteration 2362 : loss : 0.110065, loss_ce: 0.033308
[00:17:11.309] iteration 2363 : loss : 0.234817, loss_ce: 0.086953
[00:17:28.088] iteration 2364 : loss : 0.101708, loss_ce: 0.032505
[00:17:28.373] iteration 2365 : loss : 0.104290, loss_ce: 0.051977
[00:17:28.659] iteration 2366 : loss : 0.245552, loss_ce: 0.021660
[00:17:28.946] iteration 2367 : loss : 0.100809, loss_ce: 0.036040
[00:17:29.233] iteration 2368 : loss : 0.114030, loss_ce: 0.028948
[00:17:29.518] iteration 2369 : loss : 0.121108, loss_ce: 0.030502
[00:17:29.803] iteration 2370 : loss : 0.184520, loss_ce: 0.028609
[00:17:30.092] iteration 2371 : loss : 0.136327, loss_ce: 0.047118
[00:17:30.378] iteration 2372 : loss : 0.122510, loss_ce: 0.033642
[00:17:30.664] iteration 2373 : loss : 0.134712, loss_ce: 0.033786
[00:17:30.950] iteration 2374 : loss : 0.165288, loss_ce: 0.024562
[00:17:31.236] iteration 2375 : loss : 0.185523, loss_ce: 0.025999
[00:17:31.524] iteration 2376 : loss : 0.156923, loss_ce: 0.033469
[00:17:31.810] iteration 2377 : loss : 0.138603, loss_ce: 0.029043
[00:17:32.099] iteration 2378 : loss : 0.124023, loss_ce: 0.022146
[00:17:32.384] iteration 2379 : loss : 0.171129, loss_ce: 0.039790
[00:17:32.675] iteration 2380 : loss : 0.115908, loss_ce: 0.048143
[00:17:32.982] iteration 2381 : loss : 0.125208, loss_ce: 0.039897
[00:17:33.268] iteration 2382 : loss : 0.130823, loss_ce: 0.032073
[00:17:33.552] iteration 2383 : loss : 0.165589, loss_ce: 0.022849
[00:17:33.843] iteration 2384 : loss : 0.150020, loss_ce: 0.018835
[00:17:34.129] iteration 2385 : loss : 0.112016, loss_ce: 0.037122
[00:17:34.415] iteration 2386 : loss : 0.100714, loss_ce: 0.031222
[00:17:34.702] iteration 2387 : loss : 0.116984, loss_ce: 0.034763
[00:17:34.990] iteration 2388 : loss : 0.086148, loss_ce: 0.027818
[00:17:35.278] iteration 2389 : loss : 0.104692, loss_ce: 0.041226
[00:17:35.567] iteration 2390 : loss : 0.145260, loss_ce: 0.022000
[00:17:35.854] iteration 2391 : loss : 0.106560, loss_ce: 0.033689
[00:17:36.140] iteration 2392 : loss : 0.123887, loss_ce: 0.036452
[00:17:36.427] iteration 2393 : loss : 0.133193, loss_ce: 0.063565
[00:17:36.716] iteration 2394 : loss : 0.121116, loss_ce: 0.022559
[00:17:37.003] iteration 2395 : loss : 0.119292, loss_ce: 0.047128
[00:17:37.288] iteration 2396 : loss : 0.115818, loss_ce: 0.050696
[00:17:37.577] iteration 2397 : loss : 0.112087, loss_ce: 0.021728
[00:17:37.865] iteration 2398 : loss : 0.143240, loss_ce: 0.026691
[00:17:38.153] iteration 2399 : loss : 0.149370, loss_ce: 0.032940
[00:17:38.442] iteration 2400 : loss : 0.166533, loss_ce: 0.050290
[00:17:38.743] iteration 2401 : loss : 0.217174, loss_ce: 0.033275
[00:17:39.029] iteration 2402 : loss : 0.209313, loss_ce: 0.022862
[00:17:39.316] iteration 2403 : loss : 0.124279, loss_ce: 0.036247
[00:17:39.605] iteration 2404 : loss : 0.169615, loss_ce: 0.027439
[00:17:39.892] iteration 2405 : loss : 0.123102, loss_ce: 0.031564
[00:17:40.185] iteration 2406 : loss : 0.390218, loss_ce: 0.006859
[00:17:40.472] iteration 2407 : loss : 0.141116, loss_ce: 0.030480
[00:17:40.759] iteration 2408 : loss : 0.109882, loss_ce: 0.031693
[00:17:41.046] iteration 2409 : loss : 0.107380, loss_ce: 0.040587
[00:17:41.334] iteration 2410 : loss : 0.135221, loss_ce: 0.029090
[00:17:41.620] iteration 2411 : loss : 0.096981, loss_ce: 0.026902
[00:17:41.911] iteration 2412 : loss : 0.108870, loss_ce: 0.030854
[00:17:42.198] iteration 2413 : loss : 0.158949, loss_ce: 0.036187
[00:17:42.489] iteration 2414 : loss : 0.104371, loss_ce: 0.020634
[00:17:42.777] iteration 2415 : loss : 0.133929, loss_ce: 0.039972
[00:17:43.065] iteration 2416 : loss : 0.245105, loss_ce: 0.026931
[00:17:43.353] iteration 2417 : loss : 0.106435, loss_ce: 0.035790
[00:17:43.640] iteration 2418 : loss : 0.114904, loss_ce: 0.020231
[00:17:43.927] iteration 2419 : loss : 0.123354, loss_ce: 0.058138
[00:17:44.213] iteration 2420 : loss : 0.145810, loss_ce: 0.026552
[00:17:44.521] iteration 2421 : loss : 0.163046, loss_ce: 0.028420
[00:17:44.808] iteration 2422 : loss : 0.128512, loss_ce: 0.033294
[00:17:45.097] iteration 2423 : loss : 0.184171, loss_ce: 0.029810
[00:17:45.387] iteration 2424 : loss : 0.109093, loss_ce: 0.029799
[00:17:45.679] iteration 2425 : loss : 0.104791, loss_ce: 0.035642
[00:17:45.968] iteration 2426 : loss : 0.145356, loss_ce: 0.034979
[00:17:46.260] iteration 2427 : loss : 0.158388, loss_ce: 0.026567
[00:17:46.548] iteration 2428 : loss : 0.152791, loss_ce: 0.042343
[00:17:46.834] iteration 2429 : loss : 0.232878, loss_ce: 0.017420
[00:17:47.120] iteration 2430 : loss : 0.148184, loss_ce: 0.028131
[00:17:47.406] iteration 2431 : loss : 0.092704, loss_ce: 0.030518
[00:17:47.699] iteration 2432 : loss : 0.096169, loss_ce: 0.037785
[00:17:47.985] iteration 2433 : loss : 0.115950, loss_ce: 0.044257
[00:17:48.273] iteration 2434 : loss : 0.113774, loss_ce: 0.045510
[00:17:48.561] iteration 2435 : loss : 0.124966, loss_ce: 0.019738
[00:17:48.851] iteration 2436 : loss : 0.117003, loss_ce: 0.032461
[00:17:49.138] iteration 2437 : loss : 0.109022, loss_ce: 0.029741
[00:17:49.423] iteration 2438 : loss : 0.166530, loss_ce: 0.026008
[00:17:49.712] iteration 2439 : loss : 0.136933, loss_ce: 0.020342
[00:17:49.999] iteration 2440 : loss : 0.185904, loss_ce: 0.021464
[00:17:50.301] iteration 2441 : loss : 0.176512, loss_ce: 0.036545
[00:17:50.587] iteration 2442 : loss : 0.103084, loss_ce: 0.028484
[00:17:50.875] iteration 2443 : loss : 0.137696, loss_ce: 0.041984
[00:17:51.165] iteration 2444 : loss : 0.137372, loss_ce: 0.039682
[00:17:51.454] iteration 2445 : loss : 0.113727, loss_ce: 0.038156
[00:17:51.741] iteration 2446 : loss : 0.101599, loss_ce: 0.027286
[00:17:52.031] iteration 2447 : loss : 0.103066, loss_ce: 0.035484
[00:17:52.322] iteration 2448 : loss : 0.090979, loss_ce: 0.013316
[00:17:52.607] iteration 2449 : loss : 0.105985, loss_ce: 0.046855
[00:17:52.894] iteration 2450 : loss : 0.080602, loss_ce: 0.029885
[00:17:53.182] iteration 2451 : loss : 0.120268, loss_ce: 0.041551
[00:17:53.470] iteration 2452 : loss : 0.094157, loss_ce: 0.022604
[00:17:53.760] iteration 2453 : loss : 0.139653, loss_ce: 0.041181
[00:17:54.049] iteration 2454 : loss : 0.193688, loss_ce: 0.055427
[00:17:54.336] iteration 2455 : loss : 0.136421, loss_ce: 0.022279
[00:17:54.627] iteration 2456 : loss : 0.115222, loss_ce: 0.027562
[00:17:54.914] iteration 2457 : loss : 0.160536, loss_ce: 0.030207
[00:17:55.202] iteration 2458 : loss : 0.102848, loss_ce: 0.033001
[00:17:55.489] iteration 2459 : loss : 0.234091, loss_ce: 0.014112
[00:17:55.778] iteration 2460 : loss : 0.163173, loss_ce: 0.030263
[00:17:56.082] iteration 2461 : loss : 0.073226, loss_ce: 0.021304
[00:17:56.369] iteration 2462 : loss : 0.172575, loss_ce: 0.042378
[00:17:56.657] iteration 2463 : loss : 0.204104, loss_ce: 0.010646
[00:17:56.950] iteration 2464 : loss : 0.227821, loss_ce: 0.011941
[00:17:57.240] iteration 2465 : loss : 0.114516, loss_ce: 0.042886
[00:17:57.528] iteration 2466 : loss : 0.101477, loss_ce: 0.038600
[00:17:57.814] iteration 2467 : loss : 0.118107, loss_ce: 0.043373
[00:17:58.105] iteration 2468 : loss : 0.180643, loss_ce: 0.036460
[00:17:58.394] iteration 2469 : loss : 0.147760, loss_ce: 0.040471
[00:17:58.681] iteration 2470 : loss : 0.102540, loss_ce: 0.040297
[00:17:58.970] iteration 2471 : loss : 0.150422, loss_ce: 0.036816
[00:17:59.260] iteration 2472 : loss : 0.165216, loss_ce: 0.041025
[00:17:59.548] iteration 2473 : loss : 0.090519, loss_ce: 0.039716
[00:17:59.838] iteration 2474 : loss : 0.167547, loss_ce: 0.020776
[00:18:00.127] iteration 2475 : loss : 0.131320, loss_ce: 0.034972
[00:18:00.415] iteration 2476 : loss : 0.173331, loss_ce: 0.029931
[00:18:00.707] iteration 2477 : loss : 0.126159, loss_ce: 0.026524
[00:18:00.996] iteration 2478 : loss : 0.118169, loss_ce: 0.030731
[00:18:01.284] iteration 2479 : loss : 0.141226, loss_ce: 0.036313
[00:18:01.575] iteration 2480 : loss : 0.136395, loss_ce: 0.038459
[00:18:01.879] iteration 2481 : loss : 0.184846, loss_ce: 0.046050
[00:18:02.166] iteration 2482 : loss : 0.198528, loss_ce: 0.028004
[00:18:02.452] iteration 2483 : loss : 0.127576, loss_ce: 0.052306
[00:18:02.748] iteration 2484 : loss : 0.158378, loss_ce: 0.035401
[00:18:03.034] iteration 2485 : loss : 0.126590, loss_ce: 0.038223
[00:18:03.328] iteration 2486 : loss : 0.101229, loss_ce: 0.038069
[00:18:03.618] iteration 2487 : loss : 0.148135, loss_ce: 0.019577
[00:18:03.914] iteration 2488 : loss : 0.153300, loss_ce: 0.037300
[00:18:04.203] iteration 2489 : loss : 0.105014, loss_ce: 0.029244
[00:18:04.496] iteration 2490 : loss : 0.112370, loss_ce: 0.022608
[00:18:04.788] iteration 2491 : loss : 0.103596, loss_ce: 0.039525
[00:18:05.083] iteration 2492 : loss : 0.108018, loss_ce: 0.029190
[00:18:05.374] iteration 2493 : loss : 0.132299, loss_ce: 0.031156
[00:18:05.663] iteration 2494 : loss : 0.132737, loss_ce: 0.045701
[00:18:05.956] iteration 2495 : loss : 0.119458, loss_ce: 0.052693
[00:18:06.244] iteration 2496 : loss : 0.152651, loss_ce: 0.026119
[00:18:06.531] iteration 2497 : loss : 0.148519, loss_ce: 0.032706
[00:18:06.822] iteration 2498 : loss : 0.140195, loss_ce: 0.035298
[00:18:07.116] iteration 2499 : loss : 0.115252, loss_ce: 0.038422
[00:18:07.407] iteration 2500 : loss : 0.097723, loss_ce: 0.027414
[00:18:07.713] iteration 2501 : loss : 0.104942, loss_ce: 0.041516
[00:18:07.790] iteration 2502 : loss : 0.109613, loss_ce: 0.070867
[00:18:24.355] iteration 2503 : loss : 0.146474, loss_ce: 0.038975
[00:18:24.640] iteration 2504 : loss : 0.102551, loss_ce: 0.042309
[00:18:24.925] iteration 2505 : loss : 0.155997, loss_ce: 0.043740
[00:18:25.212] iteration 2506 : loss : 0.105077, loss_ce: 0.027518
[00:18:25.499] iteration 2507 : loss : 0.100336, loss_ce: 0.038627
[00:18:25.786] iteration 2508 : loss : 0.185639, loss_ce: 0.042883
[00:18:26.071] iteration 2509 : loss : 0.150089, loss_ce: 0.025942
[00:18:26.359] iteration 2510 : loss : 0.131209, loss_ce: 0.070427
[00:18:26.645] iteration 2511 : loss : 0.187053, loss_ce: 0.021430
[00:18:26.930] iteration 2512 : loss : 0.157627, loss_ce: 0.032505
[00:18:27.220] iteration 2513 : loss : 0.126495, loss_ce: 0.047948
[00:18:27.506] iteration 2514 : loss : 0.134451, loss_ce: 0.016610
[00:18:27.792] iteration 2515 : loss : 0.269942, loss_ce: 0.027951
[00:18:28.078] iteration 2516 : loss : 0.122966, loss_ce: 0.028233
[00:18:28.367] iteration 2517 : loss : 0.192054, loss_ce: 0.017191
[00:18:28.652] iteration 2518 : loss : 0.093984, loss_ce: 0.034852
[00:18:28.937] iteration 2519 : loss : 0.184981, loss_ce: 0.035097
[00:18:29.226] iteration 2520 : loss : 0.107301, loss_ce: 0.020815
[00:18:29.530] iteration 2521 : loss : 0.151689, loss_ce: 0.019570
[00:18:29.815] iteration 2522 : loss : 0.072909, loss_ce: 0.019690
[00:18:30.103] iteration 2523 : loss : 0.173461, loss_ce: 0.056664
[00:18:30.393] iteration 2524 : loss : 0.092717, loss_ce: 0.035502
[00:18:30.677] iteration 2525 : loss : 0.106248, loss_ce: 0.029640
[00:18:30.964] iteration 2526 : loss : 0.132034, loss_ce: 0.034920
[00:18:31.251] iteration 2527 : loss : 0.103104, loss_ce: 0.041932
[00:18:31.536] iteration 2528 : loss : 0.156630, loss_ce: 0.020774
[00:18:31.820] iteration 2529 : loss : 0.095801, loss_ce: 0.031916
[00:18:32.111] iteration 2530 : loss : 0.127692, loss_ce: 0.018441
[00:18:32.397] iteration 2531 : loss : 0.113147, loss_ce: 0.031124
[00:18:32.684] iteration 2532 : loss : 0.158706, loss_ce: 0.043080
[00:18:32.971] iteration 2533 : loss : 0.141196, loss_ce: 0.039979
[00:18:33.258] iteration 2534 : loss : 0.107607, loss_ce: 0.034156
[00:18:33.545] iteration 2535 : loss : 0.114425, loss_ce: 0.041737
[00:18:33.831] iteration 2536 : loss : 0.136036, loss_ce: 0.035743
[00:18:34.119] iteration 2537 : loss : 0.139942, loss_ce: 0.023715
[00:18:34.404] iteration 2538 : loss : 0.174239, loss_ce: 0.037225
[00:18:34.691] iteration 2539 : loss : 0.124000, loss_ce: 0.040613
[00:18:34.978] iteration 2540 : loss : 0.107000, loss_ce: 0.018155
[00:18:35.281] iteration 2541 : loss : 0.132697, loss_ce: 0.023754
[00:18:35.568] iteration 2542 : loss : 0.146600, loss_ce: 0.010423
[00:18:35.858] iteration 2543 : loss : 0.150255, loss_ce: 0.042220
[00:18:36.148] iteration 2544 : loss : 0.103209, loss_ce: 0.038231
[00:18:36.434] iteration 2545 : loss : 0.095807, loss_ce: 0.056157
[00:18:36.722] iteration 2546 : loss : 0.123692, loss_ce: 0.037003
[00:18:37.011] iteration 2547 : loss : 0.100091, loss_ce: 0.016991
[00:18:37.298] iteration 2548 : loss : 0.181895, loss_ce: 0.044111
[00:18:37.585] iteration 2549 : loss : 0.145111, loss_ce: 0.038563
[00:18:37.875] iteration 2550 : loss : 0.089511, loss_ce: 0.033863
[00:18:38.162] iteration 2551 : loss : 0.083207, loss_ce: 0.032966
[00:18:38.450] iteration 2552 : loss : 0.092520, loss_ce: 0.044441
[00:18:38.736] iteration 2553 : loss : 0.146268, loss_ce: 0.018587
[00:18:39.025] iteration 2554 : loss : 0.167008, loss_ce: 0.045631
[00:18:39.316] iteration 2555 : loss : 0.147031, loss_ce: 0.035710
[00:18:39.602] iteration 2556 : loss : 0.135926, loss_ce: 0.021495
[00:18:39.892] iteration 2557 : loss : 0.099304, loss_ce: 0.025526
[00:18:40.181] iteration 2558 : loss : 0.089685, loss_ce: 0.025613
[00:18:40.471] iteration 2559 : loss : 0.105357, loss_ce: 0.033200
[00:18:40.759] iteration 2560 : loss : 0.104742, loss_ce: 0.036046
[00:18:41.063] iteration 2561 : loss : 0.164479, loss_ce: 0.023541
[00:18:41.350] iteration 2562 : loss : 0.126061, loss_ce: 0.035562
[00:18:41.638] iteration 2563 : loss : 0.110376, loss_ce: 0.032009
[00:18:41.925] iteration 2564 : loss : 0.126741, loss_ce: 0.033887
[00:18:42.214] iteration 2565 : loss : 0.107362, loss_ce: 0.026255
[00:18:42.501] iteration 2566 : loss : 0.087717, loss_ce: 0.033700
[00:18:42.789] iteration 2567 : loss : 0.112926, loss_ce: 0.030354
[00:18:43.078] iteration 2568 : loss : 0.100256, loss_ce: 0.039088
[00:18:43.367] iteration 2569 : loss : 0.153853, loss_ce: 0.026071
[00:18:43.656] iteration 2570 : loss : 0.090534, loss_ce: 0.041859
[00:18:43.943] iteration 2571 : loss : 0.090468, loss_ce: 0.022251
[00:18:44.231] iteration 2572 : loss : 0.199157, loss_ce: 0.023504
[00:18:44.517] iteration 2573 : loss : 0.111439, loss_ce: 0.054874
[00:18:44.804] iteration 2574 : loss : 0.168109, loss_ce: 0.050251
[00:18:45.096] iteration 2575 : loss : 0.107642, loss_ce: 0.033990
[00:18:45.382] iteration 2576 : loss : 0.135476, loss_ce: 0.043959
[00:18:45.671] iteration 2577 : loss : 0.151956, loss_ce: 0.029719
[00:18:45.958] iteration 2578 : loss : 0.127056, loss_ce: 0.020391
[00:18:46.248] iteration 2579 : loss : 0.147064, loss_ce: 0.042017
[00:18:46.533] iteration 2580 : loss : 0.122116, loss_ce: 0.026412
[00:18:46.839] iteration 2581 : loss : 0.124560, loss_ce: 0.042375
[00:18:47.125] iteration 2582 : loss : 0.128913, loss_ce: 0.029693
[00:18:47.410] iteration 2583 : loss : 0.149975, loss_ce: 0.034680
[00:18:47.697] iteration 2584 : loss : 0.200480, loss_ce: 0.014170
[00:18:47.987] iteration 2585 : loss : 0.115972, loss_ce: 0.024073
[00:18:48.273] iteration 2586 : loss : 0.226826, loss_ce: 0.020021
[00:18:48.560] iteration 2587 : loss : 0.148125, loss_ce: 0.015725
[00:18:48.846] iteration 2588 : loss : 0.089100, loss_ce: 0.024982
[00:18:49.134] iteration 2589 : loss : 0.119832, loss_ce: 0.034287
[00:18:49.424] iteration 2590 : loss : 0.122542, loss_ce: 0.046321
[00:18:49.713] iteration 2591 : loss : 0.161660, loss_ce: 0.025097
[00:18:49.999] iteration 2592 : loss : 0.108693, loss_ce: 0.039164
[00:18:50.285] iteration 2593 : loss : 0.115961, loss_ce: 0.022625
[00:18:50.574] iteration 2594 : loss : 0.201528, loss_ce: 0.036654
[00:18:50.863] iteration 2595 : loss : 0.125013, loss_ce: 0.045035
[00:18:51.154] iteration 2596 : loss : 0.075415, loss_ce: 0.026397
[00:18:51.444] iteration 2597 : loss : 0.079257, loss_ce: 0.026087
[00:18:51.730] iteration 2598 : loss : 0.133478, loss_ce: 0.031039
[00:18:52.023] iteration 2599 : loss : 0.273837, loss_ce: 0.026869
[00:18:52.312] iteration 2600 : loss : 0.205584, loss_ce: 0.051428
[00:18:52.618] iteration 2601 : loss : 0.136883, loss_ce: 0.035471
[00:18:52.908] iteration 2602 : loss : 0.090966, loss_ce: 0.038161
[00:18:53.197] iteration 2603 : loss : 0.114059, loss_ce: 0.024411
[00:18:53.487] iteration 2604 : loss : 0.107569, loss_ce: 0.010804
[00:18:53.778] iteration 2605 : loss : 0.194319, loss_ce: 0.040544
[00:18:54.066] iteration 2606 : loss : 0.154382, loss_ce: 0.026874
[00:18:54.356] iteration 2607 : loss : 0.101901, loss_ce: 0.019850
[00:18:54.648] iteration 2608 : loss : 0.111287, loss_ce: 0.027989
[00:18:54.939] iteration 2609 : loss : 0.146939, loss_ce: 0.014544
[00:18:55.229] iteration 2610 : loss : 0.163569, loss_ce: 0.044178
[00:18:55.519] iteration 2611 : loss : 0.183910, loss_ce: 0.021393
[00:18:55.809] iteration 2612 : loss : 0.109766, loss_ce: 0.029683
[00:18:56.098] iteration 2613 : loss : 0.108496, loss_ce: 0.039639
[00:18:56.387] iteration 2614 : loss : 0.097479, loss_ce: 0.040381
[00:18:56.677] iteration 2615 : loss : 0.120903, loss_ce: 0.028958
[00:18:56.966] iteration 2616 : loss : 0.155487, loss_ce: 0.042303
[00:18:57.255] iteration 2617 : loss : 0.162349, loss_ce: 0.032224
[00:18:57.544] iteration 2618 : loss : 0.257088, loss_ce: 0.024697
[00:18:57.834] iteration 2619 : loss : 0.123637, loss_ce: 0.043180
[00:18:58.124] iteration 2620 : loss : 0.104110, loss_ce: 0.033786
[00:18:58.427] iteration 2621 : loss : 0.128340, loss_ce: 0.034715
[00:18:58.717] iteration 2622 : loss : 0.126955, loss_ce: 0.028731
[00:18:59.009] iteration 2623 : loss : 0.262128, loss_ce: 0.013695
[00:18:59.300] iteration 2624 : loss : 0.105481, loss_ce: 0.036159
[00:18:59.591] iteration 2625 : loss : 0.128366, loss_ce: 0.042261
[00:18:59.885] iteration 2626 : loss : 0.124820, loss_ce: 0.043533
[00:19:00.186] iteration 2627 : loss : 0.141913, loss_ce: 0.013442
[00:19:00.480] iteration 2628 : loss : 0.099623, loss_ce: 0.031314
[00:19:00.776] iteration 2629 : loss : 0.168892, loss_ce: 0.026786
[00:19:01.071] iteration 2630 : loss : 0.083579, loss_ce: 0.024380
[00:19:01.365] iteration 2631 : loss : 0.197675, loss_ce: 0.042081
[00:19:01.662] iteration 2632 : loss : 0.178170, loss_ce: 0.030492
[00:19:01.954] iteration 2633 : loss : 0.160593, loss_ce: 0.023302
[00:19:02.247] iteration 2634 : loss : 0.093278, loss_ce: 0.018541
[00:19:02.540] iteration 2635 : loss : 0.094727, loss_ce: 0.034876
[00:19:02.832] iteration 2636 : loss : 0.084658, loss_ce: 0.023718
[00:19:03.124] iteration 2637 : loss : 0.108626, loss_ce: 0.034507
[00:19:03.417] iteration 2638 : loss : 0.079619, loss_ce: 0.029374
[00:19:03.712] iteration 2639 : loss : 0.198030, loss_ce: 0.012886
[00:19:04.005] iteration 2640 : loss : 0.108878, loss_ce: 0.026654
[00:19:04.100] iteration 2641 : loss : 0.355999, loss_ce: 0.008063
[00:19:20.828] iteration 2642 : loss : 0.109192, loss_ce: 0.035017
[00:19:21.113] iteration 2643 : loss : 0.172796, loss_ce: 0.018304
[00:19:21.396] iteration 2644 : loss : 0.094285, loss_ce: 0.019034
[00:19:21.687] iteration 2645 : loss : 0.107830, loss_ce: 0.024745
[00:19:21.973] iteration 2646 : loss : 0.102488, loss_ce: 0.024205
[00:19:22.260] iteration 2647 : loss : 0.116575, loss_ce: 0.032665
[00:19:22.547] iteration 2648 : loss : 0.117426, loss_ce: 0.045719
[00:19:22.836] iteration 2649 : loss : 0.092331, loss_ce: 0.038759
[00:19:23.122] iteration 2650 : loss : 0.096784, loss_ce: 0.039118
[00:19:23.407] iteration 2651 : loss : 0.106216, loss_ce: 0.032119
[00:19:23.693] iteration 2652 : loss : 0.124598, loss_ce: 0.010168
[00:19:23.980] iteration 2653 : loss : 0.129924, loss_ce: 0.016062
[00:19:24.269] iteration 2654 : loss : 0.102239, loss_ce: 0.028744
[00:19:24.557] iteration 2655 : loss : 0.117728, loss_ce: 0.043670
[00:19:24.844] iteration 2656 : loss : 0.182713, loss_ce: 0.014138
[00:19:25.131] iteration 2657 : loss : 0.142560, loss_ce: 0.012345
[00:19:25.416] iteration 2658 : loss : 0.123570, loss_ce: 0.055979
[00:19:25.703] iteration 2659 : loss : 0.096447, loss_ce: 0.035203
[00:19:25.990] iteration 2660 : loss : 0.196075, loss_ce: 0.018995
[00:19:26.292] iteration 2661 : loss : 0.129428, loss_ce: 0.024663
[00:19:26.580] iteration 2662 : loss : 0.110242, loss_ce: 0.029897
[00:19:26.868] iteration 2663 : loss : 0.155311, loss_ce: 0.019383
[00:19:27.157] iteration 2664 : loss : 0.066310, loss_ce: 0.010312
[00:19:27.443] iteration 2665 : loss : 0.163575, loss_ce: 0.040241
[00:19:27.728] iteration 2666 : loss : 0.153353, loss_ce: 0.015219
[00:19:28.017] iteration 2667 : loss : 0.117187, loss_ce: 0.027400
[00:19:28.304] iteration 2668 : loss : 0.251409, loss_ce: 0.015859
[00:19:28.591] iteration 2669 : loss : 0.074060, loss_ce: 0.028529
[00:19:28.879] iteration 2670 : loss : 0.097989, loss_ce: 0.042101
[00:19:29.166] iteration 2671 : loss : 0.123791, loss_ce: 0.035206
[00:19:29.454] iteration 2672 : loss : 0.099978, loss_ce: 0.035647
[00:19:29.745] iteration 2673 : loss : 0.123057, loss_ce: 0.052454
[00:19:30.033] iteration 2674 : loss : 0.114620, loss_ce: 0.033417
[00:19:30.322] iteration 2675 : loss : 0.080215, loss_ce: 0.032262
[00:19:30.608] iteration 2676 : loss : 0.156941, loss_ce: 0.017981
[00:19:30.897] iteration 2677 : loss : 0.171775, loss_ce: 0.028653
[00:19:31.186] iteration 2678 : loss : 0.161619, loss_ce: 0.013937
[00:19:31.474] iteration 2679 : loss : 0.168168, loss_ce: 0.028715
[00:19:31.761] iteration 2680 : loss : 0.198333, loss_ce: 0.035840
[00:19:32.062] iteration 2681 : loss : 0.113538, loss_ce: 0.038799
[00:19:32.351] iteration 2682 : loss : 0.110717, loss_ce: 0.055244
[00:19:32.638] iteration 2683 : loss : 0.192846, loss_ce: 0.048496
[00:19:32.929] iteration 2684 : loss : 0.139806, loss_ce: 0.044764
[00:19:33.218] iteration 2685 : loss : 0.149191, loss_ce: 0.045420
[00:19:33.507] iteration 2686 : loss : 0.216631, loss_ce: 0.015504
[00:19:33.795] iteration 2687 : loss : 0.123778, loss_ce: 0.046598
[00:19:34.087] iteration 2688 : loss : 0.113498, loss_ce: 0.030751
[00:19:34.372] iteration 2689 : loss : 0.100586, loss_ce: 0.028564
[00:19:34.659] iteration 2690 : loss : 0.123897, loss_ce: 0.036945
[00:19:34.947] iteration 2691 : loss : 0.143230, loss_ce: 0.034783
[00:19:35.235] iteration 2692 : loss : 0.095732, loss_ce: 0.027860
[00:19:35.522] iteration 2693 : loss : 0.126045, loss_ce: 0.041020
[00:19:35.808] iteration 2694 : loss : 0.126872, loss_ce: 0.040995
[00:19:36.094] iteration 2695 : loss : 0.192363, loss_ce: 0.056160
[00:19:36.382] iteration 2696 : loss : 0.108213, loss_ce: 0.039820
[00:19:36.669] iteration 2697 : loss : 0.163988, loss_ce: 0.047616
[00:19:36.956] iteration 2698 : loss : 0.202082, loss_ce: 0.027014
[00:19:37.243] iteration 2699 : loss : 0.126408, loss_ce: 0.034515
[00:19:37.529] iteration 2700 : loss : 0.140283, loss_ce: 0.015298
[00:19:37.831] iteration 2701 : loss : 0.114826, loss_ce: 0.031153
[00:19:38.119] iteration 2702 : loss : 0.091548, loss_ce: 0.021837
[00:19:38.408] iteration 2703 : loss : 0.140488, loss_ce: 0.035642
[00:19:38.695] iteration 2704 : loss : 0.090899, loss_ce: 0.028217
[00:19:38.982] iteration 2705 : loss : 0.090573, loss_ce: 0.026157
[00:19:39.272] iteration 2706 : loss : 0.213203, loss_ce: 0.019319
[00:19:39.561] iteration 2707 : loss : 0.159814, loss_ce: 0.039267
[00:19:39.848] iteration 2708 : loss : 0.213075, loss_ce: 0.019016
[00:19:40.134] iteration 2709 : loss : 0.191078, loss_ce: 0.029394
[00:19:40.420] iteration 2710 : loss : 0.140954, loss_ce: 0.079740
[00:19:40.709] iteration 2711 : loss : 0.174372, loss_ce: 0.027213
[00:19:40.998] iteration 2712 : loss : 0.191565, loss_ce: 0.027731
[00:19:41.287] iteration 2713 : loss : 0.109275, loss_ce: 0.025897
[00:19:41.575] iteration 2714 : loss : 0.097794, loss_ce: 0.036461
[00:19:41.861] iteration 2715 : loss : 0.078339, loss_ce: 0.014257
[00:19:42.151] iteration 2716 : loss : 0.165308, loss_ce: 0.047525
[00:19:42.441] iteration 2717 : loss : 0.124497, loss_ce: 0.032944
[00:19:42.732] iteration 2718 : loss : 0.116775, loss_ce: 0.018464
[00:19:43.019] iteration 2719 : loss : 0.100098, loss_ce: 0.022377
[00:19:43.307] iteration 2720 : loss : 0.178922, loss_ce: 0.030202
[00:19:43.610] iteration 2721 : loss : 0.115760, loss_ce: 0.032375
[00:19:43.898] iteration 2722 : loss : 0.108893, loss_ce: 0.033265
[00:19:44.183] iteration 2723 : loss : 0.164409, loss_ce: 0.052720
[00:19:44.473] iteration 2724 : loss : 0.123880, loss_ce: 0.026357
[00:19:44.763] iteration 2725 : loss : 0.149867, loss_ce: 0.033858
[00:19:45.048] iteration 2726 : loss : 0.111075, loss_ce: 0.035382
[00:19:45.336] iteration 2727 : loss : 0.112180, loss_ce: 0.026606
[00:19:45.626] iteration 2728 : loss : 0.115423, loss_ce: 0.023657
[00:19:45.912] iteration 2729 : loss : 0.086597, loss_ce: 0.038780
[00:19:46.201] iteration 2730 : loss : 0.135678, loss_ce: 0.019498
[00:19:46.486] iteration 2731 : loss : 0.105888, loss_ce: 0.027163
[00:19:46.777] iteration 2732 : loss : 0.099644, loss_ce: 0.028542
[00:19:47.064] iteration 2733 : loss : 0.136125, loss_ce: 0.035888
[00:19:47.351] iteration 2734 : loss : 0.155871, loss_ce: 0.027608
[00:19:47.638] iteration 2735 : loss : 0.128660, loss_ce: 0.034666
[00:19:47.926] iteration 2736 : loss : 0.173391, loss_ce: 0.033758
[00:19:48.216] iteration 2737 : loss : 0.117604, loss_ce: 0.041129
[00:19:48.506] iteration 2738 : loss : 0.118718, loss_ce: 0.037904
[00:19:48.793] iteration 2739 : loss : 0.140927, loss_ce: 0.030337
[00:19:49.084] iteration 2740 : loss : 0.140508, loss_ce: 0.043925
[00:19:49.384] iteration 2741 : loss : 0.120905, loss_ce: 0.038845
[00:19:49.670] iteration 2742 : loss : 0.135463, loss_ce: 0.039778
[00:19:49.957] iteration 2743 : loss : 0.079798, loss_ce: 0.025208
[00:19:50.248] iteration 2744 : loss : 0.166631, loss_ce: 0.018799
[00:19:50.537] iteration 2745 : loss : 0.150014, loss_ce: 0.023163
[00:19:50.823] iteration 2746 : loss : 0.116371, loss_ce: 0.051631
[00:19:51.113] iteration 2747 : loss : 0.094193, loss_ce: 0.022145
[00:19:51.399] iteration 2748 : loss : 0.139766, loss_ce: 0.029253
[00:19:51.686] iteration 2749 : loss : 0.144265, loss_ce: 0.029678
[00:19:51.975] iteration 2750 : loss : 0.107453, loss_ce: 0.040999
[00:19:52.263] iteration 2751 : loss : 0.111165, loss_ce: 0.024281
[00:19:52.550] iteration 2752 : loss : 0.266950, loss_ce: 0.027953
[00:19:52.837] iteration 2753 : loss : 0.181489, loss_ce: 0.034798
[00:19:53.126] iteration 2754 : loss : 0.144484, loss_ce: 0.036594
[00:19:53.416] iteration 2755 : loss : 0.103602, loss_ce: 0.030413
[00:19:53.704] iteration 2756 : loss : 0.151084, loss_ce: 0.027224
[00:19:53.991] iteration 2757 : loss : 0.148103, loss_ce: 0.048580
[00:19:54.277] iteration 2758 : loss : 0.117772, loss_ce: 0.020722
[00:19:54.564] iteration 2759 : loss : 0.110359, loss_ce: 0.041551
[00:19:54.852] iteration 2760 : loss : 0.150099, loss_ce: 0.015634
[00:19:55.153] iteration 2761 : loss : 0.107621, loss_ce: 0.037923
[00:19:55.442] iteration 2762 : loss : 0.116510, loss_ce: 0.030533
[00:19:55.730] iteration 2763 : loss : 0.121621, loss_ce: 0.031158
[00:19:56.022] iteration 2764 : loss : 0.133025, loss_ce: 0.031519
[00:19:56.312] iteration 2765 : loss : 0.124147, loss_ce: 0.026655
[00:19:56.604] iteration 2766 : loss : 0.102012, loss_ce: 0.016870
[00:19:56.892] iteration 2767 : loss : 0.171894, loss_ce: 0.026760
[00:19:57.186] iteration 2768 : loss : 0.094663, loss_ce: 0.021567
[00:19:57.476] iteration 2769 : loss : 0.077563, loss_ce: 0.023635
[00:19:57.768] iteration 2770 : loss : 0.098320, loss_ce: 0.033722
[00:19:58.062] iteration 2771 : loss : 0.147654, loss_ce: 0.037495
[00:19:58.352] iteration 2772 : loss : 0.098391, loss_ce: 0.035614
[00:19:58.640] iteration 2773 : loss : 0.147707, loss_ce: 0.057380
[00:19:58.929] iteration 2774 : loss : 0.118325, loss_ce: 0.010815
[00:19:59.225] iteration 2775 : loss : 0.087447, loss_ce: 0.031463
[00:19:59.518] iteration 2776 : loss : 0.165636, loss_ce: 0.034850
[00:19:59.807] iteration 2777 : loss : 0.107222, loss_ce: 0.027350
[00:20:00.101] iteration 2778 : loss : 0.122599, loss_ce: 0.050062
[00:20:00.395] iteration 2779 : loss : 0.258219, loss_ce: 0.024858
[00:20:00.470] iteration 2780 : loss : 0.340185, loss_ce: 0.059021
[00:20:16.820] iteration 2781 : loss : 0.104937, loss_ce: 0.015834
[00:20:17.104] iteration 2782 : loss : 0.125282, loss_ce: 0.046912
[00:20:17.388] iteration 2783 : loss : 0.115489, loss_ce: 0.050952
[00:20:17.677] iteration 2784 : loss : 0.136568, loss_ce: 0.020460
[00:20:17.964] iteration 2785 : loss : 0.092777, loss_ce: 0.023463
[00:20:18.251] iteration 2786 : loss : 0.118813, loss_ce: 0.035910
[00:20:18.537] iteration 2787 : loss : 0.133473, loss_ce: 0.031816
[00:20:18.825] iteration 2788 : loss : 0.115005, loss_ce: 0.042361
[00:20:19.111] iteration 2789 : loss : 0.082832, loss_ce: 0.020685
[00:20:19.395] iteration 2790 : loss : 0.203594, loss_ce: 0.023138
[00:20:19.682] iteration 2791 : loss : 0.112294, loss_ce: 0.037112
[00:20:19.969] iteration 2792 : loss : 0.107109, loss_ce: 0.026635
[00:20:20.257] iteration 2793 : loss : 0.151114, loss_ce: 0.020211
[00:20:20.545] iteration 2794 : loss : 0.156227, loss_ce: 0.027203
[00:20:20.832] iteration 2795 : loss : 0.118283, loss_ce: 0.030916
[00:20:21.118] iteration 2796 : loss : 0.165861, loss_ce: 0.021471
[00:20:21.406] iteration 2797 : loss : 0.192107, loss_ce: 0.023056
[00:20:21.691] iteration 2798 : loss : 0.172288, loss_ce: 0.032021
[00:20:21.976] iteration 2799 : loss : 0.159003, loss_ce: 0.025847
[00:20:22.264] iteration 2800 : loss : 0.107619, loss_ce: 0.036732
[00:20:22.568] iteration 2801 : loss : 0.164296, loss_ce: 0.042142
[00:20:22.856] iteration 2802 : loss : 0.161223, loss_ce: 0.052704
[00:20:23.142] iteration 2803 : loss : 0.127264, loss_ce: 0.063480
[00:20:23.429] iteration 2804 : loss : 0.155486, loss_ce: 0.040796
[00:20:23.716] iteration 2805 : loss : 0.110404, loss_ce: 0.038275
[00:20:24.003] iteration 2806 : loss : 0.102161, loss_ce: 0.020301
[00:20:24.291] iteration 2807 : loss : 0.108869, loss_ce: 0.036383
[00:20:24.577] iteration 2808 : loss : 0.135558, loss_ce: 0.020238
[00:20:24.867] iteration 2809 : loss : 0.174767, loss_ce: 0.024885
[00:20:25.154] iteration 2810 : loss : 0.117325, loss_ce: 0.028806
[00:20:25.439] iteration 2811 : loss : 0.139840, loss_ce: 0.033503
[00:20:25.725] iteration 2812 : loss : 0.097115, loss_ce: 0.012968
[00:20:26.012] iteration 2813 : loss : 0.162182, loss_ce: 0.029131
[00:20:26.298] iteration 2814 : loss : 0.177786, loss_ce: 0.030387
[00:20:26.584] iteration 2815 : loss : 0.111162, loss_ce: 0.038503
[00:20:26.872] iteration 2816 : loss : 0.096021, loss_ce: 0.044706
[00:20:27.158] iteration 2817 : loss : 0.099647, loss_ce: 0.041365
[00:20:27.447] iteration 2818 : loss : 0.179709, loss_ce: 0.022127
[00:20:27.731] iteration 2819 : loss : 0.143614, loss_ce: 0.022360
[00:20:28.021] iteration 2820 : loss : 0.109193, loss_ce: 0.036894
[00:20:28.320] iteration 2821 : loss : 0.111273, loss_ce: 0.028934
[00:20:28.606] iteration 2822 : loss : 0.100547, loss_ce: 0.037548
[00:20:28.893] iteration 2823 : loss : 0.129893, loss_ce: 0.032956
[00:20:29.182] iteration 2824 : loss : 0.128612, loss_ce: 0.030185
[00:20:29.467] iteration 2825 : loss : 0.082032, loss_ce: 0.036333
[00:20:29.752] iteration 2826 : loss : 0.093612, loss_ce: 0.019649
[00:20:30.041] iteration 2827 : loss : 0.127444, loss_ce: 0.022794
[00:20:30.328] iteration 2828 : loss : 0.116242, loss_ce: 0.050644
[00:20:30.615] iteration 2829 : loss : 0.119808, loss_ce: 0.022677
[00:20:30.900] iteration 2830 : loss : 0.205127, loss_ce: 0.020265
[00:20:31.189] iteration 2831 : loss : 0.114638, loss_ce: 0.038488
[00:20:31.475] iteration 2832 : loss : 0.114462, loss_ce: 0.028890
[00:20:31.762] iteration 2833 : loss : 0.132273, loss_ce: 0.035967
[00:20:32.047] iteration 2834 : loss : 0.098139, loss_ce: 0.043688
[00:20:32.334] iteration 2835 : loss : 0.088309, loss_ce: 0.027106
[00:20:32.621] iteration 2836 : loss : 0.104129, loss_ce: 0.033152
[00:20:32.911] iteration 2837 : loss : 0.102226, loss_ce: 0.027264
[00:20:33.199] iteration 2838 : loss : 0.110138, loss_ce: 0.027679
[00:20:33.487] iteration 2839 : loss : 0.089096, loss_ce: 0.019601
[00:20:33.772] iteration 2840 : loss : 0.108322, loss_ce: 0.031161
[00:20:34.078] iteration 2841 : loss : 0.098824, loss_ce: 0.033011
[00:20:34.364] iteration 2842 : loss : 0.129516, loss_ce: 0.035731
[00:20:34.650] iteration 2843 : loss : 0.103990, loss_ce: 0.025564
[00:20:34.937] iteration 2844 : loss : 0.079317, loss_ce: 0.012930
[00:20:35.224] iteration 2845 : loss : 0.093813, loss_ce: 0.037356
[00:20:35.509] iteration 2846 : loss : 0.101855, loss_ce: 0.053026
[00:20:35.799] iteration 2847 : loss : 0.079662, loss_ce: 0.032626
[00:20:36.084] iteration 2848 : loss : 0.114568, loss_ce: 0.034372
[00:20:36.374] iteration 2849 : loss : 0.086316, loss_ce: 0.034174
[00:20:36.661] iteration 2850 : loss : 0.107358, loss_ce: 0.031907
[00:20:36.950] iteration 2851 : loss : 0.146751, loss_ce: 0.032262
[00:20:37.236] iteration 2852 : loss : 0.099107, loss_ce: 0.024326
[00:20:37.522] iteration 2853 : loss : 0.097975, loss_ce: 0.028471
[00:20:37.809] iteration 2854 : loss : 0.150335, loss_ce: 0.028703
[00:20:38.098] iteration 2855 : loss : 0.113556, loss_ce: 0.025392
[00:20:38.385] iteration 2856 : loss : 0.169486, loss_ce: 0.012491
[00:20:38.671] iteration 2857 : loss : 0.191585, loss_ce: 0.022194
[00:20:38.963] iteration 2858 : loss : 0.085769, loss_ce: 0.029455
[00:20:39.250] iteration 2859 : loss : 0.153392, loss_ce: 0.016542
[00:20:39.536] iteration 2860 : loss : 0.087636, loss_ce: 0.020868
[00:20:39.838] iteration 2861 : loss : 0.118701, loss_ce: 0.023904
[00:20:40.125] iteration 2862 : loss : 0.200764, loss_ce: 0.024999
[00:20:40.411] iteration 2863 : loss : 0.221861, loss_ce: 0.023979
[00:20:40.698] iteration 2864 : loss : 0.162804, loss_ce: 0.028175
[00:20:40.986] iteration 2865 : loss : 0.123129, loss_ce: 0.041312
[00:20:41.273] iteration 2866 : loss : 0.091153, loss_ce: 0.028683
[00:20:41.565] iteration 2867 : loss : 0.092686, loss_ce: 0.019038
[00:20:41.850] iteration 2868 : loss : 0.149145, loss_ce: 0.028817
[00:20:42.138] iteration 2869 : loss : 0.191406, loss_ce: 0.036728
[00:20:42.423] iteration 2870 : loss : 0.094741, loss_ce: 0.030365
[00:20:42.711] iteration 2871 : loss : 0.096923, loss_ce: 0.024663
[00:20:42.998] iteration 2872 : loss : 0.137218, loss_ce: 0.032847
[00:20:43.287] iteration 2873 : loss : 0.094277, loss_ce: 0.034401
[00:20:43.575] iteration 2874 : loss : 0.094923, loss_ce: 0.043991
[00:20:43.863] iteration 2875 : loss : 0.093150, loss_ce: 0.022708
[00:20:44.150] iteration 2876 : loss : 0.125460, loss_ce: 0.038284
[00:20:44.437] iteration 2877 : loss : 0.085476, loss_ce: 0.034954
[00:20:44.725] iteration 2878 : loss : 0.110592, loss_ce: 0.029219
[00:20:45.012] iteration 2879 : loss : 0.083490, loss_ce: 0.020448
[00:20:45.301] iteration 2880 : loss : 0.139667, loss_ce: 0.028747
[00:20:45.603] iteration 2881 : loss : 0.121373, loss_ce: 0.012637
[00:20:45.889] iteration 2882 : loss : 0.153701, loss_ce: 0.026269
[00:20:46.176] iteration 2883 : loss : 0.091011, loss_ce: 0.030691
[00:20:46.467] iteration 2884 : loss : 0.101919, loss_ce: 0.011796
[00:20:46.756] iteration 2885 : loss : 0.111690, loss_ce: 0.031832
[00:20:47.042] iteration 2886 : loss : 0.127030, loss_ce: 0.034927
[00:20:47.329] iteration 2887 : loss : 0.102702, loss_ce: 0.039739
[00:20:47.619] iteration 2888 : loss : 0.198800, loss_ce: 0.029508
[00:20:47.905] iteration 2889 : loss : 0.087623, loss_ce: 0.042933
[00:20:48.192] iteration 2890 : loss : 0.104205, loss_ce: 0.034787
[00:20:48.479] iteration 2891 : loss : 0.110569, loss_ce: 0.022507
[00:20:48.766] iteration 2892 : loss : 0.122123, loss_ce: 0.016247
[00:20:49.053] iteration 2893 : loss : 0.075841, loss_ce: 0.017450
[00:20:49.340] iteration 2894 : loss : 0.095827, loss_ce: 0.034613
[00:20:49.627] iteration 2895 : loss : 0.143600, loss_ce: 0.015620
[00:20:49.914] iteration 2896 : loss : 0.090232, loss_ce: 0.024130
[00:20:50.205] iteration 2897 : loss : 0.085710, loss_ce: 0.015396
[00:20:50.496] iteration 2898 : loss : 0.092781, loss_ce: 0.032340
[00:20:50.785] iteration 2899 : loss : 0.095648, loss_ce: 0.023668
[00:20:51.077] iteration 2900 : loss : 0.079501, loss_ce: 0.019626
[00:20:51.379] iteration 2901 : loss : 0.201373, loss_ce: 0.015622
[00:20:51.669] iteration 2902 : loss : 0.106206, loss_ce: 0.028302
[00:20:51.962] iteration 2903 : loss : 0.082936, loss_ce: 0.027745
[00:20:52.256] iteration 2904 : loss : 0.087136, loss_ce: 0.031163
[00:20:52.550] iteration 2905 : loss : 0.158429, loss_ce: 0.045583
[00:20:52.843] iteration 2906 : loss : 0.143664, loss_ce: 0.031339
[00:20:53.134] iteration 2907 : loss : 0.197024, loss_ce: 0.023561
[00:20:53.428] iteration 2908 : loss : 0.103633, loss_ce: 0.025327
[00:20:53.723] iteration 2909 : loss : 0.092434, loss_ce: 0.032461
[00:20:54.016] iteration 2910 : loss : 0.121793, loss_ce: 0.031115
[00:20:54.308] iteration 2911 : loss : 0.188980, loss_ce: 0.015947
[00:20:54.599] iteration 2912 : loss : 0.136980, loss_ce: 0.024664
[00:20:54.895] iteration 2913 : loss : 0.078950, loss_ce: 0.029446
[00:20:55.188] iteration 2914 : loss : 0.102790, loss_ce: 0.030660
[00:20:55.478] iteration 2915 : loss : 0.116462, loss_ce: 0.034215
[00:20:55.775] iteration 2916 : loss : 0.125322, loss_ce: 0.031331
[00:20:56.067] iteration 2917 : loss : 0.140431, loss_ce: 0.020907
[00:20:56.358] iteration 2918 : loss : 0.112338, loss_ce: 0.029820
[00:20:56.441] iteration 2919 : loss : 0.167318, loss_ce: 0.033972
[00:21:12.480] iteration 2920 : loss : 0.205418, loss_ce: 0.029466
[00:21:12.779] iteration 2921 : loss : 0.142646, loss_ce: 0.027999
[00:21:13.069] iteration 2922 : loss : 0.097105, loss_ce: 0.028354
[00:21:13.357] iteration 2923 : loss : 0.097070, loss_ce: 0.022670
[00:21:13.644] iteration 2924 : loss : 0.116698, loss_ce: 0.032252
[00:21:13.930] iteration 2925 : loss : 0.094918, loss_ce: 0.020817
[00:21:14.215] iteration 2926 : loss : 0.260622, loss_ce: 0.012168
[00:21:14.504] iteration 2927 : loss : 0.120720, loss_ce: 0.042195
[00:21:14.791] iteration 2928 : loss : 0.090436, loss_ce: 0.024420
[00:21:15.082] iteration 2929 : loss : 0.139932, loss_ce: 0.021426
[00:21:15.369] iteration 2930 : loss : 0.124794, loss_ce: 0.020510
[00:21:15.664] iteration 2931 : loss : 0.255204, loss_ce: 0.013504
[00:21:15.954] iteration 2932 : loss : 0.190840, loss_ce: 0.022832
[00:21:16.245] iteration 2933 : loss : 0.127640, loss_ce: 0.031064
[00:21:16.535] iteration 2934 : loss : 0.097906, loss_ce: 0.035578
[00:21:16.824] iteration 2935 : loss : 0.095869, loss_ce: 0.021382
[00:21:17.113] iteration 2936 : loss : 0.090764, loss_ce: 0.029203
[00:21:17.403] iteration 2937 : loss : 0.157080, loss_ce: 0.015879
[00:21:17.692] iteration 2938 : loss : 0.282080, loss_ce: 0.028614
[00:21:17.981] iteration 2939 : loss : 0.091641, loss_ce: 0.039901
[00:21:18.272] iteration 2940 : loss : 0.197611, loss_ce: 0.024228
[00:21:18.576] iteration 2941 : loss : 0.085823, loss_ce: 0.023950
[00:21:18.867] iteration 2942 : loss : 0.144978, loss_ce: 0.015821
[00:21:19.157] iteration 2943 : loss : 0.078937, loss_ce: 0.022446
[00:21:19.446] iteration 2944 : loss : 0.154114, loss_ce: 0.023739
[00:21:19.735] iteration 2945 : loss : 0.116743, loss_ce: 0.045228
[00:21:20.025] iteration 2946 : loss : 0.114529, loss_ce: 0.033771
[00:21:20.312] iteration 2947 : loss : 0.186364, loss_ce: 0.020385
[00:21:20.600] iteration 2948 : loss : 0.119045, loss_ce: 0.021613
[00:21:20.889] iteration 2949 : loss : 0.158650, loss_ce: 0.024206
[00:21:21.176] iteration 2950 : loss : 0.194434, loss_ce: 0.014722
[00:21:21.466] iteration 2951 : loss : 0.076721, loss_ce: 0.026120
[00:21:21.753] iteration 2952 : loss : 0.098506, loss_ce: 0.031298
[00:21:22.038] iteration 2953 : loss : 0.118864, loss_ce: 0.028962
[00:21:22.325] iteration 2954 : loss : 0.182790, loss_ce: 0.019724
[00:21:22.617] iteration 2955 : loss : 0.081549, loss_ce: 0.029516
[00:21:22.903] iteration 2956 : loss : 0.120362, loss_ce: 0.013758
[00:21:23.189] iteration 2957 : loss : 0.167082, loss_ce: 0.051845
[00:21:23.476] iteration 2958 : loss : 0.064133, loss_ce: 0.025222
[00:21:23.763] iteration 2959 : loss : 0.099060, loss_ce: 0.013847
[00:21:24.050] iteration 2960 : loss : 0.124400, loss_ce: 0.023509
[00:21:24.353] iteration 2961 : loss : 0.092948, loss_ce: 0.024590
[00:21:24.642] iteration 2962 : loss : 0.190487, loss_ce: 0.033469
[00:21:24.927] iteration 2963 : loss : 0.110599, loss_ce: 0.034409
[00:21:25.217] iteration 2964 : loss : 0.115868, loss_ce: 0.030023
[00:21:25.508] iteration 2965 : loss : 0.112077, loss_ce: 0.040580
[00:21:25.798] iteration 2966 : loss : 0.109893, loss_ce: 0.025412
[00:21:26.086] iteration 2967 : loss : 0.115346, loss_ce: 0.022812
[00:21:26.372] iteration 2968 : loss : 0.149637, loss_ce: 0.023204
[00:21:26.660] iteration 2969 : loss : 0.086759, loss_ce: 0.026982
[00:21:26.946] iteration 2970 : loss : 0.119050, loss_ce: 0.015062
[00:21:27.234] iteration 2971 : loss : 0.082860, loss_ce: 0.026999
[00:21:27.525] iteration 2972 : loss : 0.141741, loss_ce: 0.043414
[00:21:27.811] iteration 2973 : loss : 0.102259, loss_ce: 0.038038
[00:21:28.098] iteration 2974 : loss : 0.095620, loss_ce: 0.035147
[00:21:28.387] iteration 2975 : loss : 0.100426, loss_ce: 0.032876
[00:21:28.677] iteration 2976 : loss : 0.127730, loss_ce: 0.028980
[00:21:28.963] iteration 2977 : loss : 0.095399, loss_ce: 0.033908
[00:21:29.252] iteration 2978 : loss : 0.085928, loss_ce: 0.046243
[00:21:29.538] iteration 2979 : loss : 0.100955, loss_ce: 0.035426
[00:21:29.825] iteration 2980 : loss : 0.125692, loss_ce: 0.030633
[00:21:30.134] iteration 2981 : loss : 0.211219, loss_ce: 0.015184
[00:21:30.420] iteration 2982 : loss : 0.080029, loss_ce: 0.027288
[00:21:30.706] iteration 2983 : loss : 0.124687, loss_ce: 0.017024
[00:21:30.994] iteration 2984 : loss : 0.136017, loss_ce: 0.018894
[00:21:31.281] iteration 2985 : loss : 0.128670, loss_ce: 0.029035
[00:21:31.567] iteration 2986 : loss : 0.163482, loss_ce: 0.026980
[00:21:31.855] iteration 2987 : loss : 0.163957, loss_ce: 0.038437
[00:21:32.145] iteration 2988 : loss : 0.133394, loss_ce: 0.030013
[00:21:32.431] iteration 2989 : loss : 0.102793, loss_ce: 0.019741
[00:21:32.721] iteration 2990 : loss : 0.181812, loss_ce: 0.016691
[00:21:33.008] iteration 2991 : loss : 0.178542, loss_ce: 0.015417
[00:21:33.294] iteration 2992 : loss : 0.107265, loss_ce: 0.039466
[00:21:33.579] iteration 2993 : loss : 0.162176, loss_ce: 0.026613
[00:21:33.870] iteration 2994 : loss : 0.179837, loss_ce: 0.028070
[00:21:34.157] iteration 2995 : loss : 0.100639, loss_ce: 0.040778
[00:21:34.443] iteration 2996 : loss : 0.098902, loss_ce: 0.036004
[00:21:34.728] iteration 2997 : loss : 0.098021, loss_ce: 0.016455
[00:21:35.016] iteration 2998 : loss : 0.125713, loss_ce: 0.043463
[00:21:35.307] iteration 2999 : loss : 0.087598, loss_ce: 0.029106
[00:21:35.598] iteration 3000 : loss : 0.114907, loss_ce: 0.031163
[00:21:35.902] iteration 3001 : loss : 0.104249, loss_ce: 0.029424
[00:21:36.191] iteration 3002 : loss : 0.121951, loss_ce: 0.051348
[00:21:36.477] iteration 3003 : loss : 0.085116, loss_ce: 0.028065
[00:21:36.765] iteration 3004 : loss : 0.134074, loss_ce: 0.024628
[00:21:37.051] iteration 3005 : loss : 0.112766, loss_ce: 0.045718
[00:21:37.339] iteration 3006 : loss : 0.151358, loss_ce: 0.029215
[00:21:37.627] iteration 3007 : loss : 0.110392, loss_ce: 0.046354
[00:21:37.914] iteration 3008 : loss : 0.090795, loss_ce: 0.030392
[00:21:38.202] iteration 3009 : loss : 0.135230, loss_ce: 0.030147
[00:21:38.487] iteration 3010 : loss : 0.104813, loss_ce: 0.029760
[00:21:38.778] iteration 3011 : loss : 0.149957, loss_ce: 0.030715
[00:21:39.070] iteration 3012 : loss : 0.096405, loss_ce: 0.030832
[00:21:39.357] iteration 3013 : loss : 0.076457, loss_ce: 0.024479
[00:21:39.643] iteration 3014 : loss : 0.112305, loss_ce: 0.023333
[00:21:39.932] iteration 3015 : loss : 0.193762, loss_ce: 0.025870
[00:21:40.223] iteration 3016 : loss : 0.156034, loss_ce: 0.009564
[00:21:40.509] iteration 3017 : loss : 0.112816, loss_ce: 0.027343
[00:21:40.798] iteration 3018 : loss : 0.137736, loss_ce: 0.029886
[00:21:41.083] iteration 3019 : loss : 0.113103, loss_ce: 0.040530
[00:21:41.372] iteration 3020 : loss : 0.080605, loss_ce: 0.020153
[00:21:41.680] iteration 3021 : loss : 0.149678, loss_ce: 0.018018
[00:21:41.968] iteration 3022 : loss : 0.147910, loss_ce: 0.039541
[00:21:42.256] iteration 3023 : loss : 0.106595, loss_ce: 0.035675
[00:21:42.544] iteration 3024 : loss : 0.179015, loss_ce: 0.010217
[00:21:42.831] iteration 3025 : loss : 0.161322, loss_ce: 0.010711
[00:21:43.120] iteration 3026 : loss : 0.144001, loss_ce: 0.024838
[00:21:43.407] iteration 3027 : loss : 0.152980, loss_ce: 0.014755
[00:21:43.696] iteration 3028 : loss : 0.097519, loss_ce: 0.034124
[00:21:43.983] iteration 3029 : loss : 0.093681, loss_ce: 0.028291
[00:21:44.270] iteration 3030 : loss : 0.096804, loss_ce: 0.035141
[00:21:44.557] iteration 3031 : loss : 0.091624, loss_ce: 0.019823
[00:21:44.847] iteration 3032 : loss : 0.102997, loss_ce: 0.048148
[00:21:45.137] iteration 3033 : loss : 0.152782, loss_ce: 0.027386
[00:21:45.427] iteration 3034 : loss : 0.112035, loss_ce: 0.039410
[00:21:45.718] iteration 3035 : loss : 0.101403, loss_ce: 0.028097
[00:21:46.005] iteration 3036 : loss : 0.110932, loss_ce: 0.039330
[00:21:46.292] iteration 3037 : loss : 0.181444, loss_ce: 0.067460
[00:21:46.581] iteration 3038 : loss : 0.153584, loss_ce: 0.046015
[00:21:46.871] iteration 3039 : loss : 0.111158, loss_ce: 0.023605
[00:21:47.159] iteration 3040 : loss : 0.122713, loss_ce: 0.028616
[00:21:47.463] iteration 3041 : loss : 0.106584, loss_ce: 0.033864
[00:21:47.753] iteration 3042 : loss : 0.135081, loss_ce: 0.030198
[00:21:48.050] iteration 3043 : loss : 0.124313, loss_ce: 0.041138
[00:21:48.338] iteration 3044 : loss : 0.136007, loss_ce: 0.038630
[00:21:48.630] iteration 3045 : loss : 0.196695, loss_ce: 0.021935
[00:21:48.921] iteration 3046 : loss : 0.126083, loss_ce: 0.036531
[00:21:49.215] iteration 3047 : loss : 0.091000, loss_ce: 0.031555
[00:21:49.504] iteration 3048 : loss : 0.112647, loss_ce: 0.054937
[00:21:49.794] iteration 3049 : loss : 0.130476, loss_ce: 0.023973
[00:21:50.081] iteration 3050 : loss : 0.107376, loss_ce: 0.042773
[00:21:50.372] iteration 3051 : loss : 0.097880, loss_ce: 0.025451
[00:21:50.664] iteration 3052 : loss : 0.086724, loss_ce: 0.018695
[00:21:50.955] iteration 3053 : loss : 0.087877, loss_ce: 0.034766
[00:21:51.247] iteration 3054 : loss : 0.140746, loss_ce: 0.029974
[00:21:51.539] iteration 3055 : loss : 0.098418, loss_ce: 0.031196
[00:21:51.831] iteration 3056 : loss : 0.083481, loss_ce: 0.025768
[00:21:52.120] iteration 3057 : loss : 0.087528, loss_ce: 0.025747
[00:21:52.200] iteration 3058 : loss : 0.521267, loss_ce: 0.000419
[00:22:09.032] iteration 3059 : loss : 0.152273, loss_ce: 0.016554
[00:22:09.317] iteration 3060 : loss : 0.096338, loss_ce: 0.034925
[00:22:09.617] iteration 3061 : loss : 0.182805, loss_ce: 0.037149
[00:22:09.902] iteration 3062 : loss : 0.180433, loss_ce: 0.023431
[00:22:10.189] iteration 3063 : loss : 0.103812, loss_ce: 0.029886
[00:22:10.480] iteration 3064 : loss : 0.082088, loss_ce: 0.016919
[00:22:10.768] iteration 3065 : loss : 0.085975, loss_ce: 0.023581
[00:22:11.056] iteration 3066 : loss : 0.075911, loss_ce: 0.024176
[00:22:11.341] iteration 3067 : loss : 0.123116, loss_ce: 0.028123
[00:22:11.628] iteration 3068 : loss : 0.141603, loss_ce: 0.040616
[00:22:11.916] iteration 3069 : loss : 0.138073, loss_ce: 0.017200
[00:22:12.203] iteration 3070 : loss : 0.113860, loss_ce: 0.030369
[00:22:12.494] iteration 3071 : loss : 0.099506, loss_ce: 0.022282
[00:22:12.779] iteration 3072 : loss : 0.158907, loss_ce: 0.060539
[00:22:13.064] iteration 3073 : loss : 0.119253, loss_ce: 0.043129
[00:22:13.352] iteration 3074 : loss : 0.089897, loss_ce: 0.035044
[00:22:13.642] iteration 3075 : loss : 0.244805, loss_ce: 0.012818
[00:22:13.931] iteration 3076 : loss : 0.080976, loss_ce: 0.033009
[00:22:14.216] iteration 3077 : loss : 0.082364, loss_ce: 0.023627
[00:22:14.502] iteration 3078 : loss : 0.106136, loss_ce: 0.036107
[00:22:14.789] iteration 3079 : loss : 0.122596, loss_ce: 0.031045
[00:22:15.077] iteration 3080 : loss : 0.100096, loss_ce: 0.022121
[00:22:15.383] iteration 3081 : loss : 0.098846, loss_ce: 0.023803
[00:22:15.674] iteration 3082 : loss : 0.072539, loss_ce: 0.017612
[00:22:15.960] iteration 3083 : loss : 0.109186, loss_ce: 0.019560
[00:22:16.250] iteration 3084 : loss : 0.144237, loss_ce: 0.034909
[00:22:16.535] iteration 3085 : loss : 0.166193, loss_ce: 0.019837
[00:22:16.822] iteration 3086 : loss : 0.133451, loss_ce: 0.037008
[00:22:17.111] iteration 3087 : loss : 0.093990, loss_ce: 0.014245
[00:22:17.401] iteration 3088 : loss : 0.124187, loss_ce: 0.023975
[00:22:17.686] iteration 3089 : loss : 0.083348, loss_ce: 0.035903
[00:22:17.972] iteration 3090 : loss : 0.196052, loss_ce: 0.010317
[00:22:18.259] iteration 3091 : loss : 0.076835, loss_ce: 0.016474
[00:22:18.547] iteration 3092 : loss : 0.094305, loss_ce: 0.035921
[00:22:18.833] iteration 3093 : loss : 0.097853, loss_ce: 0.024503
[00:22:19.119] iteration 3094 : loss : 0.100922, loss_ce: 0.033470
[00:22:19.405] iteration 3095 : loss : 0.128502, loss_ce: 0.020102
[00:22:19.692] iteration 3096 : loss : 0.161484, loss_ce: 0.031440
[00:22:19.979] iteration 3097 : loss : 0.133664, loss_ce: 0.022060
[00:22:20.268] iteration 3098 : loss : 0.095649, loss_ce: 0.037564
[00:22:20.559] iteration 3099 : loss : 0.101268, loss_ce: 0.019582
[00:22:20.844] iteration 3100 : loss : 0.103369, loss_ce: 0.023281
[00:22:21.146] iteration 3101 : loss : 0.104285, loss_ce: 0.031734
[00:22:21.432] iteration 3102 : loss : 0.095825, loss_ce: 0.029751
[00:22:21.718] iteration 3103 : loss : 0.102795, loss_ce: 0.035181
[00:22:22.005] iteration 3104 : loss : 0.139417, loss_ce: 0.024681
[00:22:22.292] iteration 3105 : loss : 0.105927, loss_ce: 0.025466
[00:22:22.580] iteration 3106 : loss : 0.092914, loss_ce: 0.044881
[00:22:22.869] iteration 3107 : loss : 0.110717, loss_ce: 0.036713
[00:22:23.155] iteration 3108 : loss : 0.101859, loss_ce: 0.030403
[00:22:23.443] iteration 3109 : loss : 0.156299, loss_ce: 0.032204
[00:22:23.730] iteration 3110 : loss : 0.179713, loss_ce: 0.032598
[00:22:24.018] iteration 3111 : loss : 0.088310, loss_ce: 0.033698
[00:22:24.308] iteration 3112 : loss : 0.099936, loss_ce: 0.033806
[00:22:24.597] iteration 3113 : loss : 0.101184, loss_ce: 0.030313
[00:22:24.886] iteration 3114 : loss : 0.107621, loss_ce: 0.022044
[00:22:25.172] iteration 3115 : loss : 0.104467, loss_ce: 0.018604
[00:22:25.459] iteration 3116 : loss : 0.141013, loss_ce: 0.029996
[00:22:25.747] iteration 3117 : loss : 0.140219, loss_ce: 0.031468
[00:22:26.035] iteration 3118 : loss : 0.147940, loss_ce: 0.032259
[00:22:26.324] iteration 3119 : loss : 0.130513, loss_ce: 0.020825
[00:22:26.611] iteration 3120 : loss : 0.080850, loss_ce: 0.027834
[00:22:26.913] iteration 3121 : loss : 0.090788, loss_ce: 0.018663
[00:22:27.203] iteration 3122 : loss : 0.090811, loss_ce: 0.027346
[00:22:27.493] iteration 3123 : loss : 0.091103, loss_ce: 0.032178
[00:22:27.781] iteration 3124 : loss : 0.138782, loss_ce: 0.024355
[00:22:28.068] iteration 3125 : loss : 0.104979, loss_ce: 0.027418
[00:22:28.354] iteration 3126 : loss : 0.163184, loss_ce: 0.028372
[00:22:28.642] iteration 3127 : loss : 0.081013, loss_ce: 0.018195
[00:22:28.929] iteration 3128 : loss : 0.148981, loss_ce: 0.028496
[00:22:29.219] iteration 3129 : loss : 0.140644, loss_ce: 0.037442
[00:22:29.509] iteration 3130 : loss : 0.109699, loss_ce: 0.026163
[00:22:29.797] iteration 3131 : loss : 0.108786, loss_ce: 0.039327
[00:22:30.084] iteration 3132 : loss : 0.072725, loss_ce: 0.019371
[00:22:30.373] iteration 3133 : loss : 0.149437, loss_ce: 0.030856
[00:22:30.661] iteration 3134 : loss : 0.085625, loss_ce: 0.029155
[00:22:30.948] iteration 3135 : loss : 0.123221, loss_ce: 0.037503
[00:22:31.237] iteration 3136 : loss : 0.086773, loss_ce: 0.029934
[00:22:31.527] iteration 3137 : loss : 0.111882, loss_ce: 0.023846
[00:22:31.814] iteration 3138 : loss : 0.119525, loss_ce: 0.022907
[00:22:32.100] iteration 3139 : loss : 0.089483, loss_ce: 0.022087
[00:22:32.390] iteration 3140 : loss : 0.076992, loss_ce: 0.028339
[00:22:32.695] iteration 3141 : loss : 0.133515, loss_ce: 0.057565
[00:22:32.983] iteration 3142 : loss : 0.115356, loss_ce: 0.016807
[00:22:33.272] iteration 3143 : loss : 0.107648, loss_ce: 0.030293
[00:22:33.563] iteration 3144 : loss : 0.109650, loss_ce: 0.051142
[00:22:33.850] iteration 3145 : loss : 0.162498, loss_ce: 0.023155
[00:22:34.138] iteration 3146 : loss : 0.063171, loss_ce: 0.029218
[00:22:34.430] iteration 3147 : loss : 0.100232, loss_ce: 0.016939
[00:22:34.720] iteration 3148 : loss : 0.094493, loss_ce: 0.035393
[00:22:35.008] iteration 3149 : loss : 0.149568, loss_ce: 0.019395
[00:22:35.297] iteration 3150 : loss : 0.149961, loss_ce: 0.056195
[00:22:35.584] iteration 3151 : loss : 0.132930, loss_ce: 0.021192
[00:22:35.875] iteration 3152 : loss : 0.078072, loss_ce: 0.014800
[00:22:36.162] iteration 3153 : loss : 0.127074, loss_ce: 0.016416
[00:22:36.449] iteration 3154 : loss : 0.098389, loss_ce: 0.038102
[00:22:36.738] iteration 3155 : loss : 0.077723, loss_ce: 0.029372
[00:22:37.026] iteration 3156 : loss : 0.092907, loss_ce: 0.041493
[00:22:37.314] iteration 3157 : loss : 0.118383, loss_ce: 0.034805
[00:22:37.602] iteration 3158 : loss : 0.144584, loss_ce: 0.032118
[00:22:37.893] iteration 3159 : loss : 0.121519, loss_ce: 0.024835
[00:22:38.179] iteration 3160 : loss : 0.166005, loss_ce: 0.020622
[00:22:38.480] iteration 3161 : loss : 0.138766, loss_ce: 0.024019
[00:22:38.771] iteration 3162 : loss : 0.149827, loss_ce: 0.013149
[00:22:39.058] iteration 3163 : loss : 0.249278, loss_ce: 0.015858
[00:22:39.345] iteration 3164 : loss : 0.107367, loss_ce: 0.032284
[00:22:39.632] iteration 3165 : loss : 0.117368, loss_ce: 0.041390
[00:22:39.921] iteration 3166 : loss : 0.174379, loss_ce: 0.024777
[00:22:40.212] iteration 3167 : loss : 0.170545, loss_ce: 0.041213
[00:22:40.499] iteration 3168 : loss : 0.111285, loss_ce: 0.039982
[00:22:40.785] iteration 3169 : loss : 0.159029, loss_ce: 0.050732
[00:22:41.072] iteration 3170 : loss : 0.129624, loss_ce: 0.035486
[00:22:41.362] iteration 3171 : loss : 0.167979, loss_ce: 0.030257
[00:22:41.650] iteration 3172 : loss : 0.152282, loss_ce: 0.038890
[00:22:41.941] iteration 3173 : loss : 0.201718, loss_ce: 0.012222
[00:22:42.232] iteration 3174 : loss : 0.105794, loss_ce: 0.036933
[00:22:42.524] iteration 3175 : loss : 0.119787, loss_ce: 0.032118
[00:22:42.814] iteration 3176 : loss : 0.094153, loss_ce: 0.036258
[00:22:43.100] iteration 3177 : loss : 0.098669, loss_ce: 0.035352
[00:22:43.386] iteration 3178 : loss : 0.112855, loss_ce: 0.030374
[00:22:43.678] iteration 3179 : loss : 0.120256, loss_ce: 0.026120
[00:22:43.966] iteration 3180 : loss : 0.133732, loss_ce: 0.056620
[00:22:44.273] iteration 3181 : loss : 0.099247, loss_ce: 0.014628
[00:22:44.565] iteration 3182 : loss : 0.131636, loss_ce: 0.025841
[00:22:44.857] iteration 3183 : loss : 0.118897, loss_ce: 0.014130
[00:22:45.148] iteration 3184 : loss : 0.151354, loss_ce: 0.011065
[00:22:45.441] iteration 3185 : loss : 0.169546, loss_ce: 0.032531
[00:22:45.731] iteration 3186 : loss : 0.127729, loss_ce: 0.036343
[00:22:46.021] iteration 3187 : loss : 0.210153, loss_ce: 0.025440
[00:22:46.311] iteration 3188 : loss : 0.107648, loss_ce: 0.027358
[00:22:46.602] iteration 3189 : loss : 0.102638, loss_ce: 0.046325
[00:22:46.894] iteration 3190 : loss : 0.154255, loss_ce: 0.042881
[00:22:47.184] iteration 3191 : loss : 0.200758, loss_ce: 0.022150
[00:22:47.470] iteration 3192 : loss : 0.128958, loss_ce: 0.025690
[00:22:47.758] iteration 3193 : loss : 0.116466, loss_ce: 0.038323
[00:22:48.050] iteration 3194 : loss : 0.107943, loss_ce: 0.049082
[00:22:48.340] iteration 3195 : loss : 0.162288, loss_ce: 0.030352
[00:22:48.629] iteration 3196 : loss : 0.195468, loss_ce: 0.035679
[00:22:48.706] iteration 3197 : loss : 0.504631, loss_ce: 0.012216
[00:23:05.365] iteration 3198 : loss : 0.131420, loss_ce: 0.025741
[00:23:05.650] iteration 3199 : loss : 0.101151, loss_ce: 0.030264
[00:23:05.936] iteration 3200 : loss : 0.099662, loss_ce: 0.023132
[00:23:06.239] iteration 3201 : loss : 0.156827, loss_ce: 0.026717
[00:23:06.524] iteration 3202 : loss : 0.074389, loss_ce: 0.021770
[00:23:06.813] iteration 3203 : loss : 0.103556, loss_ce: 0.020478
[00:23:07.104] iteration 3204 : loss : 0.087965, loss_ce: 0.025389
[00:23:07.393] iteration 3205 : loss : 0.130593, loss_ce: 0.033844
[00:23:07.682] iteration 3206 : loss : 0.100085, loss_ce: 0.039532
[00:23:07.973] iteration 3207 : loss : 0.160459, loss_ce: 0.025488
[00:23:08.257] iteration 3208 : loss : 0.167431, loss_ce: 0.018517
[00:23:08.544] iteration 3209 : loss : 0.106508, loss_ce: 0.057805
[00:23:08.834] iteration 3210 : loss : 0.092904, loss_ce: 0.035325
[00:23:09.122] iteration 3211 : loss : 0.139405, loss_ce: 0.038262
[00:23:09.413] iteration 3212 : loss : 0.099165, loss_ce: 0.028054
[00:23:09.703] iteration 3213 : loss : 0.124511, loss_ce: 0.012301
[00:23:09.994] iteration 3214 : loss : 0.171619, loss_ce: 0.018817
[00:23:10.281] iteration 3215 : loss : 0.157388, loss_ce: 0.015740
[00:23:10.571] iteration 3216 : loss : 0.091687, loss_ce: 0.024325
[00:23:10.860] iteration 3217 : loss : 0.087571, loss_ce: 0.030310
[00:23:11.150] iteration 3218 : loss : 0.097329, loss_ce: 0.035366
[00:23:11.440] iteration 3219 : loss : 0.127718, loss_ce: 0.027800
[00:23:11.733] iteration 3220 : loss : 0.098285, loss_ce: 0.016820
[00:23:12.036] iteration 3221 : loss : 0.102695, loss_ce: 0.028697
[00:23:12.326] iteration 3222 : loss : 0.114344, loss_ce: 0.041664
[00:23:12.613] iteration 3223 : loss : 0.102014, loss_ce: 0.032760
[00:23:12.905] iteration 3224 : loss : 0.165407, loss_ce: 0.013931
[00:23:13.192] iteration 3225 : loss : 0.093705, loss_ce: 0.023526
[00:23:13.480] iteration 3226 : loss : 0.134893, loss_ce: 0.028138
[00:23:13.771] iteration 3227 : loss : 0.079084, loss_ce: 0.022250
[00:23:14.060] iteration 3228 : loss : 0.159082, loss_ce: 0.040202
[00:23:14.349] iteration 3229 : loss : 0.085636, loss_ce: 0.025849
[00:23:14.638] iteration 3230 : loss : 0.086402, loss_ce: 0.033453
[00:23:14.926] iteration 3231 : loss : 0.091454, loss_ce: 0.035308
[00:23:15.219] iteration 3232 : loss : 0.104419, loss_ce: 0.033953
[00:23:15.507] iteration 3233 : loss : 0.135511, loss_ce: 0.056406
[00:23:15.796] iteration 3234 : loss : 0.107013, loss_ce: 0.025354
[00:23:16.084] iteration 3235 : loss : 0.085593, loss_ce: 0.024710
[00:23:16.370] iteration 3236 : loss : 0.127679, loss_ce: 0.044871
[00:23:16.659] iteration 3237 : loss : 0.143050, loss_ce: 0.023548
[00:23:16.949] iteration 3238 : loss : 0.076948, loss_ce: 0.025070
[00:23:17.239] iteration 3239 : loss : 0.192612, loss_ce: 0.023483
[00:23:17.528] iteration 3240 : loss : 0.119864, loss_ce: 0.035112
[00:23:17.834] iteration 3241 : loss : 0.115570, loss_ce: 0.026259
[00:23:18.121] iteration 3242 : loss : 0.083019, loss_ce: 0.019695
[00:23:18.409] iteration 3243 : loss : 0.116260, loss_ce: 0.018091
[00:23:18.698] iteration 3244 : loss : 0.124597, loss_ce: 0.016891
[00:23:18.985] iteration 3245 : loss : 0.158823, loss_ce: 0.033034
[00:23:19.275] iteration 3246 : loss : 0.106922, loss_ce: 0.011915
[00:23:19.562] iteration 3247 : loss : 0.121895, loss_ce: 0.029549
[00:23:19.853] iteration 3248 : loss : 0.090732, loss_ce: 0.029703
[00:23:20.141] iteration 3249 : loss : 0.080838, loss_ce: 0.015887
[00:23:20.427] iteration 3250 : loss : 0.106849, loss_ce: 0.054866
[00:23:20.717] iteration 3251 : loss : 0.092059, loss_ce: 0.037337
[00:23:21.003] iteration 3252 : loss : 0.070676, loss_ce: 0.030122
[00:23:21.289] iteration 3253 : loss : 0.118947, loss_ce: 0.040636
[00:23:21.575] iteration 3254 : loss : 0.178063, loss_ce: 0.023887
[00:23:21.862] iteration 3255 : loss : 0.147901, loss_ce: 0.022510
[00:23:22.150] iteration 3256 : loss : 0.087525, loss_ce: 0.016262
[00:23:22.437] iteration 3257 : loss : 0.083303, loss_ce: 0.020572
[00:23:22.723] iteration 3258 : loss : 0.120248, loss_ce: 0.028850
[00:23:23.011] iteration 3259 : loss : 0.131004, loss_ce: 0.022885
[00:23:23.300] iteration 3260 : loss : 0.092329, loss_ce: 0.035139
[00:23:23.605] iteration 3261 : loss : 0.157178, loss_ce: 0.024104
[00:23:23.893] iteration 3262 : loss : 0.101932, loss_ce: 0.026621
[00:23:24.186] iteration 3263 : loss : 0.129006, loss_ce: 0.041058
[00:23:24.474] iteration 3264 : loss : 0.140107, loss_ce: 0.023406
[00:23:24.760] iteration 3265 : loss : 0.156383, loss_ce: 0.028936
[00:23:25.047] iteration 3266 : loss : 0.106714, loss_ce: 0.012033
[00:23:25.340] iteration 3267 : loss : 0.106470, loss_ce: 0.036016
[00:23:25.632] iteration 3268 : loss : 0.099744, loss_ce: 0.034165
[00:23:25.919] iteration 3269 : loss : 0.141157, loss_ce: 0.020613
[00:23:26.204] iteration 3270 : loss : 0.089324, loss_ce: 0.023472
[00:23:26.496] iteration 3271 : loss : 0.076456, loss_ce: 0.032054
[00:23:26.783] iteration 3272 : loss : 0.198976, loss_ce: 0.029404
[00:23:27.069] iteration 3273 : loss : 0.096739, loss_ce: 0.033440
[00:23:27.356] iteration 3274 : loss : 0.229234, loss_ce: 0.015455
[00:23:27.642] iteration 3275 : loss : 0.096090, loss_ce: 0.046379
[00:23:27.929] iteration 3276 : loss : 0.087073, loss_ce: 0.012096
[00:23:28.215] iteration 3277 : loss : 0.074785, loss_ce: 0.025053
[00:23:28.503] iteration 3278 : loss : 0.099076, loss_ce: 0.034388
[00:23:28.792] iteration 3279 : loss : 0.118751, loss_ce: 0.019066
[00:23:29.080] iteration 3280 : loss : 0.131901, loss_ce: 0.023295
[00:23:29.383] iteration 3281 : loss : 0.106994, loss_ce: 0.030734
[00:23:29.670] iteration 3282 : loss : 0.093730, loss_ce: 0.026390
[00:23:29.955] iteration 3283 : loss : 0.143070, loss_ce: 0.016758
[00:23:30.245] iteration 3284 : loss : 0.243121, loss_ce: 0.020097
[00:23:30.534] iteration 3285 : loss : 0.084935, loss_ce: 0.034231
[00:23:30.822] iteration 3286 : loss : 0.145152, loss_ce: 0.035105
[00:23:31.108] iteration 3287 : loss : 0.146964, loss_ce: 0.031798
[00:23:31.395] iteration 3288 : loss : 0.105107, loss_ce: 0.037399
[00:23:31.680] iteration 3289 : loss : 0.146545, loss_ce: 0.033047
[00:23:31.967] iteration 3290 : loss : 0.153906, loss_ce: 0.032515
[00:23:32.257] iteration 3291 : loss : 0.108382, loss_ce: 0.029638
[00:23:32.544] iteration 3292 : loss : 0.098369, loss_ce: 0.034353
[00:23:32.831] iteration 3293 : loss : 0.087758, loss_ce: 0.036293
[00:23:33.119] iteration 3294 : loss : 0.118155, loss_ce: 0.022343
[00:23:33.408] iteration 3295 : loss : 0.123371, loss_ce: 0.034370
[00:23:33.695] iteration 3296 : loss : 0.101236, loss_ce: 0.019447
[00:23:33.982] iteration 3297 : loss : 0.146549, loss_ce: 0.034939
[00:23:34.271] iteration 3298 : loss : 0.162011, loss_ce: 0.020462
[00:23:34.558] iteration 3299 : loss : 0.110717, loss_ce: 0.032081
[00:23:34.849] iteration 3300 : loss : 0.137456, loss_ce: 0.024375
[00:23:35.153] iteration 3301 : loss : 0.079651, loss_ce: 0.025121
[00:23:35.443] iteration 3302 : loss : 0.124834, loss_ce: 0.007226
[00:23:35.731] iteration 3303 : loss : 0.147875, loss_ce: 0.023368
[00:23:36.020] iteration 3304 : loss : 0.069655, loss_ce: 0.023614
[00:23:36.310] iteration 3305 : loss : 0.106651, loss_ce: 0.029304
[00:23:36.596] iteration 3306 : loss : 0.105728, loss_ce: 0.044572
[00:23:36.888] iteration 3307 : loss : 0.311888, loss_ce: 0.011328
[00:23:37.175] iteration 3308 : loss : 0.085870, loss_ce: 0.029463
[00:23:37.462] iteration 3309 : loss : 0.083533, loss_ce: 0.032323
[00:23:37.751] iteration 3310 : loss : 0.080937, loss_ce: 0.027972
[00:23:38.038] iteration 3311 : loss : 0.063460, loss_ce: 0.019856
[00:23:38.328] iteration 3312 : loss : 0.094785, loss_ce: 0.045318
[00:23:38.616] iteration 3313 : loss : 0.117890, loss_ce: 0.029688
[00:23:38.903] iteration 3314 : loss : 0.115124, loss_ce: 0.019278
[00:23:39.190] iteration 3315 : loss : 0.074385, loss_ce: 0.018354
[00:23:39.479] iteration 3316 : loss : 0.099951, loss_ce: 0.024504
[00:23:39.766] iteration 3317 : loss : 0.117950, loss_ce: 0.024846
[00:23:40.056] iteration 3318 : loss : 0.146980, loss_ce: 0.012142
[00:23:40.345] iteration 3319 : loss : 0.194358, loss_ce: 0.009518
[00:23:40.632] iteration 3320 : loss : 0.098966, loss_ce: 0.012566
[00:23:40.936] iteration 3321 : loss : 0.124680, loss_ce: 0.036192
[00:23:41.223] iteration 3322 : loss : 0.114677, loss_ce: 0.040586
[00:23:41.512] iteration 3323 : loss : 0.145024, loss_ce: 0.027541
[00:23:41.805] iteration 3324 : loss : 0.128952, loss_ce: 0.021281
[00:23:42.093] iteration 3325 : loss : 0.079359, loss_ce: 0.025252
[00:23:42.386] iteration 3326 : loss : 0.106428, loss_ce: 0.036395
[00:23:42.679] iteration 3327 : loss : 0.097855, loss_ce: 0.031327
[00:23:42.969] iteration 3328 : loss : 0.166224, loss_ce: 0.007051
[00:23:43.259] iteration 3329 : loss : 0.092611, loss_ce: 0.028716
[00:23:43.551] iteration 3330 : loss : 0.122322, loss_ce: 0.020137
[00:23:43.842] iteration 3331 : loss : 0.068607, loss_ce: 0.025860
[00:23:44.134] iteration 3332 : loss : 0.083038, loss_ce: 0.034940
[00:23:44.423] iteration 3333 : loss : 0.118119, loss_ce: 0.029696
[00:23:44.712] iteration 3334 : loss : 0.101578, loss_ce: 0.021954
[00:23:45.006] iteration 3335 : loss : 0.138594, loss_ce: 0.015487
[00:23:45.087] iteration 3336 : loss : 0.488619, loss_ce: 0.009506
[00:24:01.531] iteration 3337 : loss : 0.088781, loss_ce: 0.030809
[00:24:01.818] iteration 3338 : loss : 0.134118, loss_ce: 0.013777
[00:24:02.102] iteration 3339 : loss : 0.110919, loss_ce: 0.040166
[00:24:02.392] iteration 3340 : loss : 0.119261, loss_ce: 0.024654
[00:24:02.702] iteration 3341 : loss : 0.129308, loss_ce: 0.033339
[00:24:02.991] iteration 3342 : loss : 0.105583, loss_ce: 0.020725
[00:24:03.279] iteration 3343 : loss : 0.148979, loss_ce: 0.017284
[00:24:03.564] iteration 3344 : loss : 0.101514, loss_ce: 0.022379
[00:24:03.850] iteration 3345 : loss : 0.081368, loss_ce: 0.027896
[00:24:04.135] iteration 3346 : loss : 0.120966, loss_ce: 0.017367
[00:24:04.422] iteration 3347 : loss : 0.223386, loss_ce: 0.021554
[00:24:04.708] iteration 3348 : loss : 0.093569, loss_ce: 0.039380
[00:24:04.993] iteration 3349 : loss : 0.104462, loss_ce: 0.034145
[00:24:05.283] iteration 3350 : loss : 0.178547, loss_ce: 0.019833
[00:24:05.570] iteration 3351 : loss : 0.079108, loss_ce: 0.018501
[00:24:05.854] iteration 3352 : loss : 0.106998, loss_ce: 0.023350
[00:24:06.140] iteration 3353 : loss : 0.069136, loss_ce: 0.024716
[00:24:06.425] iteration 3354 : loss : 0.083756, loss_ce: 0.027745
[00:24:06.714] iteration 3355 : loss : 0.122102, loss_ce: 0.034827
[00:24:07.000] iteration 3356 : loss : 0.157883, loss_ce: 0.022569
[00:24:07.286] iteration 3357 : loss : 0.078525, loss_ce: 0.020303
[00:24:07.573] iteration 3358 : loss : 0.075353, loss_ce: 0.016419
[00:24:07.861] iteration 3359 : loss : 0.150341, loss_ce: 0.040354
[00:24:08.147] iteration 3360 : loss : 0.148379, loss_ce: 0.026733
[00:24:08.448] iteration 3361 : loss : 0.088339, loss_ce: 0.021058
[00:24:08.735] iteration 3362 : loss : 0.085030, loss_ce: 0.021616
[00:24:09.020] iteration 3363 : loss : 0.148596, loss_ce: 0.022482
[00:24:09.307] iteration 3364 : loss : 0.090800, loss_ce: 0.033103
[00:24:09.595] iteration 3365 : loss : 0.102853, loss_ce: 0.033050
[00:24:09.881] iteration 3366 : loss : 0.110608, loss_ce: 0.028095
[00:24:10.171] iteration 3367 : loss : 0.094681, loss_ce: 0.017936
[00:24:10.459] iteration 3368 : loss : 0.120086, loss_ce: 0.028960
[00:24:10.744] iteration 3369 : loss : 0.190608, loss_ce: 0.012151
[00:24:11.031] iteration 3370 : loss : 0.084404, loss_ce: 0.019876
[00:24:11.317] iteration 3371 : loss : 0.154901, loss_ce: 0.013965
[00:24:11.603] iteration 3372 : loss : 0.086614, loss_ce: 0.022701
[00:24:11.892] iteration 3373 : loss : 0.098505, loss_ce: 0.036561
[00:24:12.177] iteration 3374 : loss : 0.103577, loss_ce: 0.024204
[00:24:12.464] iteration 3375 : loss : 0.103167, loss_ce: 0.039486
[00:24:12.751] iteration 3376 : loss : 0.126956, loss_ce: 0.021571
[00:24:13.039] iteration 3377 : loss : 0.090586, loss_ce: 0.030105
[00:24:13.326] iteration 3378 : loss : 0.089500, loss_ce: 0.023022
[00:24:13.615] iteration 3379 : loss : 0.114367, loss_ce: 0.030340
[00:24:13.902] iteration 3380 : loss : 0.087072, loss_ce: 0.024380
[00:24:14.203] iteration 3381 : loss : 0.141671, loss_ce: 0.017724
[00:24:14.491] iteration 3382 : loss : 0.093662, loss_ce: 0.041888
[00:24:14.777] iteration 3383 : loss : 0.089420, loss_ce: 0.023854
[00:24:15.067] iteration 3384 : loss : 0.143906, loss_ce: 0.021121
[00:24:15.357] iteration 3385 : loss : 0.127425, loss_ce: 0.023855
[00:24:15.643] iteration 3386 : loss : 0.088752, loss_ce: 0.030420
[00:24:15.933] iteration 3387 : loss : 0.161424, loss_ce: 0.036239
[00:24:16.220] iteration 3388 : loss : 0.095513, loss_ce: 0.033276
[00:24:16.508] iteration 3389 : loss : 0.138516, loss_ce: 0.022561
[00:24:16.794] iteration 3390 : loss : 0.099699, loss_ce: 0.017353
[00:24:17.081] iteration 3391 : loss : 0.073262, loss_ce: 0.016907
[00:24:17.369] iteration 3392 : loss : 0.109357, loss_ce: 0.029674
[00:24:17.656] iteration 3393 : loss : 0.119459, loss_ce: 0.024477
[00:24:17.944] iteration 3394 : loss : 0.100300, loss_ce: 0.016029
[00:24:18.231] iteration 3395 : loss : 0.094688, loss_ce: 0.024776
[00:24:18.517] iteration 3396 : loss : 0.088294, loss_ce: 0.021422
[00:24:18.806] iteration 3397 : loss : 0.228917, loss_ce: 0.008549
[00:24:19.092] iteration 3398 : loss : 0.079942, loss_ce: 0.019575
[00:24:19.379] iteration 3399 : loss : 0.163652, loss_ce: 0.024464
[00:24:19.666] iteration 3400 : loss : 0.073840, loss_ce: 0.019409
[00:24:19.966] iteration 3401 : loss : 0.156796, loss_ce: 0.022227
[00:24:20.256] iteration 3402 : loss : 0.055073, loss_ce: 0.018835
[00:24:20.542] iteration 3403 : loss : 0.075710, loss_ce: 0.033262
[00:24:20.831] iteration 3404 : loss : 0.108168, loss_ce: 0.027561
[00:24:21.118] iteration 3405 : loss : 0.189489, loss_ce: 0.036894
[00:24:21.405] iteration 3406 : loss : 0.088505, loss_ce: 0.013040
[00:24:21.695] iteration 3407 : loss : 0.067110, loss_ce: 0.017440
[00:24:21.984] iteration 3408 : loss : 0.154446, loss_ce: 0.014493
[00:24:22.271] iteration 3409 : loss : 0.119949, loss_ce: 0.038546
[00:24:22.558] iteration 3410 : loss : 0.101346, loss_ce: 0.029125
[00:24:22.846] iteration 3411 : loss : 0.129043, loss_ce: 0.015629
[00:24:23.134] iteration 3412 : loss : 0.104466, loss_ce: 0.019169
[00:24:23.420] iteration 3413 : loss : 0.069011, loss_ce: 0.020232
[00:24:23.708] iteration 3414 : loss : 0.094306, loss_ce: 0.026836
[00:24:23.996] iteration 3415 : loss : 0.091261, loss_ce: 0.035460
[00:24:24.283] iteration 3416 : loss : 0.070162, loss_ce: 0.036256
[00:24:24.571] iteration 3417 : loss : 0.124406, loss_ce: 0.008909
[00:24:24.857] iteration 3418 : loss : 0.092310, loss_ce: 0.027933
[00:24:25.145] iteration 3419 : loss : 0.111195, loss_ce: 0.033908
[00:24:25.434] iteration 3420 : loss : 0.056410, loss_ce: 0.013363
[00:24:25.739] iteration 3421 : loss : 0.092729, loss_ce: 0.036723
[00:24:26.029] iteration 3422 : loss : 0.117395, loss_ce: 0.026987
[00:24:26.316] iteration 3423 : loss : 0.132888, loss_ce: 0.026229
[00:24:26.606] iteration 3424 : loss : 0.100425, loss_ce: 0.033045
[00:24:26.894] iteration 3425 : loss : 0.086433, loss_ce: 0.027268
[00:24:27.180] iteration 3426 : loss : 0.078029, loss_ce: 0.030104
[00:24:27.469] iteration 3427 : loss : 0.104967, loss_ce: 0.024000
[00:24:27.756] iteration 3428 : loss : 0.079649, loss_ce: 0.032002
[00:24:28.044] iteration 3429 : loss : 0.091114, loss_ce: 0.028784
[00:24:28.332] iteration 3430 : loss : 0.175436, loss_ce: 0.037057
[00:24:28.619] iteration 3431 : loss : 0.101534, loss_ce: 0.046003
[00:24:28.906] iteration 3432 : loss : 0.085728, loss_ce: 0.023101
[00:24:29.195] iteration 3433 : loss : 0.152436, loss_ce: 0.016068
[00:24:29.484] iteration 3434 : loss : 0.074773, loss_ce: 0.016965
[00:24:29.772] iteration 3435 : loss : 0.174885, loss_ce: 0.018965
[00:24:30.058] iteration 3436 : loss : 0.196086, loss_ce: 0.019422
[00:24:30.350] iteration 3437 : loss : 0.160476, loss_ce: 0.046042
[00:24:30.638] iteration 3438 : loss : 0.099316, loss_ce: 0.040030
[00:24:30.924] iteration 3439 : loss : 0.087403, loss_ce: 0.035570
[00:24:31.212] iteration 3440 : loss : 0.144737, loss_ce: 0.038741
[00:24:31.515] iteration 3441 : loss : 0.127410, loss_ce: 0.034316
[00:24:31.802] iteration 3442 : loss : 0.085816, loss_ce: 0.036111
[00:24:32.091] iteration 3443 : loss : 0.078642, loss_ce: 0.030649
[00:24:32.380] iteration 3444 : loss : 0.100844, loss_ce: 0.022824
[00:24:32.669] iteration 3445 : loss : 0.072113, loss_ce: 0.018040
[00:24:32.955] iteration 3446 : loss : 0.067099, loss_ce: 0.031470
[00:24:33.243] iteration 3447 : loss : 0.083660, loss_ce: 0.031072
[00:24:33.532] iteration 3448 : loss : 0.080273, loss_ce: 0.021148
[00:24:33.819] iteration 3449 : loss : 0.077558, loss_ce: 0.021777
[00:24:34.107] iteration 3450 : loss : 0.077950, loss_ce: 0.017616
[00:24:34.395] iteration 3451 : loss : 0.090549, loss_ce: 0.022434
[00:24:34.683] iteration 3452 : loss : 0.070508, loss_ce: 0.021636
[00:24:34.971] iteration 3453 : loss : 0.093704, loss_ce: 0.035699
[00:24:35.258] iteration 3454 : loss : 0.097207, loss_ce: 0.033475
[00:24:35.549] iteration 3455 : loss : 0.074867, loss_ce: 0.013826
[00:24:35.834] iteration 3456 : loss : 0.175585, loss_ce: 0.018348
[00:24:36.124] iteration 3457 : loss : 0.116049, loss_ce: 0.035636
[00:24:36.415] iteration 3458 : loss : 0.135542, loss_ce: 0.024725
[00:24:36.704] iteration 3459 : loss : 0.124931, loss_ce: 0.042874
[00:24:36.995] iteration 3460 : loss : 0.125273, loss_ce: 0.023108
[00:24:37.303] iteration 3461 : loss : 0.148843, loss_ce: 0.029435
[00:24:37.594] iteration 3462 : loss : 0.133851, loss_ce: 0.030241
[00:24:37.882] iteration 3463 : loss : 0.072871, loss_ce: 0.022795
[00:24:38.171] iteration 3464 : loss : 0.093904, loss_ce: 0.025827
[00:24:38.464] iteration 3465 : loss : 0.148499, loss_ce: 0.019661
[00:24:38.756] iteration 3466 : loss : 0.098278, loss_ce: 0.043814
[00:24:39.048] iteration 3467 : loss : 0.090981, loss_ce: 0.013656
[00:24:39.338] iteration 3468 : loss : 0.111014, loss_ce: 0.044610
[00:24:39.630] iteration 3469 : loss : 0.133151, loss_ce: 0.024741
[00:24:39.922] iteration 3470 : loss : 0.078246, loss_ce: 0.023172
[00:24:40.213] iteration 3471 : loss : 0.113816, loss_ce: 0.030148
[00:24:40.501] iteration 3472 : loss : 0.102895, loss_ce: 0.031252
[00:24:40.793] iteration 3473 : loss : 0.196286, loss_ce: 0.025344
[00:24:41.084] iteration 3474 : loss : 0.101926, loss_ce: 0.040558
[00:24:41.163] iteration 3475 : loss : 0.479411, loss_ce: 0.006614
[00:24:57.418] iteration 3476 : loss : 0.068757, loss_ce: 0.020992
[00:24:57.703] iteration 3477 : loss : 0.108566, loss_ce: 0.048932
[00:24:57.988] iteration 3478 : loss : 0.095810, loss_ce: 0.024117
[00:24:58.274] iteration 3479 : loss : 0.100289, loss_ce: 0.038673
[00:24:58.566] iteration 3480 : loss : 0.156495, loss_ce: 0.024148
[00:24:58.874] iteration 3481 : loss : 0.089176, loss_ce: 0.030207
[00:24:59.160] iteration 3482 : loss : 0.122128, loss_ce: 0.026825
[00:24:59.443] iteration 3483 : loss : 0.135290, loss_ce: 0.020260
[00:24:59.732] iteration 3484 : loss : 0.106261, loss_ce: 0.047157
[00:25:00.020] iteration 3485 : loss : 0.090330, loss_ce: 0.016766
[00:25:00.313] iteration 3486 : loss : 0.134341, loss_ce: 0.034611
[00:25:00.605] iteration 3487 : loss : 0.108756, loss_ce: 0.030440
[00:25:00.899] iteration 3488 : loss : 0.087061, loss_ce: 0.019252
[00:25:01.184] iteration 3489 : loss : 0.086994, loss_ce: 0.022342
[00:25:01.472] iteration 3490 : loss : 0.094910, loss_ce: 0.040785
[00:25:01.763] iteration 3491 : loss : 0.092685, loss_ce: 0.021564
[00:25:02.050] iteration 3492 : loss : 0.072746, loss_ce: 0.022327
[00:25:02.337] iteration 3493 : loss : 0.149944, loss_ce: 0.021595
[00:25:02.625] iteration 3494 : loss : 0.100178, loss_ce: 0.039852
[00:25:02.917] iteration 3495 : loss : 0.106401, loss_ce: 0.037207
[00:25:03.206] iteration 3496 : loss : 0.204105, loss_ce: 0.016213
[00:25:03.493] iteration 3497 : loss : 0.097489, loss_ce: 0.052009
[00:25:03.782] iteration 3498 : loss : 0.084484, loss_ce: 0.028104
[00:25:04.070] iteration 3499 : loss : 0.099773, loss_ce: 0.026149
[00:25:04.356] iteration 3500 : loss : 0.199793, loss_ce: 0.016894
[00:25:04.661] iteration 3501 : loss : 0.124985, loss_ce: 0.026467
[00:25:04.948] iteration 3502 : loss : 0.093251, loss_ce: 0.027908
[00:25:05.240] iteration 3503 : loss : 0.198842, loss_ce: 0.007026
[00:25:05.530] iteration 3504 : loss : 0.146419, loss_ce: 0.036248
[00:25:05.817] iteration 3505 : loss : 0.085514, loss_ce: 0.027054
[00:25:06.107] iteration 3506 : loss : 0.125929, loss_ce: 0.023428
[00:25:06.395] iteration 3507 : loss : 0.093686, loss_ce: 0.024884
[00:25:06.685] iteration 3508 : loss : 0.193338, loss_ce: 0.005664
[00:25:06.972] iteration 3509 : loss : 0.086832, loss_ce: 0.024202
[00:25:07.258] iteration 3510 : loss : 0.095857, loss_ce: 0.026743
[00:25:07.549] iteration 3511 : loss : 0.086666, loss_ce: 0.012561
[00:25:07.840] iteration 3512 : loss : 0.071591, loss_ce: 0.031149
[00:25:08.131] iteration 3513 : loss : 0.086526, loss_ce: 0.024145
[00:25:08.417] iteration 3514 : loss : 0.084835, loss_ce: 0.017544
[00:25:08.706] iteration 3515 : loss : 0.108941, loss_ce: 0.023082
[00:25:08.999] iteration 3516 : loss : 0.092929, loss_ce: 0.038954
[00:25:09.287] iteration 3517 : loss : 0.088644, loss_ce: 0.057845
[00:25:09.579] iteration 3518 : loss : 0.084003, loss_ce: 0.036475
[00:25:09.866] iteration 3519 : loss : 0.178014, loss_ce: 0.039318
[00:25:10.156] iteration 3520 : loss : 0.121254, loss_ce: 0.029925
[00:25:10.459] iteration 3521 : loss : 0.199814, loss_ce: 0.010427
[00:25:10.747] iteration 3522 : loss : 0.147354, loss_ce: 0.030239
[00:25:11.037] iteration 3523 : loss : 0.087289, loss_ce: 0.025611
[00:25:11.327] iteration 3524 : loss : 0.097673, loss_ce: 0.023384
[00:25:11.618] iteration 3525 : loss : 0.080210, loss_ce: 0.023995
[00:25:11.904] iteration 3526 : loss : 0.087573, loss_ce: 0.041672
[00:25:12.197] iteration 3527 : loss : 0.092512, loss_ce: 0.021786
[00:25:12.491] iteration 3528 : loss : 0.065889, loss_ce: 0.024410
[00:25:12.777] iteration 3529 : loss : 0.079500, loss_ce: 0.025267
[00:25:13.071] iteration 3530 : loss : 0.085457, loss_ce: 0.030211
[00:25:13.362] iteration 3531 : loss : 0.147099, loss_ce: 0.015831
[00:25:13.654] iteration 3532 : loss : 0.099388, loss_ce: 0.036754
[00:25:13.943] iteration 3533 : loss : 0.105247, loss_ce: 0.040049
[00:25:14.232] iteration 3534 : loss : 0.138747, loss_ce: 0.022593
[00:25:14.524] iteration 3535 : loss : 0.152390, loss_ce: 0.014170
[00:25:14.815] iteration 3536 : loss : 0.068340, loss_ce: 0.032247
[00:25:15.105] iteration 3537 : loss : 0.106126, loss_ce: 0.019669
[00:25:15.394] iteration 3538 : loss : 0.147567, loss_ce: 0.039825
[00:25:15.683] iteration 3539 : loss : 0.092862, loss_ce: 0.017253
[00:25:15.975] iteration 3540 : loss : 0.137480, loss_ce: 0.041115
[00:25:16.283] iteration 3541 : loss : 0.083118, loss_ce: 0.015185
[00:25:16.574] iteration 3542 : loss : 0.138171, loss_ce: 0.013773
[00:25:16.864] iteration 3543 : loss : 0.091155, loss_ce: 0.033894
[00:25:17.154] iteration 3544 : loss : 0.085597, loss_ce: 0.031017
[00:25:17.443] iteration 3545 : loss : 0.129144, loss_ce: 0.024209
[00:25:17.733] iteration 3546 : loss : 0.076788, loss_ce: 0.027437
[00:25:18.023] iteration 3547 : loss : 0.085085, loss_ce: 0.039976
[00:25:18.312] iteration 3548 : loss : 0.095878, loss_ce: 0.035509
[00:25:18.601] iteration 3549 : loss : 0.237223, loss_ce: 0.008852
[00:25:18.891] iteration 3550 : loss : 0.139163, loss_ce: 0.016405
[00:25:19.181] iteration 3551 : loss : 0.097229, loss_ce: 0.031893
[00:25:19.469] iteration 3552 : loss : 0.088112, loss_ce: 0.025317
[00:25:19.759] iteration 3553 : loss : 0.192640, loss_ce: 0.017176
[00:25:20.050] iteration 3554 : loss : 0.086997, loss_ce: 0.029128
[00:25:20.342] iteration 3555 : loss : 0.091197, loss_ce: 0.038620
[00:25:20.628] iteration 3556 : loss : 0.226692, loss_ce: 0.014331
[00:25:20.914] iteration 3557 : loss : 0.161764, loss_ce: 0.017859
[00:25:21.202] iteration 3558 : loss : 0.098860, loss_ce: 0.047182
[00:25:21.490] iteration 3559 : loss : 0.066902, loss_ce: 0.027929
[00:25:21.777] iteration 3560 : loss : 0.140018, loss_ce: 0.019680
[00:25:22.081] iteration 3561 : loss : 0.125569, loss_ce: 0.012327
[00:25:22.370] iteration 3562 : loss : 0.088281, loss_ce: 0.025026
[00:25:22.655] iteration 3563 : loss : 0.080406, loss_ce: 0.022508
[00:25:22.945] iteration 3564 : loss : 0.082301, loss_ce: 0.019218
[00:25:23.237] iteration 3565 : loss : 0.077898, loss_ce: 0.019941
[00:25:23.523] iteration 3566 : loss : 0.140904, loss_ce: 0.024891
[00:25:23.814] iteration 3567 : loss : 0.096463, loss_ce: 0.031145
[00:25:24.104] iteration 3568 : loss : 0.142272, loss_ce: 0.024471
[00:25:24.388] iteration 3569 : loss : 0.107791, loss_ce: 0.018845
[00:25:24.677] iteration 3570 : loss : 0.138704, loss_ce: 0.041120
[00:25:24.964] iteration 3571 : loss : 0.097901, loss_ce: 0.018951
[00:25:25.251] iteration 3572 : loss : 0.129600, loss_ce: 0.024803
[00:25:25.539] iteration 3573 : loss : 0.089433, loss_ce: 0.023825
[00:25:25.828] iteration 3574 : loss : 0.185012, loss_ce: 0.022242
[00:25:26.119] iteration 3575 : loss : 0.202229, loss_ce: 0.018967
[00:25:26.408] iteration 3576 : loss : 0.101226, loss_ce: 0.017532
[00:25:26.695] iteration 3577 : loss : 0.145881, loss_ce: 0.018642
[00:25:26.981] iteration 3578 : loss : 0.126428, loss_ce: 0.012615
[00:25:27.273] iteration 3579 : loss : 0.082405, loss_ce: 0.026455
[00:25:27.560] iteration 3580 : loss : 0.087813, loss_ce: 0.026373
[00:25:27.863] iteration 3581 : loss : 0.112208, loss_ce: 0.013045
[00:25:28.154] iteration 3582 : loss : 0.181890, loss_ce: 0.013017
[00:25:28.445] iteration 3583 : loss : 0.108337, loss_ce: 0.015310
[00:25:28.739] iteration 3584 : loss : 0.093402, loss_ce: 0.017688
[00:25:29.025] iteration 3585 : loss : 0.058945, loss_ce: 0.015648
[00:25:29.314] iteration 3586 : loss : 0.106682, loss_ce: 0.028603
[00:25:29.604] iteration 3587 : loss : 0.097261, loss_ce: 0.045236
[00:25:29.891] iteration 3588 : loss : 0.077219, loss_ce: 0.015813
[00:25:30.178] iteration 3589 : loss : 0.157592, loss_ce: 0.019881
[00:25:30.466] iteration 3590 : loss : 0.088218, loss_ce: 0.027120
[00:25:30.754] iteration 3591 : loss : 0.108006, loss_ce: 0.037183
[00:25:31.042] iteration 3592 : loss : 0.134924, loss_ce: 0.020959
[00:25:31.334] iteration 3593 : loss : 0.089698, loss_ce: 0.031779
[00:25:31.622] iteration 3594 : loss : 0.081133, loss_ce: 0.022835
[00:25:31.915] iteration 3595 : loss : 0.141609, loss_ce: 0.041108
[00:25:32.205] iteration 3596 : loss : 0.101449, loss_ce: 0.029212
[00:25:32.493] iteration 3597 : loss : 0.096711, loss_ce: 0.013037
[00:25:32.784] iteration 3598 : loss : 0.099201, loss_ce: 0.028380
[00:25:33.074] iteration 3599 : loss : 0.152683, loss_ce: 0.018115
[00:25:33.364] iteration 3600 : loss : 0.150142, loss_ce: 0.024133
[00:25:33.679] iteration 3601 : loss : 0.165256, loss_ce: 0.017335
[00:25:33.971] iteration 3602 : loss : 0.150442, loss_ce: 0.039714
[00:25:34.264] iteration 3603 : loss : 0.130788, loss_ce: 0.013429
[00:25:34.555] iteration 3604 : loss : 0.097628, loss_ce: 0.050849
[00:25:34.844] iteration 3605 : loss : 0.151524, loss_ce: 0.041800
[00:25:35.136] iteration 3606 : loss : 0.296151, loss_ce: 0.017082
[00:25:35.430] iteration 3607 : loss : 0.143689, loss_ce: 0.043686
[00:25:35.720] iteration 3608 : loss : 0.130589, loss_ce: 0.024888
[00:25:36.010] iteration 3609 : loss : 0.096403, loss_ce: 0.027881
[00:25:36.300] iteration 3610 : loss : 0.114679, loss_ce: 0.034381
[00:25:36.589] iteration 3611 : loss : 0.103693, loss_ce: 0.025699
[00:25:36.876] iteration 3612 : loss : 0.302414, loss_ce: 0.014314
[00:25:37.168] iteration 3613 : loss : 0.115360, loss_ce: 0.013700
[00:25:37.249] iteration 3614 : loss : 0.116411, loss_ce: 0.048538
[00:25:54.123] iteration 3615 : loss : 0.108991, loss_ce: 0.019534
[00:25:54.406] iteration 3616 : loss : 0.129802, loss_ce: 0.014772
[00:25:54.691] iteration 3617 : loss : 0.114187, loss_ce: 0.023666
[00:25:54.979] iteration 3618 : loss : 0.088600, loss_ce: 0.021723
[00:25:55.267] iteration 3619 : loss : 0.085188, loss_ce: 0.016654
[00:25:55.554] iteration 3620 : loss : 0.100655, loss_ce: 0.034832
[00:25:55.857] iteration 3621 : loss : 0.077180, loss_ce: 0.027809
[00:25:56.145] iteration 3622 : loss : 0.068223, loss_ce: 0.021655
[00:25:56.434] iteration 3623 : loss : 0.059897, loss_ce: 0.021379
[00:25:56.722] iteration 3624 : loss : 0.084194, loss_ce: 0.032137
[00:25:57.009] iteration 3625 : loss : 0.079224, loss_ce: 0.029389
[00:25:57.297] iteration 3626 : loss : 0.090228, loss_ce: 0.019272
[00:25:57.587] iteration 3627 : loss : 0.071670, loss_ce: 0.030923
[00:25:57.872] iteration 3628 : loss : 0.138572, loss_ce: 0.019711
[00:25:58.158] iteration 3629 : loss : 0.132290, loss_ce: 0.035977
[00:25:58.444] iteration 3630 : loss : 0.079203, loss_ce: 0.023650
[00:25:58.731] iteration 3631 : loss : 0.083926, loss_ce: 0.041366
[00:25:59.018] iteration 3632 : loss : 0.229911, loss_ce: 0.009815
[00:25:59.305] iteration 3633 : loss : 0.109535, loss_ce: 0.029070
[00:25:59.595] iteration 3634 : loss : 0.110545, loss_ce: 0.019453
[00:25:59.883] iteration 3635 : loss : 0.105090, loss_ce: 0.024196
[00:26:00.176] iteration 3636 : loss : 0.076171, loss_ce: 0.016862
[00:26:00.466] iteration 3637 : loss : 0.092912, loss_ce: 0.023694
[00:26:00.756] iteration 3638 : loss : 0.103238, loss_ce: 0.031247
[00:26:01.046] iteration 3639 : loss : 0.078223, loss_ce: 0.019791
[00:26:01.333] iteration 3640 : loss : 0.087646, loss_ce: 0.040936
[00:26:01.641] iteration 3641 : loss : 0.132580, loss_ce: 0.012329
[00:26:01.928] iteration 3642 : loss : 0.095741, loss_ce: 0.027466
[00:26:02.216] iteration 3643 : loss : 0.059821, loss_ce: 0.008722
[00:26:02.506] iteration 3644 : loss : 0.132209, loss_ce: 0.026053
[00:26:02.796] iteration 3645 : loss : 0.078802, loss_ce: 0.023861
[00:26:03.084] iteration 3646 : loss : 0.079568, loss_ce: 0.028104
[00:26:03.374] iteration 3647 : loss : 0.141934, loss_ce: 0.025250
[00:26:03.659] iteration 3648 : loss : 0.080203, loss_ce: 0.021644
[00:26:03.948] iteration 3649 : loss : 0.084535, loss_ce: 0.019206
[00:26:04.234] iteration 3650 : loss : 0.078907, loss_ce: 0.026480
[00:26:04.523] iteration 3651 : loss : 0.107505, loss_ce: 0.022289
[00:26:04.807] iteration 3652 : loss : 0.064905, loss_ce: 0.018966
[00:26:05.097] iteration 3653 : loss : 0.073038, loss_ce: 0.025446
[00:26:05.389] iteration 3654 : loss : 0.109394, loss_ce: 0.017389
[00:26:05.678] iteration 3655 : loss : 0.128753, loss_ce: 0.024203
[00:26:05.966] iteration 3656 : loss : 0.071251, loss_ce: 0.026631
[00:26:06.254] iteration 3657 : loss : 0.086307, loss_ce: 0.014895
[00:26:06.541] iteration 3658 : loss : 0.103011, loss_ce: 0.031223
[00:26:06.827] iteration 3659 : loss : 0.085359, loss_ce: 0.025530
[00:26:07.114] iteration 3660 : loss : 0.077287, loss_ce: 0.019919
[00:26:07.419] iteration 3661 : loss : 0.125546, loss_ce: 0.038128
[00:26:07.706] iteration 3662 : loss : 0.143329, loss_ce: 0.015198
[00:26:07.995] iteration 3663 : loss : 0.159128, loss_ce: 0.023702
[00:26:08.283] iteration 3664 : loss : 0.137388, loss_ce: 0.022009
[00:26:08.574] iteration 3665 : loss : 0.085260, loss_ce: 0.031317
[00:26:08.862] iteration 3666 : loss : 0.100598, loss_ce: 0.045056
[00:26:09.150] iteration 3667 : loss : 0.127158, loss_ce: 0.023018
[00:26:09.437] iteration 3668 : loss : 0.130891, loss_ce: 0.032586
[00:26:09.725] iteration 3669 : loss : 0.078961, loss_ce: 0.027367
[00:26:10.010] iteration 3670 : loss : 0.100915, loss_ce: 0.017183
[00:26:10.303] iteration 3671 : loss : 0.134876, loss_ce: 0.025944
[00:26:10.589] iteration 3672 : loss : 0.067676, loss_ce: 0.022741
[00:26:10.877] iteration 3673 : loss : 0.098654, loss_ce: 0.034024
[00:26:11.163] iteration 3674 : loss : 0.166068, loss_ce: 0.017584
[00:26:11.450] iteration 3675 : loss : 0.161078, loss_ce: 0.026377
[00:26:11.739] iteration 3676 : loss : 0.098449, loss_ce: 0.023105
[00:26:12.027] iteration 3677 : loss : 0.131504, loss_ce: 0.018415
[00:26:12.316] iteration 3678 : loss : 0.135283, loss_ce: 0.019789
[00:26:12.607] iteration 3679 : loss : 0.124351, loss_ce: 0.013562
[00:26:12.895] iteration 3680 : loss : 0.096606, loss_ce: 0.025752
[00:26:13.199] iteration 3681 : loss : 0.092097, loss_ce: 0.032789
[00:26:13.485] iteration 3682 : loss : 0.091394, loss_ce: 0.030405
[00:26:13.775] iteration 3683 : loss : 0.077865, loss_ce: 0.020368
[00:26:14.063] iteration 3684 : loss : 0.130901, loss_ce: 0.011429
[00:26:14.352] iteration 3685 : loss : 0.067003, loss_ce: 0.022330
[00:26:14.637] iteration 3686 : loss : 0.105386, loss_ce: 0.034473
[00:26:14.926] iteration 3687 : loss : 0.080744, loss_ce: 0.028223
[00:26:15.216] iteration 3688 : loss : 0.164676, loss_ce: 0.020893
[00:26:15.506] iteration 3689 : loss : 0.080786, loss_ce: 0.019318
[00:26:15.796] iteration 3690 : loss : 0.113281, loss_ce: 0.036686
[00:26:16.082] iteration 3691 : loss : 0.071499, loss_ce: 0.029967
[00:26:16.368] iteration 3692 : loss : 0.065609, loss_ce: 0.028096
[00:26:16.655] iteration 3693 : loss : 0.085687, loss_ce: 0.026376
[00:26:16.944] iteration 3694 : loss : 0.066377, loss_ce: 0.014036
[00:26:17.232] iteration 3695 : loss : 0.136512, loss_ce: 0.017293
[00:26:17.521] iteration 3696 : loss : 0.090384, loss_ce: 0.018423
[00:26:17.810] iteration 3697 : loss : 0.088381, loss_ce: 0.034112
[00:26:18.099] iteration 3698 : loss : 0.128866, loss_ce: 0.029875
[00:26:18.389] iteration 3699 : loss : 0.105083, loss_ce: 0.029646
[00:26:18.678] iteration 3700 : loss : 0.132912, loss_ce: 0.012892
[00:26:18.979] iteration 3701 : loss : 0.130907, loss_ce: 0.022037
[00:26:19.270] iteration 3702 : loss : 0.108629, loss_ce: 0.025558
[00:26:19.556] iteration 3703 : loss : 0.130811, loss_ce: 0.027842
[00:26:19.845] iteration 3704 : loss : 0.067478, loss_ce: 0.020109
[00:26:20.132] iteration 3705 : loss : 0.116585, loss_ce: 0.008944
[00:26:20.423] iteration 3706 : loss : 0.109610, loss_ce: 0.025884
[00:26:20.713] iteration 3707 : loss : 0.104971, loss_ce: 0.032632
[00:26:21.001] iteration 3708 : loss : 0.089095, loss_ce: 0.037183
[00:26:21.289] iteration 3709 : loss : 0.081220, loss_ce: 0.032070
[00:26:21.577] iteration 3710 : loss : 0.074258, loss_ce: 0.032431
[00:26:21.868] iteration 3711 : loss : 0.140870, loss_ce: 0.017062
[00:26:22.156] iteration 3712 : loss : 0.076863, loss_ce: 0.012734
[00:26:22.446] iteration 3713 : loss : 0.140440, loss_ce: 0.018153
[00:26:22.734] iteration 3714 : loss : 0.237849, loss_ce: 0.025528
[00:26:23.020] iteration 3715 : loss : 0.100146, loss_ce: 0.030036
[00:26:23.307] iteration 3716 : loss : 0.081710, loss_ce: 0.025853
[00:26:23.593] iteration 3717 : loss : 0.080534, loss_ce: 0.026947
[00:26:23.881] iteration 3718 : loss : 0.111382, loss_ce: 0.031642
[00:26:24.171] iteration 3719 : loss : 0.139931, loss_ce: 0.018930
[00:26:24.459] iteration 3720 : loss : 0.115035, loss_ce: 0.043023
[00:26:24.764] iteration 3721 : loss : 0.081463, loss_ce: 0.033398
[00:26:25.053] iteration 3722 : loss : 0.090629, loss_ce: 0.026276
[00:26:25.340] iteration 3723 : loss : 0.169682, loss_ce: 0.027688
[00:26:25.627] iteration 3724 : loss : 0.090257, loss_ce: 0.028538
[00:26:25.917] iteration 3725 : loss : 0.072883, loss_ce: 0.021027
[00:26:26.204] iteration 3726 : loss : 0.080889, loss_ce: 0.033961
[00:26:26.493] iteration 3727 : loss : 0.145969, loss_ce: 0.027732
[00:26:26.783] iteration 3728 : loss : 0.145858, loss_ce: 0.023914
[00:26:27.071] iteration 3729 : loss : 0.092291, loss_ce: 0.019534
[00:26:27.361] iteration 3730 : loss : 0.085691, loss_ce: 0.028565
[00:26:27.648] iteration 3731 : loss : 0.084049, loss_ce: 0.025563
[00:26:27.935] iteration 3732 : loss : 0.090053, loss_ce: 0.036889
[00:26:28.225] iteration 3733 : loss : 0.103383, loss_ce: 0.034960
[00:26:28.515] iteration 3734 : loss : 0.146403, loss_ce: 0.018320
[00:26:28.802] iteration 3735 : loss : 0.120315, loss_ce: 0.015788
[00:26:29.089] iteration 3736 : loss : 0.146396, loss_ce: 0.021135
[00:26:29.379] iteration 3737 : loss : 0.083980, loss_ce: 0.044255
[00:26:29.669] iteration 3738 : loss : 0.073977, loss_ce: 0.020615
[00:26:29.961] iteration 3739 : loss : 0.117905, loss_ce: 0.035604
[00:26:30.249] iteration 3740 : loss : 0.078455, loss_ce: 0.018860
[00:26:30.560] iteration 3741 : loss : 0.086847, loss_ce: 0.022134
[00:26:30.852] iteration 3742 : loss : 0.187340, loss_ce: 0.009888
[00:26:31.140] iteration 3743 : loss : 0.105405, loss_ce: 0.038519
[00:26:31.428] iteration 3744 : loss : 0.087069, loss_ce: 0.028468
[00:26:31.719] iteration 3745 : loss : 0.093935, loss_ce: 0.027707
[00:26:32.007] iteration 3746 : loss : 0.173015, loss_ce: 0.029293
[00:26:32.301] iteration 3747 : loss : 0.085834, loss_ce: 0.032859
[00:26:32.590] iteration 3748 : loss : 0.091353, loss_ce: 0.025966
[00:26:32.878] iteration 3749 : loss : 0.104825, loss_ce: 0.023418
[00:26:33.171] iteration 3750 : loss : 0.258367, loss_ce: 0.004097
[00:26:33.460] iteration 3751 : loss : 0.159219, loss_ce: 0.027934
[00:26:33.753] iteration 3752 : loss : 0.103893, loss_ce: 0.025449
[00:26:33.840] iteration 3753 : loss : 0.494305, loss_ce: 0.000272
[00:26:50.322] iteration 3754 : loss : 0.087827, loss_ce: 0.029389
[00:26:50.608] iteration 3755 : loss : 0.100256, loss_ce: 0.027886
[00:26:50.893] iteration 3756 : loss : 0.189226, loss_ce: 0.013885
[00:26:51.182] iteration 3757 : loss : 0.169147, loss_ce: 0.041014
[00:26:51.469] iteration 3758 : loss : 0.085438, loss_ce: 0.020484
[00:26:51.755] iteration 3759 : loss : 0.082713, loss_ce: 0.035626
[00:26:52.040] iteration 3760 : loss : 0.123151, loss_ce: 0.014148
[00:26:52.343] iteration 3761 : loss : 0.133481, loss_ce: 0.015424
[00:26:52.631] iteration 3762 : loss : 0.124004, loss_ce: 0.021282
[00:26:52.919] iteration 3763 : loss : 0.092896, loss_ce: 0.026064
[00:26:53.209] iteration 3764 : loss : 0.079269, loss_ce: 0.029767
[00:26:53.497] iteration 3765 : loss : 0.112350, loss_ce: 0.026694
[00:26:53.789] iteration 3766 : loss : 0.085276, loss_ce: 0.037197
[00:26:54.077] iteration 3767 : loss : 0.094725, loss_ce: 0.049608
[00:26:54.366] iteration 3768 : loss : 0.082719, loss_ce: 0.028166
[00:26:54.652] iteration 3769 : loss : 0.110541, loss_ce: 0.017155
[00:26:54.941] iteration 3770 : loss : 0.078569, loss_ce: 0.023102
[00:26:55.231] iteration 3771 : loss : 0.148292, loss_ce: 0.027308
[00:26:55.520] iteration 3772 : loss : 0.146227, loss_ce: 0.020564
[00:26:55.809] iteration 3773 : loss : 0.074291, loss_ce: 0.030614
[00:26:56.100] iteration 3774 : loss : 0.143826, loss_ce: 0.041706
[00:26:56.389] iteration 3775 : loss : 0.092236, loss_ce: 0.012181
[00:26:56.677] iteration 3776 : loss : 0.109089, loss_ce: 0.014291
[00:26:56.967] iteration 3777 : loss : 0.114800, loss_ce: 0.015750
[00:26:57.256] iteration 3778 : loss : 0.101004, loss_ce: 0.030444
[00:26:57.546] iteration 3779 : loss : 0.078184, loss_ce: 0.015529
[00:26:57.837] iteration 3780 : loss : 0.111335, loss_ce: 0.022310
[00:26:58.141] iteration 3781 : loss : 0.158647, loss_ce: 0.027157
[00:26:58.432] iteration 3782 : loss : 0.160946, loss_ce: 0.023889
[00:26:58.720] iteration 3783 : loss : 0.072670, loss_ce: 0.025155
[00:26:59.009] iteration 3784 : loss : 0.122130, loss_ce: 0.045422
[00:26:59.298] iteration 3785 : loss : 0.160378, loss_ce: 0.011172
[00:26:59.585] iteration 3786 : loss : 0.233830, loss_ce: 0.009791
[00:26:59.873] iteration 3787 : loss : 0.093317, loss_ce: 0.028868
[00:27:00.164] iteration 3788 : loss : 0.068821, loss_ce: 0.024529
[00:27:00.456] iteration 3789 : loss : 0.142340, loss_ce: 0.027533
[00:27:00.751] iteration 3790 : loss : 0.058181, loss_ce: 0.019162
[00:27:01.043] iteration 3791 : loss : 0.096033, loss_ce: 0.021370
[00:27:01.331] iteration 3792 : loss : 0.143632, loss_ce: 0.024977
[00:27:01.620] iteration 3793 : loss : 0.102086, loss_ce: 0.017127
[00:27:01.911] iteration 3794 : loss : 0.110067, loss_ce: 0.025262
[00:27:02.198] iteration 3795 : loss : 0.128778, loss_ce: 0.013944
[00:27:02.487] iteration 3796 : loss : 0.128952, loss_ce: 0.015456
[00:27:02.777] iteration 3797 : loss : 0.085956, loss_ce: 0.038696
[00:27:03.071] iteration 3798 : loss : 0.090250, loss_ce: 0.034371
[00:27:03.360] iteration 3799 : loss : 0.145999, loss_ce: 0.022468
[00:27:03.649] iteration 3800 : loss : 0.100850, loss_ce: 0.043111
[00:27:03.955] iteration 3801 : loss : 0.087618, loss_ce: 0.026335
[00:27:04.247] iteration 3802 : loss : 0.079456, loss_ce: 0.018208
[00:27:04.535] iteration 3803 : loss : 0.083276, loss_ce: 0.033727
[00:27:04.826] iteration 3804 : loss : 0.100110, loss_ce: 0.032440
[00:27:05.115] iteration 3805 : loss : 0.088129, loss_ce: 0.026103
[00:27:05.406] iteration 3806 : loss : 0.105556, loss_ce: 0.035227
[00:27:05.694] iteration 3807 : loss : 0.126096, loss_ce: 0.029886
[00:27:05.984] iteration 3808 : loss : 0.186628, loss_ce: 0.011701
[00:27:06.272] iteration 3809 : loss : 0.149281, loss_ce: 0.019412
[00:27:06.560] iteration 3810 : loss : 0.157714, loss_ce: 0.015813
[00:27:06.853] iteration 3811 : loss : 0.071393, loss_ce: 0.024949
[00:27:07.142] iteration 3812 : loss : 0.082448, loss_ce: 0.019295
[00:27:07.434] iteration 3813 : loss : 0.102023, loss_ce: 0.029119
[00:27:07.727] iteration 3814 : loss : 0.078184, loss_ce: 0.026164
[00:27:08.017] iteration 3815 : loss : 0.137628, loss_ce: 0.015975
[00:27:08.309] iteration 3816 : loss : 0.084013, loss_ce: 0.019649
[00:27:08.597] iteration 3817 : loss : 0.122582, loss_ce: 0.039909
[00:27:08.887] iteration 3818 : loss : 0.103333, loss_ce: 0.025011
[00:27:09.179] iteration 3819 : loss : 0.140751, loss_ce: 0.019654
[00:27:09.468] iteration 3820 : loss : 0.141593, loss_ce: 0.017607
[00:27:09.775] iteration 3821 : loss : 0.200214, loss_ce: 0.016179
[00:27:10.065] iteration 3822 : loss : 0.085403, loss_ce: 0.029496
[00:27:10.358] iteration 3823 : loss : 0.113284, loss_ce: 0.021069
[00:27:10.650] iteration 3824 : loss : 0.180465, loss_ce: 0.010571
[00:27:10.936] iteration 3825 : loss : 0.080636, loss_ce: 0.022613
[00:27:11.226] iteration 3826 : loss : 0.242787, loss_ce: 0.020119
[00:27:11.517] iteration 3827 : loss : 0.093900, loss_ce: 0.022514
[00:27:11.806] iteration 3828 : loss : 0.077822, loss_ce: 0.022969
[00:27:12.092] iteration 3829 : loss : 0.111414, loss_ce: 0.026601
[00:27:12.380] iteration 3830 : loss : 0.093070, loss_ce: 0.028963
[00:27:12.672] iteration 3831 : loss : 0.098731, loss_ce: 0.027886
[00:27:12.964] iteration 3832 : loss : 0.072889, loss_ce: 0.028512
[00:27:13.254] iteration 3833 : loss : 0.094328, loss_ce: 0.021484
[00:27:13.543] iteration 3834 : loss : 0.071078, loss_ce: 0.017367
[00:27:13.832] iteration 3835 : loss : 0.067948, loss_ce: 0.020717
[00:27:14.122] iteration 3836 : loss : 0.140243, loss_ce: 0.025628
[00:27:14.410] iteration 3837 : loss : 0.096873, loss_ce: 0.024260
[00:27:14.699] iteration 3838 : loss : 0.150444, loss_ce: 0.024285
[00:27:14.987] iteration 3839 : loss : 0.090263, loss_ce: 0.027713
[00:27:15.279] iteration 3840 : loss : 0.090428, loss_ce: 0.016289
[00:27:15.579] iteration 3841 : loss : 0.153370, loss_ce: 0.012829
[00:27:15.868] iteration 3842 : loss : 0.075349, loss_ce: 0.015728
[00:27:16.158] iteration 3843 : loss : 0.158316, loss_ce: 0.019411
[00:27:16.446] iteration 3844 : loss : 0.289123, loss_ce: 0.007298
[00:27:16.732] iteration 3845 : loss : 0.072639, loss_ce: 0.021477
[00:27:17.024] iteration 3846 : loss : 0.149928, loss_ce: 0.025523
[00:27:17.313] iteration 3847 : loss : 0.087265, loss_ce: 0.024277
[00:27:17.602] iteration 3848 : loss : 0.118326, loss_ce: 0.035933
[00:27:17.889] iteration 3849 : loss : 0.079025, loss_ce: 0.023917
[00:27:18.181] iteration 3850 : loss : 0.092016, loss_ce: 0.033777
[00:27:18.471] iteration 3851 : loss : 0.084817, loss_ce: 0.020239
[00:27:18.762] iteration 3852 : loss : 0.073597, loss_ce: 0.025109
[00:27:19.050] iteration 3853 : loss : 0.090343, loss_ce: 0.024017
[00:27:19.342] iteration 3854 : loss : 0.117980, loss_ce: 0.024574
[00:27:19.630] iteration 3855 : loss : 0.085205, loss_ce: 0.026104
[00:27:19.922] iteration 3856 : loss : 0.099098, loss_ce: 0.028152
[00:27:20.213] iteration 3857 : loss : 0.084382, loss_ce: 0.026378
[00:27:20.502] iteration 3858 : loss : 0.059703, loss_ce: 0.019590
[00:27:20.789] iteration 3859 : loss : 0.139540, loss_ce: 0.024847
[00:27:21.076] iteration 3860 : loss : 0.088275, loss_ce: 0.015001
[00:27:21.384] iteration 3861 : loss : 0.082842, loss_ce: 0.030560
[00:27:21.672] iteration 3862 : loss : 0.089035, loss_ce: 0.026932
[00:27:21.963] iteration 3863 : loss : 0.168279, loss_ce: 0.016583
[00:27:22.254] iteration 3864 : loss : 0.096959, loss_ce: 0.030959
[00:27:22.544] iteration 3865 : loss : 0.085046, loss_ce: 0.025652
[00:27:22.832] iteration 3866 : loss : 0.077932, loss_ce: 0.030042
[00:27:23.119] iteration 3867 : loss : 0.077141, loss_ce: 0.014396
[00:27:23.408] iteration 3868 : loss : 0.085194, loss_ce: 0.040940
[00:27:23.697] iteration 3869 : loss : 0.157239, loss_ce: 0.027936
[00:27:23.984] iteration 3870 : loss : 0.127983, loss_ce: 0.015684
[00:27:24.272] iteration 3871 : loss : 0.103605, loss_ce: 0.047652
[00:27:24.560] iteration 3872 : loss : 0.113388, loss_ce: 0.018527
[00:27:24.848] iteration 3873 : loss : 0.079079, loss_ce: 0.021266
[00:27:25.134] iteration 3874 : loss : 0.065559, loss_ce: 0.025284
[00:27:25.423] iteration 3875 : loss : 0.144149, loss_ce: 0.022254
[00:27:25.716] iteration 3876 : loss : 0.068763, loss_ce: 0.024813
[00:27:26.004] iteration 3877 : loss : 0.064114, loss_ce: 0.022292
[00:27:26.300] iteration 3878 : loss : 0.094623, loss_ce: 0.045775
[00:27:26.588] iteration 3879 : loss : 0.093727, loss_ce: 0.039251
[00:27:26.879] iteration 3880 : loss : 0.090375, loss_ce: 0.021223
[00:27:27.195] iteration 3881 : loss : 0.070388, loss_ce: 0.019153
[00:27:27.483] iteration 3882 : loss : 0.102492, loss_ce: 0.026601
[00:27:27.775] iteration 3883 : loss : 0.134599, loss_ce: 0.020239
[00:27:28.065] iteration 3884 : loss : 0.074818, loss_ce: 0.028140
[00:27:28.355] iteration 3885 : loss : 0.141250, loss_ce: 0.020938
[00:27:28.647] iteration 3886 : loss : 0.135688, loss_ce: 0.017873
[00:27:28.940] iteration 3887 : loss : 0.064808, loss_ce: 0.032054
[00:27:29.229] iteration 3888 : loss : 0.087987, loss_ce: 0.045064
[00:27:29.523] iteration 3889 : loss : 0.135959, loss_ce: 0.017149
[00:27:29.816] iteration 3890 : loss : 0.105794, loss_ce: 0.044179
[00:27:30.108] iteration 3891 : loss : 0.105298, loss_ce: 0.041302
[00:27:30.185] iteration 3892 : loss : 0.210113, loss_ce: 0.069936
[00:27:46.919] iteration 3893 : loss : 0.108145, loss_ce: 0.017164
[00:27:47.204] iteration 3894 : loss : 0.065562, loss_ce: 0.019396
[00:27:47.490] iteration 3895 : loss : 0.080706, loss_ce: 0.028774
[00:27:47.779] iteration 3896 : loss : 0.088673, loss_ce: 0.039402
[00:27:48.069] iteration 3897 : loss : 0.076730, loss_ce: 0.025562
[00:27:48.353] iteration 3898 : loss : 0.079409, loss_ce: 0.033010
[00:27:48.640] iteration 3899 : loss : 0.142978, loss_ce: 0.017114
[00:27:48.928] iteration 3900 : loss : 0.074222, loss_ce: 0.027359
[00:27:49.234] iteration 3901 : loss : 0.146353, loss_ce: 0.019259
[00:27:49.521] iteration 3902 : loss : 0.075179, loss_ce: 0.021102
[00:27:49.806] iteration 3903 : loss : 0.080261, loss_ce: 0.015208
[00:27:50.093] iteration 3904 : loss : 0.079806, loss_ce: 0.020590
[00:27:50.382] iteration 3905 : loss : 0.058384, loss_ce: 0.023455
[00:27:50.666] iteration 3906 : loss : 0.100494, loss_ce: 0.023899
[00:27:50.955] iteration 3907 : loss : 0.073616, loss_ce: 0.018906
[00:27:51.239] iteration 3908 : loss : 0.077355, loss_ce: 0.018807
[00:27:51.526] iteration 3909 : loss : 0.123663, loss_ce: 0.022506
[00:27:51.811] iteration 3910 : loss : 0.068069, loss_ce: 0.022091
[00:27:52.099] iteration 3911 : loss : 0.174585, loss_ce: 0.019856
[00:27:52.386] iteration 3912 : loss : 0.069387, loss_ce: 0.032364
[00:27:52.673] iteration 3913 : loss : 0.092169, loss_ce: 0.020504
[00:27:52.958] iteration 3914 : loss : 0.080156, loss_ce: 0.033320
[00:27:53.250] iteration 3915 : loss : 0.103775, loss_ce: 0.021687
[00:27:53.536] iteration 3916 : loss : 0.132845, loss_ce: 0.011300
[00:27:53.822] iteration 3917 : loss : 0.090268, loss_ce: 0.034999
[00:27:54.109] iteration 3918 : loss : 0.086620, loss_ce: 0.028876
[00:27:54.399] iteration 3919 : loss : 0.071326, loss_ce: 0.024443
[00:27:54.685] iteration 3920 : loss : 0.070692, loss_ce: 0.018819
[00:27:54.985] iteration 3921 : loss : 0.075328, loss_ce: 0.027559
[00:27:55.273] iteration 3922 : loss : 0.069272, loss_ce: 0.029787
[00:27:55.559] iteration 3923 : loss : 0.097712, loss_ce: 0.028295
[00:27:55.846] iteration 3924 : loss : 0.377255, loss_ce: 0.005266
[00:27:56.133] iteration 3925 : loss : 0.077539, loss_ce: 0.023413
[00:27:56.421] iteration 3926 : loss : 0.080858, loss_ce: 0.021076
[00:27:56.708] iteration 3927 : loss : 0.085400, loss_ce: 0.016588
[00:27:56.995] iteration 3928 : loss : 0.081519, loss_ce: 0.026972
[00:27:57.281] iteration 3929 : loss : 0.095001, loss_ce: 0.045007
[00:27:57.570] iteration 3930 : loss : 0.075320, loss_ce: 0.024525
[00:27:57.855] iteration 3931 : loss : 0.147426, loss_ce: 0.026161
[00:27:58.144] iteration 3932 : loss : 0.146831, loss_ce: 0.045391
[00:27:58.432] iteration 3933 : loss : 0.123683, loss_ce: 0.020346
[00:27:58.717] iteration 3934 : loss : 0.094252, loss_ce: 0.038940
[00:27:59.006] iteration 3935 : loss : 0.079478, loss_ce: 0.020385
[00:27:59.293] iteration 3936 : loss : 0.116582, loss_ce: 0.031064
[00:27:59.581] iteration 3937 : loss : 0.101915, loss_ce: 0.027849
[00:27:59.868] iteration 3938 : loss : 0.142041, loss_ce: 0.015022
[00:28:00.156] iteration 3939 : loss : 0.097962, loss_ce: 0.034812
[00:28:00.447] iteration 3940 : loss : 0.081555, loss_ce: 0.022727
[00:28:00.755] iteration 3941 : loss : 0.070968, loss_ce: 0.022467
[00:28:01.044] iteration 3942 : loss : 0.113231, loss_ce: 0.026551
[00:28:01.329] iteration 3943 : loss : 0.106294, loss_ce: 0.036524
[00:28:01.619] iteration 3944 : loss : 0.081416, loss_ce: 0.030328
[00:28:01.906] iteration 3945 : loss : 0.054827, loss_ce: 0.017120
[00:28:02.194] iteration 3946 : loss : 0.092790, loss_ce: 0.028605
[00:28:02.482] iteration 3947 : loss : 0.105148, loss_ce: 0.033940
[00:28:02.771] iteration 3948 : loss : 0.057071, loss_ce: 0.014288
[00:28:03.057] iteration 3949 : loss : 0.176095, loss_ce: 0.019948
[00:28:03.343] iteration 3950 : loss : 0.131719, loss_ce: 0.019205
[00:28:03.631] iteration 3951 : loss : 0.126323, loss_ce: 0.023328
[00:28:03.918] iteration 3952 : loss : 0.136561, loss_ce: 0.020069
[00:28:04.205] iteration 3953 : loss : 0.092631, loss_ce: 0.018475
[00:28:04.493] iteration 3954 : loss : 0.105838, loss_ce: 0.037816
[00:28:04.782] iteration 3955 : loss : 0.091042, loss_ce: 0.033660
[00:28:05.068] iteration 3956 : loss : 0.124701, loss_ce: 0.015415
[00:28:05.354] iteration 3957 : loss : 0.061447, loss_ce: 0.019011
[00:28:05.642] iteration 3958 : loss : 0.165416, loss_ce: 0.021463
[00:28:05.931] iteration 3959 : loss : 0.234174, loss_ce: 0.007965
[00:28:06.218] iteration 3960 : loss : 0.101247, loss_ce: 0.035140
[00:28:06.520] iteration 3961 : loss : 0.100464, loss_ce: 0.018603
[00:28:06.807] iteration 3962 : loss : 0.185122, loss_ce: 0.022076
[00:28:07.094] iteration 3963 : loss : 0.133986, loss_ce: 0.026640
[00:28:07.381] iteration 3964 : loss : 0.108960, loss_ce: 0.037333
[00:28:07.668] iteration 3965 : loss : 0.089247, loss_ce: 0.024566
[00:28:07.955] iteration 3966 : loss : 0.068593, loss_ce: 0.021192
[00:28:08.244] iteration 3967 : loss : 0.054021, loss_ce: 0.013179
[00:28:08.532] iteration 3968 : loss : 0.083423, loss_ce: 0.041931
[00:28:08.821] iteration 3969 : loss : 0.087157, loss_ce: 0.017872
[00:28:09.107] iteration 3970 : loss : 0.128922, loss_ce: 0.027703
[00:28:09.395] iteration 3971 : loss : 0.126772, loss_ce: 0.023610
[00:28:09.684] iteration 3972 : loss : 0.080208, loss_ce: 0.023056
[00:28:09.974] iteration 3973 : loss : 0.160682, loss_ce: 0.013248
[00:28:10.262] iteration 3974 : loss : 0.073852, loss_ce: 0.023026
[00:28:10.547] iteration 3975 : loss : 0.141982, loss_ce: 0.029570
[00:28:10.835] iteration 3976 : loss : 0.073389, loss_ce: 0.026430
[00:28:11.129] iteration 3977 : loss : 0.106604, loss_ce: 0.035067
[00:28:11.415] iteration 3978 : loss : 0.107482, loss_ce: 0.019568
[00:28:11.703] iteration 3979 : loss : 0.059258, loss_ce: 0.017812
[00:28:11.994] iteration 3980 : loss : 0.067279, loss_ce: 0.019681
[00:28:12.295] iteration 3981 : loss : 0.088862, loss_ce: 0.011893
[00:28:12.581] iteration 3982 : loss : 0.128230, loss_ce: 0.029551
[00:28:12.868] iteration 3983 : loss : 0.137233, loss_ce: 0.015492
[00:28:13.153] iteration 3984 : loss : 0.098729, loss_ce: 0.031186
[00:28:13.440] iteration 3985 : loss : 0.083166, loss_ce: 0.023257
[00:28:13.726] iteration 3986 : loss : 0.139259, loss_ce: 0.035681
[00:28:14.013] iteration 3987 : loss : 0.136269, loss_ce: 0.025891
[00:28:14.301] iteration 3988 : loss : 0.075578, loss_ce: 0.021034
[00:28:14.588] iteration 3989 : loss : 0.099589, loss_ce: 0.027731
[00:28:14.875] iteration 3990 : loss : 0.111932, loss_ce: 0.029973
[00:28:15.162] iteration 3991 : loss : 0.072637, loss_ce: 0.022370
[00:28:15.451] iteration 3992 : loss : 0.114007, loss_ce: 0.021660
[00:28:15.738] iteration 3993 : loss : 0.122334, loss_ce: 0.024518
[00:28:16.026] iteration 3994 : loss : 0.080053, loss_ce: 0.019940
[00:28:16.312] iteration 3995 : loss : 0.124264, loss_ce: 0.021445
[00:28:16.601] iteration 3996 : loss : 0.067632, loss_ce: 0.026177
[00:28:16.890] iteration 3997 : loss : 0.112043, loss_ce: 0.023531
[00:28:17.175] iteration 3998 : loss : 0.100315, loss_ce: 0.024833
[00:28:17.462] iteration 3999 : loss : 0.093964, loss_ce: 0.027090
[00:28:17.751] iteration 4000 : loss : 0.088707, loss_ce: 0.011404
[00:28:18.052] iteration 4001 : loss : 0.092570, loss_ce: 0.029393
[00:28:18.339] iteration 4002 : loss : 0.086630, loss_ce: 0.028860
[00:28:18.626] iteration 4003 : loss : 0.124513, loss_ce: 0.032868
[00:28:18.914] iteration 4004 : loss : 0.123691, loss_ce: 0.032377
[00:28:19.199] iteration 4005 : loss : 0.113854, loss_ce: 0.018968
[00:28:19.487] iteration 4006 : loss : 0.082071, loss_ce: 0.024219
[00:28:19.775] iteration 4007 : loss : 0.105640, loss_ce: 0.027829
[00:28:20.064] iteration 4008 : loss : 0.148842, loss_ce: 0.023661
[00:28:20.352] iteration 4009 : loss : 0.082715, loss_ce: 0.028264
[00:28:20.642] iteration 4010 : loss : 0.107798, loss_ce: 0.037355
[00:28:20.929] iteration 4011 : loss : 0.078232, loss_ce: 0.014379
[00:28:21.219] iteration 4012 : loss : 0.143582, loss_ce: 0.024306
[00:28:21.505] iteration 4013 : loss : 0.080994, loss_ce: 0.024635
[00:28:21.793] iteration 4014 : loss : 0.117338, loss_ce: 0.022383
[00:28:22.084] iteration 4015 : loss : 0.077404, loss_ce: 0.021533
[00:28:22.374] iteration 4016 : loss : 0.131517, loss_ce: 0.027158
[00:28:22.665] iteration 4017 : loss : 0.098945, loss_ce: 0.032093
[00:28:22.956] iteration 4018 : loss : 0.097545, loss_ce: 0.033660
[00:28:23.248] iteration 4019 : loss : 0.105509, loss_ce: 0.025923
[00:28:23.536] iteration 4020 : loss : 0.126178, loss_ce: 0.029652
[00:28:23.845] iteration 4021 : loss : 0.143009, loss_ce: 0.015136
[00:28:24.133] iteration 4022 : loss : 0.097569, loss_ce: 0.036624
[00:28:24.424] iteration 4023 : loss : 0.198219, loss_ce: 0.012540
[00:28:24.717] iteration 4024 : loss : 0.106057, loss_ce: 0.029165
[00:28:25.008] iteration 4025 : loss : 0.087579, loss_ce: 0.027689
[00:28:25.301] iteration 4026 : loss : 0.116185, loss_ce: 0.030267
[00:28:25.593] iteration 4027 : loss : 0.139820, loss_ce: 0.018779
[00:28:25.886] iteration 4028 : loss : 0.084798, loss_ce: 0.020680
[00:28:26.176] iteration 4029 : loss : 0.099024, loss_ce: 0.031044
[00:28:26.465] iteration 4030 : loss : 0.094366, loss_ce: 0.021065
[00:28:26.541] iteration 4031 : loss : 0.239754, loss_ce: 0.041723
[00:28:43.077] iteration 4032 : loss : 0.091238, loss_ce: 0.016329
[00:28:43.364] iteration 4033 : loss : 0.201322, loss_ce: 0.011275
[00:28:43.652] iteration 4034 : loss : 0.100349, loss_ce: 0.033812
[00:28:43.942] iteration 4035 : loss : 0.101935, loss_ce: 0.034313
[00:28:44.230] iteration 4036 : loss : 0.084350, loss_ce: 0.016872
[00:28:44.517] iteration 4037 : loss : 0.107238, loss_ce: 0.022896
[00:28:44.802] iteration 4038 : loss : 0.072178, loss_ce: 0.018551
[00:28:45.088] iteration 4039 : loss : 0.157249, loss_ce: 0.028614
[00:28:45.377] iteration 4040 : loss : 0.101485, loss_ce: 0.018799
[00:28:45.679] iteration 4041 : loss : 0.083742, loss_ce: 0.029363
[00:28:45.965] iteration 4042 : loss : 0.107290, loss_ce: 0.036481
[00:28:46.250] iteration 4043 : loss : 0.080497, loss_ce: 0.035163
[00:28:46.536] iteration 4044 : loss : 0.135101, loss_ce: 0.011113
[00:28:46.822] iteration 4045 : loss : 0.124818, loss_ce: 0.040632
[00:28:47.110] iteration 4046 : loss : 0.101677, loss_ce: 0.031548
[00:28:47.396] iteration 4047 : loss : 0.085018, loss_ce: 0.036531
[00:28:47.682] iteration 4048 : loss : 0.108560, loss_ce: 0.033423
[00:28:47.970] iteration 4049 : loss : 0.149488, loss_ce: 0.024960
[00:28:48.254] iteration 4050 : loss : 0.136250, loss_ce: 0.025066
[00:28:48.540] iteration 4051 : loss : 0.108472, loss_ce: 0.026804
[00:28:48.826] iteration 4052 : loss : 0.081908, loss_ce: 0.015879
[00:28:49.111] iteration 4053 : loss : 0.086322, loss_ce: 0.026960
[00:28:49.400] iteration 4054 : loss : 0.245587, loss_ce: 0.010955
[00:28:49.687] iteration 4055 : loss : 0.117321, loss_ce: 0.024629
[00:28:49.973] iteration 4056 : loss : 0.137606, loss_ce: 0.012420
[00:28:50.259] iteration 4057 : loss : 0.065285, loss_ce: 0.012038
[00:28:50.549] iteration 4058 : loss : 0.077753, loss_ce: 0.036053
[00:28:50.837] iteration 4059 : loss : 0.088943, loss_ce: 0.013856
[00:28:51.126] iteration 4060 : loss : 0.085583, loss_ce: 0.027833
[00:28:51.440] iteration 4061 : loss : 0.142968, loss_ce: 0.023407
[00:28:51.729] iteration 4062 : loss : 0.115839, loss_ce: 0.016604
[00:28:52.018] iteration 4063 : loss : 0.075174, loss_ce: 0.016570
[00:28:52.307] iteration 4064 : loss : 0.077139, loss_ce: 0.025107
[00:28:52.596] iteration 4065 : loss : 0.122559, loss_ce: 0.037837
[00:28:52.886] iteration 4066 : loss : 0.077055, loss_ce: 0.040927
[00:28:53.177] iteration 4067 : loss : 0.078925, loss_ce: 0.020814
[00:28:53.466] iteration 4068 : loss : 0.064978, loss_ce: 0.022294
[00:28:53.756] iteration 4069 : loss : 0.080835, loss_ce: 0.012939
[00:28:54.044] iteration 4070 : loss : 0.112075, loss_ce: 0.013441
[00:28:54.332] iteration 4071 : loss : 0.089786, loss_ce: 0.023023
[00:28:54.622] iteration 4072 : loss : 0.153043, loss_ce: 0.031495
[00:28:54.911] iteration 4073 : loss : 0.081945, loss_ce: 0.017679
[00:28:55.202] iteration 4074 : loss : 0.068691, loss_ce: 0.019899
[00:28:55.490] iteration 4075 : loss : 0.105876, loss_ce: 0.025699
[00:28:55.780] iteration 4076 : loss : 0.127121, loss_ce: 0.021559
[00:28:56.069] iteration 4077 : loss : 0.067227, loss_ce: 0.022354
[00:28:56.361] iteration 4078 : loss : 0.136411, loss_ce: 0.039322
[00:28:56.651] iteration 4079 : loss : 0.134284, loss_ce: 0.021837
[00:28:56.940] iteration 4080 : loss : 0.073488, loss_ce: 0.020489
[00:28:57.243] iteration 4081 : loss : 0.161183, loss_ce: 0.036923
[00:28:57.534] iteration 4082 : loss : 0.132254, loss_ce: 0.029120
[00:28:57.824] iteration 4083 : loss : 0.089734, loss_ce: 0.022409
[00:28:58.114] iteration 4084 : loss : 0.073292, loss_ce: 0.009102
[00:28:58.406] iteration 4085 : loss : 0.081536, loss_ce: 0.021993
[00:28:58.696] iteration 4086 : loss : 0.074924, loss_ce: 0.026368
[00:28:58.986] iteration 4087 : loss : 0.100253, loss_ce: 0.026004
[00:28:59.276] iteration 4088 : loss : 0.099484, loss_ce: 0.028387
[00:28:59.566] iteration 4089 : loss : 0.086925, loss_ce: 0.038126
[00:28:59.854] iteration 4090 : loss : 0.089788, loss_ce: 0.035539
[00:29:00.145] iteration 4091 : loss : 0.087507, loss_ce: 0.023646
[00:29:00.439] iteration 4092 : loss : 0.118686, loss_ce: 0.009465
[00:29:00.732] iteration 4093 : loss : 0.271728, loss_ce: 0.005513
[00:29:01.024] iteration 4094 : loss : 0.067751, loss_ce: 0.031741
[00:29:01.313] iteration 4095 : loss : 0.088600, loss_ce: 0.018996
[00:29:01.600] iteration 4096 : loss : 0.151347, loss_ce: 0.022558
[00:29:01.892] iteration 4097 : loss : 0.076521, loss_ce: 0.022284
[00:29:02.181] iteration 4098 : loss : 0.132454, loss_ce: 0.016135
[00:29:02.470] iteration 4099 : loss : 0.094019, loss_ce: 0.030568
[00:29:02.758] iteration 4100 : loss : 0.080545, loss_ce: 0.033884
[00:29:03.062] iteration 4101 : loss : 0.205639, loss_ce: 0.022182
[00:29:03.352] iteration 4102 : loss : 0.068482, loss_ce: 0.023679
[00:29:03.642] iteration 4103 : loss : 0.121174, loss_ce: 0.014007
[00:29:03.930] iteration 4104 : loss : 0.115494, loss_ce: 0.017285
[00:29:04.221] iteration 4105 : loss : 0.084866, loss_ce: 0.024215
[00:29:04.511] iteration 4106 : loss : 0.142528, loss_ce: 0.026718
[00:29:04.801] iteration 4107 : loss : 0.110482, loss_ce: 0.033933
[00:29:05.088] iteration 4108 : loss : 0.070958, loss_ce: 0.024286
[00:29:05.382] iteration 4109 : loss : 0.071303, loss_ce: 0.013148
[00:29:05.672] iteration 4110 : loss : 0.088620, loss_ce: 0.025562
[00:29:05.961] iteration 4111 : loss : 0.100516, loss_ce: 0.026872
[00:29:06.249] iteration 4112 : loss : 0.116262, loss_ce: 0.021735
[00:29:06.539] iteration 4113 : loss : 0.072128, loss_ce: 0.018130
[00:29:06.828] iteration 4114 : loss : 0.110777, loss_ce: 0.026955
[00:29:07.118] iteration 4115 : loss : 0.080355, loss_ce: 0.030842
[00:29:07.408] iteration 4116 : loss : 0.117883, loss_ce: 0.015817
[00:29:07.698] iteration 4117 : loss : 0.087715, loss_ce: 0.024045
[00:29:07.988] iteration 4118 : loss : 0.067978, loss_ce: 0.015552
[00:29:08.275] iteration 4119 : loss : 0.121877, loss_ce: 0.012749
[00:29:08.562] iteration 4120 : loss : 0.082976, loss_ce: 0.024366
[00:29:08.866] iteration 4121 : loss : 0.135160, loss_ce: 0.020334
[00:29:09.157] iteration 4122 : loss : 0.305236, loss_ce: 0.005344
[00:29:09.447] iteration 4123 : loss : 0.074802, loss_ce: 0.028642
[00:29:09.733] iteration 4124 : loss : 0.069155, loss_ce: 0.020680
[00:29:10.024] iteration 4125 : loss : 0.083117, loss_ce: 0.012883
[00:29:10.314] iteration 4126 : loss : 0.084211, loss_ce: 0.016245
[00:29:10.605] iteration 4127 : loss : 0.092555, loss_ce: 0.023566
[00:29:10.895] iteration 4128 : loss : 0.114986, loss_ce: 0.029654
[00:29:11.184] iteration 4129 : loss : 0.077607, loss_ce: 0.020096
[00:29:11.474] iteration 4130 : loss : 0.090474, loss_ce: 0.017912
[00:29:11.763] iteration 4131 : loss : 0.132908, loss_ce: 0.014633
[00:29:12.050] iteration 4132 : loss : 0.108808, loss_ce: 0.035761
[00:29:12.338] iteration 4133 : loss : 0.118741, loss_ce: 0.023498
[00:29:12.631] iteration 4134 : loss : 0.140382, loss_ce: 0.029689
[00:29:12.921] iteration 4135 : loss : 0.088798, loss_ce: 0.032644
[00:29:13.212] iteration 4136 : loss : 0.072456, loss_ce: 0.030593
[00:29:13.503] iteration 4137 : loss : 0.078639, loss_ce: 0.030828
[00:29:13.794] iteration 4138 : loss : 0.094480, loss_ce: 0.019776
[00:29:14.085] iteration 4139 : loss : 0.093185, loss_ce: 0.027997
[00:29:14.373] iteration 4140 : loss : 0.078846, loss_ce: 0.034594
[00:29:14.681] iteration 4141 : loss : 0.065845, loss_ce: 0.021820
[00:29:14.973] iteration 4142 : loss : 0.071742, loss_ce: 0.023920
[00:29:15.266] iteration 4143 : loss : 0.127738, loss_ce: 0.025278
[00:29:15.554] iteration 4144 : loss : 0.106167, loss_ce: 0.024129
[00:29:15.844] iteration 4145 : loss : 0.167999, loss_ce: 0.014956
[00:29:16.133] iteration 4146 : loss : 0.136054, loss_ce: 0.009857
[00:29:16.424] iteration 4147 : loss : 0.065289, loss_ce: 0.020205
[00:29:16.712] iteration 4148 : loss : 0.073061, loss_ce: 0.033356
[00:29:17.001] iteration 4149 : loss : 0.095049, loss_ce: 0.027019
[00:29:17.290] iteration 4150 : loss : 0.061121, loss_ce: 0.018655
[00:29:17.579] iteration 4151 : loss : 0.074804, loss_ce: 0.030527
[00:29:17.867] iteration 4152 : loss : 0.061714, loss_ce: 0.023778
[00:29:18.155] iteration 4153 : loss : 0.091265, loss_ce: 0.022039
[00:29:18.448] iteration 4154 : loss : 0.087928, loss_ce: 0.030411
[00:29:18.745] iteration 4155 : loss : 0.138885, loss_ce: 0.016627
[00:29:19.036] iteration 4156 : loss : 0.078859, loss_ce: 0.024917
[00:29:19.330] iteration 4157 : loss : 0.135755, loss_ce: 0.012784
[00:29:19.627] iteration 4158 : loss : 0.101726, loss_ce: 0.035157
[00:29:19.922] iteration 4159 : loss : 0.063957, loss_ce: 0.028568
[00:29:20.213] iteration 4160 : loss : 0.111374, loss_ce: 0.025752
[00:29:20.519] iteration 4161 : loss : 0.169129, loss_ce: 0.025068
[00:29:20.809] iteration 4162 : loss : 0.060828, loss_ce: 0.022162
[00:29:21.096] iteration 4163 : loss : 0.133815, loss_ce: 0.021287
[00:29:21.388] iteration 4164 : loss : 0.064110, loss_ce: 0.010871
[00:29:21.682] iteration 4165 : loss : 0.169733, loss_ce: 0.014157
[00:29:21.977] iteration 4166 : loss : 0.111330, loss_ce: 0.029765
[00:29:22.270] iteration 4167 : loss : 0.092887, loss_ce: 0.018714
[00:29:22.559] iteration 4168 : loss : 0.081149, loss_ce: 0.023943
[00:29:22.847] iteration 4169 : loss : 0.075991, loss_ce: 0.019868
[00:29:22.926] iteration 4170 : loss : 0.139066, loss_ce: 0.017710
[00:29:39.710] iteration 4171 : loss : 0.188566, loss_ce: 0.015264
[00:29:39.994] iteration 4172 : loss : 0.083680, loss_ce: 0.041578
[00:29:40.281] iteration 4173 : loss : 0.086263, loss_ce: 0.022453
[00:29:40.569] iteration 4174 : loss : 0.063805, loss_ce: 0.019229
[00:29:40.857] iteration 4175 : loss : 0.079769, loss_ce: 0.037443
[00:29:41.145] iteration 4176 : loss : 0.098230, loss_ce: 0.013084
[00:29:41.432] iteration 4177 : loss : 0.069181, loss_ce: 0.012102
[00:29:41.722] iteration 4178 : loss : 0.101352, loss_ce: 0.018105
[00:29:42.012] iteration 4179 : loss : 0.065617, loss_ce: 0.017467
[00:29:42.299] iteration 4180 : loss : 0.138326, loss_ce: 0.017051
[00:29:42.600] iteration 4181 : loss : 0.297242, loss_ce: 0.016893
[00:29:42.888] iteration 4182 : loss : 0.174801, loss_ce: 0.024648
[00:29:43.175] iteration 4183 : loss : 0.071988, loss_ce: 0.011460
[00:29:43.465] iteration 4184 : loss : 0.191847, loss_ce: 0.015089
[00:29:43.750] iteration 4185 : loss : 0.118218, loss_ce: 0.036730
[00:29:44.040] iteration 4186 : loss : 0.088738, loss_ce: 0.032530
[00:29:44.330] iteration 4187 : loss : 0.168541, loss_ce: 0.024943
[00:29:44.615] iteration 4188 : loss : 0.074682, loss_ce: 0.034965
[00:29:44.902] iteration 4189 : loss : 0.145034, loss_ce: 0.014749
[00:29:45.193] iteration 4190 : loss : 0.137855, loss_ce: 0.030359
[00:29:45.478] iteration 4191 : loss : 0.084304, loss_ce: 0.019386
[00:29:45.767] iteration 4192 : loss : 0.063848, loss_ce: 0.025752
[00:29:46.057] iteration 4193 : loss : 0.094330, loss_ce: 0.029505
[00:29:46.344] iteration 4194 : loss : 0.074489, loss_ce: 0.027083
[00:29:46.629] iteration 4195 : loss : 0.130882, loss_ce: 0.022102
[00:29:46.916] iteration 4196 : loss : 0.065908, loss_ce: 0.011811
[00:29:47.204] iteration 4197 : loss : 0.083157, loss_ce: 0.030450
[00:29:47.491] iteration 4198 : loss : 0.149129, loss_ce: 0.023591
[00:29:47.776] iteration 4199 : loss : 0.138739, loss_ce: 0.028254
[00:29:48.064] iteration 4200 : loss : 0.239372, loss_ce: 0.012246
[00:29:48.365] iteration 4201 : loss : 0.082031, loss_ce: 0.046897
[00:29:48.652] iteration 4202 : loss : 0.146455, loss_ce: 0.020276
[00:29:48.940] iteration 4203 : loss : 0.120565, loss_ce: 0.019245
[00:29:49.226] iteration 4204 : loss : 0.123882, loss_ce: 0.016257
[00:29:49.513] iteration 4205 : loss : 0.091314, loss_ce: 0.019742
[00:29:49.800] iteration 4206 : loss : 0.074946, loss_ce: 0.022958
[00:29:50.089] iteration 4207 : loss : 0.076663, loss_ce: 0.030285
[00:29:50.379] iteration 4208 : loss : 0.113192, loss_ce: 0.018063
[00:29:50.666] iteration 4209 : loss : 0.127719, loss_ce: 0.011805
[00:29:50.953] iteration 4210 : loss : 0.080819, loss_ce: 0.026950
[00:29:51.241] iteration 4211 : loss : 0.064235, loss_ce: 0.024458
[00:29:51.528] iteration 4212 : loss : 0.079257, loss_ce: 0.017246
[00:29:51.816] iteration 4213 : loss : 0.079101, loss_ce: 0.017340
[00:29:52.104] iteration 4214 : loss : 0.171696, loss_ce: 0.011638
[00:29:52.392] iteration 4215 : loss : 0.148372, loss_ce: 0.026195
[00:29:52.680] iteration 4216 : loss : 0.097169, loss_ce: 0.022758
[00:29:52.967] iteration 4217 : loss : 0.149538, loss_ce: 0.011906
[00:29:53.253] iteration 4218 : loss : 0.142248, loss_ce: 0.038323
[00:29:53.543] iteration 4219 : loss : 0.104892, loss_ce: 0.024526
[00:29:53.831] iteration 4220 : loss : 0.079001, loss_ce: 0.028929
[00:29:54.136] iteration 4221 : loss : 0.068321, loss_ce: 0.025187
[00:29:54.425] iteration 4222 : loss : 0.103422, loss_ce: 0.037903
[00:29:54.715] iteration 4223 : loss : 0.065826, loss_ce: 0.028307
[00:29:55.002] iteration 4224 : loss : 0.108855, loss_ce: 0.038099
[00:29:55.289] iteration 4225 : loss : 0.131296, loss_ce: 0.017890
[00:29:55.577] iteration 4226 : loss : 0.081444, loss_ce: 0.026781
[00:29:55.863] iteration 4227 : loss : 0.139228, loss_ce: 0.017585
[00:29:56.150] iteration 4228 : loss : 0.058436, loss_ce: 0.010544
[00:29:56.437] iteration 4229 : loss : 0.077363, loss_ce: 0.023590
[00:29:56.726] iteration 4230 : loss : 0.112232, loss_ce: 0.027094
[00:29:57.012] iteration 4231 : loss : 0.078515, loss_ce: 0.025348
[00:29:57.299] iteration 4232 : loss : 0.120950, loss_ce: 0.018210
[00:29:57.586] iteration 4233 : loss : 0.110257, loss_ce: 0.024694
[00:29:57.873] iteration 4234 : loss : 0.076345, loss_ce: 0.015559
[00:29:58.160] iteration 4235 : loss : 0.080238, loss_ce: 0.043160
[00:29:58.449] iteration 4236 : loss : 0.089015, loss_ce: 0.042062
[00:29:58.737] iteration 4237 : loss : 0.080825, loss_ce: 0.027266
[00:29:59.025] iteration 4238 : loss : 0.092264, loss_ce: 0.028738
[00:29:59.311] iteration 4239 : loss : 0.243131, loss_ce: 0.016462
[00:29:59.599] iteration 4240 : loss : 0.066224, loss_ce: 0.016939
[00:29:59.903] iteration 4241 : loss : 0.081496, loss_ce: 0.021703
[00:30:00.193] iteration 4242 : loss : 0.114122, loss_ce: 0.021145
[00:30:00.481] iteration 4243 : loss : 0.077359, loss_ce: 0.020769
[00:30:00.773] iteration 4244 : loss : 0.061234, loss_ce: 0.016849
[00:30:01.063] iteration 4245 : loss : 0.077293, loss_ce: 0.019054
[00:30:01.350] iteration 4246 : loss : 0.190140, loss_ce: 0.012906
[00:30:01.637] iteration 4247 : loss : 0.096862, loss_ce: 0.034729
[00:30:01.925] iteration 4248 : loss : 0.081297, loss_ce: 0.028158
[00:30:02.215] iteration 4249 : loss : 0.073870, loss_ce: 0.024700
[00:30:02.502] iteration 4250 : loss : 0.105038, loss_ce: 0.018469
[00:30:02.791] iteration 4251 : loss : 0.073794, loss_ce: 0.020027
[00:30:03.078] iteration 4252 : loss : 0.107698, loss_ce: 0.021638
[00:30:03.367] iteration 4253 : loss : 0.126715, loss_ce: 0.033998
[00:30:03.654] iteration 4254 : loss : 0.102858, loss_ce: 0.038615
[00:30:03.944] iteration 4255 : loss : 0.129964, loss_ce: 0.024229
[00:30:04.231] iteration 4256 : loss : 0.061600, loss_ce: 0.026853
[00:30:04.519] iteration 4257 : loss : 0.120596, loss_ce: 0.006986
[00:30:04.808] iteration 4258 : loss : 0.066453, loss_ce: 0.010656
[00:30:05.098] iteration 4259 : loss : 0.087156, loss_ce: 0.026660
[00:30:05.386] iteration 4260 : loss : 0.107880, loss_ce: 0.035245
[00:30:05.688] iteration 4261 : loss : 0.070178, loss_ce: 0.024695
[00:30:05.978] iteration 4262 : loss : 0.091550, loss_ce: 0.035314
[00:30:06.265] iteration 4263 : loss : 0.066406, loss_ce: 0.020351
[00:30:06.552] iteration 4264 : loss : 0.065593, loss_ce: 0.013702
[00:30:06.841] iteration 4265 : loss : 0.091589, loss_ce: 0.019542
[00:30:07.129] iteration 4266 : loss : 0.085031, loss_ce: 0.010411
[00:30:07.419] iteration 4267 : loss : 0.076500, loss_ce: 0.012333
[00:30:07.706] iteration 4268 : loss : 0.114173, loss_ce: 0.038002
[00:30:07.994] iteration 4269 : loss : 0.092040, loss_ce: 0.029436
[00:30:08.282] iteration 4270 : loss : 0.100415, loss_ce: 0.017649
[00:30:08.570] iteration 4271 : loss : 0.135500, loss_ce: 0.015395
[00:30:08.860] iteration 4272 : loss : 0.078548, loss_ce: 0.031132
[00:30:09.151] iteration 4273 : loss : 0.085693, loss_ce: 0.034629
[00:30:09.438] iteration 4274 : loss : 0.070834, loss_ce: 0.023425
[00:30:09.725] iteration 4275 : loss : 0.097928, loss_ce: 0.038532
[00:30:10.013] iteration 4276 : loss : 0.166894, loss_ce: 0.046513
[00:30:10.304] iteration 4277 : loss : 0.073599, loss_ce: 0.024507
[00:30:10.591] iteration 4278 : loss : 0.116624, loss_ce: 0.026608
[00:30:10.880] iteration 4279 : loss : 0.124285, loss_ce: 0.024761
[00:30:11.168] iteration 4280 : loss : 0.079582, loss_ce: 0.023592
[00:30:11.468] iteration 4281 : loss : 0.070622, loss_ce: 0.017955
[00:30:11.757] iteration 4282 : loss : 0.125463, loss_ce: 0.020377
[00:30:12.044] iteration 4283 : loss : 0.104675, loss_ce: 0.029184
[00:30:12.331] iteration 4284 : loss : 0.084820, loss_ce: 0.029294
[00:30:12.617] iteration 4285 : loss : 0.088003, loss_ce: 0.026213
[00:30:12.908] iteration 4286 : loss : 0.131013, loss_ce: 0.014497
[00:30:13.196] iteration 4287 : loss : 0.062640, loss_ce: 0.019836
[00:30:13.483] iteration 4288 : loss : 0.082776, loss_ce: 0.023634
[00:30:13.773] iteration 4289 : loss : 0.177184, loss_ce: 0.015762
[00:30:14.060] iteration 4290 : loss : 0.180853, loss_ce: 0.021046
[00:30:14.348] iteration 4291 : loss : 0.087454, loss_ce: 0.026754
[00:30:14.635] iteration 4292 : loss : 0.083780, loss_ce: 0.025998
[00:30:14.926] iteration 4293 : loss : 0.064643, loss_ce: 0.020995
[00:30:15.219] iteration 4294 : loss : 0.068261, loss_ce: 0.010909
[00:30:15.515] iteration 4295 : loss : 0.114642, loss_ce: 0.020130
[00:30:15.804] iteration 4296 : loss : 0.083745, loss_ce: 0.024914
[00:30:16.092] iteration 4297 : loss : 0.133591, loss_ce: 0.011925
[00:30:16.382] iteration 4298 : loss : 0.092676, loss_ce: 0.020974
[00:30:16.672] iteration 4299 : loss : 0.139996, loss_ce: 0.021993
[00:30:16.961] iteration 4300 : loss : 0.079969, loss_ce: 0.033275
[00:30:17.271] iteration 4301 : loss : 0.060215, loss_ce: 0.029678
[00:30:17.561] iteration 4302 : loss : 0.083462, loss_ce: 0.031107
[00:30:17.853] iteration 4303 : loss : 0.127565, loss_ce: 0.022283
[00:30:18.143] iteration 4304 : loss : 0.079883, loss_ce: 0.023382
[00:30:18.432] iteration 4305 : loss : 0.072501, loss_ce: 0.016502
[00:30:18.720] iteration 4306 : loss : 0.124661, loss_ce: 0.017521
[00:30:19.011] iteration 4307 : loss : 0.069331, loss_ce: 0.020759
[00:30:19.299] iteration 4308 : loss : 0.167580, loss_ce: 0.017748
[00:30:19.376] iteration 4309 : loss : 0.369269, loss_ce: 0.011090
[00:30:19.915] save model to ./logs/swin_unet\epoch_30.pth
[00:30:36.047] iteration 4310 : loss : 0.061834, loss_ce: 0.017823
[00:30:36.332] iteration 4311 : loss : 0.080258, loss_ce: 0.027607
[00:30:36.616] iteration 4312 : loss : 0.111069, loss_ce: 0.029328
[00:30:36.904] iteration 4313 : loss : 0.101886, loss_ce: 0.030629
[00:30:37.192] iteration 4314 : loss : 0.078981, loss_ce: 0.034901
[00:30:37.481] iteration 4315 : loss : 0.105453, loss_ce: 0.015377
[00:30:37.771] iteration 4316 : loss : 0.140602, loss_ce: 0.019318
[00:30:38.058] iteration 4317 : loss : 0.084040, loss_ce: 0.024031
[00:30:38.348] iteration 4318 : loss : 0.070490, loss_ce: 0.017909
[00:30:38.635] iteration 4319 : loss : 0.101202, loss_ce: 0.028398
[00:30:38.921] iteration 4320 : loss : 0.162123, loss_ce: 0.023252
[00:30:39.230] iteration 4321 : loss : 0.081051, loss_ce: 0.036506
[00:30:39.518] iteration 4322 : loss : 0.091769, loss_ce: 0.033204
[00:30:39.805] iteration 4323 : loss : 0.133065, loss_ce: 0.019499
[00:30:40.093] iteration 4324 : loss : 0.067314, loss_ce: 0.016343
[00:30:40.380] iteration 4325 : loss : 0.058158, loss_ce: 0.010441
[00:30:40.665] iteration 4326 : loss : 0.164204, loss_ce: 0.010133
[00:30:40.955] iteration 4327 : loss : 0.124460, loss_ce: 0.025782
[00:30:41.244] iteration 4328 : loss : 0.117751, loss_ce: 0.037572
[00:30:41.534] iteration 4329 : loss : 0.091997, loss_ce: 0.021237
[00:30:41.820] iteration 4330 : loss : 0.121561, loss_ce: 0.011443
[00:30:42.111] iteration 4331 : loss : 0.153465, loss_ce: 0.022615
[00:30:42.397] iteration 4332 : loss : 0.086498, loss_ce: 0.019586
[00:30:42.685] iteration 4333 : loss : 0.086157, loss_ce: 0.019745
[00:30:42.970] iteration 4334 : loss : 0.083458, loss_ce: 0.022730
[00:30:43.258] iteration 4335 : loss : 0.117390, loss_ce: 0.031942
[00:30:43.547] iteration 4336 : loss : 0.094165, loss_ce: 0.033758
[00:30:43.833] iteration 4337 : loss : 0.086157, loss_ce: 0.031741
[00:30:44.118] iteration 4338 : loss : 0.055440, loss_ce: 0.013511
[00:30:44.408] iteration 4339 : loss : 0.115678, loss_ce: 0.016929
[00:30:44.697] iteration 4340 : loss : 0.211534, loss_ce: 0.007905
[00:30:45.000] iteration 4341 : loss : 0.072469, loss_ce: 0.027910
[00:30:45.291] iteration 4342 : loss : 0.172853, loss_ce: 0.032839
[00:30:45.580] iteration 4343 : loss : 0.069357, loss_ce: 0.023079
[00:30:45.864] iteration 4344 : loss : 0.152278, loss_ce: 0.023092
[00:30:46.152] iteration 4345 : loss : 0.240638, loss_ce: 0.008083
[00:30:46.441] iteration 4346 : loss : 0.091657, loss_ce: 0.024211
[00:30:46.731] iteration 4347 : loss : 0.080804, loss_ce: 0.020158
[00:30:47.017] iteration 4348 : loss : 0.076654, loss_ce: 0.019188
[00:30:47.305] iteration 4349 : loss : 0.109558, loss_ce: 0.023953
[00:30:47.594] iteration 4350 : loss : 0.197296, loss_ce: 0.016271
[00:30:47.880] iteration 4351 : loss : 0.118550, loss_ce: 0.013536
[00:30:48.170] iteration 4352 : loss : 0.077151, loss_ce: 0.020275
[00:30:48.455] iteration 4353 : loss : 0.071901, loss_ce: 0.022505
[00:30:48.741] iteration 4354 : loss : 0.130999, loss_ce: 0.025763
[00:30:49.028] iteration 4355 : loss : 0.067075, loss_ce: 0.026768
[00:30:49.315] iteration 4356 : loss : 0.116473, loss_ce: 0.024479
[00:30:49.603] iteration 4357 : loss : 0.083324, loss_ce: 0.021541
[00:30:49.891] iteration 4358 : loss : 0.069296, loss_ce: 0.023081
[00:30:50.182] iteration 4359 : loss : 0.079750, loss_ce: 0.017252
[00:30:50.471] iteration 4360 : loss : 0.105528, loss_ce: 0.015354
[00:30:50.776] iteration 4361 : loss : 0.086700, loss_ce: 0.020440
[00:30:51.067] iteration 4362 : loss : 0.092046, loss_ce: 0.021548
[00:30:51.356] iteration 4363 : loss : 0.122208, loss_ce: 0.023281
[00:30:51.646] iteration 4364 : loss : 0.070228, loss_ce: 0.031447
[00:30:51.935] iteration 4365 : loss : 0.089414, loss_ce: 0.027056
[00:30:52.224] iteration 4366 : loss : 0.097953, loss_ce: 0.026177
[00:30:52.516] iteration 4367 : loss : 0.059996, loss_ce: 0.019644
[00:30:52.805] iteration 4368 : loss : 0.087827, loss_ce: 0.029000
[00:30:53.091] iteration 4369 : loss : 0.081293, loss_ce: 0.025358
[00:30:53.381] iteration 4370 : loss : 0.094515, loss_ce: 0.022256
[00:30:53.669] iteration 4371 : loss : 0.101050, loss_ce: 0.030542
[00:30:53.962] iteration 4372 : loss : 0.066428, loss_ce: 0.019774
[00:30:54.251] iteration 4373 : loss : 0.094996, loss_ce: 0.023309
[00:30:54.541] iteration 4374 : loss : 0.073771, loss_ce: 0.021407
[00:30:54.828] iteration 4375 : loss : 0.076038, loss_ce: 0.015234
[00:30:55.121] iteration 4376 : loss : 0.191286, loss_ce: 0.022828
[00:30:55.412] iteration 4377 : loss : 0.087311, loss_ce: 0.021919
[00:30:55.703] iteration 4378 : loss : 0.084154, loss_ce: 0.043681
[00:30:55.990] iteration 4379 : loss : 0.083280, loss_ce: 0.022753
[00:30:56.280] iteration 4380 : loss : 0.093063, loss_ce: 0.019690
[00:30:56.583] iteration 4381 : loss : 0.091519, loss_ce: 0.023333
[00:30:56.871] iteration 4382 : loss : 0.081256, loss_ce: 0.034327
[00:30:57.162] iteration 4383 : loss : 0.074560, loss_ce: 0.022401
[00:30:57.450] iteration 4384 : loss : 0.131169, loss_ce: 0.015301
[00:30:57.737] iteration 4385 : loss : 0.085284, loss_ce: 0.025787
[00:30:58.023] iteration 4386 : loss : 0.166586, loss_ce: 0.013423
[00:30:58.313] iteration 4387 : loss : 0.070137, loss_ce: 0.021873
[00:30:58.605] iteration 4388 : loss : 0.130449, loss_ce: 0.013252
[00:30:58.895] iteration 4389 : loss : 0.073896, loss_ce: 0.027626
[00:30:59.184] iteration 4390 : loss : 0.062939, loss_ce: 0.034945
[00:30:59.475] iteration 4391 : loss : 0.087592, loss_ce: 0.021388
[00:30:59.764] iteration 4392 : loss : 0.137491, loss_ce: 0.018042
[00:31:00.051] iteration 4393 : loss : 0.089273, loss_ce: 0.017668
[00:31:00.348] iteration 4394 : loss : 0.078097, loss_ce: 0.015690
[00:31:00.636] iteration 4395 : loss : 0.071314, loss_ce: 0.021007
[00:31:00.933] iteration 4396 : loss : 0.070654, loss_ce: 0.030291
[00:31:01.226] iteration 4397 : loss : 0.128961, loss_ce: 0.018485
[00:31:01.515] iteration 4398 : loss : 0.123944, loss_ce: 0.020799
[00:31:01.802] iteration 4399 : loss : 0.086008, loss_ce: 0.046727
[00:31:02.092] iteration 4400 : loss : 0.085421, loss_ce: 0.025216
[00:31:02.397] iteration 4401 : loss : 0.117136, loss_ce: 0.012075
[00:31:02.689] iteration 4402 : loss : 0.093968, loss_ce: 0.023149
[00:31:02.977] iteration 4403 : loss : 0.169613, loss_ce: 0.015668
[00:31:03.268] iteration 4404 : loss : 0.135367, loss_ce: 0.036091
[00:31:03.557] iteration 4405 : loss : 0.087709, loss_ce: 0.023008
[00:31:03.848] iteration 4406 : loss : 0.135074, loss_ce: 0.029744
[00:31:04.136] iteration 4407 : loss : 0.097114, loss_ce: 0.048497
[00:31:04.427] iteration 4408 : loss : 0.067185, loss_ce: 0.022975
[00:31:04.714] iteration 4409 : loss : 0.152067, loss_ce: 0.012211
[00:31:05.003] iteration 4410 : loss : 0.066539, loss_ce: 0.016947
[00:31:05.292] iteration 4411 : loss : 0.146350, loss_ce: 0.030182
[00:31:05.581] iteration 4412 : loss : 0.116959, loss_ce: 0.020538
[00:31:05.872] iteration 4413 : loss : 0.061942, loss_ce: 0.026072
[00:31:06.162] iteration 4414 : loss : 0.097741, loss_ce: 0.030210
[00:31:06.453] iteration 4415 : loss : 0.098841, loss_ce: 0.029802
[00:31:06.740] iteration 4416 : loss : 0.095024, loss_ce: 0.038693
[00:31:07.029] iteration 4417 : loss : 0.135970, loss_ce: 0.012961
[00:31:07.321] iteration 4418 : loss : 0.097313, loss_ce: 0.013563
[00:31:07.610] iteration 4419 : loss : 0.076029, loss_ce: 0.033918
[00:31:07.900] iteration 4420 : loss : 0.156182, loss_ce: 0.011921
[00:31:08.209] iteration 4421 : loss : 0.086510, loss_ce: 0.030821
[00:31:08.496] iteration 4422 : loss : 0.088645, loss_ce: 0.024948
[00:31:08.784] iteration 4423 : loss : 0.107256, loss_ce: 0.038933
[00:31:09.072] iteration 4424 : loss : 0.244824, loss_ce: 0.023532
[00:31:09.361] iteration 4425 : loss : 0.085717, loss_ce: 0.030479
[00:31:09.649] iteration 4426 : loss : 0.070029, loss_ce: 0.026824
[00:31:09.940] iteration 4427 : loss : 0.108765, loss_ce: 0.042058
[00:31:10.229] iteration 4428 : loss : 0.090653, loss_ce: 0.024089
[00:31:10.520] iteration 4429 : loss : 0.096178, loss_ce: 0.018755
[00:31:10.813] iteration 4430 : loss : 0.140914, loss_ce: 0.013084
[00:31:11.098] iteration 4431 : loss : 0.144415, loss_ce: 0.007126
[00:31:11.390] iteration 4432 : loss : 0.082215, loss_ce: 0.022777
[00:31:11.680] iteration 4433 : loss : 0.083042, loss_ce: 0.026925
[00:31:11.976] iteration 4434 : loss : 0.074841, loss_ce: 0.023529
[00:31:12.267] iteration 4435 : loss : 0.114545, loss_ce: 0.023092
[00:31:12.562] iteration 4436 : loss : 0.085994, loss_ce: 0.037708
[00:31:12.857] iteration 4437 : loss : 0.070901, loss_ce: 0.015138
[00:31:13.151] iteration 4438 : loss : 0.170293, loss_ce: 0.013260
[00:31:13.443] iteration 4439 : loss : 0.143710, loss_ce: 0.015272
[00:31:13.733] iteration 4440 : loss : 0.088804, loss_ce: 0.041511
[00:31:14.059] iteration 4441 : loss : 0.146549, loss_ce: 0.023234
[00:31:14.351] iteration 4442 : loss : 0.062601, loss_ce: 0.024863
[00:31:14.644] iteration 4443 : loss : 0.079354, loss_ce: 0.018537
[00:31:14.937] iteration 4444 : loss : 0.082790, loss_ce: 0.033266
[00:31:15.233] iteration 4445 : loss : 0.127448, loss_ce: 0.023909
[00:31:15.526] iteration 4446 : loss : 0.126515, loss_ce: 0.016384
[00:31:15.820] iteration 4447 : loss : 0.133846, loss_ce: 0.014962
[00:31:15.899] iteration 4448 : loss : 0.159302, loss_ce: 0.027239
[00:31:32.648] iteration 4449 : loss : 0.078158, loss_ce: 0.017074
[00:31:32.935] iteration 4450 : loss : 0.084275, loss_ce: 0.032952
[00:31:33.221] iteration 4451 : loss : 0.101170, loss_ce: 0.028062
[00:31:33.509] iteration 4452 : loss : 0.130893, loss_ce: 0.018941
[00:31:33.797] iteration 4453 : loss : 0.077123, loss_ce: 0.016566
[00:31:34.083] iteration 4454 : loss : 0.065062, loss_ce: 0.022045
[00:31:34.370] iteration 4455 : loss : 0.067097, loss_ce: 0.018443
[00:31:34.659] iteration 4456 : loss : 0.092867, loss_ce: 0.032826
[00:31:34.950] iteration 4457 : loss : 0.128506, loss_ce: 0.023646
[00:31:35.240] iteration 4458 : loss : 0.141118, loss_ce: 0.017440
[00:31:35.527] iteration 4459 : loss : 0.085420, loss_ce: 0.023359
[00:31:35.812] iteration 4460 : loss : 0.138244, loss_ce: 0.028686
[00:31:36.112] iteration 4461 : loss : 0.191852, loss_ce: 0.006908
[00:31:36.397] iteration 4462 : loss : 0.101187, loss_ce: 0.039112
[00:31:36.685] iteration 4463 : loss : 0.153819, loss_ce: 0.008512
[00:31:36.971] iteration 4464 : loss : 0.066316, loss_ce: 0.012417
[00:31:37.257] iteration 4465 : loss : 0.171141, loss_ce: 0.013208
[00:31:37.543] iteration 4466 : loss : 0.106530, loss_ce: 0.030181
[00:31:37.834] iteration 4467 : loss : 0.087905, loss_ce: 0.029825
[00:31:38.120] iteration 4468 : loss : 0.123051, loss_ce: 0.039708
[00:31:38.407] iteration 4469 : loss : 0.119628, loss_ce: 0.034414
[00:31:38.696] iteration 4470 : loss : 0.085396, loss_ce: 0.029898
[00:31:38.984] iteration 4471 : loss : 0.101284, loss_ce: 0.031356
[00:31:39.271] iteration 4472 : loss : 0.085319, loss_ce: 0.021382
[00:31:39.556] iteration 4473 : loss : 0.194357, loss_ce: 0.017408
[00:31:39.846] iteration 4474 : loss : 0.076139, loss_ce: 0.041930
[00:31:40.133] iteration 4475 : loss : 0.075774, loss_ce: 0.026748
[00:31:40.424] iteration 4476 : loss : 0.072099, loss_ce: 0.021300
[00:31:40.710] iteration 4477 : loss : 0.071222, loss_ce: 0.023116
[00:31:40.998] iteration 4478 : loss : 0.173277, loss_ce: 0.009882
[00:31:41.286] iteration 4479 : loss : 0.200894, loss_ce: 0.023408
[00:31:41.573] iteration 4480 : loss : 0.092218, loss_ce: 0.027742
[00:31:41.882] iteration 4481 : loss : 0.190130, loss_ce: 0.009543
[00:31:42.168] iteration 4482 : loss : 0.082635, loss_ce: 0.025079
[00:31:42.456] iteration 4483 : loss : 0.101355, loss_ce: 0.014528
[00:31:42.743] iteration 4484 : loss : 0.259214, loss_ce: 0.004726
[00:31:43.031] iteration 4485 : loss : 0.154952, loss_ce: 0.014233
[00:31:43.315] iteration 4486 : loss : 0.076181, loss_ce: 0.024049
[00:31:43.604] iteration 4487 : loss : 0.184449, loss_ce: 0.010183
[00:31:43.894] iteration 4488 : loss : 0.092059, loss_ce: 0.033907
[00:31:44.181] iteration 4489 : loss : 0.101565, loss_ce: 0.029100
[00:31:44.469] iteration 4490 : loss : 0.112204, loss_ce: 0.031873
[00:31:44.759] iteration 4491 : loss : 0.064939, loss_ce: 0.016951
[00:31:45.044] iteration 4492 : loss : 0.125557, loss_ce: 0.018955
[00:31:45.332] iteration 4493 : loss : 0.065913, loss_ce: 0.021860
[00:31:45.619] iteration 4494 : loss : 0.082429, loss_ce: 0.020770
[00:31:45.909] iteration 4495 : loss : 0.110231, loss_ce: 0.012421
[00:31:46.197] iteration 4496 : loss : 0.069903, loss_ce: 0.025296
[00:31:46.483] iteration 4497 : loss : 0.124968, loss_ce: 0.028738
[00:31:46.770] iteration 4498 : loss : 0.094053, loss_ce: 0.034782
[00:31:47.058] iteration 4499 : loss : 0.092285, loss_ce: 0.019213
[00:31:47.346] iteration 4500 : loss : 0.087769, loss_ce: 0.026241
[00:31:47.648] iteration 4501 : loss : 0.131243, loss_ce: 0.010439
[00:31:47.934] iteration 4502 : loss : 0.068880, loss_ce: 0.017991
[00:31:48.220] iteration 4503 : loss : 0.076930, loss_ce: 0.019154
[00:31:48.507] iteration 4504 : loss : 0.084752, loss_ce: 0.032782
[00:31:48.794] iteration 4505 : loss : 0.074754, loss_ce: 0.025536
[00:31:49.082] iteration 4506 : loss : 0.072204, loss_ce: 0.020423
[00:31:49.371] iteration 4507 : loss : 0.082859, loss_ce: 0.015885
[00:31:49.660] iteration 4508 : loss : 0.125290, loss_ce: 0.012798
[00:31:49.947] iteration 4509 : loss : 0.087312, loss_ce: 0.024744
[00:31:50.237] iteration 4510 : loss : 0.107989, loss_ce: 0.015647
[00:31:50.526] iteration 4511 : loss : 0.087948, loss_ce: 0.026162
[00:31:50.814] iteration 4512 : loss : 0.078570, loss_ce: 0.017495
[00:31:51.101] iteration 4513 : loss : 0.076482, loss_ce: 0.010060
[00:31:51.389] iteration 4514 : loss : 0.127691, loss_ce: 0.019606
[00:31:51.677] iteration 4515 : loss : 0.129243, loss_ce: 0.016753
[00:31:51.962] iteration 4516 : loss : 0.153902, loss_ce: 0.013439
[00:31:52.248] iteration 4517 : loss : 0.060868, loss_ce: 0.030248
[00:31:52.536] iteration 4518 : loss : 0.077604, loss_ce: 0.030464
[00:31:52.824] iteration 4519 : loss : 0.082829, loss_ce: 0.030941
[00:31:53.110] iteration 4520 : loss : 0.071773, loss_ce: 0.036944
[00:31:53.410] iteration 4521 : loss : 0.069824, loss_ce: 0.028687
[00:31:53.698] iteration 4522 : loss : 0.079547, loss_ce: 0.031369
[00:31:53.986] iteration 4523 : loss : 0.138792, loss_ce: 0.023423
[00:31:54.273] iteration 4524 : loss : 0.084444, loss_ce: 0.029806
[00:31:54.559] iteration 4525 : loss : 0.067471, loss_ce: 0.025510
[00:31:54.846] iteration 4526 : loss : 0.104584, loss_ce: 0.016616
[00:31:55.130] iteration 4527 : loss : 0.082110, loss_ce: 0.022612
[00:31:55.417] iteration 4528 : loss : 0.093375, loss_ce: 0.025487
[00:31:55.704] iteration 4529 : loss : 0.135133, loss_ce: 0.018598
[00:31:55.991] iteration 4530 : loss : 0.054197, loss_ce: 0.013755
[00:31:56.280] iteration 4531 : loss : 0.104979, loss_ce: 0.024134
[00:31:56.569] iteration 4532 : loss : 0.087820, loss_ce: 0.021508
[00:31:56.858] iteration 4533 : loss : 0.106418, loss_ce: 0.026532
[00:31:57.145] iteration 4534 : loss : 0.104195, loss_ce: 0.035164
[00:31:57.432] iteration 4535 : loss : 0.178639, loss_ce: 0.016448
[00:31:57.721] iteration 4536 : loss : 0.141211, loss_ce: 0.009440
[00:31:58.007] iteration 4537 : loss : 0.090680, loss_ce: 0.019716
[00:31:58.294] iteration 4538 : loss : 0.099917, loss_ce: 0.046283
[00:31:58.579] iteration 4539 : loss : 0.094408, loss_ce: 0.028566
[00:31:58.868] iteration 4540 : loss : 0.093641, loss_ce: 0.036904
[00:31:59.172] iteration 4541 : loss : 0.206429, loss_ce: 0.011074
[00:31:59.459] iteration 4542 : loss : 0.141295, loss_ce: 0.029358
[00:31:59.744] iteration 4543 : loss : 0.082263, loss_ce: 0.019545
[00:32:00.033] iteration 4544 : loss : 0.120503, loss_ce: 0.021310
[00:32:00.323] iteration 4545 : loss : 0.106964, loss_ce: 0.045179
[00:32:00.609] iteration 4546 : loss : 0.123666, loss_ce: 0.019019
[00:32:00.900] iteration 4547 : loss : 0.069372, loss_ce: 0.018834
[00:32:01.190] iteration 4548 : loss : 0.083241, loss_ce: 0.029135
[00:32:01.477] iteration 4549 : loss : 0.107904, loss_ce: 0.012419
[00:32:01.763] iteration 4550 : loss : 0.139539, loss_ce: 0.004753
[00:32:02.050] iteration 4551 : loss : 0.087549, loss_ce: 0.022360
[00:32:02.337] iteration 4552 : loss : 0.087763, loss_ce: 0.013296
[00:32:02.627] iteration 4553 : loss : 0.144003, loss_ce: 0.024842
[00:32:02.914] iteration 4554 : loss : 0.067849, loss_ce: 0.030520
[00:32:03.200] iteration 4555 : loss : 0.076442, loss_ce: 0.033362
[00:32:03.489] iteration 4556 : loss : 0.073222, loss_ce: 0.019281
[00:32:03.774] iteration 4557 : loss : 0.081640, loss_ce: 0.019147
[00:32:04.061] iteration 4558 : loss : 0.086314, loss_ce: 0.025059
[00:32:04.349] iteration 4559 : loss : 0.104897, loss_ce: 0.033921
[00:32:04.635] iteration 4560 : loss : 0.215375, loss_ce: 0.029143
[00:32:04.936] iteration 4561 : loss : 0.070672, loss_ce: 0.029478
[00:32:05.223] iteration 4562 : loss : 0.138370, loss_ce: 0.017664
[00:32:05.511] iteration 4563 : loss : 0.096533, loss_ce: 0.028766
[00:32:05.799] iteration 4564 : loss : 0.088818, loss_ce: 0.028251
[00:32:06.086] iteration 4565 : loss : 0.073519, loss_ce: 0.027425
[00:32:06.372] iteration 4566 : loss : 0.125558, loss_ce: 0.021710
[00:32:06.662] iteration 4567 : loss : 0.093755, loss_ce: 0.014127
[00:32:06.949] iteration 4568 : loss : 0.104826, loss_ce: 0.015626
[00:32:07.237] iteration 4569 : loss : 0.217257, loss_ce: 0.019160
[00:32:07.524] iteration 4570 : loss : 0.098305, loss_ce: 0.034916
[00:32:07.814] iteration 4571 : loss : 0.135428, loss_ce: 0.054078
[00:32:08.106] iteration 4572 : loss : 0.108287, loss_ce: 0.034569
[00:32:08.396] iteration 4573 : loss : 0.112390, loss_ce: 0.023927
[00:32:08.684] iteration 4574 : loss : 0.166919, loss_ce: 0.054006
[00:32:08.974] iteration 4575 : loss : 0.209378, loss_ce: 0.041076
[00:32:09.263] iteration 4576 : loss : 0.144146, loss_ce: 0.052770
[00:32:09.554] iteration 4577 : loss : 0.147197, loss_ce: 0.041468
[00:32:09.843] iteration 4578 : loss : 0.168353, loss_ce: 0.044764
[00:32:10.136] iteration 4579 : loss : 0.166498, loss_ce: 0.022039
[00:32:10.430] iteration 4580 : loss : 0.131461, loss_ce: 0.027134
[00:32:10.738] iteration 4581 : loss : 0.120924, loss_ce: 0.066943
[00:32:11.033] iteration 4582 : loss : 0.098152, loss_ce: 0.031188
[00:32:11.322] iteration 4583 : loss : 0.155362, loss_ce: 0.050088
[00:32:11.612] iteration 4584 : loss : 0.126232, loss_ce: 0.034463
[00:32:11.902] iteration 4585 : loss : 0.135175, loss_ce: 0.048959
[00:32:12.192] iteration 4586 : loss : 0.125820, loss_ce: 0.022451
[00:32:12.268] iteration 4587 : loss : 0.325213, loss_ce: 0.037713
[00:32:28.814] iteration 4588 : loss : 0.148166, loss_ce: 0.023214
[00:32:29.098] iteration 4589 : loss : 0.119698, loss_ce: 0.033237
[00:32:29.382] iteration 4590 : loss : 0.144772, loss_ce: 0.018973
[00:32:29.671] iteration 4591 : loss : 0.138357, loss_ce: 0.027996
[00:32:29.957] iteration 4592 : loss : 0.208795, loss_ce: 0.061860
[00:32:30.244] iteration 4593 : loss : 0.102361, loss_ce: 0.025674
[00:32:30.531] iteration 4594 : loss : 0.108639, loss_ce: 0.041523
[00:32:30.817] iteration 4595 : loss : 0.178732, loss_ce: 0.010996
[00:32:31.104] iteration 4596 : loss : 0.094393, loss_ce: 0.025223
[00:32:31.393] iteration 4597 : loss : 0.173394, loss_ce: 0.020527
[00:32:31.680] iteration 4598 : loss : 0.118755, loss_ce: 0.027280
[00:32:31.968] iteration 4599 : loss : 0.081345, loss_ce: 0.025869
[00:32:32.254] iteration 4600 : loss : 0.095706, loss_ce: 0.032703
[00:32:32.555] iteration 4601 : loss : 0.135118, loss_ce: 0.045096
[00:32:32.844] iteration 4602 : loss : 0.136388, loss_ce: 0.026138
[00:32:33.131] iteration 4603 : loss : 0.074208, loss_ce: 0.017478
[00:32:33.417] iteration 4604 : loss : 0.093282, loss_ce: 0.025674
[00:32:33.704] iteration 4605 : loss : 0.085839, loss_ce: 0.019230
[00:32:33.990] iteration 4606 : loss : 0.071194, loss_ce: 0.016779
[00:32:34.277] iteration 4607 : loss : 0.093832, loss_ce: 0.018407
[00:32:34.564] iteration 4608 : loss : 0.111723, loss_ce: 0.038854
[00:32:34.850] iteration 4609 : loss : 0.083627, loss_ce: 0.023622
[00:32:35.138] iteration 4610 : loss : 0.127191, loss_ce: 0.027299
[00:32:35.423] iteration 4611 : loss : 0.085756, loss_ce: 0.020635
[00:32:35.712] iteration 4612 : loss : 0.192191, loss_ce: 0.032636
[00:32:35.999] iteration 4613 : loss : 0.134771, loss_ce: 0.023542
[00:32:36.284] iteration 4614 : loss : 0.073880, loss_ce: 0.020473
[00:32:36.573] iteration 4615 : loss : 0.170180, loss_ce: 0.033829
[00:32:36.858] iteration 4616 : loss : 0.071285, loss_ce: 0.030266
[00:32:37.147] iteration 4617 : loss : 0.087679, loss_ce: 0.023198
[00:32:37.434] iteration 4618 : loss : 0.106551, loss_ce: 0.033162
[00:32:37.719] iteration 4619 : loss : 0.098560, loss_ce: 0.042079
[00:32:38.006] iteration 4620 : loss : 0.192418, loss_ce: 0.049448
[00:32:38.305] iteration 4621 : loss : 0.106778, loss_ce: 0.026214
[00:32:38.593] iteration 4622 : loss : 0.148274, loss_ce: 0.022562
[00:32:38.881] iteration 4623 : loss : 0.141608, loss_ce: 0.036918
[00:32:39.168] iteration 4624 : loss : 0.186466, loss_ce: 0.008255
[00:32:39.456] iteration 4625 : loss : 0.067635, loss_ce: 0.010713
[00:32:39.742] iteration 4626 : loss : 0.089753, loss_ce: 0.026309
[00:32:40.031] iteration 4627 : loss : 0.149449, loss_ce: 0.023906
[00:32:40.318] iteration 4628 : loss : 0.208060, loss_ce: 0.020136
[00:32:40.609] iteration 4629 : loss : 0.181707, loss_ce: 0.015944
[00:32:40.895] iteration 4630 : loss : 0.130230, loss_ce: 0.029304
[00:32:41.181] iteration 4631 : loss : 0.137947, loss_ce: 0.020104
[00:32:41.468] iteration 4632 : loss : 0.075873, loss_ce: 0.035531
[00:32:41.753] iteration 4633 : loss : 0.088433, loss_ce: 0.024191
[00:32:42.040] iteration 4634 : loss : 0.114842, loss_ce: 0.028321
[00:32:42.326] iteration 4635 : loss : 0.080694, loss_ce: 0.020245
[00:32:42.614] iteration 4636 : loss : 0.076450, loss_ce: 0.032826
[00:32:42.901] iteration 4637 : loss : 0.084492, loss_ce: 0.029728
[00:32:43.190] iteration 4638 : loss : 0.089505, loss_ce: 0.019996
[00:32:43.479] iteration 4639 : loss : 0.129413, loss_ce: 0.022220
[00:32:43.765] iteration 4640 : loss : 0.128295, loss_ce: 0.023364
[00:32:44.067] iteration 4641 : loss : 0.132552, loss_ce: 0.012983
[00:32:44.353] iteration 4642 : loss : 0.064746, loss_ce: 0.025106
[00:32:44.640] iteration 4643 : loss : 0.073372, loss_ce: 0.017820
[00:32:44.931] iteration 4644 : loss : 0.129800, loss_ce: 0.020497
[00:32:45.219] iteration 4645 : loss : 0.067089, loss_ce: 0.014768
[00:32:45.507] iteration 4646 : loss : 0.084978, loss_ce: 0.025041
[00:32:45.794] iteration 4647 : loss : 0.232079, loss_ce: 0.012770
[00:32:46.084] iteration 4648 : loss : 0.096115, loss_ce: 0.031113
[00:32:46.372] iteration 4649 : loss : 0.129584, loss_ce: 0.030303
[00:32:46.663] iteration 4650 : loss : 0.106180, loss_ce: 0.019523
[00:32:46.951] iteration 4651 : loss : 0.086331, loss_ce: 0.021877
[00:32:47.241] iteration 4652 : loss : 0.079792, loss_ce: 0.033581
[00:32:47.529] iteration 4653 : loss : 0.093234, loss_ce: 0.030760
[00:32:47.816] iteration 4654 : loss : 0.161204, loss_ce: 0.015002
[00:32:48.103] iteration 4655 : loss : 0.150673, loss_ce: 0.011517
[00:32:48.390] iteration 4656 : loss : 0.070523, loss_ce: 0.033524
[00:32:48.677] iteration 4657 : loss : 0.068191, loss_ce: 0.013263
[00:32:48.965] iteration 4658 : loss : 0.123330, loss_ce: 0.029849
[00:32:49.252] iteration 4659 : loss : 0.132659, loss_ce: 0.038527
[00:32:49.540] iteration 4660 : loss : 0.099365, loss_ce: 0.023131
[00:32:49.840] iteration 4661 : loss : 0.084593, loss_ce: 0.017263
[00:32:50.128] iteration 4662 : loss : 0.153780, loss_ce: 0.018790
[00:32:50.417] iteration 4663 : loss : 0.112692, loss_ce: 0.028142
[00:32:50.709] iteration 4664 : loss : 0.102577, loss_ce: 0.030472
[00:32:51.000] iteration 4665 : loss : 0.122964, loss_ce: 0.026768
[00:32:51.290] iteration 4666 : loss : 0.073181, loss_ce: 0.022982
[00:32:51.578] iteration 4667 : loss : 0.079734, loss_ce: 0.017304
[00:32:51.870] iteration 4668 : loss : 0.081056, loss_ce: 0.037147
[00:32:52.159] iteration 4669 : loss : 0.144233, loss_ce: 0.020182
[00:32:52.451] iteration 4670 : loss : 0.075657, loss_ce: 0.028743
[00:32:52.737] iteration 4671 : loss : 0.087467, loss_ce: 0.032845
[00:32:53.030] iteration 4672 : loss : 0.087644, loss_ce: 0.036365
[00:32:53.320] iteration 4673 : loss : 0.095343, loss_ce: 0.009923
[00:32:53.610] iteration 4674 : loss : 0.121328, loss_ce: 0.011108
[00:32:53.899] iteration 4675 : loss : 0.074829, loss_ce: 0.030663
[00:32:54.186] iteration 4676 : loss : 0.140779, loss_ce: 0.019652
[00:32:54.477] iteration 4677 : loss : 0.071222, loss_ce: 0.031364
[00:32:54.764] iteration 4678 : loss : 0.144379, loss_ce: 0.025157
[00:32:55.054] iteration 4679 : loss : 0.103009, loss_ce: 0.026985
[00:32:55.344] iteration 4680 : loss : 0.113461, loss_ce: 0.041837
[00:32:55.653] iteration 4681 : loss : 0.093594, loss_ce: 0.030143
[00:32:55.943] iteration 4682 : loss : 0.082612, loss_ce: 0.017726
[00:32:56.231] iteration 4683 : loss : 0.084884, loss_ce: 0.025393
[00:32:56.524] iteration 4684 : loss : 0.085195, loss_ce: 0.021666
[00:32:56.815] iteration 4685 : loss : 0.069868, loss_ce: 0.026355
[00:32:57.105] iteration 4686 : loss : 0.084767, loss_ce: 0.043604
[00:32:57.394] iteration 4687 : loss : 0.063660, loss_ce: 0.023959
[00:32:57.684] iteration 4688 : loss : 0.109041, loss_ce: 0.021119
[00:32:57.978] iteration 4689 : loss : 0.091578, loss_ce: 0.032714
[00:32:58.270] iteration 4690 : loss : 0.059164, loss_ce: 0.022989
[00:32:58.558] iteration 4691 : loss : 0.085832, loss_ce: 0.030369
[00:32:58.851] iteration 4692 : loss : 0.151578, loss_ce: 0.015696
[00:32:59.140] iteration 4693 : loss : 0.155047, loss_ce: 0.026247
[00:32:59.428] iteration 4694 : loss : 0.112475, loss_ce: 0.022187
[00:32:59.717] iteration 4695 : loss : 0.061378, loss_ce: 0.017313
[00:33:00.009] iteration 4696 : loss : 0.079969, loss_ce: 0.030652
[00:33:00.304] iteration 4697 : loss : 0.074497, loss_ce: 0.028125
[00:33:00.596] iteration 4698 : loss : 0.088852, loss_ce: 0.022639
[00:33:00.889] iteration 4699 : loss : 0.129143, loss_ce: 0.020887
[00:33:01.182] iteration 4700 : loss : 0.083162, loss_ce: 0.034602
[00:33:01.493] iteration 4701 : loss : 0.077568, loss_ce: 0.023257
[00:33:01.783] iteration 4702 : loss : 0.156536, loss_ce: 0.020180
[00:33:02.075] iteration 4703 : loss : 0.133297, loss_ce: 0.017656
[00:33:02.366] iteration 4704 : loss : 0.073873, loss_ce: 0.028187
[00:33:02.656] iteration 4705 : loss : 0.124333, loss_ce: 0.024083
[00:33:02.943] iteration 4706 : loss : 0.079129, loss_ce: 0.018656
[00:33:03.231] iteration 4707 : loss : 0.068702, loss_ce: 0.024583
[00:33:03.523] iteration 4708 : loss : 0.131847, loss_ce: 0.015575
[00:33:03.813] iteration 4709 : loss : 0.092010, loss_ce: 0.036406
[00:33:04.104] iteration 4710 : loss : 0.081283, loss_ce: 0.031083
[00:33:04.398] iteration 4711 : loss : 0.352137, loss_ce: 0.008302
[00:33:04.691] iteration 4712 : loss : 0.088789, loss_ce: 0.030908
[00:33:04.983] iteration 4713 : loss : 0.112488, loss_ce: 0.017449
[00:33:05.279] iteration 4714 : loss : 0.141122, loss_ce: 0.023508
[00:33:05.572] iteration 4715 : loss : 0.078415, loss_ce: 0.017716
[00:33:05.863] iteration 4716 : loss : 0.091242, loss_ce: 0.032649
[00:33:06.153] iteration 4717 : loss : 0.120088, loss_ce: 0.005759
[00:33:06.444] iteration 4718 : loss : 0.128969, loss_ce: 0.027126
[00:33:06.736] iteration 4719 : loss : 0.091216, loss_ce: 0.022268
[00:33:07.028] iteration 4720 : loss : 0.074166, loss_ce: 0.018740
[00:33:07.348] iteration 4721 : loss : 0.251890, loss_ce: 0.004049
[00:33:07.639] iteration 4722 : loss : 0.120846, loss_ce: 0.012305
[00:33:07.931] iteration 4723 : loss : 0.060929, loss_ce: 0.019923
[00:33:08.224] iteration 4724 : loss : 0.090051, loss_ce: 0.019505
[00:33:08.515] iteration 4725 : loss : 0.101229, loss_ce: 0.022421
[00:33:08.617] iteration 4726 : loss : 0.308336, loss_ce: 0.042218
[00:33:25.115] iteration 4727 : loss : 0.097298, loss_ce: 0.032178
[00:33:25.400] iteration 4728 : loss : 0.114762, loss_ce: 0.027998
[00:33:25.686] iteration 4729 : loss : 0.099487, loss_ce: 0.028561
[00:33:25.974] iteration 4730 : loss : 0.118893, loss_ce: 0.027988
[00:33:26.264] iteration 4731 : loss : 0.131342, loss_ce: 0.020742
[00:33:26.551] iteration 4732 : loss : 0.063528, loss_ce: 0.013095
[00:33:26.838] iteration 4733 : loss : 0.112654, loss_ce: 0.027546
[00:33:27.127] iteration 4734 : loss : 0.073153, loss_ce: 0.024720
[00:33:27.417] iteration 4735 : loss : 0.111170, loss_ce: 0.020397
[00:33:27.703] iteration 4736 : loss : 0.067561, loss_ce: 0.017041
[00:33:27.992] iteration 4737 : loss : 0.125851, loss_ce: 0.024557
[00:33:28.281] iteration 4738 : loss : 0.144013, loss_ce: 0.015642
[00:33:28.569] iteration 4739 : loss : 0.077096, loss_ce: 0.026700
[00:33:28.858] iteration 4740 : loss : 0.140871, loss_ce: 0.025033
[00:33:29.164] iteration 4741 : loss : 0.086298, loss_ce: 0.021408
[00:33:29.452] iteration 4742 : loss : 0.091014, loss_ce: 0.033178
[00:33:29.737] iteration 4743 : loss : 0.068794, loss_ce: 0.014544
[00:33:30.027] iteration 4744 : loss : 0.160409, loss_ce: 0.016633
[00:33:30.317] iteration 4745 : loss : 0.109564, loss_ce: 0.021477
[00:33:30.603] iteration 4746 : loss : 0.113985, loss_ce: 0.026388
[00:33:30.891] iteration 4747 : loss : 0.137235, loss_ce: 0.012756
[00:33:31.179] iteration 4748 : loss : 0.094758, loss_ce: 0.026610
[00:33:31.469] iteration 4749 : loss : 0.102244, loss_ce: 0.030663
[00:33:31.757] iteration 4750 : loss : 0.076942, loss_ce: 0.021624
[00:33:32.045] iteration 4751 : loss : 0.057728, loss_ce: 0.017699
[00:33:32.333] iteration 4752 : loss : 0.104964, loss_ce: 0.025498
[00:33:32.619] iteration 4753 : loss : 0.078950, loss_ce: 0.024637
[00:33:32.907] iteration 4754 : loss : 0.074655, loss_ce: 0.039134
[00:33:33.196] iteration 4755 : loss : 0.125227, loss_ce: 0.022459
[00:33:33.482] iteration 4756 : loss : 0.073552, loss_ce: 0.021807
[00:33:33.770] iteration 4757 : loss : 0.107724, loss_ce: 0.029939
[00:33:34.063] iteration 4758 : loss : 0.097567, loss_ce: 0.024300
[00:33:34.349] iteration 4759 : loss : 0.114943, loss_ce: 0.039249
[00:33:34.640] iteration 4760 : loss : 0.132319, loss_ce: 0.035313
[00:33:34.946] iteration 4761 : loss : 0.084124, loss_ce: 0.023253
[00:33:35.232] iteration 4762 : loss : 0.093259, loss_ce: 0.028792
[00:33:35.523] iteration 4763 : loss : 0.090296, loss_ce: 0.027329
[00:33:35.812] iteration 4764 : loss : 0.073304, loss_ce: 0.025373
[00:33:36.099] iteration 4765 : loss : 0.111426, loss_ce: 0.025299
[00:33:36.385] iteration 4766 : loss : 0.089152, loss_ce: 0.017963
[00:33:36.673] iteration 4767 : loss : 0.136883, loss_ce: 0.028932
[00:33:36.961] iteration 4768 : loss : 0.112830, loss_ce: 0.016893
[00:33:37.250] iteration 4769 : loss : 0.070493, loss_ce: 0.033461
[00:33:37.536] iteration 4770 : loss : 0.074617, loss_ce: 0.020716
[00:33:37.824] iteration 4771 : loss : 0.073315, loss_ce: 0.038905
[00:33:38.111] iteration 4772 : loss : 0.060759, loss_ce: 0.023330
[00:33:38.400] iteration 4773 : loss : 0.164750, loss_ce: 0.029329
[00:33:38.686] iteration 4774 : loss : 0.123106, loss_ce: 0.010263
[00:33:38.973] iteration 4775 : loss : 0.119797, loss_ce: 0.012875
[00:33:39.261] iteration 4776 : loss : 0.072130, loss_ce: 0.018114
[00:33:39.549] iteration 4777 : loss : 0.084518, loss_ce: 0.035577
[00:33:39.837] iteration 4778 : loss : 0.088061, loss_ce: 0.017609
[00:33:40.124] iteration 4779 : loss : 0.075584, loss_ce: 0.017188
[00:33:40.413] iteration 4780 : loss : 0.148828, loss_ce: 0.019498
[00:33:40.715] iteration 4781 : loss : 0.128827, loss_ce: 0.020129
[00:33:41.004] iteration 4782 : loss : 0.089543, loss_ce: 0.043748
[00:33:41.290] iteration 4783 : loss : 0.077956, loss_ce: 0.024180
[00:33:41.580] iteration 4784 : loss : 0.080983, loss_ce: 0.020595
[00:33:41.870] iteration 4785 : loss : 0.088741, loss_ce: 0.020574
[00:33:42.160] iteration 4786 : loss : 0.066498, loss_ce: 0.026293
[00:33:42.449] iteration 4787 : loss : 0.185645, loss_ce: 0.010708
[00:33:42.736] iteration 4788 : loss : 0.101818, loss_ce: 0.015023
[00:33:43.022] iteration 4789 : loss : 0.081086, loss_ce: 0.024191
[00:33:43.310] iteration 4790 : loss : 0.073731, loss_ce: 0.027868
[00:33:43.597] iteration 4791 : loss : 0.105370, loss_ce: 0.013347
[00:33:43.887] iteration 4792 : loss : 0.206005, loss_ce: 0.021139
[00:33:44.175] iteration 4793 : loss : 0.092396, loss_ce: 0.029563
[00:33:44.462] iteration 4794 : loss : 0.096254, loss_ce: 0.012052
[00:33:44.749] iteration 4795 : loss : 0.071401, loss_ce: 0.025448
[00:33:45.039] iteration 4796 : loss : 0.103863, loss_ce: 0.024865
[00:33:45.330] iteration 4797 : loss : 0.089578, loss_ce: 0.016483
[00:33:45.619] iteration 4798 : loss : 0.065851, loss_ce: 0.024413
[00:33:45.908] iteration 4799 : loss : 0.136163, loss_ce: 0.019975
[00:33:46.197] iteration 4800 : loss : 0.153343, loss_ce: 0.027751
[00:33:46.502] iteration 4801 : loss : 0.131703, loss_ce: 0.015259
[00:33:46.789] iteration 4802 : loss : 0.115861, loss_ce: 0.017813
[00:33:47.077] iteration 4803 : loss : 0.130292, loss_ce: 0.011961
[00:33:47.365] iteration 4804 : loss : 0.187609, loss_ce: 0.018461
[00:33:47.652] iteration 4805 : loss : 0.064565, loss_ce: 0.019472
[00:33:47.939] iteration 4806 : loss : 0.067997, loss_ce: 0.026624
[00:33:48.228] iteration 4807 : loss : 0.080259, loss_ce: 0.030883
[00:33:48.516] iteration 4808 : loss : 0.131966, loss_ce: 0.023401
[00:33:48.806] iteration 4809 : loss : 0.085135, loss_ce: 0.032592
[00:33:49.095] iteration 4810 : loss : 0.086826, loss_ce: 0.032316
[00:33:49.380] iteration 4811 : loss : 0.093888, loss_ce: 0.016445
[00:33:49.667] iteration 4812 : loss : 0.080651, loss_ce: 0.011743
[00:33:49.956] iteration 4813 : loss : 0.067434, loss_ce: 0.019374
[00:33:50.243] iteration 4814 : loss : 0.063258, loss_ce: 0.015413
[00:33:50.533] iteration 4815 : loss : 0.083631, loss_ce: 0.039832
[00:33:50.819] iteration 4816 : loss : 0.072000, loss_ce: 0.023430
[00:33:51.107] iteration 4817 : loss : 0.149625, loss_ce: 0.018474
[00:33:51.396] iteration 4818 : loss : 0.129374, loss_ce: 0.010561
[00:33:51.683] iteration 4819 : loss : 0.140945, loss_ce: 0.018846
[00:33:51.970] iteration 4820 : loss : 0.296475, loss_ce: 0.004740
[00:33:52.279] iteration 4821 : loss : 0.203737, loss_ce: 0.019877
[00:33:52.567] iteration 4822 : loss : 0.144430, loss_ce: 0.014862
[00:33:52.856] iteration 4823 : loss : 0.078691, loss_ce: 0.028613
[00:33:53.145] iteration 4824 : loss : 0.093875, loss_ce: 0.039423
[00:33:53.431] iteration 4825 : loss : 0.093704, loss_ce: 0.020654
[00:33:53.720] iteration 4826 : loss : 0.088419, loss_ce: 0.023361
[00:33:54.008] iteration 4827 : loss : 0.076141, loss_ce: 0.032992
[00:33:54.294] iteration 4828 : loss : 0.101934, loss_ce: 0.020874
[00:33:54.582] iteration 4829 : loss : 0.112665, loss_ce: 0.043932
[00:33:54.869] iteration 4830 : loss : 0.066638, loss_ce: 0.021735
[00:33:55.155] iteration 4831 : loss : 0.098824, loss_ce: 0.030014
[00:33:55.442] iteration 4832 : loss : 0.092458, loss_ce: 0.025007
[00:33:55.734] iteration 4833 : loss : 0.086047, loss_ce: 0.026030
[00:33:56.022] iteration 4834 : loss : 0.065632, loss_ce: 0.018013
[00:33:56.309] iteration 4835 : loss : 0.135891, loss_ce: 0.025521
[00:33:56.596] iteration 4836 : loss : 0.133031, loss_ce: 0.017942
[00:33:56.884] iteration 4837 : loss : 0.121191, loss_ce: 0.008006
[00:33:57.172] iteration 4838 : loss : 0.103116, loss_ce: 0.044222
[00:33:57.461] iteration 4839 : loss : 0.118616, loss_ce: 0.034941
[00:33:57.748] iteration 4840 : loss : 0.077644, loss_ce: 0.031090
[00:33:58.054] iteration 4841 : loss : 0.102004, loss_ce: 0.029046
[00:33:58.341] iteration 4842 : loss : 0.138781, loss_ce: 0.022996
[00:33:58.629] iteration 4843 : loss : 0.070847, loss_ce: 0.020745
[00:33:58.917] iteration 4844 : loss : 0.121648, loss_ce: 0.018024
[00:33:59.209] iteration 4845 : loss : 0.074473, loss_ce: 0.018010
[00:33:59.495] iteration 4846 : loss : 0.088038, loss_ce: 0.027142
[00:33:59.785] iteration 4847 : loss : 0.078375, loss_ce: 0.017896
[00:34:00.073] iteration 4848 : loss : 0.079781, loss_ce: 0.041232
[00:34:00.367] iteration 4849 : loss : 0.182726, loss_ce: 0.020509
[00:34:00.657] iteration 4850 : loss : 0.140804, loss_ce: 0.035958
[00:34:00.951] iteration 4851 : loss : 0.068108, loss_ce: 0.023361
[00:34:01.244] iteration 4852 : loss : 0.109891, loss_ce: 0.044221
[00:34:01.537] iteration 4853 : loss : 0.104075, loss_ce: 0.024431
[00:34:01.827] iteration 4854 : loss : 0.083870, loss_ce: 0.024346
[00:34:02.115] iteration 4855 : loss : 0.094281, loss_ce: 0.022628
[00:34:02.408] iteration 4856 : loss : 0.083501, loss_ce: 0.019131
[00:34:02.695] iteration 4857 : loss : 0.094386, loss_ce: 0.030245
[00:34:02.986] iteration 4858 : loss : 0.133381, loss_ce: 0.027201
[00:34:03.278] iteration 4859 : loss : 0.072417, loss_ce: 0.011836
[00:34:03.570] iteration 4860 : loss : 0.083472, loss_ce: 0.036597
[00:34:03.877] iteration 4861 : loss : 0.144809, loss_ce: 0.016749
[00:34:04.169] iteration 4862 : loss : 0.139074, loss_ce: 0.019633
[00:34:04.456] iteration 4863 : loss : 0.063091, loss_ce: 0.027421
[00:34:04.744] iteration 4864 : loss : 0.093080, loss_ce: 0.026723
[00:34:04.820] iteration 4865 : loss : 0.358941, loss_ce: 0.015674
[00:34:21.286] iteration 4866 : loss : 0.088331, loss_ce: 0.022126
[00:34:21.570] iteration 4867 : loss : 0.087777, loss_ce: 0.023076
[00:34:21.856] iteration 4868 : loss : 0.083066, loss_ce: 0.042038
[00:34:22.143] iteration 4869 : loss : 0.062081, loss_ce: 0.013787
[00:34:22.430] iteration 4870 : loss : 0.082004, loss_ce: 0.025249
[00:34:22.718] iteration 4871 : loss : 0.071078, loss_ce: 0.025665
[00:34:23.005] iteration 4872 : loss : 0.098567, loss_ce: 0.020648
[00:34:23.293] iteration 4873 : loss : 0.123792, loss_ce: 0.022188
[00:34:23.579] iteration 4874 : loss : 0.133381, loss_ce: 0.017401
[00:34:23.867] iteration 4875 : loss : 0.077800, loss_ce: 0.017101
[00:34:24.156] iteration 4876 : loss : 0.141677, loss_ce: 0.009136
[00:34:24.444] iteration 4877 : loss : 0.074732, loss_ce: 0.020450
[00:34:24.729] iteration 4878 : loss : 0.075486, loss_ce: 0.024528
[00:34:25.016] iteration 4879 : loss : 0.144161, loss_ce: 0.021466
[00:34:25.307] iteration 4880 : loss : 0.125023, loss_ce: 0.015840
[00:34:25.610] iteration 4881 : loss : 0.063830, loss_ce: 0.013038
[00:34:25.897] iteration 4882 : loss : 0.103955, loss_ce: 0.011590
[00:34:26.182] iteration 4883 : loss : 0.058703, loss_ce: 0.029419
[00:34:26.468] iteration 4884 : loss : 0.081729, loss_ce: 0.019721
[00:34:26.756] iteration 4885 : loss : 0.080743, loss_ce: 0.031230
[00:34:27.042] iteration 4886 : loss : 0.076582, loss_ce: 0.024786
[00:34:27.334] iteration 4887 : loss : 0.120430, loss_ce: 0.017601
[00:34:27.623] iteration 4888 : loss : 0.078366, loss_ce: 0.015782
[00:34:27.911] iteration 4889 : loss : 0.097815, loss_ce: 0.024828
[00:34:28.200] iteration 4890 : loss : 0.080897, loss_ce: 0.026751
[00:34:28.487] iteration 4891 : loss : 0.093198, loss_ce: 0.020835
[00:34:28.776] iteration 4892 : loss : 0.070708, loss_ce: 0.019828
[00:34:29.067] iteration 4893 : loss : 0.079918, loss_ce: 0.029227
[00:34:29.354] iteration 4894 : loss : 0.067840, loss_ce: 0.023980
[00:34:29.643] iteration 4895 : loss : 0.129123, loss_ce: 0.030989
[00:34:29.930] iteration 4896 : loss : 0.062008, loss_ce: 0.022800
[00:34:30.218] iteration 4897 : loss : 0.103157, loss_ce: 0.028400
[00:34:30.506] iteration 4898 : loss : 0.066818, loss_ce: 0.024910
[00:34:30.792] iteration 4899 : loss : 0.129797, loss_ce: 0.026468
[00:34:31.079] iteration 4900 : loss : 0.064464, loss_ce: 0.027215
[00:34:31.379] iteration 4901 : loss : 0.073123, loss_ce: 0.030094
[00:34:31.666] iteration 4902 : loss : 0.070476, loss_ce: 0.020374
[00:34:31.952] iteration 4903 : loss : 0.090208, loss_ce: 0.010670
[00:34:32.240] iteration 4904 : loss : 0.121738, loss_ce: 0.013389
[00:34:32.526] iteration 4905 : loss : 0.128376, loss_ce: 0.022408
[00:34:32.814] iteration 4906 : loss : 0.110040, loss_ce: 0.019752
[00:34:33.101] iteration 4907 : loss : 0.121653, loss_ce: 0.016834
[00:34:33.391] iteration 4908 : loss : 0.161046, loss_ce: 0.025277
[00:34:33.680] iteration 4909 : loss : 0.071686, loss_ce: 0.020618
[00:34:33.968] iteration 4910 : loss : 0.075143, loss_ce: 0.016246
[00:34:34.257] iteration 4911 : loss : 0.098396, loss_ce: 0.019438
[00:34:34.549] iteration 4912 : loss : 0.111279, loss_ce: 0.031533
[00:34:34.836] iteration 4913 : loss : 0.067057, loss_ce: 0.026246
[00:34:35.126] iteration 4914 : loss : 0.094716, loss_ce: 0.031393
[00:34:35.414] iteration 4915 : loss : 0.147806, loss_ce: 0.033655
[00:34:35.705] iteration 4916 : loss : 0.117518, loss_ce: 0.027049
[00:34:35.994] iteration 4917 : loss : 0.094658, loss_ce: 0.022974
[00:34:36.280] iteration 4918 : loss : 0.068486, loss_ce: 0.028002
[00:34:36.567] iteration 4919 : loss : 0.215402, loss_ce: 0.007487
[00:34:36.857] iteration 4920 : loss : 0.065974, loss_ce: 0.022316
[00:34:37.162] iteration 4921 : loss : 0.082763, loss_ce: 0.031385
[00:34:37.451] iteration 4922 : loss : 0.235755, loss_ce: 0.013774
[00:34:37.737] iteration 4923 : loss : 0.082715, loss_ce: 0.027710
[00:34:38.024] iteration 4924 : loss : 0.078716, loss_ce: 0.011741
[00:34:38.312] iteration 4925 : loss : 0.070582, loss_ce: 0.021104
[00:34:38.597] iteration 4926 : loss : 0.125814, loss_ce: 0.018219
[00:34:38.890] iteration 4927 : loss : 0.122154, loss_ce: 0.016543
[00:34:39.182] iteration 4928 : loss : 0.075423, loss_ce: 0.041172
[00:34:39.470] iteration 4929 : loss : 0.063149, loss_ce: 0.020703
[00:34:39.757] iteration 4930 : loss : 0.147429, loss_ce: 0.014445
[00:34:40.045] iteration 4931 : loss : 0.066158, loss_ce: 0.010580
[00:34:40.333] iteration 4932 : loss : 0.202670, loss_ce: 0.024891
[00:34:40.623] iteration 4933 : loss : 0.108387, loss_ce: 0.023919
[00:34:40.912] iteration 4934 : loss : 0.066156, loss_ce: 0.029510
[00:34:41.201] iteration 4935 : loss : 0.068372, loss_ce: 0.021266
[00:34:41.491] iteration 4936 : loss : 0.142395, loss_ce: 0.014820
[00:34:41.778] iteration 4937 : loss : 0.053824, loss_ce: 0.019607
[00:34:42.066] iteration 4938 : loss : 0.077473, loss_ce: 0.016509
[00:34:42.356] iteration 4939 : loss : 0.142086, loss_ce: 0.008327
[00:34:42.643] iteration 4940 : loss : 0.072567, loss_ce: 0.021893
[00:34:42.943] iteration 4941 : loss : 0.065368, loss_ce: 0.017144
[00:34:43.232] iteration 4942 : loss : 0.129559, loss_ce: 0.008296
[00:34:43.519] iteration 4943 : loss : 0.138944, loss_ce: 0.043027
[00:34:43.806] iteration 4944 : loss : 0.083956, loss_ce: 0.022334
[00:34:44.093] iteration 4945 : loss : 0.078897, loss_ce: 0.026583
[00:34:44.379] iteration 4946 : loss : 0.098627, loss_ce: 0.016868
[00:34:44.669] iteration 4947 : loss : 0.125875, loss_ce: 0.017189
[00:34:44.955] iteration 4948 : loss : 0.099292, loss_ce: 0.020627
[00:34:45.245] iteration 4949 : loss : 0.072746, loss_ce: 0.021919
[00:34:45.534] iteration 4950 : loss : 0.081349, loss_ce: 0.022270
[00:34:45.825] iteration 4951 : loss : 0.165642, loss_ce: 0.034284
[00:34:46.115] iteration 4952 : loss : 0.180060, loss_ce: 0.013349
[00:34:46.402] iteration 4953 : loss : 0.147054, loss_ce: 0.018419
[00:34:46.689] iteration 4954 : loss : 0.092108, loss_ce: 0.021831
[00:34:46.978] iteration 4955 : loss : 0.130081, loss_ce: 0.033013
[00:34:47.266] iteration 4956 : loss : 0.080375, loss_ce: 0.017625
[00:34:47.555] iteration 4957 : loss : 0.082277, loss_ce: 0.025687
[00:34:47.842] iteration 4958 : loss : 0.106275, loss_ce: 0.037417
[00:34:48.131] iteration 4959 : loss : 0.072297, loss_ce: 0.018146
[00:34:48.421] iteration 4960 : loss : 0.089420, loss_ce: 0.029988
[00:34:48.727] iteration 4961 : loss : 0.069392, loss_ce: 0.025442
[00:34:49.015] iteration 4962 : loss : 0.126253, loss_ce: 0.012365
[00:34:49.306] iteration 4963 : loss : 0.118894, loss_ce: 0.019869
[00:34:49.597] iteration 4964 : loss : 0.127191, loss_ce: 0.022237
[00:34:49.882] iteration 4965 : loss : 0.061450, loss_ce: 0.018784
[00:34:50.170] iteration 4966 : loss : 0.062684, loss_ce: 0.019723
[00:34:50.461] iteration 4967 : loss : 0.130769, loss_ce: 0.018285
[00:34:50.750] iteration 4968 : loss : 0.064284, loss_ce: 0.020133
[00:34:51.041] iteration 4969 : loss : 0.061353, loss_ce: 0.018574
[00:34:51.333] iteration 4970 : loss : 0.070883, loss_ce: 0.015037
[00:34:51.622] iteration 4971 : loss : 0.084325, loss_ce: 0.020300
[00:34:51.912] iteration 4972 : loss : 0.091175, loss_ce: 0.027022
[00:34:52.201] iteration 4973 : loss : 0.071104, loss_ce: 0.018027
[00:34:52.494] iteration 4974 : loss : 0.053190, loss_ce: 0.021516
[00:34:52.785] iteration 4975 : loss : 0.067682, loss_ce: 0.030997
[00:34:53.074] iteration 4976 : loss : 0.060805, loss_ce: 0.017944
[00:34:53.362] iteration 4977 : loss : 0.063387, loss_ce: 0.025291
[00:34:53.652] iteration 4978 : loss : 0.062459, loss_ce: 0.020520
[00:34:53.942] iteration 4979 : loss : 0.127581, loss_ce: 0.021360
[00:34:54.227] iteration 4980 : loss : 0.069860, loss_ce: 0.025555
[00:34:54.529] iteration 4981 : loss : 0.073225, loss_ce: 0.020079
[00:34:54.820] iteration 4982 : loss : 0.118854, loss_ce: 0.027021
[00:34:55.109] iteration 4983 : loss : 0.131722, loss_ce: 0.011631
[00:34:55.400] iteration 4984 : loss : 0.083818, loss_ce: 0.024522
[00:34:55.690] iteration 4985 : loss : 0.165798, loss_ce: 0.015598
[00:34:55.980] iteration 4986 : loss : 0.090687, loss_ce: 0.028626
[00:34:56.274] iteration 4987 : loss : 0.129267, loss_ce: 0.013835
[00:34:56.567] iteration 4988 : loss : 0.165069, loss_ce: 0.020922
[00:34:56.862] iteration 4989 : loss : 0.185683, loss_ce: 0.025344
[00:34:57.154] iteration 4990 : loss : 0.123580, loss_ce: 0.019776
[00:34:57.447] iteration 4991 : loss : 0.114132, loss_ce: 0.015411
[00:34:57.740] iteration 4992 : loss : 0.087724, loss_ce: 0.036279
[00:34:58.031] iteration 4993 : loss : 0.089145, loss_ce: 0.033315
[00:34:58.325] iteration 4994 : loss : 0.097223, loss_ce: 0.038645
[00:34:58.614] iteration 4995 : loss : 0.096229, loss_ce: 0.013098
[00:34:58.914] iteration 4996 : loss : 0.092393, loss_ce: 0.031306
[00:34:59.208] iteration 4997 : loss : 0.068773, loss_ce: 0.014622
[00:34:59.500] iteration 4998 : loss : 0.083387, loss_ce: 0.024228
[00:34:59.792] iteration 4999 : loss : 0.121743, loss_ce: 0.026169
[00:35:00.083] iteration 5000 : loss : 0.078310, loss_ce: 0.028969
[00:35:00.399] iteration 5001 : loss : 0.081122, loss_ce: 0.028949
[00:35:00.696] iteration 5002 : loss : 0.292281, loss_ce: 0.006718
[00:35:00.997] iteration 5003 : loss : 0.104462, loss_ce: 0.028673
[00:35:01.078] iteration 5004 : loss : 0.138891, loss_ce: 0.031532
[00:35:17.762] iteration 5005 : loss : 0.084858, loss_ce: 0.024778
[00:35:18.047] iteration 5006 : loss : 0.096828, loss_ce: 0.023276
[00:35:18.332] iteration 5007 : loss : 0.095651, loss_ce: 0.034071
[00:35:18.623] iteration 5008 : loss : 0.102347, loss_ce: 0.024031
[00:35:18.909] iteration 5009 : loss : 0.130628, loss_ce: 0.017649
[00:35:19.196] iteration 5010 : loss : 0.136046, loss_ce: 0.028237
[00:35:19.483] iteration 5011 : loss : 0.067491, loss_ce: 0.019796
[00:35:19.775] iteration 5012 : loss : 0.113658, loss_ce: 0.018729
[00:35:20.066] iteration 5013 : loss : 0.090005, loss_ce: 0.028429
[00:35:20.352] iteration 5014 : loss : 0.079978, loss_ce: 0.024177
[00:35:20.638] iteration 5015 : loss : 0.082245, loss_ce: 0.018072
[00:35:20.926] iteration 5016 : loss : 0.072529, loss_ce: 0.025810
[00:35:21.214] iteration 5017 : loss : 0.067102, loss_ce: 0.014465
[00:35:21.500] iteration 5018 : loss : 0.103217, loss_ce: 0.020070
[00:35:21.790] iteration 5019 : loss : 0.071841, loss_ce: 0.028932
[00:35:22.077] iteration 5020 : loss : 0.146247, loss_ce: 0.022120
[00:35:22.381] iteration 5021 : loss : 0.064868, loss_ce: 0.020314
[00:35:22.669] iteration 5022 : loss : 0.082513, loss_ce: 0.026912
[00:35:22.956] iteration 5023 : loss : 0.055725, loss_ce: 0.019508
[00:35:23.243] iteration 5024 : loss : 0.065101, loss_ce: 0.012022
[00:35:23.532] iteration 5025 : loss : 0.064118, loss_ce: 0.013502
[00:35:23.820] iteration 5026 : loss : 0.112974, loss_ce: 0.017565
[00:35:24.110] iteration 5027 : loss : 0.139184, loss_ce: 0.017868
[00:35:24.398] iteration 5028 : loss : 0.121233, loss_ce: 0.021196
[00:35:24.685] iteration 5029 : loss : 0.085662, loss_ce: 0.024664
[00:35:24.972] iteration 5030 : loss : 0.090090, loss_ce: 0.022942
[00:35:25.260] iteration 5031 : loss : 0.116061, loss_ce: 0.008318
[00:35:25.548] iteration 5032 : loss : 0.062233, loss_ce: 0.021456
[00:35:25.835] iteration 5033 : loss : 0.073366, loss_ce: 0.023743
[00:35:26.125] iteration 5034 : loss : 0.058987, loss_ce: 0.018635
[00:35:26.414] iteration 5035 : loss : 0.098453, loss_ce: 0.024387
[00:35:26.698] iteration 5036 : loss : 0.124354, loss_ce: 0.024938
[00:35:26.988] iteration 5037 : loss : 0.123711, loss_ce: 0.019029
[00:35:27.276] iteration 5038 : loss : 0.115417, loss_ce: 0.010408
[00:35:27.566] iteration 5039 : loss : 0.115352, loss_ce: 0.028470
[00:35:27.856] iteration 5040 : loss : 0.082269, loss_ce: 0.025122
[00:35:28.155] iteration 5041 : loss : 0.126110, loss_ce: 0.012483
[00:35:28.442] iteration 5042 : loss : 0.071158, loss_ce: 0.023954
[00:35:28.727] iteration 5043 : loss : 0.074718, loss_ce: 0.033485
[00:35:29.014] iteration 5044 : loss : 0.079303, loss_ce: 0.033646
[00:35:29.304] iteration 5045 : loss : 0.086637, loss_ce: 0.016021
[00:35:29.592] iteration 5046 : loss : 0.082157, loss_ce: 0.030841
[00:35:29.880] iteration 5047 : loss : 0.060234, loss_ce: 0.021930
[00:35:30.167] iteration 5048 : loss : 0.082523, loss_ce: 0.033570
[00:35:30.457] iteration 5049 : loss : 0.080220, loss_ce: 0.015909
[00:35:30.747] iteration 5050 : loss : 0.149769, loss_ce: 0.025801
[00:35:31.034] iteration 5051 : loss : 0.130654, loss_ce: 0.020150
[00:35:31.321] iteration 5052 : loss : 0.084835, loss_ce: 0.032368
[00:35:31.610] iteration 5053 : loss : 0.082422, loss_ce: 0.034667
[00:35:31.899] iteration 5054 : loss : 0.093815, loss_ce: 0.022581
[00:35:32.189] iteration 5055 : loss : 0.067716, loss_ce: 0.019635
[00:35:32.474] iteration 5056 : loss : 0.090912, loss_ce: 0.024133
[00:35:32.762] iteration 5057 : loss : 0.078852, loss_ce: 0.024409
[00:35:33.047] iteration 5058 : loss : 0.070596, loss_ce: 0.026380
[00:35:33.334] iteration 5059 : loss : 0.078319, loss_ce: 0.027426
[00:35:33.624] iteration 5060 : loss : 0.062658, loss_ce: 0.013533
[00:35:33.927] iteration 5061 : loss : 0.107402, loss_ce: 0.030484
[00:35:34.216] iteration 5062 : loss : 0.068548, loss_ce: 0.015624
[00:35:34.505] iteration 5063 : loss : 0.111227, loss_ce: 0.028837
[00:35:34.797] iteration 5064 : loss : 0.090158, loss_ce: 0.024999
[00:35:35.087] iteration 5065 : loss : 0.062662, loss_ce: 0.009659
[00:35:35.374] iteration 5066 : loss : 0.089132, loss_ce: 0.039234
[00:35:35.661] iteration 5067 : loss : 0.070630, loss_ce: 0.015232
[00:35:35.950] iteration 5068 : loss : 0.174849, loss_ce: 0.015872
[00:35:36.238] iteration 5069 : loss : 0.077308, loss_ce: 0.020946
[00:35:36.525] iteration 5070 : loss : 0.103966, loss_ce: 0.008581
[00:35:36.812] iteration 5071 : loss : 0.075154, loss_ce: 0.019633
[00:35:37.097] iteration 5072 : loss : 0.214275, loss_ce: 0.010987
[00:35:37.384] iteration 5073 : loss : 0.098787, loss_ce: 0.019773
[00:35:37.672] iteration 5074 : loss : 0.068228, loss_ce: 0.019055
[00:35:37.962] iteration 5075 : loss : 0.088090, loss_ce: 0.035416
[00:35:38.252] iteration 5076 : loss : 0.056803, loss_ce: 0.022181
[00:35:38.540] iteration 5077 : loss : 0.118232, loss_ce: 0.039757
[00:35:38.825] iteration 5078 : loss : 0.088185, loss_ce: 0.018026
[00:35:39.113] iteration 5079 : loss : 0.061573, loss_ce: 0.019006
[00:35:39.401] iteration 5080 : loss : 0.059561, loss_ce: 0.026383
[00:35:39.705] iteration 5081 : loss : 0.062281, loss_ce: 0.024134
[00:35:39.992] iteration 5082 : loss : 0.125789, loss_ce: 0.016859
[00:35:40.280] iteration 5083 : loss : 0.051688, loss_ce: 0.018379
[00:35:40.570] iteration 5084 : loss : 0.075064, loss_ce: 0.020920
[00:35:40.857] iteration 5085 : loss : 0.137109, loss_ce: 0.008887
[00:35:41.145] iteration 5086 : loss : 0.072966, loss_ce: 0.020453
[00:35:41.432] iteration 5087 : loss : 0.060332, loss_ce: 0.016320
[00:35:41.719] iteration 5088 : loss : 0.127936, loss_ce: 0.010656
[00:35:42.008] iteration 5089 : loss : 0.130058, loss_ce: 0.029434
[00:35:42.295] iteration 5090 : loss : 0.078650, loss_ce: 0.019691
[00:35:42.586] iteration 5091 : loss : 0.059958, loss_ce: 0.016203
[00:35:42.875] iteration 5092 : loss : 0.058602, loss_ce: 0.016717
[00:35:43.162] iteration 5093 : loss : 0.070259, loss_ce: 0.030795
[00:35:43.450] iteration 5094 : loss : 0.114384, loss_ce: 0.017111
[00:35:43.736] iteration 5095 : loss : 0.126620, loss_ce: 0.018546
[00:35:44.025] iteration 5096 : loss : 0.105309, loss_ce: 0.024920
[00:35:44.312] iteration 5097 : loss : 0.066925, loss_ce: 0.019311
[00:35:44.598] iteration 5098 : loss : 0.118390, loss_ce: 0.024288
[00:35:44.888] iteration 5099 : loss : 0.159792, loss_ce: 0.014539
[00:35:45.177] iteration 5100 : loss : 0.074871, loss_ce: 0.027813
[00:35:45.479] iteration 5101 : loss : 0.133958, loss_ce: 0.028789
[00:35:45.768] iteration 5102 : loss : 0.063392, loss_ce: 0.015266
[00:35:46.056] iteration 5103 : loss : 0.067821, loss_ce: 0.024669
[00:35:46.344] iteration 5104 : loss : 0.078873, loss_ce: 0.029235
[00:35:46.633] iteration 5105 : loss : 0.121981, loss_ce: 0.029633
[00:35:46.920] iteration 5106 : loss : 0.075410, loss_ce: 0.016924
[00:35:47.209] iteration 5107 : loss : 0.125259, loss_ce: 0.016308
[00:35:47.498] iteration 5108 : loss : 0.224411, loss_ce: 0.009306
[00:35:47.786] iteration 5109 : loss : 0.089116, loss_ce: 0.016085
[00:35:48.073] iteration 5110 : loss : 0.122210, loss_ce: 0.017045
[00:35:48.360] iteration 5111 : loss : 0.099184, loss_ce: 0.031663
[00:35:48.647] iteration 5112 : loss : 0.086909, loss_ce: 0.021627
[00:35:48.935] iteration 5113 : loss : 0.073429, loss_ce: 0.017403
[00:35:49.224] iteration 5114 : loss : 0.058028, loss_ce: 0.029238
[00:35:49.513] iteration 5115 : loss : 0.088502, loss_ce: 0.016983
[00:35:49.801] iteration 5116 : loss : 0.081021, loss_ce: 0.028139
[00:35:50.089] iteration 5117 : loss : 0.129667, loss_ce: 0.012743
[00:35:50.380] iteration 5118 : loss : 0.109784, loss_ce: 0.009080
[00:35:50.668] iteration 5119 : loss : 0.102156, loss_ce: 0.021743
[00:35:50.955] iteration 5120 : loss : 0.068188, loss_ce: 0.014169
[00:35:51.262] iteration 5121 : loss : 0.125644, loss_ce: 0.015027
[00:35:51.549] iteration 5122 : loss : 0.072279, loss_ce: 0.015408
[00:35:51.835] iteration 5123 : loss : 0.066549, loss_ce: 0.019875
[00:35:52.125] iteration 5124 : loss : 0.077761, loss_ce: 0.024055
[00:35:52.413] iteration 5125 : loss : 0.078312, loss_ce: 0.034919
[00:35:52.700] iteration 5126 : loss : 0.060526, loss_ce: 0.013403
[00:35:52.996] iteration 5127 : loss : 0.069122, loss_ce: 0.023759
[00:35:53.284] iteration 5128 : loss : 0.058465, loss_ce: 0.031880
[00:35:53.573] iteration 5129 : loss : 0.089814, loss_ce: 0.023967
[00:35:53.865] iteration 5130 : loss : 0.137371, loss_ce: 0.025577
[00:35:54.154] iteration 5131 : loss : 0.105352, loss_ce: 0.018533
[00:35:54.450] iteration 5132 : loss : 0.081225, loss_ce: 0.024600
[00:35:54.742] iteration 5133 : loss : 0.065608, loss_ce: 0.022177
[00:35:55.036] iteration 5134 : loss : 0.078195, loss_ce: 0.026961
[00:35:55.327] iteration 5135 : loss : 0.104795, loss_ce: 0.018707
[00:35:55.620] iteration 5136 : loss : 0.098597, loss_ce: 0.021546
[00:35:55.909] iteration 5137 : loss : 0.071273, loss_ce: 0.020846
[00:35:56.202] iteration 5138 : loss : 0.083267, loss_ce: 0.017499
[00:35:56.497] iteration 5139 : loss : 0.116363, loss_ce: 0.017239
[00:35:56.785] iteration 5140 : loss : 0.080143, loss_ce: 0.029332
[00:35:57.092] iteration 5141 : loss : 0.086278, loss_ce: 0.029406
[00:35:57.385] iteration 5142 : loss : 0.062464, loss_ce: 0.010895
[00:35:57.461] iteration 5143 : loss : 0.286143, loss_ce: 0.014238
[00:36:13.893] iteration 5144 : loss : 0.074698, loss_ce: 0.014950
[00:36:14.182] iteration 5145 : loss : 0.143964, loss_ce: 0.011233
[00:36:14.470] iteration 5146 : loss : 0.129393, loss_ce: 0.017411
[00:36:14.758] iteration 5147 : loss : 0.069564, loss_ce: 0.024134
[00:36:15.045] iteration 5148 : loss : 0.068710, loss_ce: 0.019772
[00:36:15.332] iteration 5149 : loss : 0.180374, loss_ce: 0.013670
[00:36:15.622] iteration 5150 : loss : 0.084696, loss_ce: 0.025166
[00:36:15.908] iteration 5151 : loss : 0.165076, loss_ce: 0.009033
[00:36:16.194] iteration 5152 : loss : 0.079375, loss_ce: 0.018392
[00:36:16.481] iteration 5153 : loss : 0.073662, loss_ce: 0.012024
[00:36:16.768] iteration 5154 : loss : 0.084160, loss_ce: 0.020758
[00:36:17.054] iteration 5155 : loss : 0.126434, loss_ce: 0.021723
[00:36:17.343] iteration 5156 : loss : 0.087989, loss_ce: 0.024580
[00:36:17.630] iteration 5157 : loss : 0.071320, loss_ce: 0.027708
[00:36:17.917] iteration 5158 : loss : 0.096178, loss_ce: 0.010838
[00:36:18.206] iteration 5159 : loss : 0.122950, loss_ce: 0.011839
[00:36:18.493] iteration 5160 : loss : 0.083820, loss_ce: 0.027557
[00:36:18.791] iteration 5161 : loss : 0.077136, loss_ce: 0.018554
[00:36:19.079] iteration 5162 : loss : 0.086085, loss_ce: 0.013999
[00:36:19.368] iteration 5163 : loss : 0.140722, loss_ce: 0.012841
[00:36:19.654] iteration 5164 : loss : 0.081087, loss_ce: 0.019486
[00:36:19.939] iteration 5165 : loss : 0.109251, loss_ce: 0.024330
[00:36:20.224] iteration 5166 : loss : 0.134787, loss_ce: 0.017333
[00:36:20.513] iteration 5167 : loss : 0.181718, loss_ce: 0.020414
[00:36:20.799] iteration 5168 : loss : 0.070524, loss_ce: 0.018962
[00:36:21.088] iteration 5169 : loss : 0.129481, loss_ce: 0.023397
[00:36:21.373] iteration 5170 : loss : 0.076256, loss_ce: 0.019548
[00:36:21.659] iteration 5171 : loss : 0.064235, loss_ce: 0.012049
[00:36:21.950] iteration 5172 : loss : 0.063367, loss_ce: 0.013783
[00:36:22.237] iteration 5173 : loss : 0.061111, loss_ce: 0.019854
[00:36:22.525] iteration 5174 : loss : 0.082976, loss_ce: 0.014328
[00:36:22.812] iteration 5175 : loss : 0.119602, loss_ce: 0.016940
[00:36:23.098] iteration 5176 : loss : 0.067638, loss_ce: 0.022789
[00:36:23.384] iteration 5177 : loss : 0.073607, loss_ce: 0.016406
[00:36:23.671] iteration 5178 : loss : 0.347975, loss_ce: 0.001448
[00:36:23.959] iteration 5179 : loss : 0.121167, loss_ce: 0.015381
[00:36:24.245] iteration 5180 : loss : 0.070112, loss_ce: 0.018955
[00:36:24.550] iteration 5181 : loss : 0.114634, loss_ce: 0.018405
[00:36:24.836] iteration 5182 : loss : 0.077932, loss_ce: 0.030928
[00:36:25.126] iteration 5183 : loss : 0.058642, loss_ce: 0.019797
[00:36:25.415] iteration 5184 : loss : 0.069983, loss_ce: 0.022818
[00:36:25.701] iteration 5185 : loss : 0.062076, loss_ce: 0.019386
[00:36:25.987] iteration 5186 : loss : 0.105999, loss_ce: 0.021016
[00:36:26.274] iteration 5187 : loss : 0.094919, loss_ce: 0.024401
[00:36:26.561] iteration 5188 : loss : 0.062707, loss_ce: 0.028182
[00:36:26.848] iteration 5189 : loss : 0.118823, loss_ce: 0.014699
[00:36:27.133] iteration 5190 : loss : 0.148695, loss_ce: 0.037991
[00:36:27.423] iteration 5191 : loss : 0.119870, loss_ce: 0.034087
[00:36:27.710] iteration 5192 : loss : 0.078170, loss_ce: 0.019662
[00:36:27.999] iteration 5193 : loss : 0.063312, loss_ce: 0.022067
[00:36:28.286] iteration 5194 : loss : 0.098624, loss_ce: 0.027050
[00:36:28.572] iteration 5195 : loss : 0.077886, loss_ce: 0.036134
[00:36:28.861] iteration 5196 : loss : 0.101814, loss_ce: 0.019709
[00:36:29.149] iteration 5197 : loss : 0.080344, loss_ce: 0.018069
[00:36:29.438] iteration 5198 : loss : 0.071629, loss_ce: 0.024747
[00:36:29.724] iteration 5199 : loss : 0.116418, loss_ce: 0.017087
[00:36:30.011] iteration 5200 : loss : 0.079795, loss_ce: 0.038655
[00:36:30.316] iteration 5201 : loss : 0.129242, loss_ce: 0.017981
[00:36:30.605] iteration 5202 : loss : 0.075484, loss_ce: 0.018694
[00:36:30.894] iteration 5203 : loss : 0.065042, loss_ce: 0.020587
[00:36:31.181] iteration 5204 : loss : 0.085897, loss_ce: 0.025304
[00:36:31.467] iteration 5205 : loss : 0.101228, loss_ce: 0.017708
[00:36:31.754] iteration 5206 : loss : 0.080513, loss_ce: 0.010139
[00:36:32.046] iteration 5207 : loss : 0.063991, loss_ce: 0.029264
[00:36:32.333] iteration 5208 : loss : 0.124711, loss_ce: 0.008609
[00:36:32.621] iteration 5209 : loss : 0.074814, loss_ce: 0.025435
[00:36:32.909] iteration 5210 : loss : 0.074997, loss_ce: 0.026688
[00:36:33.197] iteration 5211 : loss : 0.074656, loss_ce: 0.022308
[00:36:33.489] iteration 5212 : loss : 0.078963, loss_ce: 0.028328
[00:36:33.780] iteration 5213 : loss : 0.064744, loss_ce: 0.018471
[00:36:34.067] iteration 5214 : loss : 0.105195, loss_ce: 0.021448
[00:36:34.355] iteration 5215 : loss : 0.073959, loss_ce: 0.027580
[00:36:34.641] iteration 5216 : loss : 0.087081, loss_ce: 0.024659
[00:36:34.929] iteration 5217 : loss : 0.120010, loss_ce: 0.018553
[00:36:35.215] iteration 5218 : loss : 0.076725, loss_ce: 0.022196
[00:36:35.504] iteration 5219 : loss : 0.083266, loss_ce: 0.016444
[00:36:35.792] iteration 5220 : loss : 0.058028, loss_ce: 0.015067
[00:36:36.092] iteration 5221 : loss : 0.058481, loss_ce: 0.024323
[00:36:36.379] iteration 5222 : loss : 0.071260, loss_ce: 0.017265
[00:36:36.667] iteration 5223 : loss : 0.108445, loss_ce: 0.018336
[00:36:36.957] iteration 5224 : loss : 0.163290, loss_ce: 0.027478
[00:36:37.244] iteration 5225 : loss : 0.077996, loss_ce: 0.027855
[00:36:37.530] iteration 5226 : loss : 0.123102, loss_ce: 0.008162
[00:36:37.818] iteration 5227 : loss : 0.094140, loss_ce: 0.043031
[00:36:38.107] iteration 5228 : loss : 0.138952, loss_ce: 0.007195
[00:36:38.392] iteration 5229 : loss : 0.064573, loss_ce: 0.032223
[00:36:38.681] iteration 5230 : loss : 0.057850, loss_ce: 0.023025
[00:36:38.968] iteration 5231 : loss : 0.130411, loss_ce: 0.022042
[00:36:39.254] iteration 5232 : loss : 0.057121, loss_ce: 0.020487
[00:36:39.545] iteration 5233 : loss : 0.117812, loss_ce: 0.014720
[00:36:39.832] iteration 5234 : loss : 0.090192, loss_ce: 0.025566
[00:36:40.118] iteration 5235 : loss : 0.133449, loss_ce: 0.015872
[00:36:40.405] iteration 5236 : loss : 0.088357, loss_ce: 0.026627
[00:36:40.693] iteration 5237 : loss : 0.122068, loss_ce: 0.014947
[00:36:40.980] iteration 5238 : loss : 0.062257, loss_ce: 0.019876
[00:36:41.268] iteration 5239 : loss : 0.116840, loss_ce: 0.032590
[00:36:41.555] iteration 5240 : loss : 0.116558, loss_ce: 0.021437
[00:36:41.865] iteration 5241 : loss : 0.092448, loss_ce: 0.028531
[00:36:42.153] iteration 5242 : loss : 0.090014, loss_ce: 0.029622
[00:36:42.440] iteration 5243 : loss : 0.145810, loss_ce: 0.022497
[00:36:42.729] iteration 5244 : loss : 0.114717, loss_ce: 0.040956
[00:36:43.019] iteration 5245 : loss : 0.081984, loss_ce: 0.025319
[00:36:43.304] iteration 5246 : loss : 0.095990, loss_ce: 0.032890
[00:36:43.597] iteration 5247 : loss : 0.089892, loss_ce: 0.035368
[00:36:43.885] iteration 5248 : loss : 0.071148, loss_ce: 0.019686
[00:36:44.173] iteration 5249 : loss : 0.105549, loss_ce: 0.033584
[00:36:44.464] iteration 5250 : loss : 0.092116, loss_ce: 0.036727
[00:36:44.751] iteration 5251 : loss : 0.116334, loss_ce: 0.026358
[00:36:45.038] iteration 5252 : loss : 0.073381, loss_ce: 0.034319
[00:36:45.328] iteration 5253 : loss : 0.071262, loss_ce: 0.022413
[00:36:45.617] iteration 5254 : loss : 0.056395, loss_ce: 0.021995
[00:36:45.904] iteration 5255 : loss : 0.097667, loss_ce: 0.020009
[00:36:46.191] iteration 5256 : loss : 0.155275, loss_ce: 0.014839
[00:36:46.480] iteration 5257 : loss : 0.128016, loss_ce: 0.024572
[00:36:46.766] iteration 5258 : loss : 0.131004, loss_ce: 0.017155
[00:36:47.053] iteration 5259 : loss : 0.092557, loss_ce: 0.021706
[00:36:47.341] iteration 5260 : loss : 0.072736, loss_ce: 0.013420
[00:36:47.643] iteration 5261 : loss : 0.059063, loss_ce: 0.018667
[00:36:47.931] iteration 5262 : loss : 0.068139, loss_ce: 0.034850
[00:36:48.219] iteration 5263 : loss : 0.118066, loss_ce: 0.018986
[00:36:48.506] iteration 5264 : loss : 0.083906, loss_ce: 0.016785
[00:36:48.793] iteration 5265 : loss : 0.299549, loss_ce: 0.014083
[00:36:49.082] iteration 5266 : loss : 0.090368, loss_ce: 0.016164
[00:36:49.374] iteration 5267 : loss : 0.068232, loss_ce: 0.034622
[00:36:49.664] iteration 5268 : loss : 0.078746, loss_ce: 0.025506
[00:36:49.954] iteration 5269 : loss : 0.120634, loss_ce: 0.026586
[00:36:50.243] iteration 5270 : loss : 0.076244, loss_ce: 0.025821
[00:36:50.536] iteration 5271 : loss : 0.053159, loss_ce: 0.021100
[00:36:50.826] iteration 5272 : loss : 0.088178, loss_ce: 0.016285
[00:36:51.118] iteration 5273 : loss : 0.116490, loss_ce: 0.018062
[00:36:51.413] iteration 5274 : loss : 0.067271, loss_ce: 0.021175
[00:36:51.707] iteration 5275 : loss : 0.069102, loss_ce: 0.031160
[00:36:51.998] iteration 5276 : loss : 0.087587, loss_ce: 0.028315
[00:36:52.291] iteration 5277 : loss : 0.063850, loss_ce: 0.023488
[00:36:52.586] iteration 5278 : loss : 0.084496, loss_ce: 0.033296
[00:36:52.883] iteration 5279 : loss : 0.066980, loss_ce: 0.029217
[00:36:53.175] iteration 5280 : loss : 0.079120, loss_ce: 0.016007
[00:36:53.489] iteration 5281 : loss : 0.109081, loss_ce: 0.012853
[00:36:53.584] iteration 5282 : loss : 0.421402, loss_ce: 0.002333
[00:37:09.835] iteration 5283 : loss : 0.179083, loss_ce: 0.014404
[00:37:10.123] iteration 5284 : loss : 0.063577, loss_ce: 0.014601
[00:37:10.411] iteration 5285 : loss : 0.090007, loss_ce: 0.013675
[00:37:10.698] iteration 5286 : loss : 0.067015, loss_ce: 0.019048
[00:37:10.986] iteration 5287 : loss : 0.049120, loss_ce: 0.011417
[00:37:11.271] iteration 5288 : loss : 0.093010, loss_ce: 0.036308
[00:37:11.558] iteration 5289 : loss : 0.152606, loss_ce: 0.023402
[00:37:11.847] iteration 5290 : loss : 0.069925, loss_ce: 0.020962
[00:37:12.134] iteration 5291 : loss : 0.078832, loss_ce: 0.028468
[00:37:12.423] iteration 5292 : loss : 0.086699, loss_ce: 0.022279
[00:37:12.715] iteration 5293 : loss : 0.081939, loss_ce: 0.014850
[00:37:13.004] iteration 5294 : loss : 0.113877, loss_ce: 0.020277
[00:37:13.291] iteration 5295 : loss : 0.063157, loss_ce: 0.019482
[00:37:13.580] iteration 5296 : loss : 0.095174, loss_ce: 0.032672
[00:37:13.868] iteration 5297 : loss : 0.085218, loss_ce: 0.014385
[00:37:14.156] iteration 5298 : loss : 0.079890, loss_ce: 0.027629
[00:37:14.445] iteration 5299 : loss : 0.063822, loss_ce: 0.025555
[00:37:14.736] iteration 5300 : loss : 0.061375, loss_ce: 0.027437
[00:37:15.044] iteration 5301 : loss : 0.055239, loss_ce: 0.019874
[00:37:15.335] iteration 5302 : loss : 0.123663, loss_ce: 0.024385
[00:37:15.623] iteration 5303 : loss : 0.062557, loss_ce: 0.021209
[00:37:15.916] iteration 5304 : loss : 0.079194, loss_ce: 0.021719
[00:37:16.204] iteration 5305 : loss : 0.117033, loss_ce: 0.013511
[00:37:16.494] iteration 5306 : loss : 0.137649, loss_ce: 0.030244
[00:37:16.782] iteration 5307 : loss : 0.067854, loss_ce: 0.027085
[00:37:17.073] iteration 5308 : loss : 0.070680, loss_ce: 0.019970
[00:37:17.364] iteration 5309 : loss : 0.073541, loss_ce: 0.028757
[00:37:17.652] iteration 5310 : loss : 0.054478, loss_ce: 0.018647
[00:37:17.938] iteration 5311 : loss : 0.071013, loss_ce: 0.027936
[00:37:18.228] iteration 5312 : loss : 0.064682, loss_ce: 0.018666
[00:37:18.518] iteration 5313 : loss : 0.080489, loss_ce: 0.025537
[00:37:18.810] iteration 5314 : loss : 0.071504, loss_ce: 0.027113
[00:37:19.101] iteration 5315 : loss : 0.129820, loss_ce: 0.016132
[00:37:19.392] iteration 5316 : loss : 0.074351, loss_ce: 0.014317
[00:37:19.680] iteration 5317 : loss : 0.096517, loss_ce: 0.017692
[00:37:19.970] iteration 5318 : loss : 0.073237, loss_ce: 0.019119
[00:37:20.260] iteration 5319 : loss : 0.081160, loss_ce: 0.029124
[00:37:20.548] iteration 5320 : loss : 0.067425, loss_ce: 0.014827
[00:37:20.850] iteration 5321 : loss : 0.121670, loss_ce: 0.008426
[00:37:21.138] iteration 5322 : loss : 0.133016, loss_ce: 0.036731
[00:37:21.424] iteration 5323 : loss : 0.081404, loss_ce: 0.044162
[00:37:21.713] iteration 5324 : loss : 0.075715, loss_ce: 0.017497
[00:37:22.003] iteration 5325 : loss : 0.107509, loss_ce: 0.020065
[00:37:22.293] iteration 5326 : loss : 0.067822, loss_ce: 0.029765
[00:37:22.583] iteration 5327 : loss : 0.066849, loss_ce: 0.028472
[00:37:22.873] iteration 5328 : loss : 0.055187, loss_ce: 0.021969
[00:37:23.161] iteration 5329 : loss : 0.085828, loss_ce: 0.019894
[00:37:23.448] iteration 5330 : loss : 0.111154, loss_ce: 0.031060
[00:37:23.736] iteration 5331 : loss : 0.075736, loss_ce: 0.014293
[00:37:24.021] iteration 5332 : loss : 0.115854, loss_ce: 0.009897
[00:37:24.311] iteration 5333 : loss : 0.220196, loss_ce: 0.017081
[00:37:24.598] iteration 5334 : loss : 0.081504, loss_ce: 0.035226
[00:37:24.888] iteration 5335 : loss : 0.047805, loss_ce: 0.010199
[00:37:25.177] iteration 5336 : loss : 0.122642, loss_ce: 0.015300
[00:37:25.468] iteration 5337 : loss : 0.060828, loss_ce: 0.028955
[00:37:25.756] iteration 5338 : loss : 0.133204, loss_ce: 0.009718
[00:37:26.043] iteration 5339 : loss : 0.129349, loss_ce: 0.020298
[00:37:26.330] iteration 5340 : loss : 0.071633, loss_ce: 0.023481
[00:37:26.634] iteration 5341 : loss : 0.087723, loss_ce: 0.031716
[00:37:26.922] iteration 5342 : loss : 0.076703, loss_ce: 0.038110
[00:37:27.208] iteration 5343 : loss : 0.063637, loss_ce: 0.013483
[00:37:27.498] iteration 5344 : loss : 0.064608, loss_ce: 0.018557
[00:37:27.789] iteration 5345 : loss : 0.046051, loss_ce: 0.017004
[00:37:28.075] iteration 5346 : loss : 0.064625, loss_ce: 0.020528
[00:37:28.364] iteration 5347 : loss : 0.058036, loss_ce: 0.017692
[00:37:28.650] iteration 5348 : loss : 0.095663, loss_ce: 0.034357
[00:37:28.936] iteration 5349 : loss : 0.075155, loss_ce: 0.026099
[00:37:29.227] iteration 5350 : loss : 0.057661, loss_ce: 0.014256
[00:37:29.516] iteration 5351 : loss : 0.071590, loss_ce: 0.032639
[00:37:29.805] iteration 5352 : loss : 0.151886, loss_ce: 0.013457
[00:37:30.090] iteration 5353 : loss : 0.086244, loss_ce: 0.019149
[00:37:30.381] iteration 5354 : loss : 0.066747, loss_ce: 0.014323
[00:37:30.668] iteration 5355 : loss : 0.104292, loss_ce: 0.018538
[00:37:30.954] iteration 5356 : loss : 0.086708, loss_ce: 0.028202
[00:37:31.241] iteration 5357 : loss : 0.095239, loss_ce: 0.026610
[00:37:31.528] iteration 5358 : loss : 0.065829, loss_ce: 0.024040
[00:37:31.816] iteration 5359 : loss : 0.072339, loss_ce: 0.022429
[00:37:32.101] iteration 5360 : loss : 0.137830, loss_ce: 0.010364
[00:37:32.404] iteration 5361 : loss : 0.077092, loss_ce: 0.019825
[00:37:32.693] iteration 5362 : loss : 0.073710, loss_ce: 0.029946
[00:37:32.980] iteration 5363 : loss : 0.076706, loss_ce: 0.013864
[00:37:33.268] iteration 5364 : loss : 0.078663, loss_ce: 0.018360
[00:37:33.553] iteration 5365 : loss : 0.088345, loss_ce: 0.019426
[00:37:33.846] iteration 5366 : loss : 0.098105, loss_ce: 0.024526
[00:37:34.134] iteration 5367 : loss : 0.072017, loss_ce: 0.019355
[00:37:34.423] iteration 5368 : loss : 0.068474, loss_ce: 0.022025
[00:37:34.712] iteration 5369 : loss : 0.071309, loss_ce: 0.016420
[00:37:34.999] iteration 5370 : loss : 0.067966, loss_ce: 0.018525
[00:37:35.288] iteration 5371 : loss : 0.097304, loss_ce: 0.017121
[00:37:35.577] iteration 5372 : loss : 0.134494, loss_ce: 0.029185
[00:37:35.865] iteration 5373 : loss : 0.063032, loss_ce: 0.009157
[00:37:36.152] iteration 5374 : loss : 0.056391, loss_ce: 0.011986
[00:37:36.442] iteration 5375 : loss : 0.058006, loss_ce: 0.022215
[00:37:36.732] iteration 5376 : loss : 0.126331, loss_ce: 0.005022
[00:37:37.021] iteration 5377 : loss : 0.086614, loss_ce: 0.024242
[00:37:37.308] iteration 5378 : loss : 0.075987, loss_ce: 0.018167
[00:37:37.595] iteration 5379 : loss : 0.073136, loss_ce: 0.030835
[00:37:37.883] iteration 5380 : loss : 0.059474, loss_ce: 0.016729
[00:37:38.191] iteration 5381 : loss : 0.142817, loss_ce: 0.026230
[00:37:38.480] iteration 5382 : loss : 0.155664, loss_ce: 0.012025
[00:37:38.768] iteration 5383 : loss : 0.095955, loss_ce: 0.039564
[00:37:39.057] iteration 5384 : loss : 0.083101, loss_ce: 0.010439
[00:37:39.346] iteration 5385 : loss : 0.111537, loss_ce: 0.013094
[00:37:39.633] iteration 5386 : loss : 0.080809, loss_ce: 0.023954
[00:37:39.922] iteration 5387 : loss : 0.126814, loss_ce: 0.014892
[00:37:40.212] iteration 5388 : loss : 0.071621, loss_ce: 0.025288
[00:37:40.502] iteration 5389 : loss : 0.215046, loss_ce: 0.007175
[00:37:40.791] iteration 5390 : loss : 0.075318, loss_ce: 0.014981
[00:37:41.080] iteration 5391 : loss : 0.078974, loss_ce: 0.025914
[00:37:41.368] iteration 5392 : loss : 0.221381, loss_ce: 0.008834
[00:37:41.655] iteration 5393 : loss : 0.137108, loss_ce: 0.015740
[00:37:41.940] iteration 5394 : loss : 0.078594, loss_ce: 0.019201
[00:37:42.231] iteration 5395 : loss : 0.126959, loss_ce: 0.025585
[00:37:42.519] iteration 5396 : loss : 0.075458, loss_ce: 0.017556
[00:37:42.812] iteration 5397 : loss : 0.084451, loss_ce: 0.031440
[00:37:43.102] iteration 5398 : loss : 0.077280, loss_ce: 0.015695
[00:37:43.394] iteration 5399 : loss : 0.074944, loss_ce: 0.016285
[00:37:43.680] iteration 5400 : loss : 0.123768, loss_ce: 0.020817
[00:37:43.983] iteration 5401 : loss : 0.066625, loss_ce: 0.021754
[00:37:44.271] iteration 5402 : loss : 0.076070, loss_ce: 0.014507
[00:37:44.562] iteration 5403 : loss : 0.106958, loss_ce: 0.019583
[00:37:44.850] iteration 5404 : loss : 0.106763, loss_ce: 0.024920
[00:37:45.146] iteration 5405 : loss : 0.059961, loss_ce: 0.020730
[00:37:45.437] iteration 5406 : loss : 0.089771, loss_ce: 0.017428
[00:37:45.728] iteration 5407 : loss : 0.070558, loss_ce: 0.031530
[00:37:46.019] iteration 5408 : loss : 0.122843, loss_ce: 0.009766
[00:37:46.308] iteration 5409 : loss : 0.150333, loss_ce: 0.013181
[00:37:46.597] iteration 5410 : loss : 0.127939, loss_ce: 0.026491
[00:37:46.890] iteration 5411 : loss : 0.108476, loss_ce: 0.020316
[00:37:47.181] iteration 5412 : loss : 0.110736, loss_ce: 0.049209
[00:37:47.471] iteration 5413 : loss : 0.089591, loss_ce: 0.017498
[00:37:47.763] iteration 5414 : loss : 0.137396, loss_ce: 0.025426
[00:37:48.050] iteration 5415 : loss : 0.124788, loss_ce: 0.022500
[00:37:48.344] iteration 5416 : loss : 0.071495, loss_ce: 0.017791
[00:37:48.634] iteration 5417 : loss : 0.070132, loss_ce: 0.024960
[00:37:48.924] iteration 5418 : loss : 0.081656, loss_ce: 0.022758
[00:37:49.216] iteration 5419 : loss : 0.178670, loss_ce: 0.014985
[00:37:49.506] iteration 5420 : loss : 0.189543, loss_ce: 0.012476
[00:37:49.623] iteration 5421 : loss : 0.125557, loss_ce: 0.039311
[00:38:06.194] iteration 5422 : loss : 0.125991, loss_ce: 0.019459
[00:38:06.477] iteration 5423 : loss : 0.189989, loss_ce: 0.011766
[00:38:06.762] iteration 5424 : loss : 0.062292, loss_ce: 0.019545
[00:38:07.048] iteration 5425 : loss : 0.076408, loss_ce: 0.021929
[00:38:07.335] iteration 5426 : loss : 0.099397, loss_ce: 0.020231
[00:38:07.623] iteration 5427 : loss : 0.118415, loss_ce: 0.011274
[00:38:07.910] iteration 5428 : loss : 0.076689, loss_ce: 0.028399
[00:38:08.197] iteration 5429 : loss : 0.076515, loss_ce: 0.021087
[00:38:08.484] iteration 5430 : loss : 0.104580, loss_ce: 0.041139
[00:38:08.770] iteration 5431 : loss : 0.056561, loss_ce: 0.023656
[00:38:09.059] iteration 5432 : loss : 0.107378, loss_ce: 0.016868
[00:38:09.346] iteration 5433 : loss : 0.107613, loss_ce: 0.032725
[00:38:09.632] iteration 5434 : loss : 0.080812, loss_ce: 0.028259
[00:38:09.918] iteration 5435 : loss : 0.085542, loss_ce: 0.033639
[00:38:10.205] iteration 5436 : loss : 0.110047, loss_ce: 0.015728
[00:38:10.499] iteration 5437 : loss : 0.078821, loss_ce: 0.027090
[00:38:10.787] iteration 5438 : loss : 0.094394, loss_ce: 0.004533
[00:38:11.076] iteration 5439 : loss : 0.092950, loss_ce: 0.023185
[00:38:11.367] iteration 5440 : loss : 0.068335, loss_ce: 0.018179
[00:38:11.670] iteration 5441 : loss : 0.079615, loss_ce: 0.022401
[00:38:11.960] iteration 5442 : loss : 0.062645, loss_ce: 0.015966
[00:38:12.250] iteration 5443 : loss : 0.079132, loss_ce: 0.012064
[00:38:12.540] iteration 5444 : loss : 0.120923, loss_ce: 0.022413
[00:38:12.827] iteration 5445 : loss : 0.083326, loss_ce: 0.018355
[00:38:13.114] iteration 5446 : loss : 0.067989, loss_ce: 0.030571
[00:38:13.401] iteration 5447 : loss : 0.193731, loss_ce: 0.006594
[00:38:13.691] iteration 5448 : loss : 0.098390, loss_ce: 0.027382
[00:38:13.977] iteration 5449 : loss : 0.118260, loss_ce: 0.014376
[00:38:14.266] iteration 5450 : loss : 0.121856, loss_ce: 0.017000
[00:38:14.554] iteration 5451 : loss : 0.068085, loss_ce: 0.026510
[00:38:14.841] iteration 5452 : loss : 0.064124, loss_ce: 0.021001
[00:38:15.128] iteration 5453 : loss : 0.068679, loss_ce: 0.021332
[00:38:15.416] iteration 5454 : loss : 0.124310, loss_ce: 0.018013
[00:38:15.702] iteration 5455 : loss : 0.105085, loss_ce: 0.014434
[00:38:15.988] iteration 5456 : loss : 0.115963, loss_ce: 0.019089
[00:38:16.276] iteration 5457 : loss : 0.154810, loss_ce: 0.026544
[00:38:16.565] iteration 5458 : loss : 0.062357, loss_ce: 0.024749
[00:38:16.853] iteration 5459 : loss : 0.062687, loss_ce: 0.019024
[00:38:17.144] iteration 5460 : loss : 0.082091, loss_ce: 0.026796
[00:38:17.446] iteration 5461 : loss : 0.147844, loss_ce: 0.023118
[00:38:17.735] iteration 5462 : loss : 0.074902, loss_ce: 0.019853
[00:38:18.025] iteration 5463 : loss : 0.148716, loss_ce: 0.040295
[00:38:18.311] iteration 5464 : loss : 0.080774, loss_ce: 0.018463
[00:38:18.599] iteration 5465 : loss : 0.363759, loss_ce: 0.006707
[00:38:18.887] iteration 5466 : loss : 0.070486, loss_ce: 0.024955
[00:38:19.175] iteration 5467 : loss : 0.221574, loss_ce: 0.006912
[00:38:19.462] iteration 5468 : loss : 0.076251, loss_ce: 0.020238
[00:38:19.751] iteration 5469 : loss : 0.066845, loss_ce: 0.023421
[00:38:20.039] iteration 5470 : loss : 0.051262, loss_ce: 0.021866
[00:38:20.326] iteration 5471 : loss : 0.095472, loss_ce: 0.025615
[00:38:20.615] iteration 5472 : loss : 0.066770, loss_ce: 0.014528
[00:38:20.903] iteration 5473 : loss : 0.076722, loss_ce: 0.017503
[00:38:21.190] iteration 5474 : loss : 0.104157, loss_ce: 0.026685
[00:38:21.478] iteration 5475 : loss : 0.069033, loss_ce: 0.035886
[00:38:21.765] iteration 5476 : loss : 0.114748, loss_ce: 0.016472
[00:38:22.052] iteration 5477 : loss : 0.061289, loss_ce: 0.022622
[00:38:22.340] iteration 5478 : loss : 0.089618, loss_ce: 0.020050
[00:38:22.629] iteration 5479 : loss : 0.177612, loss_ce: 0.032055
[00:38:22.918] iteration 5480 : loss : 0.160015, loss_ce: 0.015904
[00:38:23.225] iteration 5481 : loss : 0.069652, loss_ce: 0.019965
[00:38:23.516] iteration 5482 : loss : 0.078493, loss_ce: 0.031908
[00:38:23.803] iteration 5483 : loss : 0.083914, loss_ce: 0.021047
[00:38:24.091] iteration 5484 : loss : 0.086919, loss_ce: 0.012934
[00:38:24.382] iteration 5485 : loss : 0.133603, loss_ce: 0.033885
[00:38:24.670] iteration 5486 : loss : 0.075783, loss_ce: 0.015350
[00:38:24.959] iteration 5487 : loss : 0.066193, loss_ce: 0.014318
[00:38:25.246] iteration 5488 : loss : 0.106636, loss_ce: 0.023609
[00:38:25.535] iteration 5489 : loss : 0.078639, loss_ce: 0.031804
[00:38:25.823] iteration 5490 : loss : 0.090070, loss_ce: 0.031836
[00:38:26.110] iteration 5491 : loss : 0.078013, loss_ce: 0.020300
[00:38:26.398] iteration 5492 : loss : 0.086756, loss_ce: 0.028389
[00:38:26.685] iteration 5493 : loss : 0.076872, loss_ce: 0.014626
[00:38:26.971] iteration 5494 : loss : 0.071241, loss_ce: 0.024924
[00:38:27.261] iteration 5495 : loss : 0.125103, loss_ce: 0.023633
[00:38:27.551] iteration 5496 : loss : 0.086801, loss_ce: 0.019589
[00:38:27.842] iteration 5497 : loss : 0.094339, loss_ce: 0.014442
[00:38:28.129] iteration 5498 : loss : 0.046629, loss_ce: 0.015742
[00:38:28.416] iteration 5499 : loss : 0.085450, loss_ce: 0.021412
[00:38:28.705] iteration 5500 : loss : 0.071402, loss_ce: 0.026422
[00:38:29.008] iteration 5501 : loss : 0.083296, loss_ce: 0.035975
[00:38:29.296] iteration 5502 : loss : 0.116885, loss_ce: 0.016126
[00:38:29.588] iteration 5503 : loss : 0.130168, loss_ce: 0.015962
[00:38:29.877] iteration 5504 : loss : 0.097565, loss_ce: 0.012598
[00:38:30.168] iteration 5505 : loss : 0.065727, loss_ce: 0.021594
[00:38:30.456] iteration 5506 : loss : 0.074510, loss_ce: 0.022942
[00:38:30.746] iteration 5507 : loss : 0.080382, loss_ce: 0.025131
[00:38:31.032] iteration 5508 : loss : 0.121511, loss_ce: 0.010549
[00:38:31.322] iteration 5509 : loss : 0.084796, loss_ce: 0.017081
[00:38:31.610] iteration 5510 : loss : 0.059632, loss_ce: 0.020425
[00:38:31.897] iteration 5511 : loss : 0.080823, loss_ce: 0.016879
[00:38:32.185] iteration 5512 : loss : 0.080361, loss_ce: 0.027422
[00:38:32.472] iteration 5513 : loss : 0.063436, loss_ce: 0.019016
[00:38:32.764] iteration 5514 : loss : 0.113663, loss_ce: 0.014894
[00:38:33.055] iteration 5515 : loss : 0.064156, loss_ce: 0.017056
[00:38:33.342] iteration 5516 : loss : 0.077038, loss_ce: 0.019943
[00:38:33.632] iteration 5517 : loss : 0.071751, loss_ce: 0.020209
[00:38:33.921] iteration 5518 : loss : 0.082675, loss_ce: 0.022877
[00:38:34.209] iteration 5519 : loss : 0.080752, loss_ce: 0.014792
[00:38:34.496] iteration 5520 : loss : 0.070197, loss_ce: 0.030533
[00:38:34.799] iteration 5521 : loss : 0.073516, loss_ce: 0.011304
[00:38:35.088] iteration 5522 : loss : 0.099133, loss_ce: 0.024194
[00:38:35.374] iteration 5523 : loss : 0.078547, loss_ce: 0.019603
[00:38:35.666] iteration 5524 : loss : 0.073379, loss_ce: 0.039112
[00:38:35.957] iteration 5525 : loss : 0.067460, loss_ce: 0.029210
[00:38:36.246] iteration 5526 : loss : 0.067288, loss_ce: 0.025946
[00:38:36.538] iteration 5527 : loss : 0.073052, loss_ce: 0.023222
[00:38:36.825] iteration 5528 : loss : 0.081775, loss_ce: 0.019393
[00:38:37.116] iteration 5529 : loss : 0.076738, loss_ce: 0.031148
[00:38:37.406] iteration 5530 : loss : 0.070568, loss_ce: 0.015514
[00:38:37.695] iteration 5531 : loss : 0.130125, loss_ce: 0.011065
[00:38:37.985] iteration 5532 : loss : 0.074199, loss_ce: 0.013554
[00:38:38.274] iteration 5533 : loss : 0.175301, loss_ce: 0.015865
[00:38:38.564] iteration 5534 : loss : 0.098535, loss_ce: 0.028309
[00:38:38.852] iteration 5535 : loss : 0.069453, loss_ce: 0.023271
[00:38:39.140] iteration 5536 : loss : 0.063950, loss_ce: 0.025548
[00:38:39.428] iteration 5537 : loss : 0.065454, loss_ce: 0.021537
[00:38:39.718] iteration 5538 : loss : 0.068172, loss_ce: 0.022869
[00:38:40.005] iteration 5539 : loss : 0.293248, loss_ce: 0.010062
[00:38:40.296] iteration 5540 : loss : 0.076820, loss_ce: 0.007155
[00:38:40.606] iteration 5541 : loss : 0.074160, loss_ce: 0.020997
[00:38:40.894] iteration 5542 : loss : 0.130939, loss_ce: 0.017774
[00:38:41.182] iteration 5543 : loss : 0.198628, loss_ce: 0.015293
[00:38:41.478] iteration 5544 : loss : 0.065223, loss_ce: 0.030659
[00:38:41.766] iteration 5545 : loss : 0.124605, loss_ce: 0.019783
[00:38:42.055] iteration 5546 : loss : 0.086161, loss_ce: 0.019578
[00:38:42.351] iteration 5547 : loss : 0.104863, loss_ce: 0.008463
[00:38:42.642] iteration 5548 : loss : 0.073440, loss_ce: 0.032695
[00:38:42.930] iteration 5549 : loss : 0.117239, loss_ce: 0.018119
[00:38:43.221] iteration 5550 : loss : 0.078525, loss_ce: 0.011973
[00:38:43.508] iteration 5551 : loss : 0.100210, loss_ce: 0.022613
[00:38:43.801] iteration 5552 : loss : 0.086495, loss_ce: 0.028626
[00:38:44.092] iteration 5553 : loss : 0.058422, loss_ce: 0.012940
[00:38:44.385] iteration 5554 : loss : 0.056041, loss_ce: 0.016446
[00:38:44.674] iteration 5555 : loss : 0.112350, loss_ce: 0.023952
[00:38:44.967] iteration 5556 : loss : 0.058425, loss_ce: 0.020862
[00:38:45.259] iteration 5557 : loss : 0.138172, loss_ce: 0.021943
[00:38:45.555] iteration 5558 : loss : 0.072689, loss_ce: 0.019288
[00:38:45.846] iteration 5559 : loss : 0.078917, loss_ce: 0.024435
[00:38:45.925] iteration 5560 : loss : 0.229257, loss_ce: 0.006575
[00:39:02.650] iteration 5561 : loss : 0.067315, loss_ce: 0.013312
[00:39:02.938] iteration 5562 : loss : 0.070072, loss_ce: 0.037068
[00:39:03.225] iteration 5563 : loss : 0.086547, loss_ce: 0.029350
[00:39:03.514] iteration 5564 : loss : 0.064935, loss_ce: 0.016142
[00:39:03.802] iteration 5565 : loss : 0.121777, loss_ce: 0.024264
[00:39:04.089] iteration 5566 : loss : 0.062791, loss_ce: 0.017146
[00:39:04.375] iteration 5567 : loss : 0.153569, loss_ce: 0.018428
[00:39:04.667] iteration 5568 : loss : 0.053113, loss_ce: 0.010478
[00:39:04.956] iteration 5569 : loss : 0.064444, loss_ce: 0.026328
[00:39:05.246] iteration 5570 : loss : 0.071301, loss_ce: 0.025200
[00:39:05.536] iteration 5571 : loss : 0.071013, loss_ce: 0.018657
[00:39:05.826] iteration 5572 : loss : 0.057540, loss_ce: 0.015230
[00:39:06.114] iteration 5573 : loss : 0.063751, loss_ce: 0.013728
[00:39:06.406] iteration 5574 : loss : 0.148413, loss_ce: 0.013785
[00:39:06.693] iteration 5575 : loss : 0.064920, loss_ce: 0.012313
[00:39:06.984] iteration 5576 : loss : 0.063419, loss_ce: 0.018736
[00:39:07.274] iteration 5577 : loss : 0.117008, loss_ce: 0.014763
[00:39:07.565] iteration 5578 : loss : 0.070047, loss_ce: 0.026493
[00:39:07.851] iteration 5579 : loss : 0.110168, loss_ce: 0.031534
[00:39:08.142] iteration 5580 : loss : 0.068634, loss_ce: 0.024845
[00:39:08.452] iteration 5581 : loss : 0.122952, loss_ce: 0.014662
[00:39:08.740] iteration 5582 : loss : 0.074980, loss_ce: 0.027825
[00:39:09.031] iteration 5583 : loss : 0.075568, loss_ce: 0.014665
[00:39:09.318] iteration 5584 : loss : 0.089727, loss_ce: 0.022847
[00:39:09.607] iteration 5585 : loss : 0.063318, loss_ce: 0.023549
[00:39:09.898] iteration 5586 : loss : 0.126732, loss_ce: 0.023448
[00:39:10.188] iteration 5587 : loss : 0.079967, loss_ce: 0.021876
[00:39:10.480] iteration 5588 : loss : 0.076360, loss_ce: 0.017522
[00:39:10.772] iteration 5589 : loss : 0.069468, loss_ce: 0.016842
[00:39:11.063] iteration 5590 : loss : 0.063567, loss_ce: 0.011342
[00:39:11.353] iteration 5591 : loss : 0.068164, loss_ce: 0.038824
[00:39:11.642] iteration 5592 : loss : 0.094221, loss_ce: 0.031414
[00:39:11.930] iteration 5593 : loss : 0.080546, loss_ce: 0.020065
[00:39:12.219] iteration 5594 : loss : 0.065907, loss_ce: 0.022857
[00:39:12.509] iteration 5595 : loss : 0.082707, loss_ce: 0.026337
[00:39:12.798] iteration 5596 : loss : 0.076768, loss_ce: 0.029582
[00:39:13.087] iteration 5597 : loss : 0.096079, loss_ce: 0.024135
[00:39:13.378] iteration 5598 : loss : 0.061008, loss_ce: 0.013242
[00:39:13.669] iteration 5599 : loss : 0.105021, loss_ce: 0.023306
[00:39:13.958] iteration 5600 : loss : 0.073284, loss_ce: 0.013241
[00:39:14.264] iteration 5601 : loss : 0.068409, loss_ce: 0.023093
[00:39:14.552] iteration 5602 : loss : 0.121395, loss_ce: 0.014765
[00:39:14.842] iteration 5603 : loss : 0.068813, loss_ce: 0.023028
[00:39:15.134] iteration 5604 : loss : 0.070380, loss_ce: 0.024004
[00:39:15.422] iteration 5605 : loss : 0.135495, loss_ce: 0.005516
[00:39:15.710] iteration 5606 : loss : 0.064461, loss_ce: 0.021230
[00:39:15.996] iteration 5607 : loss : 0.057919, loss_ce: 0.015388
[00:39:16.287] iteration 5608 : loss : 0.074463, loss_ce: 0.022630
[00:39:16.576] iteration 5609 : loss : 0.104018, loss_ce: 0.018235
[00:39:16.865] iteration 5610 : loss : 0.060399, loss_ce: 0.013060
[00:39:17.159] iteration 5611 : loss : 0.162840, loss_ce: 0.035387
[00:39:17.448] iteration 5612 : loss : 0.120579, loss_ce: 0.017884
[00:39:17.738] iteration 5613 : loss : 0.071199, loss_ce: 0.013791
[00:39:18.029] iteration 5614 : loss : 0.067117, loss_ce: 0.019003
[00:39:18.322] iteration 5615 : loss : 0.067934, loss_ce: 0.024372
[00:39:18.610] iteration 5616 : loss : 0.063666, loss_ce: 0.020409
[00:39:18.903] iteration 5617 : loss : 0.060783, loss_ce: 0.021124
[00:39:19.194] iteration 5618 : loss : 0.062241, loss_ce: 0.008698
[00:39:19.483] iteration 5619 : loss : 0.066561, loss_ce: 0.025291
[00:39:19.775] iteration 5620 : loss : 0.122833, loss_ce: 0.017539
[00:39:20.079] iteration 5621 : loss : 0.055663, loss_ce: 0.019469
[00:39:20.369] iteration 5622 : loss : 0.064081, loss_ce: 0.020306
[00:39:20.655] iteration 5623 : loss : 0.053667, loss_ce: 0.012840
[00:39:20.942] iteration 5624 : loss : 0.167732, loss_ce: 0.008338
[00:39:21.228] iteration 5625 : loss : 0.057244, loss_ce: 0.015582
[00:39:21.519] iteration 5626 : loss : 0.198655, loss_ce: 0.005125
[00:39:21.809] iteration 5627 : loss : 0.064160, loss_ce: 0.034852
[00:39:22.095] iteration 5628 : loss : 0.130246, loss_ce: 0.014754
[00:39:22.382] iteration 5629 : loss : 0.078237, loss_ce: 0.026520
[00:39:22.669] iteration 5630 : loss : 0.083562, loss_ce: 0.030464
[00:39:22.954] iteration 5631 : loss : 0.064051, loss_ce: 0.010054
[00:39:23.241] iteration 5632 : loss : 0.074463, loss_ce: 0.025284
[00:39:23.531] iteration 5633 : loss : 0.081122, loss_ce: 0.021393
[00:39:23.820] iteration 5634 : loss : 0.090221, loss_ce: 0.027757
[00:39:24.110] iteration 5635 : loss : 0.065746, loss_ce: 0.021691
[00:39:24.399] iteration 5636 : loss : 0.117409, loss_ce: 0.013138
[00:39:24.688] iteration 5637 : loss : 0.075727, loss_ce: 0.018267
[00:39:24.973] iteration 5638 : loss : 0.110450, loss_ce: 0.019071
[00:39:25.262] iteration 5639 : loss : 0.071393, loss_ce: 0.026099
[00:39:25.553] iteration 5640 : loss : 0.100854, loss_ce: 0.031541
[00:39:25.859] iteration 5641 : loss : 0.062042, loss_ce: 0.014768
[00:39:26.147] iteration 5642 : loss : 0.075908, loss_ce: 0.016881
[00:39:26.434] iteration 5643 : loss : 0.086112, loss_ce: 0.035302
[00:39:26.722] iteration 5644 : loss : 0.071001, loss_ce: 0.022658
[00:39:27.011] iteration 5645 : loss : 0.083373, loss_ce: 0.019309
[00:39:27.298] iteration 5646 : loss : 0.063802, loss_ce: 0.018505
[00:39:27.589] iteration 5647 : loss : 0.116767, loss_ce: 0.016219
[00:39:27.876] iteration 5648 : loss : 0.083853, loss_ce: 0.021963
[00:39:28.167] iteration 5649 : loss : 0.061808, loss_ce: 0.017803
[00:39:28.454] iteration 5650 : loss : 0.060855, loss_ce: 0.015278
[00:39:28.743] iteration 5651 : loss : 0.073170, loss_ce: 0.014361
[00:39:29.031] iteration 5652 : loss : 0.087865, loss_ce: 0.021788
[00:39:29.320] iteration 5653 : loss : 0.096237, loss_ce: 0.014992
[00:39:29.608] iteration 5654 : loss : 0.095669, loss_ce: 0.033709
[00:39:29.897] iteration 5655 : loss : 0.082374, loss_ce: 0.032777
[00:39:30.184] iteration 5656 : loss : 0.064021, loss_ce: 0.019240
[00:39:30.473] iteration 5657 : loss : 0.083253, loss_ce: 0.031666
[00:39:30.760] iteration 5658 : loss : 0.075523, loss_ce: 0.027485
[00:39:31.048] iteration 5659 : loss : 0.137013, loss_ce: 0.025505
[00:39:31.336] iteration 5660 : loss : 0.119253, loss_ce: 0.016741
[00:39:31.639] iteration 5661 : loss : 0.064575, loss_ce: 0.017575
[00:39:31.926] iteration 5662 : loss : 0.129793, loss_ce: 0.022723
[00:39:32.212] iteration 5663 : loss : 0.063307, loss_ce: 0.021874
[00:39:32.502] iteration 5664 : loss : 0.123858, loss_ce: 0.015335
[00:39:32.792] iteration 5665 : loss : 0.130245, loss_ce: 0.030324
[00:39:33.080] iteration 5666 : loss : 0.129956, loss_ce: 0.019171
[00:39:33.371] iteration 5667 : loss : 0.076425, loss_ce: 0.031554
[00:39:33.659] iteration 5668 : loss : 0.060601, loss_ce: 0.022380
[00:39:33.947] iteration 5669 : loss : 0.056391, loss_ce: 0.011028
[00:39:34.237] iteration 5670 : loss : 0.122465, loss_ce: 0.015605
[00:39:34.526] iteration 5671 : loss : 0.049336, loss_ce: 0.020728
[00:39:34.813] iteration 5672 : loss : 0.098256, loss_ce: 0.020806
[00:39:35.104] iteration 5673 : loss : 0.068753, loss_ce: 0.013655
[00:39:35.393] iteration 5674 : loss : 0.066904, loss_ce: 0.014415
[00:39:35.681] iteration 5675 : loss : 0.088705, loss_ce: 0.014927
[00:39:35.970] iteration 5676 : loss : 0.068631, loss_ce: 0.012569
[00:39:36.261] iteration 5677 : loss : 0.068480, loss_ce: 0.024956
[00:39:36.547] iteration 5678 : loss : 0.139226, loss_ce: 0.015984
[00:39:36.833] iteration 5679 : loss : 0.107833, loss_ce: 0.023536
[00:39:37.120] iteration 5680 : loss : 0.049105, loss_ce: 0.023571
[00:39:37.427] iteration 5681 : loss : 0.072467, loss_ce: 0.030615
[00:39:37.715] iteration 5682 : loss : 0.069295, loss_ce: 0.018762
[00:39:38.003] iteration 5683 : loss : 0.239655, loss_ce: 0.009640
[00:39:38.297] iteration 5684 : loss : 0.074079, loss_ce: 0.024411
[00:39:38.590] iteration 5685 : loss : 0.112245, loss_ce: 0.012949
[00:39:38.882] iteration 5686 : loss : 0.081962, loss_ce: 0.026309
[00:39:39.172] iteration 5687 : loss : 0.065145, loss_ce: 0.019682
[00:39:39.462] iteration 5688 : loss : 0.118160, loss_ce: 0.011776
[00:39:39.750] iteration 5689 : loss : 0.108516, loss_ce: 0.018416
[00:39:40.042] iteration 5690 : loss : 0.058226, loss_ce: 0.012220
[00:39:40.334] iteration 5691 : loss : 0.130214, loss_ce: 0.012455
[00:39:40.627] iteration 5692 : loss : 0.112092, loss_ce: 0.020157
[00:39:40.916] iteration 5693 : loss : 0.061369, loss_ce: 0.027007
[00:39:41.205] iteration 5694 : loss : 0.090834, loss_ce: 0.022866
[00:39:41.498] iteration 5695 : loss : 0.083717, loss_ce: 0.026391
[00:39:41.796] iteration 5696 : loss : 0.076550, loss_ce: 0.028214
[00:39:42.087] iteration 5697 : loss : 0.101424, loss_ce: 0.022855
[00:39:42.380] iteration 5698 : loss : 0.059767, loss_ce: 0.018296
[00:39:42.463] iteration 5699 : loss : 0.244853, loss_ce: 0.037521
[00:39:59.102] iteration 5700 : loss : 0.075708, loss_ce: 0.031499
[00:39:59.408] iteration 5701 : loss : 0.084205, loss_ce: 0.014978
[00:39:59.695] iteration 5702 : loss : 0.061063, loss_ce: 0.010215
[00:39:59.980] iteration 5703 : loss : 0.067945, loss_ce: 0.014849
[00:40:00.272] iteration 5704 : loss : 0.093535, loss_ce: 0.022185
[00:40:00.560] iteration 5705 : loss : 0.112906, loss_ce: 0.026062
[00:40:00.849] iteration 5706 : loss : 0.118221, loss_ce: 0.013992
[00:40:01.138] iteration 5707 : loss : 0.130400, loss_ce: 0.024980
[00:40:01.424] iteration 5708 : loss : 0.104896, loss_ce: 0.014849
[00:40:01.710] iteration 5709 : loss : 0.234246, loss_ce: 0.006947
[00:40:01.996] iteration 5710 : loss : 0.108752, loss_ce: 0.029200
[00:40:02.284] iteration 5711 : loss : 0.072251, loss_ce: 0.013530
[00:40:02.572] iteration 5712 : loss : 0.103867, loss_ce: 0.029205
[00:40:02.858] iteration 5713 : loss : 0.081210, loss_ce: 0.023274
[00:40:03.145] iteration 5714 : loss : 0.081956, loss_ce: 0.011517
[00:40:03.433] iteration 5715 : loss : 0.101974, loss_ce: 0.029450
[00:40:03.721] iteration 5716 : loss : 0.181363, loss_ce: 0.009830
[00:40:04.008] iteration 5717 : loss : 0.079963, loss_ce: 0.034928
[00:40:04.294] iteration 5718 : loss : 0.071639, loss_ce: 0.014462
[00:40:04.581] iteration 5719 : loss : 0.113210, loss_ce: 0.012273
[00:40:04.869] iteration 5720 : loss : 0.120492, loss_ce: 0.011152
[00:40:05.170] iteration 5721 : loss : 0.128948, loss_ce: 0.023137
[00:40:05.458] iteration 5722 : loss : 0.059143, loss_ce: 0.016647
[00:40:05.744] iteration 5723 : loss : 0.064270, loss_ce: 0.030381
[00:40:06.031] iteration 5724 : loss : 0.118531, loss_ce: 0.011115
[00:40:06.317] iteration 5725 : loss : 0.077918, loss_ce: 0.034404
[00:40:06.605] iteration 5726 : loss : 0.118473, loss_ce: 0.013157
[00:40:06.893] iteration 5727 : loss : 0.063427, loss_ce: 0.022830
[00:40:07.178] iteration 5728 : loss : 0.061167, loss_ce: 0.016885
[00:40:07.466] iteration 5729 : loss : 0.059443, loss_ce: 0.028215
[00:40:07.755] iteration 5730 : loss : 0.076810, loss_ce: 0.032428
[00:40:08.039] iteration 5731 : loss : 0.074732, loss_ce: 0.028910
[00:40:08.325] iteration 5732 : loss : 0.134695, loss_ce: 0.030593
[00:40:08.614] iteration 5733 : loss : 0.124246, loss_ce: 0.021519
[00:40:08.900] iteration 5734 : loss : 0.122023, loss_ce: 0.024408
[00:40:09.187] iteration 5735 : loss : 0.074801, loss_ce: 0.013581
[00:40:09.472] iteration 5736 : loss : 0.135409, loss_ce: 0.014216
[00:40:09.759] iteration 5737 : loss : 0.083450, loss_ce: 0.022283
[00:40:10.046] iteration 5738 : loss : 0.055676, loss_ce: 0.024449
[00:40:10.333] iteration 5739 : loss : 0.061065, loss_ce: 0.017986
[00:40:10.622] iteration 5740 : loss : 0.110195, loss_ce: 0.012814
[00:40:10.923] iteration 5741 : loss : 0.057596, loss_ce: 0.012957
[00:40:11.210] iteration 5742 : loss : 0.066358, loss_ce: 0.016232
[00:40:11.499] iteration 5743 : loss : 0.084300, loss_ce: 0.022376
[00:40:11.785] iteration 5744 : loss : 0.065059, loss_ce: 0.017822
[00:40:12.072] iteration 5745 : loss : 0.064708, loss_ce: 0.014415
[00:40:12.359] iteration 5746 : loss : 0.172926, loss_ce: 0.010976
[00:40:12.646] iteration 5747 : loss : 0.128749, loss_ce: 0.020026
[00:40:12.933] iteration 5748 : loss : 0.064856, loss_ce: 0.023202
[00:40:13.221] iteration 5749 : loss : 0.085186, loss_ce: 0.017344
[00:40:13.511] iteration 5750 : loss : 0.055333, loss_ce: 0.015830
[00:40:13.797] iteration 5751 : loss : 0.103548, loss_ce: 0.009809
[00:40:14.084] iteration 5752 : loss : 0.081948, loss_ce: 0.033027
[00:40:14.370] iteration 5753 : loss : 0.121664, loss_ce: 0.031116
[00:40:14.656] iteration 5754 : loss : 0.072021, loss_ce: 0.022269
[00:40:14.943] iteration 5755 : loss : 0.098886, loss_ce: 0.008378
[00:40:15.229] iteration 5756 : loss : 0.063758, loss_ce: 0.021192
[00:40:15.517] iteration 5757 : loss : 0.067816, loss_ce: 0.015109
[00:40:15.802] iteration 5758 : loss : 0.094527, loss_ce: 0.013201
[00:40:16.091] iteration 5759 : loss : 0.115904, loss_ce: 0.014905
[00:40:16.381] iteration 5760 : loss : 0.060484, loss_ce: 0.011932
[00:40:16.682] iteration 5761 : loss : 0.066707, loss_ce: 0.015360
[00:40:16.969] iteration 5762 : loss : 0.066557, loss_ce: 0.017350
[00:40:17.254] iteration 5763 : loss : 0.100550, loss_ce: 0.005447
[00:40:17.544] iteration 5764 : loss : 0.062842, loss_ce: 0.022607
[00:40:17.831] iteration 5765 : loss : 0.121227, loss_ce: 0.023258
[00:40:18.117] iteration 5766 : loss : 0.119028, loss_ce: 0.020196
[00:40:18.406] iteration 5767 : loss : 0.074305, loss_ce: 0.027574
[00:40:18.693] iteration 5768 : loss : 0.065048, loss_ce: 0.019530
[00:40:18.979] iteration 5769 : loss : 0.062028, loss_ce: 0.025964
[00:40:19.268] iteration 5770 : loss : 0.067418, loss_ce: 0.029925
[00:40:19.556] iteration 5771 : loss : 0.063376, loss_ce: 0.020557
[00:40:19.842] iteration 5772 : loss : 0.084969, loss_ce: 0.050794
[00:40:20.129] iteration 5773 : loss : 0.135768, loss_ce: 0.008718
[00:40:20.418] iteration 5774 : loss : 0.107049, loss_ce: 0.025519
[00:40:20.704] iteration 5775 : loss : 0.097778, loss_ce: 0.020138
[00:40:20.992] iteration 5776 : loss : 0.061598, loss_ce: 0.022514
[00:40:21.280] iteration 5777 : loss : 0.077182, loss_ce: 0.025396
[00:40:21.567] iteration 5778 : loss : 0.089459, loss_ce: 0.023286
[00:40:21.856] iteration 5779 : loss : 0.065870, loss_ce: 0.010918
[00:40:22.142] iteration 5780 : loss : 0.082898, loss_ce: 0.011823
[00:40:22.448] iteration 5781 : loss : 0.088589, loss_ce: 0.010853
[00:40:22.735] iteration 5782 : loss : 0.123683, loss_ce: 0.017460
[00:40:23.019] iteration 5783 : loss : 0.084092, loss_ce: 0.016807
[00:40:23.310] iteration 5784 : loss : 0.070896, loss_ce: 0.020738
[00:40:23.596] iteration 5785 : loss : 0.085556, loss_ce: 0.034575
[00:40:23.883] iteration 5786 : loss : 0.077053, loss_ce: 0.019042
[00:40:24.171] iteration 5787 : loss : 0.068241, loss_ce: 0.023000
[00:40:24.459] iteration 5788 : loss : 0.079760, loss_ce: 0.029440
[00:40:24.746] iteration 5789 : loss : 0.061861, loss_ce: 0.025152
[00:40:25.031] iteration 5790 : loss : 0.064815, loss_ce: 0.015442
[00:40:25.320] iteration 5791 : loss : 0.059968, loss_ce: 0.027569
[00:40:25.607] iteration 5792 : loss : 0.072849, loss_ce: 0.018556
[00:40:25.894] iteration 5793 : loss : 0.100835, loss_ce: 0.012793
[00:40:26.181] iteration 5794 : loss : 0.245938, loss_ce: 0.018689
[00:40:26.472] iteration 5795 : loss : 0.082566, loss_ce: 0.034816
[00:40:26.759] iteration 5796 : loss : 0.092797, loss_ce: 0.016038
[00:40:27.050] iteration 5797 : loss : 0.057917, loss_ce: 0.016988
[00:40:27.338] iteration 5798 : loss : 0.054920, loss_ce: 0.020367
[00:40:27.625] iteration 5799 : loss : 0.078932, loss_ce: 0.029942
[00:40:27.913] iteration 5800 : loss : 0.125625, loss_ce: 0.011907
[00:40:28.217] iteration 5801 : loss : 0.114672, loss_ce: 0.022071
[00:40:28.504] iteration 5802 : loss : 0.070319, loss_ce: 0.021953
[00:40:28.792] iteration 5803 : loss : 0.303341, loss_ce: 0.004799
[00:40:29.081] iteration 5804 : loss : 0.064980, loss_ce: 0.017882
[00:40:29.367] iteration 5805 : loss : 0.081906, loss_ce: 0.015409
[00:40:29.653] iteration 5806 : loss : 0.095692, loss_ce: 0.020691
[00:40:29.942] iteration 5807 : loss : 0.148019, loss_ce: 0.014346
[00:40:30.230] iteration 5808 : loss : 0.064984, loss_ce: 0.020463
[00:40:30.518] iteration 5809 : loss : 0.082491, loss_ce: 0.033070
[00:40:30.807] iteration 5810 : loss : 0.077851, loss_ce: 0.017887
[00:40:31.096] iteration 5811 : loss : 0.108437, loss_ce: 0.010304
[00:40:31.381] iteration 5812 : loss : 0.101294, loss_ce: 0.036165
[00:40:31.670] iteration 5813 : loss : 0.052523, loss_ce: 0.023333
[00:40:31.958] iteration 5814 : loss : 0.111644, loss_ce: 0.011933
[00:40:32.246] iteration 5815 : loss : 0.064324, loss_ce: 0.010608
[00:40:32.533] iteration 5816 : loss : 0.086918, loss_ce: 0.022682
[00:40:32.822] iteration 5817 : loss : 0.091939, loss_ce: 0.033369
[00:40:33.110] iteration 5818 : loss : 0.073047, loss_ce: 0.021001
[00:40:33.398] iteration 5819 : loss : 0.066971, loss_ce: 0.019670
[00:40:33.685] iteration 5820 : loss : 0.069963, loss_ce: 0.022769
[00:40:33.992] iteration 5821 : loss : 0.059419, loss_ce: 0.025586
[00:40:34.283] iteration 5822 : loss : 0.123291, loss_ce: 0.018741
[00:40:34.579] iteration 5823 : loss : 0.082022, loss_ce: 0.030968
[00:40:34.873] iteration 5824 : loss : 0.096531, loss_ce: 0.037620
[00:40:35.170] iteration 5825 : loss : 0.073728, loss_ce: 0.016278
[00:40:35.458] iteration 5826 : loss : 0.100521, loss_ce: 0.015841
[00:40:35.751] iteration 5827 : loss : 0.081625, loss_ce: 0.021593
[00:40:36.040] iteration 5828 : loss : 0.069937, loss_ce: 0.022185
[00:40:36.332] iteration 5829 : loss : 0.203483, loss_ce: 0.008433
[00:40:36.621] iteration 5830 : loss : 0.071222, loss_ce: 0.026306
[00:40:36.917] iteration 5831 : loss : 0.072575, loss_ce: 0.028604
[00:40:37.211] iteration 5832 : loss : 0.082570, loss_ce: 0.023594
[00:40:37.502] iteration 5833 : loss : 0.071517, loss_ce: 0.017731
[00:40:37.791] iteration 5834 : loss : 0.292140, loss_ce: 0.005158
[00:40:38.087] iteration 5835 : loss : 0.076037, loss_ce: 0.026185
[00:40:38.378] iteration 5836 : loss : 0.063721, loss_ce: 0.025355
[00:40:38.668] iteration 5837 : loss : 0.080091, loss_ce: 0.018339
[00:40:38.743] iteration 5838 : loss : 0.478749, loss_ce: 0.002418
[00:40:54.995] iteration 5839 : loss : 0.078308, loss_ce: 0.010232
[00:40:55.281] iteration 5840 : loss : 0.080893, loss_ce: 0.025292
[00:40:55.581] iteration 5841 : loss : 0.081578, loss_ce: 0.036389
[00:40:55.868] iteration 5842 : loss : 0.127982, loss_ce: 0.028286
[00:40:56.155] iteration 5843 : loss : 0.056698, loss_ce: 0.017246
[00:40:56.440] iteration 5844 : loss : 0.091366, loss_ce: 0.009734
[00:40:56.726] iteration 5845 : loss : 0.062129, loss_ce: 0.022363
[00:40:57.013] iteration 5846 : loss : 0.074216, loss_ce: 0.020452
[00:40:57.301] iteration 5847 : loss : 0.071162, loss_ce: 0.028816
[00:40:57.590] iteration 5848 : loss : 0.061072, loss_ce: 0.019654
[00:40:57.881] iteration 5849 : loss : 0.159500, loss_ce: 0.006929
[00:40:58.170] iteration 5850 : loss : 0.122927, loss_ce: 0.010586
[00:40:58.457] iteration 5851 : loss : 0.073735, loss_ce: 0.025595
[00:40:58.748] iteration 5852 : loss : 0.103221, loss_ce: 0.015229
[00:40:59.040] iteration 5853 : loss : 0.126031, loss_ce: 0.021475
[00:40:59.330] iteration 5854 : loss : 0.085108, loss_ce: 0.026945
[00:40:59.620] iteration 5855 : loss : 0.090410, loss_ce: 0.028274
[00:40:59.909] iteration 5856 : loss : 0.112883, loss_ce: 0.011893
[00:41:00.200] iteration 5857 : loss : 0.179467, loss_ce: 0.007800
[00:41:00.494] iteration 5858 : loss : 0.128307, loss_ce: 0.019340
[00:41:00.783] iteration 5859 : loss : 0.079159, loss_ce: 0.024613
[00:41:01.079] iteration 5860 : loss : 0.080790, loss_ce: 0.025242
[00:41:01.386] iteration 5861 : loss : 0.073893, loss_ce: 0.023794
[00:41:01.677] iteration 5862 : loss : 0.229712, loss_ce: 0.015198
[00:41:01.965] iteration 5863 : loss : 0.059323, loss_ce: 0.022868
[00:41:02.256] iteration 5864 : loss : 0.073611, loss_ce: 0.013096
[00:41:02.549] iteration 5865 : loss : 0.054414, loss_ce: 0.021428
[00:41:02.838] iteration 5866 : loss : 0.066996, loss_ce: 0.017942
[00:41:03.131] iteration 5867 : loss : 0.045037, loss_ce: 0.009614
[00:41:03.422] iteration 5868 : loss : 0.242885, loss_ce: 0.003164
[00:41:03.709] iteration 5869 : loss : 0.096192, loss_ce: 0.033118
[00:41:03.999] iteration 5870 : loss : 0.085013, loss_ce: 0.024396
[00:41:04.288] iteration 5871 : loss : 0.094010, loss_ce: 0.030996
[00:41:04.578] iteration 5872 : loss : 0.048210, loss_ce: 0.010843
[00:41:04.866] iteration 5873 : loss : 0.060413, loss_ce: 0.019054
[00:41:05.155] iteration 5874 : loss : 0.068267, loss_ce: 0.009443
[00:41:05.444] iteration 5875 : loss : 0.095270, loss_ce: 0.024176
[00:41:05.734] iteration 5876 : loss : 0.064284, loss_ce: 0.021500
[00:41:06.024] iteration 5877 : loss : 0.054556, loss_ce: 0.017842
[00:41:06.316] iteration 5878 : loss : 0.078880, loss_ce: 0.024345
[00:41:06.606] iteration 5879 : loss : 0.072870, loss_ce: 0.033388
[00:41:06.897] iteration 5880 : loss : 0.066721, loss_ce: 0.029501
[00:41:07.206] iteration 5881 : loss : 0.121066, loss_ce: 0.012955
[00:41:07.495] iteration 5882 : loss : 0.086406, loss_ce: 0.013126
[00:41:07.784] iteration 5883 : loss : 0.099434, loss_ce: 0.020519
[00:41:08.075] iteration 5884 : loss : 0.079835, loss_ce: 0.022318
[00:41:08.368] iteration 5885 : loss : 0.074897, loss_ce: 0.013071
[00:41:08.660] iteration 5886 : loss : 0.065945, loss_ce: 0.022495
[00:41:08.953] iteration 5887 : loss : 0.090551, loss_ce: 0.022783
[00:41:09.241] iteration 5888 : loss : 0.137051, loss_ce: 0.017562
[00:41:09.531] iteration 5889 : loss : 0.124382, loss_ce: 0.016687
[00:41:09.821] iteration 5890 : loss : 0.076788, loss_ce: 0.013783
[00:41:10.110] iteration 5891 : loss : 0.066070, loss_ce: 0.018993
[00:41:10.401] iteration 5892 : loss : 0.075584, loss_ce: 0.025495
[00:41:10.690] iteration 5893 : loss : 0.149681, loss_ce: 0.022555
[00:41:10.980] iteration 5894 : loss : 0.059276, loss_ce: 0.014001
[00:41:11.268] iteration 5895 : loss : 0.128974, loss_ce: 0.012444
[00:41:11.561] iteration 5896 : loss : 0.070497, loss_ce: 0.017212
[00:41:11.854] iteration 5897 : loss : 0.067881, loss_ce: 0.036387
[00:41:12.144] iteration 5898 : loss : 0.114365, loss_ce: 0.010781
[00:41:12.435] iteration 5899 : loss : 0.071549, loss_ce: 0.031148
[00:41:12.728] iteration 5900 : loss : 0.069804, loss_ce: 0.017147
[00:41:13.031] iteration 5901 : loss : 0.077040, loss_ce: 0.018019
[00:41:13.323] iteration 5902 : loss : 0.054258, loss_ce: 0.015285
[00:41:13.612] iteration 5903 : loss : 0.077505, loss_ce: 0.028850
[00:41:13.906] iteration 5904 : loss : 0.066983, loss_ce: 0.010219
[00:41:14.197] iteration 5905 : loss : 0.072222, loss_ce: 0.025580
[00:41:14.488] iteration 5906 : loss : 0.120050, loss_ce: 0.025309
[00:41:14.777] iteration 5907 : loss : 0.107746, loss_ce: 0.024674
[00:41:15.066] iteration 5908 : loss : 0.067317, loss_ce: 0.029409
[00:41:15.358] iteration 5909 : loss : 0.082634, loss_ce: 0.031633
[00:41:15.648] iteration 5910 : loss : 0.069504, loss_ce: 0.028651
[00:41:15.939] iteration 5911 : loss : 0.066341, loss_ce: 0.015267
[00:41:16.228] iteration 5912 : loss : 0.100368, loss_ce: 0.039651
[00:41:16.519] iteration 5913 : loss : 0.097526, loss_ce: 0.025454
[00:41:16.809] iteration 5914 : loss : 0.137567, loss_ce: 0.033794
[00:41:17.101] iteration 5915 : loss : 0.089013, loss_ce: 0.016758
[00:41:17.391] iteration 5916 : loss : 0.064841, loss_ce: 0.022275
[00:41:17.679] iteration 5917 : loss : 0.062922, loss_ce: 0.025582
[00:41:17.970] iteration 5918 : loss : 0.146879, loss_ce: 0.033742
[00:41:18.260] iteration 5919 : loss : 0.083925, loss_ce: 0.029602
[00:41:18.548] iteration 5920 : loss : 0.091278, loss_ce: 0.028693
[00:41:18.850] iteration 5921 : loss : 0.073502, loss_ce: 0.019639
[00:41:19.141] iteration 5922 : loss : 0.062576, loss_ce: 0.021002
[00:41:19.432] iteration 5923 : loss : 0.081063, loss_ce: 0.021750
[00:41:19.723] iteration 5924 : loss : 0.126783, loss_ce: 0.022712
[00:41:20.012] iteration 5925 : loss : 0.064429, loss_ce: 0.021422
[00:41:20.305] iteration 5926 : loss : 0.057939, loss_ce: 0.012242
[00:41:20.594] iteration 5927 : loss : 0.089648, loss_ce: 0.024480
[00:41:20.883] iteration 5928 : loss : 0.084499, loss_ce: 0.015189
[00:41:21.170] iteration 5929 : loss : 0.180468, loss_ce: 0.015314
[00:41:21.457] iteration 5930 : loss : 0.074634, loss_ce: 0.016072
[00:41:21.748] iteration 5931 : loss : 0.062261, loss_ce: 0.012211
[00:41:22.038] iteration 5932 : loss : 0.167313, loss_ce: 0.011768
[00:41:22.328] iteration 5933 : loss : 0.167218, loss_ce: 0.032323
[00:41:22.616] iteration 5934 : loss : 0.058278, loss_ce: 0.018333
[00:41:22.904] iteration 5935 : loss : 0.110006, loss_ce: 0.026062
[00:41:23.189] iteration 5936 : loss : 0.102688, loss_ce: 0.032847
[00:41:23.476] iteration 5937 : loss : 0.059941, loss_ce: 0.024790
[00:41:23.771] iteration 5938 : loss : 0.070721, loss_ce: 0.031710
[00:41:24.057] iteration 5939 : loss : 0.061208, loss_ce: 0.011788
[00:41:24.347] iteration 5940 : loss : 0.110367, loss_ce: 0.009501
[00:41:24.654] iteration 5941 : loss : 0.113497, loss_ce: 0.017318
[00:41:24.942] iteration 5942 : loss : 0.090423, loss_ce: 0.013717
[00:41:25.232] iteration 5943 : loss : 0.071100, loss_ce: 0.023783
[00:41:25.525] iteration 5944 : loss : 0.084165, loss_ce: 0.019231
[00:41:25.814] iteration 5945 : loss : 0.060913, loss_ce: 0.014871
[00:41:26.101] iteration 5946 : loss : 0.057750, loss_ce: 0.011105
[00:41:26.389] iteration 5947 : loss : 0.083160, loss_ce: 0.027834
[00:41:26.677] iteration 5948 : loss : 0.078445, loss_ce: 0.013965
[00:41:26.965] iteration 5949 : loss : 0.078591, loss_ce: 0.028087
[00:41:27.251] iteration 5950 : loss : 0.065301, loss_ce: 0.015712
[00:41:27.540] iteration 5951 : loss : 0.063582, loss_ce: 0.015568
[00:41:27.829] iteration 5952 : loss : 0.085117, loss_ce: 0.018582
[00:41:28.115] iteration 5953 : loss : 0.136498, loss_ce: 0.017802
[00:41:28.406] iteration 5954 : loss : 0.113396, loss_ce: 0.007807
[00:41:28.695] iteration 5955 : loss : 0.110554, loss_ce: 0.013472
[00:41:28.987] iteration 5956 : loss : 0.059715, loss_ce: 0.014611
[00:41:29.277] iteration 5957 : loss : 0.062503, loss_ce: 0.021430
[00:41:29.564] iteration 5958 : loss : 0.076031, loss_ce: 0.030124
[00:41:29.851] iteration 5959 : loss : 0.121261, loss_ce: 0.008578
[00:41:30.139] iteration 5960 : loss : 0.060273, loss_ce: 0.025543
[00:41:30.449] iteration 5961 : loss : 0.061330, loss_ce: 0.023813
[00:41:30.741] iteration 5962 : loss : 0.060839, loss_ce: 0.017550
[00:41:31.034] iteration 5963 : loss : 0.147687, loss_ce: 0.017278
[00:41:31.329] iteration 5964 : loss : 0.050334, loss_ce: 0.014804
[00:41:31.619] iteration 5965 : loss : 0.067182, loss_ce: 0.017778
[00:41:31.911] iteration 5966 : loss : 0.097057, loss_ce: 0.021869
[00:41:32.200] iteration 5967 : loss : 0.192922, loss_ce: 0.008726
[00:41:32.493] iteration 5968 : loss : 0.079331, loss_ce: 0.033068
[00:41:32.781] iteration 5969 : loss : 0.063362, loss_ce: 0.023196
[00:41:33.072] iteration 5970 : loss : 0.139508, loss_ce: 0.021119
[00:41:33.366] iteration 5971 : loss : 0.147089, loss_ce: 0.010269
[00:41:33.659] iteration 5972 : loss : 0.060803, loss_ce: 0.021794
[00:41:33.951] iteration 5973 : loss : 0.078860, loss_ce: 0.042174
[00:41:34.243] iteration 5974 : loss : 0.072811, loss_ce: 0.017768
[00:41:34.532] iteration 5975 : loss : 0.075059, loss_ce: 0.034175
[00:41:34.831] iteration 5976 : loss : 0.084524, loss_ce: 0.027658
[00:41:34.908] iteration 5977 : loss : 0.179133, loss_ce: 0.009048
[00:41:51.839] iteration 5978 : loss : 0.116673, loss_ce: 0.014468
[00:41:52.123] iteration 5979 : loss : 0.056986, loss_ce: 0.014453
[00:41:52.408] iteration 5980 : loss : 0.069712, loss_ce: 0.026549
[00:41:52.710] iteration 5981 : loss : 0.102026, loss_ce: 0.031857
[00:41:53.003] iteration 5982 : loss : 0.144984, loss_ce: 0.010539
[00:41:53.291] iteration 5983 : loss : 0.061226, loss_ce: 0.016348
[00:41:53.581] iteration 5984 : loss : 0.126989, loss_ce: 0.020030
[00:41:53.869] iteration 5985 : loss : 0.118177, loss_ce: 0.021070
[00:41:54.157] iteration 5986 : loss : 0.117633, loss_ce: 0.013345
[00:41:54.443] iteration 5987 : loss : 0.061575, loss_ce: 0.028677
[00:41:54.731] iteration 5988 : loss : 0.053389, loss_ce: 0.018106
[00:41:55.018] iteration 5989 : loss : 0.068128, loss_ce: 0.020886
[00:41:55.305] iteration 5990 : loss : 0.117242, loss_ce: 0.015512
[00:41:55.595] iteration 5991 : loss : 0.084562, loss_ce: 0.021313
[00:41:55.881] iteration 5992 : loss : 0.048095, loss_ce: 0.012245
[00:41:56.169] iteration 5993 : loss : 0.160849, loss_ce: 0.011689
[00:41:56.460] iteration 5994 : loss : 0.082141, loss_ce: 0.017141
[00:41:56.747] iteration 5995 : loss : 0.087854, loss_ce: 0.020768
[00:41:57.034] iteration 5996 : loss : 0.083832, loss_ce: 0.026396
[00:41:57.325] iteration 5997 : loss : 0.113152, loss_ce: 0.016115
[00:41:57.610] iteration 5998 : loss : 0.068042, loss_ce: 0.014729
[00:41:57.896] iteration 5999 : loss : 0.059262, loss_ce: 0.013944
[00:41:58.184] iteration 6000 : loss : 0.117452, loss_ce: 0.018430
[00:41:58.488] iteration 6001 : loss : 0.077756, loss_ce: 0.028649
[00:41:58.778] iteration 6002 : loss : 0.064090, loss_ce: 0.020917
[00:41:59.067] iteration 6003 : loss : 0.129795, loss_ce: 0.014441
[00:41:59.356] iteration 6004 : loss : 0.068890, loss_ce: 0.025874
[00:41:59.643] iteration 6005 : loss : 0.119745, loss_ce: 0.013946
[00:41:59.933] iteration 6006 : loss : 0.122400, loss_ce: 0.021588
[00:42:00.220] iteration 6007 : loss : 0.068385, loss_ce: 0.018578
[00:42:00.510] iteration 6008 : loss : 0.057777, loss_ce: 0.024427
[00:42:00.801] iteration 6009 : loss : 0.248275, loss_ce: 0.004818
[00:42:01.090] iteration 6010 : loss : 0.079103, loss_ce: 0.022454
[00:42:01.377] iteration 6011 : loss : 0.073766, loss_ce: 0.033761
[00:42:01.663] iteration 6012 : loss : 0.056060, loss_ce: 0.020215
[00:42:01.951] iteration 6013 : loss : 0.091409, loss_ce: 0.015829
[00:42:02.242] iteration 6014 : loss : 0.072434, loss_ce: 0.028258
[00:42:02.530] iteration 6015 : loss : 0.063639, loss_ce: 0.021893
[00:42:02.816] iteration 6016 : loss : 0.125275, loss_ce: 0.015765
[00:42:03.103] iteration 6017 : loss : 0.057711, loss_ce: 0.024970
[00:42:03.394] iteration 6018 : loss : 0.072489, loss_ce: 0.015264
[00:42:03.679] iteration 6019 : loss : 0.069788, loss_ce: 0.022554
[00:42:03.968] iteration 6020 : loss : 0.077508, loss_ce: 0.030115
[00:42:04.269] iteration 6021 : loss : 0.120325, loss_ce: 0.017920
[00:42:04.556] iteration 6022 : loss : 0.083095, loss_ce: 0.024071
[00:42:04.845] iteration 6023 : loss : 0.063052, loss_ce: 0.021199
[00:42:05.131] iteration 6024 : loss : 0.054659, loss_ce: 0.017727
[00:42:05.422] iteration 6025 : loss : 0.100704, loss_ce: 0.031283
[00:42:05.709] iteration 6026 : loss : 0.086621, loss_ce: 0.027300
[00:42:05.999] iteration 6027 : loss : 0.162461, loss_ce: 0.026518
[00:42:06.288] iteration 6028 : loss : 0.063123, loss_ce: 0.012194
[00:42:06.573] iteration 6029 : loss : 0.088620, loss_ce: 0.027204
[00:42:06.862] iteration 6030 : loss : 0.121710, loss_ce: 0.013081
[00:42:07.150] iteration 6031 : loss : 0.064295, loss_ce: 0.016161
[00:42:07.437] iteration 6032 : loss : 0.129731, loss_ce: 0.009162
[00:42:07.721] iteration 6033 : loss : 0.071972, loss_ce: 0.025629
[00:42:08.009] iteration 6034 : loss : 0.238119, loss_ce: 0.004884
[00:42:08.296] iteration 6035 : loss : 0.092433, loss_ce: 0.020214
[00:42:08.583] iteration 6036 : loss : 0.091735, loss_ce: 0.035606
[00:42:08.872] iteration 6037 : loss : 0.133168, loss_ce: 0.022392
[00:42:09.160] iteration 6038 : loss : 0.104692, loss_ce: 0.028366
[00:42:09.448] iteration 6039 : loss : 0.133169, loss_ce: 0.011082
[00:42:09.738] iteration 6040 : loss : 0.068887, loss_ce: 0.020340
[00:42:10.042] iteration 6041 : loss : 0.064934, loss_ce: 0.023939
[00:42:10.329] iteration 6042 : loss : 0.067759, loss_ce: 0.025509
[00:42:10.621] iteration 6043 : loss : 0.064128, loss_ce: 0.027069
[00:42:10.907] iteration 6044 : loss : 0.066489, loss_ce: 0.019822
[00:42:11.197] iteration 6045 : loss : 0.139645, loss_ce: 0.015437
[00:42:11.484] iteration 6046 : loss : 0.111134, loss_ce: 0.018336
[00:42:11.772] iteration 6047 : loss : 0.344815, loss_ce: 0.001930
[00:42:12.060] iteration 6048 : loss : 0.109340, loss_ce: 0.011809
[00:42:12.348] iteration 6049 : loss : 0.069124, loss_ce: 0.018157
[00:42:12.636] iteration 6050 : loss : 0.068542, loss_ce: 0.021416
[00:42:12.923] iteration 6051 : loss : 0.080663, loss_ce: 0.024893
[00:42:13.209] iteration 6052 : loss : 0.072902, loss_ce: 0.022575
[00:42:13.495] iteration 6053 : loss : 0.069979, loss_ce: 0.027437
[00:42:13.784] iteration 6054 : loss : 0.086349, loss_ce: 0.027334
[00:42:14.073] iteration 6055 : loss : 0.164804, loss_ce: 0.017235
[00:42:14.361] iteration 6056 : loss : 0.077734, loss_ce: 0.018218
[00:42:14.650] iteration 6057 : loss : 0.139635, loss_ce: 0.007606
[00:42:14.942] iteration 6058 : loss : 0.123376, loss_ce: 0.017630
[00:42:15.230] iteration 6059 : loss : 0.092935, loss_ce: 0.023112
[00:42:15.521] iteration 6060 : loss : 0.072843, loss_ce: 0.020990
[00:42:15.822] iteration 6061 : loss : 0.070267, loss_ce: 0.021776
[00:42:16.111] iteration 6062 : loss : 0.131985, loss_ce: 0.019389
[00:42:16.400] iteration 6063 : loss : 0.073283, loss_ce: 0.014438
[00:42:16.690] iteration 6064 : loss : 0.084360, loss_ce: 0.041445
[00:42:16.978] iteration 6065 : loss : 0.071549, loss_ce: 0.029349
[00:42:17.265] iteration 6066 : loss : 0.066553, loss_ce: 0.023382
[00:42:17.552] iteration 6067 : loss : 0.138911, loss_ce: 0.025760
[00:42:17.838] iteration 6068 : loss : 0.080041, loss_ce: 0.016534
[00:42:18.124] iteration 6069 : loss : 0.142883, loss_ce: 0.013762
[00:42:18.412] iteration 6070 : loss : 0.080608, loss_ce: 0.021313
[00:42:18.699] iteration 6071 : loss : 0.065595, loss_ce: 0.012019
[00:42:18.985] iteration 6072 : loss : 0.057487, loss_ce: 0.012119
[00:42:19.274] iteration 6073 : loss : 0.095091, loss_ce: 0.014818
[00:42:19.562] iteration 6074 : loss : 0.057491, loss_ce: 0.018504
[00:42:19.849] iteration 6075 : loss : 0.067723, loss_ce: 0.021575
[00:42:20.139] iteration 6076 : loss : 0.085813, loss_ce: 0.024273
[00:42:20.428] iteration 6077 : loss : 0.077902, loss_ce: 0.017504
[00:42:20.721] iteration 6078 : loss : 0.063234, loss_ce: 0.018668
[00:42:21.007] iteration 6079 : loss : 0.086793, loss_ce: 0.031104
[00:42:21.297] iteration 6080 : loss : 0.180800, loss_ce: 0.023014
[00:42:21.602] iteration 6081 : loss : 0.056852, loss_ce: 0.020661
[00:42:21.892] iteration 6082 : loss : 0.064142, loss_ce: 0.022800
[00:42:22.180] iteration 6083 : loss : 0.072594, loss_ce: 0.019587
[00:42:22.468] iteration 6084 : loss : 0.077151, loss_ce: 0.023740
[00:42:22.755] iteration 6085 : loss : 0.055745, loss_ce: 0.013171
[00:42:23.047] iteration 6086 : loss : 0.122103, loss_ce: 0.012104
[00:42:23.337] iteration 6087 : loss : 0.066511, loss_ce: 0.018424
[00:42:23.625] iteration 6088 : loss : 0.053208, loss_ce: 0.020225
[00:42:23.911] iteration 6089 : loss : 0.068087, loss_ce: 0.027171
[00:42:24.201] iteration 6090 : loss : 0.058851, loss_ce: 0.013571
[00:42:24.489] iteration 6091 : loss : 0.115890, loss_ce: 0.007007
[00:42:24.777] iteration 6092 : loss : 0.063922, loss_ce: 0.015327
[00:42:25.067] iteration 6093 : loss : 0.078316, loss_ce: 0.017973
[00:42:25.358] iteration 6094 : loss : 0.125297, loss_ce: 0.010471
[00:42:25.649] iteration 6095 : loss : 0.126166, loss_ce: 0.025169
[00:42:25.939] iteration 6096 : loss : 0.076191, loss_ce: 0.020606
[00:42:26.229] iteration 6097 : loss : 0.134760, loss_ce: 0.021902
[00:42:26.520] iteration 6098 : loss : 0.087165, loss_ce: 0.032864
[00:42:26.808] iteration 6099 : loss : 0.068523, loss_ce: 0.026653
[00:42:27.099] iteration 6100 : loss : 0.071042, loss_ce: 0.014476
[00:42:27.399] iteration 6101 : loss : 0.085333, loss_ce: 0.030172
[00:42:27.692] iteration 6102 : loss : 0.070506, loss_ce: 0.016508
[00:42:27.983] iteration 6103 : loss : 0.062681, loss_ce: 0.025985
[00:42:28.275] iteration 6104 : loss : 0.169454, loss_ce: 0.009475
[00:42:28.563] iteration 6105 : loss : 0.063769, loss_ce: 0.011883
[00:42:28.850] iteration 6106 : loss : 0.083475, loss_ce: 0.025575
[00:42:29.142] iteration 6107 : loss : 0.195744, loss_ce: 0.005673
[00:42:29.436] iteration 6108 : loss : 0.058044, loss_ce: 0.013777
[00:42:29.722] iteration 6109 : loss : 0.053482, loss_ce: 0.011235
[00:42:30.016] iteration 6110 : loss : 0.109108, loss_ce: 0.007571
[00:42:30.311] iteration 6111 : loss : 0.071115, loss_ce: 0.022514
[00:42:30.609] iteration 6112 : loss : 0.065737, loss_ce: 0.028463
[00:42:30.900] iteration 6113 : loss : 0.068988, loss_ce: 0.027943
[00:42:31.191] iteration 6114 : loss : 0.062544, loss_ce: 0.020171
[00:42:31.483] iteration 6115 : loss : 0.083281, loss_ce: 0.026821
[00:42:31.563] iteration 6116 : loss : 0.477048, loss_ce: 0.004702
[00:42:48.045] iteration 6117 : loss : 0.054239, loss_ce: 0.023152
[00:42:48.329] iteration 6118 : loss : 0.138162, loss_ce: 0.017845
[00:42:48.616] iteration 6119 : loss : 0.084966, loss_ce: 0.016551
[00:42:48.905] iteration 6120 : loss : 0.121137, loss_ce: 0.018544
[00:42:49.208] iteration 6121 : loss : 0.070550, loss_ce: 0.031166
[00:42:49.493] iteration 6122 : loss : 0.102264, loss_ce: 0.025047
[00:42:49.779] iteration 6123 : loss : 0.084322, loss_ce: 0.018061
[00:42:50.066] iteration 6124 : loss : 0.064087, loss_ce: 0.015975
[00:42:50.352] iteration 6125 : loss : 0.121669, loss_ce: 0.031110
[00:42:50.643] iteration 6126 : loss : 0.051072, loss_ce: 0.019847
[00:42:50.930] iteration 6127 : loss : 0.065109, loss_ce: 0.029173
[00:42:51.219] iteration 6128 : loss : 0.077369, loss_ce: 0.017912
[00:42:51.509] iteration 6129 : loss : 0.056369, loss_ce: 0.009138
[00:42:51.804] iteration 6130 : loss : 0.088922, loss_ce: 0.011979
[00:42:52.093] iteration 6131 : loss : 0.064756, loss_ce: 0.017705
[00:42:52.384] iteration 6132 : loss : 0.084584, loss_ce: 0.026205
[00:42:52.672] iteration 6133 : loss : 0.112121, loss_ce: 0.012218
[00:42:52.962] iteration 6134 : loss : 0.100367, loss_ce: 0.020180
[00:42:53.251] iteration 6135 : loss : 0.060073, loss_ce: 0.020717
[00:42:53.540] iteration 6136 : loss : 0.083253, loss_ce: 0.021706
[00:42:53.831] iteration 6137 : loss : 0.051609, loss_ce: 0.017134
[00:42:54.120] iteration 6138 : loss : 0.058523, loss_ce: 0.021903
[00:42:54.408] iteration 6139 : loss : 0.061639, loss_ce: 0.025836
[00:42:54.701] iteration 6140 : loss : 0.092595, loss_ce: 0.021430
[00:42:55.004] iteration 6141 : loss : 0.074457, loss_ce: 0.029994
[00:42:55.294] iteration 6142 : loss : 0.076107, loss_ce: 0.017226
[00:42:55.583] iteration 6143 : loss : 0.119405, loss_ce: 0.019828
[00:42:55.873] iteration 6144 : loss : 0.081002, loss_ce: 0.015054
[00:42:56.160] iteration 6145 : loss : 0.085609, loss_ce: 0.016059
[00:42:56.449] iteration 6146 : loss : 0.066065, loss_ce: 0.016328
[00:42:56.735] iteration 6147 : loss : 0.056125, loss_ce: 0.012588
[00:42:57.023] iteration 6148 : loss : 0.063699, loss_ce: 0.029309
[00:42:57.312] iteration 6149 : loss : 0.082910, loss_ce: 0.023395
[00:42:57.601] iteration 6150 : loss : 0.071784, loss_ce: 0.015520
[00:42:57.887] iteration 6151 : loss : 0.191909, loss_ce: 0.038798
[00:42:58.176] iteration 6152 : loss : 0.053973, loss_ce: 0.019898
[00:42:58.463] iteration 6153 : loss : 0.070493, loss_ce: 0.031483
[00:42:58.752] iteration 6154 : loss : 0.077376, loss_ce: 0.022238
[00:42:59.043] iteration 6155 : loss : 0.060049, loss_ce: 0.019297
[00:42:59.331] iteration 6156 : loss : 0.071078, loss_ce: 0.022448
[00:42:59.618] iteration 6157 : loss : 0.057140, loss_ce: 0.019426
[00:42:59.908] iteration 6158 : loss : 0.107532, loss_ce: 0.012864
[00:43:00.200] iteration 6159 : loss : 0.064828, loss_ce: 0.029614
[00:43:00.493] iteration 6160 : loss : 0.114993, loss_ce: 0.018469
[00:43:00.796] iteration 6161 : loss : 0.166004, loss_ce: 0.007135
[00:43:01.087] iteration 6162 : loss : 0.070732, loss_ce: 0.017075
[00:43:01.375] iteration 6163 : loss : 0.066102, loss_ce: 0.017166
[00:43:01.666] iteration 6164 : loss : 0.062647, loss_ce: 0.017986
[00:43:01.955] iteration 6165 : loss : 0.053183, loss_ce: 0.019114
[00:43:02.245] iteration 6166 : loss : 0.126984, loss_ce: 0.014274
[00:43:02.530] iteration 6167 : loss : 0.064297, loss_ce: 0.018178
[00:43:02.821] iteration 6168 : loss : 0.049065, loss_ce: 0.019854
[00:43:03.110] iteration 6169 : loss : 0.128923, loss_ce: 0.010908
[00:43:03.402] iteration 6170 : loss : 0.125023, loss_ce: 0.019926
[00:43:03.689] iteration 6171 : loss : 0.096045, loss_ce: 0.012605
[00:43:03.980] iteration 6172 : loss : 0.120114, loss_ce: 0.017328
[00:43:04.266] iteration 6173 : loss : 0.138830, loss_ce: 0.042207
[00:43:04.554] iteration 6174 : loss : 0.094993, loss_ce: 0.018435
[00:43:04.843] iteration 6175 : loss : 0.063968, loss_ce: 0.020896
[00:43:05.135] iteration 6176 : loss : 0.107388, loss_ce: 0.008279
[00:43:05.424] iteration 6177 : loss : 0.126224, loss_ce: 0.022925
[00:43:05.715] iteration 6178 : loss : 0.064506, loss_ce: 0.021545
[00:43:06.001] iteration 6179 : loss : 0.075473, loss_ce: 0.027528
[00:43:06.291] iteration 6180 : loss : 0.073513, loss_ce: 0.023726
[00:43:06.592] iteration 6181 : loss : 0.076318, loss_ce: 0.013859
[00:43:06.884] iteration 6182 : loss : 0.067993, loss_ce: 0.029192
[00:43:07.173] iteration 6183 : loss : 0.071777, loss_ce: 0.011395
[00:43:07.461] iteration 6184 : loss : 0.071455, loss_ce: 0.026078
[00:43:07.750] iteration 6185 : loss : 0.064673, loss_ce: 0.026402
[00:43:08.040] iteration 6186 : loss : 0.114727, loss_ce: 0.014818
[00:43:08.332] iteration 6187 : loss : 0.090609, loss_ce: 0.021594
[00:43:08.619] iteration 6188 : loss : 0.068809, loss_ce: 0.015524
[00:43:08.910] iteration 6189 : loss : 0.084838, loss_ce: 0.030503
[00:43:09.201] iteration 6190 : loss : 0.122188, loss_ce: 0.016294
[00:43:09.487] iteration 6191 : loss : 0.066653, loss_ce: 0.020068
[00:43:09.778] iteration 6192 : loss : 0.064252, loss_ce: 0.016795
[00:43:10.063] iteration 6193 : loss : 0.075895, loss_ce: 0.027219
[00:43:10.353] iteration 6194 : loss : 0.104211, loss_ce: 0.012881
[00:43:10.646] iteration 6195 : loss : 0.051145, loss_ce: 0.016016
[00:43:10.939] iteration 6196 : loss : 0.131227, loss_ce: 0.026343
[00:43:11.227] iteration 6197 : loss : 0.072425, loss_ce: 0.019827
[00:43:11.517] iteration 6198 : loss : 0.096092, loss_ce: 0.022695
[00:43:11.806] iteration 6199 : loss : 0.064423, loss_ce: 0.012144
[00:43:12.097] iteration 6200 : loss : 0.078158, loss_ce: 0.006940
[00:43:12.401] iteration 6201 : loss : 0.115934, loss_ce: 0.021963
[00:43:12.690] iteration 6202 : loss : 0.133885, loss_ce: 0.014840
[00:43:12.978] iteration 6203 : loss : 0.060700, loss_ce: 0.028406
[00:43:13.269] iteration 6204 : loss : 0.095298, loss_ce: 0.014969
[00:43:13.561] iteration 6205 : loss : 0.067652, loss_ce: 0.011959
[00:43:13.850] iteration 6206 : loss : 0.067246, loss_ce: 0.018290
[00:43:14.142] iteration 6207 : loss : 0.118171, loss_ce: 0.026030
[00:43:14.429] iteration 6208 : loss : 0.079496, loss_ce: 0.026127
[00:43:14.716] iteration 6209 : loss : 0.171910, loss_ce: 0.007613
[00:43:15.007] iteration 6210 : loss : 0.091368, loss_ce: 0.031158
[00:43:15.301] iteration 6211 : loss : 0.081894, loss_ce: 0.014796
[00:43:15.593] iteration 6212 : loss : 0.126028, loss_ce: 0.018749
[00:43:15.883] iteration 6213 : loss : 0.171735, loss_ce: 0.011196
[00:43:16.172] iteration 6214 : loss : 0.055538, loss_ce: 0.025107
[00:43:16.459] iteration 6215 : loss : 0.097074, loss_ce: 0.015655
[00:43:16.749] iteration 6216 : loss : 0.062743, loss_ce: 0.023937
[00:43:17.041] iteration 6217 : loss : 0.059092, loss_ce: 0.021706
[00:43:17.332] iteration 6218 : loss : 0.072787, loss_ce: 0.024619
[00:43:17.622] iteration 6219 : loss : 0.238121, loss_ce: 0.017532
[00:43:17.913] iteration 6220 : loss : 0.297388, loss_ce: 0.005221
[00:43:18.216] iteration 6221 : loss : 0.119035, loss_ce: 0.011833
[00:43:18.506] iteration 6222 : loss : 0.065249, loss_ce: 0.017307
[00:43:18.796] iteration 6223 : loss : 0.084884, loss_ce: 0.023191
[00:43:19.086] iteration 6224 : loss : 0.071153, loss_ce: 0.021104
[00:43:19.376] iteration 6225 : loss : 0.129699, loss_ce: 0.012521
[00:43:19.665] iteration 6226 : loss : 0.057624, loss_ce: 0.021634
[00:43:19.955] iteration 6227 : loss : 0.130056, loss_ce: 0.018284
[00:43:20.246] iteration 6228 : loss : 0.118491, loss_ce: 0.022094
[00:43:20.535] iteration 6229 : loss : 0.071782, loss_ce: 0.025229
[00:43:20.824] iteration 6230 : loss : 0.066028, loss_ce: 0.021315
[00:43:21.111] iteration 6231 : loss : 0.071144, loss_ce: 0.023472
[00:43:21.399] iteration 6232 : loss : 0.069505, loss_ce: 0.020330
[00:43:21.685] iteration 6233 : loss : 0.067712, loss_ce: 0.024913
[00:43:21.971] iteration 6234 : loss : 0.100664, loss_ce: 0.017030
[00:43:22.259] iteration 6235 : loss : 0.062421, loss_ce: 0.024908
[00:43:22.545] iteration 6236 : loss : 0.077534, loss_ce: 0.025971
[00:43:22.832] iteration 6237 : loss : 0.063424, loss_ce: 0.017857
[00:43:23.122] iteration 6238 : loss : 0.063264, loss_ce: 0.017130
[00:43:23.415] iteration 6239 : loss : 0.081500, loss_ce: 0.015531
[00:43:23.709] iteration 6240 : loss : 0.162411, loss_ce: 0.011483
[00:43:24.027] iteration 6241 : loss : 0.056715, loss_ce: 0.017616
[00:43:24.317] iteration 6242 : loss : 0.071893, loss_ce: 0.031820
[00:43:24.607] iteration 6243 : loss : 0.069797, loss_ce: 0.029380
[00:43:24.897] iteration 6244 : loss : 0.106933, loss_ce: 0.019932
[00:43:25.191] iteration 6245 : loss : 0.065199, loss_ce: 0.020223
[00:43:25.483] iteration 6246 : loss : 0.076606, loss_ce: 0.019152
[00:43:25.772] iteration 6247 : loss : 0.128738, loss_ce: 0.019664
[00:43:26.068] iteration 6248 : loss : 0.078617, loss_ce: 0.025614
[00:43:26.362] iteration 6249 : loss : 0.061808, loss_ce: 0.021664
[00:43:26.652] iteration 6250 : loss : 0.069696, loss_ce: 0.023633
[00:43:26.947] iteration 6251 : loss : 0.053828, loss_ce: 0.013008
[00:43:27.239] iteration 6252 : loss : 0.137685, loss_ce: 0.023413
[00:43:27.530] iteration 6253 : loss : 0.069740, loss_ce: 0.020381
[00:43:27.819] iteration 6254 : loss : 0.059116, loss_ce: 0.013580
[00:43:27.897] iteration 6255 : loss : 0.064524, loss_ce: 0.036323
[00:43:44.195] iteration 6256 : loss : 0.063985, loss_ce: 0.023752
[00:43:44.484] iteration 6257 : loss : 0.080597, loss_ce: 0.013286
[00:43:44.769] iteration 6258 : loss : 0.068403, loss_ce: 0.022584
[00:43:45.058] iteration 6259 : loss : 0.088072, loss_ce: 0.025657
[00:43:45.345] iteration 6260 : loss : 0.094926, loss_ce: 0.033879
[00:43:45.647] iteration 6261 : loss : 0.049752, loss_ce: 0.019846
[00:43:45.933] iteration 6262 : loss : 0.123682, loss_ce: 0.013720
[00:43:46.223] iteration 6263 : loss : 0.065904, loss_ce: 0.031160
[00:43:46.510] iteration 6264 : loss : 0.053971, loss_ce: 0.014463
[00:43:46.802] iteration 6265 : loss : 0.073324, loss_ce: 0.018405
[00:43:47.088] iteration 6266 : loss : 0.062160, loss_ce: 0.021565
[00:43:47.375] iteration 6267 : loss : 0.075018, loss_ce: 0.014640
[00:43:47.664] iteration 6268 : loss : 0.131136, loss_ce: 0.009623
[00:43:47.950] iteration 6269 : loss : 0.070083, loss_ce: 0.022715
[00:43:48.237] iteration 6270 : loss : 0.091498, loss_ce: 0.025115
[00:43:48.527] iteration 6271 : loss : 0.063995, loss_ce: 0.021417
[00:43:48.815] iteration 6272 : loss : 0.101179, loss_ce: 0.025250
[00:43:49.101] iteration 6273 : loss : 0.058708, loss_ce: 0.023860
[00:43:49.387] iteration 6274 : loss : 0.055616, loss_ce: 0.011576
[00:43:49.678] iteration 6275 : loss : 0.104460, loss_ce: 0.018197
[00:43:49.965] iteration 6276 : loss : 0.079246, loss_ce: 0.027071
[00:43:50.255] iteration 6277 : loss : 0.078094, loss_ce: 0.024124
[00:43:50.544] iteration 6278 : loss : 0.046863, loss_ce: 0.010922
[00:43:50.830] iteration 6279 : loss : 0.197538, loss_ce: 0.015494
[00:43:51.119] iteration 6280 : loss : 0.075793, loss_ce: 0.022500
[00:43:51.422] iteration 6281 : loss : 0.056818, loss_ce: 0.017889
[00:43:51.710] iteration 6282 : loss : 0.053364, loss_ce: 0.024594
[00:43:51.996] iteration 6283 : loss : 0.057936, loss_ce: 0.016956
[00:43:52.285] iteration 6284 : loss : 0.072599, loss_ce: 0.015155
[00:43:52.572] iteration 6285 : loss : 0.067111, loss_ce: 0.022254
[00:43:52.858] iteration 6286 : loss : 0.289415, loss_ce: 0.005461
[00:43:53.145] iteration 6287 : loss : 0.058556, loss_ce: 0.023622
[00:43:53.432] iteration 6288 : loss : 0.074756, loss_ce: 0.022152
[00:43:53.720] iteration 6289 : loss : 0.079032, loss_ce: 0.017530
[00:43:54.007] iteration 6290 : loss : 0.063275, loss_ce: 0.019160
[00:43:54.295] iteration 6291 : loss : 0.068875, loss_ce: 0.014130
[00:43:54.582] iteration 6292 : loss : 0.143384, loss_ce: 0.007553
[00:43:54.867] iteration 6293 : loss : 0.060267, loss_ce: 0.022606
[00:43:55.155] iteration 6294 : loss : 0.077315, loss_ce: 0.030709
[00:43:55.444] iteration 6295 : loss : 0.076889, loss_ce: 0.024586
[00:43:55.730] iteration 6296 : loss : 0.080859, loss_ce: 0.022684
[00:43:56.017] iteration 6297 : loss : 0.076971, loss_ce: 0.035536
[00:43:56.304] iteration 6298 : loss : 0.065471, loss_ce: 0.015678
[00:43:56.590] iteration 6299 : loss : 0.075974, loss_ce: 0.013821
[00:43:56.877] iteration 6300 : loss : 0.056949, loss_ce: 0.024184
[00:43:57.178] iteration 6301 : loss : 0.106659, loss_ce: 0.010616
[00:43:57.467] iteration 6302 : loss : 0.057281, loss_ce: 0.018461
[00:43:57.756] iteration 6303 : loss : 0.057518, loss_ce: 0.014908
[00:43:58.043] iteration 6304 : loss : 0.078967, loss_ce: 0.026601
[00:43:58.331] iteration 6305 : loss : 0.112483, loss_ce: 0.012691
[00:43:58.620] iteration 6306 : loss : 0.065351, loss_ce: 0.018729
[00:43:58.907] iteration 6307 : loss : 0.072245, loss_ce: 0.023075
[00:43:59.193] iteration 6308 : loss : 0.070819, loss_ce: 0.014407
[00:43:59.481] iteration 6309 : loss : 0.078289, loss_ce: 0.017456
[00:43:59.768] iteration 6310 : loss : 0.080160, loss_ce: 0.026411
[00:44:00.057] iteration 6311 : loss : 0.069088, loss_ce: 0.031420
[00:44:00.347] iteration 6312 : loss : 0.079094, loss_ce: 0.017254
[00:44:00.637] iteration 6313 : loss : 0.058241, loss_ce: 0.013647
[00:44:00.932] iteration 6314 : loss : 0.063812, loss_ce: 0.024932
[00:44:01.222] iteration 6315 : loss : 0.054385, loss_ce: 0.020006
[00:44:01.510] iteration 6316 : loss : 0.107055, loss_ce: 0.021007
[00:44:01.798] iteration 6317 : loss : 0.131771, loss_ce: 0.015059
[00:44:02.085] iteration 6318 : loss : 0.053951, loss_ce: 0.020588
[00:44:02.372] iteration 6319 : loss : 0.067472, loss_ce: 0.026816
[00:44:02.660] iteration 6320 : loss : 0.061193, loss_ce: 0.018759
[00:44:02.963] iteration 6321 : loss : 0.158356, loss_ce: 0.015750
[00:44:03.249] iteration 6322 : loss : 0.071666, loss_ce: 0.022761
[00:44:03.536] iteration 6323 : loss : 0.106393, loss_ce: 0.009671
[00:44:03.825] iteration 6324 : loss : 0.116890, loss_ce: 0.011816
[00:44:04.113] iteration 6325 : loss : 0.121504, loss_ce: 0.025203
[00:44:04.398] iteration 6326 : loss : 0.128366, loss_ce: 0.023544
[00:44:04.686] iteration 6327 : loss : 0.064175, loss_ce: 0.012681
[00:44:04.973] iteration 6328 : loss : 0.132046, loss_ce: 0.012192
[00:44:05.259] iteration 6329 : loss : 0.066184, loss_ce: 0.015282
[00:44:05.545] iteration 6330 : loss : 0.097740, loss_ce: 0.018127
[00:44:05.833] iteration 6331 : loss : 0.076267, loss_ce: 0.029573
[00:44:06.119] iteration 6332 : loss : 0.126352, loss_ce: 0.025989
[00:44:06.408] iteration 6333 : loss : 0.059680, loss_ce: 0.020067
[00:44:06.694] iteration 6334 : loss : 0.073768, loss_ce: 0.016294
[00:44:06.981] iteration 6335 : loss : 0.069277, loss_ce: 0.009760
[00:44:07.268] iteration 6336 : loss : 0.075428, loss_ce: 0.014882
[00:44:07.554] iteration 6337 : loss : 0.067001, loss_ce: 0.025395
[00:44:07.845] iteration 6338 : loss : 0.047864, loss_ce: 0.013990
[00:44:08.132] iteration 6339 : loss : 0.078137, loss_ce: 0.025030
[00:44:08.419] iteration 6340 : loss : 0.139490, loss_ce: 0.011164
[00:44:08.726] iteration 6341 : loss : 0.077325, loss_ce: 0.021733
[00:44:09.013] iteration 6342 : loss : 0.193315, loss_ce: 0.008047
[00:44:09.300] iteration 6343 : loss : 0.062894, loss_ce: 0.031795
[00:44:09.589] iteration 6344 : loss : 0.065811, loss_ce: 0.023670
[00:44:09.876] iteration 6345 : loss : 0.076103, loss_ce: 0.019201
[00:44:10.162] iteration 6346 : loss : 0.059892, loss_ce: 0.021065
[00:44:10.453] iteration 6347 : loss : 0.082414, loss_ce: 0.019477
[00:44:10.741] iteration 6348 : loss : 0.139158, loss_ce: 0.014182
[00:44:11.029] iteration 6349 : loss : 0.060607, loss_ce: 0.024931
[00:44:11.318] iteration 6350 : loss : 0.076335, loss_ce: 0.027734
[00:44:11.603] iteration 6351 : loss : 0.135580, loss_ce: 0.016240
[00:44:11.890] iteration 6352 : loss : 0.066563, loss_ce: 0.013584
[00:44:12.176] iteration 6353 : loss : 0.066809, loss_ce: 0.026111
[00:44:12.465] iteration 6354 : loss : 0.087392, loss_ce: 0.026741
[00:44:12.752] iteration 6355 : loss : 0.083252, loss_ce: 0.016129
[00:44:13.041] iteration 6356 : loss : 0.078507, loss_ce: 0.026038
[00:44:13.329] iteration 6357 : loss : 0.068602, loss_ce: 0.034462
[00:44:13.615] iteration 6358 : loss : 0.065384, loss_ce: 0.031906
[00:44:13.902] iteration 6359 : loss : 0.051138, loss_ce: 0.017492
[00:44:14.191] iteration 6360 : loss : 0.132422, loss_ce: 0.016935
[00:44:14.495] iteration 6361 : loss : 0.112381, loss_ce: 0.008444
[00:44:14.784] iteration 6362 : loss : 0.145342, loss_ce: 0.007835
[00:44:15.070] iteration 6363 : loss : 0.129749, loss_ce: 0.017021
[00:44:15.359] iteration 6364 : loss : 0.118638, loss_ce: 0.015764
[00:44:15.648] iteration 6365 : loss : 0.074703, loss_ce: 0.008139
[00:44:15.935] iteration 6366 : loss : 0.131456, loss_ce: 0.044055
[00:44:16.224] iteration 6367 : loss : 0.078237, loss_ce: 0.020739
[00:44:16.511] iteration 6368 : loss : 0.136930, loss_ce: 0.008094
[00:44:16.798] iteration 6369 : loss : 0.161823, loss_ce: 0.014132
[00:44:17.085] iteration 6370 : loss : 0.070009, loss_ce: 0.017593
[00:44:17.372] iteration 6371 : loss : 0.109587, loss_ce: 0.014807
[00:44:17.658] iteration 6372 : loss : 0.132111, loss_ce: 0.012911
[00:44:17.947] iteration 6373 : loss : 0.234675, loss_ce: 0.006029
[00:44:18.234] iteration 6374 : loss : 0.109736, loss_ce: 0.007578
[00:44:18.524] iteration 6375 : loss : 0.071902, loss_ce: 0.022683
[00:44:18.810] iteration 6376 : loss : 0.063197, loss_ce: 0.027212
[00:44:19.096] iteration 6377 : loss : 0.170787, loss_ce: 0.006214
[00:44:19.388] iteration 6378 : loss : 0.290755, loss_ce: 0.016548
[00:44:19.676] iteration 6379 : loss : 0.089431, loss_ce: 0.035437
[00:44:19.965] iteration 6380 : loss : 0.070674, loss_ce: 0.016503
[00:44:20.276] iteration 6381 : loss : 0.141543, loss_ce: 0.023359
[00:44:20.571] iteration 6382 : loss : 0.051245, loss_ce: 0.019916
[00:44:20.863] iteration 6383 : loss : 0.069681, loss_ce: 0.015228
[00:44:21.155] iteration 6384 : loss : 0.119464, loss_ce: 0.012756
[00:44:21.445] iteration 6385 : loss : 0.096855, loss_ce: 0.021444
[00:44:21.736] iteration 6386 : loss : 0.046854, loss_ce: 0.009487
[00:44:22.032] iteration 6387 : loss : 0.055386, loss_ce: 0.007732
[00:44:22.320] iteration 6388 : loss : 0.101523, loss_ce: 0.019716
[00:44:22.608] iteration 6389 : loss : 0.060493, loss_ce: 0.017948
[00:44:22.903] iteration 6390 : loss : 0.058937, loss_ce: 0.007739
[00:44:23.195] iteration 6391 : loss : 0.058548, loss_ce: 0.017917
[00:44:23.486] iteration 6392 : loss : 0.061480, loss_ce: 0.024369
[00:44:23.781] iteration 6393 : loss : 0.120153, loss_ce: 0.030650
[00:44:23.857] iteration 6394 : loss : 0.118664, loss_ce: 0.019035
[00:44:24.386] save model to ./logs/swin_unet\epoch_45.pth
[00:44:40.444] iteration 6395 : loss : 0.060945, loss_ce: 0.014253
[00:44:40.730] iteration 6396 : loss : 0.043897, loss_ce: 0.018014
[00:44:41.017] iteration 6397 : loss : 0.065070, loss_ce: 0.019889
[00:44:41.305] iteration 6398 : loss : 0.132139, loss_ce: 0.018774
[00:44:41.592] iteration 6399 : loss : 0.304114, loss_ce: 0.022682
[00:44:41.877] iteration 6400 : loss : 0.065930, loss_ce: 0.017271
[00:44:42.186] iteration 6401 : loss : 0.093608, loss_ce: 0.033649
[00:44:42.471] iteration 6402 : loss : 0.060834, loss_ce: 0.029266
[00:44:42.797] iteration 6403 : loss : 0.166484, loss_ce: 0.008556
[00:44:43.082] iteration 6404 : loss : 0.417091, loss_ce: 0.002320
[00:44:43.367] iteration 6405 : loss : 0.073500, loss_ce: 0.017214
[00:44:43.657] iteration 6406 : loss : 0.058188, loss_ce: 0.020447
[00:44:43.945] iteration 6407 : loss : 0.051470, loss_ce: 0.021585
[00:44:44.231] iteration 6408 : loss : 0.083777, loss_ce: 0.010905
[00:44:44.520] iteration 6409 : loss : 0.067590, loss_ce: 0.022429
[00:44:44.808] iteration 6410 : loss : 0.066122, loss_ce: 0.028841
[00:44:45.095] iteration 6411 : loss : 0.139695, loss_ce: 0.023829
[00:44:45.380] iteration 6412 : loss : 0.074628, loss_ce: 0.026951
[00:44:45.670] iteration 6413 : loss : 0.061014, loss_ce: 0.008183
[00:44:45.959] iteration 6414 : loss : 0.075244, loss_ce: 0.035397
[00:44:46.244] iteration 6415 : loss : 0.080401, loss_ce: 0.019384
[00:44:46.531] iteration 6416 : loss : 0.126644, loss_ce: 0.017360
[00:44:46.819] iteration 6417 : loss : 0.067080, loss_ce: 0.016199
[00:44:47.104] iteration 6418 : loss : 0.125663, loss_ce: 0.016851
[00:44:47.395] iteration 6419 : loss : 0.065021, loss_ce: 0.019824
[00:44:47.683] iteration 6420 : loss : 0.116107, loss_ce: 0.018715
[00:44:47.986] iteration 6421 : loss : 0.064672, loss_ce: 0.028610
[00:44:48.272] iteration 6422 : loss : 0.055457, loss_ce: 0.011205
[00:44:48.560] iteration 6423 : loss : 0.085118, loss_ce: 0.030238
[00:44:48.847] iteration 6424 : loss : 0.124625, loss_ce: 0.027379
[00:44:49.133] iteration 6425 : loss : 0.066774, loss_ce: 0.016148
[00:44:49.419] iteration 6426 : loss : 0.074915, loss_ce: 0.031872
[00:44:49.706] iteration 6427 : loss : 0.087105, loss_ce: 0.025474
[00:44:49.992] iteration 6428 : loss : 0.068564, loss_ce: 0.025859
[00:44:50.278] iteration 6429 : loss : 0.064502, loss_ce: 0.020238
[00:44:50.571] iteration 6430 : loss : 0.129897, loss_ce: 0.016285
[00:44:50.865] iteration 6431 : loss : 0.139228, loss_ce: 0.012165
[00:44:51.153] iteration 6432 : loss : 0.069271, loss_ce: 0.017086
[00:44:51.444] iteration 6433 : loss : 0.055241, loss_ce: 0.019501
[00:44:51.733] iteration 6434 : loss : 0.074405, loss_ce: 0.021766
[00:44:52.023] iteration 6435 : loss : 0.088234, loss_ce: 0.025710
[00:44:52.316] iteration 6436 : loss : 0.075876, loss_ce: 0.026808
[00:44:52.606] iteration 6437 : loss : 0.053499, loss_ce: 0.011432
[00:44:52.894] iteration 6438 : loss : 0.070498, loss_ce: 0.020182
[00:44:53.184] iteration 6439 : loss : 0.085391, loss_ce: 0.033743
[00:44:53.473] iteration 6440 : loss : 0.121478, loss_ce: 0.018012
[00:44:53.774] iteration 6441 : loss : 0.065624, loss_ce: 0.024579
[00:44:54.063] iteration 6442 : loss : 0.075021, loss_ce: 0.020009
[00:44:54.353] iteration 6443 : loss : 0.090462, loss_ce: 0.024283
[00:44:54.642] iteration 6444 : loss : 0.082974, loss_ce: 0.035723
[00:44:54.931] iteration 6445 : loss : 0.071266, loss_ce: 0.022934
[00:44:55.224] iteration 6446 : loss : 0.182797, loss_ce: 0.006361
[00:44:55.515] iteration 6447 : loss : 0.113872, loss_ce: 0.010339
[00:44:55.801] iteration 6448 : loss : 0.072407, loss_ce: 0.017759
[00:44:56.092] iteration 6449 : loss : 0.161460, loss_ce: 0.013475
[00:44:56.381] iteration 6450 : loss : 0.047628, loss_ce: 0.016971
[00:44:56.673] iteration 6451 : loss : 0.064924, loss_ce: 0.022103
[00:44:56.961] iteration 6452 : loss : 0.079436, loss_ce: 0.027391
[00:44:57.252] iteration 6453 : loss : 0.058675, loss_ce: 0.020028
[00:44:57.543] iteration 6454 : loss : 0.066906, loss_ce: 0.017170
[00:44:57.834] iteration 6455 : loss : 0.052451, loss_ce: 0.011722
[00:44:58.124] iteration 6456 : loss : 0.073598, loss_ce: 0.020561
[00:44:58.414] iteration 6457 : loss : 0.053441, loss_ce: 0.015115
[00:44:58.704] iteration 6458 : loss : 0.103606, loss_ce: 0.016388
[00:44:58.996] iteration 6459 : loss : 0.127179, loss_ce: 0.018894
[00:44:59.287] iteration 6460 : loss : 0.068908, loss_ce: 0.021621
[00:44:59.592] iteration 6461 : loss : 0.052887, loss_ce: 0.015864
[00:44:59.881] iteration 6462 : loss : 0.076293, loss_ce: 0.017384
[00:45:00.174] iteration 6463 : loss : 0.087231, loss_ce: 0.034880
[00:45:00.469] iteration 6464 : loss : 0.086257, loss_ce: 0.012530
[00:45:00.761] iteration 6465 : loss : 0.123296, loss_ce: 0.009787
[00:45:01.053] iteration 6466 : loss : 0.069615, loss_ce: 0.021209
[00:45:01.343] iteration 6467 : loss : 0.074661, loss_ce: 0.030446
[00:45:01.634] iteration 6468 : loss : 0.072162, loss_ce: 0.022275
[00:45:01.923] iteration 6469 : loss : 0.080114, loss_ce: 0.030365
[00:45:02.209] iteration 6470 : loss : 0.070742, loss_ce: 0.017822
[00:45:02.499] iteration 6471 : loss : 0.051275, loss_ce: 0.012154
[00:45:02.788] iteration 6472 : loss : 0.067832, loss_ce: 0.032331
[00:45:03.079] iteration 6473 : loss : 0.108547, loss_ce: 0.010907
[00:45:03.368] iteration 6474 : loss : 0.223404, loss_ce: 0.020026
[00:45:03.660] iteration 6475 : loss : 0.292184, loss_ce: 0.007432
[00:45:03.950] iteration 6476 : loss : 0.072399, loss_ce: 0.019972
[00:45:04.240] iteration 6477 : loss : 0.146499, loss_ce: 0.026124
[00:45:04.529] iteration 6478 : loss : 0.099770, loss_ce: 0.025218
[00:45:04.816] iteration 6479 : loss : 0.076600, loss_ce: 0.021224
[00:45:05.105] iteration 6480 : loss : 0.085598, loss_ce: 0.023971
[00:45:05.411] iteration 6481 : loss : 0.105797, loss_ce: 0.013118
[00:45:05.701] iteration 6482 : loss : 0.092505, loss_ce: 0.020521
[00:45:05.991] iteration 6483 : loss : 0.238950, loss_ce: 0.015519
[00:45:06.282] iteration 6484 : loss : 0.080087, loss_ce: 0.023727
[00:45:06.574] iteration 6485 : loss : 0.066902, loss_ce: 0.015594
[00:45:06.864] iteration 6486 : loss : 0.057895, loss_ce: 0.017873
[00:45:07.154] iteration 6487 : loss : 0.048865, loss_ce: 0.019420
[00:45:07.444] iteration 6488 : loss : 0.064878, loss_ce: 0.024824
[00:45:07.733] iteration 6489 : loss : 0.115771, loss_ce: 0.019036
[00:45:08.023] iteration 6490 : loss : 0.131973, loss_ce: 0.010359
[00:45:08.313] iteration 6491 : loss : 0.081744, loss_ce: 0.022446
[00:45:08.604] iteration 6492 : loss : 0.076891, loss_ce: 0.013804
[00:45:08.894] iteration 6493 : loss : 0.091818, loss_ce: 0.028882
[00:45:09.183] iteration 6494 : loss : 0.054228, loss_ce: 0.006819
[00:45:09.470] iteration 6495 : loss : 0.132351, loss_ce: 0.021647
[00:45:09.763] iteration 6496 : loss : 0.058927, loss_ce: 0.017959
[00:45:10.052] iteration 6497 : loss : 0.121349, loss_ce: 0.026248
[00:45:10.340] iteration 6498 : loss : 0.187643, loss_ce: 0.023543
[00:45:10.632] iteration 6499 : loss : 0.072950, loss_ce: 0.018172
[00:45:10.923] iteration 6500 : loss : 0.062837, loss_ce: 0.016558
[00:45:11.226] iteration 6501 : loss : 0.048841, loss_ce: 0.009132
[00:45:11.515] iteration 6502 : loss : 0.090142, loss_ce: 0.019145
[00:45:11.806] iteration 6503 : loss : 0.064263, loss_ce: 0.025355
[00:45:12.098] iteration 6504 : loss : 0.049484, loss_ce: 0.015867
[00:45:12.388] iteration 6505 : loss : 0.161274, loss_ce: 0.015858
[00:45:12.678] iteration 6506 : loss : 0.075056, loss_ce: 0.021342
[00:45:12.968] iteration 6507 : loss : 0.068112, loss_ce: 0.018830
[00:45:13.259] iteration 6508 : loss : 0.079536, loss_ce: 0.021055
[00:45:13.550] iteration 6509 : loss : 0.064409, loss_ce: 0.009176
[00:45:13.839] iteration 6510 : loss : 0.067341, loss_ce: 0.020242
[00:45:14.126] iteration 6511 : loss : 0.065096, loss_ce: 0.019134
[00:45:14.417] iteration 6512 : loss : 0.065566, loss_ce: 0.019482
[00:45:14.709] iteration 6513 : loss : 0.070335, loss_ce: 0.019798
[00:45:14.995] iteration 6514 : loss : 0.060101, loss_ce: 0.016825
[00:45:15.283] iteration 6515 : loss : 0.076756, loss_ce: 0.015553
[00:45:15.575] iteration 6516 : loss : 0.080020, loss_ce: 0.019051
[00:45:15.870] iteration 6517 : loss : 0.070789, loss_ce: 0.024618
[00:45:16.167] iteration 6518 : loss : 0.118606, loss_ce: 0.026631
[00:45:16.458] iteration 6519 : loss : 0.107978, loss_ce: 0.016681
[00:45:16.752] iteration 6520 : loss : 0.155843, loss_ce: 0.011661
[00:45:17.066] iteration 6521 : loss : 0.130501, loss_ce: 0.018680
[00:45:17.355] iteration 6522 : loss : 0.055880, loss_ce: 0.017170
[00:45:17.648] iteration 6523 : loss : 0.079560, loss_ce: 0.027438
[00:45:17.942] iteration 6524 : loss : 0.123399, loss_ce: 0.020686
[00:45:18.232] iteration 6525 : loss : 0.119783, loss_ce: 0.010296
[00:45:18.527] iteration 6526 : loss : 0.066688, loss_ce: 0.020490
[00:45:18.821] iteration 6527 : loss : 0.097206, loss_ce: 0.028212
[00:45:19.109] iteration 6528 : loss : 0.106561, loss_ce: 0.015953
[00:45:19.404] iteration 6529 : loss : 0.065852, loss_ce: 0.018412
[00:45:19.696] iteration 6530 : loss : 0.062967, loss_ce: 0.014774
[00:45:19.988] iteration 6531 : loss : 0.048142, loss_ce: 0.016592
[00:45:20.282] iteration 6532 : loss : 0.065889, loss_ce: 0.028365
[00:45:20.371] iteration 6533 : loss : 0.138258, loss_ce: 0.060459
[00:45:37.165] iteration 6534 : loss : 0.062714, loss_ce: 0.014835
[00:45:37.450] iteration 6535 : loss : 0.070959, loss_ce: 0.027326
[00:45:37.735] iteration 6536 : loss : 0.123066, loss_ce: 0.013557
[00:45:38.025] iteration 6537 : loss : 0.061250, loss_ce: 0.016214
[00:45:38.312] iteration 6538 : loss : 0.055550, loss_ce: 0.012737
[00:45:38.595] iteration 6539 : loss : 0.068484, loss_ce: 0.024223
[00:45:38.884] iteration 6540 : loss : 0.083584, loss_ce: 0.023200
[00:45:39.189] iteration 6541 : loss : 0.118947, loss_ce: 0.016207
[00:45:39.480] iteration 6542 : loss : 0.078387, loss_ce: 0.021228
[00:45:39.767] iteration 6543 : loss : 0.124830, loss_ce: 0.013533
[00:45:40.055] iteration 6544 : loss : 0.061109, loss_ce: 0.015596
[00:45:40.342] iteration 6545 : loss : 0.131681, loss_ce: 0.009011
[00:45:40.630] iteration 6546 : loss : 0.244664, loss_ce: 0.012934
[00:45:40.919] iteration 6547 : loss : 0.069413, loss_ce: 0.017546
[00:45:41.206] iteration 6548 : loss : 0.064553, loss_ce: 0.013002
[00:45:41.492] iteration 6549 : loss : 0.099327, loss_ce: 0.010199
[00:45:41.780] iteration 6550 : loss : 0.056648, loss_ce: 0.017973
[00:45:42.069] iteration 6551 : loss : 0.074970, loss_ce: 0.033406
[00:45:42.358] iteration 6552 : loss : 0.076035, loss_ce: 0.015122
[00:45:42.645] iteration 6553 : loss : 0.055515, loss_ce: 0.017350
[00:45:42.933] iteration 6554 : loss : 0.059986, loss_ce: 0.016937
[00:45:43.220] iteration 6555 : loss : 0.072037, loss_ce: 0.019140
[00:45:43.508] iteration 6556 : loss : 0.064028, loss_ce: 0.016081
[00:45:43.797] iteration 6557 : loss : 0.064332, loss_ce: 0.011258
[00:45:44.083] iteration 6558 : loss : 0.078540, loss_ce: 0.017486
[00:45:44.371] iteration 6559 : loss : 0.066933, loss_ce: 0.014302
[00:45:44.657] iteration 6560 : loss : 0.092443, loss_ce: 0.012419
[00:45:44.961] iteration 6561 : loss : 0.116978, loss_ce: 0.023741
[00:45:45.246] iteration 6562 : loss : 0.055612, loss_ce: 0.009870
[00:45:45.531] iteration 6563 : loss : 0.131673, loss_ce: 0.016714
[00:45:45.820] iteration 6564 : loss : 0.070280, loss_ce: 0.022251
[00:45:46.106] iteration 6565 : loss : 0.065996, loss_ce: 0.024208
[00:45:46.393] iteration 6566 : loss : 0.090462, loss_ce: 0.034853
[00:45:46.684] iteration 6567 : loss : 0.063712, loss_ce: 0.016158
[00:45:46.970] iteration 6568 : loss : 0.062858, loss_ce: 0.013485
[00:45:47.258] iteration 6569 : loss : 0.143922, loss_ce: 0.010265
[00:45:47.546] iteration 6570 : loss : 0.067529, loss_ce: 0.009492
[00:45:47.833] iteration 6571 : loss : 0.072875, loss_ce: 0.020879
[00:45:48.121] iteration 6572 : loss : 0.063764, loss_ce: 0.021670
[00:45:48.409] iteration 6573 : loss : 0.121050, loss_ce: 0.016362
[00:45:48.696] iteration 6574 : loss : 0.079671, loss_ce: 0.023475
[00:45:48.984] iteration 6575 : loss : 0.113408, loss_ce: 0.022973
[00:45:49.275] iteration 6576 : loss : 0.099583, loss_ce: 0.019168
[00:45:49.561] iteration 6577 : loss : 0.088034, loss_ce: 0.020515
[00:45:49.852] iteration 6578 : loss : 0.048630, loss_ce: 0.019339
[00:45:50.139] iteration 6579 : loss : 0.060312, loss_ce: 0.021824
[00:45:50.426] iteration 6580 : loss : 0.072403, loss_ce: 0.017980
[00:45:50.730] iteration 6581 : loss : 0.061867, loss_ce: 0.031119
[00:45:51.016] iteration 6582 : loss : 0.073574, loss_ce: 0.024904
[00:45:51.304] iteration 6583 : loss : 0.076560, loss_ce: 0.020444
[00:45:51.592] iteration 6584 : loss : 0.064137, loss_ce: 0.014741
[00:45:51.879] iteration 6585 : loss : 0.119524, loss_ce: 0.016161
[00:45:52.167] iteration 6586 : loss : 0.066747, loss_ce: 0.028860
[00:45:52.458] iteration 6587 : loss : 0.059203, loss_ce: 0.022811
[00:45:52.744] iteration 6588 : loss : 0.054599, loss_ce: 0.011073
[00:45:53.029] iteration 6589 : loss : 0.064172, loss_ce: 0.017867
[00:45:53.320] iteration 6590 : loss : 0.086318, loss_ce: 0.024919
[00:45:53.607] iteration 6591 : loss : 0.069391, loss_ce: 0.021981
[00:45:53.896] iteration 6592 : loss : 0.077898, loss_ce: 0.017604
[00:45:54.185] iteration 6593 : loss : 0.059036, loss_ce: 0.019639
[00:45:54.471] iteration 6594 : loss : 0.070931, loss_ce: 0.024042
[00:45:54.759] iteration 6595 : loss : 0.062063, loss_ce: 0.024658
[00:45:55.044] iteration 6596 : loss : 0.084172, loss_ce: 0.008574
[00:45:55.331] iteration 6597 : loss : 0.084697, loss_ce: 0.023970
[00:45:55.621] iteration 6598 : loss : 0.206558, loss_ce: 0.028794
[00:45:55.908] iteration 6599 : loss : 0.063657, loss_ce: 0.015056
[00:45:56.197] iteration 6600 : loss : 0.111703, loss_ce: 0.013055
[00:45:56.505] iteration 6601 : loss : 0.062340, loss_ce: 0.017176
[00:45:56.794] iteration 6602 : loss : 0.062299, loss_ce: 0.008443
[00:45:57.081] iteration 6603 : loss : 0.074466, loss_ce: 0.030358
[00:45:57.369] iteration 6604 : loss : 0.074680, loss_ce: 0.019918
[00:45:57.657] iteration 6605 : loss : 0.089800, loss_ce: 0.022845
[00:45:57.945] iteration 6606 : loss : 0.054007, loss_ce: 0.016308
[00:45:58.233] iteration 6607 : loss : 0.072997, loss_ce: 0.022939
[00:45:58.524] iteration 6608 : loss : 0.057582, loss_ce: 0.022714
[00:45:58.814] iteration 6609 : loss : 0.127688, loss_ce: 0.018171
[00:45:59.105] iteration 6610 : loss : 0.090645, loss_ce: 0.018984
[00:45:59.393] iteration 6611 : loss : 0.059773, loss_ce: 0.014885
[00:45:59.680] iteration 6612 : loss : 0.179959, loss_ce: 0.014464
[00:45:59.968] iteration 6613 : loss : 0.092651, loss_ce: 0.023024
[00:46:00.261] iteration 6614 : loss : 0.072426, loss_ce: 0.012984
[00:46:00.552] iteration 6615 : loss : 0.036730, loss_ce: 0.009304
[00:46:00.843] iteration 6616 : loss : 0.139365, loss_ce: 0.012668
[00:46:01.131] iteration 6617 : loss : 0.050688, loss_ce: 0.025796
[00:46:01.419] iteration 6618 : loss : 0.128395, loss_ce: 0.022297
[00:46:01.706] iteration 6619 : loss : 0.101291, loss_ce: 0.018408
[00:46:01.994] iteration 6620 : loss : 0.121665, loss_ce: 0.026258
[00:46:02.302] iteration 6621 : loss : 0.079314, loss_ce: 0.018498
[00:46:02.593] iteration 6622 : loss : 0.055611, loss_ce: 0.026201
[00:46:02.879] iteration 6623 : loss : 0.158744, loss_ce: 0.018918
[00:46:03.168] iteration 6624 : loss : 0.073855, loss_ce: 0.025949
[00:46:03.455] iteration 6625 : loss : 0.048889, loss_ce: 0.013808
[00:46:03.747] iteration 6626 : loss : 0.113748, loss_ce: 0.042274
[00:46:04.035] iteration 6627 : loss : 0.071637, loss_ce: 0.024997
[00:46:04.324] iteration 6628 : loss : 0.060663, loss_ce: 0.015497
[00:46:04.614] iteration 6629 : loss : 0.123687, loss_ce: 0.010835
[00:46:04.902] iteration 6630 : loss : 0.075979, loss_ce: 0.023206
[00:46:05.190] iteration 6631 : loss : 0.078010, loss_ce: 0.026480
[00:46:05.482] iteration 6632 : loss : 0.128353, loss_ce: 0.025158
[00:46:05.773] iteration 6633 : loss : 0.125392, loss_ce: 0.017418
[00:46:06.059] iteration 6634 : loss : 0.082751, loss_ce: 0.022417
[00:46:06.346] iteration 6635 : loss : 0.084267, loss_ce: 0.024779
[00:46:06.637] iteration 6636 : loss : 0.174147, loss_ce: 0.010419
[00:46:06.927] iteration 6637 : loss : 0.175074, loss_ce: 0.004777
[00:46:07.217] iteration 6638 : loss : 0.057288, loss_ce: 0.030123
[00:46:07.503] iteration 6639 : loss : 0.061453, loss_ce: 0.019747
[00:46:07.794] iteration 6640 : loss : 0.061652, loss_ce: 0.018752
[00:46:08.104] iteration 6641 : loss : 0.054168, loss_ce: 0.024269
[00:46:08.395] iteration 6642 : loss : 0.103936, loss_ce: 0.017508
[00:46:08.685] iteration 6643 : loss : 0.085854, loss_ce: 0.016186
[00:46:08.975] iteration 6644 : loss : 0.063336, loss_ce: 0.018692
[00:46:09.262] iteration 6645 : loss : 0.076785, loss_ce: 0.019198
[00:46:09.550] iteration 6646 : loss : 0.071614, loss_ce: 0.016442
[00:46:09.841] iteration 6647 : loss : 0.073298, loss_ce: 0.019980
[00:46:10.131] iteration 6648 : loss : 0.113080, loss_ce: 0.030904
[00:46:10.420] iteration 6649 : loss : 0.067065, loss_ce: 0.020782
[00:46:10.712] iteration 6650 : loss : 0.064351, loss_ce: 0.028259
[00:46:11.001] iteration 6651 : loss : 0.118936, loss_ce: 0.019721
[00:46:11.292] iteration 6652 : loss : 0.170550, loss_ce: 0.027987
[00:46:11.581] iteration 6653 : loss : 0.053987, loss_ce: 0.015692
[00:46:11.873] iteration 6654 : loss : 0.050889, loss_ce: 0.017829
[00:46:12.162] iteration 6655 : loss : 0.099039, loss_ce: 0.017631
[00:46:12.457] iteration 6656 : loss : 0.090583, loss_ce: 0.029552
[00:46:12.750] iteration 6657 : loss : 0.047634, loss_ce: 0.014933
[00:46:13.039] iteration 6658 : loss : 0.080319, loss_ce: 0.015109
[00:46:13.333] iteration 6659 : loss : 0.064946, loss_ce: 0.029044
[00:46:13.627] iteration 6660 : loss : 0.064339, loss_ce: 0.019362
[00:46:13.936] iteration 6661 : loss : 0.072628, loss_ce: 0.023098
[00:46:14.226] iteration 6662 : loss : 0.070246, loss_ce: 0.022485
[00:46:14.514] iteration 6663 : loss : 0.125963, loss_ce: 0.020028
[00:46:14.811] iteration 6664 : loss : 0.079417, loss_ce: 0.025107
[00:46:15.108] iteration 6665 : loss : 0.059584, loss_ce: 0.018143
[00:46:15.399] iteration 6666 : loss : 0.091531, loss_ce: 0.015821
[00:46:15.693] iteration 6667 : loss : 0.073770, loss_ce: 0.019938
[00:46:15.984] iteration 6668 : loss : 0.112746, loss_ce: 0.016628
[00:46:16.277] iteration 6669 : loss : 0.069773, loss_ce: 0.026627
[00:46:16.566] iteration 6670 : loss : 0.055132, loss_ce: 0.019070
[00:46:16.855] iteration 6671 : loss : 0.072921, loss_ce: 0.028129
[00:46:16.933] iteration 6672 : loss : 0.404154, loss_ce: 0.002860
[00:46:33.135] iteration 6673 : loss : 0.057506, loss_ce: 0.009472
[00:46:33.422] iteration 6674 : loss : 0.092421, loss_ce: 0.017991
[00:46:33.706] iteration 6675 : loss : 0.126484, loss_ce: 0.022000
[00:46:33.996] iteration 6676 : loss : 0.059847, loss_ce: 0.016308
[00:46:34.284] iteration 6677 : loss : 0.117310, loss_ce: 0.028030
[00:46:34.572] iteration 6678 : loss : 0.113412, loss_ce: 0.010666
[00:46:34.861] iteration 6679 : loss : 0.072392, loss_ce: 0.024404
[00:46:35.152] iteration 6680 : loss : 0.185580, loss_ce: 0.009901
[00:46:35.453] iteration 6681 : loss : 0.074660, loss_ce: 0.017420
[00:46:35.743] iteration 6682 : loss : 0.059297, loss_ce: 0.016458
[00:46:36.032] iteration 6683 : loss : 0.054899, loss_ce: 0.021291
[00:46:36.320] iteration 6684 : loss : 0.078478, loss_ce: 0.028449
[00:46:36.607] iteration 6685 : loss : 0.067946, loss_ce: 0.029949
[00:46:36.895] iteration 6686 : loss : 0.086444, loss_ce: 0.028186
[00:46:37.183] iteration 6687 : loss : 0.064528, loss_ce: 0.024875
[00:46:37.480] iteration 6688 : loss : 0.088709, loss_ce: 0.022073
[00:46:37.786] iteration 6689 : loss : 0.111206, loss_ce: 0.006080
[00:46:38.118] iteration 6690 : loss : 0.088485, loss_ce: 0.019066
[00:46:38.426] iteration 6691 : loss : 0.138775, loss_ce: 0.011375
[00:46:38.723] iteration 6692 : loss : 0.126261, loss_ce: 0.016436
[00:46:39.010] iteration 6693 : loss : 0.059821, loss_ce: 0.016448
[00:46:39.295] iteration 6694 : loss : 0.068610, loss_ce: 0.022655
[00:46:39.583] iteration 6695 : loss : 0.047685, loss_ce: 0.016607
[00:46:39.870] iteration 6696 : loss : 0.112102, loss_ce: 0.017363
[00:46:40.159] iteration 6697 : loss : 0.067752, loss_ce: 0.020157
[00:46:40.445] iteration 6698 : loss : 0.051542, loss_ce: 0.021193
[00:46:40.732] iteration 6699 : loss : 0.066674, loss_ce: 0.022750
[00:46:41.019] iteration 6700 : loss : 0.081158, loss_ce: 0.023083
[00:46:41.329] iteration 6701 : loss : 0.124871, loss_ce: 0.025842
[00:46:41.615] iteration 6702 : loss : 0.063776, loss_ce: 0.014820
[00:46:41.910] iteration 6703 : loss : 0.070975, loss_ce: 0.025383
[00:46:42.211] iteration 6704 : loss : 0.060312, loss_ce: 0.022150
[00:46:42.515] iteration 6705 : loss : 0.056657, loss_ce: 0.018590
[00:46:42.823] iteration 6706 : loss : 0.068741, loss_ce: 0.014378
[00:46:43.135] iteration 6707 : loss : 0.060384, loss_ce: 0.017666
[00:46:43.439] iteration 6708 : loss : 0.093600, loss_ce: 0.015690
[00:46:43.743] iteration 6709 : loss : 0.061130, loss_ce: 0.018172
[00:46:44.048] iteration 6710 : loss : 0.068462, loss_ce: 0.016091
[00:46:44.352] iteration 6711 : loss : 0.073190, loss_ce: 0.015940
[00:46:44.656] iteration 6712 : loss : 0.053776, loss_ce: 0.013509
[00:46:44.959] iteration 6713 : loss : 0.092686, loss_ce: 0.023590
[00:46:45.264] iteration 6714 : loss : 0.057238, loss_ce: 0.012670
[00:46:45.567] iteration 6715 : loss : 0.066372, loss_ce: 0.019565
[00:46:45.870] iteration 6716 : loss : 0.059212, loss_ce: 0.014351
[00:46:46.173] iteration 6717 : loss : 0.099517, loss_ce: 0.016680
[00:46:46.479] iteration 6718 : loss : 0.120377, loss_ce: 0.026129
[00:46:46.784] iteration 6719 : loss : 0.079842, loss_ce: 0.017334
[00:46:47.086] iteration 6720 : loss : 0.108466, loss_ce: 0.018743
[00:46:47.408] iteration 6721 : loss : 0.076904, loss_ce: 0.016636
[00:46:47.711] iteration 6722 : loss : 0.069508, loss_ce: 0.026074
[00:46:48.011] iteration 6723 : loss : 0.070646, loss_ce: 0.025725
[00:46:48.314] iteration 6724 : loss : 0.081004, loss_ce: 0.021233
[00:46:48.621] iteration 6725 : loss : 0.115336, loss_ce: 0.024061
[00:46:48.924] iteration 6726 : loss : 0.065174, loss_ce: 0.019931
[00:46:49.229] iteration 6727 : loss : 0.067928, loss_ce: 0.010714
[00:46:49.531] iteration 6728 : loss : 0.076427, loss_ce: 0.023688
[00:46:49.835] iteration 6729 : loss : 0.079667, loss_ce: 0.025696
[00:46:50.144] iteration 6730 : loss : 0.061186, loss_ce: 0.015236
[00:46:50.449] iteration 6731 : loss : 0.058003, loss_ce: 0.017587
[00:46:50.756] iteration 6732 : loss : 0.085750, loss_ce: 0.029586
[00:46:51.064] iteration 6733 : loss : 0.075877, loss_ce: 0.016661
[00:46:51.369] iteration 6734 : loss : 0.126752, loss_ce: 0.008320
[00:46:51.676] iteration 6735 : loss : 0.058291, loss_ce: 0.027823
[00:46:51.981] iteration 6736 : loss : 0.075108, loss_ce: 0.032621
[00:46:52.286] iteration 6737 : loss : 0.063220, loss_ce: 0.021181
[00:46:52.591] iteration 6738 : loss : 0.064933, loss_ce: 0.017077
[00:46:52.897] iteration 6739 : loss : 0.072936, loss_ce: 0.018740
[00:46:53.200] iteration 6740 : loss : 0.074084, loss_ce: 0.018979
[00:46:53.520] iteration 6741 : loss : 0.115479, loss_ce: 0.012111
[00:46:53.822] iteration 6742 : loss : 0.084041, loss_ce: 0.019971
[00:46:54.128] iteration 6743 : loss : 0.066441, loss_ce: 0.020489
[00:46:54.433] iteration 6744 : loss : 0.074907, loss_ce: 0.019140
[00:46:54.741] iteration 6745 : loss : 0.090028, loss_ce: 0.010767
[00:46:55.047] iteration 6746 : loss : 0.064717, loss_ce: 0.024467
[00:46:55.350] iteration 6747 : loss : 0.147189, loss_ce: 0.013375
[00:46:55.659] iteration 6748 : loss : 0.062583, loss_ce: 0.017496
[00:46:55.966] iteration 6749 : loss : 0.106145, loss_ce: 0.010540
[00:46:56.269] iteration 6750 : loss : 0.095233, loss_ce: 0.013881
[00:46:56.578] iteration 6751 : loss : 0.076649, loss_ce: 0.021575
[00:46:56.880] iteration 6752 : loss : 0.082655, loss_ce: 0.031103
[00:46:57.191] iteration 6753 : loss : 0.086231, loss_ce: 0.017465
[00:46:57.498] iteration 6754 : loss : 0.089995, loss_ce: 0.022404
[00:46:57.810] iteration 6755 : loss : 0.071900, loss_ce: 0.034814
[00:46:58.123] iteration 6756 : loss : 0.073712, loss_ce: 0.015417
[00:46:58.429] iteration 6757 : loss : 0.056028, loss_ce: 0.014714
[00:46:58.744] iteration 6758 : loss : 0.071191, loss_ce: 0.023924
[00:46:59.060] iteration 6759 : loss : 0.060937, loss_ce: 0.025412
[00:46:59.367] iteration 6760 : loss : 0.060770, loss_ce: 0.017048
[00:46:59.685] iteration 6761 : loss : 0.128955, loss_ce: 0.023310
[00:46:59.990] iteration 6762 : loss : 0.071761, loss_ce: 0.013821
[00:47:00.295] iteration 6763 : loss : 0.124604, loss_ce: 0.011162
[00:47:00.602] iteration 6764 : loss : 0.092735, loss_ce: 0.015805
[00:47:00.905] iteration 6765 : loss : 0.058884, loss_ce: 0.019313
[00:47:01.210] iteration 6766 : loss : 0.068809, loss_ce: 0.024727
[00:47:01.516] iteration 6767 : loss : 0.078159, loss_ce: 0.024728
[00:47:01.819] iteration 6768 : loss : 0.126457, loss_ce: 0.017189
[00:47:02.128] iteration 6769 : loss : 0.108299, loss_ce: 0.037683
[00:47:02.431] iteration 6770 : loss : 0.065690, loss_ce: 0.019845
[00:47:02.736] iteration 6771 : loss : 0.125016, loss_ce: 0.013108
[00:47:03.045] iteration 6772 : loss : 0.071813, loss_ce: 0.017148
[00:47:03.348] iteration 6773 : loss : 0.088640, loss_ce: 0.020234
[00:47:03.652] iteration 6774 : loss : 0.062326, loss_ce: 0.017628
[00:47:03.957] iteration 6775 : loss : 0.072187, loss_ce: 0.022575
[00:47:04.262] iteration 6776 : loss : 0.073630, loss_ce: 0.020521
[00:47:04.564] iteration 6777 : loss : 0.066077, loss_ce: 0.016472
[00:47:04.869] iteration 6778 : loss : 0.067903, loss_ce: 0.020299
[00:47:05.172] iteration 6779 : loss : 0.116491, loss_ce: 0.014574
[00:47:05.474] iteration 6780 : loss : 0.112313, loss_ce: 0.013038
[00:47:05.787] iteration 6781 : loss : 0.082977, loss_ce: 0.014235
[00:47:06.092] iteration 6782 : loss : 0.065356, loss_ce: 0.015718
[00:47:06.398] iteration 6783 : loss : 0.052496, loss_ce: 0.012724
[00:47:06.700] iteration 6784 : loss : 0.062447, loss_ce: 0.009102
[00:47:07.006] iteration 6785 : loss : 0.060401, loss_ce: 0.023368
[00:47:07.313] iteration 6786 : loss : 0.056609, loss_ce: 0.019877
[00:47:07.614] iteration 6787 : loss : 0.075616, loss_ce: 0.031274
[00:47:07.917] iteration 6788 : loss : 0.124981, loss_ce: 0.013283
[00:47:08.222] iteration 6789 : loss : 0.126128, loss_ce: 0.007891
[00:47:08.531] iteration 6790 : loss : 0.072273, loss_ce: 0.019252
[00:47:08.839] iteration 6791 : loss : 0.058607, loss_ce: 0.016137
[00:47:09.146] iteration 6792 : loss : 0.084030, loss_ce: 0.032177
[00:47:09.448] iteration 6793 : loss : 0.068262, loss_ce: 0.040742
[00:47:09.756] iteration 6794 : loss : 0.289036, loss_ce: 0.002827
[00:47:10.067] iteration 6795 : loss : 0.059331, loss_ce: 0.021570
[00:47:10.376] iteration 6796 : loss : 0.064694, loss_ce: 0.028238
[00:47:10.685] iteration 6797 : loss : 0.067410, loss_ce: 0.015472
[00:47:10.994] iteration 6798 : loss : 0.063477, loss_ce: 0.019949
[00:47:11.305] iteration 6799 : loss : 0.112726, loss_ce: 0.009616
[00:47:11.618] iteration 6800 : loss : 0.115702, loss_ce: 0.013767
[00:47:11.976] iteration 6801 : loss : 0.074340, loss_ce: 0.022464
[00:47:12.288] iteration 6802 : loss : 0.111234, loss_ce: 0.015075
[00:47:12.602] iteration 6803 : loss : 0.114915, loss_ce: 0.023029
[00:47:12.917] iteration 6804 : loss : 0.065552, loss_ce: 0.019920
[00:47:13.227] iteration 6805 : loss : 0.131195, loss_ce: 0.013796
[00:47:13.541] iteration 6806 : loss : 0.062522, loss_ce: 0.024846
[00:47:13.856] iteration 6807 : loss : 0.060397, loss_ce: 0.019791
[00:47:14.173] iteration 6808 : loss : 0.053850, loss_ce: 0.022675
[00:47:14.481] iteration 6809 : loss : 0.120139, loss_ce: 0.012944
[00:47:14.791] iteration 6810 : loss : 0.060027, loss_ce: 0.024088
[00:47:14.873] iteration 6811 : loss : 0.087294, loss_ce: 0.059573
[00:47:33.014] iteration 6812 : loss : 0.057789, loss_ce: 0.019758
[00:47:33.317] iteration 6813 : loss : 0.075840, loss_ce: 0.010105
[00:47:33.626] iteration 6814 : loss : 0.133518, loss_ce: 0.021816
[00:47:33.937] iteration 6815 : loss : 0.118266, loss_ce: 0.012447
[00:47:34.246] iteration 6816 : loss : 0.061469, loss_ce: 0.015665
[00:47:34.549] iteration 6817 : loss : 0.075983, loss_ce: 0.019907
[00:47:34.861] iteration 6818 : loss : 0.049122, loss_ce: 0.013674
[00:47:35.170] iteration 6819 : loss : 0.089002, loss_ce: 0.023256
[00:47:35.473] iteration 6820 : loss : 0.117263, loss_ce: 0.014917
[00:47:35.800] iteration 6821 : loss : 0.050100, loss_ce: 0.024397
[00:47:36.110] iteration 6822 : loss : 0.066160, loss_ce: 0.025383
[00:47:36.417] iteration 6823 : loss : 0.057566, loss_ce: 0.020821
[00:47:36.726] iteration 6824 : loss : 0.074730, loss_ce: 0.012563
[00:47:37.038] iteration 6825 : loss : 0.079933, loss_ce: 0.019921
[00:47:37.346] iteration 6826 : loss : 0.067179, loss_ce: 0.023728
[00:47:37.653] iteration 6827 : loss : 0.061994, loss_ce: 0.020322
[00:47:37.957] iteration 6828 : loss : 0.065159, loss_ce: 0.018919
[00:47:38.266] iteration 6829 : loss : 0.086658, loss_ce: 0.020004
[00:47:38.575] iteration 6830 : loss : 0.057553, loss_ce: 0.025113
[00:47:38.885] iteration 6831 : loss : 0.131862, loss_ce: 0.005838
[00:47:39.193] iteration 6832 : loss : 0.077405, loss_ce: 0.013061
[00:47:39.504] iteration 6833 : loss : 0.125568, loss_ce: 0.015111
[00:47:39.809] iteration 6834 : loss : 0.064833, loss_ce: 0.014685
[00:47:40.122] iteration 6835 : loss : 0.053922, loss_ce: 0.015972
[00:47:40.433] iteration 6836 : loss : 0.075654, loss_ce: 0.018401
[00:47:40.742] iteration 6837 : loss : 0.120453, loss_ce: 0.013267
[00:47:41.055] iteration 6838 : loss : 0.071936, loss_ce: 0.028799
[00:47:41.357] iteration 6839 : loss : 0.081450, loss_ce: 0.025297
[00:47:41.666] iteration 6840 : loss : 0.047084, loss_ce: 0.019413
[00:47:41.990] iteration 6841 : loss : 0.070301, loss_ce: 0.020422
[00:47:42.296] iteration 6842 : loss : 0.088478, loss_ce: 0.026078
[00:47:42.604] iteration 6843 : loss : 0.079832, loss_ce: 0.020061
[00:47:42.910] iteration 6844 : loss : 0.055737, loss_ce: 0.023697
[00:47:43.217] iteration 6845 : loss : 0.072896, loss_ce: 0.018764
[00:47:43.523] iteration 6846 : loss : 0.058744, loss_ce: 0.021418
[00:47:43.829] iteration 6847 : loss : 0.120562, loss_ce: 0.018982
[00:47:44.139] iteration 6848 : loss : 0.059668, loss_ce: 0.021251
[00:47:44.448] iteration 6849 : loss : 0.063919, loss_ce: 0.018185
[00:47:44.758] iteration 6850 : loss : 0.073616, loss_ce: 0.028041
[00:47:45.063] iteration 6851 : loss : 0.134357, loss_ce: 0.016588
[00:47:45.371] iteration 6852 : loss : 0.078964, loss_ce: 0.023845
[00:47:45.677] iteration 6853 : loss : 0.069210, loss_ce: 0.022234
[00:47:45.985] iteration 6854 : loss : 0.107424, loss_ce: 0.019170
[00:47:46.291] iteration 6855 : loss : 0.111783, loss_ce: 0.030401
[00:47:46.603] iteration 6856 : loss : 0.135570, loss_ce: 0.021711
[00:47:46.907] iteration 6857 : loss : 0.062473, loss_ce: 0.017867
[00:47:47.217] iteration 6858 : loss : 0.049217, loss_ce: 0.011288
[00:47:47.528] iteration 6859 : loss : 0.062482, loss_ce: 0.019497
[00:47:47.841] iteration 6860 : loss : 0.091418, loss_ce: 0.014457
[00:47:48.169] iteration 6861 : loss : 0.074822, loss_ce: 0.017254
[00:47:48.480] iteration 6862 : loss : 0.077396, loss_ce: 0.023656
[00:47:48.788] iteration 6863 : loss : 0.081584, loss_ce: 0.028490
[00:47:49.097] iteration 6864 : loss : 0.059913, loss_ce: 0.027772
[00:47:49.401] iteration 6865 : loss : 0.071261, loss_ce: 0.019918
[00:47:49.705] iteration 6866 : loss : 0.137510, loss_ce: 0.010627
[00:47:50.010] iteration 6867 : loss : 0.054189, loss_ce: 0.027140
[00:47:50.313] iteration 6868 : loss : 0.164000, loss_ce: 0.006860
[00:47:50.618] iteration 6869 : loss : 0.070827, loss_ce: 0.018644
[00:47:50.922] iteration 6870 : loss : 0.066324, loss_ce: 0.023845
[00:47:51.224] iteration 6871 : loss : 0.066884, loss_ce: 0.016187
[00:47:51.530] iteration 6872 : loss : 0.072550, loss_ce: 0.026057
[00:47:51.833] iteration 6873 : loss : 0.054683, loss_ce: 0.013944
[00:47:52.139] iteration 6874 : loss : 0.073170, loss_ce: 0.024508
[00:47:52.443] iteration 6875 : loss : 0.087353, loss_ce: 0.018778
[00:47:52.747] iteration 6876 : loss : 0.065659, loss_ce: 0.009843
[00:47:53.050] iteration 6877 : loss : 0.114318, loss_ce: 0.016301
[00:47:53.352] iteration 6878 : loss : 0.062254, loss_ce: 0.021647
[00:47:53.657] iteration 6879 : loss : 0.061896, loss_ce: 0.020560
[00:47:53.959] iteration 6880 : loss : 0.111785, loss_ce: 0.015683
[00:47:54.276] iteration 6881 : loss : 0.050880, loss_ce: 0.010171
[00:47:54.580] iteration 6882 : loss : 0.062557, loss_ce: 0.029708
[00:47:54.882] iteration 6883 : loss : 0.058051, loss_ce: 0.022766
[00:47:55.184] iteration 6884 : loss : 0.111452, loss_ce: 0.018634
[00:47:55.485] iteration 6885 : loss : 0.194093, loss_ce: 0.008426
[00:47:55.788] iteration 6886 : loss : 0.054158, loss_ce: 0.017978
[00:47:56.089] iteration 6887 : loss : 0.041536, loss_ce: 0.009457
[00:47:56.395] iteration 6888 : loss : 0.121609, loss_ce: 0.024730
[00:47:56.697] iteration 6889 : loss : 0.059220, loss_ce: 0.009935
[00:47:57.001] iteration 6890 : loss : 0.089760, loss_ce: 0.020388
[00:47:57.302] iteration 6891 : loss : 0.177448, loss_ce: 0.025691
[00:47:57.606] iteration 6892 : loss : 0.088659, loss_ce: 0.021422
[00:47:57.910] iteration 6893 : loss : 0.075505, loss_ce: 0.023015
[00:47:58.216] iteration 6894 : loss : 0.095285, loss_ce: 0.017774
[00:47:58.518] iteration 6895 : loss : 0.116141, loss_ce: 0.016395
[00:47:58.819] iteration 6896 : loss : 0.065737, loss_ce: 0.024001
[00:47:59.121] iteration 6897 : loss : 0.129623, loss_ce: 0.009809
[00:47:59.428] iteration 6898 : loss : 0.056070, loss_ce: 0.019598
[00:47:59.730] iteration 6899 : loss : 0.073794, loss_ce: 0.017563
[00:48:00.032] iteration 6900 : loss : 0.056890, loss_ce: 0.014856
[00:48:00.350] iteration 6901 : loss : 0.061311, loss_ce: 0.010909
[00:48:00.656] iteration 6902 : loss : 0.123398, loss_ce: 0.022293
[00:48:00.962] iteration 6903 : loss : 0.125812, loss_ce: 0.021752
[00:48:01.267] iteration 6904 : loss : 0.062216, loss_ce: 0.028115
[00:48:01.573] iteration 6905 : loss : 0.072201, loss_ce: 0.022145
[00:48:01.873] iteration 6906 : loss : 0.078946, loss_ce: 0.022867
[00:48:02.181] iteration 6907 : loss : 0.120756, loss_ce: 0.020084
[00:48:02.488] iteration 6908 : loss : 0.063126, loss_ce: 0.023495
[00:48:02.798] iteration 6909 : loss : 0.043263, loss_ce: 0.016022
[00:48:03.108] iteration 6910 : loss : 0.066462, loss_ce: 0.016990
[00:48:03.419] iteration 6911 : loss : 0.079561, loss_ce: 0.018418
[00:48:03.730] iteration 6912 : loss : 0.070870, loss_ce: 0.022548
[00:48:04.037] iteration 6913 : loss : 0.140055, loss_ce: 0.012737
[00:48:04.342] iteration 6914 : loss : 0.140748, loss_ce: 0.008927
[00:48:04.648] iteration 6915 : loss : 0.226510, loss_ce: 0.008885
[00:48:04.951] iteration 6916 : loss : 0.067078, loss_ce: 0.021022
[00:48:05.253] iteration 6917 : loss : 0.074587, loss_ce: 0.020664
[00:48:05.555] iteration 6918 : loss : 0.076522, loss_ce: 0.022639
[00:48:05.859] iteration 6919 : loss : 0.040915, loss_ce: 0.011319
[00:48:06.163] iteration 6920 : loss : 0.069978, loss_ce: 0.021399
[00:48:06.481] iteration 6921 : loss : 0.080000, loss_ce: 0.016054
[00:48:06.783] iteration 6922 : loss : 0.067781, loss_ce: 0.019116
[00:48:07.089] iteration 6923 : loss : 0.148815, loss_ce: 0.018360
[00:48:07.397] iteration 6924 : loss : 0.125727, loss_ce: 0.019236
[00:48:07.702] iteration 6925 : loss : 0.101823, loss_ce: 0.027660
[00:48:08.007] iteration 6926 : loss : 0.125406, loss_ce: 0.019645
[00:48:08.313] iteration 6927 : loss : 0.054377, loss_ce: 0.019313
[00:48:08.618] iteration 6928 : loss : 0.284981, loss_ce: 0.007027
[00:48:08.921] iteration 6929 : loss : 0.111130, loss_ce: 0.020927
[00:48:09.222] iteration 6930 : loss : 0.122445, loss_ce: 0.011582
[00:48:09.527] iteration 6931 : loss : 0.116192, loss_ce: 0.022634
[00:48:09.835] iteration 6932 : loss : 0.067110, loss_ce: 0.025645
[00:48:10.141] iteration 6933 : loss : 0.131766, loss_ce: 0.015309
[00:48:10.444] iteration 6934 : loss : 0.071572, loss_ce: 0.014424
[00:48:10.757] iteration 6935 : loss : 0.067386, loss_ce: 0.029685
[00:48:11.066] iteration 6936 : loss : 0.063654, loss_ce: 0.014899
[00:48:11.377] iteration 6937 : loss : 0.075586, loss_ce: 0.024533
[00:48:11.688] iteration 6938 : loss : 0.074776, loss_ce: 0.018941
[00:48:11.989] iteration 6939 : loss : 0.116351, loss_ce: 0.010596
[00:48:12.300] iteration 6940 : loss : 0.118483, loss_ce: 0.010585
[00:48:12.629] iteration 6941 : loss : 0.067491, loss_ce: 0.035408
[00:48:12.935] iteration 6942 : loss : 0.083297, loss_ce: 0.026924
[00:48:13.243] iteration 6943 : loss : 0.091326, loss_ce: 0.018786
[00:48:13.551] iteration 6944 : loss : 0.062155, loss_ce: 0.020300
[00:48:13.857] iteration 6945 : loss : 0.063330, loss_ce: 0.020597
[00:48:14.160] iteration 6946 : loss : 0.081868, loss_ce: 0.013656
[00:48:14.470] iteration 6947 : loss : 0.126810, loss_ce: 0.024346
[00:48:14.777] iteration 6948 : loss : 0.117900, loss_ce: 0.020967
[00:48:15.082] iteration 6949 : loss : 0.050978, loss_ce: 0.014941
[00:48:15.162] iteration 6950 : loss : 0.470971, loss_ce: 0.003142
[00:48:33.801] iteration 6951 : loss : 0.053312, loss_ce: 0.021582
[00:48:34.103] iteration 6952 : loss : 0.085626, loss_ce: 0.020884
[00:48:34.403] iteration 6953 : loss : 0.284183, loss_ce: 0.005496
[00:48:34.709] iteration 6954 : loss : 0.090809, loss_ce: 0.016399
[00:48:35.009] iteration 6955 : loss : 0.067633, loss_ce: 0.012844
[00:48:35.311] iteration 6956 : loss : 0.124855, loss_ce: 0.014625
[00:48:35.615] iteration 6957 : loss : 0.132773, loss_ce: 0.027762
[00:48:35.917] iteration 6958 : loss : 0.070335, loss_ce: 0.014220
[00:48:36.219] iteration 6959 : loss : 0.100521, loss_ce: 0.019637
[00:48:36.523] iteration 6960 : loss : 0.070422, loss_ce: 0.024108
[00:48:36.838] iteration 6961 : loss : 0.071388, loss_ce: 0.014903
[00:48:37.146] iteration 6962 : loss : 0.050680, loss_ce: 0.012114
[00:48:37.448] iteration 6963 : loss : 0.125948, loss_ce: 0.031462
[00:48:37.752] iteration 6964 : loss : 0.063632, loss_ce: 0.025574
[00:48:38.053] iteration 6965 : loss : 0.111925, loss_ce: 0.009641
[00:48:38.360] iteration 6966 : loss : 0.070355, loss_ce: 0.017777
[00:48:38.665] iteration 6967 : loss : 0.106981, loss_ce: 0.014527
[00:48:38.967] iteration 6968 : loss : 0.068450, loss_ce: 0.020287
[00:48:39.270] iteration 6969 : loss : 0.055710, loss_ce: 0.015157
[00:48:39.577] iteration 6970 : loss : 0.108243, loss_ce: 0.020843
[00:48:39.886] iteration 6971 : loss : 0.073013, loss_ce: 0.014275
[00:48:40.187] iteration 6972 : loss : 0.052317, loss_ce: 0.018028
[00:48:40.491] iteration 6973 : loss : 0.066664, loss_ce: 0.023705
[00:48:40.793] iteration 6974 : loss : 0.073105, loss_ce: 0.012903
[00:48:41.092] iteration 6975 : loss : 0.056888, loss_ce: 0.020162
[00:48:41.394] iteration 6976 : loss : 0.093375, loss_ce: 0.018195
[00:48:41.698] iteration 6977 : loss : 0.108965, loss_ce: 0.025262
[00:48:42.000] iteration 6978 : loss : 0.100869, loss_ce: 0.008189
[00:48:42.303] iteration 6979 : loss : 0.066464, loss_ce: 0.019289
[00:48:42.606] iteration 6980 : loss : 0.087826, loss_ce: 0.017896
[00:48:42.924] iteration 6981 : loss : 0.058435, loss_ce: 0.019177
[00:48:43.226] iteration 6982 : loss : 0.082085, loss_ce: 0.027336
[00:48:43.529] iteration 6983 : loss : 0.121623, loss_ce: 0.009715
[00:48:43.832] iteration 6984 : loss : 0.084964, loss_ce: 0.015826
[00:48:44.138] iteration 6985 : loss : 0.061222, loss_ce: 0.019195
[00:48:44.438] iteration 6986 : loss : 0.051102, loss_ce: 0.025412
[00:48:44.743] iteration 6987 : loss : 0.063411, loss_ce: 0.019845
[00:48:45.047] iteration 6988 : loss : 0.058028, loss_ce: 0.014306
[00:48:45.350] iteration 6989 : loss : 0.062988, loss_ce: 0.018710
[00:48:45.653] iteration 6990 : loss : 0.104987, loss_ce: 0.010857
[00:48:45.958] iteration 6991 : loss : 0.069554, loss_ce: 0.024599
[00:48:46.259] iteration 6992 : loss : 0.115084, loss_ce: 0.014346
[00:48:46.561] iteration 6993 : loss : 0.057633, loss_ce: 0.024281
[00:48:46.865] iteration 6994 : loss : 0.165212, loss_ce: 0.014332
[00:48:47.169] iteration 6995 : loss : 0.051138, loss_ce: 0.016884
[00:48:47.473] iteration 6996 : loss : 0.067429, loss_ce: 0.026825
[00:48:47.776] iteration 6997 : loss : 0.076477, loss_ce: 0.023407
[00:48:48.084] iteration 6998 : loss : 0.132676, loss_ce: 0.041365
[00:48:48.390] iteration 6999 : loss : 0.064743, loss_ce: 0.020973
[00:48:48.697] iteration 7000 : loss : 0.297663, loss_ce: 0.004588
[00:48:49.020] iteration 7001 : loss : 0.087544, loss_ce: 0.021165
[00:48:49.323] iteration 7002 : loss : 0.134476, loss_ce: 0.007339
[00:48:49.632] iteration 7003 : loss : 0.117075, loss_ce: 0.014817
[00:48:49.942] iteration 7004 : loss : 0.100554, loss_ce: 0.012344
[00:48:50.249] iteration 7005 : loss : 0.066163, loss_ce: 0.025086
[00:48:50.561] iteration 7006 : loss : 0.112135, loss_ce: 0.016530
[00:48:50.870] iteration 7007 : loss : 0.058002, loss_ce: 0.010201
[00:48:51.179] iteration 7008 : loss : 0.059399, loss_ce: 0.023543
[00:48:51.488] iteration 7009 : loss : 0.123273, loss_ce: 0.013823
[00:48:51.802] iteration 7010 : loss : 0.060336, loss_ce: 0.024265
[00:48:52.114] iteration 7011 : loss : 0.073267, loss_ce: 0.018186
[00:48:52.422] iteration 7012 : loss : 0.141336, loss_ce: 0.023516
[00:48:52.733] iteration 7013 : loss : 0.049108, loss_ce: 0.012105
[00:48:53.042] iteration 7014 : loss : 0.058803, loss_ce: 0.019275
[00:48:53.353] iteration 7015 : loss : 0.074153, loss_ce: 0.018500
[00:48:53.661] iteration 7016 : loss : 0.127110, loss_ce: 0.026061
[00:48:53.974] iteration 7017 : loss : 0.075456, loss_ce: 0.014479
[00:48:54.285] iteration 7018 : loss : 0.057768, loss_ce: 0.022541
[00:48:54.595] iteration 7019 : loss : 0.118723, loss_ce: 0.025972
[00:48:54.904] iteration 7020 : loss : 0.131629, loss_ce: 0.017256
[00:48:55.234] iteration 7021 : loss : 0.058020, loss_ce: 0.020761
[00:48:55.541] iteration 7022 : loss : 0.055605, loss_ce: 0.013796
[00:48:55.851] iteration 7023 : loss : 0.074498, loss_ce: 0.011668
[00:48:56.157] iteration 7024 : loss : 0.064132, loss_ce: 0.019523
[00:48:56.467] iteration 7025 : loss : 0.069309, loss_ce: 0.016134
[00:48:56.780] iteration 7026 : loss : 0.077407, loss_ce: 0.014404
[00:48:57.095] iteration 7027 : loss : 0.067401, loss_ce: 0.034602
[00:48:57.405] iteration 7028 : loss : 0.055008, loss_ce: 0.009562
[00:48:57.716] iteration 7029 : loss : 0.074465, loss_ce: 0.017652
[00:48:58.025] iteration 7030 : loss : 0.062446, loss_ce: 0.027570
[00:48:58.334] iteration 7031 : loss : 0.075707, loss_ce: 0.033049
[00:48:58.645] iteration 7032 : loss : 0.067125, loss_ce: 0.031515
[00:48:58.953] iteration 7033 : loss : 0.085099, loss_ce: 0.010762
[00:48:59.269] iteration 7034 : loss : 0.054207, loss_ce: 0.011182
[00:48:59.581] iteration 7035 : loss : 0.085666, loss_ce: 0.032797
[00:48:59.894] iteration 7036 : loss : 0.106691, loss_ce: 0.021787
[00:49:00.203] iteration 7037 : loss : 0.059774, loss_ce: 0.025286
[00:49:00.517] iteration 7038 : loss : 0.056104, loss_ce: 0.015169
[00:49:00.830] iteration 7039 : loss : 0.119127, loss_ce: 0.013856
[00:49:01.136] iteration 7040 : loss : 0.059896, loss_ce: 0.026106
[00:49:01.462] iteration 7041 : loss : 0.077564, loss_ce: 0.008625
[00:49:01.771] iteration 7042 : loss : 0.070207, loss_ce: 0.017667
[00:49:02.085] iteration 7043 : loss : 0.085004, loss_ce: 0.023004
[00:49:02.397] iteration 7044 : loss : 0.124224, loss_ce: 0.016188
[00:49:02.710] iteration 7045 : loss : 0.064473, loss_ce: 0.026557
[00:49:03.020] iteration 7046 : loss : 0.119330, loss_ce: 0.018013
[00:49:03.330] iteration 7047 : loss : 0.065755, loss_ce: 0.023111
[00:49:03.638] iteration 7048 : loss : 0.082623, loss_ce: 0.033389
[00:49:03.950] iteration 7049 : loss : 0.072970, loss_ce: 0.020592
[00:49:04.262] iteration 7050 : loss : 0.053322, loss_ce: 0.014542
[00:49:04.573] iteration 7051 : loss : 0.111628, loss_ce: 0.014580
[00:49:04.879] iteration 7052 : loss : 0.153223, loss_ce: 0.012922
[00:49:05.192] iteration 7053 : loss : 0.061825, loss_ce: 0.021435
[00:49:05.503] iteration 7054 : loss : 0.051783, loss_ce: 0.015906
[00:49:05.812] iteration 7055 : loss : 0.064552, loss_ce: 0.021987
[00:49:06.124] iteration 7056 : loss : 0.070647, loss_ce: 0.032551
[00:49:06.433] iteration 7057 : loss : 0.065322, loss_ce: 0.014021
[00:49:06.743] iteration 7058 : loss : 0.049408, loss_ce: 0.011779
[00:49:07.055] iteration 7059 : loss : 0.052765, loss_ce: 0.015560
[00:49:07.363] iteration 7060 : loss : 0.065653, loss_ce: 0.018218
[00:49:07.690] iteration 7061 : loss : 0.063580, loss_ce: 0.024050
[00:49:08.000] iteration 7062 : loss : 0.059915, loss_ce: 0.017340
[00:49:08.310] iteration 7063 : loss : 0.128650, loss_ce: 0.029129
[00:49:08.621] iteration 7064 : loss : 0.123126, loss_ce: 0.008938
[00:49:08.937] iteration 7065 : loss : 0.064949, loss_ce: 0.021964
[00:49:09.244] iteration 7066 : loss : 0.113726, loss_ce: 0.016602
[00:49:09.545] iteration 7067 : loss : 0.061604, loss_ce: 0.022166
[00:49:09.848] iteration 7068 : loss : 0.074345, loss_ce: 0.034853
[00:49:10.154] iteration 7069 : loss : 0.048467, loss_ce: 0.009305
[00:49:10.457] iteration 7070 : loss : 0.063258, loss_ce: 0.017603
[00:49:10.765] iteration 7071 : loss : 0.113322, loss_ce: 0.017473
[00:49:11.072] iteration 7072 : loss : 0.133460, loss_ce: 0.011034
[00:49:11.383] iteration 7073 : loss : 0.075416, loss_ce: 0.012881
[00:49:11.696] iteration 7074 : loss : 0.063568, loss_ce: 0.016447
[00:49:12.007] iteration 7075 : loss : 0.072823, loss_ce: 0.029848
[00:49:12.310] iteration 7076 : loss : 0.072273, loss_ce: 0.006416
[00:49:12.622] iteration 7077 : loss : 0.066559, loss_ce: 0.022552
[00:49:12.936] iteration 7078 : loss : 0.064438, loss_ce: 0.026011
[00:49:13.245] iteration 7079 : loss : 0.077275, loss_ce: 0.031113
[00:49:13.556] iteration 7080 : loss : 0.075274, loss_ce: 0.014533
[00:49:13.885] iteration 7081 : loss : 0.052163, loss_ce: 0.012019
[00:49:14.190] iteration 7082 : loss : 0.071932, loss_ce: 0.023476
[00:49:14.501] iteration 7083 : loss : 0.056862, loss_ce: 0.013556
[00:49:14.808] iteration 7084 : loss : 0.074973, loss_ce: 0.021223
[00:49:15.116] iteration 7085 : loss : 0.064263, loss_ce: 0.015529
[00:49:15.426] iteration 7086 : loss : 0.089732, loss_ce: 0.024973
[00:49:15.740] iteration 7087 : loss : 0.075279, loss_ce: 0.021478
[00:49:16.045] iteration 7088 : loss : 0.055520, loss_ce: 0.007371
[00:49:16.123] iteration 7089 : loss : 0.463082, loss_ce: 0.000713
[00:49:36.046] iteration 7090 : loss : 0.081728, loss_ce: 0.022367
[00:49:36.346] iteration 7091 : loss : 0.077082, loss_ce: 0.018021
[00:49:36.649] iteration 7092 : loss : 0.177437, loss_ce: 0.005593
[00:49:36.952] iteration 7093 : loss : 0.152686, loss_ce: 0.016016
[00:49:37.260] iteration 7094 : loss : 0.106953, loss_ce: 0.030295
[00:49:37.560] iteration 7095 : loss : 0.051836, loss_ce: 0.020040
[00:49:37.867] iteration 7096 : loss : 0.072018, loss_ce: 0.019696
[00:49:38.171] iteration 7097 : loss : 0.076278, loss_ce: 0.019137
[00:49:38.475] iteration 7098 : loss : 0.059183, loss_ce: 0.020003
[00:49:38.779] iteration 7099 : loss : 0.049175, loss_ce: 0.014619
[00:49:39.086] iteration 7100 : loss : 0.069733, loss_ce: 0.016812
[00:49:39.408] iteration 7101 : loss : 0.057804, loss_ce: 0.022880
[00:49:39.715] iteration 7102 : loss : 0.063679, loss_ce: 0.012992
[00:49:40.022] iteration 7103 : loss : 0.106598, loss_ce: 0.024574
[00:49:40.333] iteration 7104 : loss : 0.120731, loss_ce: 0.008864
[00:49:40.638] iteration 7105 : loss : 0.080518, loss_ce: 0.029257
[00:49:40.944] iteration 7106 : loss : 0.063737, loss_ce: 0.023276
[00:49:41.250] iteration 7107 : loss : 0.086346, loss_ce: 0.023278
[00:49:41.559] iteration 7108 : loss : 0.141944, loss_ce: 0.007161
[00:49:41.866] iteration 7109 : loss : 0.048554, loss_ce: 0.015154
[00:49:42.175] iteration 7110 : loss : 0.117446, loss_ce: 0.021394
[00:49:42.487] iteration 7111 : loss : 0.064011, loss_ce: 0.026300
[00:49:42.796] iteration 7112 : loss : 0.103254, loss_ce: 0.014911
[00:49:43.103] iteration 7113 : loss : 0.114817, loss_ce: 0.017397
[00:49:43.411] iteration 7114 : loss : 0.059494, loss_ce: 0.018228
[00:49:43.722] iteration 7115 : loss : 0.058391, loss_ce: 0.017815
[00:49:44.027] iteration 7116 : loss : 0.057492, loss_ce: 0.014560
[00:49:44.337] iteration 7117 : loss : 0.041871, loss_ce: 0.017251
[00:49:44.649] iteration 7118 : loss : 0.063889, loss_ce: 0.010465
[00:49:44.958] iteration 7119 : loss : 0.066820, loss_ce: 0.018775
[00:49:45.263] iteration 7120 : loss : 0.061450, loss_ce: 0.019186
[00:49:45.587] iteration 7121 : loss : 0.082863, loss_ce: 0.018039
[00:49:45.897] iteration 7122 : loss : 0.124125, loss_ce: 0.013493
[00:49:46.205] iteration 7123 : loss : 0.129332, loss_ce: 0.013989
[00:49:46.508] iteration 7124 : loss : 0.082938, loss_ce: 0.025341
[00:49:46.810] iteration 7125 : loss : 0.094523, loss_ce: 0.013319
[00:49:47.119] iteration 7126 : loss : 0.056514, loss_ce: 0.017737
[00:49:47.424] iteration 7127 : loss : 0.105675, loss_ce: 0.013941
[00:49:47.729] iteration 7128 : loss : 0.067737, loss_ce: 0.031611
[00:49:48.035] iteration 7129 : loss : 0.056211, loss_ce: 0.021528
[00:49:48.340] iteration 7130 : loss : 0.072148, loss_ce: 0.023501
[00:49:48.649] iteration 7131 : loss : 0.068233, loss_ce: 0.013279
[00:49:48.956] iteration 7132 : loss : 0.076545, loss_ce: 0.025618
[00:49:49.264] iteration 7133 : loss : 0.122650, loss_ce: 0.018095
[00:49:49.576] iteration 7134 : loss : 0.072526, loss_ce: 0.019832
[00:49:49.883] iteration 7135 : loss : 0.078424, loss_ce: 0.033053
[00:49:50.193] iteration 7136 : loss : 0.066149, loss_ce: 0.029387
[00:49:50.498] iteration 7137 : loss : 0.064007, loss_ce: 0.018706
[00:49:50.809] iteration 7138 : loss : 0.071114, loss_ce: 0.023829
[00:49:51.116] iteration 7139 : loss : 0.060546, loss_ce: 0.024148
[00:49:51.427] iteration 7140 : loss : 0.070247, loss_ce: 0.031579
[00:49:51.751] iteration 7141 : loss : 0.059096, loss_ce: 0.009907
[00:49:52.057] iteration 7142 : loss : 0.089698, loss_ce: 0.019689
[00:49:52.365] iteration 7143 : loss : 0.060391, loss_ce: 0.019078
[00:49:52.678] iteration 7144 : loss : 0.065121, loss_ce: 0.015066
[00:49:52.983] iteration 7145 : loss : 0.132380, loss_ce: 0.012516
[00:49:53.295] iteration 7146 : loss : 0.088258, loss_ce: 0.018386
[00:49:53.606] iteration 7147 : loss : 0.140070, loss_ce: 0.018647
[00:49:53.913] iteration 7148 : loss : 0.057997, loss_ce: 0.018861
[00:49:54.219] iteration 7149 : loss : 0.061901, loss_ce: 0.014063
[00:49:54.526] iteration 7150 : loss : 0.050458, loss_ce: 0.021728
[00:49:54.835] iteration 7151 : loss : 0.068189, loss_ce: 0.014566
[00:49:55.142] iteration 7152 : loss : 0.066103, loss_ce: 0.015946
[00:49:55.450] iteration 7153 : loss : 0.113576, loss_ce: 0.013312
[00:49:55.755] iteration 7154 : loss : 0.060881, loss_ce: 0.021460
[00:49:56.061] iteration 7155 : loss : 0.071822, loss_ce: 0.029390
[00:49:56.369] iteration 7156 : loss : 0.102468, loss_ce: 0.024719
[00:49:56.676] iteration 7157 : loss : 0.076025, loss_ce: 0.020248
[00:49:56.983] iteration 7158 : loss : 0.068878, loss_ce: 0.017238
[00:49:57.292] iteration 7159 : loss : 0.126644, loss_ce: 0.019863
[00:49:57.600] iteration 7160 : loss : 0.057708, loss_ce: 0.011434
[00:49:57.927] iteration 7161 : loss : 0.057265, loss_ce: 0.021444
[00:49:58.236] iteration 7162 : loss : 0.061681, loss_ce: 0.029834
[00:49:58.546] iteration 7163 : loss : 0.068466, loss_ce: 0.019013
[00:49:58.854] iteration 7164 : loss : 0.080408, loss_ce: 0.013476
[00:49:59.164] iteration 7165 : loss : 0.068127, loss_ce: 0.017442
[00:49:59.467] iteration 7166 : loss : 0.086005, loss_ce: 0.015013
[00:49:59.775] iteration 7167 : loss : 0.063254, loss_ce: 0.015647
[00:50:00.083] iteration 7168 : loss : 0.063296, loss_ce: 0.020603
[00:50:00.390] iteration 7169 : loss : 0.073374, loss_ce: 0.027962
[00:50:00.698] iteration 7170 : loss : 0.063943, loss_ce: 0.023757
[00:50:01.003] iteration 7171 : loss : 0.061492, loss_ce: 0.028549
[00:50:01.306] iteration 7172 : loss : 0.059798, loss_ce: 0.019271
[00:50:01.612] iteration 7173 : loss : 0.083111, loss_ce: 0.019574
[00:50:01.912] iteration 7174 : loss : 0.063560, loss_ce: 0.021219
[00:50:02.216] iteration 7175 : loss : 0.061295, loss_ce: 0.019115
[00:50:02.522] iteration 7176 : loss : 0.089522, loss_ce: 0.011522
[00:50:02.823] iteration 7177 : loss : 0.041660, loss_ce: 0.013302
[00:50:03.127] iteration 7178 : loss : 0.074371, loss_ce: 0.014369
[00:50:03.430] iteration 7179 : loss : 0.080916, loss_ce: 0.018555
[00:50:03.734] iteration 7180 : loss : 0.063495, loss_ce: 0.020627
[00:50:04.054] iteration 7181 : loss : 0.053307, loss_ce: 0.018057
[00:50:04.358] iteration 7182 : loss : 0.090701, loss_ce: 0.021770
[00:50:04.664] iteration 7183 : loss : 0.057254, loss_ce: 0.011453
[00:50:04.966] iteration 7184 : loss : 0.054796, loss_ce: 0.024848
[00:50:05.270] iteration 7185 : loss : 0.084784, loss_ce: 0.016349
[00:50:05.572] iteration 7186 : loss : 0.229896, loss_ce: 0.012740
[00:50:05.874] iteration 7187 : loss : 0.065365, loss_ce: 0.022533
[00:50:06.178] iteration 7188 : loss : 0.080001, loss_ce: 0.015605
[00:50:06.482] iteration 7189 : loss : 0.065053, loss_ce: 0.018900
[00:50:06.793] iteration 7190 : loss : 0.092163, loss_ce: 0.017300
[00:50:07.099] iteration 7191 : loss : 0.091996, loss_ce: 0.009238
[00:50:07.404] iteration 7192 : loss : 0.122740, loss_ce: 0.013309
[00:50:07.708] iteration 7193 : loss : 0.079472, loss_ce: 0.024923
[00:50:08.014] iteration 7194 : loss : 0.055142, loss_ce: 0.015565
[00:50:08.316] iteration 7195 : loss : 0.074216, loss_ce: 0.031736
[00:50:08.618] iteration 7196 : loss : 0.066099, loss_ce: 0.025862
[00:50:08.925] iteration 7197 : loss : 0.056127, loss_ce: 0.024773
[00:50:09.227] iteration 7198 : loss : 0.090757, loss_ce: 0.023617
[00:50:09.534] iteration 7199 : loss : 0.071712, loss_ce: 0.013547
[00:50:09.839] iteration 7200 : loss : 0.059667, loss_ce: 0.019782
[00:50:10.159] iteration 7201 : loss : 0.076947, loss_ce: 0.022977
[00:50:10.465] iteration 7202 : loss : 0.074581, loss_ce: 0.022539
[00:50:10.773] iteration 7203 : loss : 0.105390, loss_ce: 0.013908
[00:50:11.078] iteration 7204 : loss : 0.108443, loss_ce: 0.015548
[00:50:11.384] iteration 7205 : loss : 0.116280, loss_ce: 0.013957
[00:50:11.692] iteration 7206 : loss : 0.066457, loss_ce: 0.023078
[00:50:11.997] iteration 7207 : loss : 0.113569, loss_ce: 0.013990
[00:50:12.302] iteration 7208 : loss : 0.065948, loss_ce: 0.010619
[00:50:12.608] iteration 7209 : loss : 0.054347, loss_ce: 0.016879
[00:50:12.920] iteration 7210 : loss : 0.099942, loss_ce: 0.013422
[00:50:13.233] iteration 7211 : loss : 0.120672, loss_ce: 0.013290
[00:50:13.545] iteration 7212 : loss : 0.050754, loss_ce: 0.022582
[00:50:13.857] iteration 7213 : loss : 0.069997, loss_ce: 0.020392
[00:50:14.166] iteration 7214 : loss : 0.162964, loss_ce: 0.008867
[00:50:14.476] iteration 7215 : loss : 0.072350, loss_ce: 0.027211
[00:50:14.788] iteration 7216 : loss : 0.059452, loss_ce: 0.026968
[00:50:15.101] iteration 7217 : loss : 0.115131, loss_ce: 0.020347
[00:50:15.407] iteration 7218 : loss : 0.063528, loss_ce: 0.028524
[00:50:15.718] iteration 7219 : loss : 0.116955, loss_ce: 0.014438
[00:50:16.029] iteration 7220 : loss : 0.063128, loss_ce: 0.013215
[00:50:16.349] iteration 7221 : loss : 0.055698, loss_ce: 0.009853
[00:50:16.655] iteration 7222 : loss : 0.085367, loss_ce: 0.012665
[00:50:16.970] iteration 7223 : loss : 0.114406, loss_ce: 0.010182
[00:50:17.275] iteration 7224 : loss : 0.108156, loss_ce: 0.012437
[00:50:17.578] iteration 7225 : loss : 0.061232, loss_ce: 0.019828
[00:50:17.890] iteration 7226 : loss : 0.075585, loss_ce: 0.023920
[00:50:18.205] iteration 7227 : loss : 0.089447, loss_ce: 0.023289
[00:50:18.283] iteration 7228 : loss : 0.174936, loss_ce: 0.017867
[00:50:37.130] iteration 7229 : loss : 0.057162, loss_ce: 0.012541
[00:50:37.431] iteration 7230 : loss : 0.064707, loss_ce: 0.028827
[00:50:37.733] iteration 7231 : loss : 0.285009, loss_ce: 0.009417
[00:50:38.034] iteration 7232 : loss : 0.140249, loss_ce: 0.013044
[00:50:38.333] iteration 7233 : loss : 0.082374, loss_ce: 0.017318
[00:50:38.633] iteration 7234 : loss : 0.059088, loss_ce: 0.015006
[00:50:38.935] iteration 7235 : loss : 0.118322, loss_ce: 0.013992
[00:50:39.237] iteration 7236 : loss : 0.064503, loss_ce: 0.019569
[00:50:39.540] iteration 7237 : loss : 0.166338, loss_ce: 0.012147
[00:50:39.843] iteration 7238 : loss : 0.099975, loss_ce: 0.031748
[00:50:40.149] iteration 7239 : loss : 0.127580, loss_ce: 0.026104
[00:50:40.450] iteration 7240 : loss : 0.063050, loss_ce: 0.025825
[00:50:40.770] iteration 7241 : loss : 0.046865, loss_ce: 0.014672
[00:50:41.074] iteration 7242 : loss : 0.170702, loss_ce: 0.012366
[00:50:41.379] iteration 7243 : loss : 0.077869, loss_ce: 0.039551
[00:50:41.684] iteration 7244 : loss : 0.064324, loss_ce: 0.017324
[00:50:41.988] iteration 7245 : loss : 0.055092, loss_ce: 0.023433
[00:50:42.294] iteration 7246 : loss : 0.064974, loss_ce: 0.019728
[00:50:42.602] iteration 7247 : loss : 0.053611, loss_ce: 0.016660
[00:50:42.906] iteration 7248 : loss : 0.067885, loss_ce: 0.023150
[00:50:43.216] iteration 7249 : loss : 0.060069, loss_ce: 0.009037
[00:50:43.519] iteration 7250 : loss : 0.051235, loss_ce: 0.007834
[00:50:43.826] iteration 7251 : loss : 0.095508, loss_ce: 0.012951
[00:50:44.130] iteration 7252 : loss : 0.057977, loss_ce: 0.022105
[00:50:44.434] iteration 7253 : loss : 0.126306, loss_ce: 0.009779
[00:50:44.737] iteration 7254 : loss : 0.116569, loss_ce: 0.014050
[00:50:45.044] iteration 7255 : loss : 0.135724, loss_ce: 0.022939
[00:50:45.348] iteration 7256 : loss : 0.110046, loss_ce: 0.012614
[00:50:45.655] iteration 7257 : loss : 0.058052, loss_ce: 0.019925
[00:50:45.966] iteration 7258 : loss : 0.111783, loss_ce: 0.019865
[00:50:46.271] iteration 7259 : loss : 0.067675, loss_ce: 0.027826
[00:50:46.581] iteration 7260 : loss : 0.077649, loss_ce: 0.040975
[00:50:46.902] iteration 7261 : loss : 0.127146, loss_ce: 0.016506
[00:50:47.206] iteration 7262 : loss : 0.075197, loss_ce: 0.021744
[00:50:47.515] iteration 7263 : loss : 0.055311, loss_ce: 0.024576
[00:50:47.820] iteration 7264 : loss : 0.061333, loss_ce: 0.020122
[00:50:48.125] iteration 7265 : loss : 0.064103, loss_ce: 0.021827
[00:50:48.430] iteration 7266 : loss : 0.241296, loss_ce: 0.016836
[00:50:48.737] iteration 7267 : loss : 0.056343, loss_ce: 0.014725
[00:50:49.049] iteration 7268 : loss : 0.120106, loss_ce: 0.012263
[00:50:49.357] iteration 7269 : loss : 0.072570, loss_ce: 0.013328
[00:50:49.665] iteration 7270 : loss : 0.123542, loss_ce: 0.008196
[00:50:49.971] iteration 7271 : loss : 0.071792, loss_ce: 0.018740
[00:50:50.282] iteration 7272 : loss : 0.124477, loss_ce: 0.025251
[00:50:50.591] iteration 7273 : loss : 0.071335, loss_ce: 0.025703
[00:50:50.901] iteration 7274 : loss : 0.088616, loss_ce: 0.013346
[00:50:51.210] iteration 7275 : loss : 0.064795, loss_ce: 0.016112
[00:50:51.520] iteration 7276 : loss : 0.074651, loss_ce: 0.027413
[00:50:51.829] iteration 7277 : loss : 0.087634, loss_ce: 0.021783
[00:50:52.141] iteration 7278 : loss : 0.065638, loss_ce: 0.015426
[00:50:52.453] iteration 7279 : loss : 0.050156, loss_ce: 0.011203
[00:50:52.763] iteration 7280 : loss : 0.069380, loss_ce: 0.011242
[00:50:53.088] iteration 7281 : loss : 0.061613, loss_ce: 0.010608
[00:50:53.397] iteration 7282 : loss : 0.064039, loss_ce: 0.010605
[00:50:53.704] iteration 7283 : loss : 0.058396, loss_ce: 0.019586
[00:50:54.014] iteration 7284 : loss : 0.109908, loss_ce: 0.015409
[00:50:54.325] iteration 7285 : loss : 0.068549, loss_ce: 0.026444
[00:50:54.634] iteration 7286 : loss : 0.119531, loss_ce: 0.007424
[00:50:54.940] iteration 7287 : loss : 0.055160, loss_ce: 0.023759
[00:50:55.255] iteration 7288 : loss : 0.087318, loss_ce: 0.032987
[00:50:55.567] iteration 7289 : loss : 0.140700, loss_ce: 0.006713
[00:50:55.875] iteration 7290 : loss : 0.052783, loss_ce: 0.018228
[00:50:56.183] iteration 7291 : loss : 0.050989, loss_ce: 0.027297
[00:50:56.493] iteration 7292 : loss : 0.116341, loss_ce: 0.010996
[00:50:56.800] iteration 7293 : loss : 0.118865, loss_ce: 0.009862
[00:50:57.111] iteration 7294 : loss : 0.125517, loss_ce: 0.017885
[00:50:57.422] iteration 7295 : loss : 0.184681, loss_ce: 0.009144
[00:50:57.730] iteration 7296 : loss : 0.067716, loss_ce: 0.014493
[00:50:58.042] iteration 7297 : loss : 0.072554, loss_ce: 0.024263
[00:50:58.353] iteration 7298 : loss : 0.083823, loss_ce: 0.026545
[00:50:58.662] iteration 7299 : loss : 0.062905, loss_ce: 0.018715
[00:50:58.974] iteration 7300 : loss : 0.049885, loss_ce: 0.009032
[00:50:59.295] iteration 7301 : loss : 0.227491, loss_ce: 0.007063
[00:50:59.602] iteration 7302 : loss : 0.068156, loss_ce: 0.020438
[00:50:59.911] iteration 7303 : loss : 0.147061, loss_ce: 0.019646
[00:51:00.219] iteration 7304 : loss : 0.112146, loss_ce: 0.028354
[00:51:00.529] iteration 7305 : loss : 0.112188, loss_ce: 0.022235
[00:51:00.841] iteration 7306 : loss : 0.058559, loss_ce: 0.025952
[00:51:01.148] iteration 7307 : loss : 0.058915, loss_ce: 0.026059
[00:51:01.460] iteration 7308 : loss : 0.122467, loss_ce: 0.023380
[00:51:01.770] iteration 7309 : loss : 0.079434, loss_ce: 0.031649
[00:51:02.077] iteration 7310 : loss : 0.065411, loss_ce: 0.029305
[00:51:02.393] iteration 7311 : loss : 0.072899, loss_ce: 0.015399
[00:51:02.703] iteration 7312 : loss : 0.072383, loss_ce: 0.027835
[00:51:03.010] iteration 7313 : loss : 0.062650, loss_ce: 0.022839
[00:51:03.323] iteration 7314 : loss : 0.100849, loss_ce: 0.022676
[00:51:03.631] iteration 7315 : loss : 0.055577, loss_ce: 0.018952
[00:51:03.941] iteration 7316 : loss : 0.136557, loss_ce: 0.010329
[00:51:04.248] iteration 7317 : loss : 0.058444, loss_ce: 0.022292
[00:51:04.552] iteration 7318 : loss : 0.111364, loss_ce: 0.021882
[00:51:04.856] iteration 7319 : loss : 0.123272, loss_ce: 0.008171
[00:51:05.163] iteration 7320 : loss : 0.131138, loss_ce: 0.010040
[00:51:05.482] iteration 7321 : loss : 0.061522, loss_ce: 0.013703
[00:51:05.789] iteration 7322 : loss : 0.062286, loss_ce: 0.017177
[00:51:06.093] iteration 7323 : loss : 0.050294, loss_ce: 0.018379
[00:51:06.395] iteration 7324 : loss : 0.080292, loss_ce: 0.022903
[00:51:06.700] iteration 7325 : loss : 0.069076, loss_ce: 0.029332
[00:51:07.001] iteration 7326 : loss : 0.056786, loss_ce: 0.013082
[00:51:07.307] iteration 7327 : loss : 0.134952, loss_ce: 0.009108
[00:51:07.612] iteration 7328 : loss : 0.076474, loss_ce: 0.032460
[00:51:07.920] iteration 7329 : loss : 0.065757, loss_ce: 0.021239
[00:51:08.226] iteration 7330 : loss : 0.073137, loss_ce: 0.028032
[00:51:08.531] iteration 7331 : loss : 0.063641, loss_ce: 0.020558
[00:51:08.837] iteration 7332 : loss : 0.062891, loss_ce: 0.018572
[00:51:09.145] iteration 7333 : loss : 0.102073, loss_ce: 0.017320
[00:51:09.450] iteration 7334 : loss : 0.064551, loss_ce: 0.011791
[00:51:09.753] iteration 7335 : loss : 0.346050, loss_ce: 0.001137
[00:51:10.059] iteration 7336 : loss : 0.063778, loss_ce: 0.018696
[00:51:10.368] iteration 7337 : loss : 0.059111, loss_ce: 0.032445
[00:51:10.675] iteration 7338 : loss : 0.092674, loss_ce: 0.021940
[00:51:10.976] iteration 7339 : loss : 0.058245, loss_ce: 0.018578
[00:51:11.280] iteration 7340 : loss : 0.063390, loss_ce: 0.017459
[00:51:11.603] iteration 7341 : loss : 0.059686, loss_ce: 0.023008
[00:51:11.907] iteration 7342 : loss : 0.068466, loss_ce: 0.020421
[00:51:12.213] iteration 7343 : loss : 0.083879, loss_ce: 0.022888
[00:51:12.518] iteration 7344 : loss : 0.068891, loss_ce: 0.021030
[00:51:12.824] iteration 7345 : loss : 0.073011, loss_ce: 0.019718
[00:51:13.131] iteration 7346 : loss : 0.038559, loss_ce: 0.013359
[00:51:13.437] iteration 7347 : loss : 0.121023, loss_ce: 0.008753
[00:51:13.739] iteration 7348 : loss : 0.082033, loss_ce: 0.007048
[00:51:14.043] iteration 7349 : loss : 0.114690, loss_ce: 0.019331
[00:51:14.347] iteration 7350 : loss : 0.059503, loss_ce: 0.012831
[00:51:14.661] iteration 7351 : loss : 0.175404, loss_ce: 0.010808
[00:51:14.974] iteration 7352 : loss : 0.120530, loss_ce: 0.004893
[00:51:15.286] iteration 7353 : loss : 0.058491, loss_ce: 0.025074
[00:51:15.596] iteration 7354 : loss : 0.070273, loss_ce: 0.023803
[00:51:15.903] iteration 7355 : loss : 0.074787, loss_ce: 0.017553
[00:51:16.210] iteration 7356 : loss : 0.095104, loss_ce: 0.026479
[00:51:16.515] iteration 7357 : loss : 0.126002, loss_ce: 0.029930
[00:51:16.829] iteration 7358 : loss : 0.071378, loss_ce: 0.024557
[00:51:17.143] iteration 7359 : loss : 0.078151, loss_ce: 0.029818
[00:51:17.450] iteration 7360 : loss : 0.074367, loss_ce: 0.023713
[00:51:17.779] iteration 7361 : loss : 0.062906, loss_ce: 0.018931
[00:51:18.093] iteration 7362 : loss : 0.087166, loss_ce: 0.026749
[00:51:18.409] iteration 7363 : loss : 0.051148, loss_ce: 0.019136
[00:51:18.720] iteration 7364 : loss : 0.063053, loss_ce: 0.020392
[00:51:19.034] iteration 7365 : loss : 0.078366, loss_ce: 0.025189
[00:51:19.347] iteration 7366 : loss : 0.098300, loss_ce: 0.013074
[00:51:19.432] iteration 7367 : loss : 0.140162, loss_ce: 0.022487
[00:51:37.547] iteration 7368 : loss : 0.065873, loss_ce: 0.012026
[00:51:37.849] iteration 7369 : loss : 0.063864, loss_ce: 0.016516
[00:51:38.149] iteration 7370 : loss : 0.055987, loss_ce: 0.015106
[00:51:38.453] iteration 7371 : loss : 0.057362, loss_ce: 0.021591
[00:51:38.755] iteration 7372 : loss : 0.082806, loss_ce: 0.018640
[00:51:39.059] iteration 7373 : loss : 0.088181, loss_ce: 0.023125
[00:51:39.359] iteration 7374 : loss : 0.059590, loss_ce: 0.010285
[00:51:39.660] iteration 7375 : loss : 0.135352, loss_ce: 0.014281
[00:51:39.968] iteration 7376 : loss : 0.061420, loss_ce: 0.024587
[00:51:40.275] iteration 7377 : loss : 0.057719, loss_ce: 0.012748
[00:51:40.578] iteration 7378 : loss : 0.176323, loss_ce: 0.017085
[00:51:40.881] iteration 7379 : loss : 0.061542, loss_ce: 0.018376
[00:51:41.185] iteration 7380 : loss : 0.090668, loss_ce: 0.020707
[00:51:41.503] iteration 7381 : loss : 0.073258, loss_ce: 0.013227
[00:51:41.803] iteration 7382 : loss : 0.060026, loss_ce: 0.023243
[00:51:42.107] iteration 7383 : loss : 0.066351, loss_ce: 0.024086
[00:51:42.410] iteration 7384 : loss : 0.094596, loss_ce: 0.019336
[00:51:42.712] iteration 7385 : loss : 0.065773, loss_ce: 0.014113
[00:51:43.015] iteration 7386 : loss : 0.068159, loss_ce: 0.014120
[00:51:43.319] iteration 7387 : loss : 0.063455, loss_ce: 0.023515
[00:51:43.620] iteration 7388 : loss : 0.055032, loss_ce: 0.016203
[00:51:43.924] iteration 7389 : loss : 0.119742, loss_ce: 0.013105
[00:51:44.227] iteration 7390 : loss : 0.120349, loss_ce: 0.010521
[00:51:44.531] iteration 7391 : loss : 0.057786, loss_ce: 0.019120
[00:51:44.833] iteration 7392 : loss : 0.154888, loss_ce: 0.014865
[00:51:45.134] iteration 7393 : loss : 0.085656, loss_ce: 0.026296
[00:51:45.435] iteration 7394 : loss : 0.058079, loss_ce: 0.019035
[00:51:45.741] iteration 7395 : loss : 0.053732, loss_ce: 0.007936
[00:51:46.048] iteration 7396 : loss : 0.076433, loss_ce: 0.011796
[00:51:46.351] iteration 7397 : loss : 0.064904, loss_ce: 0.023617
[00:51:46.654] iteration 7398 : loss : 0.100509, loss_ce: 0.008585
[00:51:46.956] iteration 7399 : loss : 0.055454, loss_ce: 0.020766
[00:51:47.262] iteration 7400 : loss : 0.120230, loss_ce: 0.027431
[00:51:47.584] iteration 7401 : loss : 0.114154, loss_ce: 0.015118
[00:51:47.890] iteration 7402 : loss : 0.040175, loss_ce: 0.011723
[00:51:48.194] iteration 7403 : loss : 0.083314, loss_ce: 0.018116
[00:51:48.497] iteration 7404 : loss : 0.093063, loss_ce: 0.021311
[00:51:48.798] iteration 7405 : loss : 0.085777, loss_ce: 0.020047
[00:51:49.106] iteration 7406 : loss : 0.053253, loss_ce: 0.028464
[00:51:49.409] iteration 7407 : loss : 0.107201, loss_ce: 0.013974
[00:51:49.714] iteration 7408 : loss : 0.056303, loss_ce: 0.023744
[00:51:50.026] iteration 7409 : loss : 0.067346, loss_ce: 0.026128
[00:51:50.329] iteration 7410 : loss : 0.071731, loss_ce: 0.014574
[00:51:50.636] iteration 7411 : loss : 0.071451, loss_ce: 0.028175
[00:51:50.944] iteration 7412 : loss : 0.054893, loss_ce: 0.021634
[00:51:51.255] iteration 7413 : loss : 0.088845, loss_ce: 0.022128
[00:51:51.562] iteration 7414 : loss : 0.051910, loss_ce: 0.016596
[00:51:51.870] iteration 7415 : loss : 0.071301, loss_ce: 0.024156
[00:51:52.179] iteration 7416 : loss : 0.057881, loss_ce: 0.014924
[00:51:52.486] iteration 7417 : loss : 0.063269, loss_ce: 0.017222
[00:51:52.793] iteration 7418 : loss : 0.053282, loss_ce: 0.021815
[00:51:53.106] iteration 7419 : loss : 0.163764, loss_ce: 0.018597
[00:51:53.416] iteration 7420 : loss : 0.070648, loss_ce: 0.017614
[00:51:53.741] iteration 7421 : loss : 0.137441, loss_ce: 0.013191
[00:51:54.047] iteration 7422 : loss : 0.081529, loss_ce: 0.007293
[00:51:54.357] iteration 7423 : loss : 0.051651, loss_ce: 0.020341
[00:51:54.669] iteration 7424 : loss : 0.127618, loss_ce: 0.011472
[00:51:54.976] iteration 7425 : loss : 0.063402, loss_ce: 0.019890
[00:51:55.281] iteration 7426 : loss : 0.069896, loss_ce: 0.020907
[00:51:55.586] iteration 7427 : loss : 0.065604, loss_ce: 0.023951
[00:51:55.892] iteration 7428 : loss : 0.067870, loss_ce: 0.022818
[00:51:56.201] iteration 7429 : loss : 0.062734, loss_ce: 0.023441
[00:51:56.510] iteration 7430 : loss : 0.059177, loss_ce: 0.021768
[00:51:56.817] iteration 7431 : loss : 0.076310, loss_ce: 0.016537
[00:51:57.126] iteration 7432 : loss : 0.064596, loss_ce: 0.015510
[00:51:57.430] iteration 7433 : loss : 0.063481, loss_ce: 0.026192
[00:51:57.742] iteration 7434 : loss : 0.072829, loss_ce: 0.016726
[00:51:58.049] iteration 7435 : loss : 0.057560, loss_ce: 0.015821
[00:51:58.360] iteration 7436 : loss : 0.115345, loss_ce: 0.013531
[00:51:58.667] iteration 7437 : loss : 0.061790, loss_ce: 0.016907
[00:51:58.979] iteration 7438 : loss : 0.057969, loss_ce: 0.024586
[00:51:59.285] iteration 7439 : loss : 0.067662, loss_ce: 0.025658
[00:51:59.589] iteration 7440 : loss : 0.057144, loss_ce: 0.022154
[00:51:59.911] iteration 7441 : loss : 0.064921, loss_ce: 0.021286
[00:52:00.220] iteration 7442 : loss : 0.051755, loss_ce: 0.010720
[00:52:00.527] iteration 7443 : loss : 0.070972, loss_ce: 0.018656
[00:52:00.835] iteration 7444 : loss : 0.078160, loss_ce: 0.014045
[00:52:01.149] iteration 7445 : loss : 0.052133, loss_ce: 0.014718
[00:52:01.456] iteration 7446 : loss : 0.061420, loss_ce: 0.021182
[00:52:01.767] iteration 7447 : loss : 0.077782, loss_ce: 0.023088
[00:52:02.074] iteration 7448 : loss : 0.055060, loss_ce: 0.009647
[00:52:02.384] iteration 7449 : loss : 0.057612, loss_ce: 0.011864
[00:52:02.691] iteration 7450 : loss : 0.110578, loss_ce: 0.010489
[00:52:03.001] iteration 7451 : loss : 0.063759, loss_ce: 0.016690
[00:52:03.306] iteration 7452 : loss : 0.068452, loss_ce: 0.019385
[00:52:03.612] iteration 7453 : loss : 0.104514, loss_ce: 0.014415
[00:52:03.921] iteration 7454 : loss : 0.066897, loss_ce: 0.023480
[00:52:04.229] iteration 7455 : loss : 0.060863, loss_ce: 0.018425
[00:52:04.533] iteration 7456 : loss : 0.130906, loss_ce: 0.011867
[00:52:04.845] iteration 7457 : loss : 0.066899, loss_ce: 0.013238
[00:52:05.153] iteration 7458 : loss : 0.050377, loss_ce: 0.017735
[00:52:05.460] iteration 7459 : loss : 0.059035, loss_ce: 0.017720
[00:52:05.769] iteration 7460 : loss : 0.057801, loss_ce: 0.020480
[00:52:06.096] iteration 7461 : loss : 0.058446, loss_ce: 0.012758
[00:52:06.401] iteration 7462 : loss : 0.124950, loss_ce: 0.020859
[00:52:06.712] iteration 7463 : loss : 0.098634, loss_ce: 0.020129
[00:52:07.019] iteration 7464 : loss : 0.065694, loss_ce: 0.017762
[00:52:07.326] iteration 7465 : loss : 0.119144, loss_ce: 0.015265
[00:52:07.636] iteration 7466 : loss : 0.051676, loss_ce: 0.016896
[00:52:07.948] iteration 7467 : loss : 0.051112, loss_ce: 0.011673
[00:52:08.253] iteration 7468 : loss : 0.105985, loss_ce: 0.017972
[00:52:08.562] iteration 7469 : loss : 0.074935, loss_ce: 0.021672
[00:52:08.869] iteration 7470 : loss : 0.059888, loss_ce: 0.014530
[00:52:09.175] iteration 7471 : loss : 0.067645, loss_ce: 0.019734
[00:52:09.479] iteration 7472 : loss : 0.069316, loss_ce: 0.030863
[00:52:09.783] iteration 7473 : loss : 0.176327, loss_ce: 0.014409
[00:52:10.088] iteration 7474 : loss : 0.109334, loss_ce: 0.010520
[00:52:10.393] iteration 7475 : loss : 0.095987, loss_ce: 0.022245
[00:52:10.697] iteration 7476 : loss : 0.075511, loss_ce: 0.025379
[00:52:11.001] iteration 7477 : loss : 0.164314, loss_ce: 0.016982
[00:52:11.304] iteration 7478 : loss : 0.086653, loss_ce: 0.027153
[00:52:11.611] iteration 7479 : loss : 0.058588, loss_ce: 0.006948
[00:52:11.913] iteration 7480 : loss : 0.071865, loss_ce: 0.034588
[00:52:12.229] iteration 7481 : loss : 0.063555, loss_ce: 0.013665
[00:52:12.534] iteration 7482 : loss : 0.068479, loss_ce: 0.019732
[00:52:12.839] iteration 7483 : loss : 0.091171, loss_ce: 0.026014
[00:52:13.144] iteration 7484 : loss : 0.115121, loss_ce: 0.017993
[00:52:13.449] iteration 7485 : loss : 0.058970, loss_ce: 0.027949
[00:52:13.757] iteration 7486 : loss : 0.242725, loss_ce: 0.008236
[00:52:14.063] iteration 7487 : loss : 0.071234, loss_ce: 0.029389
[00:52:14.363] iteration 7488 : loss : 0.059892, loss_ce: 0.017173
[00:52:14.664] iteration 7489 : loss : 0.070991, loss_ce: 0.019911
[00:52:14.972] iteration 7490 : loss : 0.129541, loss_ce: 0.023129
[00:52:15.281] iteration 7491 : loss : 0.065223, loss_ce: 0.013431
[00:52:15.586] iteration 7492 : loss : 0.069204, loss_ce: 0.014137
[00:52:15.895] iteration 7493 : loss : 0.115753, loss_ce: 0.019471
[00:52:16.202] iteration 7494 : loss : 0.072637, loss_ce: 0.033109
[00:52:16.503] iteration 7495 : loss : 0.061915, loss_ce: 0.019088
[00:52:16.810] iteration 7496 : loss : 0.112926, loss_ce: 0.008760
[00:52:17.117] iteration 7497 : loss : 0.065760, loss_ce: 0.018003
[00:52:17.427] iteration 7498 : loss : 0.115981, loss_ce: 0.012381
[00:52:17.735] iteration 7499 : loss : 0.067895, loss_ce: 0.023841
[00:52:18.047] iteration 7500 : loss : 0.070265, loss_ce: 0.018504
[00:52:18.388] iteration 7501 : loss : 0.066652, loss_ce: 0.023320
[00:52:18.689] iteration 7502 : loss : 0.122203, loss_ce: 0.023781
[00:52:18.995] iteration 7503 : loss : 0.297104, loss_ce: 0.008233
[00:52:19.307] iteration 7504 : loss : 0.112413, loss_ce: 0.017722
[00:52:19.618] iteration 7505 : loss : 0.055893, loss_ce: 0.023934
[00:52:19.699] iteration 7506 : loss : 0.400912, loss_ce: 0.000102
[00:52:37.883] iteration 7507 : loss : 0.076424, loss_ce: 0.021616
[00:52:38.189] iteration 7508 : loss : 0.111365, loss_ce: 0.030586
[00:52:38.494] iteration 7509 : loss : 0.141191, loss_ce: 0.037525
[00:52:38.809] iteration 7510 : loss : 0.160865, loss_ce: 0.041679
[00:52:39.115] iteration 7511 : loss : 0.185685, loss_ce: 0.046910
[00:52:39.413] iteration 7512 : loss : 0.306366, loss_ce: 0.016322
[00:52:39.716] iteration 7513 : loss : 0.202519, loss_ce: 0.022552
[00:52:40.020] iteration 7514 : loss : 0.082648, loss_ce: 0.025509
[00:52:40.319] iteration 7515 : loss : 0.142034, loss_ce: 0.014333
[00:52:40.621] iteration 7516 : loss : 0.091927, loss_ce: 0.019719
[00:52:40.926] iteration 7517 : loss : 0.106523, loss_ce: 0.046831
[00:52:41.227] iteration 7518 : loss : 0.133432, loss_ce: 0.036841
[00:52:41.531] iteration 7519 : loss : 0.095840, loss_ce: 0.030135
[00:52:41.835] iteration 7520 : loss : 0.116249, loss_ce: 0.030941
[00:52:42.153] iteration 7521 : loss : 0.109201, loss_ce: 0.021734
[00:52:42.455] iteration 7522 : loss : 0.079076, loss_ce: 0.023721
[00:52:42.757] iteration 7523 : loss : 0.092450, loss_ce: 0.019081
[00:52:43.062] iteration 7524 : loss : 0.097238, loss_ce: 0.038592
[00:52:43.362] iteration 7525 : loss : 0.092922, loss_ce: 0.030767
[00:52:43.666] iteration 7526 : loss : 0.112922, loss_ce: 0.033116
[00:52:43.969] iteration 7527 : loss : 0.089342, loss_ce: 0.021077
[00:52:44.272] iteration 7528 : loss : 0.072386, loss_ce: 0.013344
[00:52:44.574] iteration 7529 : loss : 0.099399, loss_ce: 0.022570
[00:52:44.875] iteration 7530 : loss : 0.113496, loss_ce: 0.046737
[00:52:45.180] iteration 7531 : loss : 0.147002, loss_ce: 0.019359
[00:52:45.481] iteration 7532 : loss : 0.152256, loss_ce: 0.020004
[00:52:45.784] iteration 7533 : loss : 0.078292, loss_ce: 0.023542
[00:52:46.086] iteration 7534 : loss : 0.122945, loss_ce: 0.015370
[00:52:46.389] iteration 7535 : loss : 0.120679, loss_ce: 0.025178
[00:52:46.693] iteration 7536 : loss : 0.133516, loss_ce: 0.020029
[00:52:46.996] iteration 7537 : loss : 0.078687, loss_ce: 0.032770
[00:52:47.302] iteration 7538 : loss : 0.078870, loss_ce: 0.011986
[00:52:47.607] iteration 7539 : loss : 0.076385, loss_ce: 0.023341
[00:52:47.906] iteration 7540 : loss : 0.078373, loss_ce: 0.015146
[00:52:48.228] iteration 7541 : loss : 0.066253, loss_ce: 0.022000
[00:52:48.530] iteration 7542 : loss : 0.116184, loss_ce: 0.011551
[00:52:48.834] iteration 7543 : loss : 0.081887, loss_ce: 0.019970
[00:52:49.133] iteration 7544 : loss : 0.083009, loss_ce: 0.019189
[00:52:49.435] iteration 7545 : loss : 0.064968, loss_ce: 0.017606
[00:52:49.736] iteration 7546 : loss : 0.074964, loss_ce: 0.021958
[00:52:50.039] iteration 7547 : loss : 0.069335, loss_ce: 0.011251
[00:52:50.342] iteration 7548 : loss : 0.060037, loss_ce: 0.018681
[00:52:50.648] iteration 7549 : loss : 0.062195, loss_ce: 0.015529
[00:52:50.957] iteration 7550 : loss : 0.083937, loss_ce: 0.016873
[00:52:51.256] iteration 7551 : loss : 0.064962, loss_ce: 0.020323
[00:52:51.556] iteration 7552 : loss : 0.065412, loss_ce: 0.014577
[00:52:51.864] iteration 7553 : loss : 0.154400, loss_ce: 0.017252
[00:52:52.168] iteration 7554 : loss : 0.086801, loss_ce: 0.022985
[00:52:52.474] iteration 7555 : loss : 0.085391, loss_ce: 0.026157
[00:52:52.784] iteration 7556 : loss : 0.057558, loss_ce: 0.016761
[00:52:53.099] iteration 7557 : loss : 0.091337, loss_ce: 0.035431
[00:52:53.408] iteration 7558 : loss : 0.055127, loss_ce: 0.014131
[00:52:53.716] iteration 7559 : loss : 0.057608, loss_ce: 0.023003
[00:52:54.024] iteration 7560 : loss : 0.081062, loss_ce: 0.019129
[00:52:54.348] iteration 7561 : loss : 0.069905, loss_ce: 0.015207
[00:52:54.654] iteration 7562 : loss : 0.083526, loss_ce: 0.016721
[00:52:54.963] iteration 7563 : loss : 0.074509, loss_ce: 0.023347
[00:52:55.275] iteration 7564 : loss : 0.121150, loss_ce: 0.017383
[00:52:55.581] iteration 7565 : loss : 0.118353, loss_ce: 0.012868
[00:52:55.893] iteration 7566 : loss : 0.137574, loss_ce: 0.027664
[00:52:56.200] iteration 7567 : loss : 0.058351, loss_ce: 0.014671
[00:52:56.513] iteration 7568 : loss : 0.076567, loss_ce: 0.027753
[00:52:56.821] iteration 7569 : loss : 0.071819, loss_ce: 0.025791
[00:52:57.129] iteration 7570 : loss : 0.117162, loss_ce: 0.025258
[00:52:57.435] iteration 7571 : loss : 0.071850, loss_ce: 0.030049
[00:52:57.745] iteration 7572 : loss : 0.062170, loss_ce: 0.025699
[00:52:58.057] iteration 7573 : loss : 0.067983, loss_ce: 0.017538
[00:52:58.369] iteration 7574 : loss : 0.088013, loss_ce: 0.032095
[00:52:58.678] iteration 7575 : loss : 0.071691, loss_ce: 0.018043
[00:52:58.987] iteration 7576 : loss : 0.074161, loss_ce: 0.013094
[00:52:59.301] iteration 7577 : loss : 0.076000, loss_ce: 0.028299
[00:52:59.609] iteration 7578 : loss : 0.345733, loss_ce: 0.004659
[00:52:59.919] iteration 7579 : loss : 0.058938, loss_ce: 0.020826
[00:53:00.226] iteration 7580 : loss : 0.080286, loss_ce: 0.017603
[00:53:00.556] iteration 7581 : loss : 0.137494, loss_ce: 0.007840
[00:53:00.860] iteration 7582 : loss : 0.079110, loss_ce: 0.015276
[00:53:01.174] iteration 7583 : loss : 0.131896, loss_ce: 0.024352
[00:53:01.489] iteration 7584 : loss : 0.084681, loss_ce: 0.022803
[00:53:01.797] iteration 7585 : loss : 0.060217, loss_ce: 0.014628
[00:53:02.108] iteration 7586 : loss : 0.170429, loss_ce: 0.010049
[00:53:02.419] iteration 7587 : loss : 0.066483, loss_ce: 0.025309
[00:53:02.729] iteration 7588 : loss : 0.062495, loss_ce: 0.025751
[00:53:03.041] iteration 7589 : loss : 0.061038, loss_ce: 0.018620
[00:53:03.350] iteration 7590 : loss : 0.081071, loss_ce: 0.028897
[00:53:03.663] iteration 7591 : loss : 0.054414, loss_ce: 0.028117
[00:53:03.969] iteration 7592 : loss : 0.065051, loss_ce: 0.015224
[00:53:04.284] iteration 7593 : loss : 0.168513, loss_ce: 0.009931
[00:53:04.593] iteration 7594 : loss : 0.082301, loss_ce: 0.012773
[00:53:04.906] iteration 7595 : loss : 0.057560, loss_ce: 0.026986
[00:53:05.217] iteration 7596 : loss : 0.071820, loss_ce: 0.012749
[00:53:05.528] iteration 7597 : loss : 0.051236, loss_ce: 0.011367
[00:53:05.839] iteration 7598 : loss : 0.077013, loss_ce: 0.015276
[00:53:06.148] iteration 7599 : loss : 0.096848, loss_ce: 0.017378
[00:53:06.459] iteration 7600 : loss : 0.079666, loss_ce: 0.019545
[00:53:06.783] iteration 7601 : loss : 0.108529, loss_ce: 0.016177
[00:53:07.095] iteration 7602 : loss : 0.069312, loss_ce: 0.028614
[00:53:07.406] iteration 7603 : loss : 0.084950, loss_ce: 0.029559
[00:53:07.716] iteration 7604 : loss : 0.053135, loss_ce: 0.019400
[00:53:08.032] iteration 7605 : loss : 0.053230, loss_ce: 0.022396
[00:53:08.343] iteration 7606 : loss : 0.061898, loss_ce: 0.017128
[00:53:08.652] iteration 7607 : loss : 0.111621, loss_ce: 0.023841
[00:53:08.962] iteration 7608 : loss : 0.120782, loss_ce: 0.021036
[00:53:09.275] iteration 7609 : loss : 0.055456, loss_ce: 0.018137
[00:53:09.585] iteration 7610 : loss : 0.064848, loss_ce: 0.029610
[00:53:09.895] iteration 7611 : loss : 0.084931, loss_ce: 0.015253
[00:53:10.203] iteration 7612 : loss : 0.125200, loss_ce: 0.016265
[00:53:10.513] iteration 7613 : loss : 0.058605, loss_ce: 0.020362
[00:53:10.822] iteration 7614 : loss : 0.110594, loss_ce: 0.014223
[00:53:11.132] iteration 7615 : loss : 0.062485, loss_ce: 0.020366
[00:53:11.442] iteration 7616 : loss : 0.069804, loss_ce: 0.019099
[00:53:11.753] iteration 7617 : loss : 0.100612, loss_ce: 0.029979
[00:53:12.065] iteration 7618 : loss : 0.089437, loss_ce: 0.025708
[00:53:12.378] iteration 7619 : loss : 0.120156, loss_ce: 0.020938
[00:53:12.685] iteration 7620 : loss : 0.079717, loss_ce: 0.013440
[00:53:13.012] iteration 7621 : loss : 0.073530, loss_ce: 0.023739
[00:53:13.325] iteration 7622 : loss : 0.049232, loss_ce: 0.019214
[00:53:13.638] iteration 7623 : loss : 0.055383, loss_ce: 0.017055
[00:53:13.943] iteration 7624 : loss : 0.061565, loss_ce: 0.014508
[00:53:14.251] iteration 7625 : loss : 0.119355, loss_ce: 0.020874
[00:53:14.553] iteration 7626 : loss : 0.057857, loss_ce: 0.022167
[00:53:14.860] iteration 7627 : loss : 0.084944, loss_ce: 0.015001
[00:53:15.165] iteration 7628 : loss : 0.135669, loss_ce: 0.020307
[00:53:15.474] iteration 7629 : loss : 0.113405, loss_ce: 0.021309
[00:53:15.780] iteration 7630 : loss : 0.077694, loss_ce: 0.021549
[00:53:16.089] iteration 7631 : loss : 0.072525, loss_ce: 0.029755
[00:53:16.394] iteration 7632 : loss : 0.074966, loss_ce: 0.026641
[00:53:16.709] iteration 7633 : loss : 0.080186, loss_ce: 0.017993
[00:53:17.024] iteration 7634 : loss : 0.118413, loss_ce: 0.016718
[00:53:17.335] iteration 7635 : loss : 0.071204, loss_ce: 0.025375
[00:53:17.647] iteration 7636 : loss : 0.082865, loss_ce: 0.023085
[00:53:17.956] iteration 7637 : loss : 0.056997, loss_ce: 0.022303
[00:53:18.264] iteration 7638 : loss : 0.069556, loss_ce: 0.024340
[00:53:18.575] iteration 7639 : loss : 0.121257, loss_ce: 0.012315
[00:53:18.886] iteration 7640 : loss : 0.075585, loss_ce: 0.015909
[00:53:19.230] iteration 7641 : loss : 0.084527, loss_ce: 0.019883
[00:53:19.538] iteration 7642 : loss : 0.069993, loss_ce: 0.029921
[00:53:19.849] iteration 7643 : loss : 0.063285, loss_ce: 0.007165
[00:53:20.164] iteration 7644 : loss : 0.119871, loss_ce: 0.017552
[00:53:20.252] iteration 7645 : loss : 0.178541, loss_ce: 0.020620
[00:53:39.716] iteration 7646 : loss : 0.088322, loss_ce: 0.029161
[00:53:40.012] iteration 7647 : loss : 0.067821, loss_ce: 0.029895
[00:53:40.315] iteration 7648 : loss : 0.066036, loss_ce: 0.023735
[00:53:40.616] iteration 7649 : loss : 0.065080, loss_ce: 0.024003
[00:53:40.919] iteration 7650 : loss : 0.067740, loss_ce: 0.021520
[00:53:41.224] iteration 7651 : loss : 0.054718, loss_ce: 0.019913
[00:53:41.527] iteration 7652 : loss : 0.056361, loss_ce: 0.015072
[00:53:41.832] iteration 7653 : loss : 0.066435, loss_ce: 0.014811
[00:53:42.135] iteration 7654 : loss : 0.067678, loss_ce: 0.021041
[00:53:42.443] iteration 7655 : loss : 0.060269, loss_ce: 0.014626
[00:53:42.754] iteration 7656 : loss : 0.063246, loss_ce: 0.011638
[00:53:43.066] iteration 7657 : loss : 0.052459, loss_ce: 0.016569
[00:53:43.374] iteration 7658 : loss : 0.062777, loss_ce: 0.014800
[00:53:43.688] iteration 7659 : loss : 0.122437, loss_ce: 0.018063
[00:53:43.998] iteration 7660 : loss : 0.069893, loss_ce: 0.017754
[00:53:44.315] iteration 7661 : loss : 0.065026, loss_ce: 0.018603
[00:53:44.620] iteration 7662 : loss : 0.108912, loss_ce: 0.014501
[00:53:44.924] iteration 7663 : loss : 0.063255, loss_ce: 0.021003
[00:53:45.229] iteration 7664 : loss : 0.090349, loss_ce: 0.013951
[00:53:45.533] iteration 7665 : loss : 0.056373, loss_ce: 0.012580
[00:53:45.838] iteration 7666 : loss : 0.058478, loss_ce: 0.023572
[00:53:46.144] iteration 7667 : loss : 0.114130, loss_ce: 0.008314
[00:53:46.448] iteration 7668 : loss : 0.062508, loss_ce: 0.016535
[00:53:46.754] iteration 7669 : loss : 0.050918, loss_ce: 0.014125
[00:53:47.056] iteration 7670 : loss : 0.117281, loss_ce: 0.012298
[00:53:47.357] iteration 7671 : loss : 0.133750, loss_ce: 0.033762
[00:53:47.658] iteration 7672 : loss : 0.110551, loss_ce: 0.020540
[00:53:47.961] iteration 7673 : loss : 0.046675, loss_ce: 0.012660
[00:53:48.265] iteration 7674 : loss : 0.055897, loss_ce: 0.014689
[00:53:48.569] iteration 7675 : loss : 0.084425, loss_ce: 0.021395
[00:53:48.875] iteration 7676 : loss : 0.073496, loss_ce: 0.015785
[00:53:49.178] iteration 7677 : loss : 0.089878, loss_ce: 0.019261
[00:53:49.482] iteration 7678 : loss : 0.066491, loss_ce: 0.016952
[00:53:49.785] iteration 7679 : loss : 0.070798, loss_ce: 0.024468
[00:53:50.088] iteration 7680 : loss : 0.136256, loss_ce: 0.017617
[00:53:50.411] iteration 7681 : loss : 0.042217, loss_ce: 0.014230
[00:53:50.714] iteration 7682 : loss : 0.057202, loss_ce: 0.022535
[00:53:51.014] iteration 7683 : loss : 0.055626, loss_ce: 0.010249
[00:53:51.316] iteration 7684 : loss : 0.066497, loss_ce: 0.014958
[00:53:51.621] iteration 7685 : loss : 0.058967, loss_ce: 0.015551
[00:53:51.923] iteration 7686 : loss : 0.066621, loss_ce: 0.026575
[00:53:52.230] iteration 7687 : loss : 0.054316, loss_ce: 0.012748
[00:53:52.531] iteration 7688 : loss : 0.075086, loss_ce: 0.029642
[00:53:52.833] iteration 7689 : loss : 0.057821, loss_ce: 0.021305
[00:53:53.136] iteration 7690 : loss : 0.061731, loss_ce: 0.013914
[00:53:53.439] iteration 7691 : loss : 0.066808, loss_ce: 0.018430
[00:53:53.744] iteration 7692 : loss : 0.063012, loss_ce: 0.019475
[00:53:54.049] iteration 7693 : loss : 0.059112, loss_ce: 0.018582
[00:53:54.357] iteration 7694 : loss : 0.082219, loss_ce: 0.023161
[00:53:54.660] iteration 7695 : loss : 0.069581, loss_ce: 0.014074
[00:53:54.965] iteration 7696 : loss : 0.122596, loss_ce: 0.014975
[00:53:55.266] iteration 7697 : loss : 0.115277, loss_ce: 0.012105
[00:53:55.571] iteration 7698 : loss : 0.179199, loss_ce: 0.012269
[00:53:55.878] iteration 7699 : loss : 0.058125, loss_ce: 0.025818
[00:53:56.181] iteration 7700 : loss : 0.077299, loss_ce: 0.025764
[00:53:56.494] iteration 7701 : loss : 0.046168, loss_ce: 0.009604
[00:53:56.796] iteration 7702 : loss : 0.102672, loss_ce: 0.013827
[00:53:57.099] iteration 7703 : loss : 0.103179, loss_ce: 0.012225
[00:53:57.410] iteration 7704 : loss : 0.133442, loss_ce: 0.020188
[00:53:57.721] iteration 7705 : loss : 0.054955, loss_ce: 0.010973
[00:53:58.026] iteration 7706 : loss : 0.052314, loss_ce: 0.015073
[00:53:58.338] iteration 7707 : loss : 0.063364, loss_ce: 0.023777
[00:53:58.646] iteration 7708 : loss : 0.075663, loss_ce: 0.014297
[00:53:58.956] iteration 7709 : loss : 0.068497, loss_ce: 0.017968
[00:53:59.260] iteration 7710 : loss : 0.137506, loss_ce: 0.011021
[00:53:59.564] iteration 7711 : loss : 0.053134, loss_ce: 0.019757
[00:53:59.867] iteration 7712 : loss : 0.064714, loss_ce: 0.020504
[00:54:00.172] iteration 7713 : loss : 0.124374, loss_ce: 0.018465
[00:54:00.478] iteration 7714 : loss : 0.068634, loss_ce: 0.023084
[00:54:00.783] iteration 7715 : loss : 0.070561, loss_ce: 0.018435
[00:54:01.086] iteration 7716 : loss : 0.072967, loss_ce: 0.020714
[00:54:01.392] iteration 7717 : loss : 0.135275, loss_ce: 0.017697
[00:54:01.695] iteration 7718 : loss : 0.288979, loss_ce: 0.007617
[00:54:01.998] iteration 7719 : loss : 0.055011, loss_ce: 0.024272
[00:54:02.303] iteration 7720 : loss : 0.060453, loss_ce: 0.034724
[00:54:02.623] iteration 7721 : loss : 0.074402, loss_ce: 0.014240
[00:54:02.926] iteration 7722 : loss : 0.070364, loss_ce: 0.016514
[00:54:03.232] iteration 7723 : loss : 0.137590, loss_ce: 0.014108
[00:54:03.532] iteration 7724 : loss : 0.074551, loss_ce: 0.012055
[00:54:03.833] iteration 7725 : loss : 0.076852, loss_ce: 0.025731
[00:54:04.136] iteration 7726 : loss : 0.066128, loss_ce: 0.021532
[00:54:04.438] iteration 7727 : loss : 0.114490, loss_ce: 0.019010
[00:54:04.745] iteration 7728 : loss : 0.103354, loss_ce: 0.038721
[00:54:05.050] iteration 7729 : loss : 0.078545, loss_ce: 0.021681
[00:54:05.356] iteration 7730 : loss : 0.070813, loss_ce: 0.025659
[00:54:05.658] iteration 7731 : loss : 0.074845, loss_ce: 0.029790
[00:54:05.965] iteration 7732 : loss : 0.061488, loss_ce: 0.022410
[00:54:06.271] iteration 7733 : loss : 0.110298, loss_ce: 0.008109
[00:54:06.574] iteration 7734 : loss : 0.060107, loss_ce: 0.016072
[00:54:06.879] iteration 7735 : loss : 0.139583, loss_ce: 0.010511
[00:54:07.185] iteration 7736 : loss : 0.064800, loss_ce: 0.015478
[00:54:07.489] iteration 7737 : loss : 0.138166, loss_ce: 0.022821
[00:54:07.793] iteration 7738 : loss : 0.057672, loss_ce: 0.017201
[00:54:08.098] iteration 7739 : loss : 0.067725, loss_ce: 0.009572
[00:54:08.403] iteration 7740 : loss : 0.130755, loss_ce: 0.017022
[00:54:08.724] iteration 7741 : loss : 0.120348, loss_ce: 0.009579
[00:54:09.030] iteration 7742 : loss : 0.070607, loss_ce: 0.022002
[00:54:09.333] iteration 7743 : loss : 0.112545, loss_ce: 0.016114
[00:54:09.640] iteration 7744 : loss : 0.145160, loss_ce: 0.016748
[00:54:09.944] iteration 7745 : loss : 0.114235, loss_ce: 0.017091
[00:54:10.247] iteration 7746 : loss : 0.115111, loss_ce: 0.009495
[00:54:10.552] iteration 7747 : loss : 0.073446, loss_ce: 0.026319
[00:54:10.858] iteration 7748 : loss : 0.079527, loss_ce: 0.032614
[00:54:11.159] iteration 7749 : loss : 0.051381, loss_ce: 0.011292
[00:54:11.466] iteration 7750 : loss : 0.065345, loss_ce: 0.016074
[00:54:11.770] iteration 7751 : loss : 0.071484, loss_ce: 0.016071
[00:54:12.071] iteration 7752 : loss : 0.123495, loss_ce: 0.016610
[00:54:12.376] iteration 7753 : loss : 0.119696, loss_ce: 0.007004
[00:54:12.680] iteration 7754 : loss : 0.055892, loss_ce: 0.018898
[00:54:12.984] iteration 7755 : loss : 0.092955, loss_ce: 0.020285
[00:54:13.292] iteration 7756 : loss : 0.063377, loss_ce: 0.026296
[00:54:13.598] iteration 7757 : loss : 0.061478, loss_ce: 0.022758
[00:54:13.902] iteration 7758 : loss : 0.072724, loss_ce: 0.013851
[00:54:14.211] iteration 7759 : loss : 0.062873, loss_ce: 0.018745
[00:54:14.519] iteration 7760 : loss : 0.067281, loss_ce: 0.024028
[00:54:14.847] iteration 7761 : loss : 0.086102, loss_ce: 0.021257
[00:54:15.150] iteration 7762 : loss : 0.091824, loss_ce: 0.020700
[00:54:15.465] iteration 7763 : loss : 0.055919, loss_ce: 0.023980
[00:54:15.779] iteration 7764 : loss : 0.065273, loss_ce: 0.018569
[00:54:16.085] iteration 7765 : loss : 0.111199, loss_ce: 0.015467
[00:54:16.398] iteration 7766 : loss : 0.118748, loss_ce: 0.008979
[00:54:16.705] iteration 7767 : loss : 0.133731, loss_ce: 0.017406
[00:54:17.018] iteration 7768 : loss : 0.058920, loss_ce: 0.021886
[00:54:17.335] iteration 7769 : loss : 0.092668, loss_ce: 0.011694
[00:54:17.647] iteration 7770 : loss : 0.070797, loss_ce: 0.015668
[00:54:17.968] iteration 7771 : loss : 0.047434, loss_ce: 0.011527
[00:54:18.278] iteration 7772 : loss : 0.131727, loss_ce: 0.021271
[00:54:18.586] iteration 7773 : loss : 0.060459, loss_ce: 0.017854
[00:54:18.895] iteration 7774 : loss : 0.058657, loss_ce: 0.025432
[00:54:19.204] iteration 7775 : loss : 0.059235, loss_ce: 0.024979
[00:54:19.513] iteration 7776 : loss : 0.155922, loss_ce: 0.015314
[00:54:19.821] iteration 7777 : loss : 0.078677, loss_ce: 0.010626
[00:54:20.133] iteration 7778 : loss : 0.063940, loss_ce: 0.016202
[00:54:20.442] iteration 7779 : loss : 0.054053, loss_ce: 0.010307
[00:54:20.752] iteration 7780 : loss : 0.083275, loss_ce: 0.016473
[00:54:21.081] iteration 7781 : loss : 0.065741, loss_ce: 0.026250
[00:54:21.392] iteration 7782 : loss : 0.052353, loss_ce: 0.021315
[00:54:21.711] iteration 7783 : loss : 0.070105, loss_ce: 0.026463
[00:54:21.797] iteration 7784 : loss : 0.287629, loss_ce: 0.016159
[00:54:40.344] iteration 7785 : loss : 0.066007, loss_ce: 0.023657
[00:54:40.646] iteration 7786 : loss : 0.090976, loss_ce: 0.010044
[00:54:40.946] iteration 7787 : loss : 0.051778, loss_ce: 0.014647
[00:54:41.252] iteration 7788 : loss : 0.127422, loss_ce: 0.020120
[00:54:41.556] iteration 7789 : loss : 0.084088, loss_ce: 0.015664
[00:54:41.856] iteration 7790 : loss : 0.068301, loss_ce: 0.013787
[00:54:42.159] iteration 7791 : loss : 0.061619, loss_ce: 0.020930
[00:54:42.462] iteration 7792 : loss : 0.064358, loss_ce: 0.021734
[00:54:42.764] iteration 7793 : loss : 0.055943, loss_ce: 0.017623
[00:54:43.069] iteration 7794 : loss : 0.062194, loss_ce: 0.028523
[00:54:43.371] iteration 7795 : loss : 0.066183, loss_ce: 0.020087
[00:54:43.673] iteration 7796 : loss : 0.071500, loss_ce: 0.012745
[00:54:43.977] iteration 7797 : loss : 0.060624, loss_ce: 0.019415
[00:54:44.280] iteration 7798 : loss : 0.072028, loss_ce: 0.022994
[00:54:44.582] iteration 7799 : loss : 0.068809, loss_ce: 0.022030
[00:54:44.888] iteration 7800 : loss : 0.069699, loss_ce: 0.020475
[00:54:45.212] iteration 7801 : loss : 0.077040, loss_ce: 0.030609
[00:54:45.512] iteration 7802 : loss : 0.108985, loss_ce: 0.006670
[00:54:45.821] iteration 7803 : loss : 0.045548, loss_ce: 0.015857
[00:54:46.126] iteration 7804 : loss : 0.110003, loss_ce: 0.014976
[00:54:46.430] iteration 7805 : loss : 0.117274, loss_ce: 0.026372
[00:54:46.733] iteration 7806 : loss : 0.113236, loss_ce: 0.009795
[00:54:47.036] iteration 7807 : loss : 0.115863, loss_ce: 0.017587
[00:54:47.341] iteration 7808 : loss : 0.071787, loss_ce: 0.028286
[00:54:47.652] iteration 7809 : loss : 0.071704, loss_ce: 0.025403
[00:54:47.961] iteration 7810 : loss : 0.070933, loss_ce: 0.024898
[00:54:48.270] iteration 7811 : loss : 0.168473, loss_ce: 0.004780
[00:54:48.584] iteration 7812 : loss : 0.085234, loss_ce: 0.020592
[00:54:48.891] iteration 7813 : loss : 0.063438, loss_ce: 0.014881
[00:54:49.198] iteration 7814 : loss : 0.109477, loss_ce: 0.018250
[00:54:49.503] iteration 7815 : loss : 0.120189, loss_ce: 0.032735
[00:54:49.801] iteration 7816 : loss : 0.081918, loss_ce: 0.020548
[00:54:50.105] iteration 7817 : loss : 0.078095, loss_ce: 0.031053
[00:54:50.409] iteration 7818 : loss : 0.078586, loss_ce: 0.018449
[00:54:50.713] iteration 7819 : loss : 0.136017, loss_ce: 0.011567
[00:54:51.018] iteration 7820 : loss : 0.070119, loss_ce: 0.022853
[00:54:51.340] iteration 7821 : loss : 0.058859, loss_ce: 0.019646
[00:54:51.646] iteration 7822 : loss : 0.066676, loss_ce: 0.030114
[00:54:51.949] iteration 7823 : loss : 0.061596, loss_ce: 0.009919
[00:54:52.257] iteration 7824 : loss : 0.051965, loss_ce: 0.013191
[00:54:52.561] iteration 7825 : loss : 0.105819, loss_ce: 0.012992
[00:54:52.871] iteration 7826 : loss : 0.059639, loss_ce: 0.020364
[00:54:53.176] iteration 7827 : loss : 0.085944, loss_ce: 0.015918
[00:54:53.482] iteration 7828 : loss : 0.064489, loss_ce: 0.036072
[00:54:53.789] iteration 7829 : loss : 0.049054, loss_ce: 0.016155
[00:54:54.096] iteration 7830 : loss : 0.046773, loss_ce: 0.011424
[00:54:54.399] iteration 7831 : loss : 0.076553, loss_ce: 0.009555
[00:54:54.705] iteration 7832 : loss : 0.064396, loss_ce: 0.022710
[00:54:55.008] iteration 7833 : loss : 0.083626, loss_ce: 0.024562
[00:54:55.314] iteration 7834 : loss : 0.058462, loss_ce: 0.014981
[00:54:55.618] iteration 7835 : loss : 0.120625, loss_ce: 0.011146
[00:54:55.921] iteration 7836 : loss : 0.060998, loss_ce: 0.020315
[00:54:56.226] iteration 7837 : loss : 0.071403, loss_ce: 0.022012
[00:54:56.529] iteration 7838 : loss : 0.082429, loss_ce: 0.015739
[00:54:56.835] iteration 7839 : loss : 0.080871, loss_ce: 0.017199
[00:54:57.142] iteration 7840 : loss : 0.124757, loss_ce: 0.008130
[00:54:57.464] iteration 7841 : loss : 0.062966, loss_ce: 0.015809
[00:54:57.769] iteration 7842 : loss : 0.061859, loss_ce: 0.023323
[00:54:58.077] iteration 7843 : loss : 0.056018, loss_ce: 0.016328
[00:54:58.384] iteration 7844 : loss : 0.143501, loss_ce: 0.007502
[00:54:58.686] iteration 7845 : loss : 0.055836, loss_ce: 0.025515
[00:54:58.999] iteration 7846 : loss : 0.079471, loss_ce: 0.016263
[00:54:59.308] iteration 7847 : loss : 0.087659, loss_ce: 0.022166
[00:54:59.613] iteration 7848 : loss : 0.126961, loss_ce: 0.020506
[00:54:59.918] iteration 7849 : loss : 0.068777, loss_ce: 0.024765
[00:55:00.224] iteration 7850 : loss : 0.126701, loss_ce: 0.014491
[00:55:00.535] iteration 7851 : loss : 0.056449, loss_ce: 0.024730
[00:55:00.843] iteration 7852 : loss : 0.052138, loss_ce: 0.025982
[00:55:01.150] iteration 7853 : loss : 0.045955, loss_ce: 0.013205
[00:55:01.454] iteration 7854 : loss : 0.052887, loss_ce: 0.018616
[00:55:01.763] iteration 7855 : loss : 0.071194, loss_ce: 0.014463
[00:55:02.066] iteration 7856 : loss : 0.065423, loss_ce: 0.021215
[00:55:02.373] iteration 7857 : loss : 0.080580, loss_ce: 0.027443
[00:55:02.678] iteration 7858 : loss : 0.065920, loss_ce: 0.018589
[00:55:02.985] iteration 7859 : loss : 0.051376, loss_ce: 0.015957
[00:55:03.292] iteration 7860 : loss : 0.065661, loss_ce: 0.012496
[00:55:03.616] iteration 7861 : loss : 0.104176, loss_ce: 0.016137
[00:55:03.924] iteration 7862 : loss : 0.056050, loss_ce: 0.021603
[00:55:04.237] iteration 7863 : loss : 0.053322, loss_ce: 0.016160
[00:55:04.549] iteration 7864 : loss : 0.078075, loss_ce: 0.015025
[00:55:04.855] iteration 7865 : loss : 0.061948, loss_ce: 0.019240
[00:55:05.160] iteration 7866 : loss : 0.053233, loss_ce: 0.009263
[00:55:05.475] iteration 7867 : loss : 0.064844, loss_ce: 0.020989
[00:55:05.789] iteration 7868 : loss : 0.057163, loss_ce: 0.023144
[00:55:06.098] iteration 7869 : loss : 0.072563, loss_ce: 0.026475
[00:55:06.408] iteration 7870 : loss : 0.120630, loss_ce: 0.019741
[00:55:06.720] iteration 7871 : loss : 0.061209, loss_ce: 0.021701
[00:55:07.027] iteration 7872 : loss : 0.062274, loss_ce: 0.021418
[00:55:07.335] iteration 7873 : loss : 0.073686, loss_ce: 0.013495
[00:55:07.646] iteration 7874 : loss : 0.164571, loss_ce: 0.013082
[00:55:07.957] iteration 7875 : loss : 0.116555, loss_ce: 0.012913
[00:55:08.265] iteration 7876 : loss : 0.071809, loss_ce: 0.021230
[00:55:08.574] iteration 7877 : loss : 0.063933, loss_ce: 0.013311
[00:55:08.883] iteration 7878 : loss : 0.092392, loss_ce: 0.013878
[00:55:09.193] iteration 7879 : loss : 0.062819, loss_ce: 0.033313
[00:55:09.509] iteration 7880 : loss : 0.126585, loss_ce: 0.014614
[00:55:09.833] iteration 7881 : loss : 0.073090, loss_ce: 0.020552
[00:55:10.141] iteration 7882 : loss : 0.064519, loss_ce: 0.012132
[00:55:10.455] iteration 7883 : loss : 0.117032, loss_ce: 0.026692
[00:55:10.761] iteration 7884 : loss : 0.080466, loss_ce: 0.018650
[00:55:11.071] iteration 7885 : loss : 0.116076, loss_ce: 0.013779
[00:55:11.378] iteration 7886 : loss : 0.071294, loss_ce: 0.013405
[00:55:11.688] iteration 7887 : loss : 0.064395, loss_ce: 0.016025
[00:55:11.996] iteration 7888 : loss : 0.116863, loss_ce: 0.010087
[00:55:12.309] iteration 7889 : loss : 0.068584, loss_ce: 0.009109
[00:55:12.619] iteration 7890 : loss : 0.119822, loss_ce: 0.013723
[00:55:12.927] iteration 7891 : loss : 0.125145, loss_ce: 0.021679
[00:55:13.237] iteration 7892 : loss : 0.044173, loss_ce: 0.014988
[00:55:13.549] iteration 7893 : loss : 0.092567, loss_ce: 0.024315
[00:55:13.860] iteration 7894 : loss : 0.057817, loss_ce: 0.009521
[00:55:14.170] iteration 7895 : loss : 0.060235, loss_ce: 0.013298
[00:55:14.481] iteration 7896 : loss : 0.065066, loss_ce: 0.030116
[00:55:14.791] iteration 7897 : loss : 0.066174, loss_ce: 0.028652
[00:55:15.098] iteration 7898 : loss : 0.050023, loss_ce: 0.010979
[00:55:15.407] iteration 7899 : loss : 0.071589, loss_ce: 0.027420
[00:55:15.715] iteration 7900 : loss : 0.054735, loss_ce: 0.019408
[00:55:16.045] iteration 7901 : loss : 0.078599, loss_ce: 0.019269
[00:55:16.356] iteration 7902 : loss : 0.116137, loss_ce: 0.012558
[00:55:16.669] iteration 7903 : loss : 0.120827, loss_ce: 0.010091
[00:55:16.978] iteration 7904 : loss : 0.180364, loss_ce: 0.017735
[00:55:17.290] iteration 7905 : loss : 0.077020, loss_ce: 0.024503
[00:55:17.600] iteration 7906 : loss : 0.051806, loss_ce: 0.012907
[00:55:17.912] iteration 7907 : loss : 0.067006, loss_ce: 0.017762
[00:55:18.223] iteration 7908 : loss : 0.059267, loss_ce: 0.020925
[00:55:18.537] iteration 7909 : loss : 0.117577, loss_ce: 0.014565
[00:55:18.854] iteration 7910 : loss : 0.130927, loss_ce: 0.013898
[00:55:19.170] iteration 7911 : loss : 0.054961, loss_ce: 0.016356
[00:55:19.483] iteration 7912 : loss : 0.063357, loss_ce: 0.013157
[00:55:19.798] iteration 7913 : loss : 0.058706, loss_ce: 0.016122
[00:55:20.114] iteration 7914 : loss : 0.107494, loss_ce: 0.017206
[00:55:20.431] iteration 7915 : loss : 0.086184, loss_ce: 0.019416
[00:55:20.744] iteration 7916 : loss : 0.054624, loss_ce: 0.009269
[00:55:21.064] iteration 7917 : loss : 0.070922, loss_ce: 0.013284
[00:55:21.377] iteration 7918 : loss : 0.059734, loss_ce: 0.014976
[00:55:21.693] iteration 7919 : loss : 0.118397, loss_ce: 0.020094
[00:55:22.005] iteration 7920 : loss : 0.094532, loss_ce: 0.019806
[00:55:22.349] iteration 7921 : loss : 0.063264, loss_ce: 0.024743
[00:55:22.660] iteration 7922 : loss : 0.056830, loss_ce: 0.025130
[00:55:22.741] iteration 7923 : loss : 0.287153, loss_ce: 0.005685
[00:55:40.722] iteration 7924 : loss : 0.045519, loss_ce: 0.013930
[00:55:41.023] iteration 7925 : loss : 0.045133, loss_ce: 0.010138
[00:55:41.325] iteration 7926 : loss : 0.065255, loss_ce: 0.023004
[00:55:41.635] iteration 7927 : loss : 0.050452, loss_ce: 0.019977
[00:55:41.938] iteration 7928 : loss : 0.082490, loss_ce: 0.020187
[00:55:42.238] iteration 7929 : loss : 0.100811, loss_ce: 0.014325
[00:55:42.537] iteration 7930 : loss : 0.129719, loss_ce: 0.016281
[00:55:42.839] iteration 7931 : loss : 0.064591, loss_ce: 0.019844
[00:55:43.141] iteration 7932 : loss : 0.049260, loss_ce: 0.015670
[00:55:43.444] iteration 7933 : loss : 0.118265, loss_ce: 0.018483
[00:55:43.745] iteration 7934 : loss : 0.065843, loss_ce: 0.014553
[00:55:44.051] iteration 7935 : loss : 0.120513, loss_ce: 0.010295
[00:55:44.356] iteration 7936 : loss : 0.061022, loss_ce: 0.021948
[00:55:44.663] iteration 7937 : loss : 0.073662, loss_ce: 0.038421
[00:55:44.968] iteration 7938 : loss : 0.063319, loss_ce: 0.021518
[00:55:45.271] iteration 7939 : loss : 0.066040, loss_ce: 0.023137
[00:55:45.577] iteration 7940 : loss : 0.059096, loss_ce: 0.018604
[00:55:45.900] iteration 7941 : loss : 0.073804, loss_ce: 0.025347
[00:55:46.203] iteration 7942 : loss : 0.071786, loss_ce: 0.013785
[00:55:46.509] iteration 7943 : loss : 0.055369, loss_ce: 0.019234
[00:55:46.814] iteration 7944 : loss : 0.055224, loss_ce: 0.009248
[00:55:47.117] iteration 7945 : loss : 0.164162, loss_ce: 0.010107
[00:55:47.422] iteration 7946 : loss : 0.170082, loss_ce: 0.014711
[00:55:47.723] iteration 7947 : loss : 0.065802, loss_ce: 0.029140
[00:55:48.029] iteration 7948 : loss : 0.061055, loss_ce: 0.021985
[00:55:48.333] iteration 7949 : loss : 0.053849, loss_ce: 0.009033
[00:55:48.637] iteration 7950 : loss : 0.067097, loss_ce: 0.032760
[00:55:48.940] iteration 7951 : loss : 0.117868, loss_ce: 0.017697
[00:55:49.246] iteration 7952 : loss : 0.061501, loss_ce: 0.032439
[00:55:49.548] iteration 7953 : loss : 0.046442, loss_ce: 0.010189
[00:55:49.851] iteration 7954 : loss : 0.049145, loss_ce: 0.009292
[00:55:50.154] iteration 7955 : loss : 0.068122, loss_ce: 0.022020
[00:55:50.458] iteration 7956 : loss : 0.078129, loss_ce: 0.014490
[00:55:50.761] iteration 7957 : loss : 0.109745, loss_ce: 0.011957
[00:55:51.066] iteration 7958 : loss : 0.072821, loss_ce: 0.014190
[00:55:51.369] iteration 7959 : loss : 0.052918, loss_ce: 0.016691
[00:55:51.672] iteration 7960 : loss : 0.073470, loss_ce: 0.023360
[00:55:51.997] iteration 7961 : loss : 0.060431, loss_ce: 0.030462
[00:55:52.302] iteration 7962 : loss : 0.172024, loss_ce: 0.009103
[00:55:52.608] iteration 7963 : loss : 0.067288, loss_ce: 0.016095
[00:55:52.913] iteration 7964 : loss : 0.182939, loss_ce: 0.020260
[00:55:53.215] iteration 7965 : loss : 0.074120, loss_ce: 0.020660
[00:55:53.522] iteration 7966 : loss : 0.052813, loss_ce: 0.014012
[00:55:53.827] iteration 7967 : loss : 0.064666, loss_ce: 0.018339
[00:55:54.131] iteration 7968 : loss : 0.060551, loss_ce: 0.015425
[00:55:54.435] iteration 7969 : loss : 0.056576, loss_ce: 0.025621
[00:55:54.741] iteration 7970 : loss : 0.072327, loss_ce: 0.017594
[00:55:55.048] iteration 7971 : loss : 0.118540, loss_ce: 0.018564
[00:55:55.357] iteration 7972 : loss : 0.058109, loss_ce: 0.019440
[00:55:55.661] iteration 7973 : loss : 0.047450, loss_ce: 0.015129
[00:55:55.972] iteration 7974 : loss : 0.066896, loss_ce: 0.018816
[00:55:56.279] iteration 7975 : loss : 0.055476, loss_ce: 0.019969
[00:55:56.585] iteration 7976 : loss : 0.065784, loss_ce: 0.016983
[00:55:56.894] iteration 7977 : loss : 0.109662, loss_ce: 0.007110
[00:55:57.202] iteration 7978 : loss : 0.077133, loss_ce: 0.019639
[00:55:57.511] iteration 7979 : loss : 0.129044, loss_ce: 0.014469
[00:55:57.819] iteration 7980 : loss : 0.060501, loss_ce: 0.012386
[00:55:58.140] iteration 7981 : loss : 0.053516, loss_ce: 0.018513
[00:55:58.447] iteration 7982 : loss : 0.071969, loss_ce: 0.028421
[00:55:58.754] iteration 7983 : loss : 0.051991, loss_ce: 0.013281
[00:55:59.060] iteration 7984 : loss : 0.050231, loss_ce: 0.020363
[00:55:59.364] iteration 7985 : loss : 0.063209, loss_ce: 0.011244
[00:55:59.672] iteration 7986 : loss : 0.114857, loss_ce: 0.011793
[00:55:59.978] iteration 7987 : loss : 0.065266, loss_ce: 0.016136
[00:56:00.286] iteration 7988 : loss : 0.129503, loss_ce: 0.017089
[00:56:00.593] iteration 7989 : loss : 0.048789, loss_ce: 0.022808
[00:56:00.898] iteration 7990 : loss : 0.067540, loss_ce: 0.009487
[00:56:01.208] iteration 7991 : loss : 0.053645, loss_ce: 0.016246
[00:56:01.515] iteration 7992 : loss : 0.055622, loss_ce: 0.027025
[00:56:01.824] iteration 7993 : loss : 0.068698, loss_ce: 0.008235
[00:56:02.132] iteration 7994 : loss : 0.054306, loss_ce: 0.024715
[00:56:02.441] iteration 7995 : loss : 0.081082, loss_ce: 0.012374
[00:56:02.749] iteration 7996 : loss : 0.104623, loss_ce: 0.009907
[00:56:03.057] iteration 7997 : loss : 0.067192, loss_ce: 0.016049
[00:56:03.366] iteration 7998 : loss : 0.065096, loss_ce: 0.019417
[00:56:03.672] iteration 7999 : loss : 0.070041, loss_ce: 0.023751
[00:56:03.974] iteration 8000 : loss : 0.068215, loss_ce: 0.018903
[00:56:04.298] iteration 8001 : loss : 0.060536, loss_ce: 0.012761
[00:56:04.604] iteration 8002 : loss : 0.059486, loss_ce: 0.015669
[00:56:04.912] iteration 8003 : loss : 0.109773, loss_ce: 0.012071
[00:56:05.222] iteration 8004 : loss : 0.052288, loss_ce: 0.016350
[00:56:05.528] iteration 8005 : loss : 0.070063, loss_ce: 0.012993
[00:56:05.836] iteration 8006 : loss : 0.094310, loss_ce: 0.016174
[00:56:06.145] iteration 8007 : loss : 0.043828, loss_ce: 0.022336
[00:56:06.451] iteration 8008 : loss : 0.114542, loss_ce: 0.017633
[00:56:06.759] iteration 8009 : loss : 0.094702, loss_ce: 0.014673
[00:56:07.066] iteration 8010 : loss : 0.068665, loss_ce: 0.020782
[00:56:07.371] iteration 8011 : loss : 0.046783, loss_ce: 0.013840
[00:56:07.678] iteration 8012 : loss : 0.052130, loss_ce: 0.015009
[00:56:07.986] iteration 8013 : loss : 0.058971, loss_ce: 0.019068
[00:56:08.289] iteration 8014 : loss : 0.061066, loss_ce: 0.009682
[00:56:08.600] iteration 8015 : loss : 0.071048, loss_ce: 0.025610
[00:56:08.907] iteration 8016 : loss : 0.105476, loss_ce: 0.008593
[00:56:09.211] iteration 8017 : loss : 0.070072, loss_ce: 0.021661
[00:56:09.520] iteration 8018 : loss : 0.077140, loss_ce: 0.009621
[00:56:09.828] iteration 8019 : loss : 0.067045, loss_ce: 0.023757
[00:56:10.132] iteration 8020 : loss : 0.070075, loss_ce: 0.014483
[00:56:10.455] iteration 8021 : loss : 0.068403, loss_ce: 0.012042
[00:56:10.763] iteration 8022 : loss : 0.210509, loss_ce: 0.006189
[00:56:11.073] iteration 8023 : loss : 0.054803, loss_ce: 0.012441
[00:56:11.381] iteration 8024 : loss : 0.056093, loss_ce: 0.014540
[00:56:11.686] iteration 8025 : loss : 0.073564, loss_ce: 0.026179
[00:56:11.996] iteration 8026 : loss : 0.064076, loss_ce: 0.019055
[00:56:12.306] iteration 8027 : loss : 0.125511, loss_ce: 0.019421
[00:56:12.616] iteration 8028 : loss : 0.121547, loss_ce: 0.010373
[00:56:12.921] iteration 8029 : loss : 0.068700, loss_ce: 0.022791
[00:56:13.235] iteration 8030 : loss : 0.059259, loss_ce: 0.018202
[00:56:13.545] iteration 8031 : loss : 0.059495, loss_ce: 0.030563
[00:56:13.852] iteration 8032 : loss : 0.128408, loss_ce: 0.022718
[00:56:14.158] iteration 8033 : loss : 0.048992, loss_ce: 0.019301
[00:56:14.462] iteration 8034 : loss : 0.057861, loss_ce: 0.013380
[00:56:14.764] iteration 8035 : loss : 0.223814, loss_ce: 0.007802
[00:56:15.070] iteration 8036 : loss : 0.054467, loss_ce: 0.016098
[00:56:15.378] iteration 8037 : loss : 0.058827, loss_ce: 0.014709
[00:56:15.682] iteration 8038 : loss : 0.129141, loss_ce: 0.013821
[00:56:15.983] iteration 8039 : loss : 0.054296, loss_ce: 0.016273
[00:56:16.286] iteration 8040 : loss : 0.103304, loss_ce: 0.028993
[00:56:16.609] iteration 8041 : loss : 0.081859, loss_ce: 0.025056
[00:56:16.909] iteration 8042 : loss : 0.058321, loss_ce: 0.023805
[00:56:17.217] iteration 8043 : loss : 0.055910, loss_ce: 0.011924
[00:56:17.526] iteration 8044 : loss : 0.053585, loss_ce: 0.015605
[00:56:17.829] iteration 8045 : loss : 0.079093, loss_ce: 0.017746
[00:56:18.135] iteration 8046 : loss : 0.056169, loss_ce: 0.012633
[00:56:18.445] iteration 8047 : loss : 0.057343, loss_ce: 0.019181
[00:56:18.749] iteration 8048 : loss : 0.055211, loss_ce: 0.019990
[00:56:19.063] iteration 8049 : loss : 0.118647, loss_ce: 0.015490
[00:56:19.369] iteration 8050 : loss : 0.180977, loss_ce: 0.014720
[00:56:19.671] iteration 8051 : loss : 0.058011, loss_ce: 0.025460
[00:56:19.975] iteration 8052 : loss : 0.047006, loss_ce: 0.020727
[00:56:20.287] iteration 8053 : loss : 0.064295, loss_ce: 0.019370
[00:56:20.590] iteration 8054 : loss : 0.080304, loss_ce: 0.018568
[00:56:20.900] iteration 8055 : loss : 0.045491, loss_ce: 0.014276
[00:56:21.206] iteration 8056 : loss : 0.078119, loss_ce: 0.013138
[00:56:21.514] iteration 8057 : loss : 0.048298, loss_ce: 0.022416
[00:56:21.823] iteration 8058 : loss : 0.068176, loss_ce: 0.023303
[00:56:22.130] iteration 8059 : loss : 0.067407, loss_ce: 0.015463
[00:56:22.438] iteration 8060 : loss : 0.067275, loss_ce: 0.025340
[00:56:22.767] iteration 8061 : loss : 0.066934, loss_ce: 0.016846
[00:56:22.853] iteration 8062 : loss : 0.422676, loss_ce: 0.013841
[00:56:40.884] iteration 8063 : loss : 0.072588, loss_ce: 0.031025
[00:56:41.184] iteration 8064 : loss : 0.116432, loss_ce: 0.009699
[00:56:41.483] iteration 8065 : loss : 0.085381, loss_ce: 0.028179
[00:56:41.787] iteration 8066 : loss : 0.119968, loss_ce: 0.020626
[00:56:42.090] iteration 8067 : loss : 0.128755, loss_ce: 0.012948
[00:56:42.389] iteration 8068 : loss : 0.055594, loss_ce: 0.012531
[00:56:42.695] iteration 8069 : loss : 0.123913, loss_ce: 0.015590
[00:56:42.999] iteration 8070 : loss : 0.047688, loss_ce: 0.010613
[00:56:43.305] iteration 8071 : loss : 0.113103, loss_ce: 0.017432
[00:56:43.607] iteration 8072 : loss : 0.062182, loss_ce: 0.019076
[00:56:43.914] iteration 8073 : loss : 0.061559, loss_ce: 0.021605
[00:56:44.219] iteration 8074 : loss : 0.055735, loss_ce: 0.015035
[00:56:44.527] iteration 8075 : loss : 0.095852, loss_ce: 0.015142
[00:56:44.832] iteration 8076 : loss : 0.058495, loss_ce: 0.021387
[00:56:45.137] iteration 8077 : loss : 0.050540, loss_ce: 0.020897
[00:56:45.446] iteration 8078 : loss : 0.233371, loss_ce: 0.011223
[00:56:45.754] iteration 8079 : loss : 0.059921, loss_ce: 0.013920
[00:56:46.063] iteration 8080 : loss : 0.057690, loss_ce: 0.014243
[00:56:46.384] iteration 8081 : loss : 0.070588, loss_ce: 0.019359
[00:56:46.693] iteration 8082 : loss : 0.117773, loss_ce: 0.015018
[00:56:47.001] iteration 8083 : loss : 0.066131, loss_ce: 0.019406
[00:56:47.307] iteration 8084 : loss : 0.063823, loss_ce: 0.023960
[00:56:47.616] iteration 8085 : loss : 0.163829, loss_ce: 0.016770
[00:56:47.922] iteration 8086 : loss : 0.099775, loss_ce: 0.015067
[00:56:48.227] iteration 8087 : loss : 0.074798, loss_ce: 0.010883
[00:56:48.536] iteration 8088 : loss : 0.122395, loss_ce: 0.017525
[00:56:48.842] iteration 8089 : loss : 0.110205, loss_ce: 0.014618
[00:56:49.150] iteration 8090 : loss : 0.062186, loss_ce: 0.022567
[00:56:49.454] iteration 8091 : loss : 0.086581, loss_ce: 0.013804
[00:56:49.762] iteration 8092 : loss : 0.079661, loss_ce: 0.025464
[00:56:50.070] iteration 8093 : loss : 0.060399, loss_ce: 0.027221
[00:56:50.379] iteration 8094 : loss : 0.060263, loss_ce: 0.030411
[00:56:50.690] iteration 8095 : loss : 0.118445, loss_ce: 0.018134
[00:56:50.996] iteration 8096 : loss : 0.056261, loss_ce: 0.016559
[00:56:51.308] iteration 8097 : loss : 0.108249, loss_ce: 0.012650
[00:56:51.620] iteration 8098 : loss : 0.062905, loss_ce: 0.021101
[00:56:51.929] iteration 8099 : loss : 0.041024, loss_ce: 0.013454
[00:56:52.237] iteration 8100 : loss : 0.060854, loss_ce: 0.014501
[00:56:52.564] iteration 8101 : loss : 0.129802, loss_ce: 0.008586
[00:56:52.873] iteration 8102 : loss : 0.082672, loss_ce: 0.011796
[00:56:53.188] iteration 8103 : loss : 0.068500, loss_ce: 0.009836
[00:56:53.497] iteration 8104 : loss : 0.112943, loss_ce: 0.018354
[00:56:53.810] iteration 8105 : loss : 0.122053, loss_ce: 0.018822
[00:56:54.119] iteration 8106 : loss : 0.286034, loss_ce: 0.006865
[00:56:54.431] iteration 8107 : loss : 0.061249, loss_ce: 0.018505
[00:56:54.739] iteration 8108 : loss : 0.052946, loss_ce: 0.020592
[00:56:55.053] iteration 8109 : loss : 0.077181, loss_ce: 0.011397
[00:56:55.365] iteration 8110 : loss : 0.186540, loss_ce: 0.009639
[00:56:55.675] iteration 8111 : loss : 0.057378, loss_ce: 0.014186
[00:56:55.984] iteration 8112 : loss : 0.062302, loss_ce: 0.017263
[00:56:56.295] iteration 8113 : loss : 0.060905, loss_ce: 0.017988
[00:56:56.605] iteration 8114 : loss : 0.076411, loss_ce: 0.020666
[00:56:56.914] iteration 8115 : loss : 0.059905, loss_ce: 0.012925
[00:56:57.221] iteration 8116 : loss : 0.114711, loss_ce: 0.011819
[00:56:57.531] iteration 8117 : loss : 0.059284, loss_ce: 0.013629
[00:56:57.842] iteration 8118 : loss : 0.045776, loss_ce: 0.011800
[00:56:58.150] iteration 8119 : loss : 0.109896, loss_ce: 0.018766
[00:56:58.459] iteration 8120 : loss : 0.059799, loss_ce: 0.017129
[00:56:58.782] iteration 8121 : loss : 0.109270, loss_ce: 0.020023
[00:56:59.090] iteration 8122 : loss : 0.121458, loss_ce: 0.016231
[00:56:59.400] iteration 8123 : loss : 0.116985, loss_ce: 0.025499
[00:56:59.705] iteration 8124 : loss : 0.068319, loss_ce: 0.022192
[00:57:00.014] iteration 8125 : loss : 0.055974, loss_ce: 0.028580
[00:57:00.324] iteration 8126 : loss : 0.065081, loss_ce: 0.015536
[00:57:00.641] iteration 8127 : loss : 0.050079, loss_ce: 0.013111
[00:57:00.953] iteration 8128 : loss : 0.052955, loss_ce: 0.016552
[00:57:01.263] iteration 8129 : loss : 0.049757, loss_ce: 0.012540
[00:57:01.576] iteration 8130 : loss : 0.056445, loss_ce: 0.019812
[00:57:01.888] iteration 8131 : loss : 0.071031, loss_ce: 0.014381
[00:57:02.199] iteration 8132 : loss : 0.069139, loss_ce: 0.027577
[00:57:02.514] iteration 8133 : loss : 0.061015, loss_ce: 0.029170
[00:57:02.826] iteration 8134 : loss : 0.055449, loss_ce: 0.027053
[00:57:03.135] iteration 8135 : loss : 0.058439, loss_ce: 0.019211
[00:57:03.445] iteration 8136 : loss : 0.052047, loss_ce: 0.016350
[00:57:03.754] iteration 8137 : loss : 0.091388, loss_ce: 0.017089
[00:57:04.070] iteration 8138 : loss : 0.055151, loss_ce: 0.013248
[00:57:04.375] iteration 8139 : loss : 0.107835, loss_ce: 0.014957
[00:57:04.678] iteration 8140 : loss : 0.072186, loss_ce: 0.016440
[00:57:04.996] iteration 8141 : loss : 0.058880, loss_ce: 0.021820
[00:57:05.304] iteration 8142 : loss : 0.106375, loss_ce: 0.015026
[00:57:05.607] iteration 8143 : loss : 0.060236, loss_ce: 0.021220
[00:57:05.915] iteration 8144 : loss : 0.112612, loss_ce: 0.021839
[00:57:06.223] iteration 8145 : loss : 0.069921, loss_ce: 0.019160
[00:57:06.527] iteration 8146 : loss : 0.087637, loss_ce: 0.019691
[00:57:06.832] iteration 8147 : loss : 0.055603, loss_ce: 0.013675
[00:57:07.137] iteration 8148 : loss : 0.164708, loss_ce: 0.005379
[00:57:07.442] iteration 8149 : loss : 0.056553, loss_ce: 0.017441
[00:57:07.752] iteration 8150 : loss : 0.069794, loss_ce: 0.018051
[00:57:08.062] iteration 8151 : loss : 0.076370, loss_ce: 0.017287
[00:57:08.370] iteration 8152 : loss : 0.052150, loss_ce: 0.011698
[00:57:08.675] iteration 8153 : loss : 0.069199, loss_ce: 0.020038
[00:57:08.978] iteration 8154 : loss : 0.060954, loss_ce: 0.021928
[00:57:09.292] iteration 8155 : loss : 0.053464, loss_ce: 0.012811
[00:57:09.597] iteration 8156 : loss : 0.066077, loss_ce: 0.023025
[00:57:09.902] iteration 8157 : loss : 0.071019, loss_ce: 0.023527
[00:57:10.213] iteration 8158 : loss : 0.119917, loss_ce: 0.020940
[00:57:10.518] iteration 8159 : loss : 0.078973, loss_ce: 0.022654
[00:57:10.824] iteration 8160 : loss : 0.062469, loss_ce: 0.026086
[00:57:11.148] iteration 8161 : loss : 0.113002, loss_ce: 0.009155
[00:57:11.456] iteration 8162 : loss : 0.120972, loss_ce: 0.016775
[00:57:11.762] iteration 8163 : loss : 0.071635, loss_ce: 0.021394
[00:57:12.066] iteration 8164 : loss : 0.057961, loss_ce: 0.007227
[00:57:12.374] iteration 8165 : loss : 0.060253, loss_ce: 0.031577
[00:57:12.678] iteration 8166 : loss : 0.075077, loss_ce: 0.012141
[00:57:12.985] iteration 8167 : loss : 0.121410, loss_ce: 0.012120
[00:57:13.291] iteration 8168 : loss : 0.058985, loss_ce: 0.017279
[00:57:13.595] iteration 8169 : loss : 0.131795, loss_ce: 0.021986
[00:57:13.904] iteration 8170 : loss : 0.063027, loss_ce: 0.020645
[00:57:14.211] iteration 8171 : loss : 0.070601, loss_ce: 0.015212
[00:57:14.517] iteration 8172 : loss : 0.117636, loss_ce: 0.010666
[00:57:14.826] iteration 8173 : loss : 0.063781, loss_ce: 0.020774
[00:57:15.131] iteration 8174 : loss : 0.056235, loss_ce: 0.022619
[00:57:15.437] iteration 8175 : loss : 0.075625, loss_ce: 0.023762
[00:57:15.746] iteration 8176 : loss : 0.052673, loss_ce: 0.009234
[00:57:16.051] iteration 8177 : loss : 0.057325, loss_ce: 0.013744
[00:57:16.357] iteration 8178 : loss : 0.058908, loss_ce: 0.022150
[00:57:16.671] iteration 8179 : loss : 0.172705, loss_ce: 0.005953
[00:57:16.973] iteration 8180 : loss : 0.057250, loss_ce: 0.019678
[00:57:17.307] iteration 8181 : loss : 0.053837, loss_ce: 0.022355
[00:57:17.619] iteration 8182 : loss : 0.062399, loss_ce: 0.021966
[00:57:17.937] iteration 8183 : loss : 0.087598, loss_ce: 0.033332
[00:57:18.250] iteration 8184 : loss : 0.063214, loss_ce: 0.016320
[00:57:18.568] iteration 8185 : loss : 0.047939, loss_ce: 0.020311
[00:57:18.881] iteration 8186 : loss : 0.053573, loss_ce: 0.022547
[00:57:19.197] iteration 8187 : loss : 0.105098, loss_ce: 0.021717
[00:57:19.509] iteration 8188 : loss : 0.128688, loss_ce: 0.016863
[00:57:19.821] iteration 8189 : loss : 0.077039, loss_ce: 0.012119
[00:57:20.131] iteration 8190 : loss : 0.069561, loss_ce: 0.021340
[00:57:20.437] iteration 8191 : loss : 0.068523, loss_ce: 0.028656
[00:57:20.745] iteration 8192 : loss : 0.082317, loss_ce: 0.023382
[00:57:21.055] iteration 8193 : loss : 0.113751, loss_ce: 0.006810
[00:57:21.361] iteration 8194 : loss : 0.058951, loss_ce: 0.017890
[00:57:21.671] iteration 8195 : loss : 0.058539, loss_ce: 0.023038
[00:57:21.985] iteration 8196 : loss : 0.055040, loss_ce: 0.023314
[00:57:22.293] iteration 8197 : loss : 0.072108, loss_ce: 0.018565
[00:57:22.608] iteration 8198 : loss : 0.116718, loss_ce: 0.014303
[00:57:22.913] iteration 8199 : loss : 0.064051, loss_ce: 0.013643
[00:57:23.223] iteration 8200 : loss : 0.073836, loss_ce: 0.014796
[00:57:23.333] iteration 8201 : loss : 0.410883, loss_ce: 0.013057
[00:57:43.696] iteration 8202 : loss : 0.059526, loss_ce: 0.016191
[00:57:43.996] iteration 8203 : loss : 0.086260, loss_ce: 0.024149
[00:57:44.299] iteration 8204 : loss : 0.066261, loss_ce: 0.019091
[00:57:44.605] iteration 8205 : loss : 0.061762, loss_ce: 0.019243
[00:57:44.906] iteration 8206 : loss : 0.072824, loss_ce: 0.024276
[00:57:45.210] iteration 8207 : loss : 0.052717, loss_ce: 0.015735
[00:57:45.511] iteration 8208 : loss : 0.053427, loss_ce: 0.021348
[00:57:45.815] iteration 8209 : loss : 0.089280, loss_ce: 0.017921
[00:57:46.120] iteration 8210 : loss : 0.071081, loss_ce: 0.020856
[00:57:46.423] iteration 8211 : loss : 0.058323, loss_ce: 0.016961
[00:57:46.727] iteration 8212 : loss : 0.112630, loss_ce: 0.016078
[00:57:47.029] iteration 8213 : loss : 0.066396, loss_ce: 0.024821
[00:57:47.334] iteration 8214 : loss : 0.116173, loss_ce: 0.016660
[00:57:47.639] iteration 8215 : loss : 0.052141, loss_ce: 0.017551
[00:57:47.949] iteration 8216 : loss : 0.048609, loss_ce: 0.007612
[00:57:48.253] iteration 8217 : loss : 0.071075, loss_ce: 0.007748
[00:57:48.562] iteration 8218 : loss : 0.073485, loss_ce: 0.018966
[00:57:48.864] iteration 8219 : loss : 0.051101, loss_ce: 0.016837
[00:57:49.168] iteration 8220 : loss : 0.285830, loss_ce: 0.013414
[00:57:49.491] iteration 8221 : loss : 0.132986, loss_ce: 0.006292
[00:57:49.799] iteration 8222 : loss : 0.082254, loss_ce: 0.015600
[00:57:50.109] iteration 8223 : loss : 0.056579, loss_ce: 0.018181
[00:57:50.419] iteration 8224 : loss : 0.174301, loss_ce: 0.009133
[00:57:50.728] iteration 8225 : loss : 0.059217, loss_ce: 0.022100
[00:57:51.036] iteration 8226 : loss : 0.092795, loss_ce: 0.028375
[00:57:51.348] iteration 8227 : loss : 0.058591, loss_ce: 0.014146
[00:57:51.652] iteration 8228 : loss : 0.049306, loss_ce: 0.022327
[00:57:51.962] iteration 8229 : loss : 0.169705, loss_ce: 0.013626
[00:57:52.269] iteration 8230 : loss : 0.117730, loss_ce: 0.010684
[00:57:52.577] iteration 8231 : loss : 0.066730, loss_ce: 0.022334
[00:57:52.882] iteration 8232 : loss : 0.072757, loss_ce: 0.022934
[00:57:53.192] iteration 8233 : loss : 0.073886, loss_ce: 0.019992
[00:57:53.502] iteration 8234 : loss : 0.064635, loss_ce: 0.025278
[00:57:53.813] iteration 8235 : loss : 0.113105, loss_ce: 0.012783
[00:57:54.119] iteration 8236 : loss : 0.096774, loss_ce: 0.024719
[00:57:54.423] iteration 8237 : loss : 0.116401, loss_ce: 0.018199
[00:57:54.730] iteration 8238 : loss : 0.066869, loss_ce: 0.019738
[00:57:55.042] iteration 8239 : loss : 0.061422, loss_ce: 0.015759
[00:57:55.347] iteration 8240 : loss : 0.089191, loss_ce: 0.014124
[00:57:55.669] iteration 8241 : loss : 0.052170, loss_ce: 0.019772
[00:57:55.975] iteration 8242 : loss : 0.108234, loss_ce: 0.010572
[00:57:56.281] iteration 8243 : loss : 0.169644, loss_ce: 0.014870
[00:57:56.585] iteration 8244 : loss : 0.056505, loss_ce: 0.026691
[00:57:56.895] iteration 8245 : loss : 0.057439, loss_ce: 0.015258
[00:57:57.200] iteration 8246 : loss : 0.106930, loss_ce: 0.021611
[00:57:57.510] iteration 8247 : loss : 0.068313, loss_ce: 0.018892
[00:57:57.816] iteration 8248 : loss : 0.064471, loss_ce: 0.023654
[00:57:58.122] iteration 8249 : loss : 0.120447, loss_ce: 0.017386
[00:57:58.429] iteration 8250 : loss : 0.074413, loss_ce: 0.019657
[00:57:58.739] iteration 8251 : loss : 0.061849, loss_ce: 0.026588
[00:57:59.044] iteration 8252 : loss : 0.113750, loss_ce: 0.016582
[00:57:59.348] iteration 8253 : loss : 0.040805, loss_ce: 0.013753
[00:57:59.657] iteration 8254 : loss : 0.044906, loss_ce: 0.016764
[00:57:59.965] iteration 8255 : loss : 0.052082, loss_ce: 0.020001
[00:58:00.272] iteration 8256 : loss : 0.086499, loss_ce: 0.017302
[00:58:00.580] iteration 8257 : loss : 0.058650, loss_ce: 0.020347
[00:58:00.887] iteration 8258 : loss : 0.052182, loss_ce: 0.021655
[00:58:01.200] iteration 8259 : loss : 0.128747, loss_ce: 0.020063
[00:58:01.506] iteration 8260 : loss : 0.091315, loss_ce: 0.016277
[00:58:01.831] iteration 8261 : loss : 0.111868, loss_ce: 0.017720
[00:58:02.136] iteration 8262 : loss : 0.082230, loss_ce: 0.006807
[00:58:02.440] iteration 8263 : loss : 0.092326, loss_ce: 0.031039
[00:58:02.745] iteration 8264 : loss : 0.068686, loss_ce: 0.024164
[00:58:03.052] iteration 8265 : loss : 0.052265, loss_ce: 0.024043
[00:58:03.360] iteration 8266 : loss : 0.238960, loss_ce: 0.019286
[00:58:03.672] iteration 8267 : loss : 0.120722, loss_ce: 0.011948
[00:58:03.977] iteration 8268 : loss : 0.064496, loss_ce: 0.021249
[00:58:04.285] iteration 8269 : loss : 0.091996, loss_ce: 0.013609
[00:58:04.593] iteration 8270 : loss : 0.085862, loss_ce: 0.011924
[00:58:04.901] iteration 8271 : loss : 0.230645, loss_ce: 0.007158
[00:58:05.213] iteration 8272 : loss : 0.054604, loss_ce: 0.014624
[00:58:05.519] iteration 8273 : loss : 0.084970, loss_ce: 0.030363
[00:58:05.827] iteration 8274 : loss : 0.065452, loss_ce: 0.019278
[00:58:06.141] iteration 8275 : loss : 0.087499, loss_ce: 0.017101
[00:58:06.447] iteration 8276 : loss : 0.110128, loss_ce: 0.016871
[00:58:06.752] iteration 8277 : loss : 0.118965, loss_ce: 0.009430
[00:58:07.061] iteration 8278 : loss : 0.118212, loss_ce: 0.025302
[00:58:07.371] iteration 8279 : loss : 0.108264, loss_ce: 0.015679
[00:58:07.679] iteration 8280 : loss : 0.064058, loss_ce: 0.020452
[00:58:08.001] iteration 8281 : loss : 0.056357, loss_ce: 0.026897
[00:58:08.311] iteration 8282 : loss : 0.065047, loss_ce: 0.017213
[00:58:08.619] iteration 8283 : loss : 0.070094, loss_ce: 0.020660
[00:58:08.932] iteration 8284 : loss : 0.065765, loss_ce: 0.027493
[00:58:09.237] iteration 8285 : loss : 0.064093, loss_ce: 0.017566
[00:58:09.542] iteration 8286 : loss : 0.090810, loss_ce: 0.028143
[00:58:09.848] iteration 8287 : loss : 0.077949, loss_ce: 0.019319
[00:58:10.154] iteration 8288 : loss : 0.057440, loss_ce: 0.017226
[00:58:10.460] iteration 8289 : loss : 0.071147, loss_ce: 0.017292
[00:58:10.764] iteration 8290 : loss : 0.067923, loss_ce: 0.015423
[00:58:11.064] iteration 8291 : loss : 0.123348, loss_ce: 0.023845
[00:58:11.369] iteration 8292 : loss : 0.056819, loss_ce: 0.013830
[00:58:11.672] iteration 8293 : loss : 0.064692, loss_ce: 0.020012
[00:58:11.975] iteration 8294 : loss : 0.075267, loss_ce: 0.011835
[00:58:12.277] iteration 8295 : loss : 0.093143, loss_ce: 0.029100
[00:58:12.577] iteration 8296 : loss : 0.067964, loss_ce: 0.022258
[00:58:12.880] iteration 8297 : loss : 0.071072, loss_ce: 0.014310
[00:58:13.187] iteration 8298 : loss : 0.148148, loss_ce: 0.013436
[00:58:13.492] iteration 8299 : loss : 0.070769, loss_ce: 0.024889
[00:58:13.799] iteration 8300 : loss : 0.059496, loss_ce: 0.017779
[00:58:14.124] iteration 8301 : loss : 0.066407, loss_ce: 0.018382
[00:58:14.426] iteration 8302 : loss : 0.070402, loss_ce: 0.008967
[00:58:14.730] iteration 8303 : loss : 0.057116, loss_ce: 0.020010
[00:58:15.035] iteration 8304 : loss : 0.073161, loss_ce: 0.021343
[00:58:15.336] iteration 8305 : loss : 0.072366, loss_ce: 0.030590
[00:58:15.639] iteration 8306 : loss : 0.051377, loss_ce: 0.014151
[00:58:15.943] iteration 8307 : loss : 0.059551, loss_ce: 0.023911
[00:58:16.245] iteration 8308 : loss : 0.073426, loss_ce: 0.036235
[00:58:16.550] iteration 8309 : loss : 0.075052, loss_ce: 0.021281
[00:58:16.854] iteration 8310 : loss : 0.072556, loss_ce: 0.018450
[00:58:17.161] iteration 8311 : loss : 0.084771, loss_ce: 0.030015
[00:58:17.468] iteration 8312 : loss : 0.056679, loss_ce: 0.010992
[00:58:17.775] iteration 8313 : loss : 0.042350, loss_ce: 0.013013
[00:58:18.080] iteration 8314 : loss : 0.215462, loss_ce: 0.008372
[00:58:18.383] iteration 8315 : loss : 0.044101, loss_ce: 0.010211
[00:58:18.686] iteration 8316 : loss : 0.107612, loss_ce: 0.008041
[00:58:18.988] iteration 8317 : loss : 0.117270, loss_ce: 0.016593
[00:58:19.294] iteration 8318 : loss : 0.054924, loss_ce: 0.020212
[00:58:19.596] iteration 8319 : loss : 0.115391, loss_ce: 0.013910
[00:58:19.901] iteration 8320 : loss : 0.087674, loss_ce: 0.020352
[00:58:20.217] iteration 8321 : loss : 0.068082, loss_ce: 0.031470
[00:58:20.520] iteration 8322 : loss : 0.075600, loss_ce: 0.018832
[00:58:20.823] iteration 8323 : loss : 0.120267, loss_ce: 0.020387
[00:58:21.132] iteration 8324 : loss : 0.081353, loss_ce: 0.013155
[00:58:21.442] iteration 8325 : loss : 0.056755, loss_ce: 0.010839
[00:58:21.745] iteration 8326 : loss : 0.116573, loss_ce: 0.027323
[00:58:22.058] iteration 8327 : loss : 0.077830, loss_ce: 0.020421
[00:58:22.374] iteration 8328 : loss : 0.060110, loss_ce: 0.024264
[00:58:22.688] iteration 8329 : loss : 0.055636, loss_ce: 0.020239
[00:58:23.005] iteration 8330 : loss : 0.072762, loss_ce: 0.017357
[00:58:23.321] iteration 8331 : loss : 0.181968, loss_ce: 0.009926
[00:58:23.636] iteration 8332 : loss : 0.114038, loss_ce: 0.022429
[00:58:23.954] iteration 8333 : loss : 0.066271, loss_ce: 0.015165
[00:58:24.264] iteration 8334 : loss : 0.052642, loss_ce: 0.016165
[00:58:24.569] iteration 8335 : loss : 0.067026, loss_ce: 0.019234
[00:58:24.873] iteration 8336 : loss : 0.062446, loss_ce: 0.021477
[00:58:25.180] iteration 8337 : loss : 0.145284, loss_ce: 0.023962
[00:58:25.488] iteration 8338 : loss : 0.059165, loss_ce: 0.021369
[00:58:25.797] iteration 8339 : loss : 0.071782, loss_ce: 0.017162
[00:58:25.883] iteration 8340 : loss : 0.194308, loss_ce: 0.022467
[00:58:45.259] iteration 8341 : loss : 0.062491, loss_ce: 0.016761
[00:58:45.556] iteration 8342 : loss : 0.113219, loss_ce: 0.019954
[00:58:45.858] iteration 8343 : loss : 0.072599, loss_ce: 0.020825
[00:58:46.161] iteration 8344 : loss : 0.078865, loss_ce: 0.014528
[00:58:46.464] iteration 8345 : loss : 0.085136, loss_ce: 0.012098
[00:58:46.768] iteration 8346 : loss : 0.120639, loss_ce: 0.015894
[00:58:47.071] iteration 8347 : loss : 0.056141, loss_ce: 0.018152
[00:58:47.371] iteration 8348 : loss : 0.057261, loss_ce: 0.023776
[00:58:47.674] iteration 8349 : loss : 0.058148, loss_ce: 0.024597
[00:58:47.978] iteration 8350 : loss : 0.058396, loss_ce: 0.014571
[00:58:48.282] iteration 8351 : loss : 0.070859, loss_ce: 0.019455
[00:58:48.586] iteration 8352 : loss : 0.184243, loss_ce: 0.011361
[00:58:48.889] iteration 8353 : loss : 0.066581, loss_ce: 0.019151
[00:58:49.196] iteration 8354 : loss : 0.074239, loss_ce: 0.013364
[00:58:49.501] iteration 8355 : loss : 0.070311, loss_ce: 0.022730
[00:58:49.804] iteration 8356 : loss : 0.112867, loss_ce: 0.009357
[00:58:50.110] iteration 8357 : loss : 0.053925, loss_ce: 0.025367
[00:58:50.417] iteration 8358 : loss : 0.105795, loss_ce: 0.009262
[00:58:50.725] iteration 8359 : loss : 0.048957, loss_ce: 0.015136
[00:58:51.023] iteration 8360 : loss : 0.061774, loss_ce: 0.012161
[00:58:51.345] iteration 8361 : loss : 0.063869, loss_ce: 0.025109
[00:58:51.649] iteration 8362 : loss : 0.076324, loss_ce: 0.017378
[00:58:51.958] iteration 8363 : loss : 0.110050, loss_ce: 0.018636
[00:58:52.269] iteration 8364 : loss : 0.061473, loss_ce: 0.015787
[00:58:52.580] iteration 8365 : loss : 0.059442, loss_ce: 0.011143
[00:58:52.890] iteration 8366 : loss : 0.089866, loss_ce: 0.027805
[00:58:53.198] iteration 8367 : loss : 0.055697, loss_ce: 0.013649
[00:58:53.510] iteration 8368 : loss : 0.050190, loss_ce: 0.013600
[00:58:53.819] iteration 8369 : loss : 0.054303, loss_ce: 0.020026
[00:58:54.132] iteration 8370 : loss : 0.060211, loss_ce: 0.005102
[00:58:54.440] iteration 8371 : loss : 0.155402, loss_ce: 0.005533
[00:58:54.748] iteration 8372 : loss : 0.117736, loss_ce: 0.011325
[00:58:55.057] iteration 8373 : loss : 0.071789, loss_ce: 0.017323
[00:58:55.365] iteration 8374 : loss : 0.059706, loss_ce: 0.013595
[00:58:55.671] iteration 8375 : loss : 0.054135, loss_ce: 0.012426
[00:58:55.976] iteration 8376 : loss : 0.059964, loss_ce: 0.024361
[00:58:56.280] iteration 8377 : loss : 0.128421, loss_ce: 0.009674
[00:58:56.584] iteration 8378 : loss : 0.068369, loss_ce: 0.022111
[00:58:56.886] iteration 8379 : loss : 0.054682, loss_ce: 0.016739
[00:58:57.194] iteration 8380 : loss : 0.077923, loss_ce: 0.018849
[00:58:57.510] iteration 8381 : loss : 0.169834, loss_ce: 0.011536
[00:58:57.812] iteration 8382 : loss : 0.063665, loss_ce: 0.009047
[00:58:58.117] iteration 8383 : loss : 0.059020, loss_ce: 0.020688
[00:58:58.421] iteration 8384 : loss : 0.061607, loss_ce: 0.027096
[00:58:58.725] iteration 8385 : loss : 0.166416, loss_ce: 0.010757
[00:58:59.029] iteration 8386 : loss : 0.048628, loss_ce: 0.012574
[00:58:59.336] iteration 8387 : loss : 0.048146, loss_ce: 0.012965
[00:58:59.639] iteration 8388 : loss : 0.060672, loss_ce: 0.012762
[00:58:59.947] iteration 8389 : loss : 0.038653, loss_ce: 0.009156
[00:59:00.250] iteration 8390 : loss : 0.066731, loss_ce: 0.028637
[00:59:00.559] iteration 8391 : loss : 0.067527, loss_ce: 0.007609
[00:59:00.866] iteration 8392 : loss : 0.057784, loss_ce: 0.019805
[00:59:01.176] iteration 8393 : loss : 0.048584, loss_ce: 0.016295
[00:59:01.476] iteration 8394 : loss : 0.052614, loss_ce: 0.021894
[00:59:01.785] iteration 8395 : loss : 0.070667, loss_ce: 0.011863
[00:59:02.092] iteration 8396 : loss : 0.108257, loss_ce: 0.016259
[00:59:02.394] iteration 8397 : loss : 0.070646, loss_ce: 0.019122
[00:59:02.696] iteration 8398 : loss : 0.066335, loss_ce: 0.022820
[00:59:03.006] iteration 8399 : loss : 0.043687, loss_ce: 0.011621
[00:59:03.309] iteration 8400 : loss : 0.056702, loss_ce: 0.010515
[00:59:03.638] iteration 8401 : loss : 0.070810, loss_ce: 0.016610
[00:59:03.940] iteration 8402 : loss : 0.062503, loss_ce: 0.020399
[00:59:04.248] iteration 8403 : loss : 0.094107, loss_ce: 0.023282
[00:59:04.554] iteration 8404 : loss : 0.056531, loss_ce: 0.018683
[00:59:04.858] iteration 8405 : loss : 0.058642, loss_ce: 0.021750
[00:59:05.161] iteration 8406 : loss : 0.049631, loss_ce: 0.017377
[00:59:05.467] iteration 8407 : loss : 0.056932, loss_ce: 0.017401
[00:59:05.775] iteration 8408 : loss : 0.066940, loss_ce: 0.008470
[00:59:06.079] iteration 8409 : loss : 0.047172, loss_ce: 0.024044
[00:59:06.386] iteration 8410 : loss : 0.073569, loss_ce: 0.025842
[00:59:06.692] iteration 8411 : loss : 0.065728, loss_ce: 0.016176
[00:59:06.997] iteration 8412 : loss : 0.053289, loss_ce: 0.025795
[00:59:07.305] iteration 8413 : loss : 0.070888, loss_ce: 0.018426
[00:59:07.611] iteration 8414 : loss : 0.042701, loss_ce: 0.011688
[00:59:07.921] iteration 8415 : loss : 0.051710, loss_ce: 0.016035
[00:59:08.228] iteration 8416 : loss : 0.060251, loss_ce: 0.016096
[00:59:08.534] iteration 8417 : loss : 0.103732, loss_ce: 0.011963
[00:59:08.842] iteration 8418 : loss : 0.110234, loss_ce: 0.011281
[00:59:09.150] iteration 8419 : loss : 0.219822, loss_ce: 0.008400
[00:59:09.457] iteration 8420 : loss : 0.062302, loss_ce: 0.014451
[00:59:09.784] iteration 8421 : loss : 0.056314, loss_ce: 0.025084
[00:59:10.093] iteration 8422 : loss : 0.105717, loss_ce: 0.017552
[00:59:10.402] iteration 8423 : loss : 0.053852, loss_ce: 0.020899
[00:59:10.715] iteration 8424 : loss : 0.075398, loss_ce: 0.013731
[00:59:11.026] iteration 8425 : loss : 0.114503, loss_ce: 0.019287
[00:59:11.341] iteration 8426 : loss : 0.091458, loss_ce: 0.017970
[00:59:11.650] iteration 8427 : loss : 0.046715, loss_ce: 0.017327
[00:59:11.959] iteration 8428 : loss : 0.059085, loss_ce: 0.018089
[00:59:12.269] iteration 8429 : loss : 0.077934, loss_ce: 0.030437
[00:59:12.577] iteration 8430 : loss : 0.053168, loss_ce: 0.015837
[00:59:12.891] iteration 8431 : loss : 0.065817, loss_ce: 0.027267
[00:59:13.202] iteration 8432 : loss : 0.103226, loss_ce: 0.024348
[00:59:13.513] iteration 8433 : loss : 0.066508, loss_ce: 0.019125
[00:59:13.823] iteration 8434 : loss : 0.064766, loss_ce: 0.024282
[00:59:14.136] iteration 8435 : loss : 0.114916, loss_ce: 0.015378
[00:59:14.444] iteration 8436 : loss : 0.049136, loss_ce: 0.014001
[00:59:14.762] iteration 8437 : loss : 0.042887, loss_ce: 0.013808
[00:59:15.072] iteration 8438 : loss : 0.063958, loss_ce: 0.026004
[00:59:15.377] iteration 8439 : loss : 0.166358, loss_ce: 0.020041
[00:59:15.688] iteration 8440 : loss : 0.165796, loss_ce: 0.008312
[00:59:16.010] iteration 8441 : loss : 0.057010, loss_ce: 0.006564
[00:59:16.320] iteration 8442 : loss : 0.062506, loss_ce: 0.013819
[00:59:16.629] iteration 8443 : loss : 0.064487, loss_ce: 0.010855
[00:59:16.938] iteration 8444 : loss : 0.101973, loss_ce: 0.012845
[00:59:17.247] iteration 8445 : loss : 0.083560, loss_ce: 0.029893
[00:59:17.557] iteration 8446 : loss : 0.053310, loss_ce: 0.023620
[00:59:17.869] iteration 8447 : loss : 0.051894, loss_ce: 0.013487
[00:59:18.178] iteration 8448 : loss : 0.066597, loss_ce: 0.016988
[00:59:18.489] iteration 8449 : loss : 0.118379, loss_ce: 0.025639
[00:59:18.796] iteration 8450 : loss : 0.047410, loss_ce: 0.017005
[00:59:19.108] iteration 8451 : loss : 0.065448, loss_ce: 0.016842
[00:59:19.418] iteration 8452 : loss : 0.069429, loss_ce: 0.020629
[00:59:19.728] iteration 8453 : loss : 0.114287, loss_ce: 0.015700
[00:59:20.042] iteration 8454 : loss : 0.069862, loss_ce: 0.016983
[00:59:20.349] iteration 8455 : loss : 0.053991, loss_ce: 0.012860
[00:59:20.654] iteration 8456 : loss : 0.050815, loss_ce: 0.011187
[00:59:20.963] iteration 8457 : loss : 0.076136, loss_ce: 0.013418
[00:59:21.274] iteration 8458 : loss : 0.051128, loss_ce: 0.012930
[00:59:21.579] iteration 8459 : loss : 0.114484, loss_ce: 0.023821
[00:59:21.885] iteration 8460 : loss : 0.067963, loss_ce: 0.016694
[00:59:22.212] iteration 8461 : loss : 0.046641, loss_ce: 0.013681
[00:59:22.516] iteration 8462 : loss : 0.124728, loss_ce: 0.014057
[00:59:22.830] iteration 8463 : loss : 0.065323, loss_ce: 0.019767
[00:59:23.143] iteration 8464 : loss : 0.058660, loss_ce: 0.021078
[00:59:23.450] iteration 8465 : loss : 0.064298, loss_ce: 0.022077
[00:59:23.764] iteration 8466 : loss : 0.113344, loss_ce: 0.007610
[00:59:24.073] iteration 8467 : loss : 0.066108, loss_ce: 0.021321
[00:59:24.383] iteration 8468 : loss : 0.062258, loss_ce: 0.021299
[00:59:24.698] iteration 8469 : loss : 0.067244, loss_ce: 0.024879
[00:59:25.014] iteration 8470 : loss : 0.072352, loss_ce: 0.017338
[00:59:25.327] iteration 8471 : loss : 0.054547, loss_ce: 0.020656
[00:59:25.646] iteration 8472 : loss : 0.057120, loss_ce: 0.025179
[00:59:25.957] iteration 8473 : loss : 0.058035, loss_ce: 0.027355
[00:59:26.267] iteration 8474 : loss : 0.128733, loss_ce: 0.005925
[00:59:26.575] iteration 8475 : loss : 0.061871, loss_ce: 0.019984
[00:59:26.887] iteration 8476 : loss : 0.075078, loss_ce: 0.016418
[00:59:27.198] iteration 8477 : loss : 0.102235, loss_ce: 0.017447
[00:59:27.512] iteration 8478 : loss : 0.069021, loss_ce: 0.018586
[00:59:27.596] iteration 8479 : loss : 0.058152, loss_ce: 0.032862
[00:59:28.138] save model to ./logs/swin_unet\epoch_60.pth
[00:59:45.982] iteration 8480 : loss : 0.057351, loss_ce: 0.016652
[00:59:46.301] iteration 8481 : loss : 0.059831, loss_ce: 0.015848
[00:59:46.601] iteration 8482 : loss : 0.063620, loss_ce: 0.021689
[00:59:46.908] iteration 8483 : loss : 0.058575, loss_ce: 0.017111
[00:59:47.211] iteration 8484 : loss : 0.050498, loss_ce: 0.012344
[00:59:47.513] iteration 8485 : loss : 0.050104, loss_ce: 0.023830
[00:59:47.816] iteration 8486 : loss : 0.077577, loss_ce: 0.015026
[00:59:48.118] iteration 8487 : loss : 0.096873, loss_ce: 0.015440
[00:59:48.424] iteration 8488 : loss : 0.061279, loss_ce: 0.020673
[00:59:48.725] iteration 8489 : loss : 0.056238, loss_ce: 0.021297
[00:59:49.028] iteration 8490 : loss : 0.055184, loss_ce: 0.016731
[00:59:49.334] iteration 8491 : loss : 0.064401, loss_ce: 0.009041
[00:59:49.638] iteration 8492 : loss : 0.062439, loss_ce: 0.015911
[00:59:49.939] iteration 8493 : loss : 0.056957, loss_ce: 0.017824
[00:59:50.243] iteration 8494 : loss : 0.109388, loss_ce: 0.027117
[00:59:50.547] iteration 8495 : loss : 0.050902, loss_ce: 0.022777
[00:59:50.850] iteration 8496 : loss : 0.075959, loss_ce: 0.022854
[00:59:51.154] iteration 8497 : loss : 0.077021, loss_ce: 0.023407
[00:59:51.457] iteration 8498 : loss : 0.048160, loss_ce: 0.014403
[00:59:51.761] iteration 8499 : loss : 0.070442, loss_ce: 0.025371
[00:59:52.061] iteration 8500 : loss : 0.062485, loss_ce: 0.027608
[00:59:52.383] iteration 8501 : loss : 0.071716, loss_ce: 0.022068
[00:59:52.685] iteration 8502 : loss : 0.061734, loss_ce: 0.027706
[00:59:52.989] iteration 8503 : loss : 0.073966, loss_ce: 0.025038
[00:59:53.293] iteration 8504 : loss : 0.155621, loss_ce: 0.008909
[00:59:53.597] iteration 8505 : loss : 0.152414, loss_ce: 0.009659
[00:59:53.903] iteration 8506 : loss : 0.116725, loss_ce: 0.010787
[00:59:54.206] iteration 8507 : loss : 0.111879, loss_ce: 0.015307
[00:59:54.510] iteration 8508 : loss : 0.044829, loss_ce: 0.009803
[00:59:54.811] iteration 8509 : loss : 0.043968, loss_ce: 0.016521
[00:59:55.116] iteration 8510 : loss : 0.128775, loss_ce: 0.014179
[00:59:55.420] iteration 8511 : loss : 0.106378, loss_ce: 0.016342
[00:59:55.869] iteration 8512 : loss : 0.058169, loss_ce: 0.021889
[00:59:56.167] iteration 8513 : loss : 0.069887, loss_ce: 0.015579
[00:59:56.471] iteration 8514 : loss : 0.050854, loss_ce: 0.014188
[00:59:56.777] iteration 8515 : loss : 0.058911, loss_ce: 0.014530
[00:59:57.079] iteration 8516 : loss : 0.175661, loss_ce: 0.005629
[00:59:57.422] iteration 8517 : loss : 0.057680, loss_ce: 0.013872
[00:59:57.749] iteration 8518 : loss : 0.062091, loss_ce: 0.020359
[00:59:58.081] iteration 8519 : loss : 0.109277, loss_ce: 0.016462
[00:59:58.420] iteration 8520 : loss : 0.055397, loss_ce: 0.023212
[00:59:58.767] iteration 8521 : loss : 0.070622, loss_ce: 0.015370
[00:59:59.101] iteration 8522 : loss : 0.064133, loss_ce: 0.020205
[00:59:59.429] iteration 8523 : loss : 0.176368, loss_ce: 0.008721
[00:59:59.749] iteration 8524 : loss : 0.050822, loss_ce: 0.017538
[01:00:00.072] iteration 8525 : loss : 0.051727, loss_ce: 0.020873
[01:00:00.399] iteration 8526 : loss : 0.081957, loss_ce: 0.035828
[01:00:00.722] iteration 8527 : loss : 0.049321, loss_ce: 0.015281
[01:00:01.077] iteration 8528 : loss : 0.049582, loss_ce: 0.013635
[01:00:01.397] iteration 8529 : loss : 0.055427, loss_ce: 0.017926
[01:00:01.722] iteration 8530 : loss : 0.051199, loss_ce: 0.017430
[01:00:02.045] iteration 8531 : loss : 0.064529, loss_ce: 0.011482
[01:00:02.363] iteration 8532 : loss : 0.052884, loss_ce: 0.013841
[01:00:02.688] iteration 8533 : loss : 0.120061, loss_ce: 0.026559
[01:00:03.014] iteration 8534 : loss : 0.059647, loss_ce: 0.010929
[01:00:03.337] iteration 8535 : loss : 0.090337, loss_ce: 0.019573
[01:00:03.670] iteration 8536 : loss : 0.218847, loss_ce: 0.013601
[01:00:04.001] iteration 8537 : loss : 0.056624, loss_ce: 0.020847
[01:00:04.327] iteration 8538 : loss : 0.053773, loss_ce: 0.017426
[01:00:04.656] iteration 8539 : loss : 0.075465, loss_ce: 0.023858
[01:00:04.978] iteration 8540 : loss : 0.060326, loss_ce: 0.011353
[01:00:05.321] iteration 8541 : loss : 0.043146, loss_ce: 0.018597
[01:00:05.646] iteration 8542 : loss : 0.063586, loss_ce: 0.014927
[01:00:06.020] iteration 8543 : loss : 0.057426, loss_ce: 0.020177
[01:00:06.333] iteration 8544 : loss : 0.121742, loss_ce: 0.010908
[01:00:06.640] iteration 8545 : loss : 0.062311, loss_ce: 0.019948
[01:00:06.946] iteration 8546 : loss : 0.105540, loss_ce: 0.006688
[01:00:07.250] iteration 8547 : loss : 0.059073, loss_ce: 0.011221
[01:00:07.556] iteration 8548 : loss : 0.061725, loss_ce: 0.014206
[01:00:07.859] iteration 8549 : loss : 0.057507, loss_ce: 0.021218
[01:00:08.164] iteration 8550 : loss : 0.059032, loss_ce: 0.021244
[01:00:08.468] iteration 8551 : loss : 0.165465, loss_ce: 0.012151
[01:00:08.774] iteration 8552 : loss : 0.081992, loss_ce: 0.008409
[01:00:09.079] iteration 8553 : loss : 0.064225, loss_ce: 0.031786
[01:00:09.387] iteration 8554 : loss : 0.058685, loss_ce: 0.016938
[01:00:09.692] iteration 8555 : loss : 0.058415, loss_ce: 0.016886
[01:00:09.996] iteration 8556 : loss : 0.095206, loss_ce: 0.018955
[01:00:10.300] iteration 8557 : loss : 0.068199, loss_ce: 0.022134
[01:00:10.603] iteration 8558 : loss : 0.066742, loss_ce: 0.009361
[01:00:10.912] iteration 8559 : loss : 0.168564, loss_ce: 0.003858
[01:00:11.219] iteration 8560 : loss : 0.057649, loss_ce: 0.014138
[01:00:11.535] iteration 8561 : loss : 0.061635, loss_ce: 0.016895
[01:00:11.836] iteration 8562 : loss : 0.120830, loss_ce: 0.015302
[01:00:12.146] iteration 8563 : loss : 0.054190, loss_ce: 0.016228
[01:00:12.449] iteration 8564 : loss : 0.050341, loss_ce: 0.020603
[01:00:12.758] iteration 8565 : loss : 0.108928, loss_ce: 0.013182
[01:00:13.069] iteration 8566 : loss : 0.053019, loss_ce: 0.021295
[01:00:13.378] iteration 8567 : loss : 0.093127, loss_ce: 0.016646
[01:00:13.685] iteration 8568 : loss : 0.118604, loss_ce: 0.009055
[01:00:13.995] iteration 8569 : loss : 0.066775, loss_ce: 0.021437
[01:00:14.305] iteration 8570 : loss : 0.067504, loss_ce: 0.018900
[01:00:14.604] iteration 8571 : loss : 0.058942, loss_ce: 0.020826
[01:00:14.909] iteration 8572 : loss : 0.081465, loss_ce: 0.037062
[01:00:15.214] iteration 8573 : loss : 0.063328, loss_ce: 0.017630
[01:00:15.518] iteration 8574 : loss : 0.061557, loss_ce: 0.012339
[01:00:15.820] iteration 8575 : loss : 0.110339, loss_ce: 0.006824
[01:00:16.123] iteration 8576 : loss : 0.070291, loss_ce: 0.026994
[01:00:16.425] iteration 8577 : loss : 0.078648, loss_ce: 0.022123
[01:00:16.730] iteration 8578 : loss : 0.167757, loss_ce: 0.013359
[01:00:17.035] iteration 8579 : loss : 0.065378, loss_ce: 0.010489
[01:00:17.344] iteration 8580 : loss : 0.061739, loss_ce: 0.021791
[01:00:17.661] iteration 8581 : loss : 0.068469, loss_ce: 0.010570
[01:00:17.965] iteration 8582 : loss : 0.156101, loss_ce: 0.011361
[01:00:18.271] iteration 8583 : loss : 0.073438, loss_ce: 0.022184
[01:00:18.571] iteration 8584 : loss : 0.057504, loss_ce: 0.019331
[01:00:18.875] iteration 8585 : loss : 0.144326, loss_ce: 0.010741
[01:00:19.177] iteration 8586 : loss : 0.067344, loss_ce: 0.018498
[01:00:19.484] iteration 8587 : loss : 0.052553, loss_ce: 0.011923
[01:00:19.787] iteration 8588 : loss : 0.055279, loss_ce: 0.011555
[01:00:20.090] iteration 8589 : loss : 0.114907, loss_ce: 0.020244
[01:00:20.396] iteration 8590 : loss : 0.056729, loss_ce: 0.023121
[01:00:20.700] iteration 8591 : loss : 0.046157, loss_ce: 0.013879
[01:00:21.005] iteration 8592 : loss : 0.121358, loss_ce: 0.023699
[01:00:21.310] iteration 8593 : loss : 0.066146, loss_ce: 0.020209
[01:00:21.612] iteration 8594 : loss : 0.044909, loss_ce: 0.013282
[01:00:21.914] iteration 8595 : loss : 0.056686, loss_ce: 0.016758
[01:00:22.216] iteration 8596 : loss : 0.047330, loss_ce: 0.022992
[01:00:22.519] iteration 8597 : loss : 0.055637, loss_ce: 0.009241
[01:00:22.822] iteration 8598 : loss : 0.105390, loss_ce: 0.011794
[01:00:23.125] iteration 8599 : loss : 0.061978, loss_ce: 0.010722
[01:00:23.430] iteration 8600 : loss : 0.054857, loss_ce: 0.015540
[01:00:23.751] iteration 8601 : loss : 0.083343, loss_ce: 0.017145
[01:00:24.058] iteration 8602 : loss : 0.065675, loss_ce: 0.025574
[01:00:24.365] iteration 8603 : loss : 0.056575, loss_ce: 0.026308
[01:00:24.676] iteration 8604 : loss : 0.108512, loss_ce: 0.024490
[01:00:24.991] iteration 8605 : loss : 0.054071, loss_ce: 0.027221
[01:00:25.296] iteration 8606 : loss : 0.089453, loss_ce: 0.016338
[01:00:25.610] iteration 8607 : loss : 0.063664, loss_ce: 0.015508
[01:00:25.915] iteration 8608 : loss : 0.075843, loss_ce: 0.016322
[01:00:26.226] iteration 8609 : loss : 0.157794, loss_ce: 0.007117
[01:00:26.537] iteration 8610 : loss : 0.102879, loss_ce: 0.007283
[01:00:26.844] iteration 8611 : loss : 0.164675, loss_ce: 0.006552
[01:00:27.157] iteration 8612 : loss : 0.113517, loss_ce: 0.016076
[01:00:27.468] iteration 8613 : loss : 0.109173, loss_ce: 0.011754
[01:00:27.783] iteration 8614 : loss : 0.081937, loss_ce: 0.016414
[01:00:28.097] iteration 8615 : loss : 0.053975, loss_ce: 0.024686
[01:00:28.406] iteration 8616 : loss : 0.084068, loss_ce: 0.016849
[01:00:28.716] iteration 8617 : loss : 0.057790, loss_ce: 0.020657
[01:00:28.798] iteration 8618 : loss : 0.066544, loss_ce: 0.015824
[01:00:46.242] iteration 8619 : loss : 0.108621, loss_ce: 0.011910
[01:00:46.546] iteration 8620 : loss : 0.076202, loss_ce: 0.012633
[01:00:46.867] iteration 8621 : loss : 0.053753, loss_ce: 0.020227
[01:00:47.174] iteration 8622 : loss : 0.064684, loss_ce: 0.017426
[01:00:47.486] iteration 8623 : loss : 0.114872, loss_ce: 0.015804
[01:00:47.792] iteration 8624 : loss : 0.063315, loss_ce: 0.020154
[01:00:48.099] iteration 8625 : loss : 0.050848, loss_ce: 0.015292
[01:00:48.407] iteration 8626 : loss : 0.059998, loss_ce: 0.008704
[01:00:48.714] iteration 8627 : loss : 0.046674, loss_ce: 0.010498
[01:00:49.025] iteration 8628 : loss : 0.056010, loss_ce: 0.028361
[01:00:49.329] iteration 8629 : loss : 0.092702, loss_ce: 0.014708
[01:00:49.634] iteration 8630 : loss : 0.121489, loss_ce: 0.014191
[01:00:49.936] iteration 8631 : loss : 0.116216, loss_ce: 0.022716
[01:00:50.241] iteration 8632 : loss : 0.123149, loss_ce: 0.010377
[01:00:50.550] iteration 8633 : loss : 0.188006, loss_ce: 0.003414
[01:00:50.854] iteration 8634 : loss : 0.060081, loss_ce: 0.008639
[01:00:51.158] iteration 8635 : loss : 0.104042, loss_ce: 0.015107
[01:00:51.464] iteration 8636 : loss : 0.058196, loss_ce: 0.008605
[01:00:51.767] iteration 8637 : loss : 0.063281, loss_ce: 0.013754
[01:00:52.071] iteration 8638 : loss : 0.096249, loss_ce: 0.021544
[01:00:52.378] iteration 8639 : loss : 0.068333, loss_ce: 0.018251
[01:00:52.687] iteration 8640 : loss : 0.049479, loss_ce: 0.012820
[01:00:53.006] iteration 8641 : loss : 0.057841, loss_ce: 0.013148
[01:00:53.310] iteration 8642 : loss : 0.074900, loss_ce: 0.022075
[01:00:53.617] iteration 8643 : loss : 0.050720, loss_ce: 0.016951
[01:00:53.922] iteration 8644 : loss : 0.054719, loss_ce: 0.022418
[01:00:54.229] iteration 8645 : loss : 0.067316, loss_ce: 0.025704
[01:00:54.530] iteration 8646 : loss : 0.054910, loss_ce: 0.016055
[01:00:54.835] iteration 8647 : loss : 0.049146, loss_ce: 0.016901
[01:00:55.140] iteration 8648 : loss : 0.058526, loss_ce: 0.023959
[01:00:55.453] iteration 8649 : loss : 0.064126, loss_ce: 0.018696
[01:00:55.755] iteration 8650 : loss : 0.127553, loss_ce: 0.017240
[01:00:56.061] iteration 8651 : loss : 0.046810, loss_ce: 0.013315
[01:00:56.372] iteration 8652 : loss : 0.133611, loss_ce: 0.011458
[01:00:56.673] iteration 8653 : loss : 0.053747, loss_ce: 0.013346
[01:00:56.977] iteration 8654 : loss : 0.067658, loss_ce: 0.018823
[01:00:57.281] iteration 8655 : loss : 0.079706, loss_ce: 0.018883
[01:00:57.586] iteration 8656 : loss : 0.043770, loss_ce: 0.015639
[01:00:57.892] iteration 8657 : loss : 0.064595, loss_ce: 0.016699
[01:00:58.202] iteration 8658 : loss : 0.063685, loss_ce: 0.021132
[01:00:58.505] iteration 8659 : loss : 0.057618, loss_ce: 0.017129
[01:00:58.806] iteration 8660 : loss : 0.074845, loss_ce: 0.012001
[01:00:59.130] iteration 8661 : loss : 0.054938, loss_ce: 0.015149
[01:00:59.433] iteration 8662 : loss : 0.071365, loss_ce: 0.023736
[01:00:59.741] iteration 8663 : loss : 0.118697, loss_ce: 0.015617
[01:01:00.047] iteration 8664 : loss : 0.055423, loss_ce: 0.016996
[01:01:00.355] iteration 8665 : loss : 0.064602, loss_ce: 0.021193
[01:01:00.663] iteration 8666 : loss : 0.042202, loss_ce: 0.005076
[01:01:00.973] iteration 8667 : loss : 0.112426, loss_ce: 0.008285
[01:01:01.281] iteration 8668 : loss : 0.063139, loss_ce: 0.014719
[01:01:01.584] iteration 8669 : loss : 0.087995, loss_ce: 0.022179
[01:01:01.891] iteration 8670 : loss : 0.054850, loss_ce: 0.018269
[01:01:02.198] iteration 8671 : loss : 0.075519, loss_ce: 0.012797
[01:01:02.506] iteration 8672 : loss : 0.068511, loss_ce: 0.021247
[01:01:02.818] iteration 8673 : loss : 0.058170, loss_ce: 0.012968
[01:01:03.123] iteration 8674 : loss : 0.118007, loss_ce: 0.014981
[01:01:03.435] iteration 8675 : loss : 0.048539, loss_ce: 0.015230
[01:01:03.744] iteration 8676 : loss : 0.062066, loss_ce: 0.024879
[01:01:04.053] iteration 8677 : loss : 0.109221, loss_ce: 0.015792
[01:01:04.357] iteration 8678 : loss : 0.117796, loss_ce: 0.016426
[01:01:04.664] iteration 8679 : loss : 0.050586, loss_ce: 0.016545
[01:01:04.974] iteration 8680 : loss : 0.071276, loss_ce: 0.022247
[01:01:05.295] iteration 8681 : loss : 0.118773, loss_ce: 0.014781
[01:01:05.598] iteration 8682 : loss : 0.057161, loss_ce: 0.016171
[01:01:05.904] iteration 8683 : loss : 0.063203, loss_ce: 0.016095
[01:01:06.212] iteration 8684 : loss : 0.050344, loss_ce: 0.011711
[01:01:06.519] iteration 8685 : loss : 0.068064, loss_ce: 0.019706
[01:01:06.823] iteration 8686 : loss : 0.225018, loss_ce: 0.009078
[01:01:07.129] iteration 8687 : loss : 0.275320, loss_ce: 0.015738
[01:01:07.436] iteration 8688 : loss : 0.051987, loss_ce: 0.013255
[01:01:07.742] iteration 8689 : loss : 0.123553, loss_ce: 0.023554
[01:01:08.045] iteration 8690 : loss : 0.077248, loss_ce: 0.022274
[01:01:08.350] iteration 8691 : loss : 0.072330, loss_ce: 0.015913
[01:01:08.660] iteration 8692 : loss : 0.053818, loss_ce: 0.007298
[01:01:08.966] iteration 8693 : loss : 0.049547, loss_ce: 0.010511
[01:01:09.273] iteration 8694 : loss : 0.115264, loss_ce: 0.016256
[01:01:09.579] iteration 8695 : loss : 0.059795, loss_ce: 0.015564
[01:01:09.886] iteration 8696 : loss : 0.103517, loss_ce: 0.007066
[01:01:10.193] iteration 8697 : loss : 0.102695, loss_ce: 0.014051
[01:01:10.502] iteration 8698 : loss : 0.077321, loss_ce: 0.014015
[01:01:10.809] iteration 8699 : loss : 0.066483, loss_ce: 0.016114
[01:01:11.117] iteration 8700 : loss : 0.124053, loss_ce: 0.007579
[01:01:11.438] iteration 8701 : loss : 0.168832, loss_ce: 0.002790
[01:01:11.741] iteration 8702 : loss : 0.057100, loss_ce: 0.021804
[01:01:12.047] iteration 8703 : loss : 0.062232, loss_ce: 0.026493
[01:01:12.350] iteration 8704 : loss : 0.057978, loss_ce: 0.025884
[01:01:12.658] iteration 8705 : loss : 0.058468, loss_ce: 0.023866
[01:01:12.962] iteration 8706 : loss : 0.052320, loss_ce: 0.012455
[01:01:13.269] iteration 8707 : loss : 0.110612, loss_ce: 0.017096
[01:01:13.579] iteration 8708 : loss : 0.177500, loss_ce: 0.008825
[01:01:13.884] iteration 8709 : loss : 0.165793, loss_ce: 0.015456
[01:01:14.189] iteration 8710 : loss : 0.070472, loss_ce: 0.037351
[01:01:14.499] iteration 8711 : loss : 0.051606, loss_ce: 0.019039
[01:01:14.808] iteration 8712 : loss : 0.057525, loss_ce: 0.021245
[01:01:15.113] iteration 8713 : loss : 0.046690, loss_ce: 0.016473
[01:01:15.418] iteration 8714 : loss : 0.087403, loss_ce: 0.020065
[01:01:15.727] iteration 8715 : loss : 0.112259, loss_ce: 0.015811
[01:01:16.036] iteration 8716 : loss : 0.043759, loss_ce: 0.015278
[01:01:16.341] iteration 8717 : loss : 0.106225, loss_ce: 0.015427
[01:01:16.647] iteration 8718 : loss : 0.074803, loss_ce: 0.031189
[01:01:16.955] iteration 8719 : loss : 0.067159, loss_ce: 0.014378
[01:01:17.263] iteration 8720 : loss : 0.061835, loss_ce: 0.020656
[01:01:17.587] iteration 8721 : loss : 0.048224, loss_ce: 0.011164
[01:01:17.896] iteration 8722 : loss : 0.069506, loss_ce: 0.024038
[01:01:18.210] iteration 8723 : loss : 0.055581, loss_ce: 0.018679
[01:01:18.523] iteration 8724 : loss : 0.046337, loss_ce: 0.015649
[01:01:18.831] iteration 8725 : loss : 0.054458, loss_ce: 0.018171
[01:01:19.146] iteration 8726 : loss : 0.186587, loss_ce: 0.011255
[01:01:19.457] iteration 8727 : loss : 0.055459, loss_ce: 0.011586
[01:01:19.762] iteration 8728 : loss : 0.058110, loss_ce: 0.022469
[01:01:20.070] iteration 8729 : loss : 0.053559, loss_ce: 0.021187
[01:01:20.372] iteration 8730 : loss : 0.048211, loss_ce: 0.012431
[01:01:20.681] iteration 8731 : loss : 0.060325, loss_ce: 0.020592
[01:01:20.987] iteration 8732 : loss : 0.054836, loss_ce: 0.011301
[01:01:21.291] iteration 8733 : loss : 0.109510, loss_ce: 0.012903
[01:01:21.597] iteration 8734 : loss : 0.052845, loss_ce: 0.012920
[01:01:21.897] iteration 8735 : loss : 0.062159, loss_ce: 0.028713
[01:01:22.198] iteration 8736 : loss : 0.053331, loss_ce: 0.017104
[01:01:22.504] iteration 8737 : loss : 0.039862, loss_ce: 0.013193
[01:01:22.811] iteration 8738 : loss : 0.046586, loss_ce: 0.016471
[01:01:23.117] iteration 8739 : loss : 0.063336, loss_ce: 0.020345
[01:01:23.422] iteration 8740 : loss : 0.234958, loss_ce: 0.006026
[01:01:23.752] iteration 8741 : loss : 0.050898, loss_ce: 0.020327
[01:01:24.056] iteration 8742 : loss : 0.060488, loss_ce: 0.025990
[01:01:24.365] iteration 8743 : loss : 0.053315, loss_ce: 0.019840
[01:01:24.677] iteration 8744 : loss : 0.060336, loss_ce: 0.016421
[01:01:24.981] iteration 8745 : loss : 0.042147, loss_ce: 0.012314
[01:01:25.286] iteration 8746 : loss : 0.063166, loss_ce: 0.026953
[01:01:25.591] iteration 8747 : loss : 0.064724, loss_ce: 0.014057
[01:01:25.898] iteration 8748 : loss : 0.057096, loss_ce: 0.027997
[01:01:26.210] iteration 8749 : loss : 0.054152, loss_ce: 0.017489
[01:01:26.519] iteration 8750 : loss : 0.060308, loss_ce: 0.022368
[01:01:26.832] iteration 8751 : loss : 0.116655, loss_ce: 0.014533
[01:01:27.137] iteration 8752 : loss : 0.065034, loss_ce: 0.025418
[01:01:27.451] iteration 8753 : loss : 0.063338, loss_ce: 0.018608
[01:01:27.758] iteration 8754 : loss : 0.066771, loss_ce: 0.018320
[01:01:28.066] iteration 8755 : loss : 0.102762, loss_ce: 0.009929
[01:01:28.376] iteration 8756 : loss : 0.079949, loss_ce: 0.024614
[01:01:28.463] iteration 8757 : loss : 0.361548, loss_ce: 0.009770
[01:01:47.574] iteration 8758 : loss : 0.062602, loss_ce: 0.012386
[01:01:47.879] iteration 8759 : loss : 0.065303, loss_ce: 0.011930
[01:01:48.185] iteration 8760 : loss : 0.245516, loss_ce: 0.013285
[01:01:48.504] iteration 8761 : loss : 0.067603, loss_ce: 0.028245
[01:01:48.811] iteration 8762 : loss : 0.064164, loss_ce: 0.022893
[01:01:49.119] iteration 8763 : loss : 0.060940, loss_ce: 0.032829
[01:01:49.432] iteration 8764 : loss : 0.117022, loss_ce: 0.013232
[01:01:49.741] iteration 8765 : loss : 0.051143, loss_ce: 0.013362
[01:01:50.046] iteration 8766 : loss : 0.171063, loss_ce: 0.006980
[01:01:50.354] iteration 8767 : loss : 0.044718, loss_ce: 0.011886
[01:01:50.665] iteration 8768 : loss : 0.054358, loss_ce: 0.018875
[01:01:50.971] iteration 8769 : loss : 0.046734, loss_ce: 0.014746
[01:01:51.278] iteration 8770 : loss : 0.065995, loss_ce: 0.013186
[01:01:51.593] iteration 8771 : loss : 0.066537, loss_ce: 0.026745
[01:01:51.900] iteration 8772 : loss : 0.060410, loss_ce: 0.018755
[01:01:52.211] iteration 8773 : loss : 0.133196, loss_ce: 0.008377
[01:01:52.518] iteration 8774 : loss : 0.066397, loss_ce: 0.027740
[01:01:52.825] iteration 8775 : loss : 0.285302, loss_ce: 0.006080
[01:01:53.135] iteration 8776 : loss : 0.077710, loss_ce: 0.015259
[01:01:53.446] iteration 8777 : loss : 0.176174, loss_ce: 0.016327
[01:01:53.754] iteration 8778 : loss : 0.073066, loss_ce: 0.019784
[01:01:54.064] iteration 8779 : loss : 0.221951, loss_ce: 0.002225
[01:01:54.373] iteration 8780 : loss : 0.118432, loss_ce: 0.010871
[01:01:54.691] iteration 8781 : loss : 0.104196, loss_ce: 0.004356
[01:01:54.994] iteration 8782 : loss : 0.174890, loss_ce: 0.006529
[01:01:55.300] iteration 8783 : loss : 0.042475, loss_ce: 0.016265
[01:01:55.602] iteration 8784 : loss : 0.117749, loss_ce: 0.010033
[01:01:55.906] iteration 8785 : loss : 0.059912, loss_ce: 0.024321
[01:01:56.212] iteration 8786 : loss : 0.064985, loss_ce: 0.013831
[01:01:56.514] iteration 8787 : loss : 0.056751, loss_ce: 0.031174
[01:01:56.822] iteration 8788 : loss : 0.067258, loss_ce: 0.012987
[01:01:57.126] iteration 8789 : loss : 0.055278, loss_ce: 0.022185
[01:01:57.431] iteration 8790 : loss : 0.060915, loss_ce: 0.015220
[01:01:57.736] iteration 8791 : loss : 0.058254, loss_ce: 0.014958
[01:01:58.038] iteration 8792 : loss : 0.059328, loss_ce: 0.016177
[01:01:58.340] iteration 8793 : loss : 0.071005, loss_ce: 0.016426
[01:01:58.645] iteration 8794 : loss : 0.055724, loss_ce: 0.012951
[01:01:58.948] iteration 8795 : loss : 0.099562, loss_ce: 0.012296
[01:01:59.253] iteration 8796 : loss : 0.088862, loss_ce: 0.019954
[01:01:59.554] iteration 8797 : loss : 0.057609, loss_ce: 0.008814
[01:01:59.858] iteration 8798 : loss : 0.076221, loss_ce: 0.021814
[01:02:00.161] iteration 8799 : loss : 0.062299, loss_ce: 0.020759
[01:02:00.463] iteration 8800 : loss : 0.101940, loss_ce: 0.013730
[01:02:00.785] iteration 8801 : loss : 0.064159, loss_ce: 0.019030
[01:02:01.089] iteration 8802 : loss : 0.056458, loss_ce: 0.008673
[01:02:01.394] iteration 8803 : loss : 0.053544, loss_ce: 0.017838
[01:02:01.698] iteration 8804 : loss : 0.116357, loss_ce: 0.017820
[01:02:01.999] iteration 8805 : loss : 0.084185, loss_ce: 0.014402
[01:02:02.301] iteration 8806 : loss : 0.109781, loss_ce: 0.011550
[01:02:02.606] iteration 8807 : loss : 0.053669, loss_ce: 0.010762
[01:02:02.911] iteration 8808 : loss : 0.069479, loss_ce: 0.017566
[01:02:03.213] iteration 8809 : loss : 0.061418, loss_ce: 0.022658
[01:02:03.517] iteration 8810 : loss : 0.094059, loss_ce: 0.005461
[01:02:03.815] iteration 8811 : loss : 0.058510, loss_ce: 0.016271
[01:02:04.118] iteration 8812 : loss : 0.114076, loss_ce: 0.014546
[01:02:04.423] iteration 8813 : loss : 0.103808, loss_ce: 0.020066
[01:02:04.726] iteration 8814 : loss : 0.066884, loss_ce: 0.017833
[01:02:05.033] iteration 8815 : loss : 0.069597, loss_ce: 0.019963
[01:02:05.337] iteration 8816 : loss : 0.051320, loss_ce: 0.015053
[01:02:05.643] iteration 8817 : loss : 0.045628, loss_ce: 0.010980
[01:02:05.947] iteration 8818 : loss : 0.057520, loss_ce: 0.028013
[01:02:06.252] iteration 8819 : loss : 0.068353, loss_ce: 0.026242
[01:02:06.558] iteration 8820 : loss : 0.047166, loss_ce: 0.017841
[01:02:06.880] iteration 8821 : loss : 0.060767, loss_ce: 0.020377
[01:02:07.179] iteration 8822 : loss : 0.056253, loss_ce: 0.009689
[01:02:07.490] iteration 8823 : loss : 0.052139, loss_ce: 0.012437
[01:02:07.804] iteration 8824 : loss : 0.110304, loss_ce: 0.013997
[01:02:08.111] iteration 8825 : loss : 0.056990, loss_ce: 0.013557
[01:02:08.423] iteration 8826 : loss : 0.074448, loss_ce: 0.017773
[01:02:08.733] iteration 8827 : loss : 0.081337, loss_ce: 0.018629
[01:02:09.044] iteration 8828 : loss : 0.047533, loss_ce: 0.012150
[01:02:09.349] iteration 8829 : loss : 0.056684, loss_ce: 0.006818
[01:02:09.654] iteration 8830 : loss : 0.119678, loss_ce: 0.008777
[01:02:09.954] iteration 8831 : loss : 0.236365, loss_ce: 0.006286
[01:02:10.257] iteration 8832 : loss : 0.051025, loss_ce: 0.016531
[01:02:10.559] iteration 8833 : loss : 0.079299, loss_ce: 0.024262
[01:02:10.861] iteration 8834 : loss : 0.046644, loss_ce: 0.025144
[01:02:11.164] iteration 8835 : loss : 0.117204, loss_ce: 0.015516
[01:02:11.469] iteration 8836 : loss : 0.048416, loss_ce: 0.014685
[01:02:11.776] iteration 8837 : loss : 0.060015, loss_ce: 0.031562
[01:02:12.081] iteration 8838 : loss : 0.056465, loss_ce: 0.023878
[01:02:12.385] iteration 8839 : loss : 0.066000, loss_ce: 0.027691
[01:02:12.690] iteration 8840 : loss : 0.057054, loss_ce: 0.015351
[01:02:13.011] iteration 8841 : loss : 0.036690, loss_ce: 0.009671
[01:02:13.312] iteration 8842 : loss : 0.058787, loss_ce: 0.025290
[01:02:13.614] iteration 8843 : loss : 0.057749, loss_ce: 0.028164
[01:02:13.919] iteration 8844 : loss : 0.055159, loss_ce: 0.012343
[01:02:14.220] iteration 8845 : loss : 0.137806, loss_ce: 0.015957
[01:02:14.526] iteration 8846 : loss : 0.055985, loss_ce: 0.012256
[01:02:14.830] iteration 8847 : loss : 0.041614, loss_ce: 0.010015
[01:02:15.136] iteration 8848 : loss : 0.057947, loss_ce: 0.009044
[01:02:15.439] iteration 8849 : loss : 0.120675, loss_ce: 0.016308
[01:02:15.744] iteration 8850 : loss : 0.078107, loss_ce: 0.026324
[01:02:16.047] iteration 8851 : loss : 0.066175, loss_ce: 0.023628
[01:02:16.351] iteration 8852 : loss : 0.111049, loss_ce: 0.019624
[01:02:16.654] iteration 8853 : loss : 0.053524, loss_ce: 0.016286
[01:02:16.961] iteration 8854 : loss : 0.214152, loss_ce: 0.012585
[01:02:17.262] iteration 8855 : loss : 0.108200, loss_ce: 0.015817
[01:02:17.568] iteration 8856 : loss : 0.177489, loss_ce: 0.017485
[01:02:17.871] iteration 8857 : loss : 0.106008, loss_ce: 0.019993
[01:02:18.175] iteration 8858 : loss : 0.066354, loss_ce: 0.022963
[01:02:18.480] iteration 8859 : loss : 0.045995, loss_ce: 0.019787
[01:02:18.787] iteration 8860 : loss : 0.108535, loss_ce: 0.011456
[01:02:19.105] iteration 8861 : loss : 0.051065, loss_ce: 0.014979
[01:02:19.409] iteration 8862 : loss : 0.050899, loss_ce: 0.016625
[01:02:19.713] iteration 8863 : loss : 0.067997, loss_ce: 0.027490
[01:02:20.020] iteration 8864 : loss : 0.061026, loss_ce: 0.016483
[01:02:20.321] iteration 8865 : loss : 0.058642, loss_ce: 0.023308
[01:02:20.625] iteration 8866 : loss : 0.109868, loss_ce: 0.017654
[01:02:20.929] iteration 8867 : loss : 0.052239, loss_ce: 0.017054
[01:02:21.234] iteration 8868 : loss : 0.062279, loss_ce: 0.026125
[01:02:21.538] iteration 8869 : loss : 0.043725, loss_ce: 0.020498
[01:02:21.839] iteration 8870 : loss : 0.107737, loss_ce: 0.007901
[01:02:22.144] iteration 8871 : loss : 0.063243, loss_ce: 0.015050
[01:02:22.449] iteration 8872 : loss : 0.056148, loss_ce: 0.020625
[01:02:22.756] iteration 8873 : loss : 0.055895, loss_ce: 0.014017
[01:02:23.062] iteration 8874 : loss : 0.145054, loss_ce: 0.016512
[01:02:23.368] iteration 8875 : loss : 0.064832, loss_ce: 0.013391
[01:02:23.675] iteration 8876 : loss : 0.057406, loss_ce: 0.019473
[01:02:23.977] iteration 8877 : loss : 0.063984, loss_ce: 0.024045
[01:02:24.280] iteration 8878 : loss : 0.056076, loss_ce: 0.021650
[01:02:24.586] iteration 8879 : loss : 0.054837, loss_ce: 0.018813
[01:02:24.897] iteration 8880 : loss : 0.112061, loss_ce: 0.019994
[01:02:25.226] iteration 8881 : loss : 0.073769, loss_ce: 0.019236
[01:02:25.539] iteration 8882 : loss : 0.052756, loss_ce: 0.016517
[01:02:25.855] iteration 8883 : loss : 0.052204, loss_ce: 0.013638
[01:02:26.173] iteration 8884 : loss : 0.115148, loss_ce: 0.010157
[01:02:26.482] iteration 8885 : loss : 0.055769, loss_ce: 0.017174
[01:02:26.802] iteration 8886 : loss : 0.052978, loss_ce: 0.013009
[01:02:27.114] iteration 8887 : loss : 0.053610, loss_ce: 0.022090
[01:02:27.423] iteration 8888 : loss : 0.060967, loss_ce: 0.008387
[01:02:27.731] iteration 8889 : loss : 0.070959, loss_ce: 0.018218
[01:02:28.038] iteration 8890 : loss : 0.059751, loss_ce: 0.028260
[01:02:28.351] iteration 8891 : loss : 0.190515, loss_ce: 0.009481
[01:02:28.660] iteration 8892 : loss : 0.052905, loss_ce: 0.025567
[01:02:28.967] iteration 8893 : loss : 0.050347, loss_ce: 0.019971
[01:02:29.282] iteration 8894 : loss : 0.047973, loss_ce: 0.013807
[01:02:29.592] iteration 8895 : loss : 0.110781, loss_ce: 0.007857
[01:02:29.670] iteration 8896 : loss : 0.451793, loss_ce: 0.001234
[01:02:47.405] iteration 8897 : loss : 0.054458, loss_ce: 0.017717
[01:02:47.706] iteration 8898 : loss : 0.073887, loss_ce: 0.018925
[01:02:48.004] iteration 8899 : loss : 0.057325, loss_ce: 0.010559
[01:02:48.312] iteration 8900 : loss : 0.190030, loss_ce: 0.002883
[01:02:48.628] iteration 8901 : loss : 0.050854, loss_ce: 0.029121
[01:02:48.930] iteration 8902 : loss : 0.057354, loss_ce: 0.021560
[01:02:49.237] iteration 8903 : loss : 0.085978, loss_ce: 0.006524
[01:02:49.539] iteration 8904 : loss : 0.049634, loss_ce: 0.014669
[01:02:49.842] iteration 8905 : loss : 0.054857, loss_ce: 0.024017
[01:02:50.147] iteration 8906 : loss : 0.046013, loss_ce: 0.017304
[01:02:50.457] iteration 8907 : loss : 0.106978, loss_ce: 0.014130
[01:02:50.765] iteration 8908 : loss : 0.119022, loss_ce: 0.017411
[01:02:51.067] iteration 8909 : loss : 0.122794, loss_ce: 0.019411
[01:02:51.370] iteration 8910 : loss : 0.113063, loss_ce: 0.014828
[01:02:51.672] iteration 8911 : loss : 0.062885, loss_ce: 0.017744
[01:02:51.977] iteration 8912 : loss : 0.106347, loss_ce: 0.007374
[01:02:52.284] iteration 8913 : loss : 0.103449, loss_ce: 0.014138
[01:02:52.591] iteration 8914 : loss : 0.111390, loss_ce: 0.017967
[01:02:52.893] iteration 8915 : loss : 0.090562, loss_ce: 0.018775
[01:02:53.199] iteration 8916 : loss : 0.064011, loss_ce: 0.013799
[01:02:53.505] iteration 8917 : loss : 0.181158, loss_ce: 0.012033
[01:02:53.809] iteration 8918 : loss : 0.043921, loss_ce: 0.015741
[01:02:54.117] iteration 8919 : loss : 0.067528, loss_ce: 0.038614
[01:02:54.422] iteration 8920 : loss : 0.065321, loss_ce: 0.029004
[01:02:54.746] iteration 8921 : loss : 0.060580, loss_ce: 0.013954
[01:02:55.046] iteration 8922 : loss : 0.055649, loss_ce: 0.013999
[01:02:55.355] iteration 8923 : loss : 0.076750, loss_ce: 0.023833
[01:02:55.662] iteration 8924 : loss : 0.047782, loss_ce: 0.019860
[01:02:55.970] iteration 8925 : loss : 0.050696, loss_ce: 0.017906
[01:02:56.275] iteration 8926 : loss : 0.051395, loss_ce: 0.011817
[01:02:56.578] iteration 8927 : loss : 0.072519, loss_ce: 0.010433
[01:02:56.884] iteration 8928 : loss : 0.123079, loss_ce: 0.014035
[01:02:57.185] iteration 8929 : loss : 0.055238, loss_ce: 0.013661
[01:02:57.494] iteration 8930 : loss : 0.061424, loss_ce: 0.017230
[01:02:57.806] iteration 8931 : loss : 0.077934, loss_ce: 0.018060
[01:02:58.117] iteration 8932 : loss : 0.062165, loss_ce: 0.011413
[01:02:58.423] iteration 8933 : loss : 0.057933, loss_ce: 0.020866
[01:02:58.734] iteration 8934 : loss : 0.062771, loss_ce: 0.016532
[01:02:59.044] iteration 8935 : loss : 0.050596, loss_ce: 0.020974
[01:02:59.353] iteration 8936 : loss : 0.055751, loss_ce: 0.018457
[01:02:59.660] iteration 8937 : loss : 0.072490, loss_ce: 0.032215
[01:02:59.963] iteration 8938 : loss : 0.051750, loss_ce: 0.018305
[01:03:00.275] iteration 8939 : loss : 0.064531, loss_ce: 0.021495
[01:03:00.582] iteration 8940 : loss : 0.058385, loss_ce: 0.009111
[01:03:00.906] iteration 8941 : loss : 0.058870, loss_ce: 0.009291
[01:03:01.207] iteration 8942 : loss : 0.058682, loss_ce: 0.018903
[01:03:01.514] iteration 8943 : loss : 0.113282, loss_ce: 0.016487
[01:03:01.824] iteration 8944 : loss : 0.065789, loss_ce: 0.022034
[01:03:02.126] iteration 8945 : loss : 0.050866, loss_ce: 0.012692
[01:03:02.432] iteration 8946 : loss : 0.164334, loss_ce: 0.008460
[01:03:02.737] iteration 8947 : loss : 0.122369, loss_ce: 0.015370
[01:03:03.042] iteration 8948 : loss : 0.039820, loss_ce: 0.009445
[01:03:03.346] iteration 8949 : loss : 0.050670, loss_ce: 0.011288
[01:03:03.648] iteration 8950 : loss : 0.063374, loss_ce: 0.022462
[01:03:03.955] iteration 8951 : loss : 0.105743, loss_ce: 0.006459
[01:03:04.260] iteration 8952 : loss : 0.108497, loss_ce: 0.007900
[01:03:04.566] iteration 8953 : loss : 0.060890, loss_ce: 0.019038
[01:03:04.873] iteration 8954 : loss : 0.058593, loss_ce: 0.012187
[01:03:05.179] iteration 8955 : loss : 0.218325, loss_ce: 0.006307
[01:03:05.486] iteration 8956 : loss : 0.057347, loss_ce: 0.013040
[01:03:05.790] iteration 8957 : loss : 0.058361, loss_ce: 0.019381
[01:03:06.095] iteration 8958 : loss : 0.057128, loss_ce: 0.017294
[01:03:06.401] iteration 8959 : loss : 0.065920, loss_ce: 0.023363
[01:03:06.707] iteration 8960 : loss : 0.048927, loss_ce: 0.009567
[01:03:07.027] iteration 8961 : loss : 0.048008, loss_ce: 0.014475
[01:03:07.334] iteration 8962 : loss : 0.109751, loss_ce: 0.009049
[01:03:07.638] iteration 8963 : loss : 0.147892, loss_ce: 0.023740
[01:03:07.945] iteration 8964 : loss : 0.066007, loss_ce: 0.018929
[01:03:08.248] iteration 8965 : loss : 0.052843, loss_ce: 0.020582
[01:03:08.551] iteration 8966 : loss : 0.108199, loss_ce: 0.007759
[01:03:08.856] iteration 8967 : loss : 0.048191, loss_ce: 0.015138
[01:03:09.160] iteration 8968 : loss : 0.057515, loss_ce: 0.019374
[01:03:09.468] iteration 8969 : loss : 0.046516, loss_ce: 0.011820
[01:03:09.772] iteration 8970 : loss : 0.110746, loss_ce: 0.013447
[01:03:10.076] iteration 8971 : loss : 0.065027, loss_ce: 0.025103
[01:03:10.385] iteration 8972 : loss : 0.049665, loss_ce: 0.011650
[01:03:10.693] iteration 8973 : loss : 0.046794, loss_ce: 0.011995
[01:03:10.998] iteration 8974 : loss : 0.051926, loss_ce: 0.018448
[01:03:11.307] iteration 8975 : loss : 0.058519, loss_ce: 0.018994
[01:03:11.615] iteration 8976 : loss : 0.059595, loss_ce: 0.022120
[01:03:11.918] iteration 8977 : loss : 0.065257, loss_ce: 0.011000
[01:03:12.221] iteration 8978 : loss : 0.054084, loss_ce: 0.018504
[01:03:12.532] iteration 8979 : loss : 0.061566, loss_ce: 0.017289
[01:03:12.841] iteration 8980 : loss : 0.049598, loss_ce: 0.014121
[01:03:13.164] iteration 8981 : loss : 0.096905, loss_ce: 0.009997
[01:03:13.470] iteration 8982 : loss : 0.109968, loss_ce: 0.015686
[01:03:13.779] iteration 8983 : loss : 0.057470, loss_ce: 0.018349
[01:03:14.087] iteration 8984 : loss : 0.050932, loss_ce: 0.017543
[01:03:14.393] iteration 8985 : loss : 0.116604, loss_ce: 0.010276
[01:03:14.702] iteration 8986 : loss : 0.052595, loss_ce: 0.023721
[01:03:15.015] iteration 8987 : loss : 0.053624, loss_ce: 0.018027
[01:03:15.323] iteration 8988 : loss : 0.050972, loss_ce: 0.018568
[01:03:15.633] iteration 8989 : loss : 0.059770, loss_ce: 0.022364
[01:03:15.943] iteration 8990 : loss : 0.053512, loss_ce: 0.014059
[01:03:16.250] iteration 8991 : loss : 0.058032, loss_ce: 0.014397
[01:03:16.557] iteration 8992 : loss : 0.057269, loss_ce: 0.014444
[01:03:16.869] iteration 8993 : loss : 0.062898, loss_ce: 0.013953
[01:03:17.180] iteration 8994 : loss : 0.052663, loss_ce: 0.020959
[01:03:17.489] iteration 8995 : loss : 0.059092, loss_ce: 0.020673
[01:03:17.794] iteration 8996 : loss : 0.078487, loss_ce: 0.013193
[01:03:18.103] iteration 8997 : loss : 0.050404, loss_ce: 0.014953
[01:03:18.416] iteration 8998 : loss : 0.075181, loss_ce: 0.022838
[01:03:18.726] iteration 8999 : loss : 0.122052, loss_ce: 0.012665
[01:03:19.036] iteration 9000 : loss : 0.052055, loss_ce: 0.019213
[01:03:19.365] iteration 9001 : loss : 0.059512, loss_ce: 0.028076
[01:03:19.673] iteration 9002 : loss : 0.057641, loss_ce: 0.023544
[01:03:19.982] iteration 9003 : loss : 0.103474, loss_ce: 0.011676
[01:03:20.297] iteration 9004 : loss : 0.055696, loss_ce: 0.027531
[01:03:20.601] iteration 9005 : loss : 0.051657, loss_ce: 0.015546
[01:03:20.913] iteration 9006 : loss : 0.233028, loss_ce: 0.003092
[01:03:21.219] iteration 9007 : loss : 0.067224, loss_ce: 0.014830
[01:03:21.527] iteration 9008 : loss : 0.060352, loss_ce: 0.027685
[01:03:21.836] iteration 9009 : loss : 0.057072, loss_ce: 0.024516
[01:03:22.141] iteration 9010 : loss : 0.066416, loss_ce: 0.022370
[01:03:22.455] iteration 9011 : loss : 0.095854, loss_ce: 0.023484
[01:03:22.764] iteration 9012 : loss : 0.055469, loss_ce: 0.020666
[01:03:23.073] iteration 9013 : loss : 0.118640, loss_ce: 0.009149
[01:03:23.378] iteration 9014 : loss : 0.052972, loss_ce: 0.018454
[01:03:23.685] iteration 9015 : loss : 0.047474, loss_ce: 0.018109
[01:03:23.993] iteration 9016 : loss : 0.053420, loss_ce: 0.016361
[01:03:24.301] iteration 9017 : loss : 0.056840, loss_ce: 0.019643
[01:03:24.610] iteration 9018 : loss : 0.082587, loss_ce: 0.023887
[01:03:24.927] iteration 9019 : loss : 0.228754, loss_ce: 0.007538
[01:03:25.240] iteration 9020 : loss : 0.113335, loss_ce: 0.023385
[01:03:25.583] iteration 9021 : loss : 0.055494, loss_ce: 0.009409
[01:03:25.891] iteration 9022 : loss : 0.069846, loss_ce: 0.025548
[01:03:26.208] iteration 9023 : loss : 0.055232, loss_ce: 0.012249
[01:03:26.518] iteration 9024 : loss : 0.066870, loss_ce: 0.015121
[01:03:26.832] iteration 9025 : loss : 0.057008, loss_ce: 0.021363
[01:03:27.147] iteration 9026 : loss : 0.110668, loss_ce: 0.009434
[01:03:27.459] iteration 9027 : loss : 0.069121, loss_ce: 0.022341
[01:03:27.772] iteration 9028 : loss : 0.045820, loss_ce: 0.013231
[01:03:28.087] iteration 9029 : loss : 0.051119, loss_ce: 0.021432
[01:03:28.394] iteration 9030 : loss : 0.051108, loss_ce: 0.021867
[01:03:28.708] iteration 9031 : loss : 0.052832, loss_ce: 0.011839
[01:03:29.017] iteration 9032 : loss : 0.059529, loss_ce: 0.018785
[01:03:29.329] iteration 9033 : loss : 0.083155, loss_ce: 0.022627
[01:03:29.645] iteration 9034 : loss : 0.082987, loss_ce: 0.026646
[01:03:29.732] iteration 9035 : loss : 0.349113, loss_ce: 0.006219
[01:03:48.410] iteration 9036 : loss : 0.107935, loss_ce: 0.009574
[01:03:48.718] iteration 9037 : loss : 0.070195, loss_ce: 0.020919
[01:03:49.021] iteration 9038 : loss : 0.051406, loss_ce: 0.014614
[01:03:49.325] iteration 9039 : loss : 0.107768, loss_ce: 0.010203
[01:03:49.626] iteration 9040 : loss : 0.056550, loss_ce: 0.019477
[01:03:49.945] iteration 9041 : loss : 0.060221, loss_ce: 0.017042
[01:03:50.246] iteration 9042 : loss : 0.067169, loss_ce: 0.017325
[01:03:50.550] iteration 9043 : loss : 0.061226, loss_ce: 0.014190
[01:03:50.853] iteration 9044 : loss : 0.054536, loss_ce: 0.016182
[01:03:51.157] iteration 9045 : loss : 0.069188, loss_ce: 0.019980
[01:03:51.457] iteration 9046 : loss : 0.120876, loss_ce: 0.016614
[01:03:51.759] iteration 9047 : loss : 0.051210, loss_ce: 0.013551
[01:03:52.062] iteration 9048 : loss : 0.048445, loss_ce: 0.004738
[01:03:52.366] iteration 9049 : loss : 0.109485, loss_ce: 0.009472
[01:03:52.669] iteration 9050 : loss : 0.110658, loss_ce: 0.016656
[01:03:52.972] iteration 9051 : loss : 0.049104, loss_ce: 0.015719
[01:03:53.275] iteration 9052 : loss : 0.054439, loss_ce: 0.017058
[01:03:53.575] iteration 9053 : loss : 0.072609, loss_ce: 0.017093
[01:03:53.879] iteration 9054 : loss : 0.065730, loss_ce: 0.009615
[01:03:54.184] iteration 9055 : loss : 0.066222, loss_ce: 0.015710
[01:03:54.487] iteration 9056 : loss : 0.118590, loss_ce: 0.009746
[01:03:54.788] iteration 9057 : loss : 0.062630, loss_ce: 0.014967
[01:03:55.092] iteration 9058 : loss : 0.164687, loss_ce: 0.009705
[01:03:55.397] iteration 9059 : loss : 0.057280, loss_ce: 0.022252
[01:03:55.702] iteration 9060 : loss : 0.276120, loss_ce: 0.014636
[01:03:56.021] iteration 9061 : loss : 0.054951, loss_ce: 0.009335
[01:03:56.323] iteration 9062 : loss : 0.039914, loss_ce: 0.011494
[01:03:56.626] iteration 9063 : loss : 0.055121, loss_ce: 0.016372
[01:03:56.932] iteration 9064 : loss : 0.134747, loss_ce: 0.011845
[01:03:57.235] iteration 9065 : loss : 0.054933, loss_ce: 0.025313
[01:03:57.536] iteration 9066 : loss : 0.053674, loss_ce: 0.027445
[01:03:57.840] iteration 9067 : loss : 0.063953, loss_ce: 0.009915
[01:03:58.143] iteration 9068 : loss : 0.066355, loss_ce: 0.027028
[01:03:58.447] iteration 9069 : loss : 0.061356, loss_ce: 0.027671
[01:03:58.752] iteration 9070 : loss : 0.046752, loss_ce: 0.013319
[01:03:59.055] iteration 9071 : loss : 0.074927, loss_ce: 0.012763
[01:03:59.359] iteration 9072 : loss : 0.043485, loss_ce: 0.016450
[01:03:59.660] iteration 9073 : loss : 0.045556, loss_ce: 0.008805
[01:03:59.962] iteration 9074 : loss : 0.066696, loss_ce: 0.014025
[01:04:00.268] iteration 9075 : loss : 0.053859, loss_ce: 0.011577
[01:04:00.571] iteration 9076 : loss : 0.111223, loss_ce: 0.013124
[01:04:00.872] iteration 9077 : loss : 0.051853, loss_ce: 0.013255
[01:04:01.176] iteration 9078 : loss : 0.047206, loss_ce: 0.013887
[01:04:01.481] iteration 9079 : loss : 0.061370, loss_ce: 0.017994
[01:04:01.788] iteration 9080 : loss : 0.041729, loss_ce: 0.008676
[01:04:02.106] iteration 9081 : loss : 0.050921, loss_ce: 0.023162
[01:04:02.414] iteration 9082 : loss : 0.075069, loss_ce: 0.024625
[01:04:02.725] iteration 9083 : loss : 0.059739, loss_ce: 0.013310
[01:04:03.037] iteration 9084 : loss : 0.057944, loss_ce: 0.014986
[01:04:03.344] iteration 9085 : loss : 0.055955, loss_ce: 0.015257
[01:04:03.653] iteration 9086 : loss : 0.053421, loss_ce: 0.010543
[01:04:03.963] iteration 9087 : loss : 0.084962, loss_ce: 0.014774
[01:04:04.270] iteration 9088 : loss : 0.112882, loss_ce: 0.018621
[01:04:04.570] iteration 9089 : loss : 0.064214, loss_ce: 0.016120
[01:04:04.872] iteration 9090 : loss : 0.049621, loss_ce: 0.012603
[01:04:05.178] iteration 9091 : loss : 0.058365, loss_ce: 0.014183
[01:04:05.480] iteration 9092 : loss : 0.069840, loss_ce: 0.018262
[01:04:05.783] iteration 9093 : loss : 0.060773, loss_ce: 0.017095
[01:04:06.086] iteration 9094 : loss : 0.103757, loss_ce: 0.010994
[01:04:06.391] iteration 9095 : loss : 0.060197, loss_ce: 0.023556
[01:04:06.696] iteration 9096 : loss : 0.050885, loss_ce: 0.011893
[01:04:06.998] iteration 9097 : loss : 0.051821, loss_ce: 0.017924
[01:04:07.306] iteration 9098 : loss : 0.048049, loss_ce: 0.011710
[01:04:07.610] iteration 9099 : loss : 0.108336, loss_ce: 0.017478
[01:04:07.915] iteration 9100 : loss : 0.062201, loss_ce: 0.021986
[01:04:08.234] iteration 9101 : loss : 0.058115, loss_ce: 0.007683
[01:04:08.535] iteration 9102 : loss : 0.052352, loss_ce: 0.013966
[01:04:08.839] iteration 9103 : loss : 0.114257, loss_ce: 0.016097
[01:04:09.141] iteration 9104 : loss : 0.054918, loss_ce: 0.012772
[01:04:09.442] iteration 9105 : loss : 0.109030, loss_ce: 0.013725
[01:04:09.746] iteration 9106 : loss : 0.055857, loss_ce: 0.009629
[01:04:10.049] iteration 9107 : loss : 0.045208, loss_ce: 0.013768
[01:04:10.350] iteration 9108 : loss : 0.059279, loss_ce: 0.027274
[01:04:10.654] iteration 9109 : loss : 0.059008, loss_ce: 0.016745
[01:04:10.959] iteration 9110 : loss : 0.048575, loss_ce: 0.013590
[01:04:11.261] iteration 9111 : loss : 0.070351, loss_ce: 0.021523
[01:04:11.562] iteration 9112 : loss : 0.052419, loss_ce: 0.022205
[01:04:11.865] iteration 9113 : loss : 0.055527, loss_ce: 0.020514
[01:04:12.166] iteration 9114 : loss : 0.064897, loss_ce: 0.025305
[01:04:12.470] iteration 9115 : loss : 0.057069, loss_ce: 0.016335
[01:04:12.773] iteration 9116 : loss : 0.055120, loss_ce: 0.023248
[01:04:13.076] iteration 9117 : loss : 0.049841, loss_ce: 0.020105
[01:04:13.378] iteration 9118 : loss : 0.057684, loss_ce: 0.021439
[01:04:13.682] iteration 9119 : loss : 0.047115, loss_ce: 0.015845
[01:04:13.987] iteration 9120 : loss : 0.063685, loss_ce: 0.029690
[01:04:14.307] iteration 9121 : loss : 0.105938, loss_ce: 0.014431
[01:04:14.611] iteration 9122 : loss : 0.049503, loss_ce: 0.018504
[01:04:14.914] iteration 9123 : loss : 0.061734, loss_ce: 0.013701
[01:04:15.219] iteration 9124 : loss : 0.079544, loss_ce: 0.025626
[01:04:15.525] iteration 9125 : loss : 0.104876, loss_ce: 0.014766
[01:04:15.827] iteration 9126 : loss : 0.055899, loss_ce: 0.018504
[01:04:16.131] iteration 9127 : loss : 0.056945, loss_ce: 0.025746
[01:04:16.437] iteration 9128 : loss : 0.046460, loss_ce: 0.014614
[01:04:16.741] iteration 9129 : loss : 0.043454, loss_ce: 0.011721
[01:04:17.041] iteration 9130 : loss : 0.071868, loss_ce: 0.018035
[01:04:17.348] iteration 9131 : loss : 0.057714, loss_ce: 0.010810
[01:04:17.654] iteration 9132 : loss : 0.057583, loss_ce: 0.019028
[01:04:17.963] iteration 9133 : loss : 0.048264, loss_ce: 0.012420
[01:04:18.267] iteration 9134 : loss : 0.064162, loss_ce: 0.019519
[01:04:18.573] iteration 9135 : loss : 0.128155, loss_ce: 0.007190
[01:04:18.882] iteration 9136 : loss : 0.055726, loss_ce: 0.007646
[01:04:19.189] iteration 9137 : loss : 0.063628, loss_ce: 0.015188
[01:04:19.494] iteration 9138 : loss : 0.066461, loss_ce: 0.017012
[01:04:19.805] iteration 9139 : loss : 0.057916, loss_ce: 0.018615
[01:04:20.113] iteration 9140 : loss : 0.046892, loss_ce: 0.017410
[01:04:20.437] iteration 9141 : loss : 0.189099, loss_ce: 0.007421
[01:04:20.743] iteration 9142 : loss : 0.053628, loss_ce: 0.013907
[01:04:21.054] iteration 9143 : loss : 0.166395, loss_ce: 0.005040
[01:04:21.359] iteration 9144 : loss : 0.046274, loss_ce: 0.014723
[01:04:21.669] iteration 9145 : loss : 0.114062, loss_ce: 0.021639
[01:04:21.976] iteration 9146 : loss : 0.054270, loss_ce: 0.015220
[01:04:22.285] iteration 9147 : loss : 0.049412, loss_ce: 0.013247
[01:04:22.590] iteration 9148 : loss : 0.065135, loss_ce: 0.013902
[01:04:22.900] iteration 9149 : loss : 0.057395, loss_ce: 0.017956
[01:04:23.206] iteration 9150 : loss : 0.066489, loss_ce: 0.023279
[01:04:23.517] iteration 9151 : loss : 0.068864, loss_ce: 0.025285
[01:04:23.824] iteration 9152 : loss : 0.043664, loss_ce: 0.012247
[01:04:24.133] iteration 9153 : loss : 0.063969, loss_ce: 0.012107
[01:04:24.442] iteration 9154 : loss : 0.055239, loss_ce: 0.019265
[01:04:24.751] iteration 9155 : loss : 0.069092, loss_ce: 0.025407
[01:04:25.066] iteration 9156 : loss : 0.052187, loss_ce: 0.017905
[01:04:25.376] iteration 9157 : loss : 0.071008, loss_ce: 0.024790
[01:04:25.688] iteration 9158 : loss : 0.053862, loss_ce: 0.023646
[01:04:26.002] iteration 9159 : loss : 0.058472, loss_ce: 0.015474
[01:04:26.319] iteration 9160 : loss : 0.135796, loss_ce: 0.010121
[01:04:26.642] iteration 9161 : loss : 0.046014, loss_ce: 0.013445
[01:04:26.949] iteration 9162 : loss : 0.064588, loss_ce: 0.008544
[01:04:27.262] iteration 9163 : loss : 0.074153, loss_ce: 0.020868
[01:04:27.577] iteration 9164 : loss : 0.103985, loss_ce: 0.026238
[01:04:27.893] iteration 9165 : loss : 0.050226, loss_ce: 0.014129
[01:04:28.202] iteration 9166 : loss : 0.109788, loss_ce: 0.019059
[01:04:28.513] iteration 9167 : loss : 0.179355, loss_ce: 0.007899
[01:04:28.826] iteration 9168 : loss : 0.103520, loss_ce: 0.011654
[01:04:29.137] iteration 9169 : loss : 0.068472, loss_ce: 0.029543
[01:04:29.448] iteration 9170 : loss : 0.113599, loss_ce: 0.025132
[01:04:29.758] iteration 9171 : loss : 0.051307, loss_ce: 0.011262
[01:04:30.067] iteration 9172 : loss : 0.072579, loss_ce: 0.019266
[01:04:30.380] iteration 9173 : loss : 0.066508, loss_ce: 0.019801
[01:04:30.465] iteration 9174 : loss : 0.088279, loss_ce: 0.037550
[01:04:48.545] iteration 9175 : loss : 0.050357, loss_ce: 0.015732
[01:04:48.844] iteration 9176 : loss : 0.062150, loss_ce: 0.018278
[01:04:49.150] iteration 9177 : loss : 0.061062, loss_ce: 0.020439
[01:04:49.451] iteration 9178 : loss : 0.111870, loss_ce: 0.013091
[01:04:49.753] iteration 9179 : loss : 0.058680, loss_ce: 0.025238
[01:04:50.057] iteration 9180 : loss : 0.172808, loss_ce: 0.004855
[01:04:50.371] iteration 9181 : loss : 0.044893, loss_ce: 0.017858
[01:04:50.675] iteration 9182 : loss : 0.048041, loss_ce: 0.014500
[01:04:50.979] iteration 9183 : loss : 0.079408, loss_ce: 0.013430
[01:04:51.285] iteration 9184 : loss : 0.047357, loss_ce: 0.012261
[01:04:51.587] iteration 9185 : loss : 0.062650, loss_ce: 0.008378
[01:04:51.892] iteration 9186 : loss : 0.106335, loss_ce: 0.004541
[01:04:52.199] iteration 9187 : loss : 0.111462, loss_ce: 0.011392
[01:04:52.511] iteration 9188 : loss : 0.059627, loss_ce: 0.021869
[01:04:52.821] iteration 9189 : loss : 0.108657, loss_ce: 0.014263
[01:04:53.135] iteration 9190 : loss : 0.056199, loss_ce: 0.021494
[01:04:53.444] iteration 9191 : loss : 0.068659, loss_ce: 0.019748
[01:04:53.757] iteration 9192 : loss : 0.063811, loss_ce: 0.035778
[01:04:54.069] iteration 9193 : loss : 0.053256, loss_ce: 0.015407
[01:04:54.376] iteration 9194 : loss : 0.057533, loss_ce: 0.014506
[01:04:54.680] iteration 9195 : loss : 0.057104, loss_ce: 0.019506
[01:04:54.985] iteration 9196 : loss : 0.048418, loss_ce: 0.016931
[01:04:55.290] iteration 9197 : loss : 0.060950, loss_ce: 0.028085
[01:04:55.597] iteration 9198 : loss : 0.063230, loss_ce: 0.018879
[01:04:55.904] iteration 9199 : loss : 0.052955, loss_ce: 0.016422
[01:04:56.211] iteration 9200 : loss : 0.063116, loss_ce: 0.009594
[01:04:56.531] iteration 9201 : loss : 0.057947, loss_ce: 0.018954
[01:04:56.834] iteration 9202 : loss : 0.073404, loss_ce: 0.014656
[01:04:57.139] iteration 9203 : loss : 0.056894, loss_ce: 0.018511
[01:04:57.448] iteration 9204 : loss : 0.059400, loss_ce: 0.012720
[01:04:57.752] iteration 9205 : loss : 0.058709, loss_ce: 0.025900
[01:04:58.061] iteration 9206 : loss : 0.052146, loss_ce: 0.011624
[01:04:58.371] iteration 9207 : loss : 0.172581, loss_ce: 0.003410
[01:04:58.676] iteration 9208 : loss : 0.056412, loss_ce: 0.019567
[01:04:58.982] iteration 9209 : loss : 0.053866, loss_ce: 0.024755
[01:04:59.294] iteration 9210 : loss : 0.059271, loss_ce: 0.013540
[01:04:59.598] iteration 9211 : loss : 0.115904, loss_ce: 0.011525
[01:04:59.901] iteration 9212 : loss : 0.057328, loss_ce: 0.011868
[01:05:00.208] iteration 9213 : loss : 0.075082, loss_ce: 0.018004
[01:05:00.514] iteration 9214 : loss : 0.112205, loss_ce: 0.013461
[01:05:00.825] iteration 9215 : loss : 0.059116, loss_ce: 0.023351
[01:05:01.130] iteration 9216 : loss : 0.044568, loss_ce: 0.015697
[01:05:01.436] iteration 9217 : loss : 0.086955, loss_ce: 0.016834
[01:05:01.738] iteration 9218 : loss : 0.056392, loss_ce: 0.024138
[01:05:02.045] iteration 9219 : loss : 0.048859, loss_ce: 0.024800
[01:05:02.349] iteration 9220 : loss : 0.042504, loss_ce: 0.012828
[01:05:02.666] iteration 9221 : loss : 0.080338, loss_ce: 0.010895
[01:05:02.970] iteration 9222 : loss : 0.043750, loss_ce: 0.018886
[01:05:03.276] iteration 9223 : loss : 0.064706, loss_ce: 0.012607
[01:05:03.584] iteration 9224 : loss : 0.093899, loss_ce: 0.011487
[01:05:03.888] iteration 9225 : loss : 0.057456, loss_ce: 0.023807
[01:05:04.196] iteration 9226 : loss : 0.070057, loss_ce: 0.012199
[01:05:04.504] iteration 9227 : loss : 0.039335, loss_ce: 0.016881
[01:05:04.815] iteration 9228 : loss : 0.054831, loss_ce: 0.016837
[01:05:05.121] iteration 9229 : loss : 0.111682, loss_ce: 0.014051
[01:05:05.425] iteration 9230 : loss : 0.067237, loss_ce: 0.026434
[01:05:05.732] iteration 9231 : loss : 0.056611, loss_ce: 0.018624
[01:05:06.041] iteration 9232 : loss : 0.058248, loss_ce: 0.018844
[01:05:06.350] iteration 9233 : loss : 0.115900, loss_ce: 0.006641
[01:05:06.659] iteration 9234 : loss : 0.159141, loss_ce: 0.010995
[01:05:06.964] iteration 9235 : loss : 0.047533, loss_ce: 0.019818
[01:05:07.272] iteration 9236 : loss : 0.044871, loss_ce: 0.011032
[01:05:07.588] iteration 9237 : loss : 0.054787, loss_ce: 0.021175
[01:05:07.899] iteration 9238 : loss : 0.048159, loss_ce: 0.015645
[01:05:08.216] iteration 9239 : loss : 0.106562, loss_ce: 0.012222
[01:05:08.532] iteration 9240 : loss : 0.065352, loss_ce: 0.010231
[01:05:08.861] iteration 9241 : loss : 0.064995, loss_ce: 0.021531
[01:05:09.170] iteration 9242 : loss : 0.228869, loss_ce: 0.005091
[01:05:09.474] iteration 9243 : loss : 0.105688, loss_ce: 0.009733
[01:05:09.781] iteration 9244 : loss : 0.066566, loss_ce: 0.009156
[01:05:10.082] iteration 9245 : loss : 0.058691, loss_ce: 0.023753
[01:05:10.385] iteration 9246 : loss : 0.043308, loss_ce: 0.012899
[01:05:10.696] iteration 9247 : loss : 0.055385, loss_ce: 0.013543
[01:05:11.001] iteration 9248 : loss : 0.048645, loss_ce: 0.016170
[01:05:11.305] iteration 9249 : loss : 0.064242, loss_ce: 0.018169
[01:05:11.610] iteration 9250 : loss : 0.053630, loss_ce: 0.016669
[01:05:11.923] iteration 9251 : loss : 0.061865, loss_ce: 0.026474
[01:05:12.231] iteration 9252 : loss : 0.063647, loss_ce: 0.014889
[01:05:12.538] iteration 9253 : loss : 0.060072, loss_ce: 0.011072
[01:05:12.846] iteration 9254 : loss : 0.055859, loss_ce: 0.017140
[01:05:13.151] iteration 9255 : loss : 0.061906, loss_ce: 0.016785
[01:05:13.463] iteration 9256 : loss : 0.056065, loss_ce: 0.018548
[01:05:13.769] iteration 9257 : loss : 0.068641, loss_ce: 0.022820
[01:05:14.078] iteration 9258 : loss : 0.048242, loss_ce: 0.024276
[01:05:14.385] iteration 9259 : loss : 0.057568, loss_ce: 0.022346
[01:05:14.695] iteration 9260 : loss : 0.063410, loss_ce: 0.019759
[01:05:15.016] iteration 9261 : loss : 0.047406, loss_ce: 0.010269
[01:05:15.321] iteration 9262 : loss : 0.047215, loss_ce: 0.010671
[01:05:15.625] iteration 9263 : loss : 0.058334, loss_ce: 0.026354
[01:05:15.932] iteration 9264 : loss : 0.065919, loss_ce: 0.018310
[01:05:16.237] iteration 9265 : loss : 0.058439, loss_ce: 0.022232
[01:05:16.543] iteration 9266 : loss : 0.050394, loss_ce: 0.022008
[01:05:16.849] iteration 9267 : loss : 0.067813, loss_ce: 0.020426
[01:05:17.157] iteration 9268 : loss : 0.061855, loss_ce: 0.020743
[01:05:17.462] iteration 9269 : loss : 0.049970, loss_ce: 0.014038
[01:05:17.767] iteration 9270 : loss : 0.054157, loss_ce: 0.016039
[01:05:18.073] iteration 9271 : loss : 0.109200, loss_ce: 0.009410
[01:05:18.381] iteration 9272 : loss : 0.174402, loss_ce: 0.012441
[01:05:18.688] iteration 9273 : loss : 0.108355, loss_ce: 0.016910
[01:05:18.993] iteration 9274 : loss : 0.051761, loss_ce: 0.020064
[01:05:19.301] iteration 9275 : loss : 0.058134, loss_ce: 0.017245
[01:05:19.607] iteration 9276 : loss : 0.057961, loss_ce: 0.016153
[01:05:19.911] iteration 9277 : loss : 0.054506, loss_ce: 0.022383
[01:05:20.218] iteration 9278 : loss : 0.056376, loss_ce: 0.017969
[01:05:20.523] iteration 9279 : loss : 0.133387, loss_ce: 0.011898
[01:05:20.829] iteration 9280 : loss : 0.113779, loss_ce: 0.012052
[01:05:21.147] iteration 9281 : loss : 0.053512, loss_ce: 0.017252
[01:05:21.455] iteration 9282 : loss : 0.107994, loss_ce: 0.007871
[01:05:21.759] iteration 9283 : loss : 0.066660, loss_ce: 0.021677
[01:05:22.063] iteration 9284 : loss : 0.046154, loss_ce: 0.012548
[01:05:22.374] iteration 9285 : loss : 0.111043, loss_ce: 0.011867
[01:05:22.685] iteration 9286 : loss : 0.047323, loss_ce: 0.009935
[01:05:22.998] iteration 9287 : loss : 0.053173, loss_ce: 0.020015
[01:05:23.306] iteration 9288 : loss : 0.058819, loss_ce: 0.017190
[01:05:23.617] iteration 9289 : loss : 0.041718, loss_ce: 0.007562
[01:05:23.930] iteration 9290 : loss : 0.053152, loss_ce: 0.014072
[01:05:24.241] iteration 9291 : loss : 0.057739, loss_ce: 0.015712
[01:05:24.546] iteration 9292 : loss : 0.052007, loss_ce: 0.015273
[01:05:24.851] iteration 9293 : loss : 0.045933, loss_ce: 0.018371
[01:05:25.156] iteration 9294 : loss : 0.067187, loss_ce: 0.012532
[01:05:25.457] iteration 9295 : loss : 0.069989, loss_ce: 0.026334
[01:05:25.764] iteration 9296 : loss : 0.088100, loss_ce: 0.017798
[01:05:26.074] iteration 9297 : loss : 0.061347, loss_ce: 0.021712
[01:05:26.382] iteration 9298 : loss : 0.110267, loss_ce: 0.014171
[01:05:26.694] iteration 9299 : loss : 0.131953, loss_ce: 0.021697
[01:05:26.999] iteration 9300 : loss : 0.045298, loss_ce: 0.016073
[01:05:27.329] iteration 9301 : loss : 0.060648, loss_ce: 0.022872
[01:05:27.639] iteration 9302 : loss : 0.050850, loss_ce: 0.015830
[01:05:27.950] iteration 9303 : loss : 0.121991, loss_ce: 0.007478
[01:05:28.255] iteration 9304 : loss : 0.103824, loss_ce: 0.013149
[01:05:28.568] iteration 9305 : loss : 0.059543, loss_ce: 0.024972
[01:05:28.877] iteration 9306 : loss : 0.109119, loss_ce: 0.015917
[01:05:29.184] iteration 9307 : loss : 0.064485, loss_ce: 0.020520
[01:05:29.498] iteration 9308 : loss : 0.069013, loss_ce: 0.008256
[01:05:29.804] iteration 9309 : loss : 0.049719, loss_ce: 0.019099
[01:05:30.111] iteration 9310 : loss : 0.063056, loss_ce: 0.015855
[01:05:30.421] iteration 9311 : loss : 0.117684, loss_ce: 0.007405
[01:05:30.730] iteration 9312 : loss : 0.092994, loss_ce: 0.011239
[01:05:30.817] iteration 9313 : loss : 0.248771, loss_ce: 0.048495
[01:05:50.099] iteration 9314 : loss : 0.062840, loss_ce: 0.018960
[01:05:50.405] iteration 9315 : loss : 0.053132, loss_ce: 0.016544
[01:05:50.708] iteration 9316 : loss : 0.064944, loss_ce: 0.027803
[01:05:51.014] iteration 9317 : loss : 0.057397, loss_ce: 0.021720
[01:05:51.320] iteration 9318 : loss : 0.056990, loss_ce: 0.018252
[01:05:51.629] iteration 9319 : loss : 0.209667, loss_ce: 0.017987
[01:05:51.937] iteration 9320 : loss : 0.117327, loss_ce: 0.006120
[01:05:52.258] iteration 9321 : loss : 0.114619, loss_ce: 0.010605
[01:05:52.566] iteration 9322 : loss : 0.052829, loss_ce: 0.015471
[01:05:52.876] iteration 9323 : loss : 0.059976, loss_ce: 0.018956
[01:05:53.185] iteration 9324 : loss : 0.059759, loss_ce: 0.018452
[01:05:53.490] iteration 9325 : loss : 0.058397, loss_ce: 0.015721
[01:05:53.797] iteration 9326 : loss : 0.055866, loss_ce: 0.019437
[01:05:54.101] iteration 9327 : loss : 0.100412, loss_ce: 0.017822
[01:05:54.413] iteration 9328 : loss : 0.072138, loss_ce: 0.016885
[01:05:54.718] iteration 9329 : loss : 0.053805, loss_ce: 0.012539
[01:05:55.022] iteration 9330 : loss : 0.060107, loss_ce: 0.021676
[01:05:55.330] iteration 9331 : loss : 0.054414, loss_ce: 0.011429
[01:05:55.639] iteration 9332 : loss : 0.062270, loss_ce: 0.021399
[01:05:55.943] iteration 9333 : loss : 0.182080, loss_ce: 0.005714
[01:05:56.257] iteration 9334 : loss : 0.058051, loss_ce: 0.017349
[01:05:56.562] iteration 9335 : loss : 0.100920, loss_ce: 0.011570
[01:05:56.872] iteration 9336 : loss : 0.054951, loss_ce: 0.012056
[01:05:57.180] iteration 9337 : loss : 0.049173, loss_ce: 0.011251
[01:05:57.495] iteration 9338 : loss : 0.156898, loss_ce: 0.007013
[01:05:57.804] iteration 9339 : loss : 0.053162, loss_ce: 0.021216
[01:05:58.112] iteration 9340 : loss : 0.050333, loss_ce: 0.017710
[01:05:58.433] iteration 9341 : loss : 0.109162, loss_ce: 0.022287
[01:05:58.741] iteration 9342 : loss : 0.050786, loss_ce: 0.023142
[01:05:59.049] iteration 9343 : loss : 0.066275, loss_ce: 0.018181
[01:05:59.356] iteration 9344 : loss : 0.074129, loss_ce: 0.020388
[01:05:59.659] iteration 9345 : loss : 0.057371, loss_ce: 0.013763
[01:05:59.965] iteration 9346 : loss : 0.058158, loss_ce: 0.018847
[01:06:00.268] iteration 9347 : loss : 0.050776, loss_ce: 0.012893
[01:06:00.574] iteration 9348 : loss : 0.051792, loss_ce: 0.019365
[01:06:00.877] iteration 9349 : loss : 0.042672, loss_ce: 0.012711
[01:06:01.181] iteration 9350 : loss : 0.054056, loss_ce: 0.010595
[01:06:01.482] iteration 9351 : loss : 0.055783, loss_ce: 0.022238
[01:06:01.784] iteration 9352 : loss : 0.067519, loss_ce: 0.016009
[01:06:02.088] iteration 9353 : loss : 0.106032, loss_ce: 0.014640
[01:06:02.388] iteration 9354 : loss : 0.170477, loss_ce: 0.015992
[01:06:02.689] iteration 9355 : loss : 0.100014, loss_ce: 0.009370
[01:06:02.993] iteration 9356 : loss : 0.057692, loss_ce: 0.019925
[01:06:03.295] iteration 9357 : loss : 0.067027, loss_ce: 0.023633
[01:06:03.598] iteration 9358 : loss : 0.054083, loss_ce: 0.019974
[01:06:03.901] iteration 9359 : loss : 0.052023, loss_ce: 0.018538
[01:06:04.206] iteration 9360 : loss : 0.062735, loss_ce: 0.013802
[01:06:04.531] iteration 9361 : loss : 0.046117, loss_ce: 0.014154
[01:06:04.834] iteration 9362 : loss : 0.123372, loss_ce: 0.007732
[01:06:05.137] iteration 9363 : loss : 0.066828, loss_ce: 0.015935
[01:06:05.442] iteration 9364 : loss : 0.079312, loss_ce: 0.038532
[01:06:05.746] iteration 9365 : loss : 0.060151, loss_ce: 0.020807
[01:06:06.047] iteration 9366 : loss : 0.050477, loss_ce: 0.018669
[01:06:06.349] iteration 9367 : loss : 0.040784, loss_ce: 0.010086
[01:06:06.653] iteration 9368 : loss : 0.051462, loss_ce: 0.023996
[01:06:06.956] iteration 9369 : loss : 0.047513, loss_ce: 0.017791
[01:06:07.260] iteration 9370 : loss : 0.047021, loss_ce: 0.017354
[01:06:07.561] iteration 9371 : loss : 0.048267, loss_ce: 0.013295
[01:06:07.864] iteration 9372 : loss : 0.061174, loss_ce: 0.008532
[01:06:08.168] iteration 9373 : loss : 0.057735, loss_ce: 0.019631
[01:06:08.471] iteration 9374 : loss : 0.046110, loss_ce: 0.014131
[01:06:08.774] iteration 9375 : loss : 0.040497, loss_ce: 0.013198
[01:06:09.080] iteration 9376 : loss : 0.065343, loss_ce: 0.018432
[01:06:09.382] iteration 9377 : loss : 0.050584, loss_ce: 0.019005
[01:06:09.686] iteration 9378 : loss : 0.060477, loss_ce: 0.014018
[01:06:09.988] iteration 9379 : loss : 0.049994, loss_ce: 0.022985
[01:06:10.294] iteration 9380 : loss : 0.066033, loss_ce: 0.014032
[01:06:10.615] iteration 9381 : loss : 0.112182, loss_ce: 0.009880
[01:06:10.920] iteration 9382 : loss : 0.115512, loss_ce: 0.012505
[01:06:11.222] iteration 9383 : loss : 0.055913, loss_ce: 0.015161
[01:06:11.524] iteration 9384 : loss : 0.056771, loss_ce: 0.017537
[01:06:11.834] iteration 9385 : loss : 0.038113, loss_ce: 0.014712
[01:06:12.136] iteration 9386 : loss : 0.058766, loss_ce: 0.022171
[01:06:12.444] iteration 9387 : loss : 0.049456, loss_ce: 0.021745
[01:06:12.755] iteration 9388 : loss : 0.044444, loss_ce: 0.015249
[01:06:13.066] iteration 9389 : loss : 0.069720, loss_ce: 0.019387
[01:06:13.373] iteration 9390 : loss : 0.048487, loss_ce: 0.015914
[01:06:13.684] iteration 9391 : loss : 0.133810, loss_ce: 0.014647
[01:06:13.998] iteration 9392 : loss : 0.047271, loss_ce: 0.010389
[01:06:14.306] iteration 9393 : loss : 0.048473, loss_ce: 0.015535
[01:06:14.607] iteration 9394 : loss : 0.051339, loss_ce: 0.013111
[01:06:14.913] iteration 9395 : loss : 0.059412, loss_ce: 0.012989
[01:06:15.216] iteration 9396 : loss : 0.061383, loss_ce: 0.023266
[01:06:15.525] iteration 9397 : loss : 0.168252, loss_ce: 0.016341
[01:06:15.826] iteration 9398 : loss : 0.057742, loss_ce: 0.016881
[01:06:16.129] iteration 9399 : loss : 0.115351, loss_ce: 0.011977
[01:06:16.433] iteration 9400 : loss : 0.078836, loss_ce: 0.014736
[01:06:16.752] iteration 9401 : loss : 0.049353, loss_ce: 0.013076
[01:06:17.055] iteration 9402 : loss : 0.058644, loss_ce: 0.019889
[01:06:17.359] iteration 9403 : loss : 0.041149, loss_ce: 0.011169
[01:06:17.660] iteration 9404 : loss : 0.110189, loss_ce: 0.005617
[01:06:17.964] iteration 9405 : loss : 0.039808, loss_ce: 0.010747
[01:06:18.268] iteration 9406 : loss : 0.114426, loss_ce: 0.011356
[01:06:18.568] iteration 9407 : loss : 0.120664, loss_ce: 0.022065
[01:06:18.872] iteration 9408 : loss : 0.122602, loss_ce: 0.014897
[01:06:19.177] iteration 9409 : loss : 0.065510, loss_ce: 0.027262
[01:06:19.478] iteration 9410 : loss : 0.047801, loss_ce: 0.015050
[01:06:19.782] iteration 9411 : loss : 0.070636, loss_ce: 0.022372
[01:06:20.084] iteration 9412 : loss : 0.057208, loss_ce: 0.026532
[01:06:20.387] iteration 9413 : loss : 0.059442, loss_ce: 0.012226
[01:06:20.690] iteration 9414 : loss : 0.045231, loss_ce: 0.011155
[01:06:20.994] iteration 9415 : loss : 0.118253, loss_ce: 0.015025
[01:06:21.299] iteration 9416 : loss : 0.123336, loss_ce: 0.023768
[01:06:21.601] iteration 9417 : loss : 0.066838, loss_ce: 0.026172
[01:06:21.904] iteration 9418 : loss : 0.117810, loss_ce: 0.011309
[01:06:22.209] iteration 9419 : loss : 0.061008, loss_ce: 0.015553
[01:06:22.512] iteration 9420 : loss : 0.129685, loss_ce: 0.010508
[01:06:22.826] iteration 9421 : loss : 0.107415, loss_ce: 0.011290
[01:06:23.131] iteration 9422 : loss : 0.055172, loss_ce: 0.019943
[01:06:23.437] iteration 9423 : loss : 0.062381, loss_ce: 0.019155
[01:06:23.742] iteration 9424 : loss : 0.046748, loss_ce: 0.011394
[01:06:24.050] iteration 9425 : loss : 0.051472, loss_ce: 0.014376
[01:06:24.352] iteration 9426 : loss : 0.058271, loss_ce: 0.017806
[01:06:24.656] iteration 9427 : loss : 0.110693, loss_ce: 0.019585
[01:06:24.960] iteration 9428 : loss : 0.101970, loss_ce: 0.011191
[01:06:25.265] iteration 9429 : loss : 0.052406, loss_ce: 0.014683
[01:06:25.570] iteration 9430 : loss : 0.075158, loss_ce: 0.014698
[01:06:25.874] iteration 9431 : loss : 0.046724, loss_ce: 0.016341
[01:06:26.177] iteration 9432 : loss : 0.063873, loss_ce: 0.023669
[01:06:26.485] iteration 9433 : loss : 0.051242, loss_ce: 0.012826
[01:06:26.789] iteration 9434 : loss : 0.045389, loss_ce: 0.012517
[01:06:27.094] iteration 9435 : loss : 0.065883, loss_ce: 0.019785
[01:06:27.405] iteration 9436 : loss : 0.049054, loss_ce: 0.016552
[01:06:27.720] iteration 9437 : loss : 0.073380, loss_ce: 0.014479
[01:06:28.036] iteration 9438 : loss : 0.043222, loss_ce: 0.013651
[01:06:28.352] iteration 9439 : loss : 0.054080, loss_ce: 0.019577
[01:06:28.667] iteration 9440 : loss : 0.079159, loss_ce: 0.018303
[01:06:28.995] iteration 9441 : loss : 0.076344, loss_ce: 0.022458
[01:06:29.307] iteration 9442 : loss : 0.069997, loss_ce: 0.020706
[01:06:29.626] iteration 9443 : loss : 0.051019, loss_ce: 0.011116
[01:06:29.930] iteration 9444 : loss : 0.067121, loss_ce: 0.017256
[01:06:30.240] iteration 9445 : loss : 0.048049, loss_ce: 0.018316
[01:06:30.547] iteration 9446 : loss : 0.049640, loss_ce: 0.009718
[01:06:30.852] iteration 9447 : loss : 0.049240, loss_ce: 0.019665
[01:06:31.156] iteration 9448 : loss : 0.112090, loss_ce: 0.016741
[01:06:31.464] iteration 9449 : loss : 0.056200, loss_ce: 0.015304
[01:06:31.773] iteration 9450 : loss : 0.057595, loss_ce: 0.021643
[01:06:32.077] iteration 9451 : loss : 0.060450, loss_ce: 0.022491
[01:06:32.161] iteration 9452 : loss : 0.210335, loss_ce: 0.023166
[01:06:50.186] iteration 9453 : loss : 0.041440, loss_ce: 0.014928
[01:06:50.494] iteration 9454 : loss : 0.055412, loss_ce: 0.024453
[01:06:50.798] iteration 9455 : loss : 0.041501, loss_ce: 0.008707
[01:06:51.106] iteration 9456 : loss : 0.063663, loss_ce: 0.009564
[01:06:51.413] iteration 9457 : loss : 0.070394, loss_ce: 0.015156
[01:06:51.720] iteration 9458 : loss : 0.064222, loss_ce: 0.019248
[01:06:52.030] iteration 9459 : loss : 0.055480, loss_ce: 0.017042
[01:06:52.336] iteration 9460 : loss : 0.054249, loss_ce: 0.031849
[01:06:52.656] iteration 9461 : loss : 0.058911, loss_ce: 0.013353
[01:06:52.965] iteration 9462 : loss : 0.109128, loss_ce: 0.011524
[01:06:53.275] iteration 9463 : loss : 0.040765, loss_ce: 0.013726
[01:06:53.583] iteration 9464 : loss : 0.056280, loss_ce: 0.026776
[01:06:53.891] iteration 9465 : loss : 0.043289, loss_ce: 0.011987
[01:06:54.203] iteration 9466 : loss : 0.046186, loss_ce: 0.014550
[01:06:54.506] iteration 9467 : loss : 0.165413, loss_ce: 0.010635
[01:06:54.810] iteration 9468 : loss : 0.049567, loss_ce: 0.006422
[01:06:55.120] iteration 9469 : loss : 0.072604, loss_ce: 0.018830
[01:06:55.426] iteration 9470 : loss : 0.056548, loss_ce: 0.013451
[01:06:55.735] iteration 9471 : loss : 0.068063, loss_ce: 0.012362
[01:06:56.047] iteration 9472 : loss : 0.053861, loss_ce: 0.018805
[01:06:56.362] iteration 9473 : loss : 0.187239, loss_ce: 0.007578
[01:06:56.666] iteration 9474 : loss : 0.169386, loss_ce: 0.019913
[01:06:56.974] iteration 9475 : loss : 0.155739, loss_ce: 0.012620
[01:06:57.280] iteration 9476 : loss : 0.136590, loss_ce: 0.011520
[01:06:57.587] iteration 9477 : loss : 0.063435, loss_ce: 0.023639
[01:06:57.896] iteration 9478 : loss : 0.043385, loss_ce: 0.015405
[01:06:58.205] iteration 9479 : loss : 0.104988, loss_ce: 0.009993
[01:06:58.516] iteration 9480 : loss : 0.060382, loss_ce: 0.017775
[01:06:58.844] iteration 9481 : loss : 0.109896, loss_ce: 0.021534
[01:06:59.151] iteration 9482 : loss : 0.060488, loss_ce: 0.016065
[01:06:59.467] iteration 9483 : loss : 0.050602, loss_ce: 0.015173
[01:06:59.777] iteration 9484 : loss : 0.052928, loss_ce: 0.014134
[01:07:00.084] iteration 9485 : loss : 0.063467, loss_ce: 0.014699
[01:07:00.399] iteration 9486 : loss : 0.106998, loss_ce: 0.013174
[01:07:00.713] iteration 9487 : loss : 0.103527, loss_ce: 0.010829
[01:07:01.023] iteration 9488 : loss : 0.082745, loss_ce: 0.025880
[01:07:01.330] iteration 9489 : loss : 0.105800, loss_ce: 0.023911
[01:07:01.640] iteration 9490 : loss : 0.057080, loss_ce: 0.012591
[01:07:01.947] iteration 9491 : loss : 0.101524, loss_ce: 0.007501
[01:07:02.260] iteration 9492 : loss : 0.052014, loss_ce: 0.012517
[01:07:02.567] iteration 9493 : loss : 0.101407, loss_ce: 0.008067
[01:07:02.873] iteration 9494 : loss : 0.054973, loss_ce: 0.023589
[01:07:03.187] iteration 9495 : loss : 0.055647, loss_ce: 0.015951
[01:07:03.498] iteration 9496 : loss : 0.063893, loss_ce: 0.019107
[01:07:03.810] iteration 9497 : loss : 0.043354, loss_ce: 0.020083
[01:07:04.120] iteration 9498 : loss : 0.123454, loss_ce: 0.023905
[01:07:04.425] iteration 9499 : loss : 0.066609, loss_ce: 0.025913
[01:07:04.735] iteration 9500 : loss : 0.051333, loss_ce: 0.016293
[01:07:05.056] iteration 9501 : loss : 0.053053, loss_ce: 0.010853
[01:07:05.362] iteration 9502 : loss : 0.047236, loss_ce: 0.007673
[01:07:05.663] iteration 9503 : loss : 0.048657, loss_ce: 0.014129
[01:07:05.968] iteration 9504 : loss : 0.112879, loss_ce: 0.007531
[01:07:06.274] iteration 9505 : loss : 0.056782, loss_ce: 0.017545
[01:07:06.576] iteration 9506 : loss : 0.061205, loss_ce: 0.010149
[01:07:06.884] iteration 9507 : loss : 0.168115, loss_ce: 0.011398
[01:07:07.189] iteration 9508 : loss : 0.053606, loss_ce: 0.012388
[01:07:07.497] iteration 9509 : loss : 0.050300, loss_ce: 0.015717
[01:07:07.800] iteration 9510 : loss : 0.071480, loss_ce: 0.023983
[01:07:08.107] iteration 9511 : loss : 0.068816, loss_ce: 0.015908
[01:07:08.414] iteration 9512 : loss : 0.056983, loss_ce: 0.008565
[01:07:08.722] iteration 9513 : loss : 0.117896, loss_ce: 0.009133
[01:07:09.025] iteration 9514 : loss : 0.051694, loss_ce: 0.023590
[01:07:09.332] iteration 9515 : loss : 0.051352, loss_ce: 0.017862
[01:07:09.635] iteration 9516 : loss : 0.120745, loss_ce: 0.015975
[01:07:09.941] iteration 9517 : loss : 0.059902, loss_ce: 0.013429
[01:07:10.250] iteration 9518 : loss : 0.068488, loss_ce: 0.018617
[01:07:10.555] iteration 9519 : loss : 0.111374, loss_ce: 0.005895
[01:07:10.861] iteration 9520 : loss : 0.065053, loss_ce: 0.023097
[01:07:11.184] iteration 9521 : loss : 0.062717, loss_ce: 0.020341
[01:07:11.487] iteration 9522 : loss : 0.049382, loss_ce: 0.021256
[01:07:11.790] iteration 9523 : loss : 0.122558, loss_ce: 0.020558
[01:07:12.098] iteration 9524 : loss : 0.050982, loss_ce: 0.015055
[01:07:12.407] iteration 9525 : loss : 0.081886, loss_ce: 0.017528
[01:07:12.712] iteration 9526 : loss : 0.051725, loss_ce: 0.015698
[01:07:13.017] iteration 9527 : loss : 0.061182, loss_ce: 0.012264
[01:07:13.321] iteration 9528 : loss : 0.059105, loss_ce: 0.020407
[01:07:13.632] iteration 9529 : loss : 0.056840, loss_ce: 0.024741
[01:07:13.937] iteration 9530 : loss : 0.062536, loss_ce: 0.023175
[01:07:14.240] iteration 9531 : loss : 0.111860, loss_ce: 0.022342
[01:07:14.548] iteration 9532 : loss : 0.057301, loss_ce: 0.013112
[01:07:14.853] iteration 9533 : loss : 0.111020, loss_ce: 0.013537
[01:07:15.158] iteration 9534 : loss : 0.061679, loss_ce: 0.022559
[01:07:15.459] iteration 9535 : loss : 0.057688, loss_ce: 0.018166
[01:07:15.761] iteration 9536 : loss : 0.110075, loss_ce: 0.003748
[01:07:16.067] iteration 9537 : loss : 0.045560, loss_ce: 0.014466
[01:07:16.373] iteration 9538 : loss : 0.055677, loss_ce: 0.016905
[01:07:16.676] iteration 9539 : loss : 0.048047, loss_ce: 0.020133
[01:07:16.985] iteration 9540 : loss : 0.047432, loss_ce: 0.024781
[01:07:17.317] iteration 9541 : loss : 0.174708, loss_ce: 0.011961
[01:07:17.625] iteration 9542 : loss : 0.123164, loss_ce: 0.009266
[01:07:17.938] iteration 9543 : loss : 0.125193, loss_ce: 0.026444
[01:07:18.248] iteration 9544 : loss : 0.113817, loss_ce: 0.027112
[01:07:18.557] iteration 9545 : loss : 0.061838, loss_ce: 0.012037
[01:07:18.864] iteration 9546 : loss : 0.054274, loss_ce: 0.019052
[01:07:19.175] iteration 9547 : loss : 0.058123, loss_ce: 0.018177
[01:07:19.475] iteration 9548 : loss : 0.056952, loss_ce: 0.013719
[01:07:19.781] iteration 9549 : loss : 0.059813, loss_ce: 0.020434
[01:07:20.091] iteration 9550 : loss : 0.085163, loss_ce: 0.013855
[01:07:20.393] iteration 9551 : loss : 0.165119, loss_ce: 0.009414
[01:07:20.701] iteration 9552 : loss : 0.049827, loss_ce: 0.009416
[01:07:21.003] iteration 9553 : loss : 0.059642, loss_ce: 0.012157
[01:07:21.311] iteration 9554 : loss : 0.117820, loss_ce: 0.013160
[01:07:21.614] iteration 9555 : loss : 0.051120, loss_ce: 0.012528
[01:07:21.920] iteration 9556 : loss : 0.065417, loss_ce: 0.022695
[01:07:22.226] iteration 9557 : loss : 0.110595, loss_ce: 0.017160
[01:07:22.529] iteration 9558 : loss : 0.051304, loss_ce: 0.013440
[01:07:22.833] iteration 9559 : loss : 0.055678, loss_ce: 0.023809
[01:07:23.144] iteration 9560 : loss : 0.063128, loss_ce: 0.016381
[01:07:23.461] iteration 9561 : loss : 0.044986, loss_ce: 0.016427
[01:07:23.765] iteration 9562 : loss : 0.059179, loss_ce: 0.022572
[01:07:24.072] iteration 9563 : loss : 0.058614, loss_ce: 0.016514
[01:07:24.376] iteration 9564 : loss : 0.066552, loss_ce: 0.024664
[01:07:24.681] iteration 9565 : loss : 0.109495, loss_ce: 0.010251
[01:07:24.985] iteration 9566 : loss : 0.059901, loss_ce: 0.013590
[01:07:25.288] iteration 9567 : loss : 0.080315, loss_ce: 0.016949
[01:07:25.592] iteration 9568 : loss : 0.111112, loss_ce: 0.016938
[01:07:25.895] iteration 9569 : loss : 0.052594, loss_ce: 0.012564
[01:07:26.198] iteration 9570 : loss : 0.056146, loss_ce: 0.025423
[01:07:26.504] iteration 9571 : loss : 0.058422, loss_ce: 0.015247
[01:07:26.810] iteration 9572 : loss : 0.120387, loss_ce: 0.018072
[01:07:27.110] iteration 9573 : loss : 0.057131, loss_ce: 0.020849
[01:07:27.413] iteration 9574 : loss : 0.059358, loss_ce: 0.017250
[01:07:27.719] iteration 9575 : loss : 0.067662, loss_ce: 0.014327
[01:07:28.029] iteration 9576 : loss : 0.059703, loss_ce: 0.027009
[01:07:28.336] iteration 9577 : loss : 0.117756, loss_ce: 0.023455
[01:07:28.648] iteration 9578 : loss : 0.062132, loss_ce: 0.015716
[01:07:28.957] iteration 9579 : loss : 0.047258, loss_ce: 0.008673
[01:07:29.257] iteration 9580 : loss : 0.047191, loss_ce: 0.011688
[01:07:29.582] iteration 9581 : loss : 0.059904, loss_ce: 0.021398
[01:07:29.887] iteration 9582 : loss : 0.053577, loss_ce: 0.020569
[01:07:30.192] iteration 9583 : loss : 0.120832, loss_ce: 0.014968
[01:07:30.499] iteration 9584 : loss : 0.049279, loss_ce: 0.012025
[01:07:30.807] iteration 9585 : loss : 0.046805, loss_ce: 0.019776
[01:07:31.115] iteration 9586 : loss : 0.125405, loss_ce: 0.019203
[01:07:31.422] iteration 9587 : loss : 0.064935, loss_ce: 0.010478
[01:07:31.728] iteration 9588 : loss : 0.110551, loss_ce: 0.014718
[01:07:32.031] iteration 9589 : loss : 0.158334, loss_ce: 0.005552
[01:07:32.342] iteration 9590 : loss : 0.131226, loss_ce: 0.014461
[01:07:32.428] iteration 9591 : loss : 0.168723, loss_ce: 0.027383
[01:07:51.436] iteration 9592 : loss : 0.055368, loss_ce: 0.019685
[01:07:51.737] iteration 9593 : loss : 0.056585, loss_ce: 0.015745
[01:07:52.036] iteration 9594 : loss : 0.059959, loss_ce: 0.015418
[01:07:52.337] iteration 9595 : loss : 0.054931, loss_ce: 0.011110
[01:07:52.643] iteration 9596 : loss : 0.058790, loss_ce: 0.014810
[01:07:52.945] iteration 9597 : loss : 0.054286, loss_ce: 0.013598
[01:07:53.247] iteration 9598 : loss : 0.052668, loss_ce: 0.009444
[01:07:53.548] iteration 9599 : loss : 0.040905, loss_ce: 0.008885
[01:07:53.850] iteration 9600 : loss : 0.106414, loss_ce: 0.006463
[01:07:54.171] iteration 9601 : loss : 0.069874, loss_ce: 0.021782
[01:07:54.472] iteration 9602 : loss : 0.057898, loss_ce: 0.007161
[01:07:54.775] iteration 9603 : loss : 0.088858, loss_ce: 0.019020
[01:07:55.081] iteration 9604 : loss : 0.048860, loss_ce: 0.022533
[01:07:55.386] iteration 9605 : loss : 0.108922, loss_ce: 0.011125
[01:07:55.687] iteration 9606 : loss : 0.053674, loss_ce: 0.016508
[01:07:55.991] iteration 9607 : loss : 0.065274, loss_ce: 0.016125
[01:07:56.290] iteration 9608 : loss : 0.106413, loss_ce: 0.019835
[01:07:56.592] iteration 9609 : loss : 0.046236, loss_ce: 0.015188
[01:07:56.895] iteration 9610 : loss : 0.067843, loss_ce: 0.015592
[01:07:57.202] iteration 9611 : loss : 0.051275, loss_ce: 0.019187
[01:07:57.505] iteration 9612 : loss : 0.054846, loss_ce: 0.014467
[01:07:57.811] iteration 9613 : loss : 0.054152, loss_ce: 0.025233
[01:07:58.114] iteration 9614 : loss : 0.111742, loss_ce: 0.011805
[01:07:58.418] iteration 9615 : loss : 0.167100, loss_ce: 0.004080
[01:07:58.723] iteration 9616 : loss : 0.063774, loss_ce: 0.011095
[01:07:59.027] iteration 9617 : loss : 0.036533, loss_ce: 0.009489
[01:07:59.332] iteration 9618 : loss : 0.084266, loss_ce: 0.005306
[01:07:59.635] iteration 9619 : loss : 0.048311, loss_ce: 0.012230
[01:07:59.938] iteration 9620 : loss : 0.243978, loss_ce: 0.008611
[01:08:00.263] iteration 9621 : loss : 0.037044, loss_ce: 0.010368
[01:08:00.565] iteration 9622 : loss : 0.074498, loss_ce: 0.012085
[01:08:00.871] iteration 9623 : loss : 0.057898, loss_ce: 0.018386
[01:08:01.174] iteration 9624 : loss : 0.051304, loss_ce: 0.012494
[01:08:01.477] iteration 9625 : loss : 0.063031, loss_ce: 0.014950
[01:08:01.781] iteration 9626 : loss : 0.058824, loss_ce: 0.019758
[01:08:02.083] iteration 9627 : loss : 0.045360, loss_ce: 0.011309
[01:08:02.390] iteration 9628 : loss : 0.045673, loss_ce: 0.011777
[01:08:02.693] iteration 9629 : loss : 0.050581, loss_ce: 0.024374
[01:08:02.998] iteration 9630 : loss : 0.061502, loss_ce: 0.008575
[01:08:03.303] iteration 9631 : loss : 0.087422, loss_ce: 0.015646
[01:08:03.608] iteration 9632 : loss : 0.091038, loss_ce: 0.024615
[01:08:03.915] iteration 9633 : loss : 0.049112, loss_ce: 0.017907
[01:08:04.222] iteration 9634 : loss : 0.056861, loss_ce: 0.012695
[01:08:04.528] iteration 9635 : loss : 0.055776, loss_ce: 0.009924
[01:08:04.829] iteration 9636 : loss : 0.061553, loss_ce: 0.022819
[01:08:05.136] iteration 9637 : loss : 0.048961, loss_ce: 0.012041
[01:08:05.445] iteration 9638 : loss : 0.051350, loss_ce: 0.018490
[01:08:05.754] iteration 9639 : loss : 0.057356, loss_ce: 0.017443
[01:08:06.061] iteration 9640 : loss : 0.111988, loss_ce: 0.008158
[01:08:06.384] iteration 9641 : loss : 0.060654, loss_ce: 0.022435
[01:08:06.694] iteration 9642 : loss : 0.050934, loss_ce: 0.019138
[01:08:07.007] iteration 9643 : loss : 0.058651, loss_ce: 0.021202
[01:08:07.313] iteration 9644 : loss : 0.067579, loss_ce: 0.014967
[01:08:07.626] iteration 9645 : loss : 0.049427, loss_ce: 0.016180
[01:08:07.931] iteration 9646 : loss : 0.114232, loss_ce: 0.009694
[01:08:08.242] iteration 9647 : loss : 0.103099, loss_ce: 0.009913
[01:08:08.548] iteration 9648 : loss : 0.049313, loss_ce: 0.011168
[01:08:08.856] iteration 9649 : loss : 0.063774, loss_ce: 0.031283
[01:08:09.166] iteration 9650 : loss : 0.058765, loss_ce: 0.015891
[01:08:09.475] iteration 9651 : loss : 0.054783, loss_ce: 0.016505
[01:08:09.783] iteration 9652 : loss : 0.047452, loss_ce: 0.021137
[01:08:10.092] iteration 9653 : loss : 0.045580, loss_ce: 0.016210
[01:08:10.400] iteration 9654 : loss : 0.110489, loss_ce: 0.014911
[01:08:10.706] iteration 9655 : loss : 0.058331, loss_ce: 0.017842
[01:08:11.017] iteration 9656 : loss : 0.049340, loss_ce: 0.017704
[01:08:11.325] iteration 9657 : loss : 0.060140, loss_ce: 0.023565
[01:08:11.634] iteration 9658 : loss : 0.168475, loss_ce: 0.005320
[01:08:11.942] iteration 9659 : loss : 0.070114, loss_ce: 0.019111
[01:08:12.256] iteration 9660 : loss : 0.044601, loss_ce: 0.006790
[01:08:12.583] iteration 9661 : loss : 0.043660, loss_ce: 0.013018
[01:08:12.889] iteration 9662 : loss : 0.065407, loss_ce: 0.015818
[01:08:13.201] iteration 9663 : loss : 0.107614, loss_ce: 0.010471
[01:08:13.505] iteration 9664 : loss : 0.060711, loss_ce: 0.023705
[01:08:13.813] iteration 9665 : loss : 0.044503, loss_ce: 0.018434
[01:08:14.122] iteration 9666 : loss : 0.050046, loss_ce: 0.014698
[01:08:14.428] iteration 9667 : loss : 0.057987, loss_ce: 0.024757
[01:08:14.735] iteration 9668 : loss : 0.048559, loss_ce: 0.010044
[01:08:15.042] iteration 9669 : loss : 0.060760, loss_ce: 0.025843
[01:08:15.352] iteration 9670 : loss : 0.062946, loss_ce: 0.021327
[01:08:15.661] iteration 9671 : loss : 0.063358, loss_ce: 0.022528
[01:08:15.971] iteration 9672 : loss : 0.056879, loss_ce: 0.011652
[01:08:16.281] iteration 9673 : loss : 0.057669, loss_ce: 0.015212
[01:08:16.590] iteration 9674 : loss : 0.053730, loss_ce: 0.027621
[01:08:16.894] iteration 9675 : loss : 0.050081, loss_ce: 0.015638
[01:08:17.204] iteration 9676 : loss : 0.064898, loss_ce: 0.016846
[01:08:17.512] iteration 9677 : loss : 0.140197, loss_ce: 0.017482
[01:08:17.821] iteration 9678 : loss : 0.070049, loss_ce: 0.024293
[01:08:18.128] iteration 9679 : loss : 0.055718, loss_ce: 0.010043
[01:08:18.435] iteration 9680 : loss : 0.060313, loss_ce: 0.026728
[01:08:18.759] iteration 9681 : loss : 0.112175, loss_ce: 0.019411
[01:08:19.067] iteration 9682 : loss : 0.103671, loss_ce: 0.016748
[01:08:19.378] iteration 9683 : loss : 0.079711, loss_ce: 0.020084
[01:08:19.682] iteration 9684 : loss : 0.114354, loss_ce: 0.015802
[01:08:19.988] iteration 9685 : loss : 0.059202, loss_ce: 0.023659
[01:08:20.297] iteration 9686 : loss : 0.086638, loss_ce: 0.015143
[01:08:20.605] iteration 9687 : loss : 0.097141, loss_ce: 0.016965
[01:08:20.912] iteration 9688 : loss : 0.054327, loss_ce: 0.020984
[01:08:21.219] iteration 9689 : loss : 0.124010, loss_ce: 0.009027
[01:08:21.531] iteration 9690 : loss : 0.052387, loss_ce: 0.022525
[01:08:21.840] iteration 9691 : loss : 0.109669, loss_ce: 0.010220
[01:08:22.150] iteration 9692 : loss : 0.108308, loss_ce: 0.004182
[01:08:22.460] iteration 9693 : loss : 0.058886, loss_ce: 0.013016
[01:08:22.766] iteration 9694 : loss : 0.073141, loss_ce: 0.015748
[01:08:23.080] iteration 9695 : loss : 0.053696, loss_ce: 0.022890
[01:08:23.390] iteration 9696 : loss : 0.053171, loss_ce: 0.018470
[01:08:23.699] iteration 9697 : loss : 0.067772, loss_ce: 0.018224
[01:08:24.007] iteration 9698 : loss : 0.063805, loss_ce: 0.018605
[01:08:24.313] iteration 9699 : loss : 0.053942, loss_ce: 0.013555
[01:08:24.618] iteration 9700 : loss : 0.053228, loss_ce: 0.008454
[01:08:24.935] iteration 9701 : loss : 0.052717, loss_ce: 0.016265
[01:08:25.238] iteration 9702 : loss : 0.101152, loss_ce: 0.019600
[01:08:25.540] iteration 9703 : loss : 0.039884, loss_ce: 0.010520
[01:08:25.845] iteration 9704 : loss : 0.112195, loss_ce: 0.019665
[01:08:26.149] iteration 9705 : loss : 0.056994, loss_ce: 0.017349
[01:08:26.458] iteration 9706 : loss : 0.063755, loss_ce: 0.030435
[01:08:26.764] iteration 9707 : loss : 0.053721, loss_ce: 0.019862
[01:08:27.070] iteration 9708 : loss : 0.117875, loss_ce: 0.017743
[01:08:27.373] iteration 9709 : loss : 0.040406, loss_ce: 0.016796
[01:08:27.682] iteration 9710 : loss : 0.111125, loss_ce: 0.017467
[01:08:27.986] iteration 9711 : loss : 0.051902, loss_ce: 0.014022
[01:08:28.292] iteration 9712 : loss : 0.060007, loss_ce: 0.027180
[01:08:28.594] iteration 9713 : loss : 0.057023, loss_ce: 0.021147
[01:08:28.901] iteration 9714 : loss : 0.162435, loss_ce: 0.011749
[01:08:29.204] iteration 9715 : loss : 0.059755, loss_ce: 0.015068
[01:08:29.512] iteration 9716 : loss : 0.083703, loss_ce: 0.015279
[01:08:29.818] iteration 9717 : loss : 0.169309, loss_ce: 0.007735
[01:08:30.125] iteration 9718 : loss : 0.055807, loss_ce: 0.011090
[01:08:30.429] iteration 9719 : loss : 0.065900, loss_ce: 0.014362
[01:08:30.736] iteration 9720 : loss : 0.056795, loss_ce: 0.015492
[01:08:31.065] iteration 9721 : loss : 0.254904, loss_ce: 0.008302
[01:08:31.372] iteration 9722 : loss : 0.126148, loss_ce: 0.014176
[01:08:31.677] iteration 9723 : loss : 0.116420, loss_ce: 0.009367
[01:08:31.989] iteration 9724 : loss : 0.110797, loss_ce: 0.012739
[01:08:32.297] iteration 9725 : loss : 0.074696, loss_ce: 0.028444
[01:08:32.602] iteration 9726 : loss : 0.066251, loss_ce: 0.023154
[01:08:32.910] iteration 9727 : loss : 0.057714, loss_ce: 0.021694
[01:08:33.218] iteration 9728 : loss : 0.038850, loss_ce: 0.009206
[01:08:33.527] iteration 9729 : loss : 0.067466, loss_ce: 0.014148
[01:08:33.603] iteration 9730 : loss : 0.107697, loss_ce: 0.009426
[01:08:51.631] iteration 9731 : loss : 0.068830, loss_ce: 0.023243
[01:08:51.935] iteration 9732 : loss : 0.071925, loss_ce: 0.022625
[01:08:52.237] iteration 9733 : loss : 0.062975, loss_ce: 0.016660
[01:08:52.545] iteration 9734 : loss : 0.049738, loss_ce: 0.016963
[01:08:52.855] iteration 9735 : loss : 0.046610, loss_ce: 0.008391
[01:08:53.162] iteration 9736 : loss : 0.058478, loss_ce: 0.010223
[01:08:53.469] iteration 9737 : loss : 0.054169, loss_ce: 0.016031
[01:08:53.778] iteration 9738 : loss : 0.048221, loss_ce: 0.021499
[01:08:54.084] iteration 9739 : loss : 0.051835, loss_ce: 0.023540
[01:08:54.389] iteration 9740 : loss : 0.049227, loss_ce: 0.015763
[01:08:54.711] iteration 9741 : loss : 0.059916, loss_ce: 0.017811
[01:08:55.015] iteration 9742 : loss : 0.050791, loss_ce: 0.020522
[01:08:55.319] iteration 9743 : loss : 0.052848, loss_ce: 0.018945
[01:08:55.622] iteration 9744 : loss : 0.058717, loss_ce: 0.019319
[01:08:55.925] iteration 9745 : loss : 0.054253, loss_ce: 0.015310
[01:08:56.230] iteration 9746 : loss : 0.065143, loss_ce: 0.018651
[01:08:56.532] iteration 9747 : loss : 0.069678, loss_ce: 0.020761
[01:08:56.837] iteration 9748 : loss : 0.049803, loss_ce: 0.023397
[01:08:57.142] iteration 9749 : loss : 0.050692, loss_ce: 0.016855
[01:08:57.450] iteration 9750 : loss : 0.062445, loss_ce: 0.023302
[01:08:57.756] iteration 9751 : loss : 0.050408, loss_ce: 0.023610
[01:08:58.063] iteration 9752 : loss : 0.109387, loss_ce: 0.013393
[01:08:58.365] iteration 9753 : loss : 0.109140, loss_ce: 0.013320
[01:08:58.673] iteration 9754 : loss : 0.066103, loss_ce: 0.027951
[01:08:58.977] iteration 9755 : loss : 0.113772, loss_ce: 0.022620
[01:08:59.285] iteration 9756 : loss : 0.063569, loss_ce: 0.011382
[01:08:59.592] iteration 9757 : loss : 0.074804, loss_ce: 0.012348
[01:08:59.900] iteration 9758 : loss : 0.049854, loss_ce: 0.015197
[01:09:00.206] iteration 9759 : loss : 0.054642, loss_ce: 0.017710
[01:09:00.509] iteration 9760 : loss : 0.100539, loss_ce: 0.009561
[01:09:00.830] iteration 9761 : loss : 0.052321, loss_ce: 0.011892
[01:09:01.140] iteration 9762 : loss : 0.075781, loss_ce: 0.026418
[01:09:01.444] iteration 9763 : loss : 0.062273, loss_ce: 0.019454
[01:09:01.749] iteration 9764 : loss : 0.048079, loss_ce: 0.020187
[01:09:02.058] iteration 9765 : loss : 0.053587, loss_ce: 0.025080
[01:09:02.365] iteration 9766 : loss : 0.050747, loss_ce: 0.023105
[01:09:02.667] iteration 9767 : loss : 0.054242, loss_ce: 0.019944
[01:09:02.972] iteration 9768 : loss : 0.050910, loss_ce: 0.015482
[01:09:03.281] iteration 9769 : loss : 0.171880, loss_ce: 0.010639
[01:09:03.588] iteration 9770 : loss : 0.094675, loss_ce: 0.010118
[01:09:03.893] iteration 9771 : loss : 0.052552, loss_ce: 0.009301
[01:09:04.199] iteration 9772 : loss : 0.052610, loss_ce: 0.015942
[01:09:04.507] iteration 9773 : loss : 0.063676, loss_ce: 0.019049
[01:09:04.811] iteration 9774 : loss : 0.057683, loss_ce: 0.018954
[01:09:05.116] iteration 9775 : loss : 0.052530, loss_ce: 0.019868
[01:09:05.424] iteration 9776 : loss : 0.088564, loss_ce: 0.014920
[01:09:05.733] iteration 9777 : loss : 0.038942, loss_ce: 0.008057
[01:09:06.040] iteration 9778 : loss : 0.052352, loss_ce: 0.015408
[01:09:06.349] iteration 9779 : loss : 0.052516, loss_ce: 0.023802
[01:09:06.654] iteration 9780 : loss : 0.118207, loss_ce: 0.012147
[01:09:06.976] iteration 9781 : loss : 0.110475, loss_ce: 0.010202
[01:09:07.280] iteration 9782 : loss : 0.089421, loss_ce: 0.008054
[01:09:07.588] iteration 9783 : loss : 0.064536, loss_ce: 0.020562
[01:09:07.893] iteration 9784 : loss : 0.099218, loss_ce: 0.007699
[01:09:08.203] iteration 9785 : loss : 0.056847, loss_ce: 0.008974
[01:09:08.514] iteration 9786 : loss : 0.083140, loss_ce: 0.021449
[01:09:08.823] iteration 9787 : loss : 0.069379, loss_ce: 0.014087
[01:09:09.136] iteration 9788 : loss : 0.068285, loss_ce: 0.018876
[01:09:09.447] iteration 9789 : loss : 0.067245, loss_ce: 0.020748
[01:09:09.757] iteration 9790 : loss : 0.045190, loss_ce: 0.015850
[01:09:10.065] iteration 9791 : loss : 0.082557, loss_ce: 0.013713
[01:09:10.374] iteration 9792 : loss : 0.065769, loss_ce: 0.021620
[01:09:10.682] iteration 9793 : loss : 0.047655, loss_ce: 0.019704
[01:09:10.993] iteration 9794 : loss : 0.054119, loss_ce: 0.016787
[01:09:11.302] iteration 9795 : loss : 0.067487, loss_ce: 0.016140
[01:09:11.611] iteration 9796 : loss : 0.056086, loss_ce: 0.016619
[01:09:11.924] iteration 9797 : loss : 0.068981, loss_ce: 0.025574
[01:09:12.234] iteration 9798 : loss : 0.052478, loss_ce: 0.014773
[01:09:12.545] iteration 9799 : loss : 0.064949, loss_ce: 0.024209
[01:09:12.857] iteration 9800 : loss : 0.053613, loss_ce: 0.011321
[01:09:13.175] iteration 9801 : loss : 0.107643, loss_ce: 0.017218
[01:09:13.486] iteration 9802 : loss : 0.054347, loss_ce: 0.021681
[01:09:13.796] iteration 9803 : loss : 0.072967, loss_ce: 0.015509
[01:09:14.106] iteration 9804 : loss : 0.165614, loss_ce: 0.005837
[01:09:14.416] iteration 9805 : loss : 0.057602, loss_ce: 0.013279
[01:09:14.727] iteration 9806 : loss : 0.049025, loss_ce: 0.012881
[01:09:15.035] iteration 9807 : loss : 0.062051, loss_ce: 0.019240
[01:09:15.346] iteration 9808 : loss : 0.052160, loss_ce: 0.012597
[01:09:15.660] iteration 9809 : loss : 0.059158, loss_ce: 0.013187
[01:09:15.975] iteration 9810 : loss : 0.059591, loss_ce: 0.010356
[01:09:16.284] iteration 9811 : loss : 0.170498, loss_ce: 0.015734
[01:09:16.592] iteration 9812 : loss : 0.055880, loss_ce: 0.011492
[01:09:16.904] iteration 9813 : loss : 0.159452, loss_ce: 0.008778
[01:09:17.217] iteration 9814 : loss : 0.050482, loss_ce: 0.009958
[01:09:17.525] iteration 9815 : loss : 0.057287, loss_ce: 0.016831
[01:09:17.835] iteration 9816 : loss : 0.079059, loss_ce: 0.016608
[01:09:18.146] iteration 9817 : loss : 0.101184, loss_ce: 0.008775
[01:09:18.460] iteration 9818 : loss : 0.057131, loss_ce: 0.014789
[01:09:18.768] iteration 9819 : loss : 0.059644, loss_ce: 0.020996
[01:09:19.077] iteration 9820 : loss : 0.041968, loss_ce: 0.009732
[01:09:19.402] iteration 9821 : loss : 0.057457, loss_ce: 0.019695
[01:09:19.710] iteration 9822 : loss : 0.046051, loss_ce: 0.011333
[01:09:20.022] iteration 9823 : loss : 0.121653, loss_ce: 0.016000
[01:09:20.329] iteration 9824 : loss : 0.069902, loss_ce: 0.021877
[01:09:20.637] iteration 9825 : loss : 0.125357, loss_ce: 0.010063
[01:09:20.946] iteration 9826 : loss : 0.048515, loss_ce: 0.011786
[01:09:21.254] iteration 9827 : loss : 0.037643, loss_ce: 0.015355
[01:09:21.561] iteration 9828 : loss : 0.157336, loss_ce: 0.008146
[01:09:21.871] iteration 9829 : loss : 0.046730, loss_ce: 0.008635
[01:09:22.178] iteration 9830 : loss : 0.072034, loss_ce: 0.017611
[01:09:22.489] iteration 9831 : loss : 0.054603, loss_ce: 0.014976
[01:09:22.796] iteration 9832 : loss : 0.042920, loss_ce: 0.011091
[01:09:23.107] iteration 9833 : loss : 0.060627, loss_ce: 0.015393
[01:09:23.412] iteration 9834 : loss : 0.063189, loss_ce: 0.009699
[01:09:23.721] iteration 9835 : loss : 0.087068, loss_ce: 0.027049
[01:09:24.030] iteration 9836 : loss : 0.052024, loss_ce: 0.024124
[01:09:24.337] iteration 9837 : loss : 0.051712, loss_ce: 0.013482
[01:09:24.646] iteration 9838 : loss : 0.051765, loss_ce: 0.023115
[01:09:24.953] iteration 9839 : loss : 0.220550, loss_ce: 0.007253
[01:09:25.267] iteration 9840 : loss : 0.061979, loss_ce: 0.016593
[01:09:25.597] iteration 9841 : loss : 0.047861, loss_ce: 0.014833
[01:09:25.904] iteration 9842 : loss : 0.054981, loss_ce: 0.023979
[01:09:26.213] iteration 9843 : loss : 0.067251, loss_ce: 0.015071
[01:09:26.527] iteration 9844 : loss : 0.042309, loss_ce: 0.012956
[01:09:26.832] iteration 9845 : loss : 0.041766, loss_ce: 0.007527
[01:09:27.140] iteration 9846 : loss : 0.059687, loss_ce: 0.011396
[01:09:27.451] iteration 9847 : loss : 0.060837, loss_ce: 0.021324
[01:09:27.757] iteration 9848 : loss : 0.056948, loss_ce: 0.022572
[01:09:28.068] iteration 9849 : loss : 0.064073, loss_ce: 0.019023
[01:09:28.381] iteration 9850 : loss : 0.107778, loss_ce: 0.012583
[01:09:28.688] iteration 9851 : loss : 0.055769, loss_ce: 0.025024
[01:09:29.001] iteration 9852 : loss : 0.043571, loss_ce: 0.010905
[01:09:29.305] iteration 9853 : loss : 0.117376, loss_ce: 0.006724
[01:09:29.614] iteration 9854 : loss : 0.056874, loss_ce: 0.012125
[01:09:29.919] iteration 9855 : loss : 0.053619, loss_ce: 0.017727
[01:09:30.233] iteration 9856 : loss : 0.054519, loss_ce: 0.014519
[01:09:30.537] iteration 9857 : loss : 0.061468, loss_ce: 0.016311
[01:09:30.850] iteration 9858 : loss : 0.050540, loss_ce: 0.011838
[01:09:31.157] iteration 9859 : loss : 0.051898, loss_ce: 0.016195
[01:09:31.460] iteration 9860 : loss : 0.111094, loss_ce: 0.005653
[01:09:31.785] iteration 9861 : loss : 0.046349, loss_ce: 0.015793
[01:09:32.094] iteration 9862 : loss : 0.085717, loss_ce: 0.018815
[01:09:32.411] iteration 9863 : loss : 0.038073, loss_ce: 0.011293
[01:09:32.716] iteration 9864 : loss : 0.113274, loss_ce: 0.015795
[01:09:33.024] iteration 9865 : loss : 0.051319, loss_ce: 0.017998
[01:09:33.333] iteration 9866 : loss : 0.115803, loss_ce: 0.013193
[01:09:33.641] iteration 9867 : loss : 0.046902, loss_ce: 0.017742
[01:09:33.945] iteration 9868 : loss : 0.061359, loss_ce: 0.028033
[01:09:34.027] iteration 9869 : loss : 0.360784, loss_ce: 0.020086
[01:09:53.315] iteration 9870 : loss : 0.046594, loss_ce: 0.011278
[01:09:53.614] iteration 9871 : loss : 0.118385, loss_ce: 0.017569
[01:09:53.912] iteration 9872 : loss : 0.108895, loss_ce: 0.018086
[01:09:54.218] iteration 9873 : loss : 0.039992, loss_ce: 0.011101
[01:09:54.520] iteration 9874 : loss : 0.053559, loss_ce: 0.021289
[01:09:54.821] iteration 9875 : loss : 0.064530, loss_ce: 0.024998
[01:09:55.126] iteration 9876 : loss : 0.219996, loss_ce: 0.008301
[01:09:55.428] iteration 9877 : loss : 0.129647, loss_ce: 0.008985
[01:09:55.730] iteration 9878 : loss : 0.052697, loss_ce: 0.017476
[01:09:56.029] iteration 9879 : loss : 0.110772, loss_ce: 0.017245
[01:09:56.332] iteration 9880 : loss : 0.097273, loss_ce: 0.025801
[01:09:56.655] iteration 9881 : loss : 0.053954, loss_ce: 0.020941
[01:09:56.958] iteration 9882 : loss : 0.050830, loss_ce: 0.023006
[01:09:57.263] iteration 9883 : loss : 0.054556, loss_ce: 0.020751
[01:09:57.571] iteration 9884 : loss : 0.124007, loss_ce: 0.008187
[01:09:57.879] iteration 9885 : loss : 0.055824, loss_ce: 0.018221
[01:09:58.188] iteration 9886 : loss : 0.056220, loss_ce: 0.023412
[01:09:58.502] iteration 9887 : loss : 0.086666, loss_ce: 0.021668
[01:09:58.812] iteration 9888 : loss : 0.074478, loss_ce: 0.017575
[01:09:59.120] iteration 9889 : loss : 0.057271, loss_ce: 0.017492
[01:09:59.426] iteration 9890 : loss : 0.063038, loss_ce: 0.010354
[01:09:59.728] iteration 9891 : loss : 0.055981, loss_ce: 0.024953
[01:10:00.030] iteration 9892 : loss : 0.152895, loss_ce: 0.011029
[01:10:00.334] iteration 9893 : loss : 0.051513, loss_ce: 0.013948
[01:10:00.641] iteration 9894 : loss : 0.055007, loss_ce: 0.022306
[01:10:00.948] iteration 9895 : loss : 0.048469, loss_ce: 0.014585
[01:10:01.251] iteration 9896 : loss : 0.095152, loss_ce: 0.015812
[01:10:01.556] iteration 9897 : loss : 0.048238, loss_ce: 0.018472
[01:10:01.858] iteration 9898 : loss : 0.117592, loss_ce: 0.016732
[01:10:02.162] iteration 9899 : loss : 0.049193, loss_ce: 0.012735
[01:10:02.465] iteration 9900 : loss : 0.056908, loss_ce: 0.020835
[01:10:02.781] iteration 9901 : loss : 0.037924, loss_ce: 0.006959
[01:10:03.082] iteration 9902 : loss : 0.048891, loss_ce: 0.012274
[01:10:03.386] iteration 9903 : loss : 0.094705, loss_ce: 0.017975
[01:10:03.687] iteration 9904 : loss : 0.112796, loss_ce: 0.011934
[01:10:03.987] iteration 9905 : loss : 0.119648, loss_ce: 0.010359
[01:10:04.291] iteration 9906 : loss : 0.064030, loss_ce: 0.012147
[01:10:04.595] iteration 9907 : loss : 0.062250, loss_ce: 0.015864
[01:10:04.899] iteration 9908 : loss : 0.056474, loss_ce: 0.021388
[01:10:05.200] iteration 9909 : loss : 0.056024, loss_ce: 0.021708
[01:10:05.501] iteration 9910 : loss : 0.110200, loss_ce: 0.007927
[01:10:05.805] iteration 9911 : loss : 0.057971, loss_ce: 0.025705
[01:10:06.106] iteration 9912 : loss : 0.052513, loss_ce: 0.014144
[01:10:06.409] iteration 9913 : loss : 0.112850, loss_ce: 0.011418
[01:10:06.716] iteration 9914 : loss : 0.105214, loss_ce: 0.005917
[01:10:07.017] iteration 9915 : loss : 0.108052, loss_ce: 0.013096
[01:10:07.323] iteration 9916 : loss : 0.109497, loss_ce: 0.019110
[01:10:07.627] iteration 9917 : loss : 0.052463, loss_ce: 0.023636
[01:10:07.929] iteration 9918 : loss : 0.049071, loss_ce: 0.010206
[01:10:08.232] iteration 9919 : loss : 0.042246, loss_ce: 0.020504
[01:10:08.539] iteration 9920 : loss : 0.057220, loss_ce: 0.013891
[01:10:08.862] iteration 9921 : loss : 0.062456, loss_ce: 0.020064
[01:10:09.162] iteration 9922 : loss : 0.054026, loss_ce: 0.012357
[01:10:09.468] iteration 9923 : loss : 0.061215, loss_ce: 0.010089
[01:10:09.772] iteration 9924 : loss : 0.055689, loss_ce: 0.021558
[01:10:10.074] iteration 9925 : loss : 0.106962, loss_ce: 0.017579
[01:10:10.377] iteration 9926 : loss : 0.039091, loss_ce: 0.013665
[01:10:10.681] iteration 9927 : loss : 0.045144, loss_ce: 0.015051
[01:10:10.986] iteration 9928 : loss : 0.109499, loss_ce: 0.017768
[01:10:11.288] iteration 9929 : loss : 0.074558, loss_ce: 0.025541
[01:10:11.591] iteration 9930 : loss : 0.042698, loss_ce: 0.014817
[01:10:11.897] iteration 9931 : loss : 0.117766, loss_ce: 0.024508
[01:10:12.197] iteration 9932 : loss : 0.057707, loss_ce: 0.007587
[01:10:12.501] iteration 9933 : loss : 0.049234, loss_ce: 0.010945
[01:10:12.809] iteration 9934 : loss : 0.060037, loss_ce: 0.013509
[01:10:13.116] iteration 9935 : loss : 0.054265, loss_ce: 0.014913
[01:10:13.425] iteration 9936 : loss : 0.059434, loss_ce: 0.019210
[01:10:13.733] iteration 9937 : loss : 0.056822, loss_ce: 0.015896
[01:10:14.039] iteration 9938 : loss : 0.063128, loss_ce: 0.013567
[01:10:14.346] iteration 9939 : loss : 0.063553, loss_ce: 0.028400
[01:10:14.653] iteration 9940 : loss : 0.061087, loss_ce: 0.016163
[01:10:14.977] iteration 9941 : loss : 0.053195, loss_ce: 0.016281
[01:10:15.284] iteration 9942 : loss : 0.061846, loss_ce: 0.031887
[01:10:15.591] iteration 9943 : loss : 0.057712, loss_ce: 0.018408
[01:10:15.898] iteration 9944 : loss : 0.047715, loss_ce: 0.014901
[01:10:16.205] iteration 9945 : loss : 0.045206, loss_ce: 0.016888
[01:10:16.512] iteration 9946 : loss : 0.104894, loss_ce: 0.011183
[01:10:16.819] iteration 9947 : loss : 0.055909, loss_ce: 0.008781
[01:10:17.125] iteration 9948 : loss : 0.048535, loss_ce: 0.015032
[01:10:17.432] iteration 9949 : loss : 0.064447, loss_ce: 0.009751
[01:10:17.740] iteration 9950 : loss : 0.057566, loss_ce: 0.020686
[01:10:18.047] iteration 9951 : loss : 0.224394, loss_ce: 0.010643
[01:10:18.353] iteration 9952 : loss : 0.112984, loss_ce: 0.009337
[01:10:18.659] iteration 9953 : loss : 0.047042, loss_ce: 0.013888
[01:10:18.972] iteration 9954 : loss : 0.057864, loss_ce: 0.009368
[01:10:19.284] iteration 9955 : loss : 0.047126, loss_ce: 0.018216
[01:10:19.591] iteration 9956 : loss : 0.059230, loss_ce: 0.013212
[01:10:19.905] iteration 9957 : loss : 0.050570, loss_ce: 0.013195
[01:10:20.217] iteration 9958 : loss : 0.048254, loss_ce: 0.009277
[01:10:20.523] iteration 9959 : loss : 0.041819, loss_ce: 0.006188
[01:10:20.828] iteration 9960 : loss : 0.056558, loss_ce: 0.014602
[01:10:21.150] iteration 9961 : loss : 0.064880, loss_ce: 0.017715
[01:10:21.453] iteration 9962 : loss : 0.051120, loss_ce: 0.019338
[01:10:21.767] iteration 9963 : loss : 0.057506, loss_ce: 0.014971
[01:10:22.075] iteration 9964 : loss : 0.122183, loss_ce: 0.009447
[01:10:22.382] iteration 9965 : loss : 0.112835, loss_ce: 0.017014
[01:10:22.688] iteration 9966 : loss : 0.052776, loss_ce: 0.013858
[01:10:23.000] iteration 9967 : loss : 0.048951, loss_ce: 0.012591
[01:10:23.310] iteration 9968 : loss : 0.055519, loss_ce: 0.020903
[01:10:23.624] iteration 9969 : loss : 0.049370, loss_ce: 0.018340
[01:10:23.934] iteration 9970 : loss : 0.076757, loss_ce: 0.015442
[01:10:24.243] iteration 9971 : loss : 0.061338, loss_ce: 0.023262
[01:10:24.552] iteration 9972 : loss : 0.089889, loss_ce: 0.012491
[01:10:24.862] iteration 9973 : loss : 0.057191, loss_ce: 0.020867
[01:10:25.174] iteration 9974 : loss : 0.062999, loss_ce: 0.009526
[01:10:25.486] iteration 9975 : loss : 0.040903, loss_ce: 0.017090
[01:10:25.794] iteration 9976 : loss : 0.052326, loss_ce: 0.018841
[01:10:26.105] iteration 9977 : loss : 0.059866, loss_ce: 0.012716
[01:10:26.417] iteration 9978 : loss : 0.063851, loss_ce: 0.020211
[01:10:26.725] iteration 9979 : loss : 0.052687, loss_ce: 0.014001
[01:10:27.032] iteration 9980 : loss : 0.054167, loss_ce: 0.010488
[01:10:27.367] iteration 9981 : loss : 0.083365, loss_ce: 0.009720
[01:10:27.674] iteration 9982 : loss : 0.110263, loss_ce: 0.016031
[01:10:27.988] iteration 9983 : loss : 0.041889, loss_ce: 0.013901
[01:10:28.293] iteration 9984 : loss : 0.066103, loss_ce: 0.018254
[01:10:28.606] iteration 9985 : loss : 0.046556, loss_ce: 0.015327
[01:10:28.913] iteration 9986 : loss : 0.118987, loss_ce: 0.016905
[01:10:29.223] iteration 9987 : loss : 0.058001, loss_ce: 0.005457
[01:10:29.535] iteration 9988 : loss : 0.067591, loss_ce: 0.022974
[01:10:29.843] iteration 9989 : loss : 0.046451, loss_ce: 0.018906
[01:10:30.149] iteration 9990 : loss : 0.124407, loss_ce: 0.014505
[01:10:30.458] iteration 9991 : loss : 0.056736, loss_ce: 0.011576
[01:10:30.768] iteration 9992 : loss : 0.073481, loss_ce: 0.019442
[01:10:31.078] iteration 9993 : loss : 0.107703, loss_ce: 0.013207
[01:10:31.387] iteration 9994 : loss : 0.058644, loss_ce: 0.017940
[01:10:31.700] iteration 9995 : loss : 0.061733, loss_ce: 0.023169
[01:10:32.015] iteration 9996 : loss : 0.056927, loss_ce: 0.013520
[01:10:32.329] iteration 9997 : loss : 0.058266, loss_ce: 0.018039
[01:10:32.645] iteration 9998 : loss : 0.065370, loss_ce: 0.006846
[01:10:32.960] iteration 9999 : loss : 0.050149, loss_ce: 0.014927
[01:10:33.273] iteration 10000 : loss : 0.053922, loss_ce: 0.019363
[01:10:33.598] iteration 10001 : loss : 0.061051, loss_ce: 0.026749
[01:10:33.916] iteration 10002 : loss : 0.112068, loss_ce: 0.018922
[01:10:34.231] iteration 10003 : loss : 0.051242, loss_ce: 0.025073
[01:10:34.535] iteration 10004 : loss : 0.055135, loss_ce: 0.016746
[01:10:34.841] iteration 10005 : loss : 0.173937, loss_ce: 0.014696
[01:10:35.151] iteration 10006 : loss : 0.105758, loss_ce: 0.018524
[01:10:35.461] iteration 10007 : loss : 0.065304, loss_ce: 0.008802
[01:10:35.538] iteration 10008 : loss : 0.052204, loss_ce: 0.030285
[01:10:54.241] iteration 10009 : loss : 0.060106, loss_ce: 0.010633
[01:10:54.540] iteration 10010 : loss : 0.070109, loss_ce: 0.024694
[01:10:54.841] iteration 10011 : loss : 0.052374, loss_ce: 0.013359
[01:10:55.151] iteration 10012 : loss : 0.068978, loss_ce: 0.006920
[01:10:55.449] iteration 10013 : loss : 0.043889, loss_ce: 0.010745
[01:10:55.752] iteration 10014 : loss : 0.161529, loss_ce: 0.010279
[01:10:56.056] iteration 10015 : loss : 0.047856, loss_ce: 0.022194
[01:10:56.356] iteration 10016 : loss : 0.045620, loss_ce: 0.010229
[01:10:56.662] iteration 10017 : loss : 0.105959, loss_ce: 0.014118
[01:10:56.969] iteration 10018 : loss : 0.061820, loss_ce: 0.008751
[01:10:57.273] iteration 10019 : loss : 0.050736, loss_ce: 0.013378
[01:10:57.580] iteration 10020 : loss : 0.041260, loss_ce: 0.008117
[01:10:57.903] iteration 10021 : loss : 0.056763, loss_ce: 0.024767
[01:10:58.206] iteration 10022 : loss : 0.161632, loss_ce: 0.005965
[01:10:58.514] iteration 10023 : loss : 0.089767, loss_ce: 0.016061
[01:10:58.819] iteration 10024 : loss : 0.052462, loss_ce: 0.018017
[01:10:59.121] iteration 10025 : loss : 0.058668, loss_ce: 0.014155
[01:10:59.426] iteration 10026 : loss : 0.102145, loss_ce: 0.007754
[01:10:59.729] iteration 10027 : loss : 0.055259, loss_ce: 0.010614
[01:11:00.035] iteration 10028 : loss : 0.107961, loss_ce: 0.012502
[01:11:00.342] iteration 10029 : loss : 0.046251, loss_ce: 0.016656
[01:11:00.646] iteration 10030 : loss : 0.047551, loss_ce: 0.012683
[01:11:00.951] iteration 10031 : loss : 0.062923, loss_ce: 0.021991
[01:11:01.258] iteration 10032 : loss : 0.054813, loss_ce: 0.020348
[01:11:01.565] iteration 10033 : loss : 0.058781, loss_ce: 0.015444
[01:11:01.870] iteration 10034 : loss : 0.053749, loss_ce: 0.025230
[01:11:02.180] iteration 10035 : loss : 0.103924, loss_ce: 0.014894
[01:11:02.491] iteration 10036 : loss : 0.038562, loss_ce: 0.008101
[01:11:02.802] iteration 10037 : loss : 0.060289, loss_ce: 0.011735
[01:11:03.112] iteration 10038 : loss : 0.068351, loss_ce: 0.018766
[01:11:03.422] iteration 10039 : loss : 0.125466, loss_ce: 0.020906
[01:11:03.730] iteration 10040 : loss : 0.051483, loss_ce: 0.016991
[01:11:04.057] iteration 10041 : loss : 0.163516, loss_ce: 0.016193
[01:11:04.360] iteration 10042 : loss : 0.055902, loss_ce: 0.017203
[01:11:04.666] iteration 10043 : loss : 0.040911, loss_ce: 0.007415
[01:11:04.971] iteration 10044 : loss : 0.050262, loss_ce: 0.019472
[01:11:05.279] iteration 10045 : loss : 0.157452, loss_ce: 0.005688
[01:11:05.584] iteration 10046 : loss : 0.053011, loss_ce: 0.014296
[01:11:05.888] iteration 10047 : loss : 0.174590, loss_ce: 0.010536
[01:11:06.193] iteration 10048 : loss : 0.070439, loss_ce: 0.027013
[01:11:06.501] iteration 10049 : loss : 0.168139, loss_ce: 0.009942
[01:11:06.807] iteration 10050 : loss : 0.048104, loss_ce: 0.018867
[01:11:07.111] iteration 10051 : loss : 0.120726, loss_ce: 0.011176
[01:11:07.418] iteration 10052 : loss : 0.052923, loss_ce: 0.016447
[01:11:07.723] iteration 10053 : loss : 0.120468, loss_ce: 0.006122
[01:11:08.025] iteration 10054 : loss : 0.049093, loss_ce: 0.017847
[01:11:08.328] iteration 10055 : loss : 0.060468, loss_ce: 0.020867
[01:11:08.632] iteration 10056 : loss : 0.043247, loss_ce: 0.011863
[01:11:08.937] iteration 10057 : loss : 0.045075, loss_ce: 0.017551
[01:11:09.243] iteration 10058 : loss : 0.043587, loss_ce: 0.015580
[01:11:09.547] iteration 10059 : loss : 0.062467, loss_ce: 0.018934
[01:11:09.852] iteration 10060 : loss : 0.066392, loss_ce: 0.021228
[01:11:10.176] iteration 10061 : loss : 0.057887, loss_ce: 0.016248
[01:11:10.482] iteration 10062 : loss : 0.053712, loss_ce: 0.013357
[01:11:10.788] iteration 10063 : loss : 0.115172, loss_ce: 0.017341
[01:11:11.092] iteration 10064 : loss : 0.054907, loss_ce: 0.019673
[01:11:11.396] iteration 10065 : loss : 0.052251, loss_ce: 0.014912
[01:11:11.701] iteration 10066 : loss : 0.047628, loss_ce: 0.010894
[01:11:12.007] iteration 10067 : loss : 0.113782, loss_ce: 0.014894
[01:11:12.314] iteration 10068 : loss : 0.061857, loss_ce: 0.028406
[01:11:12.622] iteration 10069 : loss : 0.049330, loss_ce: 0.014916
[01:11:12.927] iteration 10070 : loss : 0.056826, loss_ce: 0.021094
[01:11:13.229] iteration 10071 : loss : 0.047305, loss_ce: 0.013400
[01:11:13.536] iteration 10072 : loss : 0.059648, loss_ce: 0.020513
[01:11:13.843] iteration 10073 : loss : 0.116469, loss_ce: 0.018786
[01:11:14.151] iteration 10074 : loss : 0.160105, loss_ce: 0.010116
[01:11:14.458] iteration 10075 : loss : 0.111436, loss_ce: 0.007793
[01:11:14.761] iteration 10076 : loss : 0.048199, loss_ce: 0.015422
[01:11:15.071] iteration 10077 : loss : 0.063855, loss_ce: 0.020362
[01:11:15.379] iteration 10078 : loss : 0.105196, loss_ce: 0.015640
[01:11:15.682] iteration 10079 : loss : 0.168621, loss_ce: 0.011453
[01:11:15.990] iteration 10080 : loss : 0.045714, loss_ce: 0.018152
[01:11:16.312] iteration 10081 : loss : 0.055452, loss_ce: 0.014170
[01:11:16.616] iteration 10082 : loss : 0.046623, loss_ce: 0.020092
[01:11:16.922] iteration 10083 : loss : 0.108048, loss_ce: 0.019027
[01:11:17.230] iteration 10084 : loss : 0.052315, loss_ce: 0.016298
[01:11:17.538] iteration 10085 : loss : 0.100444, loss_ce: 0.011066
[01:11:17.850] iteration 10086 : loss : 0.066819, loss_ce: 0.013376
[01:11:18.156] iteration 10087 : loss : 0.052431, loss_ce: 0.020381
[01:11:18.462] iteration 10088 : loss : 0.056910, loss_ce: 0.017202
[01:11:18.771] iteration 10089 : loss : 0.054049, loss_ce: 0.025688
[01:11:19.076] iteration 10090 : loss : 0.052182, loss_ce: 0.015763
[01:11:19.384] iteration 10091 : loss : 0.048114, loss_ce: 0.016532
[01:11:19.694] iteration 10092 : loss : 0.044298, loss_ce: 0.015734
[01:11:20.009] iteration 10093 : loss : 0.048307, loss_ce: 0.011710
[01:11:20.320] iteration 10094 : loss : 0.066484, loss_ce: 0.022633
[01:11:20.625] iteration 10095 : loss : 0.049789, loss_ce: 0.017498
[01:11:20.938] iteration 10096 : loss : 0.045329, loss_ce: 0.020610
[01:11:21.246] iteration 10097 : loss : 0.042955, loss_ce: 0.014038
[01:11:21.553] iteration 10098 : loss : 0.062131, loss_ce: 0.024653
[01:11:21.862] iteration 10099 : loss : 0.100088, loss_ce: 0.009706
[01:11:22.167] iteration 10100 : loss : 0.064979, loss_ce: 0.022519
[01:11:22.493] iteration 10101 : loss : 0.059253, loss_ce: 0.010249
[01:11:22.797] iteration 10102 : loss : 0.057853, loss_ce: 0.018892
[01:11:23.110] iteration 10103 : loss : 0.079882, loss_ce: 0.022563
[01:11:23.416] iteration 10104 : loss : 0.053784, loss_ce: 0.015125
[01:11:23.725] iteration 10105 : loss : 0.047955, loss_ce: 0.017082
[01:11:24.033] iteration 10106 : loss : 0.057645, loss_ce: 0.020643
[01:11:24.341] iteration 10107 : loss : 0.054372, loss_ce: 0.023793
[01:11:24.652] iteration 10108 : loss : 0.052994, loss_ce: 0.019532
[01:11:24.962] iteration 10109 : loss : 0.102148, loss_ce: 0.011880
[01:11:25.269] iteration 10110 : loss : 0.054250, loss_ce: 0.014901
[01:11:25.584] iteration 10111 : loss : 0.111978, loss_ce: 0.017836
[01:11:25.893] iteration 10112 : loss : 0.050438, loss_ce: 0.014439
[01:11:26.197] iteration 10113 : loss : 0.067252, loss_ce: 0.030987
[01:11:26.505] iteration 10114 : loss : 0.100525, loss_ce: 0.010344
[01:11:26.817] iteration 10115 : loss : 0.044145, loss_ce: 0.013292
[01:11:27.123] iteration 10116 : loss : 0.074156, loss_ce: 0.009347
[01:11:27.431] iteration 10117 : loss : 0.052049, loss_ce: 0.020980
[01:11:27.740] iteration 10118 : loss : 0.045127, loss_ce: 0.015138
[01:11:28.044] iteration 10119 : loss : 0.054162, loss_ce: 0.021522
[01:11:28.358] iteration 10120 : loss : 0.068069, loss_ce: 0.028817
[01:11:28.685] iteration 10121 : loss : 0.109809, loss_ce: 0.011187
[01:11:28.988] iteration 10122 : loss : 0.105391, loss_ce: 0.014786
[01:11:29.294] iteration 10123 : loss : 0.058412, loss_ce: 0.007518
[01:11:29.606] iteration 10124 : loss : 0.046462, loss_ce: 0.012755
[01:11:29.913] iteration 10125 : loss : 0.061194, loss_ce: 0.013513
[01:11:30.221] iteration 10126 : loss : 0.059493, loss_ce: 0.025770
[01:11:30.533] iteration 10127 : loss : 0.066417, loss_ce: 0.029172
[01:11:30.837] iteration 10128 : loss : 0.128220, loss_ce: 0.010996
[01:11:31.145] iteration 10129 : loss : 0.035842, loss_ce: 0.009456
[01:11:31.452] iteration 10130 : loss : 0.107679, loss_ce: 0.010319
[01:11:31.765] iteration 10131 : loss : 0.056039, loss_ce: 0.020636
[01:11:32.078] iteration 10132 : loss : 0.124498, loss_ce: 0.012590
[01:11:32.388] iteration 10133 : loss : 0.061249, loss_ce: 0.012647
[01:11:32.703] iteration 10134 : loss : 0.063873, loss_ce: 0.012349
[01:11:33.019] iteration 10135 : loss : 0.056284, loss_ce: 0.012544
[01:11:33.328] iteration 10136 : loss : 0.052840, loss_ce: 0.013882
[01:11:33.643] iteration 10137 : loss : 0.052997, loss_ce: 0.008944
[01:11:33.958] iteration 10138 : loss : 0.053779, loss_ce: 0.015390
[01:11:34.273] iteration 10139 : loss : 0.045621, loss_ce: 0.010205
[01:11:34.587] iteration 10140 : loss : 0.115442, loss_ce: 0.022576
[01:11:34.919] iteration 10141 : loss : 0.107853, loss_ce: 0.011280
[01:11:35.228] iteration 10142 : loss : 0.087763, loss_ce: 0.014417
[01:11:35.550] iteration 10143 : loss : 0.055424, loss_ce: 0.025953
[01:11:35.864] iteration 10144 : loss : 0.085379, loss_ce: 0.007874
[01:11:36.175] iteration 10145 : loss : 0.043411, loss_ce: 0.008661
[01:11:36.499] iteration 10146 : loss : 0.116533, loss_ce: 0.011191
[01:11:36.575] iteration 10147 : loss : 0.345555, loss_ce: 0.005707
[01:11:54.610] iteration 10148 : loss : 0.049339, loss_ce: 0.025230
[01:11:54.911] iteration 10149 : loss : 0.174716, loss_ce: 0.012797
[01:11:55.211] iteration 10150 : loss : 0.053361, loss_ce: 0.019922
[01:11:55.515] iteration 10151 : loss : 0.053473, loss_ce: 0.020321
[01:11:55.818] iteration 10152 : loss : 0.067458, loss_ce: 0.023675
[01:11:56.120] iteration 10153 : loss : 0.061030, loss_ce: 0.012473
[01:11:56.424] iteration 10154 : loss : 0.063386, loss_ce: 0.005085
[01:11:56.725] iteration 10155 : loss : 0.058785, loss_ce: 0.012017
[01:11:57.027] iteration 10156 : loss : 0.045423, loss_ce: 0.015572
[01:11:57.331] iteration 10157 : loss : 0.049486, loss_ce: 0.015538
[01:11:57.631] iteration 10158 : loss : 0.049094, loss_ce: 0.014870
[01:11:57.933] iteration 10159 : loss : 0.062802, loss_ce: 0.016050
[01:11:58.237] iteration 10160 : loss : 0.078437, loss_ce: 0.010097
[01:11:58.552] iteration 10161 : loss : 0.056600, loss_ce: 0.019196
[01:11:58.852] iteration 10162 : loss : 0.045899, loss_ce: 0.018120
[01:11:59.154] iteration 10163 : loss : 0.048637, loss_ce: 0.023881
[01:11:59.458] iteration 10164 : loss : 0.110306, loss_ce: 0.008739
[01:11:59.763] iteration 10165 : loss : 0.064257, loss_ce: 0.016142
[01:12:00.063] iteration 10166 : loss : 0.052671, loss_ce: 0.018915
[01:12:00.367] iteration 10167 : loss : 0.088781, loss_ce: 0.017859
[01:12:00.670] iteration 10168 : loss : 0.058586, loss_ce: 0.015103
[01:12:00.977] iteration 10169 : loss : 0.055416, loss_ce: 0.011244
[01:12:01.278] iteration 10170 : loss : 0.120711, loss_ce: 0.012197
[01:12:01.581] iteration 10171 : loss : 0.061233, loss_ce: 0.026270
[01:12:01.883] iteration 10172 : loss : 0.107041, loss_ce: 0.021396
[01:12:02.188] iteration 10173 : loss : 0.051791, loss_ce: 0.012869
[01:12:02.486] iteration 10174 : loss : 0.103620, loss_ce: 0.009572
[01:12:02.788] iteration 10175 : loss : 0.048223, loss_ce: 0.017646
[01:12:03.090] iteration 10176 : loss : 0.114556, loss_ce: 0.007382
[01:12:03.393] iteration 10177 : loss : 0.040649, loss_ce: 0.017598
[01:12:03.694] iteration 10178 : loss : 0.050822, loss_ce: 0.014276
[01:12:03.999] iteration 10179 : loss : 0.086008, loss_ce: 0.032442
[01:12:04.303] iteration 10180 : loss : 0.048696, loss_ce: 0.008940
[01:12:04.622] iteration 10181 : loss : 0.064786, loss_ce: 0.016661
[01:12:04.923] iteration 10182 : loss : 0.065937, loss_ce: 0.007201
[01:12:05.227] iteration 10183 : loss : 0.065489, loss_ce: 0.025378
[01:12:05.529] iteration 10184 : loss : 0.049166, loss_ce: 0.016462
[01:12:05.830] iteration 10185 : loss : 0.052651, loss_ce: 0.018942
[01:12:06.136] iteration 10186 : loss : 0.063354, loss_ce: 0.010386
[01:12:06.439] iteration 10187 : loss : 0.081698, loss_ce: 0.017789
[01:12:06.740] iteration 10188 : loss : 0.049736, loss_ce: 0.013497
[01:12:07.043] iteration 10189 : loss : 0.101944, loss_ce: 0.006164
[01:12:07.352] iteration 10190 : loss : 0.053124, loss_ce: 0.016685
[01:12:07.663] iteration 10191 : loss : 0.065421, loss_ce: 0.026372
[01:12:07.969] iteration 10192 : loss : 0.065010, loss_ce: 0.008914
[01:12:08.280] iteration 10193 : loss : 0.066543, loss_ce: 0.021604
[01:12:08.589] iteration 10194 : loss : 0.052948, loss_ce: 0.017286
[01:12:08.897] iteration 10195 : loss : 0.048784, loss_ce: 0.027958
[01:12:09.204] iteration 10196 : loss : 0.160925, loss_ce: 0.012135
[01:12:09.508] iteration 10197 : loss : 0.059871, loss_ce: 0.016542
[01:12:09.812] iteration 10198 : loss : 0.054066, loss_ce: 0.010322
[01:12:10.113] iteration 10199 : loss : 0.102923, loss_ce: 0.007115
[01:12:10.416] iteration 10200 : loss : 0.048475, loss_ce: 0.014688
[01:12:10.743] iteration 10201 : loss : 0.059920, loss_ce: 0.024205
[01:12:11.046] iteration 10202 : loss : 0.050294, loss_ce: 0.017318
[01:12:11.347] iteration 10203 : loss : 0.052970, loss_ce: 0.012511
[01:12:11.649] iteration 10204 : loss : 0.135405, loss_ce: 0.011058
[01:12:11.951] iteration 10205 : loss : 0.114345, loss_ce: 0.025020
[01:12:12.257] iteration 10206 : loss : 0.042983, loss_ce: 0.015596
[01:12:12.561] iteration 10207 : loss : 0.113337, loss_ce: 0.016317
[01:12:12.863] iteration 10208 : loss : 0.055209, loss_ce: 0.013859
[01:12:13.165] iteration 10209 : loss : 0.061124, loss_ce: 0.022103
[01:12:13.470] iteration 10210 : loss : 0.053433, loss_ce: 0.032037
[01:12:13.771] iteration 10211 : loss : 0.051835, loss_ce: 0.009877
[01:12:14.072] iteration 10212 : loss : 0.046675, loss_ce: 0.021665
[01:12:14.377] iteration 10213 : loss : 0.054675, loss_ce: 0.022889
[01:12:14.684] iteration 10214 : loss : 0.059578, loss_ce: 0.014442
[01:12:14.985] iteration 10215 : loss : 0.065359, loss_ce: 0.010514
[01:12:15.283] iteration 10216 : loss : 0.116141, loss_ce: 0.011894
[01:12:15.586] iteration 10217 : loss : 0.061414, loss_ce: 0.023097
[01:12:15.888] iteration 10218 : loss : 0.045422, loss_ce: 0.011537
[01:12:16.193] iteration 10219 : loss : 0.045427, loss_ce: 0.013878
[01:12:16.495] iteration 10220 : loss : 0.054549, loss_ce: 0.022611
[01:12:16.812] iteration 10221 : loss : 0.053743, loss_ce: 0.018086
[01:12:17.116] iteration 10222 : loss : 0.054357, loss_ce: 0.017568
[01:12:17.421] iteration 10223 : loss : 0.050357, loss_ce: 0.016443
[01:12:17.722] iteration 10224 : loss : 0.054655, loss_ce: 0.018960
[01:12:18.024] iteration 10225 : loss : 0.164435, loss_ce: 0.011078
[01:12:18.328] iteration 10226 : loss : 0.096324, loss_ce: 0.016284
[01:12:18.632] iteration 10227 : loss : 0.064618, loss_ce: 0.029942
[01:12:18.931] iteration 10228 : loss : 0.104423, loss_ce: 0.012512
[01:12:19.235] iteration 10229 : loss : 0.063155, loss_ce: 0.016968
[01:12:19.536] iteration 10230 : loss : 0.057279, loss_ce: 0.013850
[01:12:19.841] iteration 10231 : loss : 0.059657, loss_ce: 0.015466
[01:12:20.143] iteration 10232 : loss : 0.055297, loss_ce: 0.012139
[01:12:20.445] iteration 10233 : loss : 0.071280, loss_ce: 0.015996
[01:12:20.752] iteration 10234 : loss : 0.048464, loss_ce: 0.011216
[01:12:21.058] iteration 10235 : loss : 0.106832, loss_ce: 0.013000
[01:12:21.361] iteration 10236 : loss : 0.050686, loss_ce: 0.009612
[01:12:21.664] iteration 10237 : loss : 0.049981, loss_ce: 0.012377
[01:12:21.964] iteration 10238 : loss : 0.052159, loss_ce: 0.007989
[01:12:22.270] iteration 10239 : loss : 0.103916, loss_ce: 0.011333
[01:12:22.583] iteration 10240 : loss : 0.064641, loss_ce: 0.021482
[01:12:22.903] iteration 10241 : loss : 0.063573, loss_ce: 0.020512
[01:12:23.211] iteration 10242 : loss : 0.060059, loss_ce: 0.024073
[01:12:23.522] iteration 10243 : loss : 0.047977, loss_ce: 0.010268
[01:12:23.831] iteration 10244 : loss : 0.053970, loss_ce: 0.014798
[01:12:24.137] iteration 10245 : loss : 0.112180, loss_ce: 0.019134
[01:12:24.441] iteration 10246 : loss : 0.053064, loss_ce: 0.021420
[01:12:24.745] iteration 10247 : loss : 0.044985, loss_ce: 0.012802
[01:12:25.049] iteration 10248 : loss : 0.052443, loss_ce: 0.009277
[01:12:25.349] iteration 10249 : loss : 0.073529, loss_ce: 0.011362
[01:12:25.658] iteration 10250 : loss : 0.053069, loss_ce: 0.021487
[01:12:25.964] iteration 10251 : loss : 0.055836, loss_ce: 0.010791
[01:12:26.265] iteration 10252 : loss : 0.055644, loss_ce: 0.020981
[01:12:26.571] iteration 10253 : loss : 0.053932, loss_ce: 0.025699
[01:12:26.874] iteration 10254 : loss : 0.115794, loss_ce: 0.021520
[01:12:27.178] iteration 10255 : loss : 0.054354, loss_ce: 0.020344
[01:12:27.484] iteration 10256 : loss : 0.058863, loss_ce: 0.017089
[01:12:27.788] iteration 10257 : loss : 0.104777, loss_ce: 0.016011
[01:12:28.093] iteration 10258 : loss : 0.124869, loss_ce: 0.010746
[01:12:28.400] iteration 10259 : loss : 0.055861, loss_ce: 0.018688
[01:12:28.703] iteration 10260 : loss : 0.064275, loss_ce: 0.016709
[01:12:29.021] iteration 10261 : loss : 0.060913, loss_ce: 0.017856
[01:12:29.322] iteration 10262 : loss : 0.054086, loss_ce: 0.020065
[01:12:29.621] iteration 10263 : loss : 0.071180, loss_ce: 0.024148
[01:12:29.925] iteration 10264 : loss : 0.061295, loss_ce: 0.016020
[01:12:30.226] iteration 10265 : loss : 0.062585, loss_ce: 0.022335
[01:12:30.531] iteration 10266 : loss : 0.060279, loss_ce: 0.020579
[01:12:30.833] iteration 10267 : loss : 0.056436, loss_ce: 0.012847
[01:12:31.136] iteration 10268 : loss : 0.050354, loss_ce: 0.012521
[01:12:31.439] iteration 10269 : loss : 0.074010, loss_ce: 0.013896
[01:12:31.745] iteration 10270 : loss : 0.106319, loss_ce: 0.015709
[01:12:32.053] iteration 10271 : loss : 0.048243, loss_ce: 0.015194
[01:12:32.361] iteration 10272 : loss : 0.231544, loss_ce: 0.007172
[01:12:32.669] iteration 10273 : loss : 0.048209, loss_ce: 0.013738
[01:12:32.974] iteration 10274 : loss : 0.117585, loss_ce: 0.015580
[01:12:33.281] iteration 10275 : loss : 0.055259, loss_ce: 0.008541
[01:12:33.589] iteration 10276 : loss : 0.059539, loss_ce: 0.015681
[01:12:33.897] iteration 10277 : loss : 0.129497, loss_ce: 0.017242
[01:12:34.209] iteration 10278 : loss : 0.155523, loss_ce: 0.007951
[01:12:34.538] iteration 10279 : loss : 0.119671, loss_ce: 0.007760
[01:12:34.838] iteration 10280 : loss : 0.064916, loss_ce: 0.021509
[01:12:35.166] iteration 10281 : loss : 0.073200, loss_ce: 0.017671
[01:12:35.472] iteration 10282 : loss : 0.056233, loss_ce: 0.014046
[01:12:35.775] iteration 10283 : loss : 0.060800, loss_ce: 0.014650
[01:12:36.076] iteration 10284 : loss : 0.113216, loss_ce: 0.009613
[01:12:36.378] iteration 10285 : loss : 0.074136, loss_ce: 0.017591
[01:12:36.455] iteration 10286 : loss : 0.100740, loss_ce: 0.020811
[01:12:54.733] iteration 10287 : loss : 0.057260, loss_ce: 0.025136
[01:12:55.033] iteration 10288 : loss : 0.110585, loss_ce: 0.014086
[01:12:55.339] iteration 10289 : loss : 0.126886, loss_ce: 0.021041
[01:12:55.644] iteration 10290 : loss : 0.065266, loss_ce: 0.022041
[01:12:55.950] iteration 10291 : loss : 0.063138, loss_ce: 0.022306
[01:12:56.255] iteration 10292 : loss : 0.114362, loss_ce: 0.007830
[01:12:56.561] iteration 10293 : loss : 0.098628, loss_ce: 0.014443
[01:12:56.866] iteration 10294 : loss : 0.038987, loss_ce: 0.011888
[01:12:57.176] iteration 10295 : loss : 0.065773, loss_ce: 0.027200
[01:12:57.486] iteration 10296 : loss : 0.092163, loss_ce: 0.016003
[01:12:57.796] iteration 10297 : loss : 0.050577, loss_ce: 0.018627
[01:12:58.110] iteration 10298 : loss : 0.063377, loss_ce: 0.024182
[01:12:58.420] iteration 10299 : loss : 0.061982, loss_ce: 0.016359
[01:12:58.725] iteration 10300 : loss : 0.043448, loss_ce: 0.014400
[01:12:59.054] iteration 10301 : loss : 0.106396, loss_ce: 0.015671
[01:12:59.360] iteration 10302 : loss : 0.062186, loss_ce: 0.017252
[01:12:59.669] iteration 10303 : loss : 0.047971, loss_ce: 0.018710
[01:12:59.974] iteration 10304 : loss : 0.148791, loss_ce: 0.004646
[01:13:00.285] iteration 10305 : loss : 0.107363, loss_ce: 0.029791
[01:13:00.594] iteration 10306 : loss : 0.116708, loss_ce: 0.009726
[01:13:00.901] iteration 10307 : loss : 0.056683, loss_ce: 0.019489
[01:13:01.202] iteration 10308 : loss : 0.117580, loss_ce: 0.017272
[01:13:01.507] iteration 10309 : loss : 0.093097, loss_ce: 0.015637
[01:13:01.812] iteration 10310 : loss : 0.054572, loss_ce: 0.013057
[01:13:02.117] iteration 10311 : loss : 0.107816, loss_ce: 0.011002
[01:13:02.419] iteration 10312 : loss : 0.054871, loss_ce: 0.017564
[01:13:02.728] iteration 10313 : loss : 0.061606, loss_ce: 0.027928
[01:13:03.037] iteration 10314 : loss : 0.041894, loss_ce: 0.014329
[01:13:03.342] iteration 10315 : loss : 0.138018, loss_ce: 0.007800
[01:13:03.643] iteration 10316 : loss : 0.062117, loss_ce: 0.019608
[01:13:03.945] iteration 10317 : loss : 0.055261, loss_ce: 0.024693
[01:13:04.249] iteration 10318 : loss : 0.054762, loss_ce: 0.011779
[01:13:04.555] iteration 10319 : loss : 0.059591, loss_ce: 0.017498
[01:13:04.862] iteration 10320 : loss : 0.170413, loss_ce: 0.012880
[01:13:05.181] iteration 10321 : loss : 0.039191, loss_ce: 0.014854
[01:13:05.484] iteration 10322 : loss : 0.058059, loss_ce: 0.018546
[01:13:05.792] iteration 10323 : loss : 0.049632, loss_ce: 0.010644
[01:13:06.096] iteration 10324 : loss : 0.098067, loss_ce: 0.010275
[01:13:06.397] iteration 10325 : loss : 0.132106, loss_ce: 0.009813
[01:13:06.705] iteration 10326 : loss : 0.162218, loss_ce: 0.013935
[01:13:07.012] iteration 10327 : loss : 0.056412, loss_ce: 0.013082
[01:13:07.316] iteration 10328 : loss : 0.067188, loss_ce: 0.020912
[01:13:07.621] iteration 10329 : loss : 0.061235, loss_ce: 0.011915
[01:13:07.928] iteration 10330 : loss : 0.058203, loss_ce: 0.019327
[01:13:08.235] iteration 10331 : loss : 0.064709, loss_ce: 0.017544
[01:13:08.542] iteration 10332 : loss : 0.060541, loss_ce: 0.016063
[01:13:08.847] iteration 10333 : loss : 0.057415, loss_ce: 0.007282
[01:13:09.154] iteration 10334 : loss : 0.045552, loss_ce: 0.011930
[01:13:09.459] iteration 10335 : loss : 0.056680, loss_ce: 0.017381
[01:13:09.765] iteration 10336 : loss : 0.106482, loss_ce: 0.006823
[01:13:10.064] iteration 10337 : loss : 0.059856, loss_ce: 0.018792
[01:13:10.371] iteration 10338 : loss : 0.112240, loss_ce: 0.012807
[01:13:10.679] iteration 10339 : loss : 0.112268, loss_ce: 0.012089
[01:13:10.987] iteration 10340 : loss : 0.052982, loss_ce: 0.015756
[01:13:11.307] iteration 10341 : loss : 0.119225, loss_ce: 0.016240
[01:13:11.612] iteration 10342 : loss : 0.048782, loss_ce: 0.014499
[01:13:11.917] iteration 10343 : loss : 0.114109, loss_ce: 0.011804
[01:13:12.224] iteration 10344 : loss : 0.056217, loss_ce: 0.016254
[01:13:12.531] iteration 10345 : loss : 0.056068, loss_ce: 0.010737
[01:13:12.847] iteration 10346 : loss : 0.055299, loss_ce: 0.020105
[01:13:13.155] iteration 10347 : loss : 0.064891, loss_ce: 0.025303
[01:13:13.467] iteration 10348 : loss : 0.054114, loss_ce: 0.015119
[01:13:13.778] iteration 10349 : loss : 0.072438, loss_ce: 0.020181
[01:13:14.092] iteration 10350 : loss : 0.056280, loss_ce: 0.017171
[01:13:14.399] iteration 10351 : loss : 0.058956, loss_ce: 0.019018
[01:13:14.705] iteration 10352 : loss : 0.076606, loss_ce: 0.013796
[01:13:15.011] iteration 10353 : loss : 0.089093, loss_ce: 0.030113
[01:13:15.311] iteration 10354 : loss : 0.065060, loss_ce: 0.009210
[01:13:15.620] iteration 10355 : loss : 0.055495, loss_ce: 0.018168
[01:13:15.928] iteration 10356 : loss : 0.051425, loss_ce: 0.014162
[01:13:16.235] iteration 10357 : loss : 0.108571, loss_ce: 0.015733
[01:13:16.542] iteration 10358 : loss : 0.064320, loss_ce: 0.027624
[01:13:16.846] iteration 10359 : loss : 0.057152, loss_ce: 0.012356
[01:13:17.154] iteration 10360 : loss : 0.220954, loss_ce: 0.003979
[01:13:17.477] iteration 10361 : loss : 0.061992, loss_ce: 0.010307
[01:13:17.781] iteration 10362 : loss : 0.068788, loss_ce: 0.014634
[01:13:18.087] iteration 10363 : loss : 0.051543, loss_ce: 0.012840
[01:13:18.390] iteration 10364 : loss : 0.046772, loss_ce: 0.014677
[01:13:18.698] iteration 10365 : loss : 0.064635, loss_ce: 0.025261
[01:13:19.004] iteration 10366 : loss : 0.041972, loss_ce: 0.007153
[01:13:19.310] iteration 10367 : loss : 0.050282, loss_ce: 0.017179
[01:13:19.618] iteration 10368 : loss : 0.111866, loss_ce: 0.013169
[01:13:19.923] iteration 10369 : loss : 0.064721, loss_ce: 0.017572
[01:13:20.229] iteration 10370 : loss : 0.060948, loss_ce: 0.025959
[01:13:20.532] iteration 10371 : loss : 0.053150, loss_ce: 0.021333
[01:13:20.840] iteration 10372 : loss : 0.044275, loss_ce: 0.009184
[01:13:21.142] iteration 10373 : loss : 0.055597, loss_ce: 0.019144
[01:13:21.449] iteration 10374 : loss : 0.063849, loss_ce: 0.027122
[01:13:21.754] iteration 10375 : loss : 0.056971, loss_ce: 0.027963
[01:13:22.055] iteration 10376 : loss : 0.044501, loss_ce: 0.010767
[01:13:22.360] iteration 10377 : loss : 0.108312, loss_ce: 0.012252
[01:13:22.662] iteration 10378 : loss : 0.114906, loss_ce: 0.007710
[01:13:22.966] iteration 10379 : loss : 0.045010, loss_ce: 0.013453
[01:13:23.270] iteration 10380 : loss : 0.049030, loss_ce: 0.011867
[01:13:23.590] iteration 10381 : loss : 0.059354, loss_ce: 0.020553
[01:13:23.896] iteration 10382 : loss : 0.063277, loss_ce: 0.013169
[01:13:24.200] iteration 10383 : loss : 0.054412, loss_ce: 0.007549
[01:13:24.506] iteration 10384 : loss : 0.056474, loss_ce: 0.016686
[01:13:24.808] iteration 10385 : loss : 0.037061, loss_ce: 0.017452
[01:13:25.114] iteration 10386 : loss : 0.052049, loss_ce: 0.020418
[01:13:25.417] iteration 10387 : loss : 0.048463, loss_ce: 0.013248
[01:13:25.719] iteration 10388 : loss : 0.058220, loss_ce: 0.018073
[01:13:26.024] iteration 10389 : loss : 0.042198, loss_ce: 0.008173
[01:13:26.331] iteration 10390 : loss : 0.086331, loss_ce: 0.015134
[01:13:26.637] iteration 10391 : loss : 0.045420, loss_ce: 0.006778
[01:13:26.943] iteration 10392 : loss : 0.059375, loss_ce: 0.012096
[01:13:27.248] iteration 10393 : loss : 0.121614, loss_ce: 0.013398
[01:13:27.560] iteration 10394 : loss : 0.078199, loss_ce: 0.023204
[01:13:27.865] iteration 10395 : loss : 0.058782, loss_ce: 0.019087
[01:13:28.171] iteration 10396 : loss : 0.046473, loss_ce: 0.018943
[01:13:28.480] iteration 10397 : loss : 0.050534, loss_ce: 0.021893
[01:13:28.783] iteration 10398 : loss : 0.051053, loss_ce: 0.013818
[01:13:29.088] iteration 10399 : loss : 0.065913, loss_ce: 0.022308
[01:13:29.395] iteration 10400 : loss : 0.048798, loss_ce: 0.017195
[01:13:29.715] iteration 10401 : loss : 0.047408, loss_ce: 0.020087
[01:13:30.024] iteration 10402 : loss : 0.072769, loss_ce: 0.014749
[01:13:30.333] iteration 10403 : loss : 0.118789, loss_ce: 0.023677
[01:13:30.643] iteration 10404 : loss : 0.107373, loss_ce: 0.015924
[01:13:30.951] iteration 10405 : loss : 0.048786, loss_ce: 0.014869
[01:13:31.264] iteration 10406 : loss : 0.031765, loss_ce: 0.006735
[01:13:31.572] iteration 10407 : loss : 0.059884, loss_ce: 0.019845
[01:13:31.887] iteration 10408 : loss : 0.061972, loss_ce: 0.006122
[01:13:32.202] iteration 10409 : loss : 0.058883, loss_ce: 0.022786
[01:13:32.518] iteration 10410 : loss : 0.056732, loss_ce: 0.017681
[01:13:32.828] iteration 10411 : loss : 0.099323, loss_ce: 0.029609
[01:13:33.137] iteration 10412 : loss : 0.108219, loss_ce: 0.010192
[01:13:33.450] iteration 10413 : loss : 0.112503, loss_ce: 0.017232
[01:13:33.760] iteration 10414 : loss : 0.110070, loss_ce: 0.018034
[01:13:34.067] iteration 10415 : loss : 0.106783, loss_ce: 0.016148
[01:13:34.379] iteration 10416 : loss : 0.161213, loss_ce: 0.022231
[01:13:34.695] iteration 10417 : loss : 0.047677, loss_ce: 0.010466
[01:13:35.005] iteration 10418 : loss : 0.158513, loss_ce: 0.010110
[01:13:35.319] iteration 10419 : loss : 0.164632, loss_ce: 0.013011
[01:13:35.635] iteration 10420 : loss : 0.045483, loss_ce: 0.008547
[01:13:35.976] iteration 10421 : loss : 0.068542, loss_ce: 0.008114
[01:13:36.293] iteration 10422 : loss : 0.107439, loss_ce: 0.011234
[01:13:36.604] iteration 10423 : loss : 0.053463, loss_ce: 0.022031
[01:13:36.918] iteration 10424 : loss : 0.047617, loss_ce: 0.024132
[01:13:36.999] iteration 10425 : loss : 0.287823, loss_ce: 0.018284
[01:13:57.055] iteration 10426 : loss : 0.058496, loss_ce: 0.014137
[01:13:57.356] iteration 10427 : loss : 0.053679, loss_ce: 0.017045
[01:13:57.655] iteration 10428 : loss : 0.045126, loss_ce: 0.015172
[01:13:57.955] iteration 10429 : loss : 0.043903, loss_ce: 0.009890
[01:13:58.256] iteration 10430 : loss : 0.053209, loss_ce: 0.022497
[01:13:58.557] iteration 10431 : loss : 0.062013, loss_ce: 0.017716
[01:13:58.859] iteration 10432 : loss : 0.101651, loss_ce: 0.013626
[01:13:59.164] iteration 10433 : loss : 0.123846, loss_ce: 0.012214
[01:13:59.463] iteration 10434 : loss : 0.062880, loss_ce: 0.018657
[01:13:59.763] iteration 10435 : loss : 0.108854, loss_ce: 0.014073
[01:14:00.066] iteration 10436 : loss : 0.104129, loss_ce: 0.007050
[01:14:00.370] iteration 10437 : loss : 0.048926, loss_ce: 0.012612
[01:14:00.671] iteration 10438 : loss : 0.048445, loss_ce: 0.023468
[01:14:00.975] iteration 10439 : loss : 0.067687, loss_ce: 0.008769
[01:14:01.278] iteration 10440 : loss : 0.039299, loss_ce: 0.009304
[01:14:01.594] iteration 10441 : loss : 0.051605, loss_ce: 0.021971
[01:14:01.890] iteration 10442 : loss : 0.047163, loss_ce: 0.014563
[01:14:02.193] iteration 10443 : loss : 0.087577, loss_ce: 0.015306
[01:14:02.503] iteration 10444 : loss : 0.042778, loss_ce: 0.010246
[01:14:02.811] iteration 10445 : loss : 0.156842, loss_ce: 0.008864
[01:14:03.119] iteration 10446 : loss : 0.058245, loss_ce: 0.023137
[01:14:03.431] iteration 10447 : loss : 0.049960, loss_ce: 0.020802
[01:14:03.740] iteration 10448 : loss : 0.070581, loss_ce: 0.027998
[01:14:04.049] iteration 10449 : loss : 0.060474, loss_ce: 0.023544
[01:14:04.355] iteration 10450 : loss : 0.080565, loss_ce: 0.020823
[01:14:04.660] iteration 10451 : loss : 0.050342, loss_ce: 0.016758
[01:14:04.961] iteration 10452 : loss : 0.056742, loss_ce: 0.015521
[01:14:05.262] iteration 10453 : loss : 0.059502, loss_ce: 0.010697
[01:14:05.564] iteration 10454 : loss : 0.060711, loss_ce: 0.014710
[01:14:05.867] iteration 10455 : loss : 0.055322, loss_ce: 0.012893
[01:14:06.172] iteration 10456 : loss : 0.053030, loss_ce: 0.015995
[01:14:06.477] iteration 10457 : loss : 0.077482, loss_ce: 0.011483
[01:14:06.780] iteration 10458 : loss : 0.113564, loss_ce: 0.021761
[01:14:07.083] iteration 10459 : loss : 0.049018, loss_ce: 0.015894
[01:14:07.387] iteration 10460 : loss : 0.129337, loss_ce: 0.010314
[01:14:07.706] iteration 10461 : loss : 0.049553, loss_ce: 0.026524
[01:14:08.013] iteration 10462 : loss : 0.056270, loss_ce: 0.021602
[01:14:08.316] iteration 10463 : loss : 0.038799, loss_ce: 0.009304
[01:14:08.620] iteration 10464 : loss : 0.049498, loss_ce: 0.026407
[01:14:08.925] iteration 10465 : loss : 0.067109, loss_ce: 0.013809
[01:14:09.229] iteration 10466 : loss : 0.047163, loss_ce: 0.007578
[01:14:09.530] iteration 10467 : loss : 0.083705, loss_ce: 0.018041
[01:14:09.833] iteration 10468 : loss : 0.051740, loss_ce: 0.011089
[01:14:10.138] iteration 10469 : loss : 0.104779, loss_ce: 0.008048
[01:14:10.440] iteration 10470 : loss : 0.056640, loss_ce: 0.016099
[01:14:10.745] iteration 10471 : loss : 0.108821, loss_ce: 0.010035
[01:14:11.047] iteration 10472 : loss : 0.052298, loss_ce: 0.018702
[01:14:11.349] iteration 10473 : loss : 0.047848, loss_ce: 0.010724
[01:14:11.650] iteration 10474 : loss : 0.104370, loss_ce: 0.012444
[01:14:11.953] iteration 10475 : loss : 0.044134, loss_ce: 0.018200
[01:14:12.257] iteration 10476 : loss : 0.120452, loss_ce: 0.017879
[01:14:12.561] iteration 10477 : loss : 0.046289, loss_ce: 0.015293
[01:14:12.862] iteration 10478 : loss : 0.058688, loss_ce: 0.021821
[01:14:13.169] iteration 10479 : loss : 0.056344, loss_ce: 0.015307
[01:14:13.472] iteration 10480 : loss : 0.054575, loss_ce: 0.016202
[01:14:13.798] iteration 10481 : loss : 0.050375, loss_ce: 0.017802
[01:14:14.098] iteration 10482 : loss : 0.050334, loss_ce: 0.015195
[01:14:14.404] iteration 10483 : loss : 0.052358, loss_ce: 0.021582
[01:14:14.707] iteration 10484 : loss : 0.069908, loss_ce: 0.010952
[01:14:15.008] iteration 10485 : loss : 0.061524, loss_ce: 0.018049
[01:14:15.311] iteration 10486 : loss : 0.106497, loss_ce: 0.010116
[01:14:15.614] iteration 10487 : loss : 0.058682, loss_ce: 0.023233
[01:14:15.919] iteration 10488 : loss : 0.062473, loss_ce: 0.023756
[01:14:16.224] iteration 10489 : loss : 0.041089, loss_ce: 0.011137
[01:14:16.527] iteration 10490 : loss : 0.224252, loss_ce: 0.004933
[01:14:16.832] iteration 10491 : loss : 0.039682, loss_ce: 0.019631
[01:14:17.137] iteration 10492 : loss : 0.049100, loss_ce: 0.017525
[01:14:17.446] iteration 10493 : loss : 0.108087, loss_ce: 0.018986
[01:14:17.760] iteration 10494 : loss : 0.103489, loss_ce: 0.009229
[01:14:18.066] iteration 10495 : loss : 0.045470, loss_ce: 0.019524
[01:14:18.379] iteration 10496 : loss : 0.103688, loss_ce: 0.015074
[01:14:18.692] iteration 10497 : loss : 0.045175, loss_ce: 0.012971
[01:14:19.001] iteration 10498 : loss : 0.050605, loss_ce: 0.017480
[01:14:19.311] iteration 10499 : loss : 0.114603, loss_ce: 0.006462
[01:14:19.617] iteration 10500 : loss : 0.051162, loss_ce: 0.017887
[01:14:19.937] iteration 10501 : loss : 0.073228, loss_ce: 0.018200
[01:14:20.240] iteration 10502 : loss : 0.232693, loss_ce: 0.012200
[01:14:20.547] iteration 10503 : loss : 0.066915, loss_ce: 0.015141
[01:14:20.850] iteration 10504 : loss : 0.109538, loss_ce: 0.014868
[01:14:21.156] iteration 10505 : loss : 0.051993, loss_ce: 0.011176
[01:14:21.460] iteration 10506 : loss : 0.057650, loss_ce: 0.018751
[01:14:21.765] iteration 10507 : loss : 0.049782, loss_ce: 0.017681
[01:14:22.071] iteration 10508 : loss : 0.043740, loss_ce: 0.012384
[01:14:22.375] iteration 10509 : loss : 0.116415, loss_ce: 0.011160
[01:14:22.677] iteration 10510 : loss : 0.062583, loss_ce: 0.026467
[01:14:22.981] iteration 10511 : loss : 0.085349, loss_ce: 0.019913
[01:14:23.286] iteration 10512 : loss : 0.038108, loss_ce: 0.015838
[01:14:23.592] iteration 10513 : loss : 0.059439, loss_ce: 0.019625
[01:14:23.899] iteration 10514 : loss : 0.130520, loss_ce: 0.017460
[01:14:24.202] iteration 10515 : loss : 0.197152, loss_ce: 0.008463
[01:14:24.510] iteration 10516 : loss : 0.061098, loss_ce: 0.014553
[01:14:24.811] iteration 10517 : loss : 0.049892, loss_ce: 0.018420
[01:14:25.114] iteration 10518 : loss : 0.062885, loss_ce: 0.017173
[01:14:25.415] iteration 10519 : loss : 0.077961, loss_ce: 0.015284
[01:14:25.722] iteration 10520 : loss : 0.106455, loss_ce: 0.009554
[01:14:26.040] iteration 10521 : loss : 0.049666, loss_ce: 0.010920
[01:14:26.342] iteration 10522 : loss : 0.049961, loss_ce: 0.014736
[01:14:26.649] iteration 10523 : loss : 0.063010, loss_ce: 0.014232
[01:14:26.952] iteration 10524 : loss : 0.064298, loss_ce: 0.012692
[01:14:27.257] iteration 10525 : loss : 0.109311, loss_ce: 0.013416
[01:14:27.560] iteration 10526 : loss : 0.073587, loss_ce: 0.007667
[01:14:27.865] iteration 10527 : loss : 0.118654, loss_ce: 0.013692
[01:14:28.171] iteration 10528 : loss : 0.112271, loss_ce: 0.006512
[01:14:28.475] iteration 10529 : loss : 0.063106, loss_ce: 0.029032
[01:14:28.778] iteration 10530 : loss : 0.065031, loss_ce: 0.022144
[01:14:29.081] iteration 10531 : loss : 0.236546, loss_ce: 0.007237
[01:14:29.380] iteration 10532 : loss : 0.060786, loss_ce: 0.027523
[01:14:29.686] iteration 10533 : loss : 0.058858, loss_ce: 0.015764
[01:14:29.990] iteration 10534 : loss : 0.167395, loss_ce: 0.013698
[01:14:30.292] iteration 10535 : loss : 0.067857, loss_ce: 0.020535
[01:14:30.596] iteration 10536 : loss : 0.057240, loss_ce: 0.025829
[01:14:30.901] iteration 10537 : loss : 0.064321, loss_ce: 0.019671
[01:14:31.210] iteration 10538 : loss : 0.067863, loss_ce: 0.022682
[01:14:31.513] iteration 10539 : loss : 0.108206, loss_ce: 0.010666
[01:14:31.818] iteration 10540 : loss : 0.061113, loss_ce: 0.010325
[01:14:32.141] iteration 10541 : loss : 0.062147, loss_ce: 0.022950
[01:14:32.446] iteration 10542 : loss : 0.046756, loss_ce: 0.011339
[01:14:32.750] iteration 10543 : loss : 0.063526, loss_ce: 0.013959
[01:14:33.056] iteration 10544 : loss : 0.103917, loss_ce: 0.011199
[01:14:33.364] iteration 10545 : loss : 0.056047, loss_ce: 0.016465
[01:14:33.668] iteration 10546 : loss : 0.059211, loss_ce: 0.018926
[01:14:33.976] iteration 10547 : loss : 0.120657, loss_ce: 0.016626
[01:14:34.288] iteration 10548 : loss : 0.049131, loss_ce: 0.015647
[01:14:34.596] iteration 10549 : loss : 0.057255, loss_ce: 0.016280
[01:14:34.909] iteration 10550 : loss : 0.061504, loss_ce: 0.015837
[01:14:35.221] iteration 10551 : loss : 0.054453, loss_ce: 0.007495
[01:14:35.538] iteration 10552 : loss : 0.222803, loss_ce: 0.008336
[01:14:35.846] iteration 10553 : loss : 0.121705, loss_ce: 0.008747
[01:14:36.159] iteration 10554 : loss : 0.057869, loss_ce: 0.020293
[01:14:36.475] iteration 10555 : loss : 0.050555, loss_ce: 0.022534
[01:14:36.789] iteration 10556 : loss : 0.054575, loss_ce: 0.023155
[01:14:37.104] iteration 10557 : loss : 0.046793, loss_ce: 0.016306
[01:14:37.415] iteration 10558 : loss : 0.087987, loss_ce: 0.028453
[01:14:37.724] iteration 10559 : loss : 0.057712, loss_ce: 0.016956
[01:14:38.032] iteration 10560 : loss : 0.051103, loss_ce: 0.013631
[01:14:38.368] iteration 10561 : loss : 0.065960, loss_ce: 0.011718
[01:14:38.678] iteration 10562 : loss : 0.048052, loss_ce: 0.013371
[01:14:38.988] iteration 10563 : loss : 0.128194, loss_ce: 0.018013
[01:14:39.070] iteration 10564 : loss : 0.284012, loss_ce: 0.013324
[01:14:39.614] save model to ./logs/swin_unet\epoch_75.pth
[01:14:57.210] iteration 10565 : loss : 0.058981, loss_ce: 0.016412
[01:14:57.509] iteration 10566 : loss : 0.052277, loss_ce: 0.018360
[01:14:57.811] iteration 10567 : loss : 0.061908, loss_ce: 0.011178
[01:14:58.114] iteration 10568 : loss : 0.072708, loss_ce: 0.014702
[01:14:58.416] iteration 10569 : loss : 0.055114, loss_ce: 0.021001
[01:14:58.726] iteration 10570 : loss : 0.046338, loss_ce: 0.015085
[01:14:59.028] iteration 10571 : loss : 0.048532, loss_ce: 0.014097
[01:14:59.331] iteration 10572 : loss : 0.043122, loss_ce: 0.009742
[01:14:59.630] iteration 10573 : loss : 0.053526, loss_ce: 0.018002
[01:14:59.931] iteration 10574 : loss : 0.053251, loss_ce: 0.020408
[01:15:00.237] iteration 10575 : loss : 0.223102, loss_ce: 0.007206
[01:15:00.540] iteration 10576 : loss : 0.047403, loss_ce: 0.018571
[01:15:00.843] iteration 10577 : loss : 0.046484, loss_ce: 0.017712
[01:15:01.145] iteration 10578 : loss : 0.059275, loss_ce: 0.021973
[01:15:01.448] iteration 10579 : loss : 0.072658, loss_ce: 0.015911
[01:15:01.750] iteration 10580 : loss : 0.062562, loss_ce: 0.018294
[01:15:02.068] iteration 10581 : loss : 0.046931, loss_ce: 0.016014
[01:15:02.370] iteration 10582 : loss : 0.113969, loss_ce: 0.011094
[01:15:02.675] iteration 10583 : loss : 0.056021, loss_ce: 0.011470
[01:15:02.977] iteration 10584 : loss : 0.091737, loss_ce: 0.015657
[01:15:03.280] iteration 10585 : loss : 0.053502, loss_ce: 0.020946
[01:15:03.582] iteration 10586 : loss : 0.048369, loss_ce: 0.011697
[01:15:03.887] iteration 10587 : loss : 0.084477, loss_ce: 0.018118
[01:15:04.190] iteration 10588 : loss : 0.064427, loss_ce: 0.023801
[01:15:04.494] iteration 10589 : loss : 0.052248, loss_ce: 0.016838
[01:15:04.797] iteration 10590 : loss : 0.053638, loss_ce: 0.019485
[01:15:05.099] iteration 10591 : loss : 0.046742, loss_ce: 0.015439
[01:15:05.401] iteration 10592 : loss : 0.072966, loss_ce: 0.017518
[01:15:05.702] iteration 10593 : loss : 0.053550, loss_ce: 0.012300
[01:15:06.005] iteration 10594 : loss : 0.051551, loss_ce: 0.009940
[01:15:06.308] iteration 10595 : loss : 0.062072, loss_ce: 0.012591
[01:15:06.612] iteration 10596 : loss : 0.039906, loss_ce: 0.014983
[01:15:06.915] iteration 10597 : loss : 0.052226, loss_ce: 0.019514
[01:15:07.221] iteration 10598 : loss : 0.105895, loss_ce: 0.013104
[01:15:07.526] iteration 10599 : loss : 0.064072, loss_ce: 0.020572
[01:15:07.837] iteration 10600 : loss : 0.051524, loss_ce: 0.016371
[01:15:08.155] iteration 10601 : loss : 0.110652, loss_ce: 0.011125
[01:15:08.464] iteration 10602 : loss : 0.052576, loss_ce: 0.022541
[01:15:08.774] iteration 10603 : loss : 0.040787, loss_ce: 0.010989
[01:15:09.087] iteration 10604 : loss : 0.060947, loss_ce: 0.030713
[01:15:09.391] iteration 10605 : loss : 0.048765, loss_ce: 0.017809
[01:15:09.697] iteration 10606 : loss : 0.041093, loss_ce: 0.019502
[01:15:10.002] iteration 10607 : loss : 0.058432, loss_ce: 0.021816
[01:15:10.307] iteration 10608 : loss : 0.061156, loss_ce: 0.018447
[01:15:10.612] iteration 10609 : loss : 0.058383, loss_ce: 0.013121
[01:15:10.917] iteration 10610 : loss : 0.048076, loss_ce: 0.013097
[01:15:11.224] iteration 10611 : loss : 0.049880, loss_ce: 0.018661
[01:15:11.527] iteration 10612 : loss : 0.121186, loss_ce: 0.006139
[01:15:11.829] iteration 10613 : loss : 0.045130, loss_ce: 0.014363
[01:15:12.133] iteration 10614 : loss : 0.069093, loss_ce: 0.020627
[01:15:12.439] iteration 10615 : loss : 0.047661, loss_ce: 0.012955
[01:15:12.742] iteration 10616 : loss : 0.051876, loss_ce: 0.025824
[01:15:13.045] iteration 10617 : loss : 0.058984, loss_ce: 0.019862
[01:15:13.352] iteration 10618 : loss : 0.058500, loss_ce: 0.016583
[01:15:13.658] iteration 10619 : loss : 0.109295, loss_ce: 0.008164
[01:15:13.962] iteration 10620 : loss : 0.107430, loss_ce: 0.015165
[01:15:14.285] iteration 10621 : loss : 0.055930, loss_ce: 0.017452
[01:15:14.586] iteration 10622 : loss : 0.046935, loss_ce: 0.013616
[01:15:14.891] iteration 10623 : loss : 0.062422, loss_ce: 0.013240
[01:15:15.196] iteration 10624 : loss : 0.046246, loss_ce: 0.007786
[01:15:15.497] iteration 10625 : loss : 0.049049, loss_ce: 0.013006
[01:15:15.799] iteration 10626 : loss : 0.101342, loss_ce: 0.015293
[01:15:16.102] iteration 10627 : loss : 0.112300, loss_ce: 0.014691
[01:15:16.406] iteration 10628 : loss : 0.048191, loss_ce: 0.008846
[01:15:16.711] iteration 10629 : loss : 0.112557, loss_ce: 0.010561
[01:15:17.011] iteration 10630 : loss : 0.063751, loss_ce: 0.013820
[01:15:17.315] iteration 10631 : loss : 0.063377, loss_ce: 0.023863
[01:15:17.620] iteration 10632 : loss : 0.102967, loss_ce: 0.008806
[01:15:17.921] iteration 10633 : loss : 0.034684, loss_ce: 0.005444
[01:15:18.223] iteration 10634 : loss : 0.052139, loss_ce: 0.011453
[01:15:18.524] iteration 10635 : loss : 0.111134, loss_ce: 0.006880
[01:15:18.830] iteration 10636 : loss : 0.045893, loss_ce: 0.006144
[01:15:19.133] iteration 10637 : loss : 0.044507, loss_ce: 0.007332
[01:15:19.437] iteration 10638 : loss : 0.115250, loss_ce: 0.013694
[01:15:19.743] iteration 10639 : loss : 0.055665, loss_ce: 0.019070
[01:15:20.049] iteration 10640 : loss : 0.057377, loss_ce: 0.016532
[01:15:20.365] iteration 10641 : loss : 0.047808, loss_ce: 0.012746
[01:15:20.669] iteration 10642 : loss : 0.105344, loss_ce: 0.011207
[01:15:20.974] iteration 10643 : loss : 0.103567, loss_ce: 0.008626
[01:15:21.280] iteration 10644 : loss : 0.056270, loss_ce: 0.012854
[01:15:21.583] iteration 10645 : loss : 0.065905, loss_ce: 0.013423
[01:15:21.889] iteration 10646 : loss : 0.062717, loss_ce: 0.028058
[01:15:22.191] iteration 10647 : loss : 0.041905, loss_ce: 0.011025
[01:15:22.505] iteration 10648 : loss : 0.057060, loss_ce: 0.011779
[01:15:22.809] iteration 10649 : loss : 0.048268, loss_ce: 0.008102
[01:15:23.110] iteration 10650 : loss : 0.054469, loss_ce: 0.020728
[01:15:23.417] iteration 10651 : loss : 0.059518, loss_ce: 0.010172
[01:15:23.725] iteration 10652 : loss : 0.105054, loss_ce: 0.011442
[01:15:24.029] iteration 10653 : loss : 0.060564, loss_ce: 0.025210
[01:15:24.336] iteration 10654 : loss : 0.042563, loss_ce: 0.016638
[01:15:24.641] iteration 10655 : loss : 0.136839, loss_ce: 0.008633
[01:15:24.944] iteration 10656 : loss : 0.070388, loss_ce: 0.024081
[01:15:25.256] iteration 10657 : loss : 0.059829, loss_ce: 0.016547
[01:15:25.561] iteration 10658 : loss : 0.044988, loss_ce: 0.026380
[01:15:25.870] iteration 10659 : loss : 0.060484, loss_ce: 0.012902
[01:15:26.179] iteration 10660 : loss : 0.042496, loss_ce: 0.007905
[01:15:26.508] iteration 10661 : loss : 0.046716, loss_ce: 0.019303
[01:15:26.816] iteration 10662 : loss : 0.053241, loss_ce: 0.019431
[01:15:27.124] iteration 10663 : loss : 0.102240, loss_ce: 0.016314
[01:15:27.434] iteration 10664 : loss : 0.053158, loss_ce: 0.024337
[01:15:27.741] iteration 10665 : loss : 0.055045, loss_ce: 0.011576
[01:15:28.046] iteration 10666 : loss : 0.061065, loss_ce: 0.021964
[01:15:28.354] iteration 10667 : loss : 0.044296, loss_ce: 0.009185
[01:15:28.663] iteration 10668 : loss : 0.050660, loss_ce: 0.013288
[01:15:28.974] iteration 10669 : loss : 0.114451, loss_ce: 0.014324
[01:15:29.281] iteration 10670 : loss : 0.116077, loss_ce: 0.018359
[01:15:29.592] iteration 10671 : loss : 0.108623, loss_ce: 0.012764
[01:15:29.900] iteration 10672 : loss : 0.047416, loss_ce: 0.019522
[01:15:30.209] iteration 10673 : loss : 0.049916, loss_ce: 0.015724
[01:15:30.515] iteration 10674 : loss : 0.076840, loss_ce: 0.013922
[01:15:30.823] iteration 10675 : loss : 0.080957, loss_ce: 0.007702
[01:15:31.131] iteration 10676 : loss : 0.056938, loss_ce: 0.015046
[01:15:31.439] iteration 10677 : loss : 0.047842, loss_ce: 0.015285
[01:15:31.752] iteration 10678 : loss : 0.062206, loss_ce: 0.017917
[01:15:32.061] iteration 10679 : loss : 0.228228, loss_ce: 0.004043
[01:15:32.372] iteration 10680 : loss : 0.051160, loss_ce: 0.014540
[01:15:32.697] iteration 10681 : loss : 0.054569, loss_ce: 0.019411
[01:15:33.003] iteration 10682 : loss : 0.065650, loss_ce: 0.023020
[01:15:33.316] iteration 10683 : loss : 0.047495, loss_ce: 0.018761
[01:15:33.628] iteration 10684 : loss : 0.062263, loss_ce: 0.019591
[01:15:33.935] iteration 10685 : loss : 0.053033, loss_ce: 0.025826
[01:15:34.246] iteration 10686 : loss : 0.067898, loss_ce: 0.009386
[01:15:34.557] iteration 10687 : loss : 0.163921, loss_ce: 0.013138
[01:15:34.869] iteration 10688 : loss : 0.061576, loss_ce: 0.011491
[01:15:35.192] iteration 10689 : loss : 0.047912, loss_ce: 0.013185
[01:15:35.503] iteration 10690 : loss : 0.055113, loss_ce: 0.016955
[01:15:35.816] iteration 10691 : loss : 0.042803, loss_ce: 0.017050
[01:15:36.130] iteration 10692 : loss : 0.048958, loss_ce: 0.013227
[01:15:36.444] iteration 10693 : loss : 0.109791, loss_ce: 0.007556
[01:15:36.752] iteration 10694 : loss : 0.053559, loss_ce: 0.014130
[01:15:37.067] iteration 10695 : loss : 0.038621, loss_ce: 0.009293
[01:15:37.379] iteration 10696 : loss : 0.107973, loss_ce: 0.020570
[01:15:37.694] iteration 10697 : loss : 0.073317, loss_ce: 0.020996
[01:15:38.005] iteration 10698 : loss : 0.061339, loss_ce: 0.023470
[01:15:38.321] iteration 10699 : loss : 0.057936, loss_ce: 0.012374
[01:15:38.631] iteration 10700 : loss : 0.115270, loss_ce: 0.024992
[01:15:38.970] iteration 10701 : loss : 0.056381, loss_ce: 0.015126
[01:15:39.283] iteration 10702 : loss : 0.121304, loss_ce: 0.012644
[01:15:39.371] iteration 10703 : loss : 0.174708, loss_ce: 0.017990
[01:15:57.400] iteration 10704 : loss : 0.057094, loss_ce: 0.014271
[01:15:57.706] iteration 10705 : loss : 0.043978, loss_ce: 0.013914
[01:15:58.014] iteration 10706 : loss : 0.103918, loss_ce: 0.019371
[01:15:58.320] iteration 10707 : loss : 0.048963, loss_ce: 0.016171
[01:15:58.627] iteration 10708 : loss : 0.104666, loss_ce: 0.011500
[01:15:58.937] iteration 10709 : loss : 0.059046, loss_ce: 0.010887
[01:15:59.244] iteration 10710 : loss : 0.048839, loss_ce: 0.013095
[01:15:59.543] iteration 10711 : loss : 0.048101, loss_ce: 0.014302
[01:15:59.844] iteration 10712 : loss : 0.056584, loss_ce: 0.012278
[01:16:00.149] iteration 10713 : loss : 0.047326, loss_ce: 0.018971
[01:16:00.454] iteration 10714 : loss : 0.057742, loss_ce: 0.023773
[01:16:00.754] iteration 10715 : loss : 0.043608, loss_ce: 0.015290
[01:16:01.056] iteration 10716 : loss : 0.073705, loss_ce: 0.013590
[01:16:01.359] iteration 10717 : loss : 0.079172, loss_ce: 0.007400
[01:16:01.661] iteration 10718 : loss : 0.065473, loss_ce: 0.021204
[01:16:01.965] iteration 10719 : loss : 0.060689, loss_ce: 0.018849
[01:16:02.266] iteration 10720 : loss : 0.054537, loss_ce: 0.007549
[01:16:02.582] iteration 10721 : loss : 0.074879, loss_ce: 0.012109
[01:16:02.885] iteration 10722 : loss : 0.050703, loss_ce: 0.017099
[01:16:03.186] iteration 10723 : loss : 0.051131, loss_ce: 0.015580
[01:16:03.489] iteration 10724 : loss : 0.050318, loss_ce: 0.013732
[01:16:03.792] iteration 10725 : loss : 0.048892, loss_ce: 0.014228
[01:16:04.095] iteration 10726 : loss : 0.054089, loss_ce: 0.025441
[01:16:04.399] iteration 10727 : loss : 0.058353, loss_ce: 0.024685
[01:16:04.702] iteration 10728 : loss : 0.090642, loss_ce: 0.021737
[01:16:05.006] iteration 10729 : loss : 0.097136, loss_ce: 0.005945
[01:16:05.310] iteration 10730 : loss : 0.054985, loss_ce: 0.024205
[01:16:05.613] iteration 10731 : loss : 0.114236, loss_ce: 0.021060
[01:16:05.915] iteration 10732 : loss : 0.101918, loss_ce: 0.016902
[01:16:06.217] iteration 10733 : loss : 0.058564, loss_ce: 0.011451
[01:16:06.522] iteration 10734 : loss : 0.050394, loss_ce: 0.013122
[01:16:06.825] iteration 10735 : loss : 0.045097, loss_ce: 0.016779
[01:16:07.129] iteration 10736 : loss : 0.054596, loss_ce: 0.017852
[01:16:07.433] iteration 10737 : loss : 0.107560, loss_ce: 0.011059
[01:16:07.735] iteration 10738 : loss : 0.056092, loss_ce: 0.017227
[01:16:08.039] iteration 10739 : loss : 0.041111, loss_ce: 0.009032
[01:16:08.344] iteration 10740 : loss : 0.109217, loss_ce: 0.006833
[01:16:08.666] iteration 10741 : loss : 0.052112, loss_ce: 0.008798
[01:16:08.970] iteration 10742 : loss : 0.107178, loss_ce: 0.013890
[01:16:09.272] iteration 10743 : loss : 0.067275, loss_ce: 0.010463
[01:16:09.576] iteration 10744 : loss : 0.060006, loss_ce: 0.015634
[01:16:09.881] iteration 10745 : loss : 0.043508, loss_ce: 0.015506
[01:16:10.183] iteration 10746 : loss : 0.177102, loss_ce: 0.006993
[01:16:10.485] iteration 10747 : loss : 0.061174, loss_ce: 0.019527
[01:16:10.787] iteration 10748 : loss : 0.049824, loss_ce: 0.016194
[01:16:11.093] iteration 10749 : loss : 0.052357, loss_ce: 0.020611
[01:16:11.396] iteration 10750 : loss : 0.056389, loss_ce: 0.019480
[01:16:11.700] iteration 10751 : loss : 0.054930, loss_ce: 0.017889
[01:16:12.003] iteration 10752 : loss : 0.105613, loss_ce: 0.011221
[01:16:12.310] iteration 10753 : loss : 0.109697, loss_ce: 0.013845
[01:16:12.622] iteration 10754 : loss : 0.044484, loss_ce: 0.021391
[01:16:12.937] iteration 10755 : loss : 0.077661, loss_ce: 0.009669
[01:16:13.246] iteration 10756 : loss : 0.049097, loss_ce: 0.025839
[01:16:13.554] iteration 10757 : loss : 0.058063, loss_ce: 0.014736
[01:16:13.866] iteration 10758 : loss : 0.047129, loss_ce: 0.014174
[01:16:14.176] iteration 10759 : loss : 0.051636, loss_ce: 0.024355
[01:16:14.478] iteration 10760 : loss : 0.105087, loss_ce: 0.009388
[01:16:14.792] iteration 10761 : loss : 0.050997, loss_ce: 0.018035
[01:16:15.096] iteration 10762 : loss : 0.046886, loss_ce: 0.011046
[01:16:15.404] iteration 10763 : loss : 0.055376, loss_ce: 0.014662
[01:16:15.706] iteration 10764 : loss : 0.050204, loss_ce: 0.014951
[01:16:16.011] iteration 10765 : loss : 0.066350, loss_ce: 0.013318
[01:16:16.314] iteration 10766 : loss : 0.057536, loss_ce: 0.019043
[01:16:16.618] iteration 10767 : loss : 0.111575, loss_ce: 0.009720
[01:16:16.919] iteration 10768 : loss : 0.217201, loss_ce: 0.001939
[01:16:17.224] iteration 10769 : loss : 0.067426, loss_ce: 0.019689
[01:16:17.527] iteration 10770 : loss : 0.044708, loss_ce: 0.015851
[01:16:17.830] iteration 10771 : loss : 0.085464, loss_ce: 0.016941
[01:16:18.133] iteration 10772 : loss : 0.043968, loss_ce: 0.014829
[01:16:18.437] iteration 10773 : loss : 0.119798, loss_ce: 0.008612
[01:16:18.742] iteration 10774 : loss : 0.061371, loss_ce: 0.020664
[01:16:19.044] iteration 10775 : loss : 0.060674, loss_ce: 0.027612
[01:16:19.347] iteration 10776 : loss : 0.053525, loss_ce: 0.010243
[01:16:19.648] iteration 10777 : loss : 0.109131, loss_ce: 0.011160
[01:16:19.951] iteration 10778 : loss : 0.069751, loss_ce: 0.016968
[01:16:20.254] iteration 10779 : loss : 0.113122, loss_ce: 0.017134
[01:16:20.562] iteration 10780 : loss : 0.047421, loss_ce: 0.019574
[01:16:20.879] iteration 10781 : loss : 0.056929, loss_ce: 0.015687
[01:16:21.184] iteration 10782 : loss : 0.043434, loss_ce: 0.013578
[01:16:21.486] iteration 10783 : loss : 0.051609, loss_ce: 0.021500
[01:16:21.791] iteration 10784 : loss : 0.046760, loss_ce: 0.017722
[01:16:22.095] iteration 10785 : loss : 0.106506, loss_ce: 0.015034
[01:16:22.399] iteration 10786 : loss : 0.055565, loss_ce: 0.015499
[01:16:22.706] iteration 10787 : loss : 0.047115, loss_ce: 0.010692
[01:16:23.009] iteration 10788 : loss : 0.104456, loss_ce: 0.008496
[01:16:23.308] iteration 10789 : loss : 0.048008, loss_ce: 0.012641
[01:16:23.611] iteration 10790 : loss : 0.042722, loss_ce: 0.013796
[01:16:23.915] iteration 10791 : loss : 0.045703, loss_ce: 0.016087
[01:16:24.218] iteration 10792 : loss : 0.050160, loss_ce: 0.009728
[01:16:24.520] iteration 10793 : loss : 0.062771, loss_ce: 0.018705
[01:16:24.826] iteration 10794 : loss : 0.062899, loss_ce: 0.020766
[01:16:25.129] iteration 10795 : loss : 0.155677, loss_ce: 0.004804
[01:16:25.430] iteration 10796 : loss : 0.065602, loss_ce: 0.012826
[01:16:25.735] iteration 10797 : loss : 0.052356, loss_ce: 0.018547
[01:16:26.040] iteration 10798 : loss : 0.112935, loss_ce: 0.014731
[01:16:26.344] iteration 10799 : loss : 0.141578, loss_ce: 0.019101
[01:16:26.648] iteration 10800 : loss : 0.063866, loss_ce: 0.017527
[01:16:26.968] iteration 10801 : loss : 0.115311, loss_ce: 0.006953
[01:16:27.272] iteration 10802 : loss : 0.157501, loss_ce: 0.010272
[01:16:27.581] iteration 10803 : loss : 0.053566, loss_ce: 0.015591
[01:16:27.893] iteration 10804 : loss : 0.058655, loss_ce: 0.012334
[01:16:28.205] iteration 10805 : loss : 0.055028, loss_ce: 0.015261
[01:16:28.514] iteration 10806 : loss : 0.112233, loss_ce: 0.004182
[01:16:28.827] iteration 10807 : loss : 0.058843, loss_ce: 0.023848
[01:16:29.138] iteration 10808 : loss : 0.053076, loss_ce: 0.007472
[01:16:29.442] iteration 10809 : loss : 0.055121, loss_ce: 0.012918
[01:16:29.747] iteration 10810 : loss : 0.074126, loss_ce: 0.011704
[01:16:30.049] iteration 10811 : loss : 0.058339, loss_ce: 0.013958
[01:16:30.350] iteration 10812 : loss : 0.061664, loss_ce: 0.008486
[01:16:30.655] iteration 10813 : loss : 0.052788, loss_ce: 0.017068
[01:16:30.960] iteration 10814 : loss : 0.055459, loss_ce: 0.019394
[01:16:31.265] iteration 10815 : loss : 0.052347, loss_ce: 0.018438
[01:16:31.569] iteration 10816 : loss : 0.053403, loss_ce: 0.017606
[01:16:31.876] iteration 10817 : loss : 0.052828, loss_ce: 0.020596
[01:16:32.180] iteration 10818 : loss : 0.053710, loss_ce: 0.007756
[01:16:32.483] iteration 10819 : loss : 0.067224, loss_ce: 0.031263
[01:16:32.785] iteration 10820 : loss : 0.056929, loss_ce: 0.018336
[01:16:33.105] iteration 10821 : loss : 0.125646, loss_ce: 0.009983
[01:16:33.407] iteration 10822 : loss : 0.044471, loss_ce: 0.013559
[01:16:33.707] iteration 10823 : loss : 0.039606, loss_ce: 0.012670
[01:16:34.010] iteration 10824 : loss : 0.106180, loss_ce: 0.013299
[01:16:34.317] iteration 10825 : loss : 0.083888, loss_ce: 0.014749
[01:16:34.625] iteration 10826 : loss : 0.060895, loss_ce: 0.010162
[01:16:34.933] iteration 10827 : loss : 0.117384, loss_ce: 0.015205
[01:16:35.244] iteration 10828 : loss : 0.056298, loss_ce: 0.016743
[01:16:35.556] iteration 10829 : loss : 0.064042, loss_ce: 0.021749
[01:16:35.861] iteration 10830 : loss : 0.042071, loss_ce: 0.014782
[01:16:36.170] iteration 10831 : loss : 0.063575, loss_ce: 0.025461
[01:16:36.478] iteration 10832 : loss : 0.054846, loss_ce: 0.028717
[01:16:36.789] iteration 10833 : loss : 0.111582, loss_ce: 0.011429
[01:16:37.097] iteration 10834 : loss : 0.072411, loss_ce: 0.025779
[01:16:37.408] iteration 10835 : loss : 0.060472, loss_ce: 0.022563
[01:16:37.719] iteration 10836 : loss : 0.059370, loss_ce: 0.024190
[01:16:38.029] iteration 10837 : loss : 0.066074, loss_ce: 0.017017
[01:16:38.332] iteration 10838 : loss : 0.065270, loss_ce: 0.018076
[01:16:38.638] iteration 10839 : loss : 0.059428, loss_ce: 0.023938
[01:16:38.948] iteration 10840 : loss : 0.051808, loss_ce: 0.015856
[01:16:39.288] iteration 10841 : loss : 0.051425, loss_ce: 0.011708
[01:16:39.367] iteration 10842 : loss : 0.244969, loss_ce: 0.000055
[01:16:57.090] iteration 10843 : loss : 0.098083, loss_ce: 0.017559
[01:16:57.394] iteration 10844 : loss : 0.101042, loss_ce: 0.015567
[01:16:57.695] iteration 10845 : loss : 0.066299, loss_ce: 0.019344
[01:16:58.000] iteration 10846 : loss : 0.112798, loss_ce: 0.014487
[01:16:58.309] iteration 10847 : loss : 0.111234, loss_ce: 0.014893
[01:16:58.615] iteration 10848 : loss : 0.056926, loss_ce: 0.019618
[01:16:58.920] iteration 10849 : loss : 0.059748, loss_ce: 0.017676
[01:16:59.225] iteration 10850 : loss : 0.053580, loss_ce: 0.022438
[01:16:59.531] iteration 10851 : loss : 0.042614, loss_ce: 0.022444
[01:16:59.838] iteration 10852 : loss : 0.064797, loss_ce: 0.029290
[01:17:00.149] iteration 10853 : loss : 0.069975, loss_ce: 0.025682
[01:17:00.461] iteration 10854 : loss : 0.057759, loss_ce: 0.018378
[01:17:00.776] iteration 10855 : loss : 0.172788, loss_ce: 0.014231
[01:17:01.081] iteration 10856 : loss : 0.112350, loss_ce: 0.014745
[01:17:01.392] iteration 10857 : loss : 0.074540, loss_ce: 0.017878
[01:17:01.701] iteration 10858 : loss : 0.058495, loss_ce: 0.024745
[01:17:02.010] iteration 10859 : loss : 0.062362, loss_ce: 0.024170
[01:17:02.320] iteration 10860 : loss : 0.045817, loss_ce: 0.009125
[01:17:02.644] iteration 10861 : loss : 0.047601, loss_ce: 0.018092
[01:17:02.953] iteration 10862 : loss : 0.101147, loss_ce: 0.012304
[01:17:03.260] iteration 10863 : loss : 0.067500, loss_ce: 0.015331
[01:17:03.575] iteration 10864 : loss : 0.105217, loss_ce: 0.008183
[01:17:03.880] iteration 10865 : loss : 0.051338, loss_ce: 0.014835
[01:17:04.189] iteration 10866 : loss : 0.042136, loss_ce: 0.008314
[01:17:04.496] iteration 10867 : loss : 0.064760, loss_ce: 0.011804
[01:17:04.798] iteration 10868 : loss : 0.137087, loss_ce: 0.011923
[01:17:05.105] iteration 10869 : loss : 0.041286, loss_ce: 0.012975
[01:17:05.408] iteration 10870 : loss : 0.070052, loss_ce: 0.012289
[01:17:05.716] iteration 10871 : loss : 0.052974, loss_ce: 0.011755
[01:17:06.020] iteration 10872 : loss : 0.064963, loss_ce: 0.013025
[01:17:06.327] iteration 10873 : loss : 0.046930, loss_ce: 0.008205
[01:17:06.631] iteration 10874 : loss : 0.149626, loss_ce: 0.014934
[01:17:06.937] iteration 10875 : loss : 0.064043, loss_ce: 0.019772
[01:17:07.244] iteration 10876 : loss : 0.063448, loss_ce: 0.023045
[01:17:07.549] iteration 10877 : loss : 0.056850, loss_ce: 0.031471
[01:17:07.855] iteration 10878 : loss : 0.059217, loss_ce: 0.023887
[01:17:08.158] iteration 10879 : loss : 0.064275, loss_ce: 0.025251
[01:17:08.460] iteration 10880 : loss : 0.043631, loss_ce: 0.016676
[01:17:08.786] iteration 10881 : loss : 0.055080, loss_ce: 0.009175
[01:17:09.092] iteration 10882 : loss : 0.072742, loss_ce: 0.026484
[01:17:09.400] iteration 10883 : loss : 0.062134, loss_ce: 0.021696
[01:17:09.706] iteration 10884 : loss : 0.118843, loss_ce: 0.014885
[01:17:10.013] iteration 10885 : loss : 0.047843, loss_ce: 0.015556
[01:17:10.315] iteration 10886 : loss : 0.056315, loss_ce: 0.020486
[01:17:10.619] iteration 10887 : loss : 0.294116, loss_ce: 0.004691
[01:17:10.923] iteration 10888 : loss : 0.048052, loss_ce: 0.024599
[01:17:11.231] iteration 10889 : loss : 0.063234, loss_ce: 0.012211
[01:17:11.534] iteration 10890 : loss : 0.054453, loss_ce: 0.015091
[01:17:11.841] iteration 10891 : loss : 0.066879, loss_ce: 0.010124
[01:17:12.149] iteration 10892 : loss : 0.063950, loss_ce: 0.013269
[01:17:12.456] iteration 10893 : loss : 0.050024, loss_ce: 0.014080
[01:17:12.762] iteration 10894 : loss : 0.056970, loss_ce: 0.021973
[01:17:13.070] iteration 10895 : loss : 0.103544, loss_ce: 0.010792
[01:17:13.374] iteration 10896 : loss : 0.061221, loss_ce: 0.018975
[01:17:13.682] iteration 10897 : loss : 0.113549, loss_ce: 0.005980
[01:17:13.990] iteration 10898 : loss : 0.047428, loss_ce: 0.014130
[01:17:14.298] iteration 10899 : loss : 0.067068, loss_ce: 0.028587
[01:17:14.604] iteration 10900 : loss : 0.054368, loss_ce: 0.017649
[01:17:14.923] iteration 10901 : loss : 0.105622, loss_ce: 0.012356
[01:17:15.230] iteration 10902 : loss : 0.121279, loss_ce: 0.024264
[01:17:15.539] iteration 10903 : loss : 0.045525, loss_ce: 0.021169
[01:17:15.844] iteration 10904 : loss : 0.071569, loss_ce: 0.009893
[01:17:16.154] iteration 10905 : loss : 0.047118, loss_ce: 0.017536
[01:17:16.461] iteration 10906 : loss : 0.048139, loss_ce: 0.016709
[01:17:16.765] iteration 10907 : loss : 0.083811, loss_ce: 0.012555
[01:17:17.068] iteration 10908 : loss : 0.054221, loss_ce: 0.017901
[01:17:17.383] iteration 10909 : loss : 0.043177, loss_ce: 0.014873
[01:17:17.691] iteration 10910 : loss : 0.061481, loss_ce: 0.020875
[01:17:18.002] iteration 10911 : loss : 0.163593, loss_ce: 0.008611
[01:17:18.314] iteration 10912 : loss : 0.060382, loss_ce: 0.022793
[01:17:18.629] iteration 10913 : loss : 0.052128, loss_ce: 0.021127
[01:17:18.939] iteration 10914 : loss : 0.053782, loss_ce: 0.016227
[01:17:19.248] iteration 10915 : loss : 0.044199, loss_ce: 0.013319
[01:17:19.551] iteration 10916 : loss : 0.050739, loss_ce: 0.017413
[01:17:19.865] iteration 10917 : loss : 0.052681, loss_ce: 0.022418
[01:17:20.169] iteration 10918 : loss : 0.057541, loss_ce: 0.022404
[01:17:20.471] iteration 10919 : loss : 0.106860, loss_ce: 0.014188
[01:17:20.778] iteration 10920 : loss : 0.049222, loss_ce: 0.014792
[01:17:21.097] iteration 10921 : loss : 0.106390, loss_ce: 0.017546
[01:17:21.400] iteration 10922 : loss : 0.053888, loss_ce: 0.021202
[01:17:21.703] iteration 10923 : loss : 0.052006, loss_ce: 0.012368
[01:17:22.009] iteration 10924 : loss : 0.056108, loss_ce: 0.016889
[01:17:22.309] iteration 10925 : loss : 0.164247, loss_ce: 0.003437
[01:17:22.611] iteration 10926 : loss : 0.112394, loss_ce: 0.014789
[01:17:22.915] iteration 10927 : loss : 0.117473, loss_ce: 0.006369
[01:17:23.220] iteration 10928 : loss : 0.063770, loss_ce: 0.018528
[01:17:23.524] iteration 10929 : loss : 0.055121, loss_ce: 0.014030
[01:17:23.830] iteration 10930 : loss : 0.053094, loss_ce: 0.008814
[01:17:24.132] iteration 10931 : loss : 0.047120, loss_ce: 0.022758
[01:17:24.438] iteration 10932 : loss : 0.107646, loss_ce: 0.014658
[01:17:24.740] iteration 10933 : loss : 0.046652, loss_ce: 0.016113
[01:17:25.046] iteration 10934 : loss : 0.061075, loss_ce: 0.016738
[01:17:25.350] iteration 10935 : loss : 0.071191, loss_ce: 0.012449
[01:17:25.653] iteration 10936 : loss : 0.054828, loss_ce: 0.013523
[01:17:25.959] iteration 10937 : loss : 0.056747, loss_ce: 0.011036
[01:17:26.262] iteration 10938 : loss : 0.045023, loss_ce: 0.009316
[01:17:26.566] iteration 10939 : loss : 0.107390, loss_ce: 0.015899
[01:17:26.870] iteration 10940 : loss : 0.072492, loss_ce: 0.010293
[01:17:27.185] iteration 10941 : loss : 0.043739, loss_ce: 0.011563
[01:17:27.489] iteration 10942 : loss : 0.055410, loss_ce: 0.016089
[01:17:27.792] iteration 10943 : loss : 0.062038, loss_ce: 0.010651
[01:17:28.096] iteration 10944 : loss : 0.044636, loss_ce: 0.007872
[01:17:28.404] iteration 10945 : loss : 0.044392, loss_ce: 0.011899
[01:17:28.708] iteration 10946 : loss : 0.111693, loss_ce: 0.005547
[01:17:29.009] iteration 10947 : loss : 0.070207, loss_ce: 0.014680
[01:17:29.318] iteration 10948 : loss : 0.075359, loss_ce: 0.026304
[01:17:29.623] iteration 10949 : loss : 0.053088, loss_ce: 0.022634
[01:17:29.925] iteration 10950 : loss : 0.064972, loss_ce: 0.013169
[01:17:30.228] iteration 10951 : loss : 0.056938, loss_ce: 0.028532
[01:17:30.537] iteration 10952 : loss : 0.054013, loss_ce: 0.012944
[01:17:30.839] iteration 10953 : loss : 0.110887, loss_ce: 0.006498
[01:17:31.146] iteration 10954 : loss : 0.049964, loss_ce: 0.018378
[01:17:31.451] iteration 10955 : loss : 0.089400, loss_ce: 0.016722
[01:17:31.754] iteration 10956 : loss : 0.044221, loss_ce: 0.018216
[01:17:32.062] iteration 10957 : loss : 0.047564, loss_ce: 0.015496
[01:17:32.373] iteration 10958 : loss : 0.076393, loss_ce: 0.020613
[01:17:32.684] iteration 10959 : loss : 0.040680, loss_ce: 0.014757
[01:17:32.991] iteration 10960 : loss : 0.052909, loss_ce: 0.011275
[01:17:33.312] iteration 10961 : loss : 0.062002, loss_ce: 0.008546
[01:17:33.623] iteration 10962 : loss : 0.050722, loss_ce: 0.015672
[01:17:33.931] iteration 10963 : loss : 0.065674, loss_ce: 0.012984
[01:17:34.238] iteration 10964 : loss : 0.053506, loss_ce: 0.024427
[01:17:34.545] iteration 10965 : loss : 0.062833, loss_ce: 0.022213
[01:17:34.858] iteration 10966 : loss : 0.037929, loss_ce: 0.007938
[01:17:35.167] iteration 10967 : loss : 0.045336, loss_ce: 0.013532
[01:17:35.471] iteration 10968 : loss : 0.057676, loss_ce: 0.023215
[01:17:35.779] iteration 10969 : loss : 0.282134, loss_ce: 0.003346
[01:17:36.086] iteration 10970 : loss : 0.052035, loss_ce: 0.008426
[01:17:36.392] iteration 10971 : loss : 0.050975, loss_ce: 0.025177
[01:17:36.701] iteration 10972 : loss : 0.041015, loss_ce: 0.013588
[01:17:37.012] iteration 10973 : loss : 0.060846, loss_ce: 0.010425
[01:17:37.324] iteration 10974 : loss : 0.047734, loss_ce: 0.012193
[01:17:37.633] iteration 10975 : loss : 0.054857, loss_ce: 0.012552
[01:17:37.938] iteration 10976 : loss : 0.054310, loss_ce: 0.014658
[01:17:38.257] iteration 10977 : loss : 0.052017, loss_ce: 0.017499
[01:17:38.564] iteration 10978 : loss : 0.063438, loss_ce: 0.012974
[01:17:38.867] iteration 10979 : loss : 0.118660, loss_ce: 0.009256
[01:17:39.176] iteration 10980 : loss : 0.056773, loss_ce: 0.019110
[01:17:39.297] iteration 10981 : loss : 0.445878, loss_ce: 0.000057
[01:17:59.241] iteration 10982 : loss : 0.077546, loss_ce: 0.013002
[01:17:59.545] iteration 10983 : loss : 0.174478, loss_ce: 0.012849
[01:17:59.850] iteration 10984 : loss : 0.049287, loss_ce: 0.017151
[01:18:00.158] iteration 10985 : loss : 0.052590, loss_ce: 0.008602
[01:18:00.465] iteration 10986 : loss : 0.062433, loss_ce: 0.028623
[01:18:00.775] iteration 10987 : loss : 0.125719, loss_ce: 0.018064
[01:18:01.081] iteration 10988 : loss : 0.058273, loss_ce: 0.020075
[01:18:01.385] iteration 10989 : loss : 0.057838, loss_ce: 0.019965
[01:18:01.692] iteration 10990 : loss : 0.046489, loss_ce: 0.024983
[01:18:02.002] iteration 10991 : loss : 0.045361, loss_ce: 0.011827
[01:18:02.309] iteration 10992 : loss : 0.067032, loss_ce: 0.031129
[01:18:02.619] iteration 10993 : loss : 0.054121, loss_ce: 0.015462
[01:18:02.925] iteration 10994 : loss : 0.047443, loss_ce: 0.018600
[01:18:03.230] iteration 10995 : loss : 0.117839, loss_ce: 0.006186
[01:18:03.537] iteration 10996 : loss : 0.053972, loss_ce: 0.016056
[01:18:03.843] iteration 10997 : loss : 0.036644, loss_ce: 0.009079
[01:18:04.150] iteration 10998 : loss : 0.074394, loss_ce: 0.021548
[01:18:04.456] iteration 10999 : loss : 0.050447, loss_ce: 0.016224
[01:18:04.765] iteration 11000 : loss : 0.112106, loss_ce: 0.017018
[01:18:05.084] iteration 11001 : loss : 0.170502, loss_ce: 0.005475
[01:18:05.385] iteration 11002 : loss : 0.100994, loss_ce: 0.026517
[01:18:05.692] iteration 11003 : loss : 0.055627, loss_ce: 0.024332
[01:18:05.999] iteration 11004 : loss : 0.113283, loss_ce: 0.010565
[01:18:06.306] iteration 11005 : loss : 0.061978, loss_ce: 0.024742
[01:18:06.609] iteration 11006 : loss : 0.044146, loss_ce: 0.014055
[01:18:06.914] iteration 11007 : loss : 0.055506, loss_ce: 0.020193
[01:18:07.218] iteration 11008 : loss : 0.057637, loss_ce: 0.019281
[01:18:07.527] iteration 11009 : loss : 0.172614, loss_ce: 0.005919
[01:18:07.836] iteration 11010 : loss : 0.053799, loss_ce: 0.014773
[01:18:08.147] iteration 11011 : loss : 0.116104, loss_ce: 0.009092
[01:18:08.456] iteration 11012 : loss : 0.117254, loss_ce: 0.024865
[01:18:08.765] iteration 11013 : loss : 0.042203, loss_ce: 0.009765
[01:18:09.071] iteration 11014 : loss : 0.123775, loss_ce: 0.016374
[01:18:09.372] iteration 11015 : loss : 0.057606, loss_ce: 0.009747
[01:18:09.675] iteration 11016 : loss : 0.045476, loss_ce: 0.016189
[01:18:09.977] iteration 11017 : loss : 0.044797, loss_ce: 0.017171
[01:18:10.282] iteration 11018 : loss : 0.054321, loss_ce: 0.015551
[01:18:10.587] iteration 11019 : loss : 0.059719, loss_ce: 0.021264
[01:18:10.892] iteration 11020 : loss : 0.037879, loss_ce: 0.009057
[01:18:11.208] iteration 11021 : loss : 0.142162, loss_ce: 0.012345
[01:18:11.515] iteration 11022 : loss : 0.109780, loss_ce: 0.010595
[01:18:11.818] iteration 11023 : loss : 0.063808, loss_ce: 0.023743
[01:18:12.118] iteration 11024 : loss : 0.061345, loss_ce: 0.021886
[01:18:12.421] iteration 11025 : loss : 0.113891, loss_ce: 0.012812
[01:18:12.722] iteration 11026 : loss : 0.054235, loss_ce: 0.013487
[01:18:13.024] iteration 11027 : loss : 0.063365, loss_ce: 0.017138
[01:18:13.330] iteration 11028 : loss : 0.062236, loss_ce: 0.020754
[01:18:13.630] iteration 11029 : loss : 0.051226, loss_ce: 0.024568
[01:18:13.935] iteration 11030 : loss : 0.061611, loss_ce: 0.020943
[01:18:14.241] iteration 11031 : loss : 0.064662, loss_ce: 0.018725
[01:18:14.546] iteration 11032 : loss : 0.097637, loss_ce: 0.007907
[01:18:14.851] iteration 11033 : loss : 0.062500, loss_ce: 0.016117
[01:18:15.151] iteration 11034 : loss : 0.052795, loss_ce: 0.010254
[01:18:15.454] iteration 11035 : loss : 0.055666, loss_ce: 0.023585
[01:18:15.755] iteration 11036 : loss : 0.051737, loss_ce: 0.012075
[01:18:16.062] iteration 11037 : loss : 0.051007, loss_ce: 0.019379
[01:18:16.366] iteration 11038 : loss : 0.054336, loss_ce: 0.018537
[01:18:16.665] iteration 11039 : loss : 0.171193, loss_ce: 0.011652
[01:18:16.970] iteration 11040 : loss : 0.044484, loss_ce: 0.016227
[01:18:17.289] iteration 11041 : loss : 0.074450, loss_ce: 0.024207
[01:18:17.588] iteration 11042 : loss : 0.062337, loss_ce: 0.025306
[01:18:17.893] iteration 11043 : loss : 0.062677, loss_ce: 0.016847
[01:18:18.195] iteration 11044 : loss : 0.040992, loss_ce: 0.019493
[01:18:18.500] iteration 11045 : loss : 0.053191, loss_ce: 0.028127
[01:18:18.804] iteration 11046 : loss : 0.112916, loss_ce: 0.013341
[01:18:19.107] iteration 11047 : loss : 0.061309, loss_ce: 0.013019
[01:18:19.407] iteration 11048 : loss : 0.067544, loss_ce: 0.021174
[01:18:19.712] iteration 11049 : loss : 0.056539, loss_ce: 0.018559
[01:18:20.012] iteration 11050 : loss : 0.106580, loss_ce: 0.013323
[01:18:20.316] iteration 11051 : loss : 0.106786, loss_ce: 0.016016
[01:18:20.618] iteration 11052 : loss : 0.049838, loss_ce: 0.011428
[01:18:20.923] iteration 11053 : loss : 0.041714, loss_ce: 0.022017
[01:18:21.228] iteration 11054 : loss : 0.049671, loss_ce: 0.016364
[01:18:21.531] iteration 11055 : loss : 0.066694, loss_ce: 0.026123
[01:18:21.834] iteration 11056 : loss : 0.067097, loss_ce: 0.021828
[01:18:22.138] iteration 11057 : loss : 0.079306, loss_ce: 0.024167
[01:18:22.443] iteration 11058 : loss : 0.061795, loss_ce: 0.017270
[01:18:22.752] iteration 11059 : loss : 0.061049, loss_ce: 0.010864
[01:18:23.061] iteration 11060 : loss : 0.097377, loss_ce: 0.037560
[01:18:23.387] iteration 11061 : loss : 0.114623, loss_ce: 0.024614
[01:18:23.695] iteration 11062 : loss : 0.077711, loss_ce: 0.027733
[01:18:24.008] iteration 11063 : loss : 0.053370, loss_ce: 0.020480
[01:18:24.313] iteration 11064 : loss : 0.063410, loss_ce: 0.008760
[01:18:24.617] iteration 11065 : loss : 0.113149, loss_ce: 0.013875
[01:18:24.923] iteration 11066 : loss : 0.062414, loss_ce: 0.013385
[01:18:25.228] iteration 11067 : loss : 0.047610, loss_ce: 0.012148
[01:18:25.532] iteration 11068 : loss : 0.072413, loss_ce: 0.013480
[01:18:25.836] iteration 11069 : loss : 0.060008, loss_ce: 0.009278
[01:18:26.147] iteration 11070 : loss : 0.056539, loss_ce: 0.011959
[01:18:26.451] iteration 11071 : loss : 0.059455, loss_ce: 0.018156
[01:18:26.753] iteration 11072 : loss : 0.066669, loss_ce: 0.020766
[01:18:27.056] iteration 11073 : loss : 0.075201, loss_ce: 0.023038
[01:18:27.363] iteration 11074 : loss : 0.057402, loss_ce: 0.007804
[01:18:27.670] iteration 11075 : loss : 0.114982, loss_ce: 0.016390
[01:18:27.977] iteration 11076 : loss : 0.118201, loss_ce: 0.025106
[01:18:28.282] iteration 11077 : loss : 0.105786, loss_ce: 0.014027
[01:18:28.583] iteration 11078 : loss : 0.128281, loss_ce: 0.009667
[01:18:28.884] iteration 11079 : loss : 0.059337, loss_ce: 0.017922
[01:18:29.187] iteration 11080 : loss : 0.074011, loss_ce: 0.013597
[01:18:29.506] iteration 11081 : loss : 0.109640, loss_ce: 0.012342
[01:18:29.807] iteration 11082 : loss : 0.105786, loss_ce: 0.008668
[01:18:30.111] iteration 11083 : loss : 0.058095, loss_ce: 0.021740
[01:18:30.417] iteration 11084 : loss : 0.160815, loss_ce: 0.008750
[01:18:30.719] iteration 11085 : loss : 0.054730, loss_ce: 0.021215
[01:18:31.022] iteration 11086 : loss : 0.048253, loss_ce: 0.016715
[01:18:31.332] iteration 11087 : loss : 0.046345, loss_ce: 0.013166
[01:18:31.637] iteration 11088 : loss : 0.051410, loss_ce: 0.014348
[01:18:31.942] iteration 11089 : loss : 0.047581, loss_ce: 0.010562
[01:18:32.243] iteration 11090 : loss : 0.102728, loss_ce: 0.008272
[01:18:32.544] iteration 11091 : loss : 0.063912, loss_ce: 0.014665
[01:18:32.847] iteration 11092 : loss : 0.183445, loss_ce: 0.016017
[01:18:33.152] iteration 11093 : loss : 0.055340, loss_ce: 0.016142
[01:18:33.455] iteration 11094 : loss : 0.073592, loss_ce: 0.012934
[01:18:33.757] iteration 11095 : loss : 0.059908, loss_ce: 0.008183
[01:18:34.060] iteration 11096 : loss : 0.050929, loss_ce: 0.017960
[01:18:34.364] iteration 11097 : loss : 0.070867, loss_ce: 0.015153
[01:18:34.670] iteration 11098 : loss : 0.051138, loss_ce: 0.021853
[01:18:34.974] iteration 11099 : loss : 0.055704, loss_ce: 0.023843
[01:18:35.277] iteration 11100 : loss : 0.051630, loss_ce: 0.019026
[01:18:35.598] iteration 11101 : loss : 0.059520, loss_ce: 0.018655
[01:18:35.902] iteration 11102 : loss : 0.059783, loss_ce: 0.007966
[01:18:36.206] iteration 11103 : loss : 0.067397, loss_ce: 0.019945
[01:18:36.515] iteration 11104 : loss : 0.058485, loss_ce: 0.019878
[01:18:36.824] iteration 11105 : loss : 0.103716, loss_ce: 0.013694
[01:18:37.130] iteration 11106 : loss : 0.066762, loss_ce: 0.026613
[01:18:37.446] iteration 11107 : loss : 0.057426, loss_ce: 0.021826
[01:18:37.753] iteration 11108 : loss : 0.066247, loss_ce: 0.010328
[01:18:38.067] iteration 11109 : loss : 0.049364, loss_ce: 0.020519
[01:18:38.371] iteration 11110 : loss : 0.047419, loss_ce: 0.015790
[01:18:38.677] iteration 11111 : loss : 0.070933, loss_ce: 0.011665
[01:18:38.987] iteration 11112 : loss : 0.049396, loss_ce: 0.013316
[01:18:39.298] iteration 11113 : loss : 0.046638, loss_ce: 0.006395
[01:18:39.611] iteration 11114 : loss : 0.049274, loss_ce: 0.016820
[01:18:39.925] iteration 11115 : loss : 0.121256, loss_ce: 0.012209
[01:18:40.242] iteration 11116 : loss : 0.046683, loss_ce: 0.009432
[01:18:40.547] iteration 11117 : loss : 0.047976, loss_ce: 0.011531
[01:18:40.860] iteration 11118 : loss : 0.062243, loss_ce: 0.032670
[01:18:41.170] iteration 11119 : loss : 0.054168, loss_ce: 0.016121
[01:18:41.255] iteration 11120 : loss : 0.353822, loss_ce: 0.004287
[01:18:59.315] iteration 11121 : loss : 0.057724, loss_ce: 0.014495
[01:18:59.612] iteration 11122 : loss : 0.051659, loss_ce: 0.009846
[01:18:59.916] iteration 11123 : loss : 0.063510, loss_ce: 0.021472
[01:19:00.217] iteration 11124 : loss : 0.053199, loss_ce: 0.011414
[01:19:00.519] iteration 11125 : loss : 0.070350, loss_ce: 0.017611
[01:19:00.822] iteration 11126 : loss : 0.054866, loss_ce: 0.016262
[01:19:01.125] iteration 11127 : loss : 0.116898, loss_ce: 0.010479
[01:19:01.425] iteration 11128 : loss : 0.046318, loss_ce: 0.014430
[01:19:01.728] iteration 11129 : loss : 0.100762, loss_ce: 0.010927
[01:19:02.035] iteration 11130 : loss : 0.065902, loss_ce: 0.011728
[01:19:02.337] iteration 11131 : loss : 0.037690, loss_ce: 0.006123
[01:19:02.639] iteration 11132 : loss : 0.114626, loss_ce: 0.010132
[01:19:02.946] iteration 11133 : loss : 0.058545, loss_ce: 0.014479
[01:19:03.248] iteration 11134 : loss : 0.054829, loss_ce: 0.014102
[01:19:03.549] iteration 11135 : loss : 0.055857, loss_ce: 0.011665
[01:19:03.855] iteration 11136 : loss : 0.037300, loss_ce: 0.010761
[01:19:04.162] iteration 11137 : loss : 0.045461, loss_ce: 0.013404
[01:19:04.467] iteration 11138 : loss : 0.049956, loss_ce: 0.013271
[01:19:04.775] iteration 11139 : loss : 0.082117, loss_ce: 0.017645
[01:19:05.077] iteration 11140 : loss : 0.049595, loss_ce: 0.015341
[01:19:05.395] iteration 11141 : loss : 0.092329, loss_ce: 0.020412
[01:19:05.697] iteration 11142 : loss : 0.048204, loss_ce: 0.022230
[01:19:06.000] iteration 11143 : loss : 0.048867, loss_ce: 0.018537
[01:19:06.302] iteration 11144 : loss : 0.178072, loss_ce: 0.006944
[01:19:06.602] iteration 11145 : loss : 0.113439, loss_ce: 0.014718
[01:19:06.905] iteration 11146 : loss : 0.051569, loss_ce: 0.014819
[01:19:07.210] iteration 11147 : loss : 0.111695, loss_ce: 0.015828
[01:19:07.514] iteration 11148 : loss : 0.046329, loss_ce: 0.017469
[01:19:07.817] iteration 11149 : loss : 0.040491, loss_ce: 0.014108
[01:19:08.122] iteration 11150 : loss : 0.057309, loss_ce: 0.020968
[01:19:08.427] iteration 11151 : loss : 0.045264, loss_ce: 0.013117
[01:19:08.732] iteration 11152 : loss : 0.059714, loss_ce: 0.020755
[01:19:09.036] iteration 11153 : loss : 0.063832, loss_ce: 0.013501
[01:19:09.341] iteration 11154 : loss : 0.061432, loss_ce: 0.015370
[01:19:09.648] iteration 11155 : loss : 0.067581, loss_ce: 0.015391
[01:19:09.949] iteration 11156 : loss : 0.124982, loss_ce: 0.011123
[01:19:10.253] iteration 11157 : loss : 0.166148, loss_ce: 0.019610
[01:19:10.558] iteration 11158 : loss : 0.173913, loss_ce: 0.003460
[01:19:10.864] iteration 11159 : loss : 0.044804, loss_ce: 0.019022
[01:19:11.167] iteration 11160 : loss : 0.056064, loss_ce: 0.016147
[01:19:11.492] iteration 11161 : loss : 0.061196, loss_ce: 0.015373
[01:19:11.797] iteration 11162 : loss : 0.104117, loss_ce: 0.014086
[01:19:12.104] iteration 11163 : loss : 0.064193, loss_ce: 0.027793
[01:19:12.414] iteration 11164 : loss : 0.117160, loss_ce: 0.014000
[01:19:12.727] iteration 11165 : loss : 0.060354, loss_ce: 0.018867
[01:19:13.035] iteration 11166 : loss : 0.101214, loss_ce: 0.008555
[01:19:13.341] iteration 11167 : loss : 0.107013, loss_ce: 0.008416
[01:19:13.657] iteration 11168 : loss : 0.044976, loss_ce: 0.015333
[01:19:13.968] iteration 11169 : loss : 0.064213, loss_ce: 0.008593
[01:19:14.277] iteration 11170 : loss : 0.058871, loss_ce: 0.015060
[01:19:14.583] iteration 11171 : loss : 0.057351, loss_ce: 0.010554
[01:19:14.888] iteration 11172 : loss : 0.042420, loss_ce: 0.018369
[01:19:15.189] iteration 11173 : loss : 0.145794, loss_ce: 0.012777
[01:19:15.492] iteration 11174 : loss : 0.065185, loss_ce: 0.015258
[01:19:15.799] iteration 11175 : loss : 0.051554, loss_ce: 0.023516
[01:19:16.106] iteration 11176 : loss : 0.055916, loss_ce: 0.024901
[01:19:16.412] iteration 11177 : loss : 0.124193, loss_ce: 0.017096
[01:19:16.715] iteration 11178 : loss : 0.137323, loss_ce: 0.012641
[01:19:17.018] iteration 11179 : loss : 0.055834, loss_ce: 0.022217
[01:19:17.324] iteration 11180 : loss : 0.053909, loss_ce: 0.015167
[01:19:17.647] iteration 11181 : loss : 0.059194, loss_ce: 0.022298
[01:19:17.950] iteration 11182 : loss : 0.044140, loss_ce: 0.005786
[01:19:18.251] iteration 11183 : loss : 0.070831, loss_ce: 0.012697
[01:19:18.552] iteration 11184 : loss : 0.046045, loss_ce: 0.011705
[01:19:18.853] iteration 11185 : loss : 0.053727, loss_ce: 0.019503
[01:19:19.157] iteration 11186 : loss : 0.037944, loss_ce: 0.010922
[01:19:19.464] iteration 11187 : loss : 0.049925, loss_ce: 0.011815
[01:19:19.767] iteration 11188 : loss : 0.048159, loss_ce: 0.024552
[01:19:20.068] iteration 11189 : loss : 0.046186, loss_ce: 0.016432
[01:19:20.373] iteration 11190 : loss : 0.073013, loss_ce: 0.020542
[01:19:20.675] iteration 11191 : loss : 0.050157, loss_ce: 0.015628
[01:19:20.976] iteration 11192 : loss : 0.059484, loss_ce: 0.012436
[01:19:21.280] iteration 11193 : loss : 0.062977, loss_ce: 0.020877
[01:19:21.585] iteration 11194 : loss : 0.045065, loss_ce: 0.013714
[01:19:21.891] iteration 11195 : loss : 0.067099, loss_ce: 0.024853
[01:19:22.193] iteration 11196 : loss : 0.057706, loss_ce: 0.023393
[01:19:22.500] iteration 11197 : loss : 0.044624, loss_ce: 0.011383
[01:19:22.805] iteration 11198 : loss : 0.059191, loss_ce: 0.019114
[01:19:23.111] iteration 11199 : loss : 0.044480, loss_ce: 0.017317
[01:19:23.412] iteration 11200 : loss : 0.046327, loss_ce: 0.025247
[01:19:23.738] iteration 11201 : loss : 0.106002, loss_ce: 0.015177
[01:19:24.039] iteration 11202 : loss : 0.047687, loss_ce: 0.015912
[01:19:24.347] iteration 11203 : loss : 0.052435, loss_ce: 0.016486
[01:19:24.648] iteration 11204 : loss : 0.049620, loss_ce: 0.016722
[01:19:24.955] iteration 11205 : loss : 0.048073, loss_ce: 0.018756
[01:19:25.258] iteration 11206 : loss : 0.045702, loss_ce: 0.020824
[01:19:25.561] iteration 11207 : loss : 0.051988, loss_ce: 0.012346
[01:19:25.864] iteration 11208 : loss : 0.041629, loss_ce: 0.017739
[01:19:26.165] iteration 11209 : loss : 0.124411, loss_ce: 0.017590
[01:19:26.469] iteration 11210 : loss : 0.046187, loss_ce: 0.016079
[01:19:26.772] iteration 11211 : loss : 0.062203, loss_ce: 0.024019
[01:19:27.075] iteration 11212 : loss : 0.069338, loss_ce: 0.020850
[01:19:27.381] iteration 11213 : loss : 0.054723, loss_ce: 0.013890
[01:19:27.690] iteration 11214 : loss : 0.046341, loss_ce: 0.016014
[01:19:27.996] iteration 11215 : loss : 0.060495, loss_ce: 0.020533
[01:19:28.300] iteration 11216 : loss : 0.048068, loss_ce: 0.013485
[01:19:28.605] iteration 11217 : loss : 0.051117, loss_ce: 0.013936
[01:19:28.910] iteration 11218 : loss : 0.051124, loss_ce: 0.012521
[01:19:29.218] iteration 11219 : loss : 0.103031, loss_ce: 0.014604
[01:19:29.527] iteration 11220 : loss : 0.041599, loss_ce: 0.013387
[01:19:29.846] iteration 11221 : loss : 0.091891, loss_ce: 0.014259
[01:19:30.153] iteration 11222 : loss : 0.073512, loss_ce: 0.016362
[01:19:30.463] iteration 11223 : loss : 0.049401, loss_ce: 0.020684
[01:19:30.771] iteration 11224 : loss : 0.078423, loss_ce: 0.022588
[01:19:31.078] iteration 11225 : loss : 0.067864, loss_ce: 0.013693
[01:19:31.389] iteration 11226 : loss : 0.043955, loss_ce: 0.013685
[01:19:31.694] iteration 11227 : loss : 0.121961, loss_ce: 0.011553
[01:19:32.002] iteration 11228 : loss : 0.108015, loss_ce: 0.011400
[01:19:32.310] iteration 11229 : loss : 0.050009, loss_ce: 0.016962
[01:19:32.621] iteration 11230 : loss : 0.069950, loss_ce: 0.011262
[01:19:32.930] iteration 11231 : loss : 0.052458, loss_ce: 0.007536
[01:19:33.240] iteration 11232 : loss : 0.046209, loss_ce: 0.011715
[01:19:33.548] iteration 11233 : loss : 0.047903, loss_ce: 0.022189
[01:19:33.856] iteration 11234 : loss : 0.039584, loss_ce: 0.010084
[01:19:34.165] iteration 11235 : loss : 0.055674, loss_ce: 0.013241
[01:19:34.476] iteration 11236 : loss : 0.047893, loss_ce: 0.008490
[01:19:34.784] iteration 11237 : loss : 0.045901, loss_ce: 0.012338
[01:19:35.090] iteration 11238 : loss : 0.057562, loss_ce: 0.011455
[01:19:35.400] iteration 11239 : loss : 0.115901, loss_ce: 0.018823
[01:19:35.706] iteration 11240 : loss : 0.048698, loss_ce: 0.017715
[01:19:36.034] iteration 11241 : loss : 0.050852, loss_ce: 0.014782
[01:19:36.339] iteration 11242 : loss : 0.056150, loss_ce: 0.022488
[01:19:36.647] iteration 11243 : loss : 0.074068, loss_ce: 0.017944
[01:19:36.958] iteration 11244 : loss : 0.070637, loss_ce: 0.011041
[01:19:37.270] iteration 11245 : loss : 0.063438, loss_ce: 0.016732
[01:19:37.584] iteration 11246 : loss : 0.060832, loss_ce: 0.016027
[01:19:37.896] iteration 11247 : loss : 0.059681, loss_ce: 0.017438
[01:19:38.206] iteration 11248 : loss : 0.118361, loss_ce: 0.017891
[01:19:38.520] iteration 11249 : loss : 0.057279, loss_ce: 0.017275
[01:19:38.835] iteration 11250 : loss : 0.042607, loss_ce: 0.009199
[01:19:39.144] iteration 11251 : loss : 0.046805, loss_ce: 0.013449
[01:19:39.462] iteration 11252 : loss : 0.274638, loss_ce: 0.039931
[01:19:39.774] iteration 11253 : loss : 0.107617, loss_ce: 0.008222
[01:19:40.090] iteration 11254 : loss : 0.066762, loss_ce: 0.015237
[01:19:40.409] iteration 11255 : loss : 0.065906, loss_ce: 0.020437
[01:19:40.727] iteration 11256 : loss : 0.119997, loss_ce: 0.009884
[01:19:41.039] iteration 11257 : loss : 0.045719, loss_ce: 0.017951
[01:19:41.350] iteration 11258 : loss : 0.112820, loss_ce: 0.015463
[01:19:41.432] iteration 11259 : loss : 0.129941, loss_ce: 0.024192
[01:19:59.242] iteration 11260 : loss : 0.089367, loss_ce: 0.020418
[01:19:59.554] iteration 11261 : loss : 0.059000, loss_ce: 0.015510
[01:19:59.852] iteration 11262 : loss : 0.107423, loss_ce: 0.010401
[01:20:00.157] iteration 11263 : loss : 0.049478, loss_ce: 0.017490
[01:20:00.461] iteration 11264 : loss : 0.153146, loss_ce: 0.018365
[01:20:00.763] iteration 11265 : loss : 0.114437, loss_ce: 0.017476
[01:20:01.068] iteration 11266 : loss : 0.061312, loss_ce: 0.026612
[01:20:01.371] iteration 11267 : loss : 0.043699, loss_ce: 0.018138
[01:20:01.672] iteration 11268 : loss : 0.047387, loss_ce: 0.014996
[01:20:01.974] iteration 11269 : loss : 0.073764, loss_ce: 0.009140
[01:20:02.282] iteration 11270 : loss : 0.041430, loss_ce: 0.017727
[01:20:02.589] iteration 11271 : loss : 0.053943, loss_ce: 0.026418
[01:20:02.895] iteration 11272 : loss : 0.054434, loss_ce: 0.023934
[01:20:03.204] iteration 11273 : loss : 0.059493, loss_ce: 0.023022
[01:20:03.510] iteration 11274 : loss : 0.041373, loss_ce: 0.009930
[01:20:03.817] iteration 11275 : loss : 0.058876, loss_ce: 0.015300
[01:20:04.125] iteration 11276 : loss : 0.069272, loss_ce: 0.011733
[01:20:04.430] iteration 11277 : loss : 0.048480, loss_ce: 0.018375
[01:20:04.732] iteration 11278 : loss : 0.063488, loss_ce: 0.013484
[01:20:05.032] iteration 11279 : loss : 0.065588, loss_ce: 0.019528
[01:20:05.334] iteration 11280 : loss : 0.108120, loss_ce: 0.003827
[01:20:05.650] iteration 11281 : loss : 0.053749, loss_ce: 0.020685
[01:20:05.950] iteration 11282 : loss : 0.116881, loss_ce: 0.017739
[01:20:06.256] iteration 11283 : loss : 0.046141, loss_ce: 0.015845
[01:20:06.559] iteration 11284 : loss : 0.046208, loss_ce: 0.009306
[01:20:06.862] iteration 11285 : loss : 0.058125, loss_ce: 0.024409
[01:20:07.162] iteration 11286 : loss : 0.091463, loss_ce: 0.010668
[01:20:07.466] iteration 11287 : loss : 0.108384, loss_ce: 0.025298
[01:20:07.767] iteration 11288 : loss : 0.103246, loss_ce: 0.012755
[01:20:08.070] iteration 11289 : loss : 0.045446, loss_ce: 0.008468
[01:20:08.373] iteration 11290 : loss : 0.071872, loss_ce: 0.016955
[01:20:08.674] iteration 11291 : loss : 0.047174, loss_ce: 0.017432
[01:20:08.976] iteration 11292 : loss : 0.120262, loss_ce: 0.013988
[01:20:09.277] iteration 11293 : loss : 0.066250, loss_ce: 0.017739
[01:20:09.577] iteration 11294 : loss : 0.109941, loss_ce: 0.015675
[01:20:09.880] iteration 11295 : loss : 0.054694, loss_ce: 0.026719
[01:20:10.183] iteration 11296 : loss : 0.051524, loss_ce: 0.022502
[01:20:10.485] iteration 11297 : loss : 0.107465, loss_ce: 0.009724
[01:20:10.788] iteration 11298 : loss : 0.061255, loss_ce: 0.019219
[01:20:11.095] iteration 11299 : loss : 0.080884, loss_ce: 0.022731
[01:20:11.402] iteration 11300 : loss : 0.062497, loss_ce: 0.018306
[01:20:11.719] iteration 11301 : loss : 0.049824, loss_ce: 0.013917
[01:20:12.023] iteration 11302 : loss : 0.051397, loss_ce: 0.010725
[01:20:12.326] iteration 11303 : loss : 0.060093, loss_ce: 0.017562
[01:20:12.636] iteration 11304 : loss : 0.047008, loss_ce: 0.016951
[01:20:12.937] iteration 11305 : loss : 0.055342, loss_ce: 0.027714
[01:20:13.240] iteration 11306 : loss : 0.049748, loss_ce: 0.018422
[01:20:13.542] iteration 11307 : loss : 0.049517, loss_ce: 0.022425
[01:20:13.844] iteration 11308 : loss : 0.049688, loss_ce: 0.013239
[01:20:14.149] iteration 11309 : loss : 0.113545, loss_ce: 0.014377
[01:20:14.453] iteration 11310 : loss : 0.102404, loss_ce: 0.006906
[01:20:14.755] iteration 11311 : loss : 0.057888, loss_ce: 0.013748
[01:20:15.057] iteration 11312 : loss : 0.043706, loss_ce: 0.010447
[01:20:15.359] iteration 11313 : loss : 0.054444, loss_ce: 0.019495
[01:20:15.663] iteration 11314 : loss : 0.052921, loss_ce: 0.013005
[01:20:15.969] iteration 11315 : loss : 0.048471, loss_ce: 0.019635
[01:20:16.271] iteration 11316 : loss : 0.108968, loss_ce: 0.009711
[01:20:16.578] iteration 11317 : loss : 0.054843, loss_ce: 0.010823
[01:20:16.879] iteration 11318 : loss : 0.044302, loss_ce: 0.011495
[01:20:17.183] iteration 11319 : loss : 0.289934, loss_ce: 0.007186
[01:20:17.491] iteration 11320 : loss : 0.052869, loss_ce: 0.016551
[01:20:17.818] iteration 11321 : loss : 0.060958, loss_ce: 0.017409
[01:20:18.121] iteration 11322 : loss : 0.042367, loss_ce: 0.013963
[01:20:18.426] iteration 11323 : loss : 0.060841, loss_ce: 0.014403
[01:20:18.734] iteration 11324 : loss : 0.066980, loss_ce: 0.024811
[01:20:19.039] iteration 11325 : loss : 0.036832, loss_ce: 0.006596
[01:20:19.345] iteration 11326 : loss : 0.045431, loss_ce: 0.020813
[01:20:19.648] iteration 11327 : loss : 0.061591, loss_ce: 0.023072
[01:20:19.954] iteration 11328 : loss : 0.070020, loss_ce: 0.020636
[01:20:20.262] iteration 11329 : loss : 0.073017, loss_ce: 0.020091
[01:20:20.573] iteration 11330 : loss : 0.051351, loss_ce: 0.013747
[01:20:20.876] iteration 11331 : loss : 0.047193, loss_ce: 0.011216
[01:20:21.184] iteration 11332 : loss : 0.163125, loss_ce: 0.007597
[01:20:21.492] iteration 11333 : loss : 0.064666, loss_ce: 0.013655
[01:20:21.799] iteration 11334 : loss : 0.049775, loss_ce: 0.023796
[01:20:22.106] iteration 11335 : loss : 0.123397, loss_ce: 0.010156
[01:20:22.412] iteration 11336 : loss : 0.235930, loss_ce: 0.001238
[01:20:22.720] iteration 11337 : loss : 0.040905, loss_ce: 0.014957
[01:20:23.028] iteration 11338 : loss : 0.044870, loss_ce: 0.012736
[01:20:23.337] iteration 11339 : loss : 0.053212, loss_ce: 0.020054
[01:20:23.645] iteration 11340 : loss : 0.042852, loss_ce: 0.022425
[01:20:23.967] iteration 11341 : loss : 0.059439, loss_ce: 0.022095
[01:20:24.272] iteration 11342 : loss : 0.074988, loss_ce: 0.012419
[01:20:24.584] iteration 11343 : loss : 0.051755, loss_ce: 0.022416
[01:20:24.890] iteration 11344 : loss : 0.114043, loss_ce: 0.023668
[01:20:25.202] iteration 11345 : loss : 0.053407, loss_ce: 0.016790
[01:20:25.507] iteration 11346 : loss : 0.108088, loss_ce: 0.016626
[01:20:25.817] iteration 11347 : loss : 0.045863, loss_ce: 0.018751
[01:20:26.125] iteration 11348 : loss : 0.101060, loss_ce: 0.010406
[01:20:26.437] iteration 11349 : loss : 0.164307, loss_ce: 0.005563
[01:20:26.743] iteration 11350 : loss : 0.086803, loss_ce: 0.020035
[01:20:27.049] iteration 11351 : loss : 0.047828, loss_ce: 0.011804
[01:20:27.359] iteration 11352 : loss : 0.124256, loss_ce: 0.013006
[01:20:27.665] iteration 11353 : loss : 0.053579, loss_ce: 0.015492
[01:20:27.973] iteration 11354 : loss : 0.054871, loss_ce: 0.013204
[01:20:28.283] iteration 11355 : loss : 0.057783, loss_ce: 0.010818
[01:20:28.591] iteration 11356 : loss : 0.124234, loss_ce: 0.016180
[01:20:28.899] iteration 11357 : loss : 0.056328, loss_ce: 0.014085
[01:20:29.208] iteration 11358 : loss : 0.047153, loss_ce: 0.014673
[01:20:29.514] iteration 11359 : loss : 0.052325, loss_ce: 0.017146
[01:20:29.821] iteration 11360 : loss : 0.083388, loss_ce: 0.013891
[01:20:30.150] iteration 11361 : loss : 0.052979, loss_ce: 0.009237
[01:20:30.453] iteration 11362 : loss : 0.044749, loss_ce: 0.023641
[01:20:30.767] iteration 11363 : loss : 0.046068, loss_ce: 0.013465
[01:20:31.071] iteration 11364 : loss : 0.046846, loss_ce: 0.009122
[01:20:31.380] iteration 11365 : loss : 0.051833, loss_ce: 0.022981
[01:20:31.686] iteration 11366 : loss : 0.056386, loss_ce: 0.018852
[01:20:31.992] iteration 11367 : loss : 0.226814, loss_ce: 0.011056
[01:20:32.303] iteration 11368 : loss : 0.056777, loss_ce: 0.006238
[01:20:32.611] iteration 11369 : loss : 0.053638, loss_ce: 0.014858
[01:20:32.920] iteration 11370 : loss : 0.046216, loss_ce: 0.018178
[01:20:33.231] iteration 11371 : loss : 0.091223, loss_ce: 0.016454
[01:20:33.536] iteration 11372 : loss : 0.046887, loss_ce: 0.013416
[01:20:33.844] iteration 11373 : loss : 0.066464, loss_ce: 0.013837
[01:20:34.150] iteration 11374 : loss : 0.063053, loss_ce: 0.019367
[01:20:34.458] iteration 11375 : loss : 0.190467, loss_ce: 0.007600
[01:20:34.766] iteration 11376 : loss : 0.110387, loss_ce: 0.012155
[01:20:35.078] iteration 11377 : loss : 0.071408, loss_ce: 0.020725
[01:20:35.385] iteration 11378 : loss : 0.047615, loss_ce: 0.021188
[01:20:35.693] iteration 11379 : loss : 0.081927, loss_ce: 0.016304
[01:20:36.001] iteration 11380 : loss : 0.122831, loss_ce: 0.014117
[01:20:36.325] iteration 11381 : loss : 0.049044, loss_ce: 0.018845
[01:20:36.634] iteration 11382 : loss : 0.104037, loss_ce: 0.012194
[01:20:36.952] iteration 11383 : loss : 0.042655, loss_ce: 0.014492
[01:20:37.265] iteration 11384 : loss : 0.113435, loss_ce: 0.008389
[01:20:37.574] iteration 11385 : loss : 0.055204, loss_ce: 0.022172
[01:20:37.888] iteration 11386 : loss : 0.070536, loss_ce: 0.011845
[01:20:38.199] iteration 11387 : loss : 0.110862, loss_ce: 0.004120
[01:20:38.513] iteration 11388 : loss : 0.063387, loss_ce: 0.010677
[01:20:38.828] iteration 11389 : loss : 0.063844, loss_ce: 0.016493
[01:20:39.144] iteration 11390 : loss : 0.050374, loss_ce: 0.015788
[01:20:39.457] iteration 11391 : loss : 0.051190, loss_ce: 0.015239
[01:20:39.770] iteration 11392 : loss : 0.062923, loss_ce: 0.019088
[01:20:40.079] iteration 11393 : loss : 0.045298, loss_ce: 0.010856
[01:20:40.391] iteration 11394 : loss : 0.056454, loss_ce: 0.021784
[01:20:40.693] iteration 11395 : loss : 0.050468, loss_ce: 0.017989
[01:20:40.999] iteration 11396 : loss : 0.054674, loss_ce: 0.016117
[01:20:41.312] iteration 11397 : loss : 0.053398, loss_ce: 0.013158
[01:20:41.391] iteration 11398 : loss : 0.289961, loss_ce: 0.024136
[01:20:59.906] iteration 11399 : loss : 0.061324, loss_ce: 0.016510
[01:21:00.205] iteration 11400 : loss : 0.052660, loss_ce: 0.009517
[01:21:00.520] iteration 11401 : loss : 0.108843, loss_ce: 0.014469
[01:21:00.822] iteration 11402 : loss : 0.056759, loss_ce: 0.013285
[01:21:01.133] iteration 11403 : loss : 0.113024, loss_ce: 0.014105
[01:21:01.437] iteration 11404 : loss : 0.079594, loss_ce: 0.016383
[01:21:01.741] iteration 11405 : loss : 0.056822, loss_ce: 0.017783
[01:21:02.043] iteration 11406 : loss : 0.060116, loss_ce: 0.015816
[01:21:02.350] iteration 11407 : loss : 0.044664, loss_ce: 0.012923
[01:21:02.652] iteration 11408 : loss : 0.047151, loss_ce: 0.014776
[01:21:02.955] iteration 11409 : loss : 0.052806, loss_ce: 0.012662
[01:21:03.263] iteration 11410 : loss : 0.067764, loss_ce: 0.014222
[01:21:03.568] iteration 11411 : loss : 0.039848, loss_ce: 0.008890
[01:21:03.872] iteration 11412 : loss : 0.053282, loss_ce: 0.016115
[01:21:04.179] iteration 11413 : loss : 0.068692, loss_ce: 0.013110
[01:21:04.485] iteration 11414 : loss : 0.163659, loss_ce: 0.010704
[01:21:04.790] iteration 11415 : loss : 0.056255, loss_ce: 0.019813
[01:21:05.093] iteration 11416 : loss : 0.056157, loss_ce: 0.024928
[01:21:05.398] iteration 11417 : loss : 0.055383, loss_ce: 0.023126
[01:21:05.700] iteration 11418 : loss : 0.116425, loss_ce: 0.008989
[01:21:06.004] iteration 11419 : loss : 0.056453, loss_ce: 0.021819
[01:21:06.306] iteration 11420 : loss : 0.057821, loss_ce: 0.016472
[01:21:06.625] iteration 11421 : loss : 0.054601, loss_ce: 0.020339
[01:21:06.933] iteration 11422 : loss : 0.059833, loss_ce: 0.012460
[01:21:07.240] iteration 11423 : loss : 0.050866, loss_ce: 0.018597
[01:21:07.546] iteration 11424 : loss : 0.048385, loss_ce: 0.013129
[01:21:07.856] iteration 11425 : loss : 0.065817, loss_ce: 0.014406
[01:21:08.170] iteration 11426 : loss : 0.160339, loss_ce: 0.008246
[01:21:08.487] iteration 11427 : loss : 0.062286, loss_ce: 0.009867
[01:21:08.799] iteration 11428 : loss : 0.046591, loss_ce: 0.013739
[01:21:09.104] iteration 11429 : loss : 0.054723, loss_ce: 0.013611
[01:21:09.415] iteration 11430 : loss : 0.102834, loss_ce: 0.013433
[01:21:09.720] iteration 11431 : loss : 0.102942, loss_ce: 0.016581
[01:21:10.024] iteration 11432 : loss : 0.120402, loss_ce: 0.014350
[01:21:10.328] iteration 11433 : loss : 0.125451, loss_ce: 0.016338
[01:21:10.634] iteration 11434 : loss : 0.059095, loss_ce: 0.022862
[01:21:10.940] iteration 11435 : loss : 0.048584, loss_ce: 0.011208
[01:21:11.245] iteration 11436 : loss : 0.046990, loss_ce: 0.016748
[01:21:11.552] iteration 11437 : loss : 0.041380, loss_ce: 0.007510
[01:21:11.860] iteration 11438 : loss : 0.101301, loss_ce: 0.010373
[01:21:12.169] iteration 11439 : loss : 0.059634, loss_ce: 0.021316
[01:21:12.470] iteration 11440 : loss : 0.056882, loss_ce: 0.016947
[01:21:12.792] iteration 11441 : loss : 0.159852, loss_ce: 0.008339
[01:21:13.096] iteration 11442 : loss : 0.110816, loss_ce: 0.016692
[01:21:13.403] iteration 11443 : loss : 0.117332, loss_ce: 0.013148
[01:21:13.708] iteration 11444 : loss : 0.051275, loss_ce: 0.005632
[01:21:14.016] iteration 11445 : loss : 0.066929, loss_ce: 0.007276
[01:21:14.321] iteration 11446 : loss : 0.048900, loss_ce: 0.017407
[01:21:14.628] iteration 11447 : loss : 0.054036, loss_ce: 0.018544
[01:21:14.933] iteration 11448 : loss : 0.058693, loss_ce: 0.024831
[01:21:15.241] iteration 11449 : loss : 0.109828, loss_ce: 0.015897
[01:21:15.546] iteration 11450 : loss : 0.057834, loss_ce: 0.018497
[01:21:15.852] iteration 11451 : loss : 0.162277, loss_ce: 0.012571
[01:21:16.160] iteration 11452 : loss : 0.045864, loss_ce: 0.016081
[01:21:16.467] iteration 11453 : loss : 0.050096, loss_ce: 0.015236
[01:21:16.773] iteration 11454 : loss : 0.225376, loss_ce: 0.009692
[01:21:17.079] iteration 11455 : loss : 0.126792, loss_ce: 0.011788
[01:21:17.387] iteration 11456 : loss : 0.158058, loss_ce: 0.011663
[01:21:17.692] iteration 11457 : loss : 0.113100, loss_ce: 0.014844
[01:21:17.999] iteration 11458 : loss : 0.042693, loss_ce: 0.014426
[01:21:18.304] iteration 11459 : loss : 0.052454, loss_ce: 0.015809
[01:21:18.610] iteration 11460 : loss : 0.053902, loss_ce: 0.014274
[01:21:18.931] iteration 11461 : loss : 0.055843, loss_ce: 0.009703
[01:21:19.232] iteration 11462 : loss : 0.045444, loss_ce: 0.016237
[01:21:19.539] iteration 11463 : loss : 0.049113, loss_ce: 0.011296
[01:21:19.845] iteration 11464 : loss : 0.054435, loss_ce: 0.021751
[01:21:20.151] iteration 11465 : loss : 0.052643, loss_ce: 0.026920
[01:21:20.453] iteration 11466 : loss : 0.105241, loss_ce: 0.008339
[01:21:20.757] iteration 11467 : loss : 0.046752, loss_ce: 0.015859
[01:21:21.063] iteration 11468 : loss : 0.054487, loss_ce: 0.011375
[01:21:21.366] iteration 11469 : loss : 0.068288, loss_ce: 0.007834
[01:21:21.667] iteration 11470 : loss : 0.051820, loss_ce: 0.011178
[01:21:21.970] iteration 11471 : loss : 0.034800, loss_ce: 0.009058
[01:21:22.277] iteration 11472 : loss : 0.047708, loss_ce: 0.016708
[01:21:22.588] iteration 11473 : loss : 0.043663, loss_ce: 0.017050
[01:21:22.894] iteration 11474 : loss : 0.036749, loss_ce: 0.010403
[01:21:23.198] iteration 11475 : loss : 0.052537, loss_ce: 0.015685
[01:21:23.500] iteration 11476 : loss : 0.151071, loss_ce: 0.008573
[01:21:23.803] iteration 11477 : loss : 0.057801, loss_ce: 0.018611
[01:21:24.109] iteration 11478 : loss : 0.049302, loss_ce: 0.009586
[01:21:24.416] iteration 11479 : loss : 0.230824, loss_ce: 0.015927
[01:21:24.723] iteration 11480 : loss : 0.132864, loss_ce: 0.007290
[01:21:25.049] iteration 11481 : loss : 0.056202, loss_ce: 0.017654
[01:21:25.354] iteration 11482 : loss : 0.108614, loss_ce: 0.018707
[01:21:25.660] iteration 11483 : loss : 0.045900, loss_ce: 0.017788
[01:21:25.974] iteration 11484 : loss : 0.157834, loss_ce: 0.008960
[01:21:26.289] iteration 11485 : loss : 0.102804, loss_ce: 0.005469
[01:21:26.595] iteration 11486 : loss : 0.056933, loss_ce: 0.019101
[01:21:26.905] iteration 11487 : loss : 0.039870, loss_ce: 0.011248
[01:21:27.210] iteration 11488 : loss : 0.054700, loss_ce: 0.020105
[01:21:27.519] iteration 11489 : loss : 0.059796, loss_ce: 0.021332
[01:21:27.826] iteration 11490 : loss : 0.041934, loss_ce: 0.011892
[01:21:28.136] iteration 11491 : loss : 0.110804, loss_ce: 0.011212
[01:21:28.448] iteration 11492 : loss : 0.038958, loss_ce: 0.009821
[01:21:28.760] iteration 11493 : loss : 0.056357, loss_ce: 0.018943
[01:21:29.070] iteration 11494 : loss : 0.047466, loss_ce: 0.013068
[01:21:29.377] iteration 11495 : loss : 0.118124, loss_ce: 0.018294
[01:21:29.684] iteration 11496 : loss : 0.050437, loss_ce: 0.025995
[01:21:29.990] iteration 11497 : loss : 0.069565, loss_ce: 0.026978
[01:21:30.301] iteration 11498 : loss : 0.052031, loss_ce: 0.011413
[01:21:30.607] iteration 11499 : loss : 0.075510, loss_ce: 0.026903
[01:21:30.917] iteration 11500 : loss : 0.056629, loss_ce: 0.013156
[01:21:31.245] iteration 11501 : loss : 0.114532, loss_ce: 0.020739
[01:21:31.549] iteration 11502 : loss : 0.047643, loss_ce: 0.019992
[01:21:31.858] iteration 11503 : loss : 0.052978, loss_ce: 0.009734
[01:21:32.168] iteration 11504 : loss : 0.053872, loss_ce: 0.015898
[01:21:32.474] iteration 11505 : loss : 0.072824, loss_ce: 0.031149
[01:21:32.781] iteration 11506 : loss : 0.103827, loss_ce: 0.012971
[01:21:33.089] iteration 11507 : loss : 0.078159, loss_ce: 0.016398
[01:21:33.403] iteration 11508 : loss : 0.063493, loss_ce: 0.014933
[01:21:33.712] iteration 11509 : loss : 0.042732, loss_ce: 0.012444
[01:21:34.018] iteration 11510 : loss : 0.108956, loss_ce: 0.006721
[01:21:34.324] iteration 11511 : loss : 0.053065, loss_ce: 0.011259
[01:21:34.628] iteration 11512 : loss : 0.044989, loss_ce: 0.016016
[01:21:34.937] iteration 11513 : loss : 0.044402, loss_ce: 0.012327
[01:21:35.246] iteration 11514 : loss : 0.047780, loss_ce: 0.016166
[01:21:35.554] iteration 11515 : loss : 0.104165, loss_ce: 0.008486
[01:21:35.862] iteration 11516 : loss : 0.055367, loss_ce: 0.031701
[01:21:36.171] iteration 11517 : loss : 0.058884, loss_ce: 0.012066
[01:21:36.478] iteration 11518 : loss : 0.045702, loss_ce: 0.017485
[01:21:36.790] iteration 11519 : loss : 0.042895, loss_ce: 0.013697
[01:21:37.100] iteration 11520 : loss : 0.050156, loss_ce: 0.014791
[01:21:37.430] iteration 11521 : loss : 0.045316, loss_ce: 0.021947
[01:21:37.744] iteration 11522 : loss : 0.052110, loss_ce: 0.020428
[01:21:38.051] iteration 11523 : loss : 0.043243, loss_ce: 0.012697
[01:21:38.365] iteration 11524 : loss : 0.048346, loss_ce: 0.020426
[01:21:38.677] iteration 11525 : loss : 0.120473, loss_ce: 0.021889
[01:21:38.992] iteration 11526 : loss : 0.110221, loss_ce: 0.010114
[01:21:39.304] iteration 11527 : loss : 0.050720, loss_ce: 0.010394
[01:21:39.617] iteration 11528 : loss : 0.053505, loss_ce: 0.011938
[01:21:39.930] iteration 11529 : loss : 0.057426, loss_ce: 0.021402
[01:21:40.239] iteration 11530 : loss : 0.125783, loss_ce: 0.007569
[01:21:40.558] iteration 11531 : loss : 0.068277, loss_ce: 0.021213
[01:21:40.871] iteration 11532 : loss : 0.071821, loss_ce: 0.029167
[01:21:41.188] iteration 11533 : loss : 0.053719, loss_ce: 0.011244
[01:21:41.498] iteration 11534 : loss : 0.110092, loss_ce: 0.009784
[01:21:41.813] iteration 11535 : loss : 0.050919, loss_ce: 0.016184
[01:21:42.132] iteration 11536 : loss : 0.108596, loss_ce: 0.015904
[01:21:42.210] iteration 11537 : loss : 0.226553, loss_ce: 0.010110
[01:22:00.684] iteration 11538 : loss : 0.058375, loss_ce: 0.009547
[01:22:00.984] iteration 11539 : loss : 0.119452, loss_ce: 0.009069
[01:22:01.287] iteration 11540 : loss : 0.047600, loss_ce: 0.020695
[01:22:01.603] iteration 11541 : loss : 0.056257, loss_ce: 0.014044
[01:22:01.908] iteration 11542 : loss : 0.059089, loss_ce: 0.026957
[01:22:02.209] iteration 11543 : loss : 0.051279, loss_ce: 0.017635
[01:22:02.511] iteration 11544 : loss : 0.116032, loss_ce: 0.008391
[01:22:02.812] iteration 11545 : loss : 0.099129, loss_ce: 0.008316
[01:22:03.115] iteration 11546 : loss : 0.042057, loss_ce: 0.007584
[01:22:03.417] iteration 11547 : loss : 0.039535, loss_ce: 0.014524
[01:22:03.722] iteration 11548 : loss : 0.085553, loss_ce: 0.011851
[01:22:04.027] iteration 11549 : loss : 0.044288, loss_ce: 0.015004
[01:22:04.332] iteration 11550 : loss : 0.051734, loss_ce: 0.010062
[01:22:04.634] iteration 11551 : loss : 0.096085, loss_ce: 0.015381
[01:22:04.938] iteration 11552 : loss : 0.056494, loss_ce: 0.018377
[01:22:05.238] iteration 11553 : loss : 0.043059, loss_ce: 0.016815
[01:22:05.541] iteration 11554 : loss : 0.051762, loss_ce: 0.016637
[01:22:05.845] iteration 11555 : loss : 0.047799, loss_ce: 0.014274
[01:22:06.147] iteration 11556 : loss : 0.051767, loss_ce: 0.019576
[01:22:06.451] iteration 11557 : loss : 0.056039, loss_ce: 0.009790
[01:22:06.753] iteration 11558 : loss : 0.075755, loss_ce: 0.012099
[01:22:07.055] iteration 11559 : loss : 0.051776, loss_ce: 0.017446
[01:22:07.363] iteration 11560 : loss : 0.050939, loss_ce: 0.014182
[01:22:07.679] iteration 11561 : loss : 0.060834, loss_ce: 0.016649
[01:22:07.981] iteration 11562 : loss : 0.051028, loss_ce: 0.018027
[01:22:08.285] iteration 11563 : loss : 0.052402, loss_ce: 0.016449
[01:22:08.589] iteration 11564 : loss : 0.043828, loss_ce: 0.026818
[01:22:08.893] iteration 11565 : loss : 0.051579, loss_ce: 0.020828
[01:22:09.199] iteration 11566 : loss : 0.040214, loss_ce: 0.007479
[01:22:09.504] iteration 11567 : loss : 0.040567, loss_ce: 0.012073
[01:22:09.811] iteration 11568 : loss : 0.049080, loss_ce: 0.015557
[01:22:10.112] iteration 11569 : loss : 0.076029, loss_ce: 0.021988
[01:22:10.416] iteration 11570 : loss : 0.113647, loss_ce: 0.013835
[01:22:10.719] iteration 11571 : loss : 0.050315, loss_ce: 0.015176
[01:22:11.021] iteration 11572 : loss : 0.170024, loss_ce: 0.009319
[01:22:11.326] iteration 11573 : loss : 0.053842, loss_ce: 0.015323
[01:22:11.627] iteration 11574 : loss : 0.059256, loss_ce: 0.018061
[01:22:11.929] iteration 11575 : loss : 0.056620, loss_ce: 0.018510
[01:22:12.235] iteration 11576 : loss : 0.045177, loss_ce: 0.019583
[01:22:12.547] iteration 11577 : loss : 0.070093, loss_ce: 0.016682
[01:22:12.855] iteration 11578 : loss : 0.053145, loss_ce: 0.018233
[01:22:13.168] iteration 11579 : loss : 0.056031, loss_ce: 0.017584
[01:22:13.480] iteration 11580 : loss : 0.049036, loss_ce: 0.014380
[01:22:13.805] iteration 11581 : loss : 0.089153, loss_ce: 0.016076
[01:22:14.114] iteration 11582 : loss : 0.049488, loss_ce: 0.015879
[01:22:14.418] iteration 11583 : loss : 0.108592, loss_ce: 0.015975
[01:22:14.721] iteration 11584 : loss : 0.060339, loss_ce: 0.018839
[01:22:15.023] iteration 11585 : loss : 0.053269, loss_ce: 0.013241
[01:22:15.324] iteration 11586 : loss : 0.058440, loss_ce: 0.009987
[01:22:15.628] iteration 11587 : loss : 0.050736, loss_ce: 0.018981
[01:22:15.929] iteration 11588 : loss : 0.060568, loss_ce: 0.013714
[01:22:16.237] iteration 11589 : loss : 0.056835, loss_ce: 0.017887
[01:22:16.540] iteration 11590 : loss : 0.119782, loss_ce: 0.011407
[01:22:16.842] iteration 11591 : loss : 0.074898, loss_ce: 0.013058
[01:22:17.148] iteration 11592 : loss : 0.074966, loss_ce: 0.024789
[01:22:17.449] iteration 11593 : loss : 0.069944, loss_ce: 0.012370
[01:22:17.756] iteration 11594 : loss : 0.046388, loss_ce: 0.019386
[01:22:18.060] iteration 11595 : loss : 0.048400, loss_ce: 0.011385
[01:22:18.362] iteration 11596 : loss : 0.042114, loss_ce: 0.016452
[01:22:18.665] iteration 11597 : loss : 0.048102, loss_ce: 0.013138
[01:22:18.970] iteration 11598 : loss : 0.070637, loss_ce: 0.019676
[01:22:19.273] iteration 11599 : loss : 0.049864, loss_ce: 0.015363
[01:22:19.574] iteration 11600 : loss : 0.048637, loss_ce: 0.020272
[01:22:19.891] iteration 11601 : loss : 0.059229, loss_ce: 0.013405
[01:22:20.194] iteration 11602 : loss : 0.047611, loss_ce: 0.008919
[01:22:20.498] iteration 11603 : loss : 0.056844, loss_ce: 0.013464
[01:22:20.802] iteration 11604 : loss : 0.055958, loss_ce: 0.024568
[01:22:21.106] iteration 11605 : loss : 0.043938, loss_ce: 0.014964
[01:22:21.412] iteration 11606 : loss : 0.054115, loss_ce: 0.011621
[01:22:21.720] iteration 11607 : loss : 0.117858, loss_ce: 0.011945
[01:22:22.025] iteration 11608 : loss : 0.047032, loss_ce: 0.011691
[01:22:22.327] iteration 11609 : loss : 0.218427, loss_ce: 0.003662
[01:22:22.633] iteration 11610 : loss : 0.119594, loss_ce: 0.015003
[01:22:22.936] iteration 11611 : loss : 0.059789, loss_ce: 0.010785
[01:22:23.239] iteration 11612 : loss : 0.053924, loss_ce: 0.025158
[01:22:23.542] iteration 11613 : loss : 0.044974, loss_ce: 0.016268
[01:22:23.847] iteration 11614 : loss : 0.071825, loss_ce: 0.016616
[01:22:24.152] iteration 11615 : loss : 0.042738, loss_ce: 0.008973
[01:22:24.452] iteration 11616 : loss : 0.044799, loss_ce: 0.014883
[01:22:24.754] iteration 11617 : loss : 0.046917, loss_ce: 0.009426
[01:22:25.059] iteration 11618 : loss : 0.042081, loss_ce: 0.015260
[01:22:25.363] iteration 11619 : loss : 0.056569, loss_ce: 0.014732
[01:22:25.670] iteration 11620 : loss : 0.049678, loss_ce: 0.017073
[01:22:25.991] iteration 11621 : loss : 0.048908, loss_ce: 0.020627
[01:22:26.294] iteration 11622 : loss : 0.043888, loss_ce: 0.016044
[01:22:26.598] iteration 11623 : loss : 0.047435, loss_ce: 0.019226
[01:22:26.900] iteration 11624 : loss : 0.052559, loss_ce: 0.017323
[01:22:27.206] iteration 11625 : loss : 0.045098, loss_ce: 0.017473
[01:22:27.513] iteration 11626 : loss : 0.107697, loss_ce: 0.011231
[01:22:27.819] iteration 11627 : loss : 0.047302, loss_ce: 0.009501
[01:22:28.126] iteration 11628 : loss : 0.104736, loss_ce: 0.012851
[01:22:28.430] iteration 11629 : loss : 0.109304, loss_ce: 0.008036
[01:22:28.736] iteration 11630 : loss : 0.112021, loss_ce: 0.018765
[01:22:29.047] iteration 11631 : loss : 0.121602, loss_ce: 0.010350
[01:22:29.350] iteration 11632 : loss : 0.050079, loss_ce: 0.021232
[01:22:29.657] iteration 11633 : loss : 0.052126, loss_ce: 0.018144
[01:22:29.963] iteration 11634 : loss : 0.053790, loss_ce: 0.019013
[01:22:30.275] iteration 11635 : loss : 0.054880, loss_ce: 0.020469
[01:22:30.582] iteration 11636 : loss : 0.059956, loss_ce: 0.027603
[01:22:30.890] iteration 11637 : loss : 0.108906, loss_ce: 0.015693
[01:22:31.203] iteration 11638 : loss : 0.104214, loss_ce: 0.013556
[01:22:31.516] iteration 11639 : loss : 0.063857, loss_ce: 0.009677
[01:22:31.824] iteration 11640 : loss : 0.053525, loss_ce: 0.016577
[01:22:32.150] iteration 11641 : loss : 0.045920, loss_ce: 0.018550
[01:22:32.466] iteration 11642 : loss : 0.057427, loss_ce: 0.021124
[01:22:32.776] iteration 11643 : loss : 0.043127, loss_ce: 0.008600
[01:22:33.085] iteration 11644 : loss : 0.057480, loss_ce: 0.015097
[01:22:33.395] iteration 11645 : loss : 0.120873, loss_ce: 0.005662
[01:22:33.704] iteration 11646 : loss : 0.103794, loss_ce: 0.008018
[01:22:34.012] iteration 11647 : loss : 0.059049, loss_ce: 0.010211
[01:22:34.320] iteration 11648 : loss : 0.060425, loss_ce: 0.020648
[01:22:34.630] iteration 11649 : loss : 0.069744, loss_ce: 0.014186
[01:22:34.937] iteration 11650 : loss : 0.046205, loss_ce: 0.016441
[01:22:35.246] iteration 11651 : loss : 0.080961, loss_ce: 0.015297
[01:22:35.555] iteration 11652 : loss : 0.101714, loss_ce: 0.010783
[01:22:35.859] iteration 11653 : loss : 0.050260, loss_ce: 0.015430
[01:22:36.168] iteration 11654 : loss : 0.095592, loss_ce: 0.009149
[01:22:36.477] iteration 11655 : loss : 0.040731, loss_ce: 0.012339
[01:22:36.787] iteration 11656 : loss : 0.118876, loss_ce: 0.014034
[01:22:37.095] iteration 11657 : loss : 0.051432, loss_ce: 0.017404
[01:22:37.407] iteration 11658 : loss : 0.098653, loss_ce: 0.011045
[01:22:37.712] iteration 11659 : loss : 0.050891, loss_ce: 0.022066
[01:22:38.022] iteration 11660 : loss : 0.088432, loss_ce: 0.013311
[01:22:38.354] iteration 11661 : loss : 0.046921, loss_ce: 0.022691
[01:22:38.662] iteration 11662 : loss : 0.043452, loss_ce: 0.007245
[01:22:38.972] iteration 11663 : loss : 0.042369, loss_ce: 0.009248
[01:22:39.291] iteration 11664 : loss : 0.233682, loss_ce: 0.005806
[01:22:39.602] iteration 11665 : loss : 0.051333, loss_ce: 0.024840
[01:22:39.917] iteration 11666 : loss : 0.058507, loss_ce: 0.015994
[01:22:40.233] iteration 11667 : loss : 0.069249, loss_ce: 0.030585
[01:22:40.542] iteration 11668 : loss : 0.119297, loss_ce: 0.019990
[01:22:40.850] iteration 11669 : loss : 0.074586, loss_ce: 0.027986
[01:22:41.162] iteration 11670 : loss : 0.057522, loss_ce: 0.015881
[01:22:41.473] iteration 11671 : loss : 0.041522, loss_ce: 0.011637
[01:22:41.783] iteration 11672 : loss : 0.056144, loss_ce: 0.010563
[01:22:42.095] iteration 11673 : loss : 0.054372, loss_ce: 0.013779
[01:22:42.407] iteration 11674 : loss : 0.062134, loss_ce: 0.013921
[01:22:42.723] iteration 11675 : loss : 0.052959, loss_ce: 0.017778
[01:22:42.808] iteration 11676 : loss : 0.156314, loss_ce: 0.000022
[01:23:00.980] iteration 11677 : loss : 0.049267, loss_ce: 0.016282
[01:23:01.279] iteration 11678 : loss : 0.100708, loss_ce: 0.011477
[01:23:01.581] iteration 11679 : loss : 0.227581, loss_ce: 0.008043
[01:23:01.884] iteration 11680 : loss : 0.051561, loss_ce: 0.020297
[01:23:02.207] iteration 11681 : loss : 0.119077, loss_ce: 0.009798
[01:23:02.513] iteration 11682 : loss : 0.058788, loss_ce: 0.027312
[01:23:02.818] iteration 11683 : loss : 0.066487, loss_ce: 0.022141
[01:23:03.126] iteration 11684 : loss : 0.116687, loss_ce: 0.012613
[01:23:03.438] iteration 11685 : loss : 0.063636, loss_ce: 0.015644
[01:23:03.747] iteration 11686 : loss : 0.062292, loss_ce: 0.023418
[01:23:04.059] iteration 11687 : loss : 0.127910, loss_ce: 0.022596
[01:23:04.364] iteration 11688 : loss : 0.056121, loss_ce: 0.018091
[01:23:04.671] iteration 11689 : loss : 0.080514, loss_ce: 0.058241
[01:23:04.978] iteration 11690 : loss : 0.054205, loss_ce: 0.014056
[01:23:05.280] iteration 11691 : loss : 0.088845, loss_ce: 0.011819
[01:23:05.588] iteration 11692 : loss : 0.060450, loss_ce: 0.018287
[01:23:05.893] iteration 11693 : loss : 0.043682, loss_ce: 0.015817
[01:23:06.198] iteration 11694 : loss : 0.049593, loss_ce: 0.014794
[01:23:06.498] iteration 11695 : loss : 0.050787, loss_ce: 0.014369
[01:23:06.807] iteration 11696 : loss : 0.055483, loss_ce: 0.020172
[01:23:07.113] iteration 11697 : loss : 0.059000, loss_ce: 0.017602
[01:23:07.417] iteration 11698 : loss : 0.043816, loss_ce: 0.014555
[01:23:07.720] iteration 11699 : loss : 0.042114, loss_ce: 0.011448
[01:23:08.023] iteration 11700 : loss : 0.107905, loss_ce: 0.017590
[01:23:08.350] iteration 11701 : loss : 0.101204, loss_ce: 0.006939
[01:23:08.652] iteration 11702 : loss : 0.049414, loss_ce: 0.016440
[01:23:08.957] iteration 11703 : loss : 0.107624, loss_ce: 0.017809
[01:23:09.262] iteration 11704 : loss : 0.059458, loss_ce: 0.016703
[01:23:09.568] iteration 11705 : loss : 0.148376, loss_ce: 0.011104
[01:23:09.872] iteration 11706 : loss : 0.058062, loss_ce: 0.012520
[01:23:10.182] iteration 11707 : loss : 0.057137, loss_ce: 0.019536
[01:23:10.487] iteration 11708 : loss : 0.164616, loss_ce: 0.006290
[01:23:10.793] iteration 11709 : loss : 0.044445, loss_ce: 0.016562
[01:23:11.100] iteration 11710 : loss : 0.075272, loss_ce: 0.014586
[01:23:11.405] iteration 11711 : loss : 0.067785, loss_ce: 0.022941
[01:23:11.710] iteration 11712 : loss : 0.066237, loss_ce: 0.020430
[01:23:12.012] iteration 11713 : loss : 0.095668, loss_ce: 0.006978
[01:23:12.320] iteration 11714 : loss : 0.066321, loss_ce: 0.016606
[01:23:12.626] iteration 11715 : loss : 0.113883, loss_ce: 0.017241
[01:23:12.930] iteration 11716 : loss : 0.065935, loss_ce: 0.017887
[01:23:13.236] iteration 11717 : loss : 0.079031, loss_ce: 0.017680
[01:23:13.542] iteration 11718 : loss : 0.077579, loss_ce: 0.016681
[01:23:13.849] iteration 11719 : loss : 0.039001, loss_ce: 0.012006
[01:23:14.155] iteration 11720 : loss : 0.063564, loss_ce: 0.022051
[01:23:14.481] iteration 11721 : loss : 0.049219, loss_ce: 0.014693
[01:23:14.790] iteration 11722 : loss : 0.069129, loss_ce: 0.028222
[01:23:15.100] iteration 11723 : loss : 0.101679, loss_ce: 0.018468
[01:23:15.407] iteration 11724 : loss : 0.065564, loss_ce: 0.015138
[01:23:15.712] iteration 11725 : loss : 0.058668, loss_ce: 0.027196
[01:23:16.015] iteration 11726 : loss : 0.083452, loss_ce: 0.027665
[01:23:16.325] iteration 11727 : loss : 0.053905, loss_ce: 0.018525
[01:23:16.628] iteration 11728 : loss : 0.045897, loss_ce: 0.011669
[01:23:16.934] iteration 11729 : loss : 0.059043, loss_ce: 0.013570
[01:23:17.244] iteration 11730 : loss : 0.055159, loss_ce: 0.014479
[01:23:17.552] iteration 11731 : loss : 0.061666, loss_ce: 0.021284
[01:23:17.866] iteration 11732 : loss : 0.049004, loss_ce: 0.021524
[01:23:18.177] iteration 11733 : loss : 0.064372, loss_ce: 0.016804
[01:23:18.487] iteration 11734 : loss : 0.073992, loss_ce: 0.017095
[01:23:18.797] iteration 11735 : loss : 0.056311, loss_ce: 0.017015
[01:23:19.109] iteration 11736 : loss : 0.043328, loss_ce: 0.015188
[01:23:19.415] iteration 11737 : loss : 0.069964, loss_ce: 0.025836
[01:23:19.717] iteration 11738 : loss : 0.062967, loss_ce: 0.022675
[01:23:20.024] iteration 11739 : loss : 0.119213, loss_ce: 0.010482
[01:23:20.327] iteration 11740 : loss : 0.051455, loss_ce: 0.014066
[01:23:20.643] iteration 11741 : loss : 0.077175, loss_ce: 0.014967
[01:23:20.947] iteration 11742 : loss : 0.051049, loss_ce: 0.012359
[01:23:21.256] iteration 11743 : loss : 0.052894, loss_ce: 0.015918
[01:23:21.558] iteration 11744 : loss : 0.062209, loss_ce: 0.019768
[01:23:21.865] iteration 11745 : loss : 0.046266, loss_ce: 0.017817
[01:23:22.174] iteration 11746 : loss : 0.052982, loss_ce: 0.021546
[01:23:22.478] iteration 11747 : loss : 0.050557, loss_ce: 0.011031
[01:23:22.781] iteration 11748 : loss : 0.049734, loss_ce: 0.015112
[01:23:23.087] iteration 11749 : loss : 0.062816, loss_ce: 0.012168
[01:23:23.391] iteration 11750 : loss : 0.107947, loss_ce: 0.009785
[01:23:23.692] iteration 11751 : loss : 0.227927, loss_ce: 0.009320
[01:23:23.997] iteration 11752 : loss : 0.050757, loss_ce: 0.019052
[01:23:24.298] iteration 11753 : loss : 0.059720, loss_ce: 0.019563
[01:23:24.600] iteration 11754 : loss : 0.097582, loss_ce: 0.011965
[01:23:24.906] iteration 11755 : loss : 0.120132, loss_ce: 0.015025
[01:23:25.209] iteration 11756 : loss : 0.059167, loss_ce: 0.011028
[01:23:25.513] iteration 11757 : loss : 0.043741, loss_ce: 0.007194
[01:23:25.816] iteration 11758 : loss : 0.056745, loss_ce: 0.018821
[01:23:26.122] iteration 11759 : loss : 0.118640, loss_ce: 0.014740
[01:23:26.425] iteration 11760 : loss : 0.065372, loss_ce: 0.015389
[01:23:26.746] iteration 11761 : loss : 0.055643, loss_ce: 0.028820
[01:23:27.051] iteration 11762 : loss : 0.047558, loss_ce: 0.019734
[01:23:27.360] iteration 11763 : loss : 0.052504, loss_ce: 0.017751
[01:23:27.664] iteration 11764 : loss : 0.069091, loss_ce: 0.027484
[01:23:27.967] iteration 11765 : loss : 0.056497, loss_ce: 0.016911
[01:23:28.270] iteration 11766 : loss : 0.063178, loss_ce: 0.014206
[01:23:28.575] iteration 11767 : loss : 0.046687, loss_ce: 0.010704
[01:23:28.879] iteration 11768 : loss : 0.057454, loss_ce: 0.013572
[01:23:29.184] iteration 11769 : loss : 0.111294, loss_ce: 0.011653
[01:23:29.487] iteration 11770 : loss : 0.103454, loss_ce: 0.014869
[01:23:29.790] iteration 11771 : loss : 0.058037, loss_ce: 0.011807
[01:23:30.091] iteration 11772 : loss : 0.058684, loss_ce: 0.011757
[01:23:30.396] iteration 11773 : loss : 0.041426, loss_ce: 0.019484
[01:23:30.701] iteration 11774 : loss : 0.117210, loss_ce: 0.012642
[01:23:31.006] iteration 11775 : loss : 0.053759, loss_ce: 0.019656
[01:23:31.309] iteration 11776 : loss : 0.038396, loss_ce: 0.014878
[01:23:31.618] iteration 11777 : loss : 0.049889, loss_ce: 0.023069
[01:23:31.923] iteration 11778 : loss : 0.049408, loss_ce: 0.014022
[01:23:32.228] iteration 11779 : loss : 0.048617, loss_ce: 0.018768
[01:23:32.535] iteration 11780 : loss : 0.047117, loss_ce: 0.009105
[01:23:32.860] iteration 11781 : loss : 0.235885, loss_ce: 0.003907
[01:23:33.165] iteration 11782 : loss : 0.053740, loss_ce: 0.016694
[01:23:33.475] iteration 11783 : loss : 0.044289, loss_ce: 0.012682
[01:23:33.783] iteration 11784 : loss : 0.069060, loss_ce: 0.015276
[01:23:34.095] iteration 11785 : loss : 0.058283, loss_ce: 0.023593
[01:23:34.402] iteration 11786 : loss : 0.060094, loss_ce: 0.015635
[01:23:34.707] iteration 11787 : loss : 0.079971, loss_ce: 0.011796
[01:23:35.012] iteration 11788 : loss : 0.045139, loss_ce: 0.011749
[01:23:35.314] iteration 11789 : loss : 0.117304, loss_ce: 0.009062
[01:23:35.619] iteration 11790 : loss : 0.066707, loss_ce: 0.019169
[01:23:35.924] iteration 11791 : loss : 0.048061, loss_ce: 0.012873
[01:23:36.226] iteration 11792 : loss : 0.059953, loss_ce: 0.014437
[01:23:36.533] iteration 11793 : loss : 0.061783, loss_ce: 0.013645
[01:23:36.835] iteration 11794 : loss : 0.060804, loss_ce: 0.012014
[01:23:37.142] iteration 11795 : loss : 0.049128, loss_ce: 0.018553
[01:23:37.445] iteration 11796 : loss : 0.059802, loss_ce: 0.010525
[01:23:37.752] iteration 11797 : loss : 0.064388, loss_ce: 0.013370
[01:23:38.051] iteration 11798 : loss : 0.054291, loss_ce: 0.015764
[01:23:38.359] iteration 11799 : loss : 0.073584, loss_ce: 0.022167
[01:23:38.666] iteration 11800 : loss : 0.156566, loss_ce: 0.007058
[01:23:38.993] iteration 11801 : loss : 0.058339, loss_ce: 0.019242
[01:23:39.302] iteration 11802 : loss : 0.074787, loss_ce: 0.022723
[01:23:39.612] iteration 11803 : loss : 0.058770, loss_ce: 0.019557
[01:23:39.921] iteration 11804 : loss : 0.042632, loss_ce: 0.011058
[01:23:40.229] iteration 11805 : loss : 0.048661, loss_ce: 0.020137
[01:23:40.539] iteration 11806 : loss : 0.066568, loss_ce: 0.015109
[01:23:40.847] iteration 11807 : loss : 0.052096, loss_ce: 0.011234
[01:23:41.154] iteration 11808 : loss : 0.056681, loss_ce: 0.022774
[01:23:41.466] iteration 11809 : loss : 0.054020, loss_ce: 0.022026
[01:23:41.769] iteration 11810 : loss : 0.047876, loss_ce: 0.020411
[01:23:42.076] iteration 11811 : loss : 0.048346, loss_ce: 0.011776
[01:23:42.385] iteration 11812 : loss : 0.222518, loss_ce: 0.005324
[01:23:42.691] iteration 11813 : loss : 0.056272, loss_ce: 0.022343
[01:23:43.000] iteration 11814 : loss : 0.056882, loss_ce: 0.020918
[01:23:43.085] iteration 11815 : loss : 0.071832, loss_ce: 0.022758
[01:24:01.033] iteration 11816 : loss : 0.048925, loss_ce: 0.016075
[01:24:01.340] iteration 11817 : loss : 0.102605, loss_ce: 0.006463
[01:24:01.649] iteration 11818 : loss : 0.043044, loss_ce: 0.010196
[01:24:01.958] iteration 11819 : loss : 0.048040, loss_ce: 0.013711
[01:24:02.268] iteration 11820 : loss : 0.060073, loss_ce: 0.011588
[01:24:02.589] iteration 11821 : loss : 0.155049, loss_ce: 0.009297
[01:24:02.894] iteration 11822 : loss : 0.050717, loss_ce: 0.021074
[01:24:03.205] iteration 11823 : loss : 0.043684, loss_ce: 0.014117
[01:24:03.511] iteration 11824 : loss : 0.059508, loss_ce: 0.016881
[01:24:03.818] iteration 11825 : loss : 0.052363, loss_ce: 0.022538
[01:24:04.126] iteration 11826 : loss : 0.036885, loss_ce: 0.010601
[01:24:04.432] iteration 11827 : loss : 0.113319, loss_ce: 0.011614
[01:24:04.743] iteration 11828 : loss : 0.054930, loss_ce: 0.011700
[01:24:05.047] iteration 11829 : loss : 0.230484, loss_ce: 0.008539
[01:24:05.353] iteration 11830 : loss : 0.107219, loss_ce: 0.012253
[01:24:05.667] iteration 11831 : loss : 0.055823, loss_ce: 0.022387
[01:24:05.972] iteration 11832 : loss : 0.037902, loss_ce: 0.014805
[01:24:06.277] iteration 11833 : loss : 0.064967, loss_ce: 0.016109
[01:24:06.586] iteration 11834 : loss : 0.080587, loss_ce: 0.008703
[01:24:06.896] iteration 11835 : loss : 0.044949, loss_ce: 0.011385
[01:24:07.204] iteration 11836 : loss : 0.056665, loss_ce: 0.020362
[01:24:07.513] iteration 11837 : loss : 0.043325, loss_ce: 0.016287
[01:24:07.820] iteration 11838 : loss : 0.104666, loss_ce: 0.014092
[01:24:08.129] iteration 11839 : loss : 0.051373, loss_ce: 0.014384
[01:24:08.437] iteration 11840 : loss : 0.040194, loss_ce: 0.009290
[01:24:08.759] iteration 11841 : loss : 0.046802, loss_ce: 0.012231
[01:24:09.070] iteration 11842 : loss : 0.044784, loss_ce: 0.015750
[01:24:09.376] iteration 11843 : loss : 0.041603, loss_ce: 0.013278
[01:24:09.676] iteration 11844 : loss : 0.228884, loss_ce: 0.010206
[01:24:09.980] iteration 11845 : loss : 0.054819, loss_ce: 0.018373
[01:24:10.282] iteration 11846 : loss : 0.059578, loss_ce: 0.017768
[01:24:10.584] iteration 11847 : loss : 0.041429, loss_ce: 0.014116
[01:24:10.888] iteration 11848 : loss : 0.049392, loss_ce: 0.015945
[01:24:11.192] iteration 11849 : loss : 0.058371, loss_ce: 0.018671
[01:24:11.493] iteration 11850 : loss : 0.045100, loss_ce: 0.012564
[01:24:11.797] iteration 11851 : loss : 0.048376, loss_ce: 0.008954
[01:24:12.098] iteration 11852 : loss : 0.046608, loss_ce: 0.023066
[01:24:12.400] iteration 11853 : loss : 0.054966, loss_ce: 0.020872
[01:24:12.705] iteration 11854 : loss : 0.107711, loss_ce: 0.015618
[01:24:13.009] iteration 11855 : loss : 0.055727, loss_ce: 0.024055
[01:24:13.314] iteration 11856 : loss : 0.065534, loss_ce: 0.018841
[01:24:13.617] iteration 11857 : loss : 0.049766, loss_ce: 0.017231
[01:24:13.919] iteration 11858 : loss : 0.108146, loss_ce: 0.018299
[01:24:14.221] iteration 11859 : loss : 0.093190, loss_ce: 0.013801
[01:24:14.526] iteration 11860 : loss : 0.132132, loss_ce: 0.012850
[01:24:14.844] iteration 11861 : loss : 0.048930, loss_ce: 0.014798
[01:24:15.147] iteration 11862 : loss : 0.042733, loss_ce: 0.014424
[01:24:15.452] iteration 11863 : loss : 0.043962, loss_ce: 0.014236
[01:24:15.751] iteration 11864 : loss : 0.098521, loss_ce: 0.007499
[01:24:16.054] iteration 11865 : loss : 0.104917, loss_ce: 0.014859
[01:24:16.355] iteration 11866 : loss : 0.066314, loss_ce: 0.015209
[01:24:16.658] iteration 11867 : loss : 0.063246, loss_ce: 0.008152
[01:24:16.959] iteration 11868 : loss : 0.069195, loss_ce: 0.020360
[01:24:17.264] iteration 11869 : loss : 0.072935, loss_ce: 0.016064
[01:24:17.568] iteration 11870 : loss : 0.060221, loss_ce: 0.020756
[01:24:17.872] iteration 11871 : loss : 0.073261, loss_ce: 0.011968
[01:24:18.175] iteration 11872 : loss : 0.055668, loss_ce: 0.016008
[01:24:18.477] iteration 11873 : loss : 0.046358, loss_ce: 0.018790
[01:24:18.778] iteration 11874 : loss : 0.279435, loss_ce: 0.001486
[01:24:19.084] iteration 11875 : loss : 0.114072, loss_ce: 0.022919
[01:24:19.385] iteration 11876 : loss : 0.052968, loss_ce: 0.015502
[01:24:19.687] iteration 11877 : loss : 0.055036, loss_ce: 0.018576
[01:24:19.992] iteration 11878 : loss : 0.040795, loss_ce: 0.018028
[01:24:20.295] iteration 11879 : loss : 0.106128, loss_ce: 0.018423
[01:24:20.597] iteration 11880 : loss : 0.101222, loss_ce: 0.008429
[01:24:20.914] iteration 11881 : loss : 0.049438, loss_ce: 0.021648
[01:24:21.221] iteration 11882 : loss : 0.044044, loss_ce: 0.011248
[01:24:21.527] iteration 11883 : loss : 0.042718, loss_ce: 0.009501
[01:24:21.831] iteration 11884 : loss : 0.055108, loss_ce: 0.015405
[01:24:22.135] iteration 11885 : loss : 0.045301, loss_ce: 0.017152
[01:24:22.443] iteration 11886 : loss : 0.059484, loss_ce: 0.007286
[01:24:22.756] iteration 11887 : loss : 0.049985, loss_ce: 0.011531
[01:24:23.064] iteration 11888 : loss : 0.061821, loss_ce: 0.019372
[01:24:23.374] iteration 11889 : loss : 0.048399, loss_ce: 0.015176
[01:24:23.686] iteration 11890 : loss : 0.064358, loss_ce: 0.012720
[01:24:23.996] iteration 11891 : loss : 0.104532, loss_ce: 0.007021
[01:24:24.304] iteration 11892 : loss : 0.102541, loss_ce: 0.004148
[01:24:24.606] iteration 11893 : loss : 0.101290, loss_ce: 0.012703
[01:24:24.911] iteration 11894 : loss : 0.070072, loss_ce: 0.010905
[01:24:25.212] iteration 11895 : loss : 0.052104, loss_ce: 0.012021
[01:24:25.516] iteration 11896 : loss : 0.043187, loss_ce: 0.013609
[01:24:25.819] iteration 11897 : loss : 0.071961, loss_ce: 0.015418
[01:24:26.122] iteration 11898 : loss : 0.046460, loss_ce: 0.014522
[01:24:26.426] iteration 11899 : loss : 0.108377, loss_ce: 0.010357
[01:24:26.730] iteration 11900 : loss : 0.053815, loss_ce: 0.019247
[01:24:27.056] iteration 11901 : loss : 0.045096, loss_ce: 0.019108
[01:24:27.358] iteration 11902 : loss : 0.039977, loss_ce: 0.016067
[01:24:27.665] iteration 11903 : loss : 0.115605, loss_ce: 0.009650
[01:24:27.972] iteration 11904 : loss : 0.149666, loss_ce: 0.017926
[01:24:28.274] iteration 11905 : loss : 0.050551, loss_ce: 0.021529
[01:24:28.579] iteration 11906 : loss : 0.049190, loss_ce: 0.015555
[01:24:28.883] iteration 11907 : loss : 0.123868, loss_ce: 0.008045
[01:24:29.187] iteration 11908 : loss : 0.114014, loss_ce: 0.010806
[01:24:29.489] iteration 11909 : loss : 0.056783, loss_ce: 0.029535
[01:24:29.794] iteration 11910 : loss : 0.113219, loss_ce: 0.012545
[01:24:30.096] iteration 11911 : loss : 0.116713, loss_ce: 0.008807
[01:24:30.403] iteration 11912 : loss : 0.077777, loss_ce: 0.022118
[01:24:30.706] iteration 11913 : loss : 0.123583, loss_ce: 0.016690
[01:24:31.009] iteration 11914 : loss : 0.044323, loss_ce: 0.011635
[01:24:31.312] iteration 11915 : loss : 0.055681, loss_ce: 0.010888
[01:24:31.611] iteration 11916 : loss : 0.042432, loss_ce: 0.010927
[01:24:31.914] iteration 11917 : loss : 0.050487, loss_ce: 0.019673
[01:24:32.217] iteration 11918 : loss : 0.047152, loss_ce: 0.011659
[01:24:32.521] iteration 11919 : loss : 0.054136, loss_ce: 0.018354
[01:24:32.823] iteration 11920 : loss : 0.052379, loss_ce: 0.015997
[01:24:33.146] iteration 11921 : loss : 0.058130, loss_ce: 0.018657
[01:24:33.449] iteration 11922 : loss : 0.110488, loss_ce: 0.010162
[01:24:33.752] iteration 11923 : loss : 0.050725, loss_ce: 0.016294
[01:24:34.058] iteration 11924 : loss : 0.049965, loss_ce: 0.020287
[01:24:34.363] iteration 11925 : loss : 0.044174, loss_ce: 0.020787
[01:24:34.666] iteration 11926 : loss : 0.057362, loss_ce: 0.026523
[01:24:34.971] iteration 11927 : loss : 0.054899, loss_ce: 0.015423
[01:24:35.274] iteration 11928 : loss : 0.060459, loss_ce: 0.014169
[01:24:35.581] iteration 11929 : loss : 0.053594, loss_ce: 0.011161
[01:24:35.885] iteration 11930 : loss : 0.049535, loss_ce: 0.006171
[01:24:36.187] iteration 11931 : loss : 0.107883, loss_ce: 0.006790
[01:24:36.490] iteration 11932 : loss : 0.076840, loss_ce: 0.011974
[01:24:36.790] iteration 11933 : loss : 0.110424, loss_ce: 0.012978
[01:24:37.093] iteration 11934 : loss : 0.049979, loss_ce: 0.014672
[01:24:37.399] iteration 11935 : loss : 0.061655, loss_ce: 0.018014
[01:24:37.705] iteration 11936 : loss : 0.104167, loss_ce: 0.011800
[01:24:38.007] iteration 11937 : loss : 0.071894, loss_ce: 0.019493
[01:24:38.319] iteration 11938 : loss : 0.056022, loss_ce: 0.020520
[01:24:38.630] iteration 11939 : loss : 0.052689, loss_ce: 0.024913
[01:24:38.940] iteration 11940 : loss : 0.056750, loss_ce: 0.015244
[01:24:39.266] iteration 11941 : loss : 0.063247, loss_ce: 0.015919
[01:24:39.574] iteration 11942 : loss : 0.045773, loss_ce: 0.009799
[01:24:39.887] iteration 11943 : loss : 0.065546, loss_ce: 0.022966
[01:24:40.206] iteration 11944 : loss : 0.061615, loss_ce: 0.019885
[01:24:40.515] iteration 11945 : loss : 0.113986, loss_ce: 0.024373
[01:24:40.825] iteration 11946 : loss : 0.042924, loss_ce: 0.013960
[01:24:41.141] iteration 11947 : loss : 0.060707, loss_ce: 0.020916
[01:24:41.448] iteration 11948 : loss : 0.059743, loss_ce: 0.024637
[01:24:41.762] iteration 11949 : loss : 0.068244, loss_ce: 0.025717
[01:24:42.072] iteration 11950 : loss : 0.059405, loss_ce: 0.025111
[01:24:42.381] iteration 11951 : loss : 0.101863, loss_ce: 0.011683
[01:24:42.696] iteration 11952 : loss : 0.047200, loss_ce: 0.017258
[01:24:43.004] iteration 11953 : loss : 0.115495, loss_ce: 0.011506
[01:24:43.083] iteration 11954 : loss : 0.256570, loss_ce: 0.005812
[01:25:00.655] iteration 11955 : loss : 0.070696, loss_ce: 0.017006
[01:25:00.956] iteration 11956 : loss : 0.057864, loss_ce: 0.019027
[01:25:01.256] iteration 11957 : loss : 0.051523, loss_ce: 0.016968
[01:25:01.563] iteration 11958 : loss : 0.040175, loss_ce: 0.012761
[01:25:01.863] iteration 11959 : loss : 0.053138, loss_ce: 0.011415
[01:25:02.169] iteration 11960 : loss : 0.107185, loss_ce: 0.010071
[01:25:02.491] iteration 11961 : loss : 0.168548, loss_ce: 0.012333
[01:25:02.794] iteration 11962 : loss : 0.051672, loss_ce: 0.015824
[01:25:03.100] iteration 11963 : loss : 0.103499, loss_ce: 0.008071
[01:25:03.405] iteration 11964 : loss : 0.062479, loss_ce: 0.010956
[01:25:03.708] iteration 11965 : loss : 0.046351, loss_ce: 0.019392
[01:25:04.015] iteration 11966 : loss : 0.037297, loss_ce: 0.011464
[01:25:04.318] iteration 11967 : loss : 0.048938, loss_ce: 0.017664
[01:25:04.626] iteration 11968 : loss : 0.044900, loss_ce: 0.012342
[01:25:04.935] iteration 11969 : loss : 0.074127, loss_ce: 0.015276
[01:25:05.241] iteration 11970 : loss : 0.048090, loss_ce: 0.016752
[01:25:05.544] iteration 11971 : loss : 0.076561, loss_ce: 0.022682
[01:25:05.850] iteration 11972 : loss : 0.108735, loss_ce: 0.012919
[01:25:06.158] iteration 11973 : loss : 0.051694, loss_ce: 0.016903
[01:25:06.465] iteration 11974 : loss : 0.058010, loss_ce: 0.010569
[01:25:06.769] iteration 11975 : loss : 0.054202, loss_ce: 0.017699
[01:25:07.073] iteration 11976 : loss : 0.050609, loss_ce: 0.022418
[01:25:07.380] iteration 11977 : loss : 0.058523, loss_ce: 0.017716
[01:25:07.685] iteration 11978 : loss : 0.057008, loss_ce: 0.015600
[01:25:07.993] iteration 11979 : loss : 0.046734, loss_ce: 0.019063
[01:25:08.305] iteration 11980 : loss : 0.039214, loss_ce: 0.014462
[01:25:08.633] iteration 11981 : loss : 0.050988, loss_ce: 0.008285
[01:25:08.938] iteration 11982 : loss : 0.065109, loss_ce: 0.018690
[01:25:09.252] iteration 11983 : loss : 0.045211, loss_ce: 0.009626
[01:25:09.556] iteration 11984 : loss : 0.051769, loss_ce: 0.014467
[01:25:09.863] iteration 11985 : loss : 0.056402, loss_ce: 0.017885
[01:25:10.172] iteration 11986 : loss : 0.041339, loss_ce: 0.015330
[01:25:10.473] iteration 11987 : loss : 0.049868, loss_ce: 0.021104
[01:25:10.779] iteration 11988 : loss : 0.059038, loss_ce: 0.009646
[01:25:11.087] iteration 11989 : loss : 0.063734, loss_ce: 0.009934
[01:25:11.393] iteration 11990 : loss : 0.045966, loss_ce: 0.019150
[01:25:11.698] iteration 11991 : loss : 0.040648, loss_ce: 0.006887
[01:25:12.004] iteration 11992 : loss : 0.047249, loss_ce: 0.019757
[01:25:12.316] iteration 11993 : loss : 0.039773, loss_ce: 0.016453
[01:25:12.630] iteration 11994 : loss : 0.040215, loss_ce: 0.018701
[01:25:12.943] iteration 11995 : loss : 0.051080, loss_ce: 0.019609
[01:25:13.253] iteration 11996 : loss : 0.063409, loss_ce: 0.016515
[01:25:13.567] iteration 11997 : loss : 0.055981, loss_ce: 0.014768
[01:25:13.879] iteration 11998 : loss : 0.050829, loss_ce: 0.018770
[01:25:14.187] iteration 11999 : loss : 0.096012, loss_ce: 0.022032
[01:25:14.495] iteration 12000 : loss : 0.043773, loss_ce: 0.011508
[01:25:14.813] iteration 12001 : loss : 0.058327, loss_ce: 0.016289
[01:25:15.115] iteration 12002 : loss : 0.101154, loss_ce: 0.011233
[01:25:15.425] iteration 12003 : loss : 0.208387, loss_ce: 0.011881
[01:25:15.730] iteration 12004 : loss : 0.049462, loss_ce: 0.009973
[01:25:16.038] iteration 12005 : loss : 0.106399, loss_ce: 0.009235
[01:25:16.346] iteration 12006 : loss : 0.054049, loss_ce: 0.023788
[01:25:16.655] iteration 12007 : loss : 0.041646, loss_ce: 0.008539
[01:25:16.956] iteration 12008 : loss : 0.063401, loss_ce: 0.011562
[01:25:17.263] iteration 12009 : loss : 0.103111, loss_ce: 0.007283
[01:25:17.569] iteration 12010 : loss : 0.048027, loss_ce: 0.012626
[01:25:17.879] iteration 12011 : loss : 0.105040, loss_ce: 0.017244
[01:25:18.183] iteration 12012 : loss : 0.051092, loss_ce: 0.014644
[01:25:18.489] iteration 12013 : loss : 0.049021, loss_ce: 0.012900
[01:25:18.795] iteration 12014 : loss : 0.050725, loss_ce: 0.013410
[01:25:19.100] iteration 12015 : loss : 0.051848, loss_ce: 0.015289
[01:25:19.406] iteration 12016 : loss : 0.073562, loss_ce: 0.020794
[01:25:19.714] iteration 12017 : loss : 0.046360, loss_ce: 0.010791
[01:25:20.018] iteration 12018 : loss : 0.044566, loss_ce: 0.015258
[01:25:20.327] iteration 12019 : loss : 0.048022, loss_ce: 0.022782
[01:25:20.632] iteration 12020 : loss : 0.106642, loss_ce: 0.007905
[01:25:20.955] iteration 12021 : loss : 0.061490, loss_ce: 0.017824
[01:25:21.259] iteration 12022 : loss : 0.057721, loss_ce: 0.017749
[01:25:21.562] iteration 12023 : loss : 0.224694, loss_ce: 0.004618
[01:25:21.866] iteration 12024 : loss : 0.061305, loss_ce: 0.010002
[01:25:22.166] iteration 12025 : loss : 0.061516, loss_ce: 0.017383
[01:25:22.471] iteration 12026 : loss : 0.044825, loss_ce: 0.019071
[01:25:22.775] iteration 12027 : loss : 0.055282, loss_ce: 0.026183
[01:25:23.080] iteration 12028 : loss : 0.064786, loss_ce: 0.008843
[01:25:23.384] iteration 12029 : loss : 0.051946, loss_ce: 0.019198
[01:25:23.694] iteration 12030 : loss : 0.048093, loss_ce: 0.011591
[01:25:23.999] iteration 12031 : loss : 0.109863, loss_ce: 0.009800
[01:25:24.308] iteration 12032 : loss : 0.105970, loss_ce: 0.009158
[01:25:24.608] iteration 12033 : loss : 0.283157, loss_ce: 0.009326
[01:25:24.914] iteration 12034 : loss : 0.057063, loss_ce: 0.024721
[01:25:25.219] iteration 12035 : loss : 0.111130, loss_ce: 0.016904
[01:25:25.522] iteration 12036 : loss : 0.113227, loss_ce: 0.019832
[01:25:25.826] iteration 12037 : loss : 0.050033, loss_ce: 0.018741
[01:25:26.129] iteration 12038 : loss : 0.037306, loss_ce: 0.010722
[01:25:26.433] iteration 12039 : loss : 0.107852, loss_ce: 0.013528
[01:25:26.737] iteration 12040 : loss : 0.105260, loss_ce: 0.011217
[01:25:27.059] iteration 12041 : loss : 0.049088, loss_ce: 0.019896
[01:25:27.370] iteration 12042 : loss : 0.049550, loss_ce: 0.016516
[01:25:27.682] iteration 12043 : loss : 0.046009, loss_ce: 0.009045
[01:25:27.994] iteration 12044 : loss : 0.046179, loss_ce: 0.007951
[01:25:28.303] iteration 12045 : loss : 0.055678, loss_ce: 0.015201
[01:25:28.611] iteration 12046 : loss : 0.056122, loss_ce: 0.019404
[01:25:28.919] iteration 12047 : loss : 0.047924, loss_ce: 0.017559
[01:25:29.232] iteration 12048 : loss : 0.055588, loss_ce: 0.014882
[01:25:29.534] iteration 12049 : loss : 0.047584, loss_ce: 0.012077
[01:25:29.837] iteration 12050 : loss : 0.048592, loss_ce: 0.018285
[01:25:30.141] iteration 12051 : loss : 0.107083, loss_ce: 0.007391
[01:25:30.444] iteration 12052 : loss : 0.045694, loss_ce: 0.020227
[01:25:30.749] iteration 12053 : loss : 0.106598, loss_ce: 0.009271
[01:25:31.052] iteration 12054 : loss : 0.054859, loss_ce: 0.014296
[01:25:31.355] iteration 12055 : loss : 0.041133, loss_ce: 0.012923
[01:25:31.657] iteration 12056 : loss : 0.056639, loss_ce: 0.020216
[01:25:31.962] iteration 12057 : loss : 0.050218, loss_ce: 0.020462
[01:25:32.265] iteration 12058 : loss : 0.058402, loss_ce: 0.017026
[01:25:32.569] iteration 12059 : loss : 0.048789, loss_ce: 0.013553
[01:25:32.874] iteration 12060 : loss : 0.048990, loss_ce: 0.020029
[01:25:33.197] iteration 12061 : loss : 0.052106, loss_ce: 0.007261
[01:25:33.498] iteration 12062 : loss : 0.046510, loss_ce: 0.011885
[01:25:33.803] iteration 12063 : loss : 0.058582, loss_ce: 0.013101
[01:25:34.111] iteration 12064 : loss : 0.047785, loss_ce: 0.021094
[01:25:34.414] iteration 12065 : loss : 0.061800, loss_ce: 0.011680
[01:25:34.716] iteration 12066 : loss : 0.061866, loss_ce: 0.013887
[01:25:35.016] iteration 12067 : loss : 0.060045, loss_ce: 0.011277
[01:25:35.320] iteration 12068 : loss : 0.047050, loss_ce: 0.012411
[01:25:35.629] iteration 12069 : loss : 0.101621, loss_ce: 0.012673
[01:25:35.934] iteration 12070 : loss : 0.057929, loss_ce: 0.024540
[01:25:36.240] iteration 12071 : loss : 0.168676, loss_ce: 0.021567
[01:25:36.544] iteration 12072 : loss : 0.043486, loss_ce: 0.018028
[01:25:36.845] iteration 12073 : loss : 0.059837, loss_ce: 0.016886
[01:25:37.151] iteration 12074 : loss : 0.049998, loss_ce: 0.007981
[01:25:37.454] iteration 12075 : loss : 0.099446, loss_ce: 0.008858
[01:25:37.758] iteration 12076 : loss : 0.051361, loss_ce: 0.023467
[01:25:38.064] iteration 12077 : loss : 0.055932, loss_ce: 0.011382
[01:25:38.371] iteration 12078 : loss : 0.044136, loss_ce: 0.011908
[01:25:38.683] iteration 12079 : loss : 0.061655, loss_ce: 0.023570
[01:25:38.993] iteration 12080 : loss : 0.110360, loss_ce: 0.007666
[01:25:39.318] iteration 12081 : loss : 0.049464, loss_ce: 0.013127
[01:25:39.628] iteration 12082 : loss : 0.046910, loss_ce: 0.018599
[01:25:39.938] iteration 12083 : loss : 0.045002, loss_ce: 0.015897
[01:25:40.251] iteration 12084 : loss : 0.051751, loss_ce: 0.009856
[01:25:40.559] iteration 12085 : loss : 0.051749, loss_ce: 0.010771
[01:25:40.870] iteration 12086 : loss : 0.046351, loss_ce: 0.020914
[01:25:41.174] iteration 12087 : loss : 0.119284, loss_ce: 0.021930
[01:25:41.483] iteration 12088 : loss : 0.046424, loss_ce: 0.020441
[01:25:41.793] iteration 12089 : loss : 0.053215, loss_ce: 0.023147
[01:25:42.101] iteration 12090 : loss : 0.053635, loss_ce: 0.014572
[01:25:42.414] iteration 12091 : loss : 0.107831, loss_ce: 0.016737
[01:25:42.726] iteration 12092 : loss : 0.042892, loss_ce: 0.012208
[01:25:42.810] iteration 12093 : loss : 0.122987, loss_ce: 0.014814
[01:26:02.714] iteration 12094 : loss : 0.050036, loss_ce: 0.013665
[01:26:03.018] iteration 12095 : loss : 0.041576, loss_ce: 0.009859
[01:26:03.326] iteration 12096 : loss : 0.049177, loss_ce: 0.021493
[01:26:03.632] iteration 12097 : loss : 0.054911, loss_ce: 0.016856
[01:26:03.943] iteration 12098 : loss : 0.115052, loss_ce: 0.020654
[01:26:04.250] iteration 12099 : loss : 0.044568, loss_ce: 0.011179
[01:26:04.552] iteration 12100 : loss : 0.149812, loss_ce: 0.012732
[01:26:04.868] iteration 12101 : loss : 0.047077, loss_ce: 0.017155
[01:26:05.166] iteration 12102 : loss : 0.106677, loss_ce: 0.010468
[01:26:05.469] iteration 12103 : loss : 0.047664, loss_ce: 0.025535
[01:26:05.773] iteration 12104 : loss : 0.057957, loss_ce: 0.032010
[01:26:06.075] iteration 12105 : loss : 0.059763, loss_ce: 0.024794
[01:26:06.376] iteration 12106 : loss : 0.039712, loss_ce: 0.014128
[01:26:06.679] iteration 12107 : loss : 0.055155, loss_ce: 0.018395
[01:26:06.981] iteration 12108 : loss : 0.039502, loss_ce: 0.012131
[01:26:07.282] iteration 12109 : loss : 0.040844, loss_ce: 0.011112
[01:26:07.587] iteration 12110 : loss : 0.044561, loss_ce: 0.017875
[01:26:07.894] iteration 12111 : loss : 0.048191, loss_ce: 0.011517
[01:26:08.197] iteration 12112 : loss : 0.110144, loss_ce: 0.016045
[01:26:08.499] iteration 12113 : loss : 0.041037, loss_ce: 0.011025
[01:26:08.802] iteration 12114 : loss : 0.041398, loss_ce: 0.008037
[01:26:09.104] iteration 12115 : loss : 0.110749, loss_ce: 0.006231
[01:26:09.409] iteration 12116 : loss : 0.057208, loss_ce: 0.003930
[01:26:09.711] iteration 12117 : loss : 0.107644, loss_ce: 0.006811
[01:26:10.015] iteration 12118 : loss : 0.057593, loss_ce: 0.015307
[01:26:10.320] iteration 12119 : loss : 0.051593, loss_ce: 0.007211
[01:26:10.624] iteration 12120 : loss : 0.045443, loss_ce: 0.013156
[01:26:10.939] iteration 12121 : loss : 0.040185, loss_ce: 0.015134
[01:26:11.243] iteration 12122 : loss : 0.087586, loss_ce: 0.021490
[01:26:11.546] iteration 12123 : loss : 0.109918, loss_ce: 0.009771
[01:26:11.851] iteration 12124 : loss : 0.168148, loss_ce: 0.006467
[01:26:12.151] iteration 12125 : loss : 0.046550, loss_ce: 0.012250
[01:26:12.456] iteration 12126 : loss : 0.045588, loss_ce: 0.011608
[01:26:12.757] iteration 12127 : loss : 0.039451, loss_ce: 0.011955
[01:26:13.060] iteration 12128 : loss : 0.041165, loss_ce: 0.008940
[01:26:13.359] iteration 12129 : loss : 0.104981, loss_ce: 0.009678
[01:26:13.663] iteration 12130 : loss : 0.066110, loss_ce: 0.019744
[01:26:13.970] iteration 12131 : loss : 0.044492, loss_ce: 0.009394
[01:26:14.273] iteration 12132 : loss : 0.066637, loss_ce: 0.021980
[01:26:14.575] iteration 12133 : loss : 0.057888, loss_ce: 0.012926
[01:26:14.879] iteration 12134 : loss : 0.062426, loss_ce: 0.020358
[01:26:15.182] iteration 12135 : loss : 0.060314, loss_ce: 0.011800
[01:26:15.483] iteration 12136 : loss : 0.049568, loss_ce: 0.014966
[01:26:15.786] iteration 12137 : loss : 0.105096, loss_ce: 0.006200
[01:26:16.089] iteration 12138 : loss : 0.056410, loss_ce: 0.020321
[01:26:16.393] iteration 12139 : loss : 0.062752, loss_ce: 0.016014
[01:26:16.697] iteration 12140 : loss : 0.058409, loss_ce: 0.013213
[01:26:17.011] iteration 12141 : loss : 0.123056, loss_ce: 0.014597
[01:26:17.317] iteration 12142 : loss : 0.052618, loss_ce: 0.017671
[01:26:17.630] iteration 12143 : loss : 0.061025, loss_ce: 0.020104
[01:26:17.940] iteration 12144 : loss : 0.104191, loss_ce: 0.011967
[01:26:18.247] iteration 12145 : loss : 0.055168, loss_ce: 0.015718
[01:26:18.555] iteration 12146 : loss : 0.046848, loss_ce: 0.021070
[01:26:18.862] iteration 12147 : loss : 0.105169, loss_ce: 0.007954
[01:26:19.170] iteration 12148 : loss : 0.106100, loss_ce: 0.008488
[01:26:19.473] iteration 12149 : loss : 0.047543, loss_ce: 0.021658
[01:26:19.774] iteration 12150 : loss : 0.060225, loss_ce: 0.017831
[01:26:20.076] iteration 12151 : loss : 0.102264, loss_ce: 0.012228
[01:26:20.378] iteration 12152 : loss : 0.112957, loss_ce: 0.009691
[01:26:20.682] iteration 12153 : loss : 0.053786, loss_ce: 0.018909
[01:26:20.984] iteration 12154 : loss : 0.065907, loss_ce: 0.024842
[01:26:21.287] iteration 12155 : loss : 0.105056, loss_ce: 0.007425
[01:26:21.588] iteration 12156 : loss : 0.051182, loss_ce: 0.019496
[01:26:21.892] iteration 12157 : loss : 0.112905, loss_ce: 0.016931
[01:26:22.196] iteration 12158 : loss : 0.042179, loss_ce: 0.019493
[01:26:22.497] iteration 12159 : loss : 0.045626, loss_ce: 0.011346
[01:26:22.801] iteration 12160 : loss : 0.054039, loss_ce: 0.022238
[01:26:23.115] iteration 12161 : loss : 0.044305, loss_ce: 0.009764
[01:26:23.418] iteration 12162 : loss : 0.040547, loss_ce: 0.011665
[01:26:23.723] iteration 12163 : loss : 0.047972, loss_ce: 0.016606
[01:26:24.030] iteration 12164 : loss : 0.094774, loss_ce: 0.009942
[01:26:24.331] iteration 12165 : loss : 0.026986, loss_ce: 0.011277
[01:26:24.635] iteration 12166 : loss : 0.128837, loss_ce: 0.015281
[01:26:24.939] iteration 12167 : loss : 0.051138, loss_ce: 0.017296
[01:26:25.243] iteration 12168 : loss : 0.065278, loss_ce: 0.020253
[01:26:25.547] iteration 12169 : loss : 0.117334, loss_ce: 0.015800
[01:26:25.849] iteration 12170 : loss : 0.080060, loss_ce: 0.024201
[01:26:26.157] iteration 12171 : loss : 0.055304, loss_ce: 0.020671
[01:26:26.463] iteration 12172 : loss : 0.063261, loss_ce: 0.021187
[01:26:26.767] iteration 12173 : loss : 0.053435, loss_ce: 0.023290
[01:26:27.071] iteration 12174 : loss : 0.061869, loss_ce: 0.009711
[01:26:27.377] iteration 12175 : loss : 0.059730, loss_ce: 0.009938
[01:26:27.683] iteration 12176 : loss : 0.047507, loss_ce: 0.013284
[01:26:27.983] iteration 12177 : loss : 0.047740, loss_ce: 0.015950
[01:26:28.290] iteration 12178 : loss : 0.052780, loss_ce: 0.018015
[01:26:28.595] iteration 12179 : loss : 0.047997, loss_ce: 0.016432
[01:26:28.900] iteration 12180 : loss : 0.092845, loss_ce: 0.020418
[01:26:29.217] iteration 12181 : loss : 0.053618, loss_ce: 0.018704
[01:26:29.516] iteration 12182 : loss : 0.046178, loss_ce: 0.009248
[01:26:29.822] iteration 12183 : loss : 0.142100, loss_ce: 0.010307
[01:26:30.123] iteration 12184 : loss : 0.040608, loss_ce: 0.017312
[01:26:30.424] iteration 12185 : loss : 0.095437, loss_ce: 0.008007
[01:26:30.728] iteration 12186 : loss : 0.069105, loss_ce: 0.015732
[01:26:31.033] iteration 12187 : loss : 0.105862, loss_ce: 0.010503
[01:26:31.337] iteration 12188 : loss : 0.110869, loss_ce: 0.014982
[01:26:31.638] iteration 12189 : loss : 0.048718, loss_ce: 0.017380
[01:26:31.943] iteration 12190 : loss : 0.052784, loss_ce: 0.016336
[01:26:32.249] iteration 12191 : loss : 0.041234, loss_ce: 0.009100
[01:26:32.559] iteration 12192 : loss : 0.059118, loss_ce: 0.015337
[01:26:32.868] iteration 12193 : loss : 0.045062, loss_ce: 0.014707
[01:26:33.179] iteration 12194 : loss : 0.044876, loss_ce: 0.018623
[01:26:33.484] iteration 12195 : loss : 0.048800, loss_ce: 0.011982
[01:26:33.797] iteration 12196 : loss : 0.048457, loss_ce: 0.011574
[01:26:34.110] iteration 12197 : loss : 0.054737, loss_ce: 0.009927
[01:26:34.411] iteration 12198 : loss : 0.111261, loss_ce: 0.011283
[01:26:34.714] iteration 12199 : loss : 0.059774, loss_ce: 0.011989
[01:26:35.019] iteration 12200 : loss : 0.038657, loss_ce: 0.008031
[01:26:35.344] iteration 12201 : loss : 0.039307, loss_ce: 0.015442
[01:26:35.645] iteration 12202 : loss : 0.046795, loss_ce: 0.021183
[01:26:35.952] iteration 12203 : loss : 0.062301, loss_ce: 0.020020
[01:26:36.254] iteration 12204 : loss : 0.113720, loss_ce: 0.015287
[01:26:36.558] iteration 12205 : loss : 0.046941, loss_ce: 0.013310
[01:26:36.860] iteration 12206 : loss : 0.054825, loss_ce: 0.018390
[01:26:37.166] iteration 12207 : loss : 0.057730, loss_ce: 0.016325
[01:26:37.469] iteration 12208 : loss : 0.153723, loss_ce: 0.004417
[01:26:37.774] iteration 12209 : loss : 0.043014, loss_ce: 0.015551
[01:26:38.077] iteration 12210 : loss : 0.062514, loss_ce: 0.017397
[01:26:38.381] iteration 12211 : loss : 0.047763, loss_ce: 0.009589
[01:26:38.684] iteration 12212 : loss : 0.058658, loss_ce: 0.019293
[01:26:38.988] iteration 12213 : loss : 0.048930, loss_ce: 0.008988
[01:26:39.294] iteration 12214 : loss : 0.051144, loss_ce: 0.013082
[01:26:39.596] iteration 12215 : loss : 0.228249, loss_ce: 0.009055
[01:26:39.900] iteration 12216 : loss : 0.062652, loss_ce: 0.015732
[01:26:40.208] iteration 12217 : loss : 0.074601, loss_ce: 0.030052
[01:26:40.512] iteration 12218 : loss : 0.111868, loss_ce: 0.016371
[01:26:40.822] iteration 12219 : loss : 0.116676, loss_ce: 0.007988
[01:26:41.131] iteration 12220 : loss : 0.121215, loss_ce: 0.016418
[01:26:41.451] iteration 12221 : loss : 0.050957, loss_ce: 0.020922
[01:26:41.759] iteration 12222 : loss : 0.059648, loss_ce: 0.015882
[01:26:42.068] iteration 12223 : loss : 0.056546, loss_ce: 0.019104
[01:26:42.371] iteration 12224 : loss : 0.051885, loss_ce: 0.016923
[01:26:42.676] iteration 12225 : loss : 0.048036, loss_ce: 0.009481
[01:26:42.987] iteration 12226 : loss : 0.051814, loss_ce: 0.013529
[01:26:43.294] iteration 12227 : loss : 0.048386, loss_ce: 0.021283
[01:26:43.597] iteration 12228 : loss : 0.050000, loss_ce: 0.023284
[01:26:43.902] iteration 12229 : loss : 0.086224, loss_ce: 0.011928
[01:26:44.209] iteration 12230 : loss : 0.039990, loss_ce: 0.012423
[01:26:44.513] iteration 12231 : loss : 0.061724, loss_ce: 0.011918
[01:26:44.593] iteration 12232 : loss : 0.173167, loss_ce: 0.029217
[01:27:02.360] iteration 12233 : loss : 0.061168, loss_ce: 0.018686
[01:27:02.662] iteration 12234 : loss : 0.105317, loss_ce: 0.009171
[01:27:02.967] iteration 12235 : loss : 0.048919, loss_ce: 0.017203
[01:27:03.273] iteration 12236 : loss : 0.049100, loss_ce: 0.010039
[01:27:03.575] iteration 12237 : loss : 0.065118, loss_ce: 0.025056
[01:27:03.878] iteration 12238 : loss : 0.050107, loss_ce: 0.017433
[01:27:04.183] iteration 12239 : loss : 0.051262, loss_ce: 0.016501
[01:27:04.487] iteration 12240 : loss : 0.107632, loss_ce: 0.014063
[01:27:04.807] iteration 12241 : loss : 0.054453, loss_ce: 0.013574
[01:27:05.112] iteration 12242 : loss : 0.047954, loss_ce: 0.021143
[01:27:05.424] iteration 12243 : loss : 0.052922, loss_ce: 0.018358
[01:27:05.737] iteration 12244 : loss : 0.047878, loss_ce: 0.014100
[01:27:06.046] iteration 12245 : loss : 0.046455, loss_ce: 0.012459
[01:27:06.356] iteration 12246 : loss : 0.103067, loss_ce: 0.010548
[01:27:06.664] iteration 12247 : loss : 0.050143, loss_ce: 0.019146
[01:27:06.975] iteration 12248 : loss : 0.064644, loss_ce: 0.013380
[01:27:07.282] iteration 12249 : loss : 0.169262, loss_ce: 0.016974
[01:27:07.589] iteration 12250 : loss : 0.050236, loss_ce: 0.016818
[01:27:07.898] iteration 12251 : loss : 0.058358, loss_ce: 0.011905
[01:27:08.206] iteration 12252 : loss : 0.044628, loss_ce: 0.010332
[01:27:08.516] iteration 12253 : loss : 0.103654, loss_ce: 0.010909
[01:27:08.827] iteration 12254 : loss : 0.043493, loss_ce: 0.012801
[01:27:09.138] iteration 12255 : loss : 0.044978, loss_ce: 0.016891
[01:27:09.446] iteration 12256 : loss : 0.055726, loss_ce: 0.006137
[01:27:09.758] iteration 12257 : loss : 0.044272, loss_ce: 0.009890
[01:27:10.066] iteration 12258 : loss : 0.062646, loss_ce: 0.013268
[01:27:10.373] iteration 12259 : loss : 0.049258, loss_ce: 0.025444
[01:27:10.682] iteration 12260 : loss : 0.097503, loss_ce: 0.011165
[01:27:11.011] iteration 12261 : loss : 0.048696, loss_ce: 0.014830
[01:27:11.316] iteration 12262 : loss : 0.048040, loss_ce: 0.024013
[01:27:11.627] iteration 12263 : loss : 0.053597, loss_ce: 0.021004
[01:27:11.938] iteration 12264 : loss : 0.042170, loss_ce: 0.017910
[01:27:12.245] iteration 12265 : loss : 0.051579, loss_ce: 0.013984
[01:27:12.556] iteration 12266 : loss : 0.049182, loss_ce: 0.012683
[01:27:12.864] iteration 12267 : loss : 0.096658, loss_ce: 0.011077
[01:27:13.178] iteration 12268 : loss : 0.057842, loss_ce: 0.015680
[01:27:13.487] iteration 12269 : loss : 0.094373, loss_ce: 0.021328
[01:27:13.800] iteration 12270 : loss : 0.069449, loss_ce: 0.012661
[01:27:14.106] iteration 12271 : loss : 0.042082, loss_ce: 0.014092
[01:27:14.421] iteration 12272 : loss : 0.048234, loss_ce: 0.015372
[01:27:14.729] iteration 12273 : loss : 0.062200, loss_ce: 0.011383
[01:27:15.043] iteration 12274 : loss : 0.050865, loss_ce: 0.013766
[01:27:15.347] iteration 12275 : loss : 0.047293, loss_ce: 0.019523
[01:27:15.662] iteration 12276 : loss : 0.054022, loss_ce: 0.016879
[01:27:15.967] iteration 12277 : loss : 0.126624, loss_ce: 0.008450
[01:27:16.277] iteration 12278 : loss : 0.074962, loss_ce: 0.024450
[01:27:16.585] iteration 12279 : loss : 0.054764, loss_ce: 0.017675
[01:27:16.897] iteration 12280 : loss : 0.158024, loss_ce: 0.008001
[01:27:17.226] iteration 12281 : loss : 0.090669, loss_ce: 0.007330
[01:27:17.535] iteration 12282 : loss : 0.057409, loss_ce: 0.022103
[01:27:17.846] iteration 12283 : loss : 0.057837, loss_ce: 0.008883
[01:27:18.154] iteration 12284 : loss : 0.045945, loss_ce: 0.012292
[01:27:18.464] iteration 12285 : loss : 0.066443, loss_ce: 0.013159
[01:27:18.772] iteration 12286 : loss : 0.046534, loss_ce: 0.014589
[01:27:19.077] iteration 12287 : loss : 0.074769, loss_ce: 0.016754
[01:27:19.384] iteration 12288 : loss : 0.064820, loss_ce: 0.031160
[01:27:19.695] iteration 12289 : loss : 0.053823, loss_ce: 0.020057
[01:27:20.005] iteration 12290 : loss : 0.110200, loss_ce: 0.013025
[01:27:20.315] iteration 12291 : loss : 0.053152, loss_ce: 0.019676
[01:27:20.621] iteration 12292 : loss : 0.053726, loss_ce: 0.017759
[01:27:20.931] iteration 12293 : loss : 0.058310, loss_ce: 0.016400
[01:27:21.238] iteration 12294 : loss : 0.061882, loss_ce: 0.015621
[01:27:21.545] iteration 12295 : loss : 0.038345, loss_ce: 0.017711
[01:27:21.854] iteration 12296 : loss : 0.107693, loss_ce: 0.011829
[01:27:22.167] iteration 12297 : loss : 0.100463, loss_ce: 0.007821
[01:27:22.473] iteration 12298 : loss : 0.051789, loss_ce: 0.016477
[01:27:22.783] iteration 12299 : loss : 0.122934, loss_ce: 0.007118
[01:27:23.090] iteration 12300 : loss : 0.065693, loss_ce: 0.013171
[01:27:23.416] iteration 12301 : loss : 0.050332, loss_ce: 0.014876
[01:27:23.723] iteration 12302 : loss : 0.053998, loss_ce: 0.019189
[01:27:24.035] iteration 12303 : loss : 0.098846, loss_ce: 0.008579
[01:27:24.339] iteration 12304 : loss : 0.044502, loss_ce: 0.018124
[01:27:24.641] iteration 12305 : loss : 0.065215, loss_ce: 0.022487
[01:27:24.943] iteration 12306 : loss : 0.046697, loss_ce: 0.018594
[01:27:25.244] iteration 12307 : loss : 0.060406, loss_ce: 0.023023
[01:27:25.548] iteration 12308 : loss : 0.051951, loss_ce: 0.019364
[01:27:25.852] iteration 12309 : loss : 0.039760, loss_ce: 0.010617
[01:27:26.160] iteration 12310 : loss : 0.044378, loss_ce: 0.013573
[01:27:26.464] iteration 12311 : loss : 0.052538, loss_ce: 0.017615
[01:27:26.768] iteration 12312 : loss : 0.050053, loss_ce: 0.021934
[01:27:27.068] iteration 12313 : loss : 0.052896, loss_ce: 0.007890
[01:27:27.371] iteration 12314 : loss : 0.051686, loss_ce: 0.013133
[01:27:27.673] iteration 12315 : loss : 0.057408, loss_ce: 0.026765
[01:27:27.981] iteration 12316 : loss : 0.089245, loss_ce: 0.014884
[01:27:28.285] iteration 12317 : loss : 0.045650, loss_ce: 0.020037
[01:27:28.591] iteration 12318 : loss : 0.054026, loss_ce: 0.009785
[01:27:28.898] iteration 12319 : loss : 0.045553, loss_ce: 0.007573
[01:27:29.200] iteration 12320 : loss : 0.047606, loss_ce: 0.012728
[01:27:29.513] iteration 12321 : loss : 0.048739, loss_ce: 0.013585
[01:27:29.815] iteration 12322 : loss : 0.104515, loss_ce: 0.017809
[01:27:30.116] iteration 12323 : loss : 0.059780, loss_ce: 0.013384
[01:27:30.422] iteration 12324 : loss : 0.060048, loss_ce: 0.021876
[01:27:30.722] iteration 12325 : loss : 0.041952, loss_ce: 0.007228
[01:27:31.026] iteration 12326 : loss : 0.051598, loss_ce: 0.022981
[01:27:31.326] iteration 12327 : loss : 0.067563, loss_ce: 0.019332
[01:27:31.633] iteration 12328 : loss : 0.109566, loss_ce: 0.015569
[01:27:31.939] iteration 12329 : loss : 0.045147, loss_ce: 0.012315
[01:27:32.243] iteration 12330 : loss : 0.041569, loss_ce: 0.016250
[01:27:32.552] iteration 12331 : loss : 0.064015, loss_ce: 0.023583
[01:27:32.855] iteration 12332 : loss : 0.057440, loss_ce: 0.007522
[01:27:33.158] iteration 12333 : loss : 0.285752, loss_ce: 0.006156
[01:27:33.463] iteration 12334 : loss : 0.059361, loss_ce: 0.022354
[01:27:33.768] iteration 12335 : loss : 0.056263, loss_ce: 0.017445
[01:27:34.071] iteration 12336 : loss : 0.050382, loss_ce: 0.007539
[01:27:34.375] iteration 12337 : loss : 0.095794, loss_ce: 0.007508
[01:27:34.675] iteration 12338 : loss : 0.141241, loss_ce: 0.015544
[01:27:34.979] iteration 12339 : loss : 0.058003, loss_ce: 0.020181
[01:27:35.285] iteration 12340 : loss : 0.120043, loss_ce: 0.015215
[01:27:35.604] iteration 12341 : loss : 0.071226, loss_ce: 0.009701
[01:27:35.910] iteration 12342 : loss : 0.063782, loss_ce: 0.021167
[01:27:36.213] iteration 12343 : loss : 0.224004, loss_ce: 0.002640
[01:27:36.515] iteration 12344 : loss : 0.054973, loss_ce: 0.015127
[01:27:36.818] iteration 12345 : loss : 0.055788, loss_ce: 0.007520
[01:27:37.121] iteration 12346 : loss : 0.042044, loss_ce: 0.016022
[01:27:37.428] iteration 12347 : loss : 0.122328, loss_ce: 0.009923
[01:27:37.738] iteration 12348 : loss : 0.045804, loss_ce: 0.016210
[01:27:38.047] iteration 12349 : loss : 0.051092, loss_ce: 0.008673
[01:27:38.359] iteration 12350 : loss : 0.052453, loss_ce: 0.013415
[01:27:38.667] iteration 12351 : loss : 0.279061, loss_ce: 0.003725
[01:27:38.978] iteration 12352 : loss : 0.104695, loss_ce: 0.013290
[01:27:39.286] iteration 12353 : loss : 0.077353, loss_ce: 0.010722
[01:27:39.587] iteration 12354 : loss : 0.111507, loss_ce: 0.012714
[01:27:39.892] iteration 12355 : loss : 0.048238, loss_ce: 0.016451
[01:27:40.208] iteration 12356 : loss : 0.054309, loss_ce: 0.016055
[01:27:40.519] iteration 12357 : loss : 0.106043, loss_ce: 0.016903
[01:27:40.826] iteration 12358 : loss : 0.118588, loss_ce: 0.013228
[01:27:41.137] iteration 12359 : loss : 0.096372, loss_ce: 0.014070
[01:27:41.450] iteration 12360 : loss : 0.049944, loss_ce: 0.019990
[01:27:41.778] iteration 12361 : loss : 0.063913, loss_ce: 0.021399
[01:27:42.088] iteration 12362 : loss : 0.040543, loss_ce: 0.010367
[01:27:42.398] iteration 12363 : loss : 0.066204, loss_ce: 0.016758
[01:27:42.705] iteration 12364 : loss : 0.070463, loss_ce: 0.011314
[01:27:43.014] iteration 12365 : loss : 0.072106, loss_ce: 0.012168
[01:27:43.317] iteration 12366 : loss : 0.061588, loss_ce: 0.005060
[01:27:43.631] iteration 12367 : loss : 0.049551, loss_ce: 0.018962
[01:27:43.941] iteration 12368 : loss : 0.054153, loss_ce: 0.008028
[01:27:44.252] iteration 12369 : loss : 0.046257, loss_ce: 0.015285
[01:27:44.558] iteration 12370 : loss : 0.120553, loss_ce: 0.014991
[01:27:44.643] iteration 12371 : loss : 0.150055, loss_ce: 0.040577
[01:28:02.974] iteration 12372 : loss : 0.051601, loss_ce: 0.012686
[01:28:03.274] iteration 12373 : loss : 0.148627, loss_ce: 0.017459
[01:28:03.573] iteration 12374 : loss : 0.287561, loss_ce: 0.005523
[01:28:03.876] iteration 12375 : loss : 0.056215, loss_ce: 0.007703
[01:28:04.175] iteration 12376 : loss : 0.041383, loss_ce: 0.010728
[01:28:04.476] iteration 12377 : loss : 0.037800, loss_ce: 0.009968
[01:28:04.776] iteration 12378 : loss : 0.046552, loss_ce: 0.013090
[01:28:05.081] iteration 12379 : loss : 0.056462, loss_ce: 0.013869
[01:28:05.384] iteration 12380 : loss : 0.049829, loss_ce: 0.017709
[01:28:05.701] iteration 12381 : loss : 0.043549, loss_ce: 0.016675
[01:28:06.001] iteration 12382 : loss : 0.080106, loss_ce: 0.020603
[01:28:06.307] iteration 12383 : loss : 0.058463, loss_ce: 0.022188
[01:28:06.607] iteration 12384 : loss : 0.106178, loss_ce: 0.014701
[01:28:06.908] iteration 12385 : loss : 0.044683, loss_ce: 0.006989
[01:28:07.214] iteration 12386 : loss : 0.047708, loss_ce: 0.016169
[01:28:07.524] iteration 12387 : loss : 0.083172, loss_ce: 0.009935
[01:28:07.831] iteration 12388 : loss : 0.070192, loss_ce: 0.017220
[01:28:08.142] iteration 12389 : loss : 0.072544, loss_ce: 0.017565
[01:28:08.449] iteration 12390 : loss : 0.054446, loss_ce: 0.018354
[01:28:08.759] iteration 12391 : loss : 0.095913, loss_ce: 0.013640
[01:28:09.063] iteration 12392 : loss : 0.053700, loss_ce: 0.017076
[01:28:09.367] iteration 12393 : loss : 0.047366, loss_ce: 0.020680
[01:28:09.668] iteration 12394 : loss : 0.053764, loss_ce: 0.021715
[01:28:09.970] iteration 12395 : loss : 0.160211, loss_ce: 0.010142
[01:28:10.274] iteration 12396 : loss : 0.054976, loss_ce: 0.014171
[01:28:10.582] iteration 12397 : loss : 0.059343, loss_ce: 0.012686
[01:28:10.884] iteration 12398 : loss : 0.051713, loss_ce: 0.016638
[01:28:11.185] iteration 12399 : loss : 0.079333, loss_ce: 0.020439
[01:28:11.491] iteration 12400 : loss : 0.051929, loss_ce: 0.020496
[01:28:11.809] iteration 12401 : loss : 0.041533, loss_ce: 0.016704
[01:28:12.112] iteration 12402 : loss : 0.047049, loss_ce: 0.016090
[01:28:12.413] iteration 12403 : loss : 0.071239, loss_ce: 0.013841
[01:28:12.717] iteration 12404 : loss : 0.051881, loss_ce: 0.007060
[01:28:13.021] iteration 12405 : loss : 0.104228, loss_ce: 0.009242
[01:28:13.329] iteration 12406 : loss : 0.033725, loss_ce: 0.008943
[01:28:13.633] iteration 12407 : loss : 0.049132, loss_ce: 0.019719
[01:28:13.938] iteration 12408 : loss : 0.057858, loss_ce: 0.018039
[01:28:14.241] iteration 12409 : loss : 0.062200, loss_ce: 0.007617
[01:28:14.548] iteration 12410 : loss : 0.050388, loss_ce: 0.013252
[01:28:14.853] iteration 12411 : loss : 0.041432, loss_ce: 0.011252
[01:28:15.156] iteration 12412 : loss : 0.048787, loss_ce: 0.017026
[01:28:15.456] iteration 12413 : loss : 0.041352, loss_ce: 0.018755
[01:28:15.764] iteration 12414 : loss : 0.038612, loss_ce: 0.013103
[01:28:16.068] iteration 12415 : loss : 0.067663, loss_ce: 0.015966
[01:28:16.372] iteration 12416 : loss : 0.097306, loss_ce: 0.008372
[01:28:16.678] iteration 12417 : loss : 0.069083, loss_ce: 0.009253
[01:28:16.986] iteration 12418 : loss : 0.046678, loss_ce: 0.014221
[01:28:17.292] iteration 12419 : loss : 0.047481, loss_ce: 0.017149
[01:28:17.594] iteration 12420 : loss : 0.047542, loss_ce: 0.010549
[01:28:17.918] iteration 12421 : loss : 0.055712, loss_ce: 0.016159
[01:28:18.223] iteration 12422 : loss : 0.048117, loss_ce: 0.017712
[01:28:18.527] iteration 12423 : loss : 0.072529, loss_ce: 0.017525
[01:28:18.831] iteration 12424 : loss : 0.046686, loss_ce: 0.010832
[01:28:19.132] iteration 12425 : loss : 0.054115, loss_ce: 0.017043
[01:28:19.434] iteration 12426 : loss : 0.061414, loss_ce: 0.008995
[01:28:19.740] iteration 12427 : loss : 0.047704, loss_ce: 0.017162
[01:28:20.043] iteration 12428 : loss : 0.042567, loss_ce: 0.011560
[01:28:20.345] iteration 12429 : loss : 0.050535, loss_ce: 0.006626
[01:28:20.649] iteration 12430 : loss : 0.096202, loss_ce: 0.012997
[01:28:20.950] iteration 12431 : loss : 0.050458, loss_ce: 0.010668
[01:28:21.254] iteration 12432 : loss : 0.065884, loss_ce: 0.020566
[01:28:21.556] iteration 12433 : loss : 0.048798, loss_ce: 0.011258
[01:28:21.858] iteration 12434 : loss : 0.048256, loss_ce: 0.009570
[01:28:22.161] iteration 12435 : loss : 0.062448, loss_ce: 0.023832
[01:28:22.467] iteration 12436 : loss : 0.048071, loss_ce: 0.016736
[01:28:22.771] iteration 12437 : loss : 0.042152, loss_ce: 0.009263
[01:28:23.078] iteration 12438 : loss : 0.107627, loss_ce: 0.014606
[01:28:23.385] iteration 12439 : loss : 0.055627, loss_ce: 0.008472
[01:28:23.691] iteration 12440 : loss : 0.042849, loss_ce: 0.013838
[01:28:24.017] iteration 12441 : loss : 0.055694, loss_ce: 0.013325
[01:28:24.321] iteration 12442 : loss : 0.056973, loss_ce: 0.009057
[01:28:24.628] iteration 12443 : loss : 0.039042, loss_ce: 0.011608
[01:28:24.935] iteration 12444 : loss : 0.062830, loss_ce: 0.016781
[01:28:25.239] iteration 12445 : loss : 0.059082, loss_ce: 0.016898
[01:28:25.547] iteration 12446 : loss : 0.073383, loss_ce: 0.013883
[01:28:25.858] iteration 12447 : loss : 0.112592, loss_ce: 0.016195
[01:28:26.168] iteration 12448 : loss : 0.042297, loss_ce: 0.015907
[01:28:26.474] iteration 12449 : loss : 0.113646, loss_ce: 0.015198
[01:28:26.782] iteration 12450 : loss : 0.057294, loss_ce: 0.016041
[01:28:27.090] iteration 12451 : loss : 0.044999, loss_ce: 0.019263
[01:28:27.398] iteration 12452 : loss : 0.050616, loss_ce: 0.014029
[01:28:27.701] iteration 12453 : loss : 0.057491, loss_ce: 0.023180
[01:28:28.007] iteration 12454 : loss : 0.174229, loss_ce: 0.014548
[01:28:28.314] iteration 12455 : loss : 0.050662, loss_ce: 0.016890
[01:28:28.621] iteration 12456 : loss : 0.039846, loss_ce: 0.011405
[01:28:28.928] iteration 12457 : loss : 0.052489, loss_ce: 0.020633
[01:28:29.238] iteration 12458 : loss : 0.061629, loss_ce: 0.016702
[01:28:29.546] iteration 12459 : loss : 0.057177, loss_ce: 0.020878
[01:28:29.856] iteration 12460 : loss : 0.053880, loss_ce: 0.012421
[01:28:30.186] iteration 12461 : loss : 0.174186, loss_ce: 0.017252
[01:28:30.493] iteration 12462 : loss : 0.106383, loss_ce: 0.008541
[01:28:30.804] iteration 12463 : loss : 0.057005, loss_ce: 0.014669
[01:28:31.110] iteration 12464 : loss : 0.079299, loss_ce: 0.018470
[01:28:31.416] iteration 12465 : loss : 0.053064, loss_ce: 0.016589
[01:28:31.727] iteration 12466 : loss : 0.048799, loss_ce: 0.013564
[01:28:32.038] iteration 12467 : loss : 0.051665, loss_ce: 0.011582
[01:28:32.346] iteration 12468 : loss : 0.067246, loss_ce: 0.020806
[01:28:32.654] iteration 12469 : loss : 0.116835, loss_ce: 0.008407
[01:28:32.959] iteration 12470 : loss : 0.098029, loss_ce: 0.011364
[01:28:33.268] iteration 12471 : loss : 0.055223, loss_ce: 0.011910
[01:28:33.580] iteration 12472 : loss : 0.058273, loss_ce: 0.022595
[01:28:33.890] iteration 12473 : loss : 0.045159, loss_ce: 0.011756
[01:28:34.197] iteration 12474 : loss : 0.055744, loss_ce: 0.016068
[01:28:34.506] iteration 12475 : loss : 0.064185, loss_ce: 0.016565
[01:28:34.813] iteration 12476 : loss : 0.058458, loss_ce: 0.020317
[01:28:35.121] iteration 12477 : loss : 0.054727, loss_ce: 0.008817
[01:28:35.431] iteration 12478 : loss : 0.070573, loss_ce: 0.019417
[01:28:35.737] iteration 12479 : loss : 0.055615, loss_ce: 0.014688
[01:28:36.047] iteration 12480 : loss : 0.056262, loss_ce: 0.012205
[01:28:36.371] iteration 12481 : loss : 0.107332, loss_ce: 0.009801
[01:28:36.676] iteration 12482 : loss : 0.048669, loss_ce: 0.020104
[01:28:36.985] iteration 12483 : loss : 0.056446, loss_ce: 0.022929
[01:28:37.297] iteration 12484 : loss : 0.108385, loss_ce: 0.006324
[01:28:37.603] iteration 12485 : loss : 0.047898, loss_ce: 0.013087
[01:28:37.913] iteration 12486 : loss : 0.048319, loss_ce: 0.019613
[01:28:38.222] iteration 12487 : loss : 0.105932, loss_ce: 0.009702
[01:28:38.531] iteration 12488 : loss : 0.050285, loss_ce: 0.012139
[01:28:38.837] iteration 12489 : loss : 0.056470, loss_ce: 0.009033
[01:28:39.148] iteration 12490 : loss : 0.051274, loss_ce: 0.012079
[01:28:39.457] iteration 12491 : loss : 0.058920, loss_ce: 0.026437
[01:28:39.763] iteration 12492 : loss : 0.101995, loss_ce: 0.012050
[01:28:40.071] iteration 12493 : loss : 0.047556, loss_ce: 0.012687
[01:28:40.382] iteration 12494 : loss : 0.051172, loss_ce: 0.011222
[01:28:40.697] iteration 12495 : loss : 0.050257, loss_ce: 0.019018
[01:28:41.009] iteration 12496 : loss : 0.049192, loss_ce: 0.016109
[01:28:41.328] iteration 12497 : loss : 0.049396, loss_ce: 0.014497
[01:28:41.641] iteration 12498 : loss : 0.049307, loss_ce: 0.024410
[01:28:41.953] iteration 12499 : loss : 0.051501, loss_ce: 0.011517
[01:28:42.271] iteration 12500 : loss : 0.062038, loss_ce: 0.021882
[01:28:42.616] iteration 12501 : loss : 0.155063, loss_ce: 0.011015
[01:28:42.928] iteration 12502 : loss : 0.032147, loss_ce: 0.011434
[01:28:43.243] iteration 12503 : loss : 0.112172, loss_ce: 0.021163
[01:28:43.559] iteration 12504 : loss : 0.056779, loss_ce: 0.016782
[01:28:43.871] iteration 12505 : loss : 0.065041, loss_ce: 0.016598
[01:28:44.180] iteration 12506 : loss : 0.042124, loss_ce: 0.010642
[01:28:44.489] iteration 12507 : loss : 0.056108, loss_ce: 0.030666
[01:28:44.799] iteration 12508 : loss : 0.053054, loss_ce: 0.020599
[01:28:45.108] iteration 12509 : loss : 0.061963, loss_ce: 0.015935
[01:28:45.198] iteration 12510 : loss : 0.289784, loss_ce: 0.009142
[01:29:02.692] iteration 12511 : loss : 0.038470, loss_ce: 0.009727
[01:29:02.992] iteration 12512 : loss : 0.067390, loss_ce: 0.017913
[01:29:03.290] iteration 12513 : loss : 0.038379, loss_ce: 0.011139
[01:29:03.589] iteration 12514 : loss : 0.045919, loss_ce: 0.019297
[01:29:03.891] iteration 12515 : loss : 0.040594, loss_ce: 0.010326
[01:29:04.190] iteration 12516 : loss : 0.046292, loss_ce: 0.009521
[01:29:04.495] iteration 12517 : loss : 0.051807, loss_ce: 0.015642
[01:29:04.797] iteration 12518 : loss : 0.167559, loss_ce: 0.003266
[01:29:05.098] iteration 12519 : loss : 0.048835, loss_ce: 0.011637
[01:29:05.397] iteration 12520 : loss : 0.056658, loss_ce: 0.014016
[01:29:05.716] iteration 12521 : loss : 0.059525, loss_ce: 0.022599
[01:29:06.022] iteration 12522 : loss : 0.052095, loss_ce: 0.019148
[01:29:06.329] iteration 12523 : loss : 0.046667, loss_ce: 0.012557
[01:29:06.634] iteration 12524 : loss : 0.049468, loss_ce: 0.014195
[01:29:06.937] iteration 12525 : loss : 0.054472, loss_ce: 0.015120
[01:29:07.246] iteration 12526 : loss : 0.104626, loss_ce: 0.012061
[01:29:07.555] iteration 12527 : loss : 0.056766, loss_ce: 0.013766
[01:29:07.858] iteration 12528 : loss : 0.092067, loss_ce: 0.008310
[01:29:08.160] iteration 12529 : loss : 0.048366, loss_ce: 0.015531
[01:29:08.464] iteration 12530 : loss : 0.078930, loss_ce: 0.011255
[01:29:08.775] iteration 12531 : loss : 0.053540, loss_ce: 0.016800
[01:29:09.077] iteration 12532 : loss : 0.139918, loss_ce: 0.021140
[01:29:09.380] iteration 12533 : loss : 0.037836, loss_ce: 0.004145
[01:29:09.686] iteration 12534 : loss : 0.053014, loss_ce: 0.012697
[01:29:09.993] iteration 12535 : loss : 0.051116, loss_ce: 0.018826
[01:29:10.299] iteration 12536 : loss : 0.042579, loss_ce: 0.007161
[01:29:10.607] iteration 12537 : loss : 0.107771, loss_ce: 0.018032
[01:29:10.912] iteration 12538 : loss : 0.048142, loss_ce: 0.016604
[01:29:11.220] iteration 12539 : loss : 0.048743, loss_ce: 0.015653
[01:29:11.529] iteration 12540 : loss : 0.118528, loss_ce: 0.013246
[01:29:11.852] iteration 12541 : loss : 0.062438, loss_ce: 0.025470
[01:29:12.155] iteration 12542 : loss : 0.059047, loss_ce: 0.020579
[01:29:12.464] iteration 12543 : loss : 0.107489, loss_ce: 0.008796
[01:29:12.772] iteration 12544 : loss : 0.052447, loss_ce: 0.020955
[01:29:13.080] iteration 12545 : loss : 0.154800, loss_ce: 0.007752
[01:29:13.386] iteration 12546 : loss : 0.051712, loss_ce: 0.007915
[01:29:13.690] iteration 12547 : loss : 0.041934, loss_ce: 0.008231
[01:29:14.001] iteration 12548 : loss : 0.049247, loss_ce: 0.018081
[01:29:14.306] iteration 12549 : loss : 0.060273, loss_ce: 0.010527
[01:29:14.615] iteration 12550 : loss : 0.053742, loss_ce: 0.012439
[01:29:14.925] iteration 12551 : loss : 0.053195, loss_ce: 0.018064
[01:29:15.234] iteration 12552 : loss : 0.174132, loss_ce: 0.013116
[01:29:15.541] iteration 12553 : loss : 0.043801, loss_ce: 0.010247
[01:29:15.855] iteration 12554 : loss : 0.050161, loss_ce: 0.021819
[01:29:16.166] iteration 12555 : loss : 0.055379, loss_ce: 0.021031
[01:29:16.473] iteration 12556 : loss : 0.107913, loss_ce: 0.009878
[01:29:16.783] iteration 12557 : loss : 0.045486, loss_ce: 0.011074
[01:29:17.092] iteration 12558 : loss : 0.043571, loss_ce: 0.014258
[01:29:17.407] iteration 12559 : loss : 0.044102, loss_ce: 0.014472
[01:29:17.713] iteration 12560 : loss : 0.061759, loss_ce: 0.018745
[01:29:18.038] iteration 12561 : loss : 0.060726, loss_ce: 0.022420
[01:29:18.345] iteration 12562 : loss : 0.048888, loss_ce: 0.019609
[01:29:18.656] iteration 12563 : loss : 0.046566, loss_ce: 0.020871
[01:29:18.970] iteration 12564 : loss : 0.052304, loss_ce: 0.021215
[01:29:19.279] iteration 12565 : loss : 0.053164, loss_ce: 0.010686
[01:29:19.587] iteration 12566 : loss : 0.062316, loss_ce: 0.015335
[01:29:19.898] iteration 12567 : loss : 0.062109, loss_ce: 0.022703
[01:29:20.208] iteration 12568 : loss : 0.050932, loss_ce: 0.012551
[01:29:20.522] iteration 12569 : loss : 0.056967, loss_ce: 0.015019
[01:29:20.832] iteration 12570 : loss : 0.052044, loss_ce: 0.021139
[01:29:21.140] iteration 12571 : loss : 0.114350, loss_ce: 0.013562
[01:29:21.451] iteration 12572 : loss : 0.103050, loss_ce: 0.011180
[01:29:21.758] iteration 12573 : loss : 0.060920, loss_ce: 0.009822
[01:29:22.070] iteration 12574 : loss : 0.050588, loss_ce: 0.017837
[01:29:22.377] iteration 12575 : loss : 0.038932, loss_ce: 0.010591
[01:29:22.687] iteration 12576 : loss : 0.101124, loss_ce: 0.017037
[01:29:22.996] iteration 12577 : loss : 0.038813, loss_ce: 0.013164
[01:29:23.307] iteration 12578 : loss : 0.055513, loss_ce: 0.011391
[01:29:23.614] iteration 12579 : loss : 0.047373, loss_ce: 0.012228
[01:29:23.928] iteration 12580 : loss : 0.054707, loss_ce: 0.011369
[01:29:24.246] iteration 12581 : loss : 0.052556, loss_ce: 0.016768
[01:29:24.559] iteration 12582 : loss : 0.054888, loss_ce: 0.023171
[01:29:24.869] iteration 12583 : loss : 0.057568, loss_ce: 0.021630
[01:29:25.177] iteration 12584 : loss : 0.046115, loss_ce: 0.021842
[01:29:25.487] iteration 12585 : loss : 0.045847, loss_ce: 0.019934
[01:29:25.795] iteration 12586 : loss : 0.069003, loss_ce: 0.015958
[01:29:26.108] iteration 12587 : loss : 0.054274, loss_ce: 0.021300
[01:29:26.422] iteration 12588 : loss : 0.045306, loss_ce: 0.017666
[01:29:26.730] iteration 12589 : loss : 0.110187, loss_ce: 0.019550
[01:29:27.040] iteration 12590 : loss : 0.075428, loss_ce: 0.012229
[01:29:27.352] iteration 12591 : loss : 0.039702, loss_ce: 0.011306
[01:29:27.660] iteration 12592 : loss : 0.043820, loss_ce: 0.016748
[01:29:27.966] iteration 12593 : loss : 0.059604, loss_ce: 0.022445
[01:29:28.278] iteration 12594 : loss : 0.097874, loss_ce: 0.006059
[01:29:28.586] iteration 12595 : loss : 0.043305, loss_ce: 0.016140
[01:29:28.894] iteration 12596 : loss : 0.057360, loss_ce: 0.016938
[01:29:29.203] iteration 12597 : loss : 0.049738, loss_ce: 0.014046
[01:29:29.513] iteration 12598 : loss : 0.044341, loss_ce: 0.016572
[01:29:29.817] iteration 12599 : loss : 0.052996, loss_ce: 0.018445
[01:29:30.126] iteration 12600 : loss : 0.062237, loss_ce: 0.025431
[01:29:30.450] iteration 12601 : loss : 0.063124, loss_ce: 0.022029
[01:29:30.757] iteration 12602 : loss : 0.122076, loss_ce: 0.012032
[01:29:31.068] iteration 12603 : loss : 0.078509, loss_ce: 0.009252
[01:29:31.377] iteration 12604 : loss : 0.102084, loss_ce: 0.009553
[01:29:31.684] iteration 12605 : loss : 0.057909, loss_ce: 0.021608
[01:29:31.995] iteration 12606 : loss : 0.111762, loss_ce: 0.014044
[01:29:32.303] iteration 12607 : loss : 0.061335, loss_ce: 0.023622
[01:29:32.614] iteration 12608 : loss : 0.079199, loss_ce: 0.013427
[01:29:32.928] iteration 12609 : loss : 0.045813, loss_ce: 0.015430
[01:29:33.236] iteration 12610 : loss : 0.064165, loss_ce: 0.011729
[01:29:33.547] iteration 12611 : loss : 0.083898, loss_ce: 0.012351
[01:29:33.855] iteration 12612 : loss : 0.051931, loss_ce: 0.016565
[01:29:34.162] iteration 12613 : loss : 0.044623, loss_ce: 0.019223
[01:29:34.470] iteration 12614 : loss : 0.053296, loss_ce: 0.008613
[01:29:34.776] iteration 12615 : loss : 0.052659, loss_ce: 0.017199
[01:29:35.077] iteration 12616 : loss : 0.065721, loss_ce: 0.014658
[01:29:35.380] iteration 12617 : loss : 0.200675, loss_ce: 0.005058
[01:29:35.686] iteration 12618 : loss : 0.046469, loss_ce: 0.011793
[01:29:35.989] iteration 12619 : loss : 0.044163, loss_ce: 0.017311
[01:29:36.292] iteration 12620 : loss : 0.041332, loss_ce: 0.012536
[01:29:36.617] iteration 12621 : loss : 0.046292, loss_ce: 0.013628
[01:29:36.920] iteration 12622 : loss : 0.045303, loss_ce: 0.015354
[01:29:37.223] iteration 12623 : loss : 0.058524, loss_ce: 0.018781
[01:29:37.529] iteration 12624 : loss : 0.106074, loss_ce: 0.009650
[01:29:37.840] iteration 12625 : loss : 0.047943, loss_ce: 0.020801
[01:29:38.147] iteration 12626 : loss : 0.063741, loss_ce: 0.014855
[01:29:38.453] iteration 12627 : loss : 0.104010, loss_ce: 0.015774
[01:29:38.761] iteration 12628 : loss : 0.075327, loss_ce: 0.012709
[01:29:39.067] iteration 12629 : loss : 0.145495, loss_ce: 0.006134
[01:29:39.374] iteration 12630 : loss : 0.100081, loss_ce: 0.012029
[01:29:39.681] iteration 12631 : loss : 0.111041, loss_ce: 0.019087
[01:29:39.985] iteration 12632 : loss : 0.225485, loss_ce: 0.007929
[01:29:40.296] iteration 12633 : loss : 0.166029, loss_ce: 0.015704
[01:29:40.608] iteration 12634 : loss : 0.055620, loss_ce: 0.006093
[01:29:40.920] iteration 12635 : loss : 0.053937, loss_ce: 0.015100
[01:29:41.240] iteration 12636 : loss : 0.110655, loss_ce: 0.015277
[01:29:41.542] iteration 12637 : loss : 0.053838, loss_ce: 0.020217
[01:29:41.851] iteration 12638 : loss : 0.111099, loss_ce: 0.018792
[01:29:42.160] iteration 12639 : loss : 0.049454, loss_ce: 0.012638
[01:29:42.467] iteration 12640 : loss : 0.060771, loss_ce: 0.012708
[01:29:42.794] iteration 12641 : loss : 0.105408, loss_ce: 0.011210
[01:29:43.103] iteration 12642 : loss : 0.057147, loss_ce: 0.008932
[01:29:43.416] iteration 12643 : loss : 0.049323, loss_ce: 0.008015
[01:29:43.726] iteration 12644 : loss : 0.059332, loss_ce: 0.010312
[01:29:44.034] iteration 12645 : loss : 0.050589, loss_ce: 0.011067
[01:29:44.341] iteration 12646 : loss : 0.047341, loss_ce: 0.015218
[01:29:44.654] iteration 12647 : loss : 0.106475, loss_ce: 0.016207
[01:29:44.966] iteration 12648 : loss : 0.052537, loss_ce: 0.013087
[01:29:45.049] iteration 12649 : loss : 0.283762, loss_ce: 0.009077
[01:29:45.632] save model to ./logs/swin_unet\epoch_90.pth
[01:30:05.726] iteration 12650 : loss : 0.041251, loss_ce: 0.013337
[01:30:06.023] iteration 12651 : loss : 0.107051, loss_ce: 0.013830
[01:30:06.321] iteration 12652 : loss : 0.054319, loss_ce: 0.016878
[01:30:06.627] iteration 12653 : loss : 0.056072, loss_ce: 0.022439
[01:30:06.928] iteration 12654 : loss : 0.052266, loss_ce: 0.025482
[01:30:07.228] iteration 12655 : loss : 0.053871, loss_ce: 0.008872
[01:30:07.529] iteration 12656 : loss : 0.054515, loss_ce: 0.021152
[01:30:07.834] iteration 12657 : loss : 0.052980, loss_ce: 0.015567
[01:30:08.136] iteration 12658 : loss : 0.038009, loss_ce: 0.012446
[01:30:08.439] iteration 12659 : loss : 0.048211, loss_ce: 0.011509
[01:30:08.742] iteration 12660 : loss : 0.044634, loss_ce: 0.014100
[01:30:09.059] iteration 12661 : loss : 0.051520, loss_ce: 0.009878
[01:30:09.358] iteration 12662 : loss : 0.108725, loss_ce: 0.014081
[01:30:09.664] iteration 12663 : loss : 0.224344, loss_ce: 0.005915
[01:30:09.964] iteration 12664 : loss : 0.050068, loss_ce: 0.015381
[01:30:10.264] iteration 12665 : loss : 0.085388, loss_ce: 0.029151
[01:30:10.571] iteration 12666 : loss : 0.047461, loss_ce: 0.016354
[01:30:10.876] iteration 12667 : loss : 0.050433, loss_ce: 0.017961
[01:30:11.180] iteration 12668 : loss : 0.054040, loss_ce: 0.016430
[01:30:11.481] iteration 12669 : loss : 0.108377, loss_ce: 0.014305
[01:30:11.787] iteration 12670 : loss : 0.048513, loss_ce: 0.017125
[01:30:12.087] iteration 12671 : loss : 0.106232, loss_ce: 0.016283
[01:30:12.389] iteration 12672 : loss : 0.044805, loss_ce: 0.014256
[01:30:12.693] iteration 12673 : loss : 0.040182, loss_ce: 0.015718
[01:30:12.997] iteration 12674 : loss : 0.056360, loss_ce: 0.012253
[01:30:13.298] iteration 12675 : loss : 0.048208, loss_ce: 0.011115
[01:30:13.602] iteration 12676 : loss : 0.052540, loss_ce: 0.011755
[01:30:13.908] iteration 12677 : loss : 0.045803, loss_ce: 0.016042
[01:30:14.212] iteration 12678 : loss : 0.050184, loss_ce: 0.012215
[01:30:14.512] iteration 12679 : loss : 0.054149, loss_ce: 0.026698
[01:30:14.813] iteration 12680 : loss : 0.063392, loss_ce: 0.018428
[01:30:15.130] iteration 12681 : loss : 0.051506, loss_ce: 0.017323
[01:30:15.430] iteration 12682 : loss : 0.061878, loss_ce: 0.023241
[01:30:15.734] iteration 12683 : loss : 0.081063, loss_ce: 0.013548
[01:30:16.035] iteration 12684 : loss : 0.051337, loss_ce: 0.013987
[01:30:16.336] iteration 12685 : loss : 0.284039, loss_ce: 0.009486
[01:30:16.642] iteration 12686 : loss : 0.053199, loss_ce: 0.021287
[01:30:16.946] iteration 12687 : loss : 0.050349, loss_ce: 0.017524
[01:30:17.254] iteration 12688 : loss : 0.100460, loss_ce: 0.010558
[01:30:17.561] iteration 12689 : loss : 0.057341, loss_ce: 0.012754
[01:30:17.871] iteration 12690 : loss : 0.048964, loss_ce: 0.017001
[01:30:18.181] iteration 12691 : loss : 0.052228, loss_ce: 0.018799
[01:30:18.491] iteration 12692 : loss : 0.056650, loss_ce: 0.014010
[01:30:18.805] iteration 12693 : loss : 0.127599, loss_ce: 0.010835
[01:30:19.117] iteration 12694 : loss : 0.106960, loss_ce: 0.009893
[01:30:19.418] iteration 12695 : loss : 0.106416, loss_ce: 0.010816
[01:30:19.723] iteration 12696 : loss : 0.228526, loss_ce: 0.004209
[01:30:20.026] iteration 12697 : loss : 0.046401, loss_ce: 0.022707
[01:30:20.327] iteration 12698 : loss : 0.055702, loss_ce: 0.017577
[01:30:20.632] iteration 12699 : loss : 0.052704, loss_ce: 0.016343
[01:30:20.934] iteration 12700 : loss : 0.064606, loss_ce: 0.016666
[01:30:21.261] iteration 12701 : loss : 0.068360, loss_ce: 0.024227
[01:30:21.564] iteration 12702 : loss : 0.052883, loss_ce: 0.014523
[01:30:21.872] iteration 12703 : loss : 0.058552, loss_ce: 0.014294
[01:30:22.176] iteration 12704 : loss : 0.047024, loss_ce: 0.018221
[01:30:22.478] iteration 12705 : loss : 0.102943, loss_ce: 0.010920
[01:30:22.781] iteration 12706 : loss : 0.040499, loss_ce: 0.008989
[01:30:23.083] iteration 12707 : loss : 0.079800, loss_ce: 0.006323
[01:30:23.392] iteration 12708 : loss : 0.045535, loss_ce: 0.008430
[01:30:23.698] iteration 12709 : loss : 0.048639, loss_ce: 0.024209
[01:30:24.003] iteration 12710 : loss : 0.050835, loss_ce: 0.019227
[01:30:24.307] iteration 12711 : loss : 0.057711, loss_ce: 0.012541
[01:30:24.614] iteration 12712 : loss : 0.094417, loss_ce: 0.019069
[01:30:24.916] iteration 12713 : loss : 0.046189, loss_ce: 0.018330
[01:30:25.220] iteration 12714 : loss : 0.168900, loss_ce: 0.006171
[01:30:25.522] iteration 12715 : loss : 0.114783, loss_ce: 0.010177
[01:30:25.823] iteration 12716 : loss : 0.049331, loss_ce: 0.025037
[01:30:26.124] iteration 12717 : loss : 0.106722, loss_ce: 0.012274
[01:30:26.428] iteration 12718 : loss : 0.074279, loss_ce: 0.011671
[01:30:26.732] iteration 12719 : loss : 0.120021, loss_ce: 0.013317
[01:30:27.034] iteration 12720 : loss : 0.056456, loss_ce: 0.010815
[01:30:27.353] iteration 12721 : loss : 0.219112, loss_ce: 0.001672
[01:30:27.655] iteration 12722 : loss : 0.156604, loss_ce: 0.010288
[01:30:27.957] iteration 12723 : loss : 0.066168, loss_ce: 0.022920
[01:30:28.265] iteration 12724 : loss : 0.062274, loss_ce: 0.025518
[01:30:28.569] iteration 12725 : loss : 0.060904, loss_ce: 0.013476
[01:30:28.871] iteration 12726 : loss : 0.052399, loss_ce: 0.023902
[01:30:29.176] iteration 12727 : loss : 0.106466, loss_ce: 0.008459
[01:30:29.478] iteration 12728 : loss : 0.056785, loss_ce: 0.030290
[01:30:29.782] iteration 12729 : loss : 0.037710, loss_ce: 0.010006
[01:30:30.088] iteration 12730 : loss : 0.048100, loss_ce: 0.020478
[01:30:30.392] iteration 12731 : loss : 0.051090, loss_ce: 0.020166
[01:30:30.696] iteration 12732 : loss : 0.046304, loss_ce: 0.018182
[01:30:31.001] iteration 12733 : loss : 0.043154, loss_ce: 0.015071
[01:30:31.304] iteration 12734 : loss : 0.107033, loss_ce: 0.017999
[01:30:31.606] iteration 12735 : loss : 0.104872, loss_ce: 0.005630
[01:30:31.910] iteration 12736 : loss : 0.049076, loss_ce: 0.016974
[01:30:32.212] iteration 12737 : loss : 0.109499, loss_ce: 0.013180
[01:30:32.516] iteration 12738 : loss : 0.044468, loss_ce: 0.020307
[01:30:32.820] iteration 12739 : loss : 0.109879, loss_ce: 0.012472
[01:30:33.122] iteration 12740 : loss : 0.048899, loss_ce: 0.016101
[01:30:33.444] iteration 12741 : loss : 0.048053, loss_ce: 0.015934
[01:30:33.751] iteration 12742 : loss : 0.151338, loss_ce: 0.007807
[01:30:34.058] iteration 12743 : loss : 0.048230, loss_ce: 0.015484
[01:30:34.362] iteration 12744 : loss : 0.111979, loss_ce: 0.007744
[01:30:34.668] iteration 12745 : loss : 0.112115, loss_ce: 0.014833
[01:30:34.972] iteration 12746 : loss : 0.105826, loss_ce: 0.013448
[01:30:35.278] iteration 12747 : loss : 0.091701, loss_ce: 0.006539
[01:30:35.583] iteration 12748 : loss : 0.039704, loss_ce: 0.010414
[01:30:35.896] iteration 12749 : loss : 0.213298, loss_ce: 0.007072
[01:30:36.200] iteration 12750 : loss : 0.052597, loss_ce: 0.017241
[01:30:36.511] iteration 12751 : loss : 0.064020, loss_ce: 0.017419
[01:30:36.817] iteration 12752 : loss : 0.104616, loss_ce: 0.013653
[01:30:37.131] iteration 12753 : loss : 0.125356, loss_ce: 0.018047
[01:30:37.440] iteration 12754 : loss : 0.048708, loss_ce: 0.018671
[01:30:37.748] iteration 12755 : loss : 0.060507, loss_ce: 0.011072
[01:30:38.055] iteration 12756 : loss : 0.042470, loss_ce: 0.008635
[01:30:38.364] iteration 12757 : loss : 0.054426, loss_ce: 0.019094
[01:30:38.672] iteration 12758 : loss : 0.046994, loss_ce: 0.009256
[01:30:38.979] iteration 12759 : loss : 0.114106, loss_ce: 0.010656
[01:30:39.289] iteration 12760 : loss : 0.040873, loss_ce: 0.007942
[01:30:39.609] iteration 12761 : loss : 0.055291, loss_ce: 0.018671
[01:30:39.918] iteration 12762 : loss : 0.053447, loss_ce: 0.015334
[01:30:40.224] iteration 12763 : loss : 0.110779, loss_ce: 0.012150
[01:30:40.532] iteration 12764 : loss : 0.050296, loss_ce: 0.017569
[01:30:40.838] iteration 12765 : loss : 0.050883, loss_ce: 0.022533
[01:30:41.145] iteration 12766 : loss : 0.108211, loss_ce: 0.007505
[01:30:41.453] iteration 12767 : loss : 0.229767, loss_ce: 0.003797
[01:30:41.764] iteration 12768 : loss : 0.050488, loss_ce: 0.014203
[01:30:42.072] iteration 12769 : loss : 0.113287, loss_ce: 0.010801
[01:30:42.381] iteration 12770 : loss : 0.050982, loss_ce: 0.022541
[01:30:42.691] iteration 12771 : loss : 0.092303, loss_ce: 0.012525
[01:30:43.002] iteration 12772 : loss : 0.050224, loss_ce: 0.009660
[01:30:43.313] iteration 12773 : loss : 0.047493, loss_ce: 0.009189
[01:30:43.630] iteration 12774 : loss : 0.051670, loss_ce: 0.017054
[01:30:43.945] iteration 12775 : loss : 0.046814, loss_ce: 0.016904
[01:30:44.255] iteration 12776 : loss : 0.067028, loss_ce: 0.030212
[01:30:44.564] iteration 12777 : loss : 0.043016, loss_ce: 0.023046
[01:30:44.877] iteration 12778 : loss : 0.065878, loss_ce: 0.018077
[01:30:45.192] iteration 12779 : loss : 0.048368, loss_ce: 0.011757
[01:30:45.503] iteration 12780 : loss : 0.107267, loss_ce: 0.007855
[01:30:45.830] iteration 12781 : loss : 0.063762, loss_ce: 0.021304
[01:30:46.137] iteration 12782 : loss : 0.056248, loss_ce: 0.015035
[01:30:46.449] iteration 12783 : loss : 0.061636, loss_ce: 0.013677
[01:30:46.759] iteration 12784 : loss : 0.051115, loss_ce: 0.018430
[01:30:47.066] iteration 12785 : loss : 0.050034, loss_ce: 0.016737
[01:30:47.378] iteration 12786 : loss : 0.056638, loss_ce: 0.012438
[01:30:47.692] iteration 12787 : loss : 0.111984, loss_ce: 0.008406
[01:30:47.775] iteration 12788 : loss : 0.308145, loss_ce: 0.026266
[01:31:05.819] iteration 12789 : loss : 0.057296, loss_ce: 0.016723
[01:31:06.119] iteration 12790 : loss : 0.050854, loss_ce: 0.007053
[01:31:06.421] iteration 12791 : loss : 0.053062, loss_ce: 0.011863
[01:31:06.728] iteration 12792 : loss : 0.149738, loss_ce: 0.015974
[01:31:07.031] iteration 12793 : loss : 0.042942, loss_ce: 0.013532
[01:31:07.336] iteration 12794 : loss : 0.044214, loss_ce: 0.013904
[01:31:07.644] iteration 12795 : loss : 0.057266, loss_ce: 0.017305
[01:31:07.950] iteration 12796 : loss : 0.053117, loss_ce: 0.017376
[01:31:08.259] iteration 12797 : loss : 0.059621, loss_ce: 0.021928
[01:31:08.570] iteration 12798 : loss : 0.060230, loss_ce: 0.016480
[01:31:08.877] iteration 12799 : loss : 0.048127, loss_ce: 0.015984
[01:31:09.188] iteration 12800 : loss : 0.114095, loss_ce: 0.011581
[01:31:09.506] iteration 12801 : loss : 0.059988, loss_ce: 0.022995
[01:31:09.809] iteration 12802 : loss : 0.041363, loss_ce: 0.011140
[01:31:10.115] iteration 12803 : loss : 0.064829, loss_ce: 0.011211
[01:31:10.417] iteration 12804 : loss : 0.118910, loss_ce: 0.018508
[01:31:10.721] iteration 12805 : loss : 0.038926, loss_ce: 0.013959
[01:31:11.028] iteration 12806 : loss : 0.132701, loss_ce: 0.010973
[01:31:11.330] iteration 12807 : loss : 0.058044, loss_ce: 0.009017
[01:31:11.638] iteration 12808 : loss : 0.042349, loss_ce: 0.020403
[01:31:11.943] iteration 12809 : loss : 0.046424, loss_ce: 0.016617
[01:31:12.247] iteration 12810 : loss : 0.065943, loss_ce: 0.011187
[01:31:12.552] iteration 12811 : loss : 0.045932, loss_ce: 0.016489
[01:31:12.857] iteration 12812 : loss : 0.047014, loss_ce: 0.012636
[01:31:13.164] iteration 12813 : loss : 0.050028, loss_ce: 0.018974
[01:31:13.468] iteration 12814 : loss : 0.111930, loss_ce: 0.021116
[01:31:13.772] iteration 12815 : loss : 0.049091, loss_ce: 0.013004
[01:31:14.076] iteration 12816 : loss : 0.126395, loss_ce: 0.008355
[01:31:14.382] iteration 12817 : loss : 0.047231, loss_ce: 0.015586
[01:31:14.688] iteration 12818 : loss : 0.059615, loss_ce: 0.017178
[01:31:14.994] iteration 12819 : loss : 0.074010, loss_ce: 0.022016
[01:31:15.301] iteration 12820 : loss : 0.041675, loss_ce: 0.013165
[01:31:15.625] iteration 12821 : loss : 0.064854, loss_ce: 0.021348
[01:31:15.927] iteration 12822 : loss : 0.053523, loss_ce: 0.017190
[01:31:16.233] iteration 12823 : loss : 0.052057, loss_ce: 0.022538
[01:31:16.536] iteration 12824 : loss : 0.060411, loss_ce: 0.012483
[01:31:16.841] iteration 12825 : loss : 0.053929, loss_ce: 0.020242
[01:31:17.147] iteration 12826 : loss : 0.062676, loss_ce: 0.019565
[01:31:17.456] iteration 12827 : loss : 0.053996, loss_ce: 0.017501
[01:31:17.768] iteration 12828 : loss : 0.050493, loss_ce: 0.013203
[01:31:18.076] iteration 12829 : loss : 0.047861, loss_ce: 0.010696
[01:31:18.384] iteration 12830 : loss : 0.041990, loss_ce: 0.014448
[01:31:18.690] iteration 12831 : loss : 0.092927, loss_ce: 0.016204
[01:31:18.994] iteration 12832 : loss : 0.114782, loss_ce: 0.019967
[01:31:19.299] iteration 12833 : loss : 0.074121, loss_ce: 0.016522
[01:31:19.603] iteration 12834 : loss : 0.040414, loss_ce: 0.013217
[01:31:19.909] iteration 12835 : loss : 0.047542, loss_ce: 0.010751
[01:31:20.217] iteration 12836 : loss : 0.046007, loss_ce: 0.012695
[01:31:20.520] iteration 12837 : loss : 0.039786, loss_ce: 0.009549
[01:31:20.824] iteration 12838 : loss : 0.119227, loss_ce: 0.006585
[01:31:21.129] iteration 12839 : loss : 0.047955, loss_ce: 0.017604
[01:31:21.433] iteration 12840 : loss : 0.048099, loss_ce: 0.016871
[01:31:21.744] iteration 12841 : loss : 0.054530, loss_ce: 0.016757
[01:31:22.047] iteration 12842 : loss : 0.110599, loss_ce: 0.015067
[01:31:22.355] iteration 12843 : loss : 0.066441, loss_ce: 0.030418
[01:31:22.669] iteration 12844 : loss : 0.121312, loss_ce: 0.016580
[01:31:22.979] iteration 12845 : loss : 0.040437, loss_ce: 0.012287
[01:31:23.288] iteration 12846 : loss : 0.048654, loss_ce: 0.019632
[01:31:23.599] iteration 12847 : loss : 0.050714, loss_ce: 0.024128
[01:31:23.913] iteration 12848 : loss : 0.070228, loss_ce: 0.015787
[01:31:24.219] iteration 12849 : loss : 0.049015, loss_ce: 0.020962
[01:31:24.523] iteration 12850 : loss : 0.045222, loss_ce: 0.014743
[01:31:24.823] iteration 12851 : loss : 0.054668, loss_ce: 0.014896
[01:31:25.126] iteration 12852 : loss : 0.047077, loss_ce: 0.014922
[01:31:25.429] iteration 12853 : loss : 0.058805, loss_ce: 0.019071
[01:31:25.732] iteration 12854 : loss : 0.117596, loss_ce: 0.012723
[01:31:26.034] iteration 12855 : loss : 0.058437, loss_ce: 0.017721
[01:31:26.338] iteration 12856 : loss : 0.050390, loss_ce: 0.024475
[01:31:26.643] iteration 12857 : loss : 0.107831, loss_ce: 0.007674
[01:31:26.947] iteration 12858 : loss : 0.050883, loss_ce: 0.019914
[01:31:27.250] iteration 12859 : loss : 0.164980, loss_ce: 0.005823
[01:31:27.554] iteration 12860 : loss : 0.040587, loss_ce: 0.016429
[01:31:27.872] iteration 12861 : loss : 0.055069, loss_ce: 0.015288
[01:31:28.175] iteration 12862 : loss : 0.051551, loss_ce: 0.017613
[01:31:28.479] iteration 12863 : loss : 0.051750, loss_ce: 0.010862
[01:31:28.786] iteration 12864 : loss : 0.046881, loss_ce: 0.007783
[01:31:29.092] iteration 12865 : loss : 0.055166, loss_ce: 0.018294
[01:31:29.394] iteration 12866 : loss : 0.117360, loss_ce: 0.010554
[01:31:29.697] iteration 12867 : loss : 0.049014, loss_ce: 0.016074
[01:31:30.004] iteration 12868 : loss : 0.097128, loss_ce: 0.011693
[01:31:30.308] iteration 12869 : loss : 0.114897, loss_ce: 0.008843
[01:31:30.614] iteration 12870 : loss : 0.166391, loss_ce: 0.007115
[01:31:30.917] iteration 12871 : loss : 0.097783, loss_ce: 0.011973
[01:31:31.222] iteration 12872 : loss : 0.060512, loss_ce: 0.031052
[01:31:31.527] iteration 12873 : loss : 0.062851, loss_ce: 0.029407
[01:31:31.831] iteration 12874 : loss : 0.088300, loss_ce: 0.014771
[01:31:32.133] iteration 12875 : loss : 0.046257, loss_ce: 0.014907
[01:31:32.437] iteration 12876 : loss : 0.050526, loss_ce: 0.011198
[01:31:32.740] iteration 12877 : loss : 0.067579, loss_ce: 0.012219
[01:31:33.042] iteration 12878 : loss : 0.049508, loss_ce: 0.018247
[01:31:33.343] iteration 12879 : loss : 0.054408, loss_ce: 0.016666
[01:31:33.648] iteration 12880 : loss : 0.107703, loss_ce: 0.017277
[01:31:33.964] iteration 12881 : loss : 0.050704, loss_ce: 0.024032
[01:31:34.268] iteration 12882 : loss : 0.102878, loss_ce: 0.007537
[01:31:34.573] iteration 12883 : loss : 0.102097, loss_ce: 0.005924
[01:31:34.879] iteration 12884 : loss : 0.047562, loss_ce: 0.011691
[01:31:35.184] iteration 12885 : loss : 0.227495, loss_ce: 0.015145
[01:31:35.487] iteration 12886 : loss : 0.050042, loss_ce: 0.017071
[01:31:35.792] iteration 12887 : loss : 0.043790, loss_ce: 0.008264
[01:31:36.095] iteration 12888 : loss : 0.113458, loss_ce: 0.005118
[01:31:36.398] iteration 12889 : loss : 0.083230, loss_ce: 0.014483
[01:31:36.701] iteration 12890 : loss : 0.096316, loss_ce: 0.018888
[01:31:37.004] iteration 12891 : loss : 0.105298, loss_ce: 0.013155
[01:31:37.310] iteration 12892 : loss : 0.101348, loss_ce: 0.008434
[01:31:37.619] iteration 12893 : loss : 0.042413, loss_ce: 0.010188
[01:31:37.930] iteration 12894 : loss : 0.040879, loss_ce: 0.016139
[01:31:38.240] iteration 12895 : loss : 0.056686, loss_ce: 0.020088
[01:31:38.555] iteration 12896 : loss : 0.054560, loss_ce: 0.017876
[01:31:38.864] iteration 12897 : loss : 0.061181, loss_ce: 0.010266
[01:31:39.173] iteration 12898 : loss : 0.046910, loss_ce: 0.008643
[01:31:39.476] iteration 12899 : loss : 0.049132, loss_ce: 0.018856
[01:31:39.779] iteration 12900 : loss : 0.176554, loss_ce: 0.013390
[01:31:40.099] iteration 12901 : loss : 0.064041, loss_ce: 0.017688
[01:31:40.404] iteration 12902 : loss : 0.042828, loss_ce: 0.013195
[01:31:40.713] iteration 12903 : loss : 0.056237, loss_ce: 0.011123
[01:31:41.017] iteration 12904 : loss : 0.047448, loss_ce: 0.017919
[01:31:41.322] iteration 12905 : loss : 0.068523, loss_ce: 0.013956
[01:31:41.625] iteration 12906 : loss : 0.046740, loss_ce: 0.018321
[01:31:41.932] iteration 12907 : loss : 0.116044, loss_ce: 0.007108
[01:31:42.236] iteration 12908 : loss : 0.043552, loss_ce: 0.010498
[01:31:42.542] iteration 12909 : loss : 0.050386, loss_ce: 0.020253
[01:31:42.849] iteration 12910 : loss : 0.046381, loss_ce: 0.009889
[01:31:43.158] iteration 12911 : loss : 0.049174, loss_ce: 0.021920
[01:31:43.467] iteration 12912 : loss : 0.053745, loss_ce: 0.012612
[01:31:43.778] iteration 12913 : loss : 0.054372, loss_ce: 0.021390
[01:31:44.086] iteration 12914 : loss : 0.042629, loss_ce: 0.012625
[01:31:44.399] iteration 12915 : loss : 0.043913, loss_ce: 0.016441
[01:31:44.714] iteration 12916 : loss : 0.042231, loss_ce: 0.012398
[01:31:45.025] iteration 12917 : loss : 0.109228, loss_ce: 0.012779
[01:31:45.331] iteration 12918 : loss : 0.041538, loss_ce: 0.013041
[01:31:45.637] iteration 12919 : loss : 0.044694, loss_ce: 0.016815
[01:31:45.945] iteration 12920 : loss : 0.047099, loss_ce: 0.011666
[01:31:46.290] iteration 12921 : loss : 0.102195, loss_ce: 0.012221
[01:31:46.596] iteration 12922 : loss : 0.063595, loss_ce: 0.008621
[01:31:46.906] iteration 12923 : loss : 0.108711, loss_ce: 0.022052
[01:31:47.211] iteration 12924 : loss : 0.055447, loss_ce: 0.010175
[01:31:47.522] iteration 12925 : loss : 0.102301, loss_ce: 0.012830
[01:31:47.831] iteration 12926 : loss : 0.046001, loss_ce: 0.016527
[01:31:47.912] iteration 12927 : loss : 0.054043, loss_ce: 0.030163
[01:32:05.719] iteration 12928 : loss : 0.046883, loss_ce: 0.011409
[01:32:06.020] iteration 12929 : loss : 0.058736, loss_ce: 0.011915
[01:32:06.326] iteration 12930 : loss : 0.103803, loss_ce: 0.009237
[01:32:06.629] iteration 12931 : loss : 0.054452, loss_ce: 0.018972
[01:32:06.932] iteration 12932 : loss : 0.144637, loss_ce: 0.003669
[01:32:07.239] iteration 12933 : loss : 0.156587, loss_ce: 0.007452
[01:32:07.546] iteration 12934 : loss : 0.071637, loss_ce: 0.028106
[01:32:07.851] iteration 12935 : loss : 0.058332, loss_ce: 0.010934
[01:32:08.155] iteration 12936 : loss : 0.055208, loss_ce: 0.021445
[01:32:08.462] iteration 12937 : loss : 0.087925, loss_ce: 0.014627
[01:32:08.766] iteration 12938 : loss : 0.116309, loss_ce: 0.006045
[01:32:09.075] iteration 12939 : loss : 0.051308, loss_ce: 0.017222
[01:32:09.382] iteration 12940 : loss : 0.052947, loss_ce: 0.024085
[01:32:09.705] iteration 12941 : loss : 0.111764, loss_ce: 0.010930
[01:32:10.006] iteration 12942 : loss : 0.067454, loss_ce: 0.028975
[01:32:10.311] iteration 12943 : loss : 0.051924, loss_ce: 0.010503
[01:32:10.620] iteration 12944 : loss : 0.047499, loss_ce: 0.018142
[01:32:10.927] iteration 12945 : loss : 0.045226, loss_ce: 0.007534
[01:32:11.233] iteration 12946 : loss : 0.056777, loss_ce: 0.021784
[01:32:11.540] iteration 12947 : loss : 0.061563, loss_ce: 0.014991
[01:32:11.849] iteration 12948 : loss : 0.103892, loss_ce: 0.011421
[01:32:12.154] iteration 12949 : loss : 0.049273, loss_ce: 0.023961
[01:32:12.464] iteration 12950 : loss : 0.051639, loss_ce: 0.016845
[01:32:12.770] iteration 12951 : loss : 0.091966, loss_ce: 0.008415
[01:32:13.076] iteration 12952 : loss : 0.079196, loss_ce: 0.013542
[01:32:13.380] iteration 12953 : loss : 0.059205, loss_ce: 0.012245
[01:32:13.689] iteration 12954 : loss : 0.057174, loss_ce: 0.011607
[01:32:14.000] iteration 12955 : loss : 0.102701, loss_ce: 0.011353
[01:32:14.305] iteration 12956 : loss : 0.053524, loss_ce: 0.015075
[01:32:14.608] iteration 12957 : loss : 0.044426, loss_ce: 0.017129
[01:32:14.911] iteration 12958 : loss : 0.061410, loss_ce: 0.014011
[01:32:15.214] iteration 12959 : loss : 0.107735, loss_ce: 0.006703
[01:32:15.518] iteration 12960 : loss : 0.048505, loss_ce: 0.011298
[01:32:15.839] iteration 12961 : loss : 0.045991, loss_ce: 0.011142
[01:32:16.140] iteration 12962 : loss : 0.041377, loss_ce: 0.014725
[01:32:16.446] iteration 12963 : loss : 0.109895, loss_ce: 0.018030
[01:32:16.749] iteration 12964 : loss : 0.036699, loss_ce: 0.014559
[01:32:17.052] iteration 12965 : loss : 0.063256, loss_ce: 0.016003
[01:32:17.352] iteration 12966 : loss : 0.037989, loss_ce: 0.011853
[01:32:17.656] iteration 12967 : loss : 0.046912, loss_ce: 0.010246
[01:32:17.959] iteration 12968 : loss : 0.105298, loss_ce: 0.017928
[01:32:18.261] iteration 12969 : loss : 0.038994, loss_ce: 0.011291
[01:32:18.563] iteration 12970 : loss : 0.059706, loss_ce: 0.015024
[01:32:18.869] iteration 12971 : loss : 0.044789, loss_ce: 0.014805
[01:32:19.168] iteration 12972 : loss : 0.061146, loss_ce: 0.013492
[01:32:19.473] iteration 12973 : loss : 0.075148, loss_ce: 0.015001
[01:32:19.775] iteration 12974 : loss : 0.055832, loss_ce: 0.024747
[01:32:20.080] iteration 12975 : loss : 0.156204, loss_ce: 0.009761
[01:32:20.383] iteration 12976 : loss : 0.035548, loss_ce: 0.011405
[01:32:20.685] iteration 12977 : loss : 0.044909, loss_ce: 0.012977
[01:32:20.984] iteration 12978 : loss : 0.057940, loss_ce: 0.027502
[01:32:21.287] iteration 12979 : loss : 0.110083, loss_ce: 0.017303
[01:32:21.591] iteration 12980 : loss : 0.170175, loss_ce: 0.012218
[01:32:21.910] iteration 12981 : loss : 0.046792, loss_ce: 0.022066
[01:32:22.211] iteration 12982 : loss : 0.058775, loss_ce: 0.023241
[01:32:22.514] iteration 12983 : loss : 0.067407, loss_ce: 0.015611
[01:32:22.818] iteration 12984 : loss : 0.062748, loss_ce: 0.027301
[01:32:23.121] iteration 12985 : loss : 0.159275, loss_ce: 0.005646
[01:32:23.421] iteration 12986 : loss : 0.106886, loss_ce: 0.013909
[01:32:23.725] iteration 12987 : loss : 0.105733, loss_ce: 0.012952
[01:32:24.027] iteration 12988 : loss : 0.048254, loss_ce: 0.019277
[01:32:24.330] iteration 12989 : loss : 0.053305, loss_ce: 0.017265
[01:32:24.633] iteration 12990 : loss : 0.054587, loss_ce: 0.011904
[01:32:24.937] iteration 12991 : loss : 0.049989, loss_ce: 0.018245
[01:32:25.239] iteration 12992 : loss : 0.107043, loss_ce: 0.011148
[01:32:25.544] iteration 12993 : loss : 0.048064, loss_ce: 0.013579
[01:32:25.845] iteration 12994 : loss : 0.059508, loss_ce: 0.012779
[01:32:26.151] iteration 12995 : loss : 0.060340, loss_ce: 0.021576
[01:32:26.456] iteration 12996 : loss : 0.042392, loss_ce: 0.011411
[01:32:26.760] iteration 12997 : loss : 0.045783, loss_ce: 0.016922
[01:32:27.062] iteration 12998 : loss : 0.043402, loss_ce: 0.006485
[01:32:27.367] iteration 12999 : loss : 0.125712, loss_ce: 0.009090
[01:32:27.681] iteration 13000 : loss : 0.050118, loss_ce: 0.019499
[01:32:28.005] iteration 13001 : loss : 0.064481, loss_ce: 0.022652
[01:32:28.310] iteration 13002 : loss : 0.069921, loss_ce: 0.011653
[01:32:28.622] iteration 13003 : loss : 0.059182, loss_ce: 0.020511
[01:32:28.929] iteration 13004 : loss : 0.044640, loss_ce: 0.007417
[01:32:29.239] iteration 13005 : loss : 0.099128, loss_ce: 0.008273
[01:32:29.543] iteration 13006 : loss : 0.065750, loss_ce: 0.025365
[01:32:29.849] iteration 13007 : loss : 0.046352, loss_ce: 0.017770
[01:32:30.152] iteration 13008 : loss : 0.112506, loss_ce: 0.020158
[01:32:30.456] iteration 13009 : loss : 0.055965, loss_ce: 0.012408
[01:32:30.760] iteration 13010 : loss : 0.049599, loss_ce: 0.017947
[01:32:31.065] iteration 13011 : loss : 0.049564, loss_ce: 0.016615
[01:32:31.366] iteration 13012 : loss : 0.041322, loss_ce: 0.012422
[01:32:31.674] iteration 13013 : loss : 0.054172, loss_ce: 0.015343
[01:32:31.977] iteration 13014 : loss : 0.049919, loss_ce: 0.009424
[01:32:32.279] iteration 13015 : loss : 0.060663, loss_ce: 0.016894
[01:32:32.582] iteration 13016 : loss : 0.047778, loss_ce: 0.022087
[01:32:32.887] iteration 13017 : loss : 0.045713, loss_ce: 0.026256
[01:32:33.190] iteration 13018 : loss : 0.241885, loss_ce: 0.010043
[01:32:33.496] iteration 13019 : loss : 0.162715, loss_ce: 0.009741
[01:32:33.799] iteration 13020 : loss : 0.051581, loss_ce: 0.023607
[01:32:34.115] iteration 13021 : loss : 0.042689, loss_ce: 0.019910
[01:32:34.416] iteration 13022 : loss : 0.075298, loss_ce: 0.025848
[01:32:34.718] iteration 13023 : loss : 0.045550, loss_ce: 0.020716
[01:32:35.021] iteration 13024 : loss : 0.045562, loss_ce: 0.021073
[01:32:35.327] iteration 13025 : loss : 0.048773, loss_ce: 0.014199
[01:32:35.628] iteration 13026 : loss : 0.049196, loss_ce: 0.016984
[01:32:35.933] iteration 13027 : loss : 0.115928, loss_ce: 0.013560
[01:32:36.235] iteration 13028 : loss : 0.116886, loss_ce: 0.015351
[01:32:36.537] iteration 13029 : loss : 0.055056, loss_ce: 0.018895
[01:32:36.842] iteration 13030 : loss : 0.101606, loss_ce: 0.013449
[01:32:37.147] iteration 13031 : loss : 0.055213, loss_ce: 0.012127
[01:32:37.449] iteration 13032 : loss : 0.042357, loss_ce: 0.013552
[01:32:37.752] iteration 13033 : loss : 0.040763, loss_ce: 0.014672
[01:32:38.062] iteration 13034 : loss : 0.058884, loss_ce: 0.013130
[01:32:38.365] iteration 13035 : loss : 0.043788, loss_ce: 0.018443
[01:32:38.670] iteration 13036 : loss : 0.044528, loss_ce: 0.019027
[01:32:38.974] iteration 13037 : loss : 0.107006, loss_ce: 0.011044
[01:32:39.278] iteration 13038 : loss : 0.059275, loss_ce: 0.014755
[01:32:39.581] iteration 13039 : loss : 0.085376, loss_ce: 0.007254
[01:32:39.886] iteration 13040 : loss : 0.158090, loss_ce: 0.011352
[01:32:40.205] iteration 13041 : loss : 0.049478, loss_ce: 0.020225
[01:32:40.508] iteration 13042 : loss : 0.079196, loss_ce: 0.009690
[01:32:40.814] iteration 13043 : loss : 0.116007, loss_ce: 0.006554
[01:32:41.115] iteration 13044 : loss : 0.102372, loss_ce: 0.008199
[01:32:41.419] iteration 13045 : loss : 0.046633, loss_ce: 0.015481
[01:32:41.726] iteration 13046 : loss : 0.038461, loss_ce: 0.017663
[01:32:42.032] iteration 13047 : loss : 0.056420, loss_ce: 0.007123
[01:32:42.343] iteration 13048 : loss : 0.052686, loss_ce: 0.014391
[01:32:42.648] iteration 13049 : loss : 0.133679, loss_ce: 0.011673
[01:32:42.957] iteration 13050 : loss : 0.051274, loss_ce: 0.016801
[01:32:43.264] iteration 13051 : loss : 0.112602, loss_ce: 0.016729
[01:32:43.572] iteration 13052 : loss : 0.050570, loss_ce: 0.010656
[01:32:43.880] iteration 13053 : loss : 0.043067, loss_ce: 0.008827
[01:32:44.192] iteration 13054 : loss : 0.052756, loss_ce: 0.020922
[01:32:44.502] iteration 13055 : loss : 0.047026, loss_ce: 0.008418
[01:32:44.811] iteration 13056 : loss : 0.051008, loss_ce: 0.008384
[01:32:45.116] iteration 13057 : loss : 0.045187, loss_ce: 0.012772
[01:32:45.431] iteration 13058 : loss : 0.041889, loss_ce: 0.014698
[01:32:45.742] iteration 13059 : loss : 0.059925, loss_ce: 0.019402
[01:32:46.056] iteration 13060 : loss : 0.051879, loss_ce: 0.013903
[01:32:46.395] iteration 13061 : loss : 0.116735, loss_ce: 0.013490
[01:32:46.705] iteration 13062 : loss : 0.059497, loss_ce: 0.021266
[01:32:47.017] iteration 13063 : loss : 0.042024, loss_ce: 0.014386
[01:32:47.327] iteration 13064 : loss : 0.159865, loss_ce: 0.006122
[01:32:47.638] iteration 13065 : loss : 0.105821, loss_ce: 0.019295
[01:32:47.721] iteration 13066 : loss : 0.226919, loss_ce: 0.008822
[01:33:05.366] iteration 13067 : loss : 0.050900, loss_ce: 0.020319
[01:33:05.662] iteration 13068 : loss : 0.110353, loss_ce: 0.028212
[01:33:05.965] iteration 13069 : loss : 0.114123, loss_ce: 0.010459
[01:33:06.268] iteration 13070 : loss : 0.218554, loss_ce: 0.006181
[01:33:06.571] iteration 13071 : loss : 0.417484, loss_ce: 0.001412
[01:33:06.874] iteration 13072 : loss : 0.046077, loss_ce: 0.011216
[01:33:07.177] iteration 13073 : loss : 0.057571, loss_ce: 0.013301
[01:33:07.481] iteration 13074 : loss : 0.042402, loss_ce: 0.007605
[01:33:07.783] iteration 13075 : loss : 0.054356, loss_ce: 0.018343
[01:33:08.084] iteration 13076 : loss : 0.043473, loss_ce: 0.018331
[01:33:08.387] iteration 13077 : loss : 0.050696, loss_ce: 0.020465
[01:33:08.693] iteration 13078 : loss : 0.041900, loss_ce: 0.015860
[01:33:08.999] iteration 13079 : loss : 0.056736, loss_ce: 0.014431
[01:33:09.300] iteration 13080 : loss : 0.049143, loss_ce: 0.009005
[01:33:09.625] iteration 13081 : loss : 0.041505, loss_ce: 0.017178
[01:33:09.929] iteration 13082 : loss : 0.108353, loss_ce: 0.013065
[01:33:10.233] iteration 13083 : loss : 0.087061, loss_ce: 0.014795
[01:33:10.536] iteration 13084 : loss : 0.071722, loss_ce: 0.015214
[01:33:10.838] iteration 13085 : loss : 0.088028, loss_ce: 0.018292
[01:33:11.144] iteration 13086 : loss : 0.115697, loss_ce: 0.014097
[01:33:11.450] iteration 13087 : loss : 0.045767, loss_ce: 0.014206
[01:33:11.758] iteration 13088 : loss : 0.071890, loss_ce: 0.016955
[01:33:12.063] iteration 13089 : loss : 0.041842, loss_ce: 0.006676
[01:33:12.368] iteration 13090 : loss : 0.040287, loss_ce: 0.013110
[01:33:12.670] iteration 13091 : loss : 0.043382, loss_ce: 0.008601
[01:33:12.973] iteration 13092 : loss : 0.043194, loss_ce: 0.015036
[01:33:13.275] iteration 13093 : loss : 0.044725, loss_ce: 0.010386
[01:33:13.581] iteration 13094 : loss : 0.048076, loss_ce: 0.013316
[01:33:13.887] iteration 13095 : loss : 0.048378, loss_ce: 0.010665
[01:33:14.190] iteration 13096 : loss : 0.045453, loss_ce: 0.010332
[01:33:14.497] iteration 13097 : loss : 0.051451, loss_ce: 0.009634
[01:33:14.799] iteration 13098 : loss : 0.057079, loss_ce: 0.016016
[01:33:15.105] iteration 13099 : loss : 0.048854, loss_ce: 0.013478
[01:33:15.411] iteration 13100 : loss : 0.078023, loss_ce: 0.016762
[01:33:15.735] iteration 13101 : loss : 0.046864, loss_ce: 0.016202
[01:33:16.038] iteration 13102 : loss : 0.038456, loss_ce: 0.007638
[01:33:16.345] iteration 13103 : loss : 0.120406, loss_ce: 0.010081
[01:33:16.649] iteration 13104 : loss : 0.051763, loss_ce: 0.017978
[01:33:16.953] iteration 13105 : loss : 0.052560, loss_ce: 0.016610
[01:33:17.266] iteration 13106 : loss : 0.058029, loss_ce: 0.012848
[01:33:17.573] iteration 13107 : loss : 0.057117, loss_ce: 0.027400
[01:33:17.884] iteration 13108 : loss : 0.040939, loss_ce: 0.021835
[01:33:18.193] iteration 13109 : loss : 0.113919, loss_ce: 0.013300
[01:33:18.504] iteration 13110 : loss : 0.106728, loss_ce: 0.011840
[01:33:18.817] iteration 13111 : loss : 0.050342, loss_ce: 0.013235
[01:33:19.129] iteration 13112 : loss : 0.058329, loss_ce: 0.020793
[01:33:19.432] iteration 13113 : loss : 0.047809, loss_ce: 0.021282
[01:33:19.738] iteration 13114 : loss : 0.051605, loss_ce: 0.013264
[01:33:20.042] iteration 13115 : loss : 0.042596, loss_ce: 0.017975
[01:33:20.346] iteration 13116 : loss : 0.041468, loss_ce: 0.016377
[01:33:20.653] iteration 13117 : loss : 0.055041, loss_ce: 0.015165
[01:33:20.958] iteration 13118 : loss : 0.049345, loss_ce: 0.024472
[01:33:21.260] iteration 13119 : loss : 0.051950, loss_ce: 0.010071
[01:33:21.562] iteration 13120 : loss : 0.096445, loss_ce: 0.004465
[01:33:21.880] iteration 13121 : loss : 0.050590, loss_ce: 0.019970
[01:33:22.181] iteration 13122 : loss : 0.052947, loss_ce: 0.019005
[01:33:22.483] iteration 13123 : loss : 0.099184, loss_ce: 0.010936
[01:33:22.784] iteration 13124 : loss : 0.069390, loss_ce: 0.016210
[01:33:23.087] iteration 13125 : loss : 0.043999, loss_ce: 0.015185
[01:33:23.392] iteration 13126 : loss : 0.055734, loss_ce: 0.019450
[01:33:23.694] iteration 13127 : loss : 0.080004, loss_ce: 0.017050
[01:33:23.999] iteration 13128 : loss : 0.067621, loss_ce: 0.009464
[01:33:24.303] iteration 13129 : loss : 0.047622, loss_ce: 0.009298
[01:33:24.605] iteration 13130 : loss : 0.041718, loss_ce: 0.013089
[01:33:24.912] iteration 13131 : loss : 0.077364, loss_ce: 0.010142
[01:33:25.219] iteration 13132 : loss : 0.042701, loss_ce: 0.013314
[01:33:25.526] iteration 13133 : loss : 0.038658, loss_ce: 0.011721
[01:33:25.830] iteration 13134 : loss : 0.050182, loss_ce: 0.015143
[01:33:26.134] iteration 13135 : loss : 0.052752, loss_ce: 0.020889
[01:33:26.442] iteration 13136 : loss : 0.057358, loss_ce: 0.016107
[01:33:26.746] iteration 13137 : loss : 0.054565, loss_ce: 0.013898
[01:33:27.051] iteration 13138 : loss : 0.054047, loss_ce: 0.016908
[01:33:27.352] iteration 13139 : loss : 0.165796, loss_ce: 0.007443
[01:33:27.653] iteration 13140 : loss : 0.059340, loss_ce: 0.017902
[01:33:27.974] iteration 13141 : loss : 0.047468, loss_ce: 0.012750
[01:33:28.275] iteration 13142 : loss : 0.049733, loss_ce: 0.007507
[01:33:28.580] iteration 13143 : loss : 0.061549, loss_ce: 0.013798
[01:33:28.882] iteration 13144 : loss : 0.065425, loss_ce: 0.012538
[01:33:29.184] iteration 13145 : loss : 0.110357, loss_ce: 0.008567
[01:33:29.488] iteration 13146 : loss : 0.111130, loss_ce: 0.015857
[01:33:29.793] iteration 13147 : loss : 0.054383, loss_ce: 0.011630
[01:33:30.092] iteration 13148 : loss : 0.052766, loss_ce: 0.015135
[01:33:30.396] iteration 13149 : loss : 0.039766, loss_ce: 0.017287
[01:33:30.703] iteration 13150 : loss : 0.113791, loss_ce: 0.012051
[01:33:31.008] iteration 13151 : loss : 0.044947, loss_ce: 0.007103
[01:33:31.315] iteration 13152 : loss : 0.050229, loss_ce: 0.011228
[01:33:31.623] iteration 13153 : loss : 0.106974, loss_ce: 0.014578
[01:33:31.925] iteration 13154 : loss : 0.041334, loss_ce: 0.011250
[01:33:32.235] iteration 13155 : loss : 0.051417, loss_ce: 0.021214
[01:33:32.546] iteration 13156 : loss : 0.102394, loss_ce: 0.012088
[01:33:32.861] iteration 13157 : loss : 0.046564, loss_ce: 0.015919
[01:33:33.168] iteration 13158 : loss : 0.048163, loss_ce: 0.014041
[01:33:33.475] iteration 13159 : loss : 0.047745, loss_ce: 0.010564
[01:33:33.782] iteration 13160 : loss : 0.049382, loss_ce: 0.014439
[01:33:34.106] iteration 13161 : loss : 0.060451, loss_ce: 0.025874
[01:33:34.410] iteration 13162 : loss : 0.048003, loss_ce: 0.013692
[01:33:34.715] iteration 13163 : loss : 0.054747, loss_ce: 0.016127
[01:33:35.019] iteration 13164 : loss : 0.046832, loss_ce: 0.017034
[01:33:35.323] iteration 13165 : loss : 0.114080, loss_ce: 0.012455
[01:33:35.626] iteration 13166 : loss : 0.056118, loss_ce: 0.006288
[01:33:35.935] iteration 13167 : loss : 0.050622, loss_ce: 0.020452
[01:33:36.242] iteration 13168 : loss : 0.102329, loss_ce: 0.011733
[01:33:36.543] iteration 13169 : loss : 0.047484, loss_ce: 0.014400
[01:33:36.848] iteration 13170 : loss : 0.102065, loss_ce: 0.016907
[01:33:37.153] iteration 13171 : loss : 0.063030, loss_ce: 0.011022
[01:33:37.456] iteration 13172 : loss : 0.050555, loss_ce: 0.020334
[01:33:37.758] iteration 13173 : loss : 0.054287, loss_ce: 0.020366
[01:33:38.060] iteration 13174 : loss : 0.046299, loss_ce: 0.006817
[01:33:38.363] iteration 13175 : loss : 0.055206, loss_ce: 0.019412
[01:33:38.668] iteration 13176 : loss : 0.045522, loss_ce: 0.014404
[01:33:38.974] iteration 13177 : loss : 0.055098, loss_ce: 0.011947
[01:33:39.278] iteration 13178 : loss : 0.039992, loss_ce: 0.014912
[01:33:39.583] iteration 13179 : loss : 0.054675, loss_ce: 0.016476
[01:33:39.887] iteration 13180 : loss : 0.050328, loss_ce: 0.020828
[01:33:40.211] iteration 13181 : loss : 0.045129, loss_ce: 0.011091
[01:33:40.519] iteration 13182 : loss : 0.050900, loss_ce: 0.010199
[01:33:40.823] iteration 13183 : loss : 0.044292, loss_ce: 0.018912
[01:33:41.131] iteration 13184 : loss : 0.041789, loss_ce: 0.020381
[01:33:41.438] iteration 13185 : loss : 0.056464, loss_ce: 0.013039
[01:33:41.741] iteration 13186 : loss : 0.043952, loss_ce: 0.020807
[01:33:42.045] iteration 13187 : loss : 0.041187, loss_ce: 0.018902
[01:33:42.349] iteration 13188 : loss : 0.054694, loss_ce: 0.017765
[01:33:42.656] iteration 13189 : loss : 0.047473, loss_ce: 0.014641
[01:33:42.966] iteration 13190 : loss : 0.045234, loss_ce: 0.013637
[01:33:43.275] iteration 13191 : loss : 0.103510, loss_ce: 0.003883
[01:33:43.588] iteration 13192 : loss : 0.054300, loss_ce: 0.015570
[01:33:43.900] iteration 13193 : loss : 0.057924, loss_ce: 0.013280
[01:33:44.204] iteration 13194 : loss : 0.104527, loss_ce: 0.010118
[01:33:44.512] iteration 13195 : loss : 0.104138, loss_ce: 0.006857
[01:33:44.821] iteration 13196 : loss : 0.047386, loss_ce: 0.007149
[01:33:45.131] iteration 13197 : loss : 0.052497, loss_ce: 0.016243
[01:33:45.438] iteration 13198 : loss : 0.048373, loss_ce: 0.014954
[01:33:45.746] iteration 13199 : loss : 0.045829, loss_ce: 0.011535
[01:33:46.061] iteration 13200 : loss : 0.043922, loss_ce: 0.010493
[01:33:46.389] iteration 13201 : loss : 0.051021, loss_ce: 0.020280
[01:33:46.695] iteration 13202 : loss : 0.038508, loss_ce: 0.012717
[01:33:47.008] iteration 13203 : loss : 0.052869, loss_ce: 0.013573
[01:33:47.317] iteration 13204 : loss : 0.050967, loss_ce: 0.022866
[01:33:47.405] iteration 13205 : loss : 0.071301, loss_ce: 0.015535
[01:34:07.005] iteration 13206 : loss : 0.060103, loss_ce: 0.015827
[01:34:07.307] iteration 13207 : loss : 0.107427, loss_ce: 0.013344
[01:34:07.614] iteration 13208 : loss : 0.045962, loss_ce: 0.014201
[01:34:07.921] iteration 13209 : loss : 0.044569, loss_ce: 0.022189
[01:34:08.230] iteration 13210 : loss : 0.183427, loss_ce: 0.011725
[01:34:08.535] iteration 13211 : loss : 0.123890, loss_ce: 0.007123
[01:34:08.842] iteration 13212 : loss : 0.037452, loss_ce: 0.015184
[01:34:09.146] iteration 13213 : loss : 0.049814, loss_ce: 0.014419
[01:34:09.449] iteration 13214 : loss : 0.067029, loss_ce: 0.016216
[01:34:09.752] iteration 13215 : loss : 0.232083, loss_ce: 0.007830
[01:34:10.052] iteration 13216 : loss : 0.047483, loss_ce: 0.017638
[01:34:10.358] iteration 13217 : loss : 0.058198, loss_ce: 0.018044
[01:34:10.659] iteration 13218 : loss : 0.076109, loss_ce: 0.015133
[01:34:10.963] iteration 13219 : loss : 0.060508, loss_ce: 0.015051
[01:34:11.266] iteration 13220 : loss : 0.052130, loss_ce: 0.023605
[01:34:11.583] iteration 13221 : loss : 0.047147, loss_ce: 0.013459
[01:34:11.885] iteration 13222 : loss : 0.046474, loss_ce: 0.019530
[01:34:12.188] iteration 13223 : loss : 0.100172, loss_ce: 0.013157
[01:34:12.492] iteration 13224 : loss : 0.061851, loss_ce: 0.011520
[01:34:12.791] iteration 13225 : loss : 0.051278, loss_ce: 0.010051
[01:34:13.094] iteration 13226 : loss : 0.119162, loss_ce: 0.012963
[01:34:13.398] iteration 13227 : loss : 0.052568, loss_ce: 0.020045
[01:34:13.702] iteration 13228 : loss : 0.044283, loss_ce: 0.010848
[01:34:14.003] iteration 13229 : loss : 0.056448, loss_ce: 0.019815
[01:34:14.307] iteration 13230 : loss : 0.109733, loss_ce: 0.013895
[01:34:14.608] iteration 13231 : loss : 0.054973, loss_ce: 0.009302
[01:34:14.912] iteration 13232 : loss : 0.074609, loss_ce: 0.005869
[01:34:15.214] iteration 13233 : loss : 0.160367, loss_ce: 0.004499
[01:34:15.521] iteration 13234 : loss : 0.116362, loss_ce: 0.005204
[01:34:15.825] iteration 13235 : loss : 0.153120, loss_ce: 0.012935
[01:34:16.128] iteration 13236 : loss : 0.053217, loss_ce: 0.024917
[01:34:16.434] iteration 13237 : loss : 0.067167, loss_ce: 0.013716
[01:34:16.739] iteration 13238 : loss : 0.054671, loss_ce: 0.011378
[01:34:17.038] iteration 13239 : loss : 0.046912, loss_ce: 0.013800
[01:34:17.339] iteration 13240 : loss : 0.161586, loss_ce: 0.014561
[01:34:17.662] iteration 13241 : loss : 0.072842, loss_ce: 0.016762
[01:34:17.969] iteration 13242 : loss : 0.102941, loss_ce: 0.019045
[01:34:18.270] iteration 13243 : loss : 0.052764, loss_ce: 0.019852
[01:34:18.576] iteration 13244 : loss : 0.065936, loss_ce: 0.015348
[01:34:18.878] iteration 13245 : loss : 0.050678, loss_ce: 0.022289
[01:34:19.182] iteration 13246 : loss : 0.043053, loss_ce: 0.014921
[01:34:19.486] iteration 13247 : loss : 0.107513, loss_ce: 0.015137
[01:34:19.788] iteration 13248 : loss : 0.053195, loss_ce: 0.022000
[01:34:20.091] iteration 13249 : loss : 0.253368, loss_ce: 0.005998
[01:34:20.395] iteration 13250 : loss : 0.218659, loss_ce: 0.004054
[01:34:20.700] iteration 13251 : loss : 0.053175, loss_ce: 0.027977
[01:34:21.008] iteration 13252 : loss : 0.046141, loss_ce: 0.012035
[01:34:21.310] iteration 13253 : loss : 0.056910, loss_ce: 0.020539
[01:34:21.616] iteration 13254 : loss : 0.036066, loss_ce: 0.015064
[01:34:21.921] iteration 13255 : loss : 0.052620, loss_ce: 0.008862
[01:34:22.231] iteration 13256 : loss : 0.063156, loss_ce: 0.018565
[01:34:22.537] iteration 13257 : loss : 0.061601, loss_ce: 0.017378
[01:34:22.851] iteration 13258 : loss : 0.040492, loss_ce: 0.013716
[01:34:23.162] iteration 13259 : loss : 0.070973, loss_ce: 0.020486
[01:34:23.471] iteration 13260 : loss : 0.044979, loss_ce: 0.011485
[01:34:23.790] iteration 13261 : loss : 0.039692, loss_ce: 0.019961
[01:34:24.099] iteration 13262 : loss : 0.047246, loss_ce: 0.020992
[01:34:24.406] iteration 13263 : loss : 0.048539, loss_ce: 0.012106
[01:34:24.707] iteration 13264 : loss : 0.043551, loss_ce: 0.009932
[01:34:25.011] iteration 13265 : loss : 0.055328, loss_ce: 0.022280
[01:34:25.316] iteration 13266 : loss : 0.059239, loss_ce: 0.017073
[01:34:25.620] iteration 13267 : loss : 0.043458, loss_ce: 0.014172
[01:34:25.922] iteration 13268 : loss : 0.046807, loss_ce: 0.011658
[01:34:26.228] iteration 13269 : loss : 0.046303, loss_ce: 0.016148
[01:34:26.531] iteration 13270 : loss : 0.108928, loss_ce: 0.009095
[01:34:26.837] iteration 13271 : loss : 0.102973, loss_ce: 0.009705
[01:34:27.141] iteration 13272 : loss : 0.058297, loss_ce: 0.012237
[01:34:27.449] iteration 13273 : loss : 0.048097, loss_ce: 0.008802
[01:34:27.750] iteration 13274 : loss : 0.052179, loss_ce: 0.014886
[01:34:28.055] iteration 13275 : loss : 0.043419, loss_ce: 0.015384
[01:34:28.360] iteration 13276 : loss : 0.051461, loss_ce: 0.018308
[01:34:28.663] iteration 13277 : loss : 0.034906, loss_ce: 0.008989
[01:34:28.964] iteration 13278 : loss : 0.050009, loss_ce: 0.017821
[01:34:29.270] iteration 13279 : loss : 0.051451, loss_ce: 0.009986
[01:34:29.574] iteration 13280 : loss : 0.216501, loss_ce: 0.004001
[01:34:29.896] iteration 13281 : loss : 0.044406, loss_ce: 0.018051
[01:34:30.199] iteration 13282 : loss : 0.051466, loss_ce: 0.015693
[01:34:30.504] iteration 13283 : loss : 0.043658, loss_ce: 0.012400
[01:34:30.807] iteration 13284 : loss : 0.049958, loss_ce: 0.011792
[01:34:31.109] iteration 13285 : loss : 0.053436, loss_ce: 0.017906
[01:34:31.410] iteration 13286 : loss : 0.069856, loss_ce: 0.016118
[01:34:31.718] iteration 13287 : loss : 0.041998, loss_ce: 0.018679
[01:34:32.022] iteration 13288 : loss : 0.050266, loss_ce: 0.013372
[01:34:32.321] iteration 13289 : loss : 0.047022, loss_ce: 0.015525
[01:34:32.629] iteration 13290 : loss : 0.047048, loss_ce: 0.014369
[01:34:32.935] iteration 13291 : loss : 0.048295, loss_ce: 0.022176
[01:34:33.240] iteration 13292 : loss : 0.095357, loss_ce: 0.004702
[01:34:33.544] iteration 13293 : loss : 0.048974, loss_ce: 0.018009
[01:34:33.847] iteration 13294 : loss : 0.057204, loss_ce: 0.019217
[01:34:34.150] iteration 13295 : loss : 0.033220, loss_ce: 0.010688
[01:34:34.454] iteration 13296 : loss : 0.100987, loss_ce: 0.013393
[01:34:34.759] iteration 13297 : loss : 0.050325, loss_ce: 0.015420
[01:34:35.061] iteration 13298 : loss : 0.053043, loss_ce: 0.015558
[01:34:35.365] iteration 13299 : loss : 0.079595, loss_ce: 0.016049
[01:34:35.671] iteration 13300 : loss : 0.107389, loss_ce: 0.006407
[01:34:35.990] iteration 13301 : loss : 0.048768, loss_ce: 0.018720
[01:34:36.295] iteration 13302 : loss : 0.047807, loss_ce: 0.015668
[01:34:36.600] iteration 13303 : loss : 0.047234, loss_ce: 0.008509
[01:34:36.904] iteration 13304 : loss : 0.040720, loss_ce: 0.017883
[01:34:37.212] iteration 13305 : loss : 0.046308, loss_ce: 0.014509
[01:34:37.522] iteration 13306 : loss : 0.115780, loss_ce: 0.011337
[01:34:37.835] iteration 13307 : loss : 0.067545, loss_ce: 0.017792
[01:34:38.145] iteration 13308 : loss : 0.043839, loss_ce: 0.013174
[01:34:38.455] iteration 13309 : loss : 0.054996, loss_ce: 0.020911
[01:34:38.766] iteration 13310 : loss : 0.052943, loss_ce: 0.023474
[01:34:39.073] iteration 13311 : loss : 0.038358, loss_ce: 0.009560
[01:34:39.383] iteration 13312 : loss : 0.102463, loss_ce: 0.008066
[01:34:39.688] iteration 13313 : loss : 0.040494, loss_ce: 0.015976
[01:34:39.994] iteration 13314 : loss : 0.044620, loss_ce: 0.012354
[01:34:40.299] iteration 13315 : loss : 0.108493, loss_ce: 0.009923
[01:34:40.605] iteration 13316 : loss : 0.050796, loss_ce: 0.013952
[01:34:40.910] iteration 13317 : loss : 0.055071, loss_ce: 0.021926
[01:34:41.214] iteration 13318 : loss : 0.050675, loss_ce: 0.020677
[01:34:41.516] iteration 13319 : loss : 0.053025, loss_ce: 0.012162
[01:34:41.822] iteration 13320 : loss : 0.078333, loss_ce: 0.010451
[01:34:42.142] iteration 13321 : loss : 0.044269, loss_ce: 0.014201
[01:34:42.447] iteration 13322 : loss : 0.053935, loss_ce: 0.019020
[01:34:42.755] iteration 13323 : loss : 0.056013, loss_ce: 0.016928
[01:34:43.062] iteration 13324 : loss : 0.046352, loss_ce: 0.019141
[01:34:43.368] iteration 13325 : loss : 0.061763, loss_ce: 0.012866
[01:34:43.675] iteration 13326 : loss : 0.069570, loss_ce: 0.015114
[01:34:43.979] iteration 13327 : loss : 0.044451, loss_ce: 0.010170
[01:34:44.290] iteration 13328 : loss : 0.052103, loss_ce: 0.012062
[01:34:44.600] iteration 13329 : loss : 0.083540, loss_ce: 0.013925
[01:34:44.908] iteration 13330 : loss : 0.203262, loss_ce: 0.004530
[01:34:45.217] iteration 13331 : loss : 0.104893, loss_ce: 0.019805
[01:34:45.520] iteration 13332 : loss : 0.060439, loss_ce: 0.023162
[01:34:45.830] iteration 13333 : loss : 0.060733, loss_ce: 0.025459
[01:34:46.136] iteration 13334 : loss : 0.053527, loss_ce: 0.013465
[01:34:46.441] iteration 13335 : loss : 0.045254, loss_ce: 0.013678
[01:34:46.746] iteration 13336 : loss : 0.106828, loss_ce: 0.014172
[01:34:47.048] iteration 13337 : loss : 0.052559, loss_ce: 0.020829
[01:34:47.359] iteration 13338 : loss : 0.040992, loss_ce: 0.009072
[01:34:47.668] iteration 13339 : loss : 0.057342, loss_ce: 0.009999
[01:34:47.974] iteration 13340 : loss : 0.128764, loss_ce: 0.010871
[01:34:48.298] iteration 13341 : loss : 0.048332, loss_ce: 0.018290
[01:34:48.604] iteration 13342 : loss : 0.062222, loss_ce: 0.015898
[01:34:48.908] iteration 13343 : loss : 0.058404, loss_ce: 0.012703
[01:34:48.987] iteration 13344 : loss : 0.302316, loss_ce: 0.018737
[01:35:06.951] iteration 13345 : loss : 0.046803, loss_ce: 0.010529
[01:35:07.254] iteration 13346 : loss : 0.107232, loss_ce: 0.009452
[01:35:07.560] iteration 13347 : loss : 0.055166, loss_ce: 0.020157
[01:35:07.867] iteration 13348 : loss : 0.045798, loss_ce: 0.016705
[01:35:08.172] iteration 13349 : loss : 0.107526, loss_ce: 0.016316
[01:35:08.478] iteration 13350 : loss : 0.049301, loss_ce: 0.012994
[01:35:08.786] iteration 13351 : loss : 0.118746, loss_ce: 0.011457
[01:35:09.095] iteration 13352 : loss : 0.053440, loss_ce: 0.016476
[01:35:09.400] iteration 13353 : loss : 0.053998, loss_ce: 0.013348
[01:35:09.710] iteration 13354 : loss : 0.052660, loss_ce: 0.018161
[01:35:10.018] iteration 13355 : loss : 0.103550, loss_ce: 0.015559
[01:35:10.332] iteration 13356 : loss : 0.044762, loss_ce: 0.007183
[01:35:10.639] iteration 13357 : loss : 0.053690, loss_ce: 0.014756
[01:35:10.951] iteration 13358 : loss : 0.047531, loss_ce: 0.015887
[01:35:11.260] iteration 13359 : loss : 0.043351, loss_ce: 0.019087
[01:35:11.567] iteration 13360 : loss : 0.050394, loss_ce: 0.024028
[01:35:11.895] iteration 13361 : loss : 0.108945, loss_ce: 0.010275
[01:35:12.205] iteration 13362 : loss : 0.045440, loss_ce: 0.013179
[01:35:12.514] iteration 13363 : loss : 0.046207, loss_ce: 0.014113
[01:35:12.820] iteration 13364 : loss : 0.048635, loss_ce: 0.013038
[01:35:13.127] iteration 13365 : loss : 0.104292, loss_ce: 0.013049
[01:35:13.435] iteration 13366 : loss : 0.098861, loss_ce: 0.009012
[01:35:13.750] iteration 13367 : loss : 0.053626, loss_ce: 0.016492
[01:35:14.055] iteration 13368 : loss : 0.112185, loss_ce: 0.009372
[01:35:14.366] iteration 13369 : loss : 0.052949, loss_ce: 0.028084
[01:35:14.669] iteration 13370 : loss : 0.052724, loss_ce: 0.020374
[01:35:14.972] iteration 13371 : loss : 0.100012, loss_ce: 0.011053
[01:35:15.274] iteration 13372 : loss : 0.042768, loss_ce: 0.022558
[01:35:15.578] iteration 13373 : loss : 0.039905, loss_ce: 0.008007
[01:35:15.882] iteration 13374 : loss : 0.042329, loss_ce: 0.013786
[01:35:16.183] iteration 13375 : loss : 0.171805, loss_ce: 0.013400
[01:35:16.488] iteration 13376 : loss : 0.046759, loss_ce: 0.017951
[01:35:16.792] iteration 13377 : loss : 0.056700, loss_ce: 0.013557
[01:35:17.100] iteration 13378 : loss : 0.046837, loss_ce: 0.012414
[01:35:17.404] iteration 13379 : loss : 0.100776, loss_ce: 0.008914
[01:35:17.709] iteration 13380 : loss : 0.051437, loss_ce: 0.020456
[01:35:18.026] iteration 13381 : loss : 0.057503, loss_ce: 0.014731
[01:35:18.328] iteration 13382 : loss : 0.038546, loss_ce: 0.012921
[01:35:18.638] iteration 13383 : loss : 0.053137, loss_ce: 0.013665
[01:35:18.943] iteration 13384 : loss : 0.046863, loss_ce: 0.014232
[01:35:19.246] iteration 13385 : loss : 0.112789, loss_ce: 0.014645
[01:35:19.555] iteration 13386 : loss : 0.050977, loss_ce: 0.008724
[01:35:19.864] iteration 13387 : loss : 0.049249, loss_ce: 0.018162
[01:35:20.169] iteration 13388 : loss : 0.051595, loss_ce: 0.019532
[01:35:20.473] iteration 13389 : loss : 0.045202, loss_ce: 0.012059
[01:35:20.777] iteration 13390 : loss : 0.045859, loss_ce: 0.018571
[01:35:21.078] iteration 13391 : loss : 0.046281, loss_ce: 0.018376
[01:35:21.387] iteration 13392 : loss : 0.099893, loss_ce: 0.017963
[01:35:21.693] iteration 13393 : loss : 0.040942, loss_ce: 0.014819
[01:35:22.000] iteration 13394 : loss : 0.048602, loss_ce: 0.008921
[01:35:22.303] iteration 13395 : loss : 0.048325, loss_ce: 0.016967
[01:35:22.612] iteration 13396 : loss : 0.049009, loss_ce: 0.014615
[01:35:22.918] iteration 13397 : loss : 0.055820, loss_ce: 0.006494
[01:35:23.222] iteration 13398 : loss : 0.054660, loss_ce: 0.017514
[01:35:23.528] iteration 13399 : loss : 0.047135, loss_ce: 0.017098
[01:35:23.831] iteration 13400 : loss : 0.103587, loss_ce: 0.015865
[01:35:24.149] iteration 13401 : loss : 0.045901, loss_ce: 0.015611
[01:35:24.455] iteration 13402 : loss : 0.057876, loss_ce: 0.010625
[01:35:24.759] iteration 13403 : loss : 0.048814, loss_ce: 0.023312
[01:35:25.063] iteration 13404 : loss : 0.038597, loss_ce: 0.009935
[01:35:25.368] iteration 13405 : loss : 0.043698, loss_ce: 0.017201
[01:35:25.670] iteration 13406 : loss : 0.058402, loss_ce: 0.026800
[01:35:25.974] iteration 13407 : loss : 0.051125, loss_ce: 0.022123
[01:35:26.276] iteration 13408 : loss : 0.040374, loss_ce: 0.007594
[01:35:26.583] iteration 13409 : loss : 0.048565, loss_ce: 0.011785
[01:35:26.884] iteration 13410 : loss : 0.045968, loss_ce: 0.022060
[01:35:27.191] iteration 13411 : loss : 0.046473, loss_ce: 0.019335
[01:35:27.503] iteration 13412 : loss : 0.048551, loss_ce: 0.019092
[01:35:27.808] iteration 13413 : loss : 0.111554, loss_ce: 0.006614
[01:35:28.116] iteration 13414 : loss : 0.051222, loss_ce: 0.003947
[01:35:28.422] iteration 13415 : loss : 0.046061, loss_ce: 0.015184
[01:35:28.730] iteration 13416 : loss : 0.051219, loss_ce: 0.014668
[01:35:29.043] iteration 13417 : loss : 0.061990, loss_ce: 0.022026
[01:35:29.348] iteration 13418 : loss : 0.110431, loss_ce: 0.011615
[01:35:29.650] iteration 13419 : loss : 0.118964, loss_ce: 0.006649
[01:35:29.954] iteration 13420 : loss : 0.058305, loss_ce: 0.006867
[01:35:30.279] iteration 13421 : loss : 0.049529, loss_ce: 0.013628
[01:35:30.581] iteration 13422 : loss : 0.052097, loss_ce: 0.017204
[01:35:30.883] iteration 13423 : loss : 0.054121, loss_ce: 0.010017
[01:35:31.186] iteration 13424 : loss : 0.045269, loss_ce: 0.009453
[01:35:31.491] iteration 13425 : loss : 0.061103, loss_ce: 0.022882
[01:35:31.796] iteration 13426 : loss : 0.037057, loss_ce: 0.013252
[01:35:32.100] iteration 13427 : loss : 0.051594, loss_ce: 0.012229
[01:35:32.401] iteration 13428 : loss : 0.044549, loss_ce: 0.010823
[01:35:32.706] iteration 13429 : loss : 0.055256, loss_ce: 0.011705
[01:35:33.012] iteration 13430 : loss : 0.035730, loss_ce: 0.012742
[01:35:33.319] iteration 13431 : loss : 0.050192, loss_ce: 0.007921
[01:35:33.623] iteration 13432 : loss : 0.048184, loss_ce: 0.014635
[01:35:33.929] iteration 13433 : loss : 0.049405, loss_ce: 0.012470
[01:35:34.232] iteration 13434 : loss : 0.097654, loss_ce: 0.010218
[01:35:34.535] iteration 13435 : loss : 0.052372, loss_ce: 0.018171
[01:35:34.838] iteration 13436 : loss : 0.067128, loss_ce: 0.011279
[01:35:35.141] iteration 13437 : loss : 0.047709, loss_ce: 0.018000
[01:35:35.444] iteration 13438 : loss : 0.048041, loss_ce: 0.011725
[01:35:35.748] iteration 13439 : loss : 0.053667, loss_ce: 0.016878
[01:35:36.051] iteration 13440 : loss : 0.048027, loss_ce: 0.015410
[01:35:36.372] iteration 13441 : loss : 0.052906, loss_ce: 0.012327
[01:35:36.675] iteration 13442 : loss : 0.082284, loss_ce: 0.015839
[01:35:36.982] iteration 13443 : loss : 0.059820, loss_ce: 0.009448
[01:35:37.285] iteration 13444 : loss : 0.034980, loss_ce: 0.007921
[01:35:37.586] iteration 13445 : loss : 0.049996, loss_ce: 0.013939
[01:35:37.890] iteration 13446 : loss : 0.113758, loss_ce: 0.011360
[01:35:38.193] iteration 13447 : loss : 0.044559, loss_ce: 0.015540
[01:35:38.497] iteration 13448 : loss : 0.109452, loss_ce: 0.015837
[01:35:38.806] iteration 13449 : loss : 0.048312, loss_ce: 0.014468
[01:35:39.110] iteration 13450 : loss : 0.066532, loss_ce: 0.019703
[01:35:39.415] iteration 13451 : loss : 0.052552, loss_ce: 0.005063
[01:35:39.719] iteration 13452 : loss : 0.045991, loss_ce: 0.012138
[01:35:40.025] iteration 13453 : loss : 0.046522, loss_ce: 0.018400
[01:35:40.328] iteration 13454 : loss : 0.048967, loss_ce: 0.016320
[01:35:40.630] iteration 13455 : loss : 0.052856, loss_ce: 0.018446
[01:35:40.939] iteration 13456 : loss : 0.101319, loss_ce: 0.010619
[01:35:41.244] iteration 13457 : loss : 0.049480, loss_ce: 0.018920
[01:35:41.551] iteration 13458 : loss : 0.047213, loss_ce: 0.021264
[01:35:41.855] iteration 13459 : loss : 0.043916, loss_ce: 0.015744
[01:35:42.156] iteration 13460 : loss : 0.044650, loss_ce: 0.008244
[01:35:42.477] iteration 13461 : loss : 0.109247, loss_ce: 0.014841
[01:35:42.789] iteration 13462 : loss : 0.049844, loss_ce: 0.015837
[01:35:43.102] iteration 13463 : loss : 0.048516, loss_ce: 0.013161
[01:35:43.413] iteration 13464 : loss : 0.112789, loss_ce: 0.007927
[01:35:43.724] iteration 13465 : loss : 0.046621, loss_ce: 0.019917
[01:35:44.036] iteration 13466 : loss : 0.105433, loss_ce: 0.008633
[01:35:44.351] iteration 13467 : loss : 0.060311, loss_ce: 0.014149
[01:35:44.655] iteration 13468 : loss : 0.053185, loss_ce: 0.018930
[01:35:44.964] iteration 13469 : loss : 0.044843, loss_ce: 0.009395
[01:35:45.276] iteration 13470 : loss : 0.058567, loss_ce: 0.013746
[01:35:45.586] iteration 13471 : loss : 0.107552, loss_ce: 0.011884
[01:35:45.894] iteration 13472 : loss : 0.046235, loss_ce: 0.021542
[01:35:46.205] iteration 13473 : loss : 0.056620, loss_ce: 0.016785
[01:35:46.515] iteration 13474 : loss : 0.105448, loss_ce: 0.009982
[01:35:46.825] iteration 13475 : loss : 0.035684, loss_ce: 0.015296
[01:35:47.136] iteration 13476 : loss : 0.050684, loss_ce: 0.008598
[01:35:47.440] iteration 13477 : loss : 0.091481, loss_ce: 0.003849
[01:35:47.751] iteration 13478 : loss : 0.068669, loss_ce: 0.012407
[01:35:48.058] iteration 13479 : loss : 0.058413, loss_ce: 0.020788
[01:35:48.362] iteration 13480 : loss : 0.036605, loss_ce: 0.013082
[01:35:48.683] iteration 13481 : loss : 0.048560, loss_ce: 0.011975
[01:35:48.996] iteration 13482 : loss : 0.043948, loss_ce: 0.015053
[01:35:49.074] iteration 13483 : loss : 0.196704, loss_ce: 0.000041
[01:36:06.887] iteration 13484 : loss : 0.113988, loss_ce: 0.017938
[01:36:07.185] iteration 13485 : loss : 0.051392, loss_ce: 0.019098
[01:36:07.483] iteration 13486 : loss : 0.057039, loss_ce: 0.018456
[01:36:07.785] iteration 13487 : loss : 0.054107, loss_ce: 0.015120
[01:36:08.089] iteration 13488 : loss : 0.065299, loss_ce: 0.015735
[01:36:08.387] iteration 13489 : loss : 0.065199, loss_ce: 0.012132
[01:36:08.689] iteration 13490 : loss : 0.085412, loss_ce: 0.024556
[01:36:08.990] iteration 13491 : loss : 0.062548, loss_ce: 0.015562
[01:36:09.291] iteration 13492 : loss : 0.066654, loss_ce: 0.028984
[01:36:09.591] iteration 13493 : loss : 0.118640, loss_ce: 0.010482
[01:36:09.896] iteration 13494 : loss : 0.132130, loss_ce: 0.009200
[01:36:10.196] iteration 13495 : loss : 0.047542, loss_ce: 0.018453
[01:36:10.499] iteration 13496 : loss : 0.066256, loss_ce: 0.013834
[01:36:10.802] iteration 13497 : loss : 0.113646, loss_ce: 0.012585
[01:36:11.106] iteration 13498 : loss : 0.060565, loss_ce: 0.022877
[01:36:11.413] iteration 13499 : loss : 0.102576, loss_ce: 0.007494
[01:36:11.714] iteration 13500 : loss : 0.052121, loss_ce: 0.017767
[01:36:12.033] iteration 13501 : loss : 0.172613, loss_ce: 0.005086
[01:36:12.339] iteration 13502 : loss : 0.068725, loss_ce: 0.011384
[01:36:12.648] iteration 13503 : loss : 0.051568, loss_ce: 0.018151
[01:36:12.956] iteration 13504 : loss : 0.058646, loss_ce: 0.016064
[01:36:13.260] iteration 13505 : loss : 0.060926, loss_ce: 0.010397
[01:36:13.564] iteration 13506 : loss : 0.048522, loss_ce: 0.014247
[01:36:13.870] iteration 13507 : loss : 0.045565, loss_ce: 0.022491
[01:36:14.176] iteration 13508 : loss : 0.107489, loss_ce: 0.009417
[01:36:14.481] iteration 13509 : loss : 0.044877, loss_ce: 0.019742
[01:36:14.785] iteration 13510 : loss : 0.049661, loss_ce: 0.018179
[01:36:15.090] iteration 13511 : loss : 0.113380, loss_ce: 0.011219
[01:36:15.400] iteration 13512 : loss : 0.054856, loss_ce: 0.017240
[01:36:15.706] iteration 13513 : loss : 0.063609, loss_ce: 0.014482
[01:36:16.015] iteration 13514 : loss : 0.076948, loss_ce: 0.012628
[01:36:16.320] iteration 13515 : loss : 0.097693, loss_ce: 0.005878
[01:36:16.627] iteration 13516 : loss : 0.056794, loss_ce: 0.018062
[01:36:16.937] iteration 13517 : loss : 0.048395, loss_ce: 0.017201
[01:36:17.243] iteration 13518 : loss : 0.100182, loss_ce: 0.012006
[01:36:17.548] iteration 13519 : loss : 0.064861, loss_ce: 0.022709
[01:36:17.855] iteration 13520 : loss : 0.119083, loss_ce: 0.010024
[01:36:18.179] iteration 13521 : loss : 0.051681, loss_ce: 0.013431
[01:36:18.483] iteration 13522 : loss : 0.051467, loss_ce: 0.015627
[01:36:18.798] iteration 13523 : loss : 0.048521, loss_ce: 0.017049
[01:36:19.103] iteration 13524 : loss : 0.044192, loss_ce: 0.005965
[01:36:19.410] iteration 13525 : loss : 0.060415, loss_ce: 0.026708
[01:36:19.718] iteration 13526 : loss : 0.093774, loss_ce: 0.020915
[01:36:20.026] iteration 13527 : loss : 0.050263, loss_ce: 0.021855
[01:36:20.335] iteration 13528 : loss : 0.109802, loss_ce: 0.014516
[01:36:20.651] iteration 13529 : loss : 0.049497, loss_ce: 0.011622
[01:36:20.959] iteration 13530 : loss : 0.070512, loss_ce: 0.016288
[01:36:21.269] iteration 13531 : loss : 0.054642, loss_ce: 0.016351
[01:36:21.577] iteration 13532 : loss : 0.062171, loss_ce: 0.012883
[01:36:21.887] iteration 13533 : loss : 0.042502, loss_ce: 0.012783
[01:36:22.192] iteration 13534 : loss : 0.048655, loss_ce: 0.013844
[01:36:22.502] iteration 13535 : loss : 0.096412, loss_ce: 0.014511
[01:36:22.809] iteration 13536 : loss : 0.060488, loss_ce: 0.014364
[01:36:23.117] iteration 13537 : loss : 0.060917, loss_ce: 0.022353
[01:36:23.426] iteration 13538 : loss : 0.045139, loss_ce: 0.015665
[01:36:23.731] iteration 13539 : loss : 0.103759, loss_ce: 0.012106
[01:36:24.041] iteration 13540 : loss : 0.045388, loss_ce: 0.016720
[01:36:24.360] iteration 13541 : loss : 0.052535, loss_ce: 0.015262
[01:36:24.668] iteration 13542 : loss : 0.045215, loss_ce: 0.009508
[01:36:24.977] iteration 13543 : loss : 0.109637, loss_ce: 0.012462
[01:36:25.285] iteration 13544 : loss : 0.099976, loss_ce: 0.005136
[01:36:25.592] iteration 13545 : loss : 0.043554, loss_ce: 0.012064
[01:36:25.899] iteration 13546 : loss : 0.067856, loss_ce: 0.019093
[01:36:26.207] iteration 13547 : loss : 0.052365, loss_ce: 0.011777
[01:36:26.511] iteration 13548 : loss : 0.049497, loss_ce: 0.013859
[01:36:26.822] iteration 13549 : loss : 0.077103, loss_ce: 0.025259
[01:36:27.131] iteration 13550 : loss : 0.106331, loss_ce: 0.011944
[01:36:27.438] iteration 13551 : loss : 0.040930, loss_ce: 0.012828
[01:36:27.743] iteration 13552 : loss : 0.159814, loss_ce: 0.010076
[01:36:28.052] iteration 13553 : loss : 0.056576, loss_ce: 0.012670
[01:36:28.358] iteration 13554 : loss : 0.047024, loss_ce: 0.009515
[01:36:28.666] iteration 13555 : loss : 0.046269, loss_ce: 0.011149
[01:36:28.975] iteration 13556 : loss : 0.044462, loss_ce: 0.009365
[01:36:29.281] iteration 13557 : loss : 0.056076, loss_ce: 0.019736
[01:36:29.589] iteration 13558 : loss : 0.102716, loss_ce: 0.015013
[01:36:29.898] iteration 13559 : loss : 0.064404, loss_ce: 0.018952
[01:36:30.207] iteration 13560 : loss : 0.071248, loss_ce: 0.030311
[01:36:30.526] iteration 13561 : loss : 0.166277, loss_ce: 0.010610
[01:36:30.834] iteration 13562 : loss : 0.110541, loss_ce: 0.010191
[01:36:31.142] iteration 13563 : loss : 0.064681, loss_ce: 0.016649
[01:36:31.448] iteration 13564 : loss : 0.056198, loss_ce: 0.019345
[01:36:31.754] iteration 13565 : loss : 0.104604, loss_ce: 0.018226
[01:36:32.061] iteration 13566 : loss : 0.058763, loss_ce: 0.016956
[01:36:32.373] iteration 13567 : loss : 0.046310, loss_ce: 0.007775
[01:36:32.685] iteration 13568 : loss : 0.094796, loss_ce: 0.017843
[01:36:32.987] iteration 13569 : loss : 0.050459, loss_ce: 0.022043
[01:36:33.296] iteration 13570 : loss : 0.040229, loss_ce: 0.012256
[01:36:33.606] iteration 13571 : loss : 0.051725, loss_ce: 0.014943
[01:36:33.912] iteration 13572 : loss : 0.089695, loss_ce: 0.021837
[01:36:34.220] iteration 13573 : loss : 0.049376, loss_ce: 0.014565
[01:36:34.522] iteration 13574 : loss : 0.104250, loss_ce: 0.010463
[01:36:34.827] iteration 13575 : loss : 0.057215, loss_ce: 0.012007
[01:36:35.130] iteration 13576 : loss : 0.107770, loss_ce: 0.008804
[01:36:35.433] iteration 13577 : loss : 0.049943, loss_ce: 0.027077
[01:36:35.735] iteration 13578 : loss : 0.063916, loss_ce: 0.018300
[01:36:36.041] iteration 13579 : loss : 0.059408, loss_ce: 0.013850
[01:36:36.343] iteration 13580 : loss : 0.043638, loss_ce: 0.012611
[01:36:36.661] iteration 13581 : loss : 0.048575, loss_ce: 0.019679
[01:36:36.963] iteration 13582 : loss : 0.109754, loss_ce: 0.014181
[01:36:37.267] iteration 13583 : loss : 0.052476, loss_ce: 0.015631
[01:36:37.570] iteration 13584 : loss : 0.056997, loss_ce: 0.024616
[01:36:37.876] iteration 13585 : loss : 0.067390, loss_ce: 0.030446
[01:36:38.177] iteration 13586 : loss : 0.055254, loss_ce: 0.011860
[01:36:38.481] iteration 13587 : loss : 0.045790, loss_ce: 0.014439
[01:36:38.784] iteration 13588 : loss : 0.048771, loss_ce: 0.009155
[01:36:39.088] iteration 13589 : loss : 0.051632, loss_ce: 0.015565
[01:36:39.395] iteration 13590 : loss : 0.048622, loss_ce: 0.016791
[01:36:39.700] iteration 13591 : loss : 0.051949, loss_ce: 0.010605
[01:36:40.002] iteration 13592 : loss : 0.065196, loss_ce: 0.014605
[01:36:40.307] iteration 13593 : loss : 0.042150, loss_ce: 0.015976
[01:36:40.611] iteration 13594 : loss : 0.104585, loss_ce: 0.010981
[01:36:40.913] iteration 13595 : loss : 0.049959, loss_ce: 0.023140
[01:36:41.219] iteration 13596 : loss : 0.250000, loss_ce: 0.004123
[01:36:41.520] iteration 13597 : loss : 0.045725, loss_ce: 0.015211
[01:36:41.821] iteration 13598 : loss : 0.056868, loss_ce: 0.011225
[01:36:42.124] iteration 13599 : loss : 0.072982, loss_ce: 0.014638
[01:36:42.432] iteration 13600 : loss : 0.227301, loss_ce: 0.011801
[01:36:42.753] iteration 13601 : loss : 0.144559, loss_ce: 0.017409
[01:36:43.055] iteration 13602 : loss : 0.105797, loss_ce: 0.009477
[01:36:43.359] iteration 13603 : loss : 0.057454, loss_ce: 0.020911
[01:36:43.663] iteration 13604 : loss : 0.047148, loss_ce: 0.018509
[01:36:43.968] iteration 13605 : loss : 0.047952, loss_ce: 0.021612
[01:36:44.272] iteration 13606 : loss : 0.107069, loss_ce: 0.010598
[01:36:44.577] iteration 13607 : loss : 0.049232, loss_ce: 0.023161
[01:36:44.882] iteration 13608 : loss : 0.044672, loss_ce: 0.020310
[01:36:45.198] iteration 13609 : loss : 0.109667, loss_ce: 0.005980
[01:36:45.552] iteration 13610 : loss : 0.043603, loss_ce: 0.012346
[01:36:45.859] iteration 13611 : loss : 0.063154, loss_ce: 0.017044
[01:36:46.164] iteration 13612 : loss : 0.054577, loss_ce: 0.019244
[01:36:46.475] iteration 13613 : loss : 0.044911, loss_ce: 0.014352
[01:36:46.779] iteration 13614 : loss : 0.051657, loss_ce: 0.022951
[01:36:47.089] iteration 13615 : loss : 0.047056, loss_ce: 0.008752
[01:36:47.403] iteration 13616 : loss : 0.051584, loss_ce: 0.027336
[01:36:47.720] iteration 13617 : loss : 0.051586, loss_ce: 0.019737
[01:36:48.031] iteration 13618 : loss : 0.049226, loss_ce: 0.016216
[01:36:48.348] iteration 13619 : loss : 0.046872, loss_ce: 0.012931
[01:36:48.663] iteration 13620 : loss : 0.114374, loss_ce: 0.008616
[01:36:49.018] iteration 13621 : loss : 0.044664, loss_ce: 0.014730
[01:36:49.109] iteration 13622 : loss : 0.057537, loss_ce: 0.028468
[01:37:06.683] iteration 13623 : loss : 0.055959, loss_ce: 0.018265
[01:37:06.984] iteration 13624 : loss : 0.055061, loss_ce: 0.012844
[01:37:07.288] iteration 13625 : loss : 0.046324, loss_ce: 0.015258
[01:37:07.590] iteration 13626 : loss : 0.044402, loss_ce: 0.014154
[01:37:07.891] iteration 13627 : loss : 0.052352, loss_ce: 0.013311
[01:37:08.191] iteration 13628 : loss : 0.049189, loss_ce: 0.023970
[01:37:08.492] iteration 13629 : loss : 0.073390, loss_ce: 0.016673
[01:37:08.798] iteration 13630 : loss : 0.060003, loss_ce: 0.012156
[01:37:09.100] iteration 13631 : loss : 0.108340, loss_ce: 0.010439
[01:37:09.405] iteration 13632 : loss : 0.088802, loss_ce: 0.020655
[01:37:09.707] iteration 13633 : loss : 0.057536, loss_ce: 0.011232
[01:37:10.011] iteration 13634 : loss : 0.119095, loss_ce: 0.005111
[01:37:10.314] iteration 13635 : loss : 0.042044, loss_ce: 0.013799
[01:37:10.623] iteration 13636 : loss : 0.043036, loss_ce: 0.013271
[01:37:10.930] iteration 13637 : loss : 0.060539, loss_ce: 0.024852
[01:37:11.237] iteration 13638 : loss : 0.037000, loss_ce: 0.018596
[01:37:11.541] iteration 13639 : loss : 0.046951, loss_ce: 0.011766
[01:37:11.847] iteration 13640 : loss : 0.044935, loss_ce: 0.023717
[01:37:12.173] iteration 13641 : loss : 0.046577, loss_ce: 0.011801
[01:37:12.482] iteration 13642 : loss : 0.046372, loss_ce: 0.018502
[01:37:12.790] iteration 13643 : loss : 0.043296, loss_ce: 0.016671
[01:37:13.094] iteration 13644 : loss : 0.047592, loss_ce: 0.011297
[01:37:13.399] iteration 13645 : loss : 0.045352, loss_ce: 0.011047
[01:37:13.699] iteration 13646 : loss : 0.050101, loss_ce: 0.015849
[01:37:14.006] iteration 13647 : loss : 0.048669, loss_ce: 0.011911
[01:37:14.307] iteration 13648 : loss : 0.109850, loss_ce: 0.013367
[01:37:14.617] iteration 13649 : loss : 0.062912, loss_ce: 0.016351
[01:37:14.925] iteration 13650 : loss : 0.168995, loss_ce: 0.006208
[01:37:15.231] iteration 13651 : loss : 0.053515, loss_ce: 0.008275
[01:37:15.535] iteration 13652 : loss : 0.042828, loss_ce: 0.013734
[01:37:15.837] iteration 13653 : loss : 0.042990, loss_ce: 0.011783
[01:37:16.141] iteration 13654 : loss : 0.061403, loss_ce: 0.013418
[01:37:16.448] iteration 13655 : loss : 0.040095, loss_ce: 0.006204
[01:37:16.751] iteration 13656 : loss : 0.106100, loss_ce: 0.019458
[01:37:17.059] iteration 13657 : loss : 0.048809, loss_ce: 0.015352
[01:37:17.369] iteration 13658 : loss : 0.065209, loss_ce: 0.011365
[01:37:17.672] iteration 13659 : loss : 0.128906, loss_ce: 0.009520
[01:37:17.983] iteration 13660 : loss : 0.058966, loss_ce: 0.024522
[01:37:18.309] iteration 13661 : loss : 0.048524, loss_ce: 0.015165
[01:37:18.616] iteration 13662 : loss : 0.056622, loss_ce: 0.017141
[01:37:18.924] iteration 13663 : loss : 0.053411, loss_ce: 0.013947
[01:37:19.233] iteration 13664 : loss : 0.051882, loss_ce: 0.023040
[01:37:19.541] iteration 13665 : loss : 0.098856, loss_ce: 0.010178
[01:37:19.851] iteration 13666 : loss : 0.042073, loss_ce: 0.019447
[01:37:20.158] iteration 13667 : loss : 0.060132, loss_ce: 0.023438
[01:37:20.468] iteration 13668 : loss : 0.044730, loss_ce: 0.011030
[01:37:20.779] iteration 13669 : loss : 0.052317, loss_ce: 0.016532
[01:37:21.088] iteration 13670 : loss : 0.047270, loss_ce: 0.011560
[01:37:21.392] iteration 13671 : loss : 0.107494, loss_ce: 0.014941
[01:37:21.699] iteration 13672 : loss : 0.113857, loss_ce: 0.009985
[01:37:22.007] iteration 13673 : loss : 0.049891, loss_ce: 0.013942
[01:37:22.314] iteration 13674 : loss : 0.155379, loss_ce: 0.008285
[01:37:22.621] iteration 13675 : loss : 0.041242, loss_ce: 0.012784
[01:37:22.934] iteration 13676 : loss : 0.050387, loss_ce: 0.018334
[01:37:23.240] iteration 13677 : loss : 0.219412, loss_ce: 0.007959
[01:37:23.553] iteration 13678 : loss : 0.043949, loss_ce: 0.016927
[01:37:23.865] iteration 13679 : loss : 0.055118, loss_ce: 0.016175
[01:37:24.171] iteration 13680 : loss : 0.047767, loss_ce: 0.009421
[01:37:24.497] iteration 13681 : loss : 0.043069, loss_ce: 0.018796
[01:37:24.802] iteration 13682 : loss : 0.060864, loss_ce: 0.013074
[01:37:25.107] iteration 13683 : loss : 0.059266, loss_ce: 0.017717
[01:37:25.418] iteration 13684 : loss : 0.045659, loss_ce: 0.014109
[01:37:25.727] iteration 13685 : loss : 0.070602, loss_ce: 0.012934
[01:37:26.039] iteration 13686 : loss : 0.036455, loss_ce: 0.006636
[01:37:26.346] iteration 13687 : loss : 0.052509, loss_ce: 0.019959
[01:37:26.656] iteration 13688 : loss : 0.047891, loss_ce: 0.014035
[01:37:26.964] iteration 13689 : loss : 0.050278, loss_ce: 0.017069
[01:37:27.273] iteration 13690 : loss : 0.058633, loss_ce: 0.012909
[01:37:27.579] iteration 13691 : loss : 0.102303, loss_ce: 0.007441
[01:37:27.889] iteration 13692 : loss : 0.050100, loss_ce: 0.017426
[01:37:28.197] iteration 13693 : loss : 0.051618, loss_ce: 0.017664
[01:37:28.500] iteration 13694 : loss : 0.041610, loss_ce: 0.013289
[01:37:28.814] iteration 13695 : loss : 0.055086, loss_ce: 0.015377
[01:37:29.121] iteration 13696 : loss : 0.049608, loss_ce: 0.021868
[01:37:29.429] iteration 13697 : loss : 0.038198, loss_ce: 0.015573
[01:37:29.739] iteration 13698 : loss : 0.113106, loss_ce: 0.012759
[01:37:30.047] iteration 13699 : loss : 0.108136, loss_ce: 0.019497
[01:37:30.353] iteration 13700 : loss : 0.041440, loss_ce: 0.006918
[01:37:30.682] iteration 13701 : loss : 0.107266, loss_ce: 0.009452
[01:37:30.988] iteration 13702 : loss : 0.043271, loss_ce: 0.020413
[01:37:31.298] iteration 13703 : loss : 0.114310, loss_ce: 0.021378
[01:37:31.605] iteration 13704 : loss : 0.047215, loss_ce: 0.017276
[01:37:31.916] iteration 13705 : loss : 0.155594, loss_ce: 0.006435
[01:37:32.224] iteration 13706 : loss : 0.100487, loss_ce: 0.012558
[01:37:32.535] iteration 13707 : loss : 0.115620, loss_ce: 0.011809
[01:37:32.844] iteration 13708 : loss : 0.053669, loss_ce: 0.011564
[01:37:33.151] iteration 13709 : loss : 0.047845, loss_ce: 0.017967
[01:37:33.457] iteration 13710 : loss : 0.052936, loss_ce: 0.017120
[01:37:33.767] iteration 13711 : loss : 0.044799, loss_ce: 0.008801
[01:37:34.073] iteration 13712 : loss : 0.040119, loss_ce: 0.012796
[01:37:34.382] iteration 13713 : loss : 0.048487, loss_ce: 0.016338
[01:37:34.687] iteration 13714 : loss : 0.058285, loss_ce: 0.022047
[01:37:34.996] iteration 13715 : loss : 0.047990, loss_ce: 0.017303
[01:37:35.301] iteration 13716 : loss : 0.045512, loss_ce: 0.015682
[01:37:35.609] iteration 13717 : loss : 0.078463, loss_ce: 0.011576
[01:37:35.916] iteration 13718 : loss : 0.067391, loss_ce: 0.012878
[01:37:36.228] iteration 13719 : loss : 0.062275, loss_ce: 0.016511
[01:37:36.533] iteration 13720 : loss : 0.036566, loss_ce: 0.014491
[01:37:36.859] iteration 13721 : loss : 0.051671, loss_ce: 0.018006
[01:37:37.164] iteration 13722 : loss : 0.047433, loss_ce: 0.014552
[01:37:37.476] iteration 13723 : loss : 0.048976, loss_ce: 0.017166
[01:37:37.787] iteration 13724 : loss : 0.041653, loss_ce: 0.011427
[01:37:38.098] iteration 13725 : loss : 0.102419, loss_ce: 0.009923
[01:37:38.407] iteration 13726 : loss : 0.111927, loss_ce: 0.017652
[01:37:38.716] iteration 13727 : loss : 0.115081, loss_ce: 0.026646
[01:37:39.029] iteration 13728 : loss : 0.042226, loss_ce: 0.011250
[01:37:39.335] iteration 13729 : loss : 0.172770, loss_ce: 0.009532
[01:37:39.639] iteration 13730 : loss : 0.050817, loss_ce: 0.015701
[01:37:39.948] iteration 13731 : loss : 0.114417, loss_ce: 0.019641
[01:37:40.253] iteration 13732 : loss : 0.056774, loss_ce: 0.012821
[01:37:40.560] iteration 13733 : loss : 0.051781, loss_ce: 0.008439
[01:37:40.863] iteration 13734 : loss : 0.046877, loss_ce: 0.014828
[01:37:41.166] iteration 13735 : loss : 0.059909, loss_ce: 0.024025
[01:37:41.473] iteration 13736 : loss : 0.110607, loss_ce: 0.009169
[01:37:41.777] iteration 13737 : loss : 0.043533, loss_ce: 0.013522
[01:37:42.081] iteration 13738 : loss : 0.099375, loss_ce: 0.009092
[01:37:42.384] iteration 13739 : loss : 0.104760, loss_ce: 0.012915
[01:37:42.689] iteration 13740 : loss : 0.040190, loss_ce: 0.007664
[01:37:43.005] iteration 13741 : loss : 0.042742, loss_ce: 0.010371
[01:37:43.309] iteration 13742 : loss : 0.041151, loss_ce: 0.013979
[01:37:43.612] iteration 13743 : loss : 0.051022, loss_ce: 0.012690
[01:37:43.913] iteration 13744 : loss : 0.071642, loss_ce: 0.013768
[01:37:44.223] iteration 13745 : loss : 0.049299, loss_ce: 0.013473
[01:37:44.533] iteration 13746 : loss : 0.048026, loss_ce: 0.021894
[01:37:44.842] iteration 13747 : loss : 0.045596, loss_ce: 0.008591
[01:37:45.155] iteration 13748 : loss : 0.058781, loss_ce: 0.015727
[01:37:45.466] iteration 13749 : loss : 0.060817, loss_ce: 0.018749
[01:37:45.773] iteration 13750 : loss : 0.056470, loss_ce: 0.022240
[01:37:46.094] iteration 13751 : loss : 0.045264, loss_ce: 0.012145
[01:37:46.402] iteration 13752 : loss : 0.056605, loss_ce: 0.017926
[01:37:46.714] iteration 13753 : loss : 0.121786, loss_ce: 0.012390
[01:37:47.022] iteration 13754 : loss : 0.039809, loss_ce: 0.016779
[01:37:47.328] iteration 13755 : loss : 0.051040, loss_ce: 0.016550
[01:37:47.636] iteration 13756 : loss : 0.044088, loss_ce: 0.013825
[01:37:47.944] iteration 13757 : loss : 0.052632, loss_ce: 0.018147
[01:37:48.246] iteration 13758 : loss : 0.050328, loss_ce: 0.018330
[01:37:48.555] iteration 13759 : loss : 0.039192, loss_ce: 0.012484
[01:37:48.865] iteration 13760 : loss : 0.061103, loss_ce: 0.010504
[01:37:48.961] iteration 13761 : loss : 0.170860, loss_ce: 0.022932
[01:38:08.555] iteration 13762 : loss : 0.044538, loss_ce: 0.014863
[01:38:08.855] iteration 13763 : loss : 0.119940, loss_ce: 0.018229
[01:38:09.155] iteration 13764 : loss : 0.161793, loss_ce: 0.008757
[01:38:09.462] iteration 13765 : loss : 0.057044, loss_ce: 0.009360
[01:38:09.765] iteration 13766 : loss : 0.056571, loss_ce: 0.025970
[01:38:10.073] iteration 13767 : loss : 0.061304, loss_ce: 0.007209
[01:38:10.378] iteration 13768 : loss : 0.156881, loss_ce: 0.005060
[01:38:10.689] iteration 13769 : loss : 0.043014, loss_ce: 0.008912
[01:38:10.993] iteration 13770 : loss : 0.048260, loss_ce: 0.012688
[01:38:11.300] iteration 13771 : loss : 0.100049, loss_ce: 0.013002
[01:38:11.611] iteration 13772 : loss : 0.062479, loss_ce: 0.016327
[01:38:11.921] iteration 13773 : loss : 0.041798, loss_ce: 0.010318
[01:38:12.228] iteration 13774 : loss : 0.046952, loss_ce: 0.012456
[01:38:12.538] iteration 13775 : loss : 0.052439, loss_ce: 0.013517
[01:38:12.845] iteration 13776 : loss : 0.042021, loss_ce: 0.016062
[01:38:13.152] iteration 13777 : loss : 0.049934, loss_ce: 0.011254
[01:38:13.457] iteration 13778 : loss : 0.041036, loss_ce: 0.014281
[01:38:13.764] iteration 13779 : loss : 0.039504, loss_ce: 0.012225
[01:38:14.067] iteration 13780 : loss : 0.052087, loss_ce: 0.010829
[01:38:14.395] iteration 13781 : loss : 0.101887, loss_ce: 0.014776
[01:38:14.703] iteration 13782 : loss : 0.066290, loss_ce: 0.009181
[01:38:15.015] iteration 13783 : loss : 0.042544, loss_ce: 0.018368
[01:38:15.325] iteration 13784 : loss : 0.060309, loss_ce: 0.010473
[01:38:15.632] iteration 13785 : loss : 0.058300, loss_ce: 0.021707
[01:38:15.940] iteration 13786 : loss : 0.034995, loss_ce: 0.008323
[01:38:16.247] iteration 13787 : loss : 0.106749, loss_ce: 0.015365
[01:38:16.555] iteration 13788 : loss : 0.040728, loss_ce: 0.011717
[01:38:16.862] iteration 13789 : loss : 0.052156, loss_ce: 0.018844
[01:38:17.170] iteration 13790 : loss : 0.058330, loss_ce: 0.023202
[01:38:17.476] iteration 13791 : loss : 0.045882, loss_ce: 0.014272
[01:38:17.787] iteration 13792 : loss : 0.046906, loss_ce: 0.013740
[01:38:18.091] iteration 13793 : loss : 0.046920, loss_ce: 0.024172
[01:38:18.402] iteration 13794 : loss : 0.044233, loss_ce: 0.017897
[01:38:18.711] iteration 13795 : loss : 0.110028, loss_ce: 0.015367
[01:38:19.016] iteration 13796 : loss : 0.039463, loss_ce: 0.010623
[01:38:19.324] iteration 13797 : loss : 0.062441, loss_ce: 0.023873
[01:38:19.634] iteration 13798 : loss : 0.046232, loss_ce: 0.017962
[01:38:19.941] iteration 13799 : loss : 0.081780, loss_ce: 0.016617
[01:38:20.250] iteration 13800 : loss : 0.119117, loss_ce: 0.006452
[01:38:20.568] iteration 13801 : loss : 0.057854, loss_ce: 0.019737
[01:38:20.874] iteration 13802 : loss : 0.102107, loss_ce: 0.013456
[01:38:21.186] iteration 13803 : loss : 0.110007, loss_ce: 0.008791
[01:38:21.500] iteration 13804 : loss : 0.107509, loss_ce: 0.010929
[01:38:21.805] iteration 13805 : loss : 0.049052, loss_ce: 0.015978
[01:38:22.116] iteration 13806 : loss : 0.049533, loss_ce: 0.013208
[01:38:22.422] iteration 13807 : loss : 0.102558, loss_ce: 0.008791
[01:38:22.732] iteration 13808 : loss : 0.043342, loss_ce: 0.014119
[01:38:23.037] iteration 13809 : loss : 0.070502, loss_ce: 0.013269
[01:38:23.342] iteration 13810 : loss : 0.055298, loss_ce: 0.011871
[01:38:23.653] iteration 13811 : loss : 0.046362, loss_ce: 0.019154
[01:38:23.962] iteration 13812 : loss : 0.045062, loss_ce: 0.010225
[01:38:24.270] iteration 13813 : loss : 0.051643, loss_ce: 0.023123
[01:38:24.576] iteration 13814 : loss : 0.043375, loss_ce: 0.007940
[01:38:24.883] iteration 13815 : loss : 0.115471, loss_ce: 0.011144
[01:38:25.195] iteration 13816 : loss : 0.049224, loss_ce: 0.016818
[01:38:25.505] iteration 13817 : loss : 0.040434, loss_ce: 0.014605
[01:38:25.810] iteration 13818 : loss : 0.109283, loss_ce: 0.007190
[01:38:26.118] iteration 13819 : loss : 0.045303, loss_ce: 0.008987
[01:38:26.428] iteration 13820 : loss : 0.047791, loss_ce: 0.017832
[01:38:26.748] iteration 13821 : loss : 0.041603, loss_ce: 0.015086
[01:38:27.056] iteration 13822 : loss : 0.127114, loss_ce: 0.010285
[01:38:27.364] iteration 13823 : loss : 0.049109, loss_ce: 0.017180
[01:38:27.675] iteration 13824 : loss : 0.057561, loss_ce: 0.021065
[01:38:27.981] iteration 13825 : loss : 0.050437, loss_ce: 0.018822
[01:38:28.292] iteration 13826 : loss : 0.037590, loss_ce: 0.013927
[01:38:28.602] iteration 13827 : loss : 0.053651, loss_ce: 0.012899
[01:38:28.912] iteration 13828 : loss : 0.113042, loss_ce: 0.008158
[01:38:29.220] iteration 13829 : loss : 0.045856, loss_ce: 0.011887
[01:38:29.521] iteration 13830 : loss : 0.076490, loss_ce: 0.009403
[01:38:29.822] iteration 13831 : loss : 0.286021, loss_ce: 0.007636
[01:38:30.126] iteration 13832 : loss : 0.044408, loss_ce: 0.013417
[01:38:30.427] iteration 13833 : loss : 0.047755, loss_ce: 0.017963
[01:38:30.733] iteration 13834 : loss : 0.099627, loss_ce: 0.015557
[01:38:31.036] iteration 13835 : loss : 0.051710, loss_ce: 0.009057
[01:38:31.341] iteration 13836 : loss : 0.045297, loss_ce: 0.009379
[01:38:31.646] iteration 13837 : loss : 0.051530, loss_ce: 0.014305
[01:38:31.955] iteration 13838 : loss : 0.115811, loss_ce: 0.013033
[01:38:32.261] iteration 13839 : loss : 0.048761, loss_ce: 0.019880
[01:38:32.568] iteration 13840 : loss : 0.054930, loss_ce: 0.015391
[01:38:32.889] iteration 13841 : loss : 0.059104, loss_ce: 0.024613
[01:38:33.194] iteration 13842 : loss : 0.050272, loss_ce: 0.023872
[01:38:33.496] iteration 13843 : loss : 0.047767, loss_ce: 0.018306
[01:38:33.800] iteration 13844 : loss : 0.110669, loss_ce: 0.015387
[01:38:34.105] iteration 13845 : loss : 0.043466, loss_ce: 0.014357
[01:38:34.408] iteration 13846 : loss : 0.052004, loss_ce: 0.018497
[01:38:34.717] iteration 13847 : loss : 0.068831, loss_ce: 0.020579
[01:38:35.024] iteration 13848 : loss : 0.046580, loss_ce: 0.008887
[01:38:35.326] iteration 13849 : loss : 0.050625, loss_ce: 0.022704
[01:38:35.635] iteration 13850 : loss : 0.048547, loss_ce: 0.010235
[01:38:35.937] iteration 13851 : loss : 0.045260, loss_ce: 0.011672
[01:38:36.242] iteration 13852 : loss : 0.105520, loss_ce: 0.012048
[01:38:36.544] iteration 13853 : loss : 0.221678, loss_ce: 0.003363
[01:38:36.849] iteration 13854 : loss : 0.056782, loss_ce: 0.012992
[01:38:37.154] iteration 13855 : loss : 0.058295, loss_ce: 0.019761
[01:38:37.457] iteration 13856 : loss : 0.050207, loss_ce: 0.010374
[01:38:37.763] iteration 13857 : loss : 0.054191, loss_ce: 0.018680
[01:38:38.067] iteration 13858 : loss : 0.049763, loss_ce: 0.018756
[01:38:38.371] iteration 13859 : loss : 0.078153, loss_ce: 0.022117
[01:38:38.674] iteration 13860 : loss : 0.036754, loss_ce: 0.009241
[01:38:38.989] iteration 13861 : loss : 0.047013, loss_ce: 0.012526
[01:38:39.296] iteration 13862 : loss : 0.043938, loss_ce: 0.011051
[01:38:39.602] iteration 13863 : loss : 0.045204, loss_ce: 0.016765
[01:38:39.905] iteration 13864 : loss : 0.052612, loss_ce: 0.018604
[01:38:40.210] iteration 13865 : loss : 0.062956, loss_ce: 0.014805
[01:38:40.513] iteration 13866 : loss : 0.106347, loss_ce: 0.008094
[01:38:40.817] iteration 13867 : loss : 0.050622, loss_ce: 0.014984
[01:38:41.122] iteration 13868 : loss : 0.037890, loss_ce: 0.010171
[01:38:41.426] iteration 13869 : loss : 0.046648, loss_ce: 0.011560
[01:38:41.728] iteration 13870 : loss : 0.111074, loss_ce: 0.019609
[01:38:42.038] iteration 13871 : loss : 0.063377, loss_ce: 0.018880
[01:38:42.347] iteration 13872 : loss : 0.055464, loss_ce: 0.017593
[01:38:42.658] iteration 13873 : loss : 0.050555, loss_ce: 0.021601
[01:38:42.966] iteration 13874 : loss : 0.057444, loss_ce: 0.024155
[01:38:43.282] iteration 13875 : loss : 0.040316, loss_ce: 0.013734
[01:38:43.594] iteration 13876 : loss : 0.050385, loss_ce: 0.017141
[01:38:43.903] iteration 13877 : loss : 0.116445, loss_ce: 0.013052
[01:38:44.213] iteration 13878 : loss : 0.103810, loss_ce: 0.014157
[01:38:44.515] iteration 13879 : loss : 0.045197, loss_ce: 0.019492
[01:38:44.818] iteration 13880 : loss : 0.101727, loss_ce: 0.011943
[01:38:45.141] iteration 13881 : loss : 0.036447, loss_ce: 0.009352
[01:38:45.445] iteration 13882 : loss : 0.045888, loss_ce: 0.018474
[01:38:45.748] iteration 13883 : loss : 0.051642, loss_ce: 0.018431
[01:38:46.056] iteration 13884 : loss : 0.054671, loss_ce: 0.010882
[01:38:46.369] iteration 13885 : loss : 0.103464, loss_ce: 0.008551
[01:38:46.679] iteration 13886 : loss : 0.075953, loss_ce: 0.018770
[01:38:46.990] iteration 13887 : loss : 0.049324, loss_ce: 0.022525
[01:38:47.299] iteration 13888 : loss : 0.056828, loss_ce: 0.013969
[01:38:47.605] iteration 13889 : loss : 0.046709, loss_ce: 0.010356
[01:38:47.910] iteration 13890 : loss : 0.052277, loss_ce: 0.013211
[01:38:48.215] iteration 13891 : loss : 0.046059, loss_ce: 0.007973
[01:38:48.518] iteration 13892 : loss : 0.041623, loss_ce: 0.015137
[01:38:48.829] iteration 13893 : loss : 0.044001, loss_ce: 0.015194
[01:38:49.134] iteration 13894 : loss : 0.107905, loss_ce: 0.015675
[01:38:49.448] iteration 13895 : loss : 0.120810, loss_ce: 0.010451
[01:38:49.754] iteration 13896 : loss : 0.050396, loss_ce: 0.016258
[01:38:50.062] iteration 13897 : loss : 0.128685, loss_ce: 0.009357
[01:38:50.374] iteration 13898 : loss : 0.107582, loss_ce: 0.009152
[01:38:50.680] iteration 13899 : loss : 0.055090, loss_ce: 0.025790
[01:38:50.760] iteration 13900 : loss : 0.369801, loss_ce: 0.001520
[01:39:09.242] iteration 13901 : loss : 0.054305, loss_ce: 0.012194
[01:39:09.551] iteration 13902 : loss : 0.048716, loss_ce: 0.015965
[01:39:09.857] iteration 13903 : loss : 0.047788, loss_ce: 0.014413
[01:39:10.162] iteration 13904 : loss : 0.069888, loss_ce: 0.015179
[01:39:10.471] iteration 13905 : loss : 0.056744, loss_ce: 0.019190
[01:39:10.776] iteration 13906 : loss : 0.053881, loss_ce: 0.016884
[01:39:11.084] iteration 13907 : loss : 0.051949, loss_ce: 0.022039
[01:39:11.393] iteration 13908 : loss : 0.054333, loss_ce: 0.013706
[01:39:11.703] iteration 13909 : loss : 0.111438, loss_ce: 0.016718
[01:39:12.015] iteration 13910 : loss : 0.056320, loss_ce: 0.017429
[01:39:12.324] iteration 13911 : loss : 0.068329, loss_ce: 0.020359
[01:39:12.633] iteration 13912 : loss : 0.051822, loss_ce: 0.018913
[01:39:12.942] iteration 13913 : loss : 0.045227, loss_ce: 0.010617
[01:39:13.249] iteration 13914 : loss : 0.061859, loss_ce: 0.014528
[01:39:13.556] iteration 13915 : loss : 0.129390, loss_ce: 0.005884
[01:39:13.865] iteration 13916 : loss : 0.227163, loss_ce: 0.009298
[01:39:14.175] iteration 13917 : loss : 0.063113, loss_ce: 0.018314
[01:39:14.486] iteration 13918 : loss : 0.055084, loss_ce: 0.016605
[01:39:14.796] iteration 13919 : loss : 0.061967, loss_ce: 0.021553
[01:39:15.102] iteration 13920 : loss : 0.052497, loss_ce: 0.013857
[01:39:15.425] iteration 13921 : loss : 0.060628, loss_ce: 0.017721
[01:39:15.731] iteration 13922 : loss : 0.048406, loss_ce: 0.011040
[01:39:16.039] iteration 13923 : loss : 0.056223, loss_ce: 0.024852
[01:39:16.348] iteration 13924 : loss : 0.114647, loss_ce: 0.018137
[01:39:16.657] iteration 13925 : loss : 0.139184, loss_ce: 0.012180
[01:39:16.968] iteration 13926 : loss : 0.105161, loss_ce: 0.017826
[01:39:17.277] iteration 13927 : loss : 0.057308, loss_ce: 0.019745
[01:39:17.587] iteration 13928 : loss : 0.042237, loss_ce: 0.013769
[01:39:17.896] iteration 13929 : loss : 0.058695, loss_ce: 0.014230
[01:39:18.202] iteration 13930 : loss : 0.081434, loss_ce: 0.009619
[01:39:18.513] iteration 13931 : loss : 0.051757, loss_ce: 0.007233
[01:39:18.825] iteration 13932 : loss : 0.113087, loss_ce: 0.006854
[01:39:19.134] iteration 13933 : loss : 0.055796, loss_ce: 0.014842
[01:39:19.442] iteration 13934 : loss : 0.058863, loss_ce: 0.028968
[01:39:19.745] iteration 13935 : loss : 0.045040, loss_ce: 0.014387
[01:39:20.051] iteration 13936 : loss : 0.048476, loss_ce: 0.011914
[01:39:20.354] iteration 13937 : loss : 0.044759, loss_ce: 0.013457
[01:39:20.664] iteration 13938 : loss : 0.053329, loss_ce: 0.017821
[01:39:20.966] iteration 13939 : loss : 0.043076, loss_ce: 0.010187
[01:39:21.269] iteration 13940 : loss : 0.041926, loss_ce: 0.009676
[01:39:21.589] iteration 13941 : loss : 0.053120, loss_ce: 0.011855
[01:39:21.893] iteration 13942 : loss : 0.105956, loss_ce: 0.005330
[01:39:22.199] iteration 13943 : loss : 0.061782, loss_ce: 0.011995
[01:39:22.500] iteration 13944 : loss : 0.063949, loss_ce: 0.018010
[01:39:22.806] iteration 13945 : loss : 0.047528, loss_ce: 0.009147
[01:39:23.113] iteration 13946 : loss : 0.066786, loss_ce: 0.019258
[01:39:23.419] iteration 13947 : loss : 0.049126, loss_ce: 0.016847
[01:39:23.722] iteration 13948 : loss : 0.046316, loss_ce: 0.016142
[01:39:24.023] iteration 13949 : loss : 0.046975, loss_ce: 0.007706
[01:39:24.325] iteration 13950 : loss : 0.057691, loss_ce: 0.023889
[01:39:24.633] iteration 13951 : loss : 0.050533, loss_ce: 0.013118
[01:39:24.934] iteration 13952 : loss : 0.040598, loss_ce: 0.018229
[01:39:25.237] iteration 13953 : loss : 0.032325, loss_ce: 0.004971
[01:39:25.540] iteration 13954 : loss : 0.058653, loss_ce: 0.016034
[01:39:25.844] iteration 13955 : loss : 0.041114, loss_ce: 0.012973
[01:39:26.146] iteration 13956 : loss : 0.043300, loss_ce: 0.017470
[01:39:26.451] iteration 13957 : loss : 0.055230, loss_ce: 0.027440
[01:39:26.755] iteration 13958 : loss : 0.055708, loss_ce: 0.007617
[01:39:27.058] iteration 13959 : loss : 0.055225, loss_ce: 0.017954
[01:39:27.362] iteration 13960 : loss : 0.040961, loss_ce: 0.011100
[01:39:27.681] iteration 13961 : loss : 0.054908, loss_ce: 0.020857
[01:39:27.984] iteration 13962 : loss : 0.052742, loss_ce: 0.016286
[01:39:28.291] iteration 13963 : loss : 0.048491, loss_ce: 0.015561
[01:39:28.594] iteration 13964 : loss : 0.079704, loss_ce: 0.007113
[01:39:28.897] iteration 13965 : loss : 0.116819, loss_ce: 0.012890
[01:39:29.203] iteration 13966 : loss : 0.045428, loss_ce: 0.019350
[01:39:29.511] iteration 13967 : loss : 0.047388, loss_ce: 0.010933
[01:39:29.817] iteration 13968 : loss : 0.046578, loss_ce: 0.020733
[01:39:30.122] iteration 13969 : loss : 0.101637, loss_ce: 0.009693
[01:39:30.431] iteration 13970 : loss : 0.048902, loss_ce: 0.011426
[01:39:30.737] iteration 13971 : loss : 0.046479, loss_ce: 0.017601
[01:39:31.043] iteration 13972 : loss : 0.112734, loss_ce: 0.011939
[01:39:31.345] iteration 13973 : loss : 0.054590, loss_ce: 0.009750
[01:39:31.648] iteration 13974 : loss : 0.043675, loss_ce: 0.014747
[01:39:31.954] iteration 13975 : loss : 0.055490, loss_ce: 0.023530
[01:39:32.258] iteration 13976 : loss : 0.051258, loss_ce: 0.024465
[01:39:32.570] iteration 13977 : loss : 0.069000, loss_ce: 0.016279
[01:39:32.879] iteration 13978 : loss : 0.051987, loss_ce: 0.012000
[01:39:33.186] iteration 13979 : loss : 0.048708, loss_ce: 0.015427
[01:39:33.493] iteration 13980 : loss : 0.043543, loss_ce: 0.017417
[01:39:33.819] iteration 13981 : loss : 0.165466, loss_ce: 0.005746
[01:39:34.128] iteration 13982 : loss : 0.107628, loss_ce: 0.014610
[01:39:34.439] iteration 13983 : loss : 0.042993, loss_ce: 0.015379
[01:39:34.739] iteration 13984 : loss : 0.057131, loss_ce: 0.014321
[01:39:35.044] iteration 13985 : loss : 0.052782, loss_ce: 0.021705
[01:39:35.350] iteration 13986 : loss : 0.040698, loss_ce: 0.014488
[01:39:35.655] iteration 13987 : loss : 0.047820, loss_ce: 0.011885
[01:39:35.961] iteration 13988 : loss : 0.042944, loss_ce: 0.015291
[01:39:36.262] iteration 13989 : loss : 0.115202, loss_ce: 0.009849
[01:39:36.568] iteration 13990 : loss : 0.045642, loss_ce: 0.014362
[01:39:36.870] iteration 13991 : loss : 0.108192, loss_ce: 0.009166
[01:39:37.177] iteration 13992 : loss : 0.101241, loss_ce: 0.012845
[01:39:37.478] iteration 13993 : loss : 0.050946, loss_ce: 0.022364
[01:39:37.779] iteration 13994 : loss : 0.065743, loss_ce: 0.014718
[01:39:38.081] iteration 13995 : loss : 0.053759, loss_ce: 0.019277
[01:39:38.385] iteration 13996 : loss : 0.055933, loss_ce: 0.018544
[01:39:38.688] iteration 13997 : loss : 0.065702, loss_ce: 0.014076
[01:39:38.991] iteration 13998 : loss : 0.054291, loss_ce: 0.028691
[01:39:39.295] iteration 13999 : loss : 0.036343, loss_ce: 0.010532
[01:39:39.600] iteration 14000 : loss : 0.055257, loss_ce: 0.012408
[01:39:39.916] iteration 14001 : loss : 0.045134, loss_ce: 0.009225
[01:39:40.219] iteration 14002 : loss : 0.105282, loss_ce: 0.014707
[01:39:40.527] iteration 14003 : loss : 0.045748, loss_ce: 0.014237
[01:39:40.832] iteration 14004 : loss : 0.068509, loss_ce: 0.008269
[01:39:41.136] iteration 14005 : loss : 0.039175, loss_ce: 0.011233
[01:39:41.443] iteration 14006 : loss : 0.048379, loss_ce: 0.017839
[01:39:41.747] iteration 14007 : loss : 0.112848, loss_ce: 0.014848
[01:39:42.051] iteration 14008 : loss : 0.040424, loss_ce: 0.009050
[01:39:42.353] iteration 14009 : loss : 0.048543, loss_ce: 0.025340
[01:39:42.656] iteration 14010 : loss : 0.099959, loss_ce: 0.005200
[01:39:42.958] iteration 14011 : loss : 0.051247, loss_ce: 0.010774
[01:39:43.261] iteration 14012 : loss : 0.044471, loss_ce: 0.016013
[01:39:43.562] iteration 14013 : loss : 0.058718, loss_ce: 0.018582
[01:39:43.864] iteration 14014 : loss : 0.045513, loss_ce: 0.015625
[01:39:44.170] iteration 14015 : loss : 0.051402, loss_ce: 0.007170
[01:39:44.477] iteration 14016 : loss : 0.049178, loss_ce: 0.021093
[01:39:44.776] iteration 14017 : loss : 0.046729, loss_ce: 0.012882
[01:39:45.080] iteration 14018 : loss : 0.051076, loss_ce: 0.023657
[01:39:45.388] iteration 14019 : loss : 0.051680, loss_ce: 0.013038
[01:39:45.696] iteration 14020 : loss : 0.104872, loss_ce: 0.005220
[01:39:46.019] iteration 14021 : loss : 0.045198, loss_ce: 0.017940
[01:39:46.325] iteration 14022 : loss : 0.129998, loss_ce: 0.015106
[01:39:46.631] iteration 14023 : loss : 0.048165, loss_ce: 0.008765
[01:39:46.943] iteration 14024 : loss : 0.049651, loss_ce: 0.018525
[01:39:47.254] iteration 14025 : loss : 0.046952, loss_ce: 0.012074
[01:39:47.574] iteration 14026 : loss : 0.041715, loss_ce: 0.014574
[01:39:47.885] iteration 14027 : loss : 0.058738, loss_ce: 0.018082
[01:39:48.195] iteration 14028 : loss : 0.052787, loss_ce: 0.015025
[01:39:48.501] iteration 14029 : loss : 0.056938, loss_ce: 0.014809
[01:39:48.810] iteration 14030 : loss : 0.105433, loss_ce: 0.013825
[01:39:49.120] iteration 14031 : loss : 0.053541, loss_ce: 0.023785
[01:39:49.435] iteration 14032 : loss : 0.045055, loss_ce: 0.017681
[01:39:49.752] iteration 14033 : loss : 0.047757, loss_ce: 0.020639
[01:39:50.063] iteration 14034 : loss : 0.046146, loss_ce: 0.013987
[01:39:50.376] iteration 14035 : loss : 0.047106, loss_ce: 0.010968
[01:39:50.689] iteration 14036 : loss : 0.053694, loss_ce: 0.017982
[01:39:51.001] iteration 14037 : loss : 0.122259, loss_ce: 0.013621
[01:39:51.314] iteration 14038 : loss : 0.054450, loss_ce: 0.017851
[01:39:51.397] iteration 14039 : loss : 0.122157, loss_ce: 0.012489
[01:40:08.554] iteration 14040 : loss : 0.069838, loss_ce: 0.019322
[01:40:08.878] iteration 14041 : loss : 0.037241, loss_ce: 0.005448
[01:40:09.183] iteration 14042 : loss : 0.042817, loss_ce: 0.016643
[01:40:09.487] iteration 14043 : loss : 0.037774, loss_ce: 0.015118
[01:40:09.791] iteration 14044 : loss : 0.047424, loss_ce: 0.015046
[01:40:10.094] iteration 14045 : loss : 0.091889, loss_ce: 0.017464
[01:40:10.399] iteration 14046 : loss : 0.051843, loss_ce: 0.014571
[01:40:10.699] iteration 14047 : loss : 0.056109, loss_ce: 0.016525
[01:40:11.002] iteration 14048 : loss : 0.050744, loss_ce: 0.016256
[01:40:11.303] iteration 14049 : loss : 0.038724, loss_ce: 0.016595
[01:40:11.603] iteration 14050 : loss : 0.059513, loss_ce: 0.018438
[01:40:11.907] iteration 14051 : loss : 0.041614, loss_ce: 0.008996
[01:40:12.210] iteration 14052 : loss : 0.054927, loss_ce: 0.021881
[01:40:12.513] iteration 14053 : loss : 0.108392, loss_ce: 0.014751
[01:40:12.818] iteration 14054 : loss : 0.045912, loss_ce: 0.018170
[01:40:13.119] iteration 14055 : loss : 0.044418, loss_ce: 0.014887
[01:40:13.423] iteration 14056 : loss : 0.054405, loss_ce: 0.014542
[01:40:13.726] iteration 14057 : loss : 0.056281, loss_ce: 0.021679
[01:40:14.025] iteration 14058 : loss : 0.055285, loss_ce: 0.018638
[01:40:14.329] iteration 14059 : loss : 0.058883, loss_ce: 0.015736
[01:40:14.632] iteration 14060 : loss : 0.108540, loss_ce: 0.007158
[01:40:14.950] iteration 14061 : loss : 0.048559, loss_ce: 0.014182
[01:40:15.251] iteration 14062 : loss : 0.054395, loss_ce: 0.013866
[01:40:15.556] iteration 14063 : loss : 0.067685, loss_ce: 0.010602
[01:40:15.858] iteration 14064 : loss : 0.051969, loss_ce: 0.015248
[01:40:16.162] iteration 14065 : loss : 0.042972, loss_ce: 0.016422
[01:40:16.464] iteration 14066 : loss : 0.043886, loss_ce: 0.018324
[01:40:16.766] iteration 14067 : loss : 0.044091, loss_ce: 0.011712
[01:40:17.068] iteration 14068 : loss : 0.283489, loss_ce: 0.002801
[01:40:17.372] iteration 14069 : loss : 0.058594, loss_ce: 0.013957
[01:40:17.673] iteration 14070 : loss : 0.060178, loss_ce: 0.018822
[01:40:17.979] iteration 14071 : loss : 0.051903, loss_ce: 0.017900
[01:40:18.282] iteration 14072 : loss : 0.046593, loss_ce: 0.011208
[01:40:18.584] iteration 14073 : loss : 0.071868, loss_ce: 0.015919
[01:40:18.891] iteration 14074 : loss : 0.040831, loss_ce: 0.017266
[01:40:19.194] iteration 14075 : loss : 0.058790, loss_ce: 0.010843
[01:40:19.495] iteration 14076 : loss : 0.056712, loss_ce: 0.011168
[01:40:19.799] iteration 14077 : loss : 0.053890, loss_ce: 0.003996
[01:40:20.102] iteration 14078 : loss : 0.048919, loss_ce: 0.018229
[01:40:20.403] iteration 14079 : loss : 0.062459, loss_ce: 0.014355
[01:40:20.708] iteration 14080 : loss : 0.061130, loss_ce: 0.022548
[01:40:21.023] iteration 14081 : loss : 0.038720, loss_ce: 0.011261
[01:40:21.324] iteration 14082 : loss : 0.067717, loss_ce: 0.008496
[01:40:21.629] iteration 14083 : loss : 0.041482, loss_ce: 0.013429
[01:40:21.931] iteration 14084 : loss : 0.113723, loss_ce: 0.010649
[01:40:22.235] iteration 14085 : loss : 0.050580, loss_ce: 0.021009
[01:40:22.543] iteration 14086 : loss : 0.044001, loss_ce: 0.013007
[01:40:22.850] iteration 14087 : loss : 0.165094, loss_ce: 0.008930
[01:40:23.163] iteration 14088 : loss : 0.072993, loss_ce: 0.012455
[01:40:23.473] iteration 14089 : loss : 0.103260, loss_ce: 0.013022
[01:40:23.780] iteration 14090 : loss : 0.051475, loss_ce: 0.015051
[01:40:24.087] iteration 14091 : loss : 0.047633, loss_ce: 0.018758
[01:40:24.393] iteration 14092 : loss : 0.056590, loss_ce: 0.019217
[01:40:24.697] iteration 14093 : loss : 0.109490, loss_ce: 0.010306
[01:40:25.000] iteration 14094 : loss : 0.042887, loss_ce: 0.007697
[01:40:25.304] iteration 14095 : loss : 0.107428, loss_ce: 0.006741
[01:40:25.608] iteration 14096 : loss : 0.050652, loss_ce: 0.020365
[01:40:25.910] iteration 14097 : loss : 0.054408, loss_ce: 0.012619
[01:40:26.215] iteration 14098 : loss : 0.049907, loss_ce: 0.015026
[01:40:26.521] iteration 14099 : loss : 0.051149, loss_ce: 0.013164
[01:40:26.825] iteration 14100 : loss : 0.058084, loss_ce: 0.016208
[01:40:27.147] iteration 14101 : loss : 0.103434, loss_ce: 0.007572
[01:40:27.448] iteration 14102 : loss : 0.058057, loss_ce: 0.012254
[01:40:27.752] iteration 14103 : loss : 0.037759, loss_ce: 0.007182
[01:40:28.053] iteration 14104 : loss : 0.039650, loss_ce: 0.014529
[01:40:28.356] iteration 14105 : loss : 0.047544, loss_ce: 0.013144
[01:40:28.660] iteration 14106 : loss : 0.056114, loss_ce: 0.015407
[01:40:28.959] iteration 14107 : loss : 0.034293, loss_ce: 0.009714
[01:40:29.264] iteration 14108 : loss : 0.035571, loss_ce: 0.010691
[01:40:29.567] iteration 14109 : loss : 0.043385, loss_ce: 0.012725
[01:40:29.871] iteration 14110 : loss : 0.042491, loss_ce: 0.023554
[01:40:30.177] iteration 14111 : loss : 0.048086, loss_ce: 0.018899
[01:40:30.482] iteration 14112 : loss : 0.045976, loss_ce: 0.020452
[01:40:30.786] iteration 14113 : loss : 0.049212, loss_ce: 0.015072
[01:40:31.091] iteration 14114 : loss : 0.108783, loss_ce: 0.009613
[01:40:31.397] iteration 14115 : loss : 0.047081, loss_ce: 0.011541
[01:40:31.699] iteration 14116 : loss : 0.052951, loss_ce: 0.014974
[01:40:32.002] iteration 14117 : loss : 0.076036, loss_ce: 0.023660
[01:40:32.307] iteration 14118 : loss : 0.055727, loss_ce: 0.020543
[01:40:32.612] iteration 14119 : loss : 0.052066, loss_ce: 0.009680
[01:40:32.915] iteration 14120 : loss : 0.052752, loss_ce: 0.017659
[01:40:33.233] iteration 14121 : loss : 0.064912, loss_ce: 0.017323
[01:40:33.536] iteration 14122 : loss : 0.232461, loss_ce: 0.004008
[01:40:33.839] iteration 14123 : loss : 0.052399, loss_ce: 0.011651
[01:40:34.144] iteration 14124 : loss : 0.046800, loss_ce: 0.017727
[01:40:34.445] iteration 14125 : loss : 0.051966, loss_ce: 0.007592
[01:40:34.746] iteration 14126 : loss : 0.089714, loss_ce: 0.008179
[01:40:35.049] iteration 14127 : loss : 0.046890, loss_ce: 0.016715
[01:40:35.351] iteration 14128 : loss : 0.043883, loss_ce: 0.015515
[01:40:35.654] iteration 14129 : loss : 0.033711, loss_ce: 0.012002
[01:40:35.957] iteration 14130 : loss : 0.045866, loss_ce: 0.016986
[01:40:36.265] iteration 14131 : loss : 0.105909, loss_ce: 0.010839
[01:40:36.568] iteration 14132 : loss : 0.104735, loss_ce: 0.012671
[01:40:36.871] iteration 14133 : loss : 0.047996, loss_ce: 0.015648
[01:40:37.179] iteration 14134 : loss : 0.050846, loss_ce: 0.013323
[01:40:37.486] iteration 14135 : loss : 0.057799, loss_ce: 0.018110
[01:40:37.796] iteration 14136 : loss : 0.108409, loss_ce: 0.022265
[01:40:38.106] iteration 14137 : loss : 0.048081, loss_ce: 0.015431
[01:40:38.418] iteration 14138 : loss : 0.059073, loss_ce: 0.012543
[01:40:38.730] iteration 14139 : loss : 0.047378, loss_ce: 0.011741
[01:40:39.039] iteration 14140 : loss : 0.049437, loss_ce: 0.016318
[01:40:39.361] iteration 14141 : loss : 0.028244, loss_ce: 0.004709
[01:40:39.664] iteration 14142 : loss : 0.111381, loss_ce: 0.013239
[01:40:39.969] iteration 14143 : loss : 0.036890, loss_ce: 0.008293
[01:40:40.273] iteration 14144 : loss : 0.047570, loss_ce: 0.008094
[01:40:40.575] iteration 14145 : loss : 0.060363, loss_ce: 0.015498
[01:40:40.876] iteration 14146 : loss : 0.042196, loss_ce: 0.016738
[01:40:41.179] iteration 14147 : loss : 0.049388, loss_ce: 0.012721
[01:40:41.484] iteration 14148 : loss : 0.045289, loss_ce: 0.015496
[01:40:41.787] iteration 14149 : loss : 0.104752, loss_ce: 0.010280
[01:40:42.088] iteration 14150 : loss : 0.055190, loss_ce: 0.031146
[01:40:42.390] iteration 14151 : loss : 0.051548, loss_ce: 0.018807
[01:40:42.692] iteration 14152 : loss : 0.063202, loss_ce: 0.023697
[01:40:42.995] iteration 14153 : loss : 0.043893, loss_ce: 0.010887
[01:40:43.302] iteration 14154 : loss : 0.120172, loss_ce: 0.007191
[01:40:43.603] iteration 14155 : loss : 0.048614, loss_ce: 0.010803
[01:40:43.903] iteration 14156 : loss : 0.044678, loss_ce: 0.012580
[01:40:44.211] iteration 14157 : loss : 0.059951, loss_ce: 0.010725
[01:40:44.512] iteration 14158 : loss : 0.067230, loss_ce: 0.012013
[01:40:44.815] iteration 14159 : loss : 0.057674, loss_ce: 0.021481
[01:40:45.117] iteration 14160 : loss : 0.087643, loss_ce: 0.013795
[01:40:45.433] iteration 14161 : loss : 0.108350, loss_ce: 0.010750
[01:40:45.739] iteration 14162 : loss : 0.047373, loss_ce: 0.017989
[01:40:46.044] iteration 14163 : loss : 0.045046, loss_ce: 0.022127
[01:40:46.357] iteration 14164 : loss : 0.044174, loss_ce: 0.015010
[01:40:46.657] iteration 14165 : loss : 0.105520, loss_ce: 0.013395
[01:40:46.963] iteration 14166 : loss : 0.038991, loss_ce: 0.015112
[01:40:47.272] iteration 14167 : loss : 0.051163, loss_ce: 0.020193
[01:40:47.582] iteration 14168 : loss : 0.287398, loss_ce: 0.003801
[01:40:47.888] iteration 14169 : loss : 0.047991, loss_ce: 0.016879
[01:40:48.194] iteration 14170 : loss : 0.040589, loss_ce: 0.011395
[01:40:48.502] iteration 14171 : loss : 0.057156, loss_ce: 0.013747
[01:40:48.809] iteration 14172 : loss : 0.048415, loss_ce: 0.021396
[01:40:49.117] iteration 14173 : loss : 0.050834, loss_ce: 0.017384
[01:40:49.426] iteration 14174 : loss : 0.043752, loss_ce: 0.013963
[01:40:49.732] iteration 14175 : loss : 0.036397, loss_ce: 0.012238
[01:40:50.036] iteration 14176 : loss : 0.089398, loss_ce: 0.027105
[01:40:50.342] iteration 14177 : loss : 0.045802, loss_ce: 0.012845
[01:40:50.424] iteration 14178 : loss : 0.159645, loss_ce: 0.008467
[01:41:07.655] iteration 14179 : loss : 0.053224, loss_ce: 0.015489
[01:41:07.956] iteration 14180 : loss : 0.036524, loss_ce: 0.013206
[01:41:08.279] iteration 14181 : loss : 0.048324, loss_ce: 0.013650
[01:41:08.582] iteration 14182 : loss : 0.054683, loss_ce: 0.016002
[01:41:08.891] iteration 14183 : loss : 0.059356, loss_ce: 0.015244
[01:41:09.193] iteration 14184 : loss : 0.045231, loss_ce: 0.022578
[01:41:09.495] iteration 14185 : loss : 0.048098, loss_ce: 0.018242
[01:41:09.798] iteration 14186 : loss : 0.058098, loss_ce: 0.008034
[01:41:10.104] iteration 14187 : loss : 0.084079, loss_ce: 0.016757
[01:41:10.413] iteration 14188 : loss : 0.052334, loss_ce: 0.015709
[01:41:10.716] iteration 14189 : loss : 0.048072, loss_ce: 0.018360
[01:41:11.021] iteration 14190 : loss : 0.127033, loss_ce: 0.016899
[01:41:11.329] iteration 14191 : loss : 0.058349, loss_ce: 0.009331
[01:41:11.638] iteration 14192 : loss : 0.181460, loss_ce: 0.003988
[01:41:11.946] iteration 14193 : loss : 0.052809, loss_ce: 0.012481
[01:41:12.259] iteration 14194 : loss : 0.091617, loss_ce: 0.008183
[01:41:12.570] iteration 14195 : loss : 0.047142, loss_ce: 0.013229
[01:41:12.874] iteration 14196 : loss : 0.111126, loss_ce: 0.011328
[01:41:13.180] iteration 14197 : loss : 0.052157, loss_ce: 0.016626
[01:41:13.495] iteration 14198 : loss : 0.059672, loss_ce: 0.017192
[01:41:13.800] iteration 14199 : loss : 0.050608, loss_ce: 0.020173
[01:41:14.115] iteration 14200 : loss : 0.052332, loss_ce: 0.014548
[01:41:14.444] iteration 14201 : loss : 0.048005, loss_ce: 0.023252
[01:41:14.752] iteration 14202 : loss : 0.040290, loss_ce: 0.011919
[01:41:15.059] iteration 14203 : loss : 0.047377, loss_ce: 0.017693
[01:41:15.372] iteration 14204 : loss : 0.045644, loss_ce: 0.019704
[01:41:15.677] iteration 14205 : loss : 0.040378, loss_ce: 0.016893
[01:41:15.987] iteration 14206 : loss : 0.100776, loss_ce: 0.012801
[01:41:16.298] iteration 14207 : loss : 0.038492, loss_ce: 0.014640
[01:41:16.603] iteration 14208 : loss : 0.051678, loss_ce: 0.018948
[01:41:16.913] iteration 14209 : loss : 0.113689, loss_ce: 0.012271
[01:41:17.219] iteration 14210 : loss : 0.042641, loss_ce: 0.011751
[01:41:17.531] iteration 14211 : loss : 0.037606, loss_ce: 0.006121
[01:41:17.844] iteration 14212 : loss : 0.039520, loss_ce: 0.017638
[01:41:18.153] iteration 14213 : loss : 0.151786, loss_ce: 0.009517
[01:41:18.462] iteration 14214 : loss : 0.041892, loss_ce: 0.007452
[01:41:18.772] iteration 14215 : loss : 0.081045, loss_ce: 0.012326
[01:41:19.077] iteration 14216 : loss : 0.159767, loss_ce: 0.003352
[01:41:19.384] iteration 14217 : loss : 0.043099, loss_ce: 0.008452
[01:41:19.695] iteration 14218 : loss : 0.042985, loss_ce: 0.024631
[01:41:20.004] iteration 14219 : loss : 0.066721, loss_ce: 0.019909
[01:41:20.311] iteration 14220 : loss : 0.040582, loss_ce: 0.012827
[01:41:20.637] iteration 14221 : loss : 0.114845, loss_ce: 0.015575
[01:41:20.947] iteration 14222 : loss : 0.046975, loss_ce: 0.019343
[01:41:21.252] iteration 14223 : loss : 0.040219, loss_ce: 0.008051
[01:41:21.567] iteration 14224 : loss : 0.058616, loss_ce: 0.025523
[01:41:21.872] iteration 14225 : loss : 0.047018, loss_ce: 0.023225
[01:41:22.180] iteration 14226 : loss : 0.045279, loss_ce: 0.013665
[01:41:22.489] iteration 14227 : loss : 0.042226, loss_ce: 0.016105
[01:41:22.794] iteration 14228 : loss : 0.043926, loss_ce: 0.012171
[01:41:23.104] iteration 14229 : loss : 0.052797, loss_ce: 0.008937
[01:41:23.414] iteration 14230 : loss : 0.044606, loss_ce: 0.013652
[01:41:23.724] iteration 14231 : loss : 0.049561, loss_ce: 0.010745
[01:41:24.030] iteration 14232 : loss : 0.052637, loss_ce: 0.021631
[01:41:24.334] iteration 14233 : loss : 0.052251, loss_ce: 0.014334
[01:41:24.644] iteration 14234 : loss : 0.083340, loss_ce: 0.020382
[01:41:24.954] iteration 14235 : loss : 0.062681, loss_ce: 0.023209
[01:41:25.262] iteration 14236 : loss : 0.066925, loss_ce: 0.010751
[01:41:25.571] iteration 14237 : loss : 0.236733, loss_ce: 0.008488
[01:41:25.883] iteration 14238 : loss : 0.046064, loss_ce: 0.020391
[01:41:26.196] iteration 14239 : loss : 0.067521, loss_ce: 0.020325
[01:41:26.501] iteration 14240 : loss : 0.055286, loss_ce: 0.009792
[01:41:26.828] iteration 14241 : loss : 0.039972, loss_ce: 0.013096
[01:41:27.135] iteration 14242 : loss : 0.033337, loss_ce: 0.009345
[01:41:27.444] iteration 14243 : loss : 0.083994, loss_ce: 0.009391
[01:41:27.757] iteration 14244 : loss : 0.049112, loss_ce: 0.011107
[01:41:28.065] iteration 14245 : loss : 0.048950, loss_ce: 0.021305
[01:41:28.374] iteration 14246 : loss : 0.056123, loss_ce: 0.014838
[01:41:28.684] iteration 14247 : loss : 0.037857, loss_ce: 0.007969
[01:41:28.995] iteration 14248 : loss : 0.057691, loss_ce: 0.015030
[01:41:29.301] iteration 14249 : loss : 0.105290, loss_ce: 0.010378
[01:41:29.608] iteration 14250 : loss : 0.158995, loss_ce: 0.009392
[01:41:29.913] iteration 14251 : loss : 0.060283, loss_ce: 0.021084
[01:41:30.216] iteration 14252 : loss : 0.104456, loss_ce: 0.011201
[01:41:30.522] iteration 14253 : loss : 0.051697, loss_ce: 0.013278
[01:41:30.828] iteration 14254 : loss : 0.050909, loss_ce: 0.018316
[01:41:31.132] iteration 14255 : loss : 0.053838, loss_ce: 0.021697
[01:41:31.435] iteration 14256 : loss : 0.283822, loss_ce: 0.005743
[01:41:31.743] iteration 14257 : loss : 0.050059, loss_ce: 0.013981
[01:41:32.053] iteration 14258 : loss : 0.064825, loss_ce: 0.029991
[01:41:32.356] iteration 14259 : loss : 0.035431, loss_ce: 0.010438
[01:41:32.661] iteration 14260 : loss : 0.043419, loss_ce: 0.012729
[01:41:32.984] iteration 14261 : loss : 0.097822, loss_ce: 0.004268
[01:41:33.287] iteration 14262 : loss : 0.044210, loss_ce: 0.015318
[01:41:33.590] iteration 14263 : loss : 0.102690, loss_ce: 0.007139
[01:41:33.896] iteration 14264 : loss : 0.049736, loss_ce: 0.022769
[01:41:34.200] iteration 14265 : loss : 0.048403, loss_ce: 0.018280
[01:41:34.505] iteration 14266 : loss : 0.046245, loss_ce: 0.017449
[01:41:34.811] iteration 14267 : loss : 0.078725, loss_ce: 0.015407
[01:41:35.113] iteration 14268 : loss : 0.047062, loss_ce: 0.010754
[01:41:35.417] iteration 14269 : loss : 0.051678, loss_ce: 0.017815
[01:41:35.721] iteration 14270 : loss : 0.068368, loss_ce: 0.020592
[01:41:36.023] iteration 14271 : loss : 0.159513, loss_ce: 0.008870
[01:41:36.328] iteration 14272 : loss : 0.055827, loss_ce: 0.030786
[01:41:36.630] iteration 14273 : loss : 0.113494, loss_ce: 0.004598
[01:41:36.934] iteration 14274 : loss : 0.050108, loss_ce: 0.022002
[01:41:37.240] iteration 14275 : loss : 0.071104, loss_ce: 0.013212
[01:41:37.546] iteration 14276 : loss : 0.055243, loss_ce: 0.014303
[01:41:37.853] iteration 14277 : loss : 0.105819, loss_ce: 0.007487
[01:41:38.155] iteration 14278 : loss : 0.063031, loss_ce: 0.010737
[01:41:38.459] iteration 14279 : loss : 0.050220, loss_ce: 0.017539
[01:41:38.764] iteration 14280 : loss : 0.038648, loss_ce: 0.010017
[01:41:39.082] iteration 14281 : loss : 0.061252, loss_ce: 0.010757
[01:41:39.383] iteration 14282 : loss : 0.114675, loss_ce: 0.017249
[01:41:39.691] iteration 14283 : loss : 0.052416, loss_ce: 0.017201
[01:41:40.002] iteration 14284 : loss : 0.055010, loss_ce: 0.023345
[01:41:40.304] iteration 14285 : loss : 0.052104, loss_ce: 0.014711
[01:41:40.609] iteration 14286 : loss : 0.051199, loss_ce: 0.018111
[01:41:40.918] iteration 14287 : loss : 0.047339, loss_ce: 0.014716
[01:41:41.226] iteration 14288 : loss : 0.091317, loss_ce: 0.015566
[01:41:41.530] iteration 14289 : loss : 0.050828, loss_ce: 0.007073
[01:41:41.835] iteration 14290 : loss : 0.102522, loss_ce: 0.006567
[01:41:42.139] iteration 14291 : loss : 0.061781, loss_ce: 0.017336
[01:41:42.447] iteration 14292 : loss : 0.099360, loss_ce: 0.006960
[01:41:42.754] iteration 14293 : loss : 0.103505, loss_ce: 0.011672
[01:41:43.067] iteration 14294 : loss : 0.064008, loss_ce: 0.014440
[01:41:43.377] iteration 14295 : loss : 0.048501, loss_ce: 0.011716
[01:41:43.687] iteration 14296 : loss : 0.048793, loss_ce: 0.012531
[01:41:44.000] iteration 14297 : loss : 0.050403, loss_ce: 0.009977
[01:41:44.312] iteration 14298 : loss : 0.060627, loss_ce: 0.015620
[01:41:44.619] iteration 14299 : loss : 0.045385, loss_ce: 0.010708
[01:41:44.925] iteration 14300 : loss : 0.052591, loss_ce: 0.023905
[01:41:45.250] iteration 14301 : loss : 0.051571, loss_ce: 0.009918
[01:41:45.556] iteration 14302 : loss : 0.102190, loss_ce: 0.011326
[01:41:45.861] iteration 14303 : loss : 0.100405, loss_ce: 0.010907
[01:41:46.171] iteration 14304 : loss : 0.037230, loss_ce: 0.009701
[01:41:46.481] iteration 14305 : loss : 0.041341, loss_ce: 0.008524
[01:41:46.787] iteration 14306 : loss : 0.058148, loss_ce: 0.013743
[01:41:47.097] iteration 14307 : loss : 0.066939, loss_ce: 0.027665
[01:41:47.409] iteration 14308 : loss : 0.161920, loss_ce: 0.002276
[01:41:47.716] iteration 14309 : loss : 0.053130, loss_ce: 0.020684
[01:41:48.027] iteration 14310 : loss : 0.047634, loss_ce: 0.013603
[01:41:48.334] iteration 14311 : loss : 0.051184, loss_ce: 0.020874
[01:41:48.644] iteration 14312 : loss : 0.073218, loss_ce: 0.012911
[01:41:48.950] iteration 14313 : loss : 0.058876, loss_ce: 0.013976
[01:41:49.263] iteration 14314 : loss : 0.047143, loss_ce: 0.016820
[01:41:49.570] iteration 14315 : loss : 0.055135, loss_ce: 0.017571
[01:41:49.879] iteration 14316 : loss : 0.106382, loss_ce: 0.011415
[01:41:49.959] iteration 14317 : loss : 0.275547, loss_ce: 0.000032
[01:42:09.479] iteration 14318 : loss : 0.165499, loss_ce: 0.008348
[01:42:09.778] iteration 14319 : loss : 0.118906, loss_ce: 0.005176
[01:42:10.079] iteration 14320 : loss : 0.055776, loss_ce: 0.020253
[01:42:10.395] iteration 14321 : loss : 0.091419, loss_ce: 0.023495
[01:42:10.697] iteration 14322 : loss : 0.119535, loss_ce: 0.015218
[01:42:11.001] iteration 14323 : loss : 0.085541, loss_ce: 0.013694
[01:42:11.300] iteration 14324 : loss : 0.091350, loss_ce: 0.015715
[01:42:11.600] iteration 14325 : loss : 0.069983, loss_ce: 0.034690
[01:42:11.904] iteration 14326 : loss : 0.044030, loss_ce: 0.022062
[01:42:12.206] iteration 14327 : loss : 0.058653, loss_ce: 0.004354
[01:42:12.515] iteration 14328 : loss : 0.046943, loss_ce: 0.032260
[01:42:12.820] iteration 14329 : loss : 0.286740, loss_ce: 0.011003
[01:42:13.128] iteration 14330 : loss : 0.067314, loss_ce: 0.016450
[01:42:13.439] iteration 14331 : loss : 0.068406, loss_ce: 0.016263
[01:42:13.747] iteration 14332 : loss : 0.067385, loss_ce: 0.016515
[01:42:14.056] iteration 14333 : loss : 0.059870, loss_ce: 0.016253
[01:42:14.363] iteration 14334 : loss : 0.069225, loss_ce: 0.020880
[01:42:14.667] iteration 14335 : loss : 0.057767, loss_ce: 0.037534
[01:42:14.967] iteration 14336 : loss : 0.121297, loss_ce: 0.018583
[01:42:15.270] iteration 14337 : loss : 0.063760, loss_ce: 0.024314
[01:42:15.572] iteration 14338 : loss : 0.063546, loss_ce: 0.024073
[01:42:15.872] iteration 14339 : loss : 0.068103, loss_ce: 0.017648
[01:42:16.175] iteration 14340 : loss : 0.109005, loss_ce: 0.007142
[01:42:16.496] iteration 14341 : loss : 0.068930, loss_ce: 0.015218
[01:42:16.796] iteration 14342 : loss : 0.116671, loss_ce: 0.011785
[01:42:17.098] iteration 14343 : loss : 0.057736, loss_ce: 0.021231
[01:42:17.402] iteration 14344 : loss : 0.222653, loss_ce: 0.010501
[01:42:17.706] iteration 14345 : loss : 0.104249, loss_ce: 0.011934
[01:42:18.009] iteration 14346 : loss : 0.052494, loss_ce: 0.024706
[01:42:18.314] iteration 14347 : loss : 0.114439, loss_ce: 0.012120
[01:42:18.617] iteration 14348 : loss : 0.054275, loss_ce: 0.016953
[01:42:18.921] iteration 14349 : loss : 0.110891, loss_ce: 0.011136
[01:42:19.230] iteration 14350 : loss : 0.053966, loss_ce: 0.015114
[01:42:19.532] iteration 14351 : loss : 0.046341, loss_ce: 0.012879
[01:42:19.836] iteration 14352 : loss : 0.061066, loss_ce: 0.026178
[01:42:20.138] iteration 14353 : loss : 0.042360, loss_ce: 0.014466
[01:42:20.439] iteration 14354 : loss : 0.100693, loss_ce: 0.009693
[01:42:20.744] iteration 14355 : loss : 0.050842, loss_ce: 0.019334
[01:42:21.048] iteration 14356 : loss : 0.063809, loss_ce: 0.014900
[01:42:21.350] iteration 14357 : loss : 0.052332, loss_ce: 0.022669
[01:42:21.653] iteration 14358 : loss : 0.163007, loss_ce: 0.010047
[01:42:21.959] iteration 14359 : loss : 0.073574, loss_ce: 0.013551
[01:42:22.263] iteration 14360 : loss : 0.047277, loss_ce: 0.016532
[01:42:22.584] iteration 14361 : loss : 0.123461, loss_ce: 0.007918
[01:42:22.885] iteration 14362 : loss : 0.074428, loss_ce: 0.016915
[01:42:23.191] iteration 14363 : loss : 0.056476, loss_ce: 0.014167
[01:42:23.497] iteration 14364 : loss : 0.158635, loss_ce: 0.006276
[01:42:23.798] iteration 14365 : loss : 0.055180, loss_ce: 0.019849
[01:42:24.104] iteration 14366 : loss : 0.053300, loss_ce: 0.018938
[01:42:24.408] iteration 14367 : loss : 0.106717, loss_ce: 0.010043
[01:42:24.712] iteration 14368 : loss : 0.115647, loss_ce: 0.008093
[01:42:25.018] iteration 14369 : loss : 0.060918, loss_ce: 0.028777
[01:42:25.320] iteration 14370 : loss : 0.112723, loss_ce: 0.012026
[01:42:25.623] iteration 14371 : loss : 0.054990, loss_ce: 0.021008
[01:42:25.929] iteration 14372 : loss : 0.114523, loss_ce: 0.007326
[01:42:26.233] iteration 14373 : loss : 0.105397, loss_ce: 0.014515
[01:42:26.538] iteration 14374 : loss : 0.043576, loss_ce: 0.015612
[01:42:26.844] iteration 14375 : loss : 0.047682, loss_ce: 0.021437
[01:42:27.146] iteration 14376 : loss : 0.043229, loss_ce: 0.017379
[01:42:27.456] iteration 14377 : loss : 0.060576, loss_ce: 0.019705
[01:42:27.762] iteration 14378 : loss : 0.046849, loss_ce: 0.016904
[01:42:28.069] iteration 14379 : loss : 0.048650, loss_ce: 0.016325
[01:42:28.378] iteration 14380 : loss : 0.051498, loss_ce: 0.014971
[01:42:28.708] iteration 14381 : loss : 0.040136, loss_ce: 0.003587
[01:42:29.013] iteration 14382 : loss : 0.050929, loss_ce: 0.015425
[01:42:29.324] iteration 14383 : loss : 0.052292, loss_ce: 0.015209
[01:42:29.630] iteration 14384 : loss : 0.044794, loss_ce: 0.016608
[01:42:29.936] iteration 14385 : loss : 0.045476, loss_ce: 0.014349
[01:42:30.241] iteration 14386 : loss : 0.043150, loss_ce: 0.010494
[01:42:30.553] iteration 14387 : loss : 0.048601, loss_ce: 0.025407
[01:42:30.862] iteration 14388 : loss : 0.095856, loss_ce: 0.005909
[01:42:31.171] iteration 14389 : loss : 0.048449, loss_ce: 0.017918
[01:42:31.478] iteration 14390 : loss : 0.050500, loss_ce: 0.013492
[01:42:31.787] iteration 14391 : loss : 0.051190, loss_ce: 0.025566
[01:42:32.092] iteration 14392 : loss : 0.060224, loss_ce: 0.028103
[01:42:32.401] iteration 14393 : loss : 0.044266, loss_ce: 0.019001
[01:42:32.710] iteration 14394 : loss : 0.052930, loss_ce: 0.012227
[01:42:33.015] iteration 14395 : loss : 0.047211, loss_ce: 0.019811
[01:42:33.323] iteration 14396 : loss : 0.046632, loss_ce: 0.014857
[01:42:33.631] iteration 14397 : loss : 0.047182, loss_ce: 0.009808
[01:42:33.936] iteration 14398 : loss : 0.046225, loss_ce: 0.021043
[01:42:34.247] iteration 14399 : loss : 0.284064, loss_ce: 0.007487
[01:42:34.554] iteration 14400 : loss : 0.044335, loss_ce: 0.020545
[01:42:34.883] iteration 14401 : loss : 0.059873, loss_ce: 0.022423
[01:42:35.191] iteration 14402 : loss : 0.047502, loss_ce: 0.009491
[01:42:35.500] iteration 14403 : loss : 0.048156, loss_ce: 0.015932
[01:42:35.813] iteration 14404 : loss : 0.040667, loss_ce: 0.010429
[01:42:36.118] iteration 14405 : loss : 0.121732, loss_ce: 0.010025
[01:42:36.427] iteration 14406 : loss : 0.106703, loss_ce: 0.005506
[01:42:36.734] iteration 14407 : loss : 0.048884, loss_ce: 0.016379
[01:42:37.040] iteration 14408 : loss : 0.110962, loss_ce: 0.005538
[01:42:37.351] iteration 14409 : loss : 0.110797, loss_ce: 0.015982
[01:42:37.658] iteration 14410 : loss : 0.044855, loss_ce: 0.005585
[01:42:37.964] iteration 14411 : loss : 0.052937, loss_ce: 0.025197
[01:42:38.271] iteration 14412 : loss : 0.053337, loss_ce: 0.023573
[01:42:38.578] iteration 14413 : loss : 0.101370, loss_ce: 0.011162
[01:42:38.886] iteration 14414 : loss : 0.041920, loss_ce: 0.019409
[01:42:39.194] iteration 14415 : loss : 0.045190, loss_ce: 0.015272
[01:42:39.500] iteration 14416 : loss : 0.107843, loss_ce: 0.023955
[01:42:39.813] iteration 14417 : loss : 0.107149, loss_ce: 0.017389
[01:42:40.119] iteration 14418 : loss : 0.054666, loss_ce: 0.014485
[01:42:40.427] iteration 14419 : loss : 0.064103, loss_ce: 0.011864
[01:42:40.739] iteration 14420 : loss : 0.047580, loss_ce: 0.020752
[01:42:41.063] iteration 14421 : loss : 0.059389, loss_ce: 0.023180
[01:42:41.366] iteration 14422 : loss : 0.112544, loss_ce: 0.011210
[01:42:41.681] iteration 14423 : loss : 0.048732, loss_ce: 0.013761
[01:42:41.991] iteration 14424 : loss : 0.173297, loss_ce: 0.011320
[01:42:42.299] iteration 14425 : loss : 0.051081, loss_ce: 0.007514
[01:42:42.607] iteration 14426 : loss : 0.096498, loss_ce: 0.010098
[01:42:42.914] iteration 14427 : loss : 0.053583, loss_ce: 0.004670
[01:42:43.220] iteration 14428 : loss : 0.107618, loss_ce: 0.011005
[01:42:43.526] iteration 14429 : loss : 0.054583, loss_ce: 0.009978
[01:42:43.838] iteration 14430 : loss : 0.108423, loss_ce: 0.006592
[01:42:44.142] iteration 14431 : loss : 0.076113, loss_ce: 0.018546
[01:42:44.447] iteration 14432 : loss : 0.054449, loss_ce: 0.016417
[01:42:44.755] iteration 14433 : loss : 0.049026, loss_ce: 0.013106
[01:42:45.063] iteration 14434 : loss : 0.041143, loss_ce: 0.010845
[01:42:45.375] iteration 14435 : loss : 0.054022, loss_ce: 0.023220
[01:42:45.682] iteration 14436 : loss : 0.032496, loss_ce: 0.008342
[01:42:45.993] iteration 14437 : loss : 0.161289, loss_ce: 0.009703
[01:42:46.300] iteration 14438 : loss : 0.043921, loss_ce: 0.013712
[01:42:46.607] iteration 14439 : loss : 0.052213, loss_ce: 0.017658
[01:42:46.920] iteration 14440 : loss : 0.034074, loss_ce: 0.006652
[01:42:47.247] iteration 14441 : loss : 0.086572, loss_ce: 0.009829
[01:42:47.560] iteration 14442 : loss : 0.050148, loss_ce: 0.015848
[01:42:47.875] iteration 14443 : loss : 0.051269, loss_ce: 0.023518
[01:42:48.189] iteration 14444 : loss : 0.058099, loss_ce: 0.022478
[01:42:48.503] iteration 14445 : loss : 0.051764, loss_ce: 0.018991
[01:42:48.816] iteration 14446 : loss : 0.049607, loss_ce: 0.021910
[01:42:49.128] iteration 14447 : loss : 0.155890, loss_ce: 0.013026
[01:42:49.442] iteration 14448 : loss : 0.285623, loss_ce: 0.009666
[01:42:49.749] iteration 14449 : loss : 0.062332, loss_ce: 0.011197
[01:42:50.054] iteration 14450 : loss : 0.048394, loss_ce: 0.020011
[01:42:50.367] iteration 14451 : loss : 0.056374, loss_ce: 0.018108
[01:42:50.678] iteration 14452 : loss : 0.064509, loss_ce: 0.011434
[01:42:50.985] iteration 14453 : loss : 0.049466, loss_ce: 0.016718
[01:42:51.292] iteration 14454 : loss : 0.046456, loss_ce: 0.008658
[01:42:51.605] iteration 14455 : loss : 0.047058, loss_ce: 0.016418
[01:42:51.697] iteration 14456 : loss : 0.117117, loss_ce: 0.015619
[01:43:09.421] iteration 14457 : loss : 0.052089, loss_ce: 0.011168
[01:43:09.721] iteration 14458 : loss : 0.038156, loss_ce: 0.010643
[01:43:10.026] iteration 14459 : loss : 0.043964, loss_ce: 0.015620
[01:43:10.327] iteration 14460 : loss : 0.051688, loss_ce: 0.009648
[01:43:10.646] iteration 14461 : loss : 0.047666, loss_ce: 0.018836
[01:43:10.947] iteration 14462 : loss : 0.042395, loss_ce: 0.009543
[01:43:11.248] iteration 14463 : loss : 0.046235, loss_ce: 0.017251
[01:43:11.550] iteration 14464 : loss : 0.050236, loss_ce: 0.019919
[01:43:11.854] iteration 14465 : loss : 0.102848, loss_ce: 0.014056
[01:43:12.156] iteration 14466 : loss : 0.160910, loss_ce: 0.003715
[01:43:12.462] iteration 14467 : loss : 0.058531, loss_ce: 0.021853
[01:43:12.766] iteration 14468 : loss : 0.048869, loss_ce: 0.021909
[01:43:13.070] iteration 14469 : loss : 0.040544, loss_ce: 0.014398
[01:43:13.374] iteration 14470 : loss : 0.058034, loss_ce: 0.011853
[01:43:13.678] iteration 14471 : loss : 0.040063, loss_ce: 0.016405
[01:43:13.982] iteration 14472 : loss : 0.048187, loss_ce: 0.017588
[01:43:14.289] iteration 14473 : loss : 0.058865, loss_ce: 0.014964
[01:43:14.591] iteration 14474 : loss : 0.161476, loss_ce: 0.009154
[01:43:14.895] iteration 14475 : loss : 0.056724, loss_ce: 0.019836
[01:43:15.202] iteration 14476 : loss : 0.070201, loss_ce: 0.012715
[01:43:15.508] iteration 14477 : loss : 0.100985, loss_ce: 0.011699
[01:43:15.809] iteration 14478 : loss : 0.048459, loss_ce: 0.010065
[01:43:16.115] iteration 14479 : loss : 0.050956, loss_ce: 0.010078
[01:43:16.418] iteration 14480 : loss : 0.046158, loss_ce: 0.019782
[01:43:16.739] iteration 14481 : loss : 0.038814, loss_ce: 0.017180
[01:43:17.043] iteration 14482 : loss : 0.041223, loss_ce: 0.013950
[01:43:17.346] iteration 14483 : loss : 0.039185, loss_ce: 0.016746
[01:43:17.653] iteration 14484 : loss : 0.055143, loss_ce: 0.023381
[01:43:17.959] iteration 14485 : loss : 0.054418, loss_ce: 0.013852
[01:43:18.268] iteration 14486 : loss : 0.111078, loss_ce: 0.011850
[01:43:18.576] iteration 14487 : loss : 0.098862, loss_ce: 0.008772
[01:43:18.879] iteration 14488 : loss : 0.177809, loss_ce: 0.005801
[01:43:19.184] iteration 14489 : loss : 0.056862, loss_ce: 0.022791
[01:43:19.493] iteration 14490 : loss : 0.054226, loss_ce: 0.016247
[01:43:19.799] iteration 14491 : loss : 0.040087, loss_ce: 0.006960
[01:43:20.111] iteration 14492 : loss : 0.044151, loss_ce: 0.014256
[01:43:20.417] iteration 14493 : loss : 0.044007, loss_ce: 0.009874
[01:43:20.725] iteration 14494 : loss : 0.053060, loss_ce: 0.011443
[01:43:21.037] iteration 14495 : loss : 0.040527, loss_ce: 0.015721
[01:43:21.340] iteration 14496 : loss : 0.060388, loss_ce: 0.014522
[01:43:21.649] iteration 14497 : loss : 0.110318, loss_ce: 0.011934
[01:43:21.960] iteration 14498 : loss : 0.099974, loss_ce: 0.013208
[01:43:22.267] iteration 14499 : loss : 0.049485, loss_ce: 0.008912
[01:43:22.575] iteration 14500 : loss : 0.056088, loss_ce: 0.022441
[01:43:22.894] iteration 14501 : loss : 0.046143, loss_ce: 0.021503
[01:43:23.200] iteration 14502 : loss : 0.048317, loss_ce: 0.011805
[01:43:23.507] iteration 14503 : loss : 0.047331, loss_ce: 0.013345
[01:43:23.814] iteration 14504 : loss : 0.042703, loss_ce: 0.015080
[01:43:24.125] iteration 14505 : loss : 0.106955, loss_ce: 0.013874
[01:43:24.430] iteration 14506 : loss : 0.040439, loss_ce: 0.012585
[01:43:24.745] iteration 14507 : loss : 0.134494, loss_ce: 0.011494
[01:43:25.055] iteration 14508 : loss : 0.044631, loss_ce: 0.012664
[01:43:25.361] iteration 14509 : loss : 0.100344, loss_ce: 0.013619
[01:43:25.669] iteration 14510 : loss : 0.051451, loss_ce: 0.019748
[01:43:25.978] iteration 14511 : loss : 0.108060, loss_ce: 0.012484
[01:43:26.287] iteration 14512 : loss : 0.042023, loss_ce: 0.020086
[01:43:26.596] iteration 14513 : loss : 0.050355, loss_ce: 0.021307
[01:43:26.901] iteration 14514 : loss : 0.118533, loss_ce: 0.008966
[01:43:27.216] iteration 14515 : loss : 0.109123, loss_ce: 0.011279
[01:43:27.524] iteration 14516 : loss : 0.055631, loss_ce: 0.018288
[01:43:27.833] iteration 14517 : loss : 0.039599, loss_ce: 0.009150
[01:43:28.136] iteration 14518 : loss : 0.055156, loss_ce: 0.005650
[01:43:28.445] iteration 14519 : loss : 0.062171, loss_ce: 0.005455
[01:43:28.751] iteration 14520 : loss : 0.050918, loss_ce: 0.010115
[01:43:29.071] iteration 14521 : loss : 0.046763, loss_ce: 0.016806
[01:43:29.381] iteration 14522 : loss : 0.054300, loss_ce: 0.013518
[01:43:29.697] iteration 14523 : loss : 0.045167, loss_ce: 0.018894
[01:43:30.004] iteration 14524 : loss : 0.043917, loss_ce: 0.014185
[01:43:30.315] iteration 14525 : loss : 0.058549, loss_ce: 0.020630
[01:43:30.621] iteration 14526 : loss : 0.078007, loss_ce: 0.012886
[01:43:30.927] iteration 14527 : loss : 0.046617, loss_ce: 0.020538
[01:43:31.235] iteration 14528 : loss : 0.037016, loss_ce: 0.008128
[01:43:31.541] iteration 14529 : loss : 0.052548, loss_ce: 0.011241
[01:43:31.845] iteration 14530 : loss : 0.046499, loss_ce: 0.015808
[01:43:32.154] iteration 14531 : loss : 0.044286, loss_ce: 0.015289
[01:43:32.462] iteration 14532 : loss : 0.040282, loss_ce: 0.009705
[01:43:32.768] iteration 14533 : loss : 0.154643, loss_ce: 0.002888
[01:43:33.075] iteration 14534 : loss : 0.049251, loss_ce: 0.018018
[01:43:33.383] iteration 14535 : loss : 0.050441, loss_ce: 0.017587
[01:43:33.690] iteration 14536 : loss : 0.047489, loss_ce: 0.014285
[01:43:33.995] iteration 14537 : loss : 0.051453, loss_ce: 0.017815
[01:43:34.306] iteration 14538 : loss : 0.089041, loss_ce: 0.021069
[01:43:34.615] iteration 14539 : loss : 0.046435, loss_ce: 0.012231
[01:43:34.924] iteration 14540 : loss : 0.037416, loss_ce: 0.014482
[01:43:35.252] iteration 14541 : loss : 0.168883, loss_ce: 0.011504
[01:43:35.559] iteration 14542 : loss : 0.046278, loss_ce: 0.015195
[01:43:35.870] iteration 14543 : loss : 0.045874, loss_ce: 0.018692
[01:43:36.180] iteration 14544 : loss : 0.045002, loss_ce: 0.018378
[01:43:36.487] iteration 14545 : loss : 0.101488, loss_ce: 0.010109
[01:43:36.796] iteration 14546 : loss : 0.108130, loss_ce: 0.005907
[01:43:37.103] iteration 14547 : loss : 0.042794, loss_ce: 0.021648
[01:43:37.411] iteration 14548 : loss : 0.044552, loss_ce: 0.010502
[01:43:37.717] iteration 14549 : loss : 0.070411, loss_ce: 0.017925
[01:43:38.023] iteration 14550 : loss : 0.046243, loss_ce: 0.010082
[01:43:38.330] iteration 14551 : loss : 0.111738, loss_ce: 0.013232
[01:43:38.644] iteration 14552 : loss : 0.047381, loss_ce: 0.009681
[01:43:38.952] iteration 14553 : loss : 0.048427, loss_ce: 0.012926
[01:43:39.259] iteration 14554 : loss : 0.169927, loss_ce: 0.005475
[01:43:39.564] iteration 14555 : loss : 0.049498, loss_ce: 0.021664
[01:43:39.870] iteration 14556 : loss : 0.038862, loss_ce: 0.010779
[01:43:40.172] iteration 14557 : loss : 0.064687, loss_ce: 0.029311
[01:43:40.476] iteration 14558 : loss : 0.101338, loss_ce: 0.011290
[01:43:40.782] iteration 14559 : loss : 0.048898, loss_ce: 0.011048
[01:43:41.085] iteration 14560 : loss : 0.040515, loss_ce: 0.016384
[01:43:41.404] iteration 14561 : loss : 0.077208, loss_ce: 0.016828
[01:43:41.707] iteration 14562 : loss : 0.038308, loss_ce: 0.013319
[01:43:42.012] iteration 14563 : loss : 0.103446, loss_ce: 0.010127
[01:43:42.315] iteration 14564 : loss : 0.059363, loss_ce: 0.010391
[01:43:42.618] iteration 14565 : loss : 0.056489, loss_ce: 0.016656
[01:43:42.921] iteration 14566 : loss : 0.043484, loss_ce: 0.014956
[01:43:43.226] iteration 14567 : loss : 0.089814, loss_ce: 0.017409
[01:43:43.529] iteration 14568 : loss : 0.115090, loss_ce: 0.014374
[01:43:43.830] iteration 14569 : loss : 0.115304, loss_ce: 0.008272
[01:43:44.136] iteration 14570 : loss : 0.047722, loss_ce: 0.017803
[01:43:44.444] iteration 14571 : loss : 0.051211, loss_ce: 0.013185
[01:43:44.749] iteration 14572 : loss : 0.045844, loss_ce: 0.023758
[01:43:45.054] iteration 14573 : loss : 0.158749, loss_ce: 0.007697
[01:43:45.360] iteration 14574 : loss : 0.051345, loss_ce: 0.013108
[01:43:45.662] iteration 14575 : loss : 0.119075, loss_ce: 0.009243
[01:43:45.966] iteration 14576 : loss : 0.062600, loss_ce: 0.014846
[01:43:46.273] iteration 14577 : loss : 0.049680, loss_ce: 0.011654
[01:43:46.576] iteration 14578 : loss : 0.058098, loss_ce: 0.007732
[01:43:46.882] iteration 14579 : loss : 0.041462, loss_ce: 0.010796
[01:43:47.191] iteration 14580 : loss : 0.057787, loss_ce: 0.013804
[01:43:47.516] iteration 14581 : loss : 0.075389, loss_ce: 0.015354
[01:43:47.823] iteration 14582 : loss : 0.048243, loss_ce: 0.016046
[01:43:48.127] iteration 14583 : loss : 0.045815, loss_ce: 0.023292
[01:43:48.433] iteration 14584 : loss : 0.109555, loss_ce: 0.009824
[01:43:48.739] iteration 14585 : loss : 0.104602, loss_ce: 0.011553
[01:43:49.043] iteration 14586 : loss : 0.037514, loss_ce: 0.009571
[01:43:49.354] iteration 14587 : loss : 0.100359, loss_ce: 0.009589
[01:43:49.658] iteration 14588 : loss : 0.054312, loss_ce: 0.020038
[01:43:49.965] iteration 14589 : loss : 0.054496, loss_ce: 0.022502
[01:43:50.270] iteration 14590 : loss : 0.047690, loss_ce: 0.017622
[01:43:50.586] iteration 14591 : loss : 0.050492, loss_ce: 0.014986
[01:43:50.891] iteration 14592 : loss : 0.057758, loss_ce: 0.022687
[01:43:51.196] iteration 14593 : loss : 0.047242, loss_ce: 0.021980
[01:43:51.507] iteration 14594 : loss : 0.052020, loss_ce: 0.012225
[01:43:51.586] iteration 14595 : loss : 0.285488, loss_ce: 0.009117
[01:44:09.442] iteration 14596 : loss : 0.052398, loss_ce: 0.008403
[01:44:09.743] iteration 14597 : loss : 0.055714, loss_ce: 0.015063
[01:44:10.048] iteration 14598 : loss : 0.062177, loss_ce: 0.015822
[01:44:10.349] iteration 14599 : loss : 0.218199, loss_ce: 0.005249
[01:44:10.650] iteration 14600 : loss : 0.056758, loss_ce: 0.012834
[01:44:10.967] iteration 14601 : loss : 0.093809, loss_ce: 0.006980
[01:44:11.268] iteration 14602 : loss : 0.108255, loss_ce: 0.012341
[01:44:11.572] iteration 14603 : loss : 0.035575, loss_ce: 0.013982
[01:44:11.873] iteration 14604 : loss : 0.221936, loss_ce: 0.010941
[01:44:12.176] iteration 14605 : loss : 0.055757, loss_ce: 0.011857
[01:44:12.477] iteration 14606 : loss : 0.046789, loss_ce: 0.014745
[01:44:12.781] iteration 14607 : loss : 0.045732, loss_ce: 0.015559
[01:44:13.084] iteration 14608 : loss : 0.103306, loss_ce: 0.018860
[01:44:13.387] iteration 14609 : loss : 0.043064, loss_ce: 0.010916
[01:44:13.690] iteration 14610 : loss : 0.046368, loss_ce: 0.014804
[01:44:13.994] iteration 14611 : loss : 0.118816, loss_ce: 0.014617
[01:44:14.295] iteration 14612 : loss : 0.045632, loss_ce: 0.013372
[01:44:14.597] iteration 14613 : loss : 0.049337, loss_ce: 0.010403
[01:44:14.901] iteration 14614 : loss : 0.051704, loss_ce: 0.023960
[01:44:15.198] iteration 14615 : loss : 0.115892, loss_ce: 0.011107
[01:44:15.499] iteration 14616 : loss : 0.046699, loss_ce: 0.011193
[01:44:15.800] iteration 14617 : loss : 0.212074, loss_ce: 0.006371
[01:44:16.104] iteration 14618 : loss : 0.047042, loss_ce: 0.014195
[01:44:16.406] iteration 14619 : loss : 0.048991, loss_ce: 0.011275
[01:44:16.706] iteration 14620 : loss : 0.050114, loss_ce: 0.016337
[01:44:17.024] iteration 14621 : loss : 0.049345, loss_ce: 0.010861
[01:44:17.328] iteration 14622 : loss : 0.101689, loss_ce: 0.005758
[01:44:17.630] iteration 14623 : loss : 0.040338, loss_ce: 0.014663
[01:44:17.932] iteration 14624 : loss : 0.053349, loss_ce: 0.010013
[01:44:18.236] iteration 14625 : loss : 0.048318, loss_ce: 0.016221
[01:44:18.539] iteration 14626 : loss : 0.050778, loss_ce: 0.014599
[01:44:18.844] iteration 14627 : loss : 0.056435, loss_ce: 0.008454
[01:44:19.147] iteration 14628 : loss : 0.045587, loss_ce: 0.015985
[01:44:19.447] iteration 14629 : loss : 0.047055, loss_ce: 0.012636
[01:44:19.751] iteration 14630 : loss : 0.052963, loss_ce: 0.013044
[01:44:20.055] iteration 14631 : loss : 0.105749, loss_ce: 0.002790
[01:44:20.355] iteration 14632 : loss : 0.048875, loss_ce: 0.014691
[01:44:20.660] iteration 14633 : loss : 0.049084, loss_ce: 0.012446
[01:44:20.967] iteration 14634 : loss : 0.048075, loss_ce: 0.007378
[01:44:21.269] iteration 14635 : loss : 0.050713, loss_ce: 0.010285
[01:44:21.573] iteration 14636 : loss : 0.180368, loss_ce: 0.007550
[01:44:21.873] iteration 14637 : loss : 0.049811, loss_ce: 0.020512
[01:44:22.177] iteration 14638 : loss : 0.041911, loss_ce: 0.010104
[01:44:22.484] iteration 14639 : loss : 0.113690, loss_ce: 0.007525
[01:44:22.793] iteration 14640 : loss : 0.042500, loss_ce: 0.012003
[01:44:23.114] iteration 14641 : loss : 0.158414, loss_ce: 0.008175
[01:44:23.423] iteration 14642 : loss : 0.044457, loss_ce: 0.012367
[01:44:23.734] iteration 14643 : loss : 0.038592, loss_ce: 0.011212
[01:44:24.049] iteration 14644 : loss : 0.040990, loss_ce: 0.009659
[01:44:24.354] iteration 14645 : loss : 0.169139, loss_ce: 0.005670
[01:44:24.658] iteration 14646 : loss : 0.067074, loss_ce: 0.016987
[01:44:24.960] iteration 14647 : loss : 0.041067, loss_ce: 0.007067
[01:44:25.270] iteration 14648 : loss : 0.054176, loss_ce: 0.016892
[01:44:25.571] iteration 14649 : loss : 0.055146, loss_ce: 0.016989
[01:44:25.872] iteration 14650 : loss : 0.044479, loss_ce: 0.016565
[01:44:26.179] iteration 14651 : loss : 0.120327, loss_ce: 0.017619
[01:44:26.485] iteration 14652 : loss : 0.042935, loss_ce: 0.013822
[01:44:26.785] iteration 14653 : loss : 0.041397, loss_ce: 0.014311
[01:44:27.090] iteration 14654 : loss : 0.055392, loss_ce: 0.024796
[01:44:27.398] iteration 14655 : loss : 0.042215, loss_ce: 0.019245
[01:44:27.702] iteration 14656 : loss : 0.049116, loss_ce: 0.011839
[01:44:28.005] iteration 14657 : loss : 0.050371, loss_ce: 0.019070
[01:44:28.308] iteration 14658 : loss : 0.074686, loss_ce: 0.015234
[01:44:28.614] iteration 14659 : loss : 0.040315, loss_ce: 0.010699
[01:44:28.918] iteration 14660 : loss : 0.044326, loss_ce: 0.013697
[01:44:29.231] iteration 14661 : loss : 0.171362, loss_ce: 0.006896
[01:44:29.535] iteration 14662 : loss : 0.063141, loss_ce: 0.017707
[01:44:29.840] iteration 14663 : loss : 0.055731, loss_ce: 0.012958
[01:44:30.144] iteration 14664 : loss : 0.044412, loss_ce: 0.017048
[01:44:30.448] iteration 14665 : loss : 0.103556, loss_ce: 0.009263
[01:44:30.754] iteration 14666 : loss : 0.051022, loss_ce: 0.013070
[01:44:31.058] iteration 14667 : loss : 0.098417, loss_ce: 0.007012
[01:44:31.364] iteration 14668 : loss : 0.052806, loss_ce: 0.021944
[01:44:31.667] iteration 14669 : loss : 0.048035, loss_ce: 0.019625
[01:44:31.971] iteration 14670 : loss : 0.061681, loss_ce: 0.023415
[01:44:32.275] iteration 14671 : loss : 0.041408, loss_ce: 0.013237
[01:44:32.585] iteration 14672 : loss : 0.059255, loss_ce: 0.009968
[01:44:32.891] iteration 14673 : loss : 0.108308, loss_ce: 0.013323
[01:44:33.196] iteration 14674 : loss : 0.178007, loss_ce: 0.004649
[01:44:33.499] iteration 14675 : loss : 0.048051, loss_ce: 0.014833
[01:44:33.807] iteration 14676 : loss : 0.070115, loss_ce: 0.011937
[01:44:34.110] iteration 14677 : loss : 0.104429, loss_ce: 0.008481
[01:44:34.410] iteration 14678 : loss : 0.059961, loss_ce: 0.017088
[01:44:34.713] iteration 14679 : loss : 0.056325, loss_ce: 0.029756
[01:44:35.014] iteration 14680 : loss : 0.060823, loss_ce: 0.016696
[01:44:35.335] iteration 14681 : loss : 0.052978, loss_ce: 0.017716
[01:44:35.640] iteration 14682 : loss : 0.050048, loss_ce: 0.024417
[01:44:35.944] iteration 14683 : loss : 0.051927, loss_ce: 0.015012
[01:44:36.250] iteration 14684 : loss : 0.042073, loss_ce: 0.016885
[01:44:36.553] iteration 14685 : loss : 0.064948, loss_ce: 0.011369
[01:44:36.856] iteration 14686 : loss : 0.049606, loss_ce: 0.018045
[01:44:37.159] iteration 14687 : loss : 0.048914, loss_ce: 0.008801
[01:44:37.468] iteration 14688 : loss : 0.048071, loss_ce: 0.017379
[01:44:37.771] iteration 14689 : loss : 0.049186, loss_ce: 0.019442
[01:44:38.076] iteration 14690 : loss : 0.057725, loss_ce: 0.019891
[01:44:38.383] iteration 14691 : loss : 0.056099, loss_ce: 0.023360
[01:44:38.691] iteration 14692 : loss : 0.058624, loss_ce: 0.017407
[01:44:38.998] iteration 14693 : loss : 0.105240, loss_ce: 0.015386
[01:44:39.304] iteration 14694 : loss : 0.072462, loss_ce: 0.018848
[01:44:39.613] iteration 14695 : loss : 0.038563, loss_ce: 0.014938
[01:44:39.920] iteration 14696 : loss : 0.065183, loss_ce: 0.009820
[01:44:40.227] iteration 14697 : loss : 0.044742, loss_ce: 0.021079
[01:44:40.531] iteration 14698 : loss : 0.041348, loss_ce: 0.017767
[01:44:40.845] iteration 14699 : loss : 0.060531, loss_ce: 0.016019
[01:44:41.156] iteration 14700 : loss : 0.057422, loss_ce: 0.013567
[01:44:41.476] iteration 14701 : loss : 0.038786, loss_ce: 0.013995
[01:44:41.783] iteration 14702 : loss : 0.049157, loss_ce: 0.015700
[01:44:42.092] iteration 14703 : loss : 0.044230, loss_ce: 0.013877
[01:44:42.402] iteration 14704 : loss : 0.055327, loss_ce: 0.015297
[01:44:42.711] iteration 14705 : loss : 0.052992, loss_ce: 0.016790
[01:44:43.014] iteration 14706 : loss : 0.103133, loss_ce: 0.016035
[01:44:43.325] iteration 14707 : loss : 0.041616, loss_ce: 0.014115
[01:44:43.631] iteration 14708 : loss : 0.052386, loss_ce: 0.026271
[01:44:43.938] iteration 14709 : loss : 0.051997, loss_ce: 0.025498
[01:44:44.249] iteration 14710 : loss : 0.054952, loss_ce: 0.012672
[01:44:44.553] iteration 14711 : loss : 0.063108, loss_ce: 0.010850
[01:44:44.861] iteration 14712 : loss : 0.059757, loss_ce: 0.018470
[01:44:45.170] iteration 14713 : loss : 0.046001, loss_ce: 0.010599
[01:44:45.475] iteration 14714 : loss : 0.043747, loss_ce: 0.016596
[01:44:45.784] iteration 14715 : loss : 0.055605, loss_ce: 0.009941
[01:44:46.089] iteration 14716 : loss : 0.068998, loss_ce: 0.018829
[01:44:46.397] iteration 14717 : loss : 0.058710, loss_ce: 0.020948
[01:44:46.710] iteration 14718 : loss : 0.041336, loss_ce: 0.016575
[01:44:47.027] iteration 14719 : loss : 0.050814, loss_ce: 0.011279
[01:44:47.338] iteration 14720 : loss : 0.048274, loss_ce: 0.012132
[01:44:47.662] iteration 14721 : loss : 0.039386, loss_ce: 0.015193
[01:44:47.973] iteration 14722 : loss : 0.057026, loss_ce: 0.011798
[01:44:48.288] iteration 14723 : loss : 0.057821, loss_ce: 0.021639
[01:44:48.600] iteration 14724 : loss : 0.042405, loss_ce: 0.018274
[01:44:48.907] iteration 14725 : loss : 0.040451, loss_ce: 0.013328
[01:44:49.221] iteration 14726 : loss : 0.046831, loss_ce: 0.013386
[01:44:49.540] iteration 14727 : loss : 0.068399, loss_ce: 0.012290
[01:44:49.847] iteration 14728 : loss : 0.155761, loss_ce: 0.006486
[01:44:50.157] iteration 14729 : loss : 0.065587, loss_ce: 0.013024
[01:44:50.472] iteration 14730 : loss : 0.048873, loss_ce: 0.017648
[01:44:50.788] iteration 14731 : loss : 0.039920, loss_ce: 0.017181
[01:44:51.099] iteration 14732 : loss : 0.048137, loss_ce: 0.018843
[01:44:51.412] iteration 14733 : loss : 0.042448, loss_ce: 0.013209
[01:44:51.512] iteration 14734 : loss : 0.336566, loss_ce: 0.000401
[01:44:52.048] save model to ./logs/swin_unet\epoch_105.pth
[01:45:09.006] iteration 14735 : loss : 0.037947, loss_ce: 0.011310
[01:45:09.307] iteration 14736 : loss : 0.111821, loss_ce: 0.013119
[01:45:09.606] iteration 14737 : loss : 0.043338, loss_ce: 0.016389
[01:45:09.909] iteration 14738 : loss : 0.048867, loss_ce: 0.010505
[01:45:10.209] iteration 14739 : loss : 0.054470, loss_ce: 0.014555
[01:45:10.509] iteration 14740 : loss : 0.105267, loss_ce: 0.007453
[01:45:10.823] iteration 14741 : loss : 0.119822, loss_ce: 0.010696
[01:45:11.121] iteration 14742 : loss : 0.079144, loss_ce: 0.020173
[01:45:11.426] iteration 14743 : loss : 0.050328, loss_ce: 0.017692
[01:45:11.726] iteration 14744 : loss : 0.088112, loss_ce: 0.025898
[01:45:12.029] iteration 14745 : loss : 0.044460, loss_ce: 0.024126
[01:45:12.333] iteration 14746 : loss : 0.060048, loss_ce: 0.020108
[01:45:12.645] iteration 14747 : loss : 0.043011, loss_ce: 0.014109
[01:45:12.957] iteration 14748 : loss : 0.052566, loss_ce: 0.014348
[01:45:13.265] iteration 14749 : loss : 0.056736, loss_ce: 0.017539
[01:45:13.574] iteration 14750 : loss : 0.042205, loss_ce: 0.015333
[01:45:13.884] iteration 14751 : loss : 0.105902, loss_ce: 0.009011
[01:45:14.191] iteration 14752 : loss : 0.101425, loss_ce: 0.010758
[01:45:14.491] iteration 14753 : loss : 0.055299, loss_ce: 0.024963
[01:45:14.795] iteration 14754 : loss : 0.051365, loss_ce: 0.016185
[01:45:15.105] iteration 14755 : loss : 0.050161, loss_ce: 0.021426
[01:45:15.411] iteration 14756 : loss : 0.060085, loss_ce: 0.015138
[01:45:15.717] iteration 14757 : loss : 0.047140, loss_ce: 0.010501
[01:45:16.024] iteration 14758 : loss : 0.043989, loss_ce: 0.017147
[01:45:16.330] iteration 14759 : loss : 0.047549, loss_ce: 0.014910
[01:45:16.636] iteration 14760 : loss : 0.048870, loss_ce: 0.026800
[01:45:16.966] iteration 14761 : loss : 0.041034, loss_ce: 0.021492
[01:45:17.269] iteration 14762 : loss : 0.052654, loss_ce: 0.018287
[01:45:17.579] iteration 14763 : loss : 0.052708, loss_ce: 0.012096
[01:45:17.884] iteration 14764 : loss : 0.048469, loss_ce: 0.012076
[01:45:18.187] iteration 14765 : loss : 0.046862, loss_ce: 0.010564
[01:45:18.492] iteration 14766 : loss : 0.049751, loss_ce: 0.013608
[01:45:18.802] iteration 14767 : loss : 0.157201, loss_ce: 0.006429
[01:45:19.109] iteration 14768 : loss : 0.044289, loss_ce: 0.013326
[01:45:19.414] iteration 14769 : loss : 0.100203, loss_ce: 0.008280
[01:45:19.722] iteration 14770 : loss : 0.045535, loss_ce: 0.016168
[01:45:20.029] iteration 14771 : loss : 0.106763, loss_ce: 0.008097
[01:45:20.337] iteration 14772 : loss : 0.048867, loss_ce: 0.008646
[01:45:20.642] iteration 14773 : loss : 0.053910, loss_ce: 0.015910
[01:45:20.947] iteration 14774 : loss : 0.051665, loss_ce: 0.009169
[01:45:21.249] iteration 14775 : loss : 0.042753, loss_ce: 0.014646
[01:45:21.551] iteration 14776 : loss : 0.041802, loss_ce: 0.012700
[01:45:21.853] iteration 14777 : loss : 0.077580, loss_ce: 0.016553
[01:45:22.159] iteration 14778 : loss : 0.047490, loss_ce: 0.017453
[01:45:22.464] iteration 14779 : loss : 0.048994, loss_ce: 0.018209
[01:45:22.767] iteration 14780 : loss : 0.041108, loss_ce: 0.019768
[01:45:23.090] iteration 14781 : loss : 0.048006, loss_ce: 0.017348
[01:45:23.392] iteration 14782 : loss : 0.068814, loss_ce: 0.017919
[01:45:23.697] iteration 14783 : loss : 0.048271, loss_ce: 0.023445
[01:45:24.000] iteration 14784 : loss : 0.117151, loss_ce: 0.018562
[01:45:24.306] iteration 14785 : loss : 0.061934, loss_ce: 0.008772
[01:45:24.606] iteration 14786 : loss : 0.044200, loss_ce: 0.024894
[01:45:24.912] iteration 14787 : loss : 0.120647, loss_ce: 0.012793
[01:45:25.212] iteration 14788 : loss : 0.045177, loss_ce: 0.012029
[01:45:25.514] iteration 14789 : loss : 0.065853, loss_ce: 0.022758
[01:45:25.818] iteration 14790 : loss : 0.049024, loss_ce: 0.015536
[01:45:26.121] iteration 14791 : loss : 0.066651, loss_ce: 0.025775
[01:45:26.424] iteration 14792 : loss : 0.049618, loss_ce: 0.022038
[01:45:26.724] iteration 14793 : loss : 0.160504, loss_ce: 0.004732
[01:45:27.029] iteration 14794 : loss : 0.050049, loss_ce: 0.016595
[01:45:27.335] iteration 14795 : loss : 0.052714, loss_ce: 0.019380
[01:45:27.640] iteration 14796 : loss : 0.055098, loss_ce: 0.013848
[01:45:27.945] iteration 14797 : loss : 0.162529, loss_ce: 0.007238
[01:45:28.255] iteration 14798 : loss : 0.040983, loss_ce: 0.023272
[01:45:28.559] iteration 14799 : loss : 0.044400, loss_ce: 0.016070
[01:45:28.866] iteration 14800 : loss : 0.048077, loss_ce: 0.011175
[01:45:29.190] iteration 14801 : loss : 0.106568, loss_ce: 0.010257
[01:45:29.494] iteration 14802 : loss : 0.102047, loss_ce: 0.007429
[01:45:29.803] iteration 14803 : loss : 0.050008, loss_ce: 0.015924
[01:45:30.110] iteration 14804 : loss : 0.051709, loss_ce: 0.017308
[01:45:30.417] iteration 14805 : loss : 0.071355, loss_ce: 0.011170
[01:45:30.729] iteration 14806 : loss : 0.109893, loss_ce: 0.007211
[01:45:31.035] iteration 14807 : loss : 0.044079, loss_ce: 0.013417
[01:45:31.342] iteration 14808 : loss : 0.053465, loss_ce: 0.021760
[01:45:31.651] iteration 14809 : loss : 0.049432, loss_ce: 0.016831
[01:45:31.960] iteration 14810 : loss : 0.040238, loss_ce: 0.007895
[01:45:32.270] iteration 14811 : loss : 0.065811, loss_ce: 0.023655
[01:45:32.586] iteration 14812 : loss : 0.042099, loss_ce: 0.015386
[01:45:32.893] iteration 14813 : loss : 0.052577, loss_ce: 0.015251
[01:45:33.205] iteration 14814 : loss : 0.102650, loss_ce: 0.016168
[01:45:33.516] iteration 14815 : loss : 0.105593, loss_ce: 0.009306
[01:45:33.823] iteration 14816 : loss : 0.051736, loss_ce: 0.014862
[01:45:34.133] iteration 14817 : loss : 0.044399, loss_ce: 0.020783
[01:45:34.440] iteration 14818 : loss : 0.048483, loss_ce: 0.013895
[01:45:34.751] iteration 14819 : loss : 0.032488, loss_ce: 0.013205
[01:45:35.057] iteration 14820 : loss : 0.048139, loss_ce: 0.013170
[01:45:35.382] iteration 14821 : loss : 0.095440, loss_ce: 0.006043
[01:45:35.690] iteration 14822 : loss : 0.064375, loss_ce: 0.009950
[01:45:36.003] iteration 14823 : loss : 0.068642, loss_ce: 0.018253
[01:45:36.311] iteration 14824 : loss : 0.045416, loss_ce: 0.006519
[01:45:36.620] iteration 14825 : loss : 0.161245, loss_ce: 0.013007
[01:45:36.931] iteration 14826 : loss : 0.038140, loss_ce: 0.007681
[01:45:37.241] iteration 14827 : loss : 0.044057, loss_ce: 0.010233
[01:45:37.553] iteration 14828 : loss : 0.161811, loss_ce: 0.009409
[01:45:37.859] iteration 14829 : loss : 0.051034, loss_ce: 0.011020
[01:45:38.170] iteration 14830 : loss : 0.061421, loss_ce: 0.007984
[01:45:38.482] iteration 14831 : loss : 0.039434, loss_ce: 0.014209
[01:45:38.791] iteration 14832 : loss : 0.162278, loss_ce: 0.005722
[01:45:39.099] iteration 14833 : loss : 0.052218, loss_ce: 0.022465
[01:45:39.407] iteration 14834 : loss : 0.052686, loss_ce: 0.015202
[01:45:39.713] iteration 14835 : loss : 0.038353, loss_ce: 0.014145
[01:45:40.022] iteration 14836 : loss : 0.053423, loss_ce: 0.017509
[01:45:40.330] iteration 14837 : loss : 0.038558, loss_ce: 0.012009
[01:45:40.637] iteration 14838 : loss : 0.037420, loss_ce: 0.012268
[01:45:40.948] iteration 14839 : loss : 0.102955, loss_ce: 0.016415
[01:45:41.259] iteration 14840 : loss : 0.104889, loss_ce: 0.013436
[01:45:41.589] iteration 14841 : loss : 0.101920, loss_ce: 0.009403
[01:45:41.899] iteration 14842 : loss : 0.059885, loss_ce: 0.009271
[01:45:42.209] iteration 14843 : loss : 0.097782, loss_ce: 0.007384
[01:45:42.515] iteration 14844 : loss : 0.049879, loss_ce: 0.008021
[01:45:42.828] iteration 14845 : loss : 0.053658, loss_ce: 0.011725
[01:45:43.140] iteration 14846 : loss : 0.066307, loss_ce: 0.015220
[01:45:43.451] iteration 14847 : loss : 0.053681, loss_ce: 0.023302
[01:45:43.758] iteration 14848 : loss : 0.103066, loss_ce: 0.015100
[01:45:44.071] iteration 14849 : loss : 0.059994, loss_ce: 0.012571
[01:45:44.383] iteration 14850 : loss : 0.047252, loss_ce: 0.008233
[01:45:44.694] iteration 14851 : loss : 0.049833, loss_ce: 0.010570
[01:45:45.002] iteration 14852 : loss : 0.031605, loss_ce: 0.008065
[01:45:45.312] iteration 14853 : loss : 0.051062, loss_ce: 0.008644
[01:45:45.622] iteration 14854 : loss : 0.043961, loss_ce: 0.016119
[01:45:45.929] iteration 14855 : loss : 0.041697, loss_ce: 0.010156
[01:45:46.238] iteration 14856 : loss : 0.050677, loss_ce: 0.018913
[01:45:46.549] iteration 14857 : loss : 0.052442, loss_ce: 0.010090
[01:45:46.863] iteration 14858 : loss : 0.099469, loss_ce: 0.012158
[01:45:47.174] iteration 14859 : loss : 0.039880, loss_ce: 0.013847
[01:45:47.487] iteration 14860 : loss : 0.047794, loss_ce: 0.019977
[01:45:47.831] iteration 14861 : loss : 0.047003, loss_ce: 0.013638
[01:45:48.146] iteration 14862 : loss : 0.102876, loss_ce: 0.008136
[01:45:48.464] iteration 14863 : loss : 0.102797, loss_ce: 0.008751
[01:45:48.773] iteration 14864 : loss : 0.050553, loss_ce: 0.018473
[01:45:49.082] iteration 14865 : loss : 0.062141, loss_ce: 0.022565
[01:45:49.391] iteration 14866 : loss : 0.070147, loss_ce: 0.015238
[01:45:49.699] iteration 14867 : loss : 0.098096, loss_ce: 0.012665
[01:45:50.008] iteration 14868 : loss : 0.050572, loss_ce: 0.018761
[01:45:50.323] iteration 14869 : loss : 0.055088, loss_ce: 0.016849
[01:45:50.629] iteration 14870 : loss : 0.053380, loss_ce: 0.020119
[01:45:50.938] iteration 14871 : loss : 0.053693, loss_ce: 0.014735
[01:45:51.250] iteration 14872 : loss : 0.049659, loss_ce: 0.015041
[01:45:51.332] iteration 14873 : loss : 0.343654, loss_ce: 0.005780
[01:46:10.412] iteration 14874 : loss : 0.062178, loss_ce: 0.009656
[01:46:10.711] iteration 14875 : loss : 0.110311, loss_ce: 0.021004
[01:46:11.012] iteration 14876 : loss : 0.100719, loss_ce: 0.012458
[01:46:11.314] iteration 14877 : loss : 0.104130, loss_ce: 0.009003
[01:46:11.616] iteration 14878 : loss : 0.043370, loss_ce: 0.009793
[01:46:11.919] iteration 14879 : loss : 0.113416, loss_ce: 0.025444
[01:46:12.221] iteration 14880 : loss : 0.058463, loss_ce: 0.018280
[01:46:12.537] iteration 14881 : loss : 0.100849, loss_ce: 0.004572
[01:46:12.837] iteration 14882 : loss : 0.113477, loss_ce: 0.008355
[01:46:13.141] iteration 14883 : loss : 0.118746, loss_ce: 0.007065
[01:46:13.440] iteration 14884 : loss : 0.047742, loss_ce: 0.016539
[01:46:13.739] iteration 14885 : loss : 0.128639, loss_ce: 0.018839
[01:46:14.043] iteration 14886 : loss : 0.099541, loss_ce: 0.010260
[01:46:14.345] iteration 14887 : loss : 0.051898, loss_ce: 0.009603
[01:46:14.649] iteration 14888 : loss : 0.054678, loss_ce: 0.023596
[01:46:14.949] iteration 14889 : loss : 0.080312, loss_ce: 0.011982
[01:46:15.249] iteration 14890 : loss : 0.045730, loss_ce: 0.016212
[01:46:15.549] iteration 14891 : loss : 0.044291, loss_ce: 0.016273
[01:46:15.855] iteration 14892 : loss : 0.040236, loss_ce: 0.008928
[01:46:16.158] iteration 14893 : loss : 0.052701, loss_ce: 0.011697
[01:46:16.465] iteration 14894 : loss : 0.113786, loss_ce: 0.017713
[01:46:16.765] iteration 14895 : loss : 0.050502, loss_ce: 0.015525
[01:46:17.064] iteration 14896 : loss : 0.052995, loss_ce: 0.009940
[01:46:17.370] iteration 14897 : loss : 0.105176, loss_ce: 0.008309
[01:46:17.680] iteration 14898 : loss : 0.055140, loss_ce: 0.011943
[01:46:17.987] iteration 14899 : loss : 0.045195, loss_ce: 0.014522
[01:46:18.295] iteration 14900 : loss : 0.047699, loss_ce: 0.016182
[01:46:18.617] iteration 14901 : loss : 0.051379, loss_ce: 0.010707
[01:46:18.921] iteration 14902 : loss : 0.039668, loss_ce: 0.010611
[01:46:19.233] iteration 14903 : loss : 0.047213, loss_ce: 0.017805
[01:46:19.536] iteration 14904 : loss : 0.112594, loss_ce: 0.014750
[01:46:19.837] iteration 14905 : loss : 0.101596, loss_ce: 0.010983
[01:46:20.140] iteration 14906 : loss : 0.070313, loss_ce: 0.016414
[01:46:20.445] iteration 14907 : loss : 0.045018, loss_ce: 0.012251
[01:46:20.745] iteration 14908 : loss : 0.030634, loss_ce: 0.004700
[01:46:21.050] iteration 14909 : loss : 0.056463, loss_ce: 0.013719
[01:46:21.349] iteration 14910 : loss : 0.045702, loss_ce: 0.013714
[01:46:21.654] iteration 14911 : loss : 0.105563, loss_ce: 0.014099
[01:46:21.958] iteration 14912 : loss : 0.044740, loss_ce: 0.017353
[01:46:22.261] iteration 14913 : loss : 0.175423, loss_ce: 0.003905
[01:46:22.561] iteration 14914 : loss : 0.057387, loss_ce: 0.015486
[01:46:22.864] iteration 14915 : loss : 0.154168, loss_ce: 0.004064
[01:46:23.172] iteration 14916 : loss : 0.057217, loss_ce: 0.027470
[01:46:23.478] iteration 14917 : loss : 0.046133, loss_ce: 0.019527
[01:46:23.778] iteration 14918 : loss : 0.044395, loss_ce: 0.013746
[01:46:24.083] iteration 14919 : loss : 0.048626, loss_ce: 0.008193
[01:46:24.390] iteration 14920 : loss : 0.043939, loss_ce: 0.008643
[01:46:24.708] iteration 14921 : loss : 0.051418, loss_ce: 0.011168
[01:46:25.014] iteration 14922 : loss : 0.038936, loss_ce: 0.010266
[01:46:25.319] iteration 14923 : loss : 0.051027, loss_ce: 0.029451
[01:46:25.627] iteration 14924 : loss : 0.045809, loss_ce: 0.011303
[01:46:25.930] iteration 14925 : loss : 0.067543, loss_ce: 0.014774
[01:46:26.233] iteration 14926 : loss : 0.048601, loss_ce: 0.020070
[01:46:26.539] iteration 14927 : loss : 0.063853, loss_ce: 0.012391
[01:46:26.845] iteration 14928 : loss : 0.052444, loss_ce: 0.011716
[01:46:27.149] iteration 14929 : loss : 0.103176, loss_ce: 0.013788
[01:46:27.451] iteration 14930 : loss : 0.049217, loss_ce: 0.012948
[01:46:27.758] iteration 14931 : loss : 0.056498, loss_ce: 0.021432
[01:46:28.058] iteration 14932 : loss : 0.040467, loss_ce: 0.007174
[01:46:28.361] iteration 14933 : loss : 0.107421, loss_ce: 0.012929
[01:46:28.665] iteration 14934 : loss : 0.039755, loss_ce: 0.010272
[01:46:28.971] iteration 14935 : loss : 0.099128, loss_ce: 0.008543
[01:46:29.273] iteration 14936 : loss : 0.051843, loss_ce: 0.020555
[01:46:29.578] iteration 14937 : loss : 0.048482, loss_ce: 0.019667
[01:46:29.885] iteration 14938 : loss : 0.101273, loss_ce: 0.014758
[01:46:30.188] iteration 14939 : loss : 0.042151, loss_ce: 0.017337
[01:46:30.490] iteration 14940 : loss : 0.051413, loss_ce: 0.013453
[01:46:30.813] iteration 14941 : loss : 0.100954, loss_ce: 0.012392
[01:46:31.117] iteration 14942 : loss : 0.039660, loss_ce: 0.013503
[01:46:31.426] iteration 14943 : loss : 0.054640, loss_ce: 0.025466
[01:46:31.729] iteration 14944 : loss : 0.045515, loss_ce: 0.015949
[01:46:32.030] iteration 14945 : loss : 0.050776, loss_ce: 0.026610
[01:46:32.336] iteration 14946 : loss : 0.037039, loss_ce: 0.009567
[01:46:32.650] iteration 14947 : loss : 0.049612, loss_ce: 0.020520
[01:46:32.957] iteration 14948 : loss : 0.118656, loss_ce: 0.008169
[01:46:33.272] iteration 14949 : loss : 0.053061, loss_ce: 0.005344
[01:46:33.583] iteration 14950 : loss : 0.051320, loss_ce: 0.021516
[01:46:33.893] iteration 14951 : loss : 0.040042, loss_ce: 0.018956
[01:46:34.201] iteration 14952 : loss : 0.051030, loss_ce: 0.012257
[01:46:34.506] iteration 14953 : loss : 0.050381, loss_ce: 0.018532
[01:46:34.813] iteration 14954 : loss : 0.057572, loss_ce: 0.015421
[01:46:35.116] iteration 14955 : loss : 0.058754, loss_ce: 0.016666
[01:46:35.422] iteration 14956 : loss : 0.057447, loss_ce: 0.015606
[01:46:35.728] iteration 14957 : loss : 0.045875, loss_ce: 0.014310
[01:46:36.031] iteration 14958 : loss : 0.051604, loss_ce: 0.021239
[01:46:36.336] iteration 14959 : loss : 0.107617, loss_ce: 0.008085
[01:46:36.642] iteration 14960 : loss : 0.051068, loss_ce: 0.011585
[01:46:36.960] iteration 14961 : loss : 0.056994, loss_ce: 0.016998
[01:46:37.267] iteration 14962 : loss : 0.042505, loss_ce: 0.010546
[01:46:37.573] iteration 14963 : loss : 0.052882, loss_ce: 0.012000
[01:46:37.877] iteration 14964 : loss : 0.047935, loss_ce: 0.013542
[01:46:38.182] iteration 14965 : loss : 0.047025, loss_ce: 0.020786
[01:46:38.490] iteration 14966 : loss : 0.057272, loss_ce: 0.011538
[01:46:38.793] iteration 14967 : loss : 0.058641, loss_ce: 0.011672
[01:46:39.095] iteration 14968 : loss : 0.050998, loss_ce: 0.014495
[01:46:39.402] iteration 14969 : loss : 0.053610, loss_ce: 0.017736
[01:46:39.705] iteration 14970 : loss : 0.040870, loss_ce: 0.016610
[01:46:40.010] iteration 14971 : loss : 0.047944, loss_ce: 0.016215
[01:46:40.314] iteration 14972 : loss : 0.055858, loss_ce: 0.030510
[01:46:40.616] iteration 14973 : loss : 0.062140, loss_ce: 0.012146
[01:46:40.920] iteration 14974 : loss : 0.053618, loss_ce: 0.006489
[01:46:41.226] iteration 14975 : loss : 0.046224, loss_ce: 0.016388
[01:46:41.529] iteration 14976 : loss : 0.048571, loss_ce: 0.009383
[01:46:41.834] iteration 14977 : loss : 0.041077, loss_ce: 0.016763
[01:46:42.141] iteration 14978 : loss : 0.131665, loss_ce: 0.018676
[01:46:42.445] iteration 14979 : loss : 0.073670, loss_ce: 0.020922
[01:46:42.748] iteration 14980 : loss : 0.044357, loss_ce: 0.010075
[01:46:43.064] iteration 14981 : loss : 0.054276, loss_ce: 0.017334
[01:46:43.371] iteration 14982 : loss : 0.052843, loss_ce: 0.010056
[01:46:43.676] iteration 14983 : loss : 0.042457, loss_ce: 0.017992
[01:46:43.983] iteration 14984 : loss : 0.054279, loss_ce: 0.018392
[01:46:44.286] iteration 14985 : loss : 0.047990, loss_ce: 0.014490
[01:46:44.592] iteration 14986 : loss : 0.059215, loss_ce: 0.012379
[01:46:44.898] iteration 14987 : loss : 0.043852, loss_ce: 0.019059
[01:46:45.204] iteration 14988 : loss : 0.041460, loss_ce: 0.014209
[01:46:45.506] iteration 14989 : loss : 0.041517, loss_ce: 0.010393
[01:46:45.812] iteration 14990 : loss : 0.059351, loss_ce: 0.015382
[01:46:46.116] iteration 14991 : loss : 0.051503, loss_ce: 0.014586
[01:46:46.420] iteration 14992 : loss : 0.113533, loss_ce: 0.007272
[01:46:46.729] iteration 14993 : loss : 0.182672, loss_ce: 0.012331
[01:46:47.032] iteration 14994 : loss : 0.035667, loss_ce: 0.014946
[01:46:47.337] iteration 14995 : loss : 0.042958, loss_ce: 0.009289
[01:46:47.646] iteration 14996 : loss : 0.056047, loss_ce: 0.020022
[01:46:47.955] iteration 14997 : loss : 0.176076, loss_ce: 0.005096
[01:46:48.265] iteration 14998 : loss : 0.168071, loss_ce: 0.009130
[01:46:48.576] iteration 14999 : loss : 0.054315, loss_ce: 0.011509
[01:46:48.881] iteration 15000 : loss : 0.088297, loss_ce: 0.011138
[01:46:49.207] iteration 15001 : loss : 0.044834, loss_ce: 0.020620
[01:46:49.513] iteration 15002 : loss : 0.046526, loss_ce: 0.019047
[01:46:49.822] iteration 15003 : loss : 0.043747, loss_ce: 0.021223
[01:46:50.132] iteration 15004 : loss : 0.050934, loss_ce: 0.022604
[01:46:50.445] iteration 15005 : loss : 0.037249, loss_ce: 0.010206
[01:46:50.762] iteration 15006 : loss : 0.046004, loss_ce: 0.010703
[01:46:51.079] iteration 15007 : loss : 0.053527, loss_ce: 0.019545
[01:46:51.391] iteration 15008 : loss : 0.077703, loss_ce: 0.013243
[01:46:51.709] iteration 15009 : loss : 0.041622, loss_ce: 0.010134
[01:46:52.024] iteration 15010 : loss : 0.046795, loss_ce: 0.007393
[01:46:52.337] iteration 15011 : loss : 0.047064, loss_ce: 0.019314
[01:46:52.424] iteration 15012 : loss : 0.118104, loss_ce: 0.015869
[01:47:11.073] iteration 15013 : loss : 0.072183, loss_ce: 0.020370
[01:47:11.372] iteration 15014 : loss : 0.086797, loss_ce: 0.014680
[01:47:11.672] iteration 15015 : loss : 0.036528, loss_ce: 0.015245
[01:47:11.974] iteration 15016 : loss : 0.053051, loss_ce: 0.011755
[01:47:12.280] iteration 15017 : loss : 0.049161, loss_ce: 0.013607
[01:47:12.580] iteration 15018 : loss : 0.104416, loss_ce: 0.010513
[01:47:12.883] iteration 15019 : loss : 0.044808, loss_ce: 0.018302
[01:47:13.187] iteration 15020 : loss : 0.062742, loss_ce: 0.008279
[01:47:13.505] iteration 15021 : loss : 0.045912, loss_ce: 0.017342
[01:47:13.808] iteration 15022 : loss : 0.046461, loss_ce: 0.010915
[01:47:14.117] iteration 15023 : loss : 0.054131, loss_ce: 0.018938
[01:47:14.421] iteration 15024 : loss : 0.046180, loss_ce: 0.013154
[01:47:14.722] iteration 15025 : loss : 0.043530, loss_ce: 0.016007
[01:47:15.026] iteration 15026 : loss : 0.057321, loss_ce: 0.024678
[01:47:15.333] iteration 15027 : loss : 0.105070, loss_ce: 0.010076
[01:47:15.641] iteration 15028 : loss : 0.038198, loss_ce: 0.010882
[01:47:15.950] iteration 15029 : loss : 0.042896, loss_ce: 0.015582
[01:47:16.257] iteration 15030 : loss : 0.070928, loss_ce: 0.015170
[01:47:16.562] iteration 15031 : loss : 0.038350, loss_ce: 0.007253
[01:47:16.865] iteration 15032 : loss : 0.036900, loss_ce: 0.007507
[01:47:17.172] iteration 15033 : loss : 0.054513, loss_ce: 0.027940
[01:47:17.474] iteration 15034 : loss : 0.146569, loss_ce: 0.003892
[01:47:17.780] iteration 15035 : loss : 0.106025, loss_ce: 0.010723
[01:47:18.084] iteration 15036 : loss : 0.045873, loss_ce: 0.017426
[01:47:18.390] iteration 15037 : loss : 0.045346, loss_ce: 0.011916
[01:47:18.696] iteration 15038 : loss : 0.053372, loss_ce: 0.017558
[01:47:19.003] iteration 15039 : loss : 0.049284, loss_ce: 0.020300
[01:47:19.309] iteration 15040 : loss : 0.039259, loss_ce: 0.006196
[01:47:19.634] iteration 15041 : loss : 0.046047, loss_ce: 0.016655
[01:47:19.936] iteration 15042 : loss : 0.051111, loss_ce: 0.019582
[01:47:20.237] iteration 15043 : loss : 0.099439, loss_ce: 0.011355
[01:47:20.542] iteration 15044 : loss : 0.170897, loss_ce: 0.009853
[01:47:20.842] iteration 15045 : loss : 0.063392, loss_ce: 0.021777
[01:47:21.146] iteration 15046 : loss : 0.110545, loss_ce: 0.008004
[01:47:21.448] iteration 15047 : loss : 0.045404, loss_ce: 0.006749
[01:47:21.748] iteration 15048 : loss : 0.049310, loss_ce: 0.005942
[01:47:22.051] iteration 15049 : loss : 0.055469, loss_ce: 0.021657
[01:47:22.367] iteration 15050 : loss : 0.034868, loss_ce: 0.017082
[01:47:22.673] iteration 15051 : loss : 0.064972, loss_ce: 0.012042
[01:47:22.986] iteration 15052 : loss : 0.053524, loss_ce: 0.021848
[01:47:23.296] iteration 15053 : loss : 0.040922, loss_ce: 0.015749
[01:47:23.603] iteration 15054 : loss : 0.103193, loss_ce: 0.014179
[01:47:23.911] iteration 15055 : loss : 0.063316, loss_ce: 0.015576
[01:47:24.222] iteration 15056 : loss : 0.054554, loss_ce: 0.018550
[01:47:24.527] iteration 15057 : loss : 0.051767, loss_ce: 0.012576
[01:47:24.830] iteration 15058 : loss : 0.098197, loss_ce: 0.005419
[01:47:25.134] iteration 15059 : loss : 0.052431, loss_ce: 0.025402
[01:47:25.436] iteration 15060 : loss : 0.052940, loss_ce: 0.025601
[01:47:25.756] iteration 15061 : loss : 0.054522, loss_ce: 0.020206
[01:47:26.064] iteration 15062 : loss : 0.050400, loss_ce: 0.006851
[01:47:26.371] iteration 15063 : loss : 0.041102, loss_ce: 0.014923
[01:47:26.676] iteration 15064 : loss : 0.044941, loss_ce: 0.012407
[01:47:26.979] iteration 15065 : loss : 0.041775, loss_ce: 0.011470
[01:47:27.280] iteration 15066 : loss : 0.051569, loss_ce: 0.020543
[01:47:27.589] iteration 15067 : loss : 0.045591, loss_ce: 0.016698
[01:47:27.891] iteration 15068 : loss : 0.050681, loss_ce: 0.019542
[01:47:28.196] iteration 15069 : loss : 0.043988, loss_ce: 0.010169
[01:47:28.499] iteration 15070 : loss : 0.102027, loss_ce: 0.015172
[01:47:28.800] iteration 15071 : loss : 0.043661, loss_ce: 0.011347
[01:47:29.104] iteration 15072 : loss : 0.049214, loss_ce: 0.008177
[01:47:29.407] iteration 15073 : loss : 0.048096, loss_ce: 0.015574
[01:47:29.711] iteration 15074 : loss : 0.077683, loss_ce: 0.030716
[01:47:30.012] iteration 15075 : loss : 0.044557, loss_ce: 0.013633
[01:47:30.315] iteration 15076 : loss : 0.035490, loss_ce: 0.012482
[01:47:30.618] iteration 15077 : loss : 0.048676, loss_ce: 0.020520
[01:47:30.920] iteration 15078 : loss : 0.050457, loss_ce: 0.022804
[01:47:31.223] iteration 15079 : loss : 0.055557, loss_ce: 0.010054
[01:47:31.527] iteration 15080 : loss : 0.074236, loss_ce: 0.012719
[01:47:31.851] iteration 15081 : loss : 0.044232, loss_ce: 0.014595
[01:47:32.151] iteration 15082 : loss : 0.047353, loss_ce: 0.018356
[01:47:32.459] iteration 15083 : loss : 0.102331, loss_ce: 0.010174
[01:47:32.763] iteration 15084 : loss : 0.054701, loss_ce: 0.015333
[01:47:33.069] iteration 15085 : loss : 0.058327, loss_ce: 0.013626
[01:47:33.372] iteration 15086 : loss : 0.052172, loss_ce: 0.011969
[01:47:33.675] iteration 15087 : loss : 0.065623, loss_ce: 0.012115
[01:47:33.978] iteration 15088 : loss : 0.162873, loss_ce: 0.006584
[01:47:34.281] iteration 15089 : loss : 0.047518, loss_ce: 0.020544
[01:47:34.586] iteration 15090 : loss : 0.347001, loss_ce: 0.001810
[01:47:34.890] iteration 15091 : loss : 0.045686, loss_ce: 0.017126
[01:47:35.198] iteration 15092 : loss : 0.084779, loss_ce: 0.010822
[01:47:35.504] iteration 15093 : loss : 0.114635, loss_ce: 0.014176
[01:47:35.808] iteration 15094 : loss : 0.053027, loss_ce: 0.013672
[01:47:36.112] iteration 15095 : loss : 0.038645, loss_ce: 0.012806
[01:47:36.419] iteration 15096 : loss : 0.051430, loss_ce: 0.022750
[01:47:36.721] iteration 15097 : loss : 0.103340, loss_ce: 0.010356
[01:47:37.029] iteration 15098 : loss : 0.043944, loss_ce: 0.014964
[01:47:37.337] iteration 15099 : loss : 0.046240, loss_ce: 0.016359
[01:47:37.642] iteration 15100 : loss : 0.039226, loss_ce: 0.013707
[01:47:37.960] iteration 15101 : loss : 0.045912, loss_ce: 0.010302
[01:47:38.270] iteration 15102 : loss : 0.047429, loss_ce: 0.010749
[01:47:38.576] iteration 15103 : loss : 0.042650, loss_ce: 0.011895
[01:47:38.884] iteration 15104 : loss : 0.037656, loss_ce: 0.016728
[01:47:39.192] iteration 15105 : loss : 0.099735, loss_ce: 0.015945
[01:47:39.496] iteration 15106 : loss : 0.058635, loss_ce: 0.016938
[01:47:39.808] iteration 15107 : loss : 0.054366, loss_ce: 0.016078
[01:47:40.115] iteration 15108 : loss : 0.047078, loss_ce: 0.012977
[01:47:40.423] iteration 15109 : loss : 0.047376, loss_ce: 0.016868
[01:47:40.730] iteration 15110 : loss : 0.060608, loss_ce: 0.017292
[01:47:41.037] iteration 15111 : loss : 0.114334, loss_ce: 0.017744
[01:47:41.348] iteration 15112 : loss : 0.044063, loss_ce: 0.007070
[01:47:41.658] iteration 15113 : loss : 0.155548, loss_ce: 0.009664
[01:47:41.965] iteration 15114 : loss : 0.036773, loss_ce: 0.008215
[01:47:42.276] iteration 15115 : loss : 0.045242, loss_ce: 0.008997
[01:47:42.583] iteration 15116 : loss : 0.056548, loss_ce: 0.009371
[01:47:42.889] iteration 15117 : loss : 0.075594, loss_ce: 0.017249
[01:47:43.202] iteration 15118 : loss : 0.283248, loss_ce: 0.005399
[01:47:43.507] iteration 15119 : loss : 0.050085, loss_ce: 0.017523
[01:47:43.819] iteration 15120 : loss : 0.057904, loss_ce: 0.011564
[01:47:44.146] iteration 15121 : loss : 0.047193, loss_ce: 0.009009
[01:47:44.457] iteration 15122 : loss : 0.044513, loss_ce: 0.010392
[01:47:44.764] iteration 15123 : loss : 0.067957, loss_ce: 0.010359
[01:47:45.074] iteration 15124 : loss : 0.060492, loss_ce: 0.016655
[01:47:45.383] iteration 15125 : loss : 0.079043, loss_ce: 0.007806
[01:47:45.692] iteration 15126 : loss : 0.042899, loss_ce: 0.023019
[01:47:46.001] iteration 15127 : loss : 0.035417, loss_ce: 0.010464
[01:47:46.314] iteration 15128 : loss : 0.047726, loss_ce: 0.015397
[01:47:46.621] iteration 15129 : loss : 0.052762, loss_ce: 0.015802
[01:47:46.929] iteration 15130 : loss : 0.048483, loss_ce: 0.019795
[01:47:47.236] iteration 15131 : loss : 0.059668, loss_ce: 0.014352
[01:47:47.544] iteration 15132 : loss : 0.045761, loss_ce: 0.013096
[01:47:47.855] iteration 15133 : loss : 0.059561, loss_ce: 0.016384
[01:47:48.162] iteration 15134 : loss : 0.051282, loss_ce: 0.009891
[01:47:48.476] iteration 15135 : loss : 0.103093, loss_ce: 0.008583
[01:47:48.796] iteration 15136 : loss : 0.045984, loss_ce: 0.011316
[01:47:49.107] iteration 15137 : loss : 0.040265, loss_ce: 0.022647
[01:47:49.417] iteration 15138 : loss : 0.100932, loss_ce: 0.007236
[01:47:49.731] iteration 15139 : loss : 0.063890, loss_ce: 0.014730
[01:47:50.047] iteration 15140 : loss : 0.041965, loss_ce: 0.016617
[01:47:50.377] iteration 15141 : loss : 0.045072, loss_ce: 0.016026
[01:47:50.690] iteration 15142 : loss : 0.039894, loss_ce: 0.013803
[01:47:51.002] iteration 15143 : loss : 0.059214, loss_ce: 0.021455
[01:47:51.311] iteration 15144 : loss : 0.130110, loss_ce: 0.009434
[01:47:51.623] iteration 15145 : loss : 0.043435, loss_ce: 0.010747
[01:47:51.936] iteration 15146 : loss : 0.096623, loss_ce: 0.007425
[01:47:52.245] iteration 15147 : loss : 0.054138, loss_ce: 0.014125
[01:47:52.552] iteration 15148 : loss : 0.055853, loss_ce: 0.021007
[01:47:52.865] iteration 15149 : loss : 0.048592, loss_ce: 0.019655
[01:47:53.179] iteration 15150 : loss : 0.097345, loss_ce: 0.005515
[01:47:53.260] iteration 15151 : loss : 0.181255, loss_ce: 0.012062
[01:48:11.481] iteration 15152 : loss : 0.072996, loss_ce: 0.017110
[01:48:11.777] iteration 15153 : loss : 0.102330, loss_ce: 0.017086
[01:48:12.078] iteration 15154 : loss : 0.110199, loss_ce: 0.014678
[01:48:12.385] iteration 15155 : loss : 0.072617, loss_ce: 0.012902
[01:48:12.692] iteration 15156 : loss : 0.063003, loss_ce: 0.020733
[01:48:13.000] iteration 15157 : loss : 0.107901, loss_ce: 0.009974
[01:48:13.304] iteration 15158 : loss : 0.100511, loss_ce: 0.011293
[01:48:13.613] iteration 15159 : loss : 0.051868, loss_ce: 0.018170
[01:48:13.922] iteration 15160 : loss : 0.044039, loss_ce: 0.014592
[01:48:14.244] iteration 15161 : loss : 0.057639, loss_ce: 0.016303
[01:48:14.548] iteration 15162 : loss : 0.104906, loss_ce: 0.012720
[01:48:14.855] iteration 15163 : loss : 0.095875, loss_ce: 0.008582
[01:48:15.157] iteration 15164 : loss : 0.045325, loss_ce: 0.006392
[01:48:15.457] iteration 15165 : loss : 0.046645, loss_ce: 0.009701
[01:48:15.763] iteration 15166 : loss : 0.052704, loss_ce: 0.012426
[01:48:16.064] iteration 15167 : loss : 0.221436, loss_ce: 0.004356
[01:48:16.367] iteration 15168 : loss : 0.047753, loss_ce: 0.008479
[01:48:16.670] iteration 15169 : loss : 0.053176, loss_ce: 0.018241
[01:48:16.972] iteration 15170 : loss : 0.036976, loss_ce: 0.017263
[01:48:17.276] iteration 15171 : loss : 0.039564, loss_ce: 0.018487
[01:48:17.578] iteration 15172 : loss : 0.043784, loss_ce: 0.016474
[01:48:17.884] iteration 15173 : loss : 0.043485, loss_ce: 0.018039
[01:48:18.187] iteration 15174 : loss : 0.107692, loss_ce: 0.016687
[01:48:18.490] iteration 15175 : loss : 0.051414, loss_ce: 0.016339
[01:48:18.797] iteration 15176 : loss : 0.045761, loss_ce: 0.020478
[01:48:19.101] iteration 15177 : loss : 0.041955, loss_ce: 0.016722
[01:48:19.402] iteration 15178 : loss : 0.050470, loss_ce: 0.016178
[01:48:19.703] iteration 15179 : loss : 0.057690, loss_ce: 0.015086
[01:48:20.006] iteration 15180 : loss : 0.117194, loss_ce: 0.015928
[01:48:20.326] iteration 15181 : loss : 0.041222, loss_ce: 0.010768
[01:48:20.628] iteration 15182 : loss : 0.141783, loss_ce: 0.010933
[01:48:20.934] iteration 15183 : loss : 0.055308, loss_ce: 0.018686
[01:48:21.240] iteration 15184 : loss : 0.040382, loss_ce: 0.010613
[01:48:21.541] iteration 15185 : loss : 0.049450, loss_ce: 0.011000
[01:48:21.841] iteration 15186 : loss : 0.108510, loss_ce: 0.019489
[01:48:22.143] iteration 15187 : loss : 0.120951, loss_ce: 0.006097
[01:48:22.443] iteration 15188 : loss : 0.045366, loss_ce: 0.013804
[01:48:22.747] iteration 15189 : loss : 0.045179, loss_ce: 0.017573
[01:48:23.049] iteration 15190 : loss : 0.051703, loss_ce: 0.017382
[01:48:23.353] iteration 15191 : loss : 0.046827, loss_ce: 0.017853
[01:48:23.660] iteration 15192 : loss : 0.106034, loss_ce: 0.010806
[01:48:23.962] iteration 15193 : loss : 0.101086, loss_ce: 0.006716
[01:48:24.263] iteration 15194 : loss : 0.176600, loss_ce: 0.009198
[01:48:24.567] iteration 15195 : loss : 0.053049, loss_ce: 0.022597
[01:48:24.870] iteration 15196 : loss : 0.054122, loss_ce: 0.012974
[01:48:25.173] iteration 15197 : loss : 0.042854, loss_ce: 0.008630
[01:48:25.472] iteration 15198 : loss : 0.056258, loss_ce: 0.014158
[01:48:25.775] iteration 15199 : loss : 0.040185, loss_ce: 0.021150
[01:48:26.078] iteration 15200 : loss : 0.095218, loss_ce: 0.013543
[01:48:26.394] iteration 15201 : loss : 0.054581, loss_ce: 0.014262
[01:48:26.702] iteration 15202 : loss : 0.102823, loss_ce: 0.012991
[01:48:27.004] iteration 15203 : loss : 0.120088, loss_ce: 0.004943
[01:48:27.308] iteration 15204 : loss : 0.088602, loss_ce: 0.013880
[01:48:27.615] iteration 15205 : loss : 0.057781, loss_ce: 0.014055
[01:48:27.922] iteration 15206 : loss : 0.083666, loss_ce: 0.014221
[01:48:28.229] iteration 15207 : loss : 0.105583, loss_ce: 0.010385
[01:48:28.532] iteration 15208 : loss : 0.108253, loss_ce: 0.009926
[01:48:28.838] iteration 15209 : loss : 0.053455, loss_ce: 0.007388
[01:48:29.140] iteration 15210 : loss : 0.046704, loss_ce: 0.021207
[01:48:29.445] iteration 15211 : loss : 0.041770, loss_ce: 0.015906
[01:48:29.752] iteration 15212 : loss : 0.035270, loss_ce: 0.006129
[01:48:30.058] iteration 15213 : loss : 0.049069, loss_ce: 0.018957
[01:48:30.367] iteration 15214 : loss : 0.041051, loss_ce: 0.016173
[01:48:30.673] iteration 15215 : loss : 0.043866, loss_ce: 0.011475
[01:48:30.977] iteration 15216 : loss : 0.112502, loss_ce: 0.007398
[01:48:31.285] iteration 15217 : loss : 0.049230, loss_ce: 0.009600
[01:48:31.598] iteration 15218 : loss : 0.050295, loss_ce: 0.027060
[01:48:31.905] iteration 15219 : loss : 0.042518, loss_ce: 0.013206
[01:48:32.211] iteration 15220 : loss : 0.055503, loss_ce: 0.015002
[01:48:32.534] iteration 15221 : loss : 0.053450, loss_ce: 0.009940
[01:48:32.840] iteration 15222 : loss : 0.046248, loss_ce: 0.025357
[01:48:33.149] iteration 15223 : loss : 0.045970, loss_ce: 0.016082
[01:48:33.454] iteration 15224 : loss : 0.033346, loss_ce: 0.010269
[01:48:33.764] iteration 15225 : loss : 0.045503, loss_ce: 0.018836
[01:48:34.070] iteration 15226 : loss : 0.042680, loss_ce: 0.014089
[01:48:34.381] iteration 15227 : loss : 0.047997, loss_ce: 0.011455
[01:48:34.689] iteration 15228 : loss : 0.048407, loss_ce: 0.013630
[01:48:35.001] iteration 15229 : loss : 0.048091, loss_ce: 0.018202
[01:48:35.306] iteration 15230 : loss : 0.037431, loss_ce: 0.008165
[01:48:35.615] iteration 15231 : loss : 0.049576, loss_ce: 0.008947
[01:48:35.923] iteration 15232 : loss : 0.097204, loss_ce: 0.008010
[01:48:36.230] iteration 15233 : loss : 0.207293, loss_ce: 0.008122
[01:48:36.540] iteration 15234 : loss : 0.078003, loss_ce: 0.015776
[01:48:36.848] iteration 15235 : loss : 0.158764, loss_ce: 0.007873
[01:48:37.160] iteration 15236 : loss : 0.061612, loss_ce: 0.016374
[01:48:37.467] iteration 15237 : loss : 0.043478, loss_ce: 0.016076
[01:48:37.777] iteration 15238 : loss : 0.031226, loss_ce: 0.008569
[01:48:38.083] iteration 15239 : loss : 0.055074, loss_ce: 0.018090
[01:48:38.390] iteration 15240 : loss : 0.056001, loss_ce: 0.016193
[01:48:38.713] iteration 15241 : loss : 0.054961, loss_ce: 0.020513
[01:48:39.017] iteration 15242 : loss : 0.051150, loss_ce: 0.009156
[01:48:39.327] iteration 15243 : loss : 0.047823, loss_ce: 0.020628
[01:48:39.635] iteration 15244 : loss : 0.108124, loss_ce: 0.011542
[01:48:39.937] iteration 15245 : loss : 0.075661, loss_ce: 0.011404
[01:48:40.247] iteration 15246 : loss : 0.046390, loss_ce: 0.021261
[01:48:40.556] iteration 15247 : loss : 0.043410, loss_ce: 0.008944
[01:48:40.859] iteration 15248 : loss : 0.044347, loss_ce: 0.012037
[01:48:41.170] iteration 15249 : loss : 0.051378, loss_ce: 0.008751
[01:48:41.477] iteration 15250 : loss : 0.070992, loss_ce: 0.020497
[01:48:41.786] iteration 15251 : loss : 0.049274, loss_ce: 0.018645
[01:48:42.094] iteration 15252 : loss : 0.058083, loss_ce: 0.017771
[01:48:42.402] iteration 15253 : loss : 0.050541, loss_ce: 0.010791
[01:48:42.711] iteration 15254 : loss : 0.060521, loss_ce: 0.019220
[01:48:43.015] iteration 15255 : loss : 0.045115, loss_ce: 0.015382
[01:48:43.324] iteration 15256 : loss : 0.051934, loss_ce: 0.012271
[01:48:43.629] iteration 15257 : loss : 0.168052, loss_ce: 0.003663
[01:48:43.935] iteration 15258 : loss : 0.052206, loss_ce: 0.015415
[01:48:44.241] iteration 15259 : loss : 0.037181, loss_ce: 0.005119
[01:48:44.553] iteration 15260 : loss : 0.051072, loss_ce: 0.011323
[01:48:44.873] iteration 15261 : loss : 0.051822, loss_ce: 0.012803
[01:48:45.181] iteration 15262 : loss : 0.039673, loss_ce: 0.010891
[01:48:45.490] iteration 15263 : loss : 0.039923, loss_ce: 0.007976
[01:48:45.801] iteration 15264 : loss : 0.043892, loss_ce: 0.015289
[01:48:46.106] iteration 15265 : loss : 0.042783, loss_ce: 0.009410
[01:48:46.416] iteration 15266 : loss : 0.041165, loss_ce: 0.012755
[01:48:46.723] iteration 15267 : loss : 0.059969, loss_ce: 0.019583
[01:48:47.027] iteration 15268 : loss : 0.048289, loss_ce: 0.009451
[01:48:47.339] iteration 15269 : loss : 0.048308, loss_ce: 0.021265
[01:48:47.649] iteration 15270 : loss : 0.123061, loss_ce: 0.017671
[01:48:47.956] iteration 15271 : loss : 0.047098, loss_ce: 0.019757
[01:48:48.263] iteration 15272 : loss : 0.051113, loss_ce: 0.020341
[01:48:48.569] iteration 15273 : loss : 0.041995, loss_ce: 0.011378
[01:48:48.883] iteration 15274 : loss : 0.040146, loss_ce: 0.017728
[01:48:49.198] iteration 15275 : loss : 0.045140, loss_ce: 0.015791
[01:48:49.509] iteration 15276 : loss : 0.111986, loss_ce: 0.013742
[01:48:49.815] iteration 15277 : loss : 0.053846, loss_ce: 0.018040
[01:48:50.126] iteration 15278 : loss : 0.051953, loss_ce: 0.011310
[01:48:50.434] iteration 15279 : loss : 0.066975, loss_ce: 0.015754
[01:48:50.749] iteration 15280 : loss : 0.044142, loss_ce: 0.016811
[01:48:51.090] iteration 15281 : loss : 0.101986, loss_ce: 0.010787
[01:48:51.392] iteration 15282 : loss : 0.056182, loss_ce: 0.022691
[01:48:51.707] iteration 15283 : loss : 0.106198, loss_ce: 0.007377
[01:48:52.023] iteration 15284 : loss : 0.058518, loss_ce: 0.014111
[01:48:52.335] iteration 15285 : loss : 0.041828, loss_ce: 0.007951
[01:48:52.645] iteration 15286 : loss : 0.054869, loss_ce: 0.018807
[01:48:52.955] iteration 15287 : loss : 0.060864, loss_ce: 0.026819
[01:48:53.271] iteration 15288 : loss : 0.055350, loss_ce: 0.018292
[01:48:53.576] iteration 15289 : loss : 0.101313, loss_ce: 0.008290
[01:48:53.669] iteration 15290 : loss : 0.225784, loss_ce: 0.016691
[01:49:11.049] iteration 15291 : loss : 0.039880, loss_ce: 0.016451
[01:49:11.354] iteration 15292 : loss : 0.044823, loss_ce: 0.021256
[01:49:11.662] iteration 15293 : loss : 0.043890, loss_ce: 0.016949
[01:49:11.963] iteration 15294 : loss : 0.093560, loss_ce: 0.011013
[01:49:12.265] iteration 15295 : loss : 0.042725, loss_ce: 0.008254
[01:49:12.565] iteration 15296 : loss : 0.075975, loss_ce: 0.012105
[01:49:12.864] iteration 15297 : loss : 0.111585, loss_ce: 0.008219
[01:49:13.166] iteration 15298 : loss : 0.050926, loss_ce: 0.014414
[01:49:13.468] iteration 15299 : loss : 0.043284, loss_ce: 0.012208
[01:49:13.771] iteration 15300 : loss : 0.072947, loss_ce: 0.007703
[01:49:14.086] iteration 15301 : loss : 0.054309, loss_ce: 0.012871
[01:49:14.389] iteration 15302 : loss : 0.040515, loss_ce: 0.014183
[01:49:14.695] iteration 15303 : loss : 0.103348, loss_ce: 0.007800
[01:49:15.000] iteration 15304 : loss : 0.041372, loss_ce: 0.010194
[01:49:15.307] iteration 15305 : loss : 0.175433, loss_ce: 0.014648
[01:49:15.615] iteration 15306 : loss : 0.046092, loss_ce: 0.014974
[01:49:15.922] iteration 15307 : loss : 0.038385, loss_ce: 0.007778
[01:49:16.226] iteration 15308 : loss : 0.107460, loss_ce: 0.008410
[01:49:16.532] iteration 15309 : loss : 0.045085, loss_ce: 0.018870
[01:49:16.837] iteration 15310 : loss : 0.060097, loss_ce: 0.012421
[01:49:17.139] iteration 15311 : loss : 0.162752, loss_ce: 0.005088
[01:49:17.448] iteration 15312 : loss : 0.046971, loss_ce: 0.005685
[01:49:17.761] iteration 15313 : loss : 0.051897, loss_ce: 0.013962
[01:49:18.071] iteration 15314 : loss : 0.051662, loss_ce: 0.024920
[01:49:18.383] iteration 15315 : loss : 0.104215, loss_ce: 0.009430
[01:49:18.696] iteration 15316 : loss : 0.046580, loss_ce: 0.014052
[01:49:19.000] iteration 15317 : loss : 0.044932, loss_ce: 0.015392
[01:49:19.306] iteration 15318 : loss : 0.053642, loss_ce: 0.014358
[01:49:19.604] iteration 15319 : loss : 0.108005, loss_ce: 0.014439
[01:49:19.909] iteration 15320 : loss : 0.037348, loss_ce: 0.016383
[01:49:20.231] iteration 15321 : loss : 0.054521, loss_ce: 0.023400
[01:49:20.534] iteration 15322 : loss : 0.103981, loss_ce: 0.012648
[01:49:20.837] iteration 15323 : loss : 0.041883, loss_ce: 0.014981
[01:49:21.139] iteration 15324 : loss : 0.066777, loss_ce: 0.013566
[01:49:21.439] iteration 15325 : loss : 0.222708, loss_ce: 0.008170
[01:49:21.744] iteration 15326 : loss : 0.282598, loss_ce: 0.006075
[01:49:22.049] iteration 15327 : loss : 0.047660, loss_ce: 0.009377
[01:49:22.352] iteration 15328 : loss : 0.108681, loss_ce: 0.014552
[01:49:22.655] iteration 15329 : loss : 0.041881, loss_ce: 0.008116
[01:49:22.958] iteration 15330 : loss : 0.054474, loss_ce: 0.019842
[01:49:23.259] iteration 15331 : loss : 0.048356, loss_ce: 0.016921
[01:49:23.561] iteration 15332 : loss : 0.045055, loss_ce: 0.016247
[01:49:23.862] iteration 15333 : loss : 0.104659, loss_ce: 0.013974
[01:49:24.161] iteration 15334 : loss : 0.062616, loss_ce: 0.012341
[01:49:24.464] iteration 15335 : loss : 0.052800, loss_ce: 0.015465
[01:49:24.765] iteration 15336 : loss : 0.037482, loss_ce: 0.010751
[01:49:25.070] iteration 15337 : loss : 0.054119, loss_ce: 0.023714
[01:49:25.373] iteration 15338 : loss : 0.041445, loss_ce: 0.009900
[01:49:25.674] iteration 15339 : loss : 0.037584, loss_ce: 0.011009
[01:49:25.979] iteration 15340 : loss : 0.052295, loss_ce: 0.010193
[01:49:26.297] iteration 15341 : loss : 0.046145, loss_ce: 0.023543
[01:49:26.597] iteration 15342 : loss : 0.046178, loss_ce: 0.018059
[01:49:26.901] iteration 15343 : loss : 0.046680, loss_ce: 0.014290
[01:49:27.205] iteration 15344 : loss : 0.056072, loss_ce: 0.015087
[01:49:27.508] iteration 15345 : loss : 0.049651, loss_ce: 0.014544
[01:49:27.808] iteration 15346 : loss : 0.046893, loss_ce: 0.018500
[01:49:28.113] iteration 15347 : loss : 0.049235, loss_ce: 0.013596
[01:49:28.413] iteration 15348 : loss : 0.048278, loss_ce: 0.022252
[01:49:28.716] iteration 15349 : loss : 0.111018, loss_ce: 0.011834
[01:49:29.018] iteration 15350 : loss : 0.049549, loss_ce: 0.017912
[01:49:29.322] iteration 15351 : loss : 0.046441, loss_ce: 0.008519
[01:49:29.625] iteration 15352 : loss : 0.092388, loss_ce: 0.006939
[01:49:29.928] iteration 15353 : loss : 0.051136, loss_ce: 0.013609
[01:49:30.233] iteration 15354 : loss : 0.044946, loss_ce: 0.013934
[01:49:30.537] iteration 15355 : loss : 0.052261, loss_ce: 0.015887
[01:49:30.842] iteration 15356 : loss : 0.065439, loss_ce: 0.016391
[01:49:31.146] iteration 15357 : loss : 0.159625, loss_ce: 0.010043
[01:49:31.451] iteration 15358 : loss : 0.047876, loss_ce: 0.014519
[01:49:31.755] iteration 15359 : loss : 0.048178, loss_ce: 0.018504
[01:49:32.058] iteration 15360 : loss : 0.053487, loss_ce: 0.011523
[01:49:32.379] iteration 15361 : loss : 0.053201, loss_ce: 0.012146
[01:49:32.686] iteration 15362 : loss : 0.044503, loss_ce: 0.012445
[01:49:32.996] iteration 15363 : loss : 0.035898, loss_ce: 0.015847
[01:49:33.302] iteration 15364 : loss : 0.059033, loss_ce: 0.011381
[01:49:33.609] iteration 15365 : loss : 0.063150, loss_ce: 0.014175
[01:49:33.916] iteration 15366 : loss : 0.044842, loss_ce: 0.013201
[01:49:34.222] iteration 15367 : loss : 0.048216, loss_ce: 0.007682
[01:49:34.531] iteration 15368 : loss : 0.049819, loss_ce: 0.016834
[01:49:34.839] iteration 15369 : loss : 0.101091, loss_ce: 0.014624
[01:49:35.146] iteration 15370 : loss : 0.042814, loss_ce: 0.016744
[01:49:35.455] iteration 15371 : loss : 0.133592, loss_ce: 0.010364
[01:49:35.763] iteration 15372 : loss : 0.072804, loss_ce: 0.015438
[01:49:36.075] iteration 15373 : loss : 0.285542, loss_ce: 0.007895
[01:49:36.380] iteration 15374 : loss : 0.042591, loss_ce: 0.011524
[01:49:36.692] iteration 15375 : loss : 0.042656, loss_ce: 0.012299
[01:49:36.999] iteration 15376 : loss : 0.051856, loss_ce: 0.017048
[01:49:37.313] iteration 15377 : loss : 0.051221, loss_ce: 0.015575
[01:49:37.617] iteration 15378 : loss : 0.044330, loss_ce: 0.013823
[01:49:37.924] iteration 15379 : loss : 0.066709, loss_ce: 0.016630
[01:49:38.231] iteration 15380 : loss : 0.113719, loss_ce: 0.009085
[01:49:38.559] iteration 15381 : loss : 0.052627, loss_ce: 0.010928
[01:49:38.865] iteration 15382 : loss : 0.046616, loss_ce: 0.015945
[01:49:39.173] iteration 15383 : loss : 0.042428, loss_ce: 0.019789
[01:49:39.483] iteration 15384 : loss : 0.044282, loss_ce: 0.014507
[01:49:39.790] iteration 15385 : loss : 0.043362, loss_ce: 0.016528
[01:49:40.098] iteration 15386 : loss : 0.044555, loss_ce: 0.013616
[01:49:40.406] iteration 15387 : loss : 0.059204, loss_ce: 0.010493
[01:49:40.716] iteration 15388 : loss : 0.165885, loss_ce: 0.009702
[01:49:41.024] iteration 15389 : loss : 0.059809, loss_ce: 0.015431
[01:49:41.337] iteration 15390 : loss : 0.046172, loss_ce: 0.011215
[01:49:41.643] iteration 15391 : loss : 0.105411, loss_ce: 0.018092
[01:49:41.955] iteration 15392 : loss : 0.111887, loss_ce: 0.012637
[01:49:42.259] iteration 15393 : loss : 0.036013, loss_ce: 0.009931
[01:49:42.569] iteration 15394 : loss : 0.103146, loss_ce: 0.014102
[01:49:42.878] iteration 15395 : loss : 0.054678, loss_ce: 0.019597
[01:49:43.189] iteration 15396 : loss : 0.041876, loss_ce: 0.012255
[01:49:43.495] iteration 15397 : loss : 0.033178, loss_ce: 0.016121
[01:49:43.806] iteration 15398 : loss : 0.040946, loss_ce: 0.008369
[01:49:44.113] iteration 15399 : loss : 0.053319, loss_ce: 0.026750
[01:49:44.424] iteration 15400 : loss : 0.046439, loss_ce: 0.011076
[01:49:44.745] iteration 15401 : loss : 0.062755, loss_ce: 0.024557
[01:49:45.056] iteration 15402 : loss : 0.078299, loss_ce: 0.014881
[01:49:45.363] iteration 15403 : loss : 0.034413, loss_ce: 0.007756
[01:49:45.672] iteration 15404 : loss : 0.040298, loss_ce: 0.009244
[01:49:45.979] iteration 15405 : loss : 0.044335, loss_ce: 0.005173
[01:49:46.290] iteration 15406 : loss : 0.068529, loss_ce: 0.032845
[01:49:46.595] iteration 15407 : loss : 0.050897, loss_ce: 0.013036
[01:49:46.901] iteration 15408 : loss : 0.053944, loss_ce: 0.026650
[01:49:47.213] iteration 15409 : loss : 0.038268, loss_ce: 0.014739
[01:49:47.519] iteration 15410 : loss : 0.046144, loss_ce: 0.015685
[01:49:47.827] iteration 15411 : loss : 0.046123, loss_ce: 0.019087
[01:49:48.135] iteration 15412 : loss : 0.111455, loss_ce: 0.004808
[01:49:48.448] iteration 15413 : loss : 0.036729, loss_ce: 0.011819
[01:49:48.759] iteration 15414 : loss : 0.034038, loss_ce: 0.011758
[01:49:49.073] iteration 15415 : loss : 0.039652, loss_ce: 0.014507
[01:49:49.389] iteration 15416 : loss : 0.047881, loss_ce: 0.013380
[01:49:49.698] iteration 15417 : loss : 0.063912, loss_ce: 0.007615
[01:49:50.007] iteration 15418 : loss : 0.048064, loss_ce: 0.014546
[01:49:50.320] iteration 15419 : loss : 0.050753, loss_ce: 0.015293
[01:49:50.636] iteration 15420 : loss : 0.045136, loss_ce: 0.015930
[01:49:50.983] iteration 15421 : loss : 0.047224, loss_ce: 0.010247
[01:49:51.290] iteration 15422 : loss : 0.043518, loss_ce: 0.015778
[01:49:51.604] iteration 15423 : loss : 0.165984, loss_ce: 0.009051
[01:49:51.919] iteration 15424 : loss : 0.066663, loss_ce: 0.015631
[01:49:52.229] iteration 15425 : loss : 0.052974, loss_ce: 0.021694
[01:49:52.536] iteration 15426 : loss : 0.099220, loss_ce: 0.010458
[01:49:52.846] iteration 15427 : loss : 0.041208, loss_ce: 0.007968
[01:49:53.157] iteration 15428 : loss : 0.042384, loss_ce: 0.015590
[01:49:53.236] iteration 15429 : loss : 0.057567, loss_ce: 0.041733
[01:50:12.230] iteration 15430 : loss : 0.046649, loss_ce: 0.014054
[01:50:12.529] iteration 15431 : loss : 0.116333, loss_ce: 0.008363
[01:50:12.831] iteration 15432 : loss : 0.051331, loss_ce: 0.012990
[01:50:13.133] iteration 15433 : loss : 0.056016, loss_ce: 0.014345
[01:50:13.439] iteration 15434 : loss : 0.053282, loss_ce: 0.019481
[01:50:13.742] iteration 15435 : loss : 0.048495, loss_ce: 0.008785
[01:50:14.044] iteration 15436 : loss : 0.108924, loss_ce: 0.010879
[01:50:14.345] iteration 15437 : loss : 0.045501, loss_ce: 0.010987
[01:50:14.647] iteration 15438 : loss : 0.049503, loss_ce: 0.015871
[01:50:14.948] iteration 15439 : loss : 0.055672, loss_ce: 0.014681
[01:50:15.251] iteration 15440 : loss : 0.095732, loss_ce: 0.008608
[01:50:15.569] iteration 15441 : loss : 0.081176, loss_ce: 0.009842
[01:50:15.874] iteration 15442 : loss : 0.049579, loss_ce: 0.019829
[01:50:16.177] iteration 15443 : loss : 0.045423, loss_ce: 0.014113
[01:50:16.479] iteration 15444 : loss : 0.055693, loss_ce: 0.012251
[01:50:16.781] iteration 15445 : loss : 0.036190, loss_ce: 0.012895
[01:50:17.081] iteration 15446 : loss : 0.097574, loss_ce: 0.006544
[01:50:17.384] iteration 15447 : loss : 0.104668, loss_ce: 0.011258
[01:50:17.692] iteration 15448 : loss : 0.047624, loss_ce: 0.024384
[01:50:17.996] iteration 15449 : loss : 0.113125, loss_ce: 0.015428
[01:50:18.295] iteration 15450 : loss : 0.045615, loss_ce: 0.010563
[01:50:18.604] iteration 15451 : loss : 0.056296, loss_ce: 0.005680
[01:50:18.906] iteration 15452 : loss : 0.050921, loss_ce: 0.009297
[01:50:19.208] iteration 15453 : loss : 0.052953, loss_ce: 0.013044
[01:50:19.512] iteration 15454 : loss : 0.287003, loss_ce: 0.013705
[01:50:19.815] iteration 15455 : loss : 0.048597, loss_ce: 0.012957
[01:50:20.116] iteration 15456 : loss : 0.166691, loss_ce: 0.005617
[01:50:20.422] iteration 15457 : loss : 0.103983, loss_ce: 0.010504
[01:50:20.725] iteration 15458 : loss : 0.051753, loss_ce: 0.008123
[01:50:21.027] iteration 15459 : loss : 0.044298, loss_ce: 0.014929
[01:50:21.329] iteration 15460 : loss : 0.085037, loss_ce: 0.007979
[01:50:21.642] iteration 15461 : loss : 0.052952, loss_ce: 0.017763
[01:50:21.948] iteration 15462 : loss : 0.044083, loss_ce: 0.015773
[01:50:22.256] iteration 15463 : loss : 0.048827, loss_ce: 0.008015
[01:50:22.566] iteration 15464 : loss : 0.047548, loss_ce: 0.010567
[01:50:22.871] iteration 15465 : loss : 0.045850, loss_ce: 0.016949
[01:50:23.184] iteration 15466 : loss : 0.051445, loss_ce: 0.006646
[01:50:23.499] iteration 15467 : loss : 0.052435, loss_ce: 0.017436
[01:50:23.805] iteration 15468 : loss : 0.055345, loss_ce: 0.027219
[01:50:24.118] iteration 15469 : loss : 0.055873, loss_ce: 0.024082
[01:50:24.429] iteration 15470 : loss : 0.038661, loss_ce: 0.011609
[01:50:24.739] iteration 15471 : loss : 0.056949, loss_ce: 0.016679
[01:50:25.040] iteration 15472 : loss : 0.045932, loss_ce: 0.017991
[01:50:25.343] iteration 15473 : loss : 0.106143, loss_ce: 0.009352
[01:50:25.647] iteration 15474 : loss : 0.037951, loss_ce: 0.004712
[01:50:25.951] iteration 15475 : loss : 0.113743, loss_ce: 0.012907
[01:50:26.258] iteration 15476 : loss : 0.050894, loss_ce: 0.015148
[01:50:26.562] iteration 15477 : loss : 0.066224, loss_ce: 0.023489
[01:50:26.866] iteration 15478 : loss : 0.099103, loss_ce: 0.006472
[01:50:27.170] iteration 15479 : loss : 0.056508, loss_ce: 0.013011
[01:50:27.474] iteration 15480 : loss : 0.047830, loss_ce: 0.023807
[01:50:27.791] iteration 15481 : loss : 0.164895, loss_ce: 0.013084
[01:50:28.092] iteration 15482 : loss : 0.052795, loss_ce: 0.009791
[01:50:28.399] iteration 15483 : loss : 0.053146, loss_ce: 0.019928
[01:50:28.703] iteration 15484 : loss : 0.048127, loss_ce: 0.014002
[01:50:29.008] iteration 15485 : loss : 0.166992, loss_ce: 0.010249
[01:50:29.310] iteration 15486 : loss : 0.062390, loss_ce: 0.022421
[01:50:29.617] iteration 15487 : loss : 0.046992, loss_ce: 0.018232
[01:50:29.921] iteration 15488 : loss : 0.048243, loss_ce: 0.013079
[01:50:30.222] iteration 15489 : loss : 0.045371, loss_ce: 0.020705
[01:50:30.528] iteration 15490 : loss : 0.040873, loss_ce: 0.016140
[01:50:30.834] iteration 15491 : loss : 0.166316, loss_ce: 0.005504
[01:50:31.138] iteration 15492 : loss : 0.049287, loss_ce: 0.020693
[01:50:31.440] iteration 15493 : loss : 0.100330, loss_ce: 0.007975
[01:50:31.746] iteration 15494 : loss : 0.053378, loss_ce: 0.012885
[01:50:32.056] iteration 15495 : loss : 0.044347, loss_ce: 0.011682
[01:50:32.360] iteration 15496 : loss : 0.117421, loss_ce: 0.017635
[01:50:32.663] iteration 15497 : loss : 0.102590, loss_ce: 0.011653
[01:50:32.971] iteration 15498 : loss : 0.043947, loss_ce: 0.013907
[01:50:33.279] iteration 15499 : loss : 0.041518, loss_ce: 0.009107
[01:50:33.585] iteration 15500 : loss : 0.111459, loss_ce: 0.004117
[01:50:33.897] iteration 15501 : loss : 0.129928, loss_ce: 0.011883
[01:50:34.202] iteration 15502 : loss : 0.048722, loss_ce: 0.006388
[01:50:34.507] iteration 15503 : loss : 0.050766, loss_ce: 0.018099
[01:50:34.810] iteration 15504 : loss : 0.037381, loss_ce: 0.013373
[01:50:35.113] iteration 15505 : loss : 0.075772, loss_ce: 0.015291
[01:50:35.419] iteration 15506 : loss : 0.113164, loss_ce: 0.019239
[01:50:35.724] iteration 15507 : loss : 0.048069, loss_ce: 0.020335
[01:50:36.032] iteration 15508 : loss : 0.076754, loss_ce: 0.017510
[01:50:36.336] iteration 15509 : loss : 0.054341, loss_ce: 0.014248
[01:50:36.642] iteration 15510 : loss : 0.057428, loss_ce: 0.011215
[01:50:36.945] iteration 15511 : loss : 0.114018, loss_ce: 0.007946
[01:50:37.246] iteration 15512 : loss : 0.051626, loss_ce: 0.015730
[01:50:37.554] iteration 15513 : loss : 0.043006, loss_ce: 0.017129
[01:50:37.860] iteration 15514 : loss : 0.039357, loss_ce: 0.015075
[01:50:38.170] iteration 15515 : loss : 0.056122, loss_ce: 0.020653
[01:50:38.478] iteration 15516 : loss : 0.048403, loss_ce: 0.012036
[01:50:38.784] iteration 15517 : loss : 0.046758, loss_ce: 0.017679
[01:50:39.091] iteration 15518 : loss : 0.107364, loss_ce: 0.010562
[01:50:39.399] iteration 15519 : loss : 0.045195, loss_ce: 0.008353
[01:50:39.705] iteration 15520 : loss : 0.043750, loss_ce: 0.010807
[01:50:40.028] iteration 15521 : loss : 0.105746, loss_ce: 0.006731
[01:50:40.333] iteration 15522 : loss : 0.076486, loss_ce: 0.021363
[01:50:40.641] iteration 15523 : loss : 0.051061, loss_ce: 0.013857
[01:50:40.951] iteration 15524 : loss : 0.108787, loss_ce: 0.008014
[01:50:41.257] iteration 15525 : loss : 0.039092, loss_ce: 0.013103
[01:50:41.562] iteration 15526 : loss : 0.048322, loss_ce: 0.016024
[01:50:41.872] iteration 15527 : loss : 0.161405, loss_ce: 0.006396
[01:50:42.180] iteration 15528 : loss : 0.047616, loss_ce: 0.024307
[01:50:42.491] iteration 15529 : loss : 0.051399, loss_ce: 0.018231
[01:50:42.801] iteration 15530 : loss : 0.096964, loss_ce: 0.015788
[01:50:43.111] iteration 15531 : loss : 0.045242, loss_ce: 0.014875
[01:50:43.418] iteration 15532 : loss : 0.043285, loss_ce: 0.018169
[01:50:43.727] iteration 15533 : loss : 0.050695, loss_ce: 0.020797
[01:50:44.033] iteration 15534 : loss : 0.061282, loss_ce: 0.013980
[01:50:44.344] iteration 15535 : loss : 0.044528, loss_ce: 0.015752
[01:50:44.651] iteration 15536 : loss : 0.037514, loss_ce: 0.013544
[01:50:44.960] iteration 15537 : loss : 0.051346, loss_ce: 0.020258
[01:50:45.273] iteration 15538 : loss : 0.047723, loss_ce: 0.020585
[01:50:45.583] iteration 15539 : loss : 0.166022, loss_ce: 0.004160
[01:50:45.892] iteration 15540 : loss : 0.058350, loss_ce: 0.022928
[01:50:46.216] iteration 15541 : loss : 0.054051, loss_ce: 0.016085
[01:50:46.529] iteration 15542 : loss : 0.042162, loss_ce: 0.009452
[01:50:46.835] iteration 15543 : loss : 0.104972, loss_ce: 0.012447
[01:50:47.149] iteration 15544 : loss : 0.049552, loss_ce: 0.014085
[01:50:47.461] iteration 15545 : loss : 0.108477, loss_ce: 0.014295
[01:50:47.768] iteration 15546 : loss : 0.045067, loss_ce: 0.017532
[01:50:48.080] iteration 15547 : loss : 0.036193, loss_ce: 0.013576
[01:50:48.390] iteration 15548 : loss : 0.045613, loss_ce: 0.016685
[01:50:48.699] iteration 15549 : loss : 0.047391, loss_ce: 0.012925
[01:50:49.010] iteration 15550 : loss : 0.039244, loss_ce: 0.012970
[01:50:49.317] iteration 15551 : loss : 0.045337, loss_ce: 0.023682
[01:50:49.632] iteration 15552 : loss : 0.039960, loss_ce: 0.011097
[01:50:49.938] iteration 15553 : loss : 0.037960, loss_ce: 0.009206
[01:50:50.254] iteration 15554 : loss : 0.040979, loss_ce: 0.014052
[01:50:50.567] iteration 15555 : loss : 0.036304, loss_ce: 0.010837
[01:50:50.876] iteration 15556 : loss : 0.054118, loss_ce: 0.019988
[01:50:51.190] iteration 15557 : loss : 0.045667, loss_ce: 0.012959
[01:50:51.505] iteration 15558 : loss : 0.044128, loss_ce: 0.019731
[01:50:51.821] iteration 15559 : loss : 0.050469, loss_ce: 0.016272
[01:50:52.131] iteration 15560 : loss : 0.040362, loss_ce: 0.017025
[01:50:52.458] iteration 15561 : loss : 0.038040, loss_ce: 0.009149
[01:50:52.772] iteration 15562 : loss : 0.048169, loss_ce: 0.011493
[01:50:53.090] iteration 15563 : loss : 0.036407, loss_ce: 0.004979
[01:50:53.399] iteration 15564 : loss : 0.043802, loss_ce: 0.020002
[01:50:53.713] iteration 15565 : loss : 0.041759, loss_ce: 0.011068
[01:50:54.028] iteration 15566 : loss : 0.107293, loss_ce: 0.008747
[01:50:54.342] iteration 15567 : loss : 0.051224, loss_ce: 0.013201
[01:50:54.430] iteration 15568 : loss : 0.191203, loss_ce: 0.000561
[01:51:11.921] iteration 15569 : loss : 0.051767, loss_ce: 0.017420
[01:51:12.225] iteration 15570 : loss : 0.106555, loss_ce: 0.013315
[01:51:12.528] iteration 15571 : loss : 0.037065, loss_ce: 0.010809
[01:51:12.836] iteration 15572 : loss : 0.046800, loss_ce: 0.013573
[01:51:13.143] iteration 15573 : loss : 0.069392, loss_ce: 0.013160
[01:51:13.455] iteration 15574 : loss : 0.156474, loss_ce: 0.005640
[01:51:13.761] iteration 15575 : loss : 0.053819, loss_ce: 0.018299
[01:51:14.069] iteration 15576 : loss : 0.053323, loss_ce: 0.018557
[01:51:14.375] iteration 15577 : loss : 0.101342, loss_ce: 0.013728
[01:51:14.681] iteration 15578 : loss : 0.042885, loss_ce: 0.011977
[01:51:14.983] iteration 15579 : loss : 0.068682, loss_ce: 0.015400
[01:51:15.287] iteration 15580 : loss : 0.063246, loss_ce: 0.017878
[01:51:15.606] iteration 15581 : loss : 0.102028, loss_ce: 0.009364
[01:51:15.909] iteration 15582 : loss : 0.039465, loss_ce: 0.017914
[01:51:16.215] iteration 15583 : loss : 0.099878, loss_ce: 0.010912
[01:51:16.518] iteration 15584 : loss : 0.110334, loss_ce: 0.005571
[01:51:16.824] iteration 15585 : loss : 0.042728, loss_ce: 0.013960
[01:51:17.129] iteration 15586 : loss : 0.049636, loss_ce: 0.012669
[01:51:17.434] iteration 15587 : loss : 0.056452, loss_ce: 0.017526
[01:51:17.737] iteration 15588 : loss : 0.053016, loss_ce: 0.021931
[01:51:18.039] iteration 15589 : loss : 0.034078, loss_ce: 0.005596
[01:51:18.345] iteration 15590 : loss : 0.052608, loss_ce: 0.013039
[01:51:18.648] iteration 15591 : loss : 0.052341, loss_ce: 0.017631
[01:51:18.951] iteration 15592 : loss : 0.116846, loss_ce: 0.007037
[01:51:19.259] iteration 15593 : loss : 0.060872, loss_ce: 0.017032
[01:51:19.562] iteration 15594 : loss : 0.049840, loss_ce: 0.018378
[01:51:19.873] iteration 15595 : loss : 0.101747, loss_ce: 0.007839
[01:51:20.178] iteration 15596 : loss : 0.051993, loss_ce: 0.015497
[01:51:20.483] iteration 15597 : loss : 0.065847, loss_ce: 0.020314
[01:51:20.784] iteration 15598 : loss : 0.048039, loss_ce: 0.008461
[01:51:21.085] iteration 15599 : loss : 0.043455, loss_ce: 0.015408
[01:51:21.387] iteration 15600 : loss : 0.042297, loss_ce: 0.010120
[01:51:21.712] iteration 15601 : loss : 0.041224, loss_ce: 0.013056
[01:51:22.016] iteration 15602 : loss : 0.055850, loss_ce: 0.011464
[01:51:22.316] iteration 15603 : loss : 0.047369, loss_ce: 0.011244
[01:51:22.619] iteration 15604 : loss : 0.051647, loss_ce: 0.013791
[01:51:22.924] iteration 15605 : loss : 0.037911, loss_ce: 0.012862
[01:51:23.226] iteration 15606 : loss : 0.217193, loss_ce: 0.007854
[01:51:23.532] iteration 15607 : loss : 0.048791, loss_ce: 0.016873
[01:51:23.835] iteration 15608 : loss : 0.048449, loss_ce: 0.013807
[01:51:24.137] iteration 15609 : loss : 0.110388, loss_ce: 0.015156
[01:51:24.445] iteration 15610 : loss : 0.054399, loss_ce: 0.017880
[01:51:24.749] iteration 15611 : loss : 0.044322, loss_ce: 0.017580
[01:51:25.051] iteration 15612 : loss : 0.103504, loss_ce: 0.014740
[01:51:25.357] iteration 15613 : loss : 0.039615, loss_ce: 0.016243
[01:51:25.661] iteration 15614 : loss : 0.057066, loss_ce: 0.015850
[01:51:25.963] iteration 15615 : loss : 0.044599, loss_ce: 0.012270
[01:51:26.268] iteration 15616 : loss : 0.165368, loss_ce: 0.012369
[01:51:26.570] iteration 15617 : loss : 0.156585, loss_ce: 0.007284
[01:51:26.874] iteration 15618 : loss : 0.051017, loss_ce: 0.014751
[01:51:27.179] iteration 15619 : loss : 0.053049, loss_ce: 0.019139
[01:51:27.484] iteration 15620 : loss : 0.043917, loss_ce: 0.011807
[01:51:27.801] iteration 15621 : loss : 0.046639, loss_ce: 0.026576
[01:51:28.104] iteration 15622 : loss : 0.161414, loss_ce: 0.004197
[01:51:28.417] iteration 15623 : loss : 0.040895, loss_ce: 0.017186
[01:51:28.720] iteration 15624 : loss : 0.041719, loss_ce: 0.019925
[01:51:29.023] iteration 15625 : loss : 0.042322, loss_ce: 0.018174
[01:51:29.332] iteration 15626 : loss : 0.091275, loss_ce: 0.017486
[01:51:29.635] iteration 15627 : loss : 0.053296, loss_ce: 0.016265
[01:51:29.940] iteration 15628 : loss : 0.107952, loss_ce: 0.014702
[01:51:30.250] iteration 15629 : loss : 0.049605, loss_ce: 0.008942
[01:51:30.561] iteration 15630 : loss : 0.081765, loss_ce: 0.011224
[01:51:30.866] iteration 15631 : loss : 0.054228, loss_ce: 0.015681
[01:51:31.173] iteration 15632 : loss : 0.036506, loss_ce: 0.007030
[01:51:31.480] iteration 15633 : loss : 0.042285, loss_ce: 0.016593
[01:51:31.789] iteration 15634 : loss : 0.046045, loss_ce: 0.009345
[01:51:32.098] iteration 15635 : loss : 0.050676, loss_ce: 0.008070
[01:51:32.407] iteration 15636 : loss : 0.095348, loss_ce: 0.017872
[01:51:32.716] iteration 15637 : loss : 0.105142, loss_ce: 0.014550
[01:51:33.022] iteration 15638 : loss : 0.113572, loss_ce: 0.011811
[01:51:33.327] iteration 15639 : loss : 0.234476, loss_ce: 0.002618
[01:51:33.631] iteration 15640 : loss : 0.045395, loss_ce: 0.016931
[01:51:33.955] iteration 15641 : loss : 0.046058, loss_ce: 0.010720
[01:51:34.258] iteration 15642 : loss : 0.037970, loss_ce: 0.015955
[01:51:34.566] iteration 15643 : loss : 0.043526, loss_ce: 0.012548
[01:51:34.875] iteration 15644 : loss : 0.111184, loss_ce: 0.014611
[01:51:35.182] iteration 15645 : loss : 0.045101, loss_ce: 0.017850
[01:51:35.494] iteration 15646 : loss : 0.109235, loss_ce: 0.007254
[01:51:35.801] iteration 15647 : loss : 0.125161, loss_ce: 0.018067
[01:51:36.109] iteration 15648 : loss : 0.043156, loss_ce: 0.007648
[01:51:36.416] iteration 15649 : loss : 0.041232, loss_ce: 0.012646
[01:51:36.721] iteration 15650 : loss : 0.099633, loss_ce: 0.009426
[01:51:37.031] iteration 15651 : loss : 0.109512, loss_ce: 0.019241
[01:51:37.338] iteration 15652 : loss : 0.046462, loss_ce: 0.021885
[01:51:37.646] iteration 15653 : loss : 0.045052, loss_ce: 0.016134
[01:51:37.951] iteration 15654 : loss : 0.047562, loss_ce: 0.017733
[01:51:38.260] iteration 15655 : loss : 0.105787, loss_ce: 0.019408
[01:51:38.570] iteration 15656 : loss : 0.054957, loss_ce: 0.019218
[01:51:38.877] iteration 15657 : loss : 0.051799, loss_ce: 0.017141
[01:51:39.185] iteration 15658 : loss : 0.044011, loss_ce: 0.012848
[01:51:39.494] iteration 15659 : loss : 0.049132, loss_ce: 0.014503
[01:51:39.799] iteration 15660 : loss : 0.050178, loss_ce: 0.009773
[01:51:40.124] iteration 15661 : loss : 0.059354, loss_ce: 0.022878
[01:51:40.428] iteration 15662 : loss : 0.102482, loss_ce: 0.006273
[01:51:40.737] iteration 15663 : loss : 0.044814, loss_ce: 0.017301
[01:51:41.046] iteration 15664 : loss : 0.166447, loss_ce: 0.007515
[01:51:41.354] iteration 15665 : loss : 0.057343, loss_ce: 0.015560
[01:51:41.660] iteration 15666 : loss : 0.065301, loss_ce: 0.008839
[01:51:41.967] iteration 15667 : loss : 0.108228, loss_ce: 0.005722
[01:51:42.272] iteration 15668 : loss : 0.041947, loss_ce: 0.006004
[01:51:42.582] iteration 15669 : loss : 0.052405, loss_ce: 0.019057
[01:51:42.890] iteration 15670 : loss : 0.047635, loss_ce: 0.009792
[01:51:43.199] iteration 15671 : loss : 0.045554, loss_ce: 0.012964
[01:51:43.508] iteration 15672 : loss : 0.160157, loss_ce: 0.004388
[01:51:43.819] iteration 15673 : loss : 0.058298, loss_ce: 0.022868
[01:51:44.126] iteration 15674 : loss : 0.038182, loss_ce: 0.015887
[01:51:44.439] iteration 15675 : loss : 0.078570, loss_ce: 0.012321
[01:51:44.745] iteration 15676 : loss : 0.042704, loss_ce: 0.013955
[01:51:45.055] iteration 15677 : loss : 0.039936, loss_ce: 0.014197
[01:51:45.368] iteration 15678 : loss : 0.048078, loss_ce: 0.010551
[01:51:45.674] iteration 15679 : loss : 0.046671, loss_ce: 0.012128
[01:51:45.985] iteration 15680 : loss : 0.105739, loss_ce: 0.014019
[01:51:46.308] iteration 15681 : loss : 0.048944, loss_ce: 0.018204
[01:51:46.619] iteration 15682 : loss : 0.044019, loss_ce: 0.009236
[01:51:46.934] iteration 15683 : loss : 0.056631, loss_ce: 0.014563
[01:51:47.245] iteration 15684 : loss : 0.039710, loss_ce: 0.012023
[01:51:47.554] iteration 15685 : loss : 0.037366, loss_ce: 0.008967
[01:51:47.866] iteration 15686 : loss : 0.043171, loss_ce: 0.010460
[01:51:48.174] iteration 15687 : loss : 0.063442, loss_ce: 0.012236
[01:51:48.481] iteration 15688 : loss : 0.100589, loss_ce: 0.012417
[01:51:48.791] iteration 15689 : loss : 0.065181, loss_ce: 0.014636
[01:51:49.100] iteration 15690 : loss : 0.051783, loss_ce: 0.016639
[01:51:49.413] iteration 15691 : loss : 0.053272, loss_ce: 0.008046
[01:51:49.725] iteration 15692 : loss : 0.047343, loss_ce: 0.012971
[01:51:50.031] iteration 15693 : loss : 0.047078, loss_ce: 0.017018
[01:51:50.341] iteration 15694 : loss : 0.048695, loss_ce: 0.014626
[01:51:50.652] iteration 15695 : loss : 0.047749, loss_ce: 0.014196
[01:51:50.960] iteration 15696 : loss : 0.046590, loss_ce: 0.016669
[01:51:51.271] iteration 15697 : loss : 0.118260, loss_ce: 0.021519
[01:51:51.575] iteration 15698 : loss : 0.053121, loss_ce: 0.017576
[01:51:51.882] iteration 15699 : loss : 0.123947, loss_ce: 0.015946
[01:51:52.193] iteration 15700 : loss : 0.048574, loss_ce: 0.012163
[01:51:52.515] iteration 15701 : loss : 0.162766, loss_ce: 0.004760
[01:51:52.819] iteration 15702 : loss : 0.042295, loss_ce: 0.023435
[01:51:53.124] iteration 15703 : loss : 0.047184, loss_ce: 0.010747
[01:51:53.429] iteration 15704 : loss : 0.051033, loss_ce: 0.012180
[01:51:53.741] iteration 15705 : loss : 0.033871, loss_ce: 0.007311
[01:51:54.051] iteration 15706 : loss : 0.103578, loss_ce: 0.022904
[01:51:54.130] iteration 15707 : loss : 0.178503, loss_ce: 0.018003
[01:52:11.797] iteration 15708 : loss : 0.099437, loss_ce: 0.021872
[01:52:12.096] iteration 15709 : loss : 0.037899, loss_ce: 0.012144
[01:52:12.398] iteration 15710 : loss : 0.110865, loss_ce: 0.010250
[01:52:12.699] iteration 15711 : loss : 0.046356, loss_ce: 0.022946
[01:52:13.002] iteration 15712 : loss : 0.107844, loss_ce: 0.011770
[01:52:13.302] iteration 15713 : loss : 0.038562, loss_ce: 0.009818
[01:52:13.604] iteration 15714 : loss : 0.045853, loss_ce: 0.016592
[01:52:13.903] iteration 15715 : loss : 0.039693, loss_ce: 0.008543
[01:52:14.202] iteration 15716 : loss : 0.040692, loss_ce: 0.017963
[01:52:14.506] iteration 15717 : loss : 0.036858, loss_ce: 0.018737
[01:52:14.809] iteration 15718 : loss : 0.100140, loss_ce: 0.014304
[01:52:15.110] iteration 15719 : loss : 0.044675, loss_ce: 0.014409
[01:52:15.411] iteration 15720 : loss : 0.032883, loss_ce: 0.012371
[01:52:15.729] iteration 15721 : loss : 0.104859, loss_ce: 0.011561
[01:52:16.032] iteration 15722 : loss : 0.051861, loss_ce: 0.013028
[01:52:16.335] iteration 15723 : loss : 0.038052, loss_ce: 0.018215
[01:52:16.636] iteration 15724 : loss : 0.041903, loss_ce: 0.007100
[01:52:16.940] iteration 15725 : loss : 0.051298, loss_ce: 0.009436
[01:52:17.249] iteration 15726 : loss : 0.048314, loss_ce: 0.020016
[01:52:17.552] iteration 15727 : loss : 0.061446, loss_ce: 0.015203
[01:52:17.865] iteration 15728 : loss : 0.047684, loss_ce: 0.020615
[01:52:18.174] iteration 15729 : loss : 0.038328, loss_ce: 0.006330
[01:52:18.481] iteration 15730 : loss : 0.099094, loss_ce: 0.011196
[01:52:18.787] iteration 15731 : loss : 0.042529, loss_ce: 0.013336
[01:52:19.093] iteration 15732 : loss : 0.043892, loss_ce: 0.009957
[01:52:19.401] iteration 15733 : loss : 0.048014, loss_ce: 0.015217
[01:52:19.702] iteration 15734 : loss : 0.062140, loss_ce: 0.011062
[01:52:20.002] iteration 15735 : loss : 0.050756, loss_ce: 0.015271
[01:52:20.304] iteration 15736 : loss : 0.055207, loss_ce: 0.015549
[01:52:20.607] iteration 15737 : loss : 0.168946, loss_ce: 0.021137
[01:52:20.909] iteration 15738 : loss : 0.055631, loss_ce: 0.014038
[01:52:21.214] iteration 15739 : loss : 0.045010, loss_ce: 0.017949
[01:52:21.515] iteration 15740 : loss : 0.043303, loss_ce: 0.017105
[01:52:21.832] iteration 15741 : loss : 0.028061, loss_ce: 0.004762
[01:52:22.138] iteration 15742 : loss : 0.047808, loss_ce: 0.016775
[01:52:22.443] iteration 15743 : loss : 0.048260, loss_ce: 0.015279
[01:52:22.745] iteration 15744 : loss : 0.047846, loss_ce: 0.014045
[01:52:23.049] iteration 15745 : loss : 0.047509, loss_ce: 0.011665
[01:52:23.353] iteration 15746 : loss : 0.042213, loss_ce: 0.016638
[01:52:23.655] iteration 15747 : loss : 0.058495, loss_ce: 0.010894
[01:52:23.958] iteration 15748 : loss : 0.061725, loss_ce: 0.018564
[01:52:24.261] iteration 15749 : loss : 0.034325, loss_ce: 0.011201
[01:52:24.564] iteration 15750 : loss : 0.046876, loss_ce: 0.008305
[01:52:24.868] iteration 15751 : loss : 0.175066, loss_ce: 0.008685
[01:52:25.170] iteration 15752 : loss : 0.051042, loss_ce: 0.014154
[01:52:25.472] iteration 15753 : loss : 0.051531, loss_ce: 0.018006
[01:52:25.776] iteration 15754 : loss : 0.041263, loss_ce: 0.010231
[01:52:26.078] iteration 15755 : loss : 0.162570, loss_ce: 0.010960
[01:52:26.384] iteration 15756 : loss : 0.151439, loss_ce: 0.003289
[01:52:26.686] iteration 15757 : loss : 0.037392, loss_ce: 0.008852
[01:52:26.992] iteration 15758 : loss : 0.056838, loss_ce: 0.019923
[01:52:27.297] iteration 15759 : loss : 0.040805, loss_ce: 0.013387
[01:52:27.598] iteration 15760 : loss : 0.056592, loss_ce: 0.016672
[01:52:27.916] iteration 15761 : loss : 0.053446, loss_ce: 0.013834
[01:52:28.219] iteration 15762 : loss : 0.050577, loss_ce: 0.014033
[01:52:28.521] iteration 15763 : loss : 0.050106, loss_ce: 0.017285
[01:52:28.822] iteration 15764 : loss : 0.043157, loss_ce: 0.017719
[01:52:29.124] iteration 15765 : loss : 0.105905, loss_ce: 0.016237
[01:52:29.432] iteration 15766 : loss : 0.044683, loss_ce: 0.017326
[01:52:29.737] iteration 15767 : loss : 0.046471, loss_ce: 0.014879
[01:52:30.046] iteration 15768 : loss : 0.044757, loss_ce: 0.011168
[01:52:30.346] iteration 15769 : loss : 0.095281, loss_ce: 0.010237
[01:52:30.649] iteration 15770 : loss : 0.051109, loss_ce: 0.016824
[01:52:30.952] iteration 15771 : loss : 0.042693, loss_ce: 0.008080
[01:52:31.256] iteration 15772 : loss : 0.067744, loss_ce: 0.012415
[01:52:31.558] iteration 15773 : loss : 0.065746, loss_ce: 0.012714
[01:52:31.863] iteration 15774 : loss : 0.033475, loss_ce: 0.008342
[01:52:32.168] iteration 15775 : loss : 0.052133, loss_ce: 0.012421
[01:52:32.475] iteration 15776 : loss : 0.035823, loss_ce: 0.016355
[01:52:32.783] iteration 15777 : loss : 0.058169, loss_ce: 0.018275
[01:52:33.092] iteration 15778 : loss : 0.066250, loss_ce: 0.008592
[01:52:33.402] iteration 15779 : loss : 0.095895, loss_ce: 0.006926
[01:52:33.709] iteration 15780 : loss : 0.050372, loss_ce: 0.026924
[01:52:34.033] iteration 15781 : loss : 0.063101, loss_ce: 0.018782
[01:52:34.339] iteration 15782 : loss : 0.042263, loss_ce: 0.012998
[01:52:34.644] iteration 15783 : loss : 0.050496, loss_ce: 0.014616
[01:52:34.946] iteration 15784 : loss : 0.059029, loss_ce: 0.011297
[01:52:35.249] iteration 15785 : loss : 0.046967, loss_ce: 0.014004
[01:52:35.553] iteration 15786 : loss : 0.043739, loss_ce: 0.015389
[01:52:35.859] iteration 15787 : loss : 0.055717, loss_ce: 0.020919
[01:52:36.163] iteration 15788 : loss : 0.042670, loss_ce: 0.022342
[01:52:36.466] iteration 15789 : loss : 0.045765, loss_ce: 0.012413
[01:52:36.770] iteration 15790 : loss : 0.042172, loss_ce: 0.010364
[01:52:37.075] iteration 15791 : loss : 0.100636, loss_ce: 0.009039
[01:52:37.378] iteration 15792 : loss : 0.037820, loss_ce: 0.012753
[01:52:37.680] iteration 15793 : loss : 0.164358, loss_ce: 0.005253
[01:52:37.983] iteration 15794 : loss : 0.041400, loss_ce: 0.021953
[01:52:38.288] iteration 15795 : loss : 0.076147, loss_ce: 0.015503
[01:52:38.594] iteration 15796 : loss : 0.106655, loss_ce: 0.018127
[01:52:38.899] iteration 15797 : loss : 0.045838, loss_ce: 0.009620
[01:52:39.202] iteration 15798 : loss : 0.050720, loss_ce: 0.013810
[01:52:39.509] iteration 15799 : loss : 0.046838, loss_ce: 0.022584
[01:52:39.812] iteration 15800 : loss : 0.095263, loss_ce: 0.011052
[01:52:40.130] iteration 15801 : loss : 0.117429, loss_ce: 0.011618
[01:52:40.430] iteration 15802 : loss : 0.039269, loss_ce: 0.007171
[01:52:40.735] iteration 15803 : loss : 0.035778, loss_ce: 0.012766
[01:52:41.039] iteration 15804 : loss : 0.110198, loss_ce: 0.016737
[01:52:41.339] iteration 15805 : loss : 0.112594, loss_ce: 0.007646
[01:52:41.646] iteration 15806 : loss : 0.047772, loss_ce: 0.014580
[01:52:41.950] iteration 15807 : loss : 0.103731, loss_ce: 0.007087
[01:52:42.251] iteration 15808 : loss : 0.100819, loss_ce: 0.013685
[01:52:42.554] iteration 15809 : loss : 0.055523, loss_ce: 0.016125
[01:52:42.858] iteration 15810 : loss : 0.072209, loss_ce: 0.014163
[01:52:43.160] iteration 15811 : loss : 0.053478, loss_ce: 0.012266
[01:52:43.463] iteration 15812 : loss : 0.042247, loss_ce: 0.013254
[01:52:43.766] iteration 15813 : loss : 0.042150, loss_ce: 0.012476
[01:52:44.070] iteration 15814 : loss : 0.046752, loss_ce: 0.012449
[01:52:44.373] iteration 15815 : loss : 0.045576, loss_ce: 0.012498
[01:52:44.675] iteration 15816 : loss : 0.054248, loss_ce: 0.018816
[01:52:44.974] iteration 15817 : loss : 0.036475, loss_ce: 0.014860
[01:52:45.276] iteration 15818 : loss : 0.049714, loss_ce: 0.018296
[01:52:45.579] iteration 15819 : loss : 0.076779, loss_ce: 0.014905
[01:52:45.884] iteration 15820 : loss : 0.055510, loss_ce: 0.014066
[01:52:46.209] iteration 15821 : loss : 0.087880, loss_ce: 0.013886
[01:52:46.512] iteration 15822 : loss : 0.053205, loss_ce: 0.013284
[01:52:46.817] iteration 15823 : loss : 0.052769, loss_ce: 0.012537
[01:52:47.122] iteration 15824 : loss : 0.054012, loss_ce: 0.018265
[01:52:47.428] iteration 15825 : loss : 0.047899, loss_ce: 0.013082
[01:52:47.733] iteration 15826 : loss : 0.046763, loss_ce: 0.016848
[01:52:48.039] iteration 15827 : loss : 0.051169, loss_ce: 0.017580
[01:52:48.345] iteration 15828 : loss : 0.035180, loss_ce: 0.007442
[01:52:48.652] iteration 15829 : loss : 0.043751, loss_ce: 0.012019
[01:52:48.958] iteration 15830 : loss : 0.071250, loss_ce: 0.031429
[01:52:49.271] iteration 15831 : loss : 0.041830, loss_ce: 0.014436
[01:52:49.576] iteration 15832 : loss : 0.045254, loss_ce: 0.016215
[01:52:49.887] iteration 15833 : loss : 0.047776, loss_ce: 0.011592
[01:52:50.202] iteration 15834 : loss : 0.043814, loss_ce: 0.008042
[01:52:50.516] iteration 15835 : loss : 0.049336, loss_ce: 0.010618
[01:52:50.826] iteration 15836 : loss : 0.105811, loss_ce: 0.005212
[01:52:51.141] iteration 15837 : loss : 0.043709, loss_ce: 0.017393
[01:52:51.456] iteration 15838 : loss : 0.048086, loss_ce: 0.009534
[01:52:51.766] iteration 15839 : loss : 0.047258, loss_ce: 0.009744
[01:52:52.081] iteration 15840 : loss : 0.053222, loss_ce: 0.011395
[01:52:52.422] iteration 15841 : loss : 0.052267, loss_ce: 0.016763
[01:52:52.730] iteration 15842 : loss : 0.055218, loss_ce: 0.016137
[01:52:53.044] iteration 15843 : loss : 0.165339, loss_ce: 0.006087
[01:52:53.357] iteration 15844 : loss : 0.082223, loss_ce: 0.009930
[01:52:53.671] iteration 15845 : loss : 0.106532, loss_ce: 0.013672
[01:52:53.756] iteration 15846 : loss : 0.293208, loss_ce: 0.024016
[01:53:10.467] iteration 15847 : loss : 0.056195, loss_ce: 0.014623
[01:53:10.765] iteration 15848 : loss : 0.047555, loss_ce: 0.013314
[01:53:11.065] iteration 15849 : loss : 0.042619, loss_ce: 0.015916
[01:53:11.366] iteration 15850 : loss : 0.044453, loss_ce: 0.018756
[01:53:11.669] iteration 15851 : loss : 0.047311, loss_ce: 0.013949
[01:53:11.970] iteration 15852 : loss : 0.066399, loss_ce: 0.018704
[01:53:12.269] iteration 15853 : loss : 0.102874, loss_ce: 0.017326
[01:53:12.578] iteration 15854 : loss : 0.039694, loss_ce: 0.014269
[01:53:12.883] iteration 15855 : loss : 0.050185, loss_ce: 0.017478
[01:53:13.189] iteration 15856 : loss : 0.039462, loss_ce: 0.007902
[01:53:13.493] iteration 15857 : loss : 0.049222, loss_ce: 0.012036
[01:53:13.800] iteration 15858 : loss : 0.046956, loss_ce: 0.013189
[01:53:14.102] iteration 15859 : loss : 0.057679, loss_ce: 0.019987
[01:53:14.407] iteration 15860 : loss : 0.050315, loss_ce: 0.016517
[01:53:14.732] iteration 15861 : loss : 0.096877, loss_ce: 0.013378
[01:53:15.034] iteration 15862 : loss : 0.118610, loss_ce: 0.008508
[01:53:15.339] iteration 15863 : loss : 0.101498, loss_ce: 0.011711
[01:53:15.644] iteration 15864 : loss : 0.047398, loss_ce: 0.008647
[01:53:15.950] iteration 15865 : loss : 0.106848, loss_ce: 0.014568
[01:53:16.253] iteration 15866 : loss : 0.048593, loss_ce: 0.016514
[01:53:16.559] iteration 15867 : loss : 0.044050, loss_ce: 0.007651
[01:53:16.863] iteration 15868 : loss : 0.046742, loss_ce: 0.013950
[01:53:17.167] iteration 15869 : loss : 0.048072, loss_ce: 0.013348
[01:53:17.472] iteration 15870 : loss : 0.040294, loss_ce: 0.020675
[01:53:17.776] iteration 15871 : loss : 0.042133, loss_ce: 0.008250
[01:53:18.080] iteration 15872 : loss : 0.052136, loss_ce: 0.016857
[01:53:18.386] iteration 15873 : loss : 0.067641, loss_ce: 0.021041
[01:53:18.691] iteration 15874 : loss : 0.043997, loss_ce: 0.013985
[01:53:18.999] iteration 15875 : loss : 0.053100, loss_ce: 0.016664
[01:53:19.305] iteration 15876 : loss : 0.103045, loss_ce: 0.005382
[01:53:19.609] iteration 15877 : loss : 0.043497, loss_ce: 0.018457
[01:53:19.913] iteration 15878 : loss : 0.041194, loss_ce: 0.018035
[01:53:20.215] iteration 15879 : loss : 0.061324, loss_ce: 0.013798
[01:53:20.517] iteration 15880 : loss : 0.031247, loss_ce: 0.006455
[01:53:20.839] iteration 15881 : loss : 0.047248, loss_ce: 0.009693
[01:53:21.142] iteration 15882 : loss : 0.042278, loss_ce: 0.016924
[01:53:21.445] iteration 15883 : loss : 0.044979, loss_ce: 0.020869
[01:53:21.747] iteration 15884 : loss : 0.099519, loss_ce: 0.005825
[01:53:22.050] iteration 15885 : loss : 0.052008, loss_ce: 0.021008
[01:53:22.360] iteration 15886 : loss : 0.046878, loss_ce: 0.015117
[01:53:22.674] iteration 15887 : loss : 0.048575, loss_ce: 0.011710
[01:53:22.984] iteration 15888 : loss : 0.035979, loss_ce: 0.014163
[01:53:23.293] iteration 15889 : loss : 0.033893, loss_ce: 0.005636
[01:53:23.606] iteration 15890 : loss : 0.050704, loss_ce: 0.011823
[01:53:23.915] iteration 15891 : loss : 0.040662, loss_ce: 0.017493
[01:53:24.223] iteration 15892 : loss : 0.107418, loss_ce: 0.015579
[01:53:24.526] iteration 15893 : loss : 0.041687, loss_ce: 0.008472
[01:53:24.832] iteration 15894 : loss : 0.050186, loss_ce: 0.022242
[01:53:25.135] iteration 15895 : loss : 0.061308, loss_ce: 0.010327
[01:53:25.436] iteration 15896 : loss : 0.030451, loss_ce: 0.008955
[01:53:25.741] iteration 15897 : loss : 0.055246, loss_ce: 0.016142
[01:53:26.042] iteration 15898 : loss : 0.102230, loss_ce: 0.013198
[01:53:26.348] iteration 15899 : loss : 0.066398, loss_ce: 0.017521
[01:53:26.655] iteration 15900 : loss : 0.102459, loss_ce: 0.006367
[01:53:26.974] iteration 15901 : loss : 0.053392, loss_ce: 0.018284
[01:53:27.274] iteration 15902 : loss : 0.043941, loss_ce: 0.008987
[01:53:27.579] iteration 15903 : loss : 0.104215, loss_ce: 0.007513
[01:53:27.880] iteration 15904 : loss : 0.048628, loss_ce: 0.009554
[01:53:28.182] iteration 15905 : loss : 0.040630, loss_ce: 0.015780
[01:53:28.483] iteration 15906 : loss : 0.099163, loss_ce: 0.009369
[01:53:28.790] iteration 15907 : loss : 0.046908, loss_ce: 0.012905
[01:53:29.092] iteration 15908 : loss : 0.048292, loss_ce: 0.011191
[01:53:29.393] iteration 15909 : loss : 0.039689, loss_ce: 0.011062
[01:53:29.698] iteration 15910 : loss : 0.033409, loss_ce: 0.012051
[01:53:30.002] iteration 15911 : loss : 0.108368, loss_ce: 0.013242
[01:53:30.304] iteration 15912 : loss : 0.104329, loss_ce: 0.011396
[01:53:30.608] iteration 15913 : loss : 0.044680, loss_ce: 0.019825
[01:53:30.908] iteration 15914 : loss : 0.047054, loss_ce: 0.012580
[01:53:31.212] iteration 15915 : loss : 0.031539, loss_ce: 0.013300
[01:53:31.517] iteration 15916 : loss : 0.050302, loss_ce: 0.015558
[01:53:31.821] iteration 15917 : loss : 0.107615, loss_ce: 0.007080
[01:53:32.125] iteration 15918 : loss : 0.031874, loss_ce: 0.007179
[01:53:32.430] iteration 15919 : loss : 0.060238, loss_ce: 0.016063
[01:53:32.735] iteration 15920 : loss : 0.040120, loss_ce: 0.018910
[01:53:33.056] iteration 15921 : loss : 0.097834, loss_ce: 0.009155
[01:53:33.359] iteration 15922 : loss : 0.037464, loss_ce: 0.012065
[01:53:33.662] iteration 15923 : loss : 0.047099, loss_ce: 0.021612
[01:53:33.970] iteration 15924 : loss : 0.057584, loss_ce: 0.018133
[01:53:34.271] iteration 15925 : loss : 0.057117, loss_ce: 0.012952
[01:53:34.576] iteration 15926 : loss : 0.054679, loss_ce: 0.015164
[01:53:34.880] iteration 15927 : loss : 0.103326, loss_ce: 0.010720
[01:53:35.186] iteration 15928 : loss : 0.054893, loss_ce: 0.022005
[01:53:35.492] iteration 15929 : loss : 0.044338, loss_ce: 0.013547
[01:53:35.794] iteration 15930 : loss : 0.050634, loss_ce: 0.014459
[01:53:36.097] iteration 15931 : loss : 0.055916, loss_ce: 0.016002
[01:53:36.400] iteration 15932 : loss : 0.034579, loss_ce: 0.010420
[01:53:36.704] iteration 15933 : loss : 0.102565, loss_ce: 0.007824
[01:53:37.007] iteration 15934 : loss : 0.071474, loss_ce: 0.013322
[01:53:37.312] iteration 15935 : loss : 0.059312, loss_ce: 0.008098
[01:53:37.624] iteration 15936 : loss : 0.042505, loss_ce: 0.014717
[01:53:37.929] iteration 15937 : loss : 0.113094, loss_ce: 0.006288
[01:53:38.234] iteration 15938 : loss : 0.042935, loss_ce: 0.017530
[01:53:38.538] iteration 15939 : loss : 0.085495, loss_ce: 0.010748
[01:53:38.843] iteration 15940 : loss : 0.042950, loss_ce: 0.014365
[01:53:39.163] iteration 15941 : loss : 0.045649, loss_ce: 0.011508
[01:53:39.469] iteration 15942 : loss : 0.035810, loss_ce: 0.011705
[01:53:39.776] iteration 15943 : loss : 0.075454, loss_ce: 0.011263
[01:53:40.087] iteration 15944 : loss : 0.052602, loss_ce: 0.014727
[01:53:40.397] iteration 15945 : loss : 0.041308, loss_ce: 0.015576
[01:53:40.706] iteration 15946 : loss : 0.047820, loss_ce: 0.017670
[01:53:41.012] iteration 15947 : loss : 0.057106, loss_ce: 0.015424
[01:53:41.322] iteration 15948 : loss : 0.045654, loss_ce: 0.010499
[01:53:41.630] iteration 15949 : loss : 0.144684, loss_ce: 0.010789
[01:53:41.941] iteration 15950 : loss : 0.048612, loss_ce: 0.019280
[01:53:42.249] iteration 15951 : loss : 0.049174, loss_ce: 0.011395
[01:53:42.558] iteration 15952 : loss : 0.060459, loss_ce: 0.016070
[01:53:42.865] iteration 15953 : loss : 0.039982, loss_ce: 0.010389
[01:53:43.176] iteration 15954 : loss : 0.040685, loss_ce: 0.010583
[01:53:43.480] iteration 15955 : loss : 0.052180, loss_ce: 0.017910
[01:53:43.788] iteration 15956 : loss : 0.039808, loss_ce: 0.006350
[01:53:44.101] iteration 15957 : loss : 0.054972, loss_ce: 0.016955
[01:53:44.410] iteration 15958 : loss : 0.049847, loss_ce: 0.014144
[01:53:44.718] iteration 15959 : loss : 0.050982, loss_ce: 0.018852
[01:53:45.027] iteration 15960 : loss : 0.046570, loss_ce: 0.014913
[01:53:45.350] iteration 15961 : loss : 0.049597, loss_ce: 0.014793
[01:53:45.655] iteration 15962 : loss : 0.049191, loss_ce: 0.015661
[01:53:45.968] iteration 15963 : loss : 0.051323, loss_ce: 0.012090
[01:53:46.278] iteration 15964 : loss : 0.064328, loss_ce: 0.014015
[01:53:46.581] iteration 15965 : loss : 0.109791, loss_ce: 0.010839
[01:53:46.886] iteration 15966 : loss : 0.094740, loss_ce: 0.008320
[01:53:47.194] iteration 15967 : loss : 0.049303, loss_ce: 0.018149
[01:53:47.507] iteration 15968 : loss : 0.036810, loss_ce: 0.007195
[01:53:47.819] iteration 15969 : loss : 0.042269, loss_ce: 0.012368
[01:53:48.129] iteration 15970 : loss : 0.046726, loss_ce: 0.022477
[01:53:48.438] iteration 15971 : loss : 0.044512, loss_ce: 0.008966
[01:53:48.758] iteration 15972 : loss : 0.051145, loss_ce: 0.018603
[01:53:49.068] iteration 15973 : loss : 0.048916, loss_ce: 0.018467
[01:53:49.383] iteration 15974 : loss : 0.054183, loss_ce: 0.014872
[01:53:49.700] iteration 15975 : loss : 0.052500, loss_ce: 0.015462
[01:53:50.006] iteration 15976 : loss : 0.054297, loss_ce: 0.013918
[01:53:50.317] iteration 15977 : loss : 0.112181, loss_ce: 0.012344
[01:53:50.635] iteration 15978 : loss : 0.109411, loss_ce: 0.011494
[01:53:50.948] iteration 15979 : loss : 0.046224, loss_ce: 0.022397
[01:53:51.256] iteration 15980 : loss : 0.060372, loss_ce: 0.011831
[01:53:51.591] iteration 15981 : loss : 0.088796, loss_ce: 0.009198
[01:53:51.910] iteration 15982 : loss : 0.047645, loss_ce: 0.008814
[01:53:52.220] iteration 15983 : loss : 0.118724, loss_ce: 0.017550
[01:53:52.531] iteration 15984 : loss : 0.048487, loss_ce: 0.013798
[01:53:52.610] iteration 15985 : loss : 0.280548, loss_ce: 0.013968
[01:54:11.877] iteration 15986 : loss : 0.048366, loss_ce: 0.020888
[01:54:12.178] iteration 15987 : loss : 0.051466, loss_ce: 0.016191
[01:54:12.487] iteration 15988 : loss : 0.159971, loss_ce: 0.006788
[01:54:12.794] iteration 15989 : loss : 0.048962, loss_ce: 0.013879
[01:54:13.102] iteration 15990 : loss : 0.044049, loss_ce: 0.014411
[01:54:13.408] iteration 15991 : loss : 0.039051, loss_ce: 0.010371
[01:54:13.717] iteration 15992 : loss : 0.097946, loss_ce: 0.012447
[01:54:14.025] iteration 15993 : loss : 0.048368, loss_ce: 0.016929
[01:54:14.330] iteration 15994 : loss : 0.048435, loss_ce: 0.013825
[01:54:14.632] iteration 15995 : loss : 0.045009, loss_ce: 0.014706
[01:54:14.935] iteration 15996 : loss : 0.052645, loss_ce: 0.020339
[01:54:15.232] iteration 15997 : loss : 0.103403, loss_ce: 0.013587
[01:54:15.537] iteration 15998 : loss : 0.059133, loss_ce: 0.015560
[01:54:15.839] iteration 15999 : loss : 0.044735, loss_ce: 0.013879
[01:54:16.140] iteration 16000 : loss : 0.050364, loss_ce: 0.019950
[01:54:16.454] iteration 16001 : loss : 0.045015, loss_ce: 0.013004
[01:54:16.759] iteration 16002 : loss : 0.042073, loss_ce: 0.017675
[01:54:17.061] iteration 16003 : loss : 0.037433, loss_ce: 0.014302
[01:54:17.367] iteration 16004 : loss : 0.079294, loss_ce: 0.009854
[01:54:17.672] iteration 16005 : loss : 0.033171, loss_ce: 0.009501
[01:54:17.974] iteration 16006 : loss : 0.046245, loss_ce: 0.014006
[01:54:18.280] iteration 16007 : loss : 0.051891, loss_ce: 0.019231
[01:54:18.585] iteration 16008 : loss : 0.049873, loss_ce: 0.022721
[01:54:18.893] iteration 16009 : loss : 0.043178, loss_ce: 0.014219
[01:54:19.197] iteration 16010 : loss : 0.153103, loss_ce: 0.003902
[01:54:19.501] iteration 16011 : loss : 0.043336, loss_ce: 0.004570
[01:54:19.804] iteration 16012 : loss : 0.040256, loss_ce: 0.012098
[01:54:20.105] iteration 16013 : loss : 0.051150, loss_ce: 0.019413
[01:54:20.408] iteration 16014 : loss : 0.047472, loss_ce: 0.015759
[01:54:20.714] iteration 16015 : loss : 0.055387, loss_ce: 0.011394
[01:54:21.017] iteration 16016 : loss : 0.049548, loss_ce: 0.024051
[01:54:21.315] iteration 16017 : loss : 0.052418, loss_ce: 0.010851
[01:54:21.619] iteration 16018 : loss : 0.051095, loss_ce: 0.015655
[01:54:21.923] iteration 16019 : loss : 0.107025, loss_ce: 0.016547
[01:54:22.224] iteration 16020 : loss : 0.107487, loss_ce: 0.011582
[01:54:22.542] iteration 16021 : loss : 0.358471, loss_ce: 0.001948
[01:54:22.843] iteration 16022 : loss : 0.047451, loss_ce: 0.011239
[01:54:23.146] iteration 16023 : loss : 0.057116, loss_ce: 0.020645
[01:54:23.448] iteration 16024 : loss : 0.039962, loss_ce: 0.008789
[01:54:23.752] iteration 16025 : loss : 0.101695, loss_ce: 0.017460
[01:54:24.054] iteration 16026 : loss : 0.047307, loss_ce: 0.017183
[01:54:24.357] iteration 16027 : loss : 0.082967, loss_ce: 0.012581
[01:54:24.663] iteration 16028 : loss : 0.068441, loss_ce: 0.006680
[01:54:24.965] iteration 16029 : loss : 0.046632, loss_ce: 0.008319
[01:54:25.269] iteration 16030 : loss : 0.115331, loss_ce: 0.016336
[01:54:25.571] iteration 16031 : loss : 0.054623, loss_ce: 0.016802
[01:54:25.875] iteration 16032 : loss : 0.055308, loss_ce: 0.020145
[01:54:26.181] iteration 16033 : loss : 0.059972, loss_ce: 0.018793
[01:54:26.485] iteration 16034 : loss : 0.054374, loss_ce: 0.021334
[01:54:26.789] iteration 16035 : loss : 0.036103, loss_ce: 0.009364
[01:54:27.096] iteration 16036 : loss : 0.043857, loss_ce: 0.010221
[01:54:27.406] iteration 16037 : loss : 0.070610, loss_ce: 0.020237
[01:54:27.713] iteration 16038 : loss : 0.047980, loss_ce: 0.009632
[01:54:28.015] iteration 16039 : loss : 0.044156, loss_ce: 0.015279
[01:54:28.321] iteration 16040 : loss : 0.045796, loss_ce: 0.013273
[01:54:28.638] iteration 16041 : loss : 0.051505, loss_ce: 0.009439
[01:54:28.941] iteration 16042 : loss : 0.035376, loss_ce: 0.011548
[01:54:29.249] iteration 16043 : loss : 0.056889, loss_ce: 0.016310
[01:54:29.553] iteration 16044 : loss : 0.046416, loss_ce: 0.018731
[01:54:29.860] iteration 16045 : loss : 0.041108, loss_ce: 0.010978
[01:54:30.167] iteration 16046 : loss : 0.047763, loss_ce: 0.013080
[01:54:30.474] iteration 16047 : loss : 0.102440, loss_ce: 0.010132
[01:54:30.782] iteration 16048 : loss : 0.044393, loss_ce: 0.018807
[01:54:31.092] iteration 16049 : loss : 0.050408, loss_ce: 0.014353
[01:54:31.403] iteration 16050 : loss : 0.036730, loss_ce: 0.018114
[01:54:31.711] iteration 16051 : loss : 0.131813, loss_ce: 0.004174
[01:54:32.024] iteration 16052 : loss : 0.047993, loss_ce: 0.022946
[01:54:32.328] iteration 16053 : loss : 0.045230, loss_ce: 0.010656
[01:54:32.643] iteration 16054 : loss : 0.046237, loss_ce: 0.011936
[01:54:32.948] iteration 16055 : loss : 0.064230, loss_ce: 0.009708
[01:54:33.260] iteration 16056 : loss : 0.049419, loss_ce: 0.018610
[01:54:33.568] iteration 16057 : loss : 0.057056, loss_ce: 0.018380
[01:54:33.874] iteration 16058 : loss : 0.050736, loss_ce: 0.014437
[01:54:34.181] iteration 16059 : loss : 0.036557, loss_ce: 0.012325
[01:54:34.485] iteration 16060 : loss : 0.046912, loss_ce: 0.016889
[01:54:34.812] iteration 16061 : loss : 0.046321, loss_ce: 0.010530
[01:54:35.115] iteration 16062 : loss : 0.050345, loss_ce: 0.014687
[01:54:35.423] iteration 16063 : loss : 0.044155, loss_ce: 0.015880
[01:54:35.729] iteration 16064 : loss : 0.057050, loss_ce: 0.009277
[01:54:36.036] iteration 16065 : loss : 0.101620, loss_ce: 0.006972
[01:54:36.349] iteration 16066 : loss : 0.058122, loss_ce: 0.018203
[01:54:36.662] iteration 16067 : loss : 0.149156, loss_ce: 0.006348
[01:54:36.970] iteration 16068 : loss : 0.071841, loss_ce: 0.011788
[01:54:37.276] iteration 16069 : loss : 0.050817, loss_ce: 0.006573
[01:54:37.587] iteration 16070 : loss : 0.111059, loss_ce: 0.010395
[01:54:37.897] iteration 16071 : loss : 0.106891, loss_ce: 0.010312
[01:54:38.203] iteration 16072 : loss : 0.044734, loss_ce: 0.017632
[01:54:38.510] iteration 16073 : loss : 0.051560, loss_ce: 0.016285
[01:54:38.816] iteration 16074 : loss : 0.049209, loss_ce: 0.014170
[01:54:39.124] iteration 16075 : loss : 0.041724, loss_ce: 0.009262
[01:54:39.435] iteration 16076 : loss : 0.047296, loss_ce: 0.008591
[01:54:39.744] iteration 16077 : loss : 0.036038, loss_ce: 0.011123
[01:54:40.058] iteration 16078 : loss : 0.082315, loss_ce: 0.008446
[01:54:40.363] iteration 16079 : loss : 0.048471, loss_ce: 0.011066
[01:54:40.670] iteration 16080 : loss : 0.049472, loss_ce: 0.013734
[01:54:40.998] iteration 16081 : loss : 0.122140, loss_ce: 0.010787
[01:54:41.301] iteration 16082 : loss : 0.052794, loss_ce: 0.020720
[01:54:41.613] iteration 16083 : loss : 0.058757, loss_ce: 0.014872
[01:54:41.927] iteration 16084 : loss : 0.045012, loss_ce: 0.015640
[01:54:42.236] iteration 16085 : loss : 0.104978, loss_ce: 0.007570
[01:54:42.544] iteration 16086 : loss : 0.044996, loss_ce: 0.013019
[01:54:42.853] iteration 16087 : loss : 0.043610, loss_ce: 0.014985
[01:54:43.161] iteration 16088 : loss : 0.043349, loss_ce: 0.017159
[01:54:43.470] iteration 16089 : loss : 0.050612, loss_ce: 0.017451
[01:54:43.778] iteration 16090 : loss : 0.047799, loss_ce: 0.015342
[01:54:44.083] iteration 16091 : loss : 0.048614, loss_ce: 0.023266
[01:54:44.393] iteration 16092 : loss : 0.042388, loss_ce: 0.015122
[01:54:44.699] iteration 16093 : loss : 0.097075, loss_ce: 0.008830
[01:54:45.008] iteration 16094 : loss : 0.163514, loss_ce: 0.012996
[01:54:45.319] iteration 16095 : loss : 0.059945, loss_ce: 0.022043
[01:54:45.627] iteration 16096 : loss : 0.055387, loss_ce: 0.013038
[01:54:45.934] iteration 16097 : loss : 0.052816, loss_ce: 0.019303
[01:54:46.243] iteration 16098 : loss : 0.137215, loss_ce: 0.006186
[01:54:46.552] iteration 16099 : loss : 0.043971, loss_ce: 0.012799
[01:54:46.864] iteration 16100 : loss : 0.053214, loss_ce: 0.012470
[01:54:47.185] iteration 16101 : loss : 0.050191, loss_ce: 0.019964
[01:54:47.495] iteration 16102 : loss : 0.107789, loss_ce: 0.013471
[01:54:47.806] iteration 16103 : loss : 0.048551, loss_ce: 0.011689
[01:54:48.120] iteration 16104 : loss : 0.034991, loss_ce: 0.011567
[01:54:48.434] iteration 16105 : loss : 0.048901, loss_ce: 0.015851
[01:54:48.744] iteration 16106 : loss : 0.035418, loss_ce: 0.012822
[01:54:49.051] iteration 16107 : loss : 0.052167, loss_ce: 0.016686
[01:54:49.367] iteration 16108 : loss : 0.042462, loss_ce: 0.014089
[01:54:49.680] iteration 16109 : loss : 0.040665, loss_ce: 0.010711
[01:54:49.985] iteration 16110 : loss : 0.102777, loss_ce: 0.009692
[01:54:50.291] iteration 16111 : loss : 0.045481, loss_ce: 0.010716
[01:54:50.600] iteration 16112 : loss : 0.124622, loss_ce: 0.018904
[01:54:50.912] iteration 16113 : loss : 0.106197, loss_ce: 0.012284
[01:54:51.222] iteration 16114 : loss : 0.047388, loss_ce: 0.013257
[01:54:51.532] iteration 16115 : loss : 0.045731, loss_ce: 0.013496
[01:54:51.843] iteration 16116 : loss : 0.302884, loss_ce: 0.002420
[01:54:52.149] iteration 16117 : loss : 0.108619, loss_ce: 0.017168
[01:54:52.456] iteration 16118 : loss : 0.054527, loss_ce: 0.014030
[01:54:52.762] iteration 16119 : loss : 0.074169, loss_ce: 0.004511
[01:54:53.075] iteration 16120 : loss : 0.036984, loss_ce: 0.014341
[01:54:53.419] iteration 16121 : loss : 0.044011, loss_ce: 0.018275
[01:54:53.723] iteration 16122 : loss : 0.055796, loss_ce: 0.020595
[01:54:54.036] iteration 16123 : loss : 0.058050, loss_ce: 0.016921
[01:54:54.133] iteration 16124 : loss : 0.240274, loss_ce: 0.003647
[01:55:11.731] iteration 16125 : loss : 0.041044, loss_ce: 0.014858
[01:55:12.033] iteration 16126 : loss : 0.041946, loss_ce: 0.011574
[01:55:12.333] iteration 16127 : loss : 0.171343, loss_ce: 0.005640
[01:55:12.636] iteration 16128 : loss : 0.040068, loss_ce: 0.010291
[01:55:12.937] iteration 16129 : loss : 0.043656, loss_ce: 0.010387
[01:55:13.237] iteration 16130 : loss : 0.045867, loss_ce: 0.018779
[01:55:13.540] iteration 16131 : loss : 0.055079, loss_ce: 0.012335
[01:55:13.848] iteration 16132 : loss : 0.104032, loss_ce: 0.008345
[01:55:14.149] iteration 16133 : loss : 0.039927, loss_ce: 0.017568
[01:55:14.450] iteration 16134 : loss : 0.052058, loss_ce: 0.017521
[01:55:14.751] iteration 16135 : loss : 0.049591, loss_ce: 0.007639
[01:55:15.053] iteration 16136 : loss : 0.057516, loss_ce: 0.015921
[01:55:15.355] iteration 16137 : loss : 0.119725, loss_ce: 0.015994
[01:55:15.660] iteration 16138 : loss : 0.044819, loss_ce: 0.016499
[01:55:15.964] iteration 16139 : loss : 0.079031, loss_ce: 0.017952
[01:55:16.273] iteration 16140 : loss : 0.045985, loss_ce: 0.018225
[01:55:16.590] iteration 16141 : loss : 0.166478, loss_ce: 0.006522
[01:55:16.891] iteration 16142 : loss : 0.049679, loss_ce: 0.013295
[01:55:17.193] iteration 16143 : loss : 0.049560, loss_ce: 0.012841
[01:55:17.507] iteration 16144 : loss : 0.108423, loss_ce: 0.008259
[01:55:17.814] iteration 16145 : loss : 0.040591, loss_ce: 0.009468
[01:55:18.123] iteration 16146 : loss : 0.045628, loss_ce: 0.013540
[01:55:18.431] iteration 16147 : loss : 0.043042, loss_ce: 0.016792
[01:55:18.744] iteration 16148 : loss : 0.045991, loss_ce: 0.014003
[01:55:19.053] iteration 16149 : loss : 0.051893, loss_ce: 0.023116
[01:55:19.366] iteration 16150 : loss : 0.045329, loss_ce: 0.010515
[01:55:19.669] iteration 16151 : loss : 0.059299, loss_ce: 0.019618
[01:55:19.983] iteration 16152 : loss : 0.049621, loss_ce: 0.010402
[01:55:20.286] iteration 16153 : loss : 0.039059, loss_ce: 0.013114
[01:55:20.586] iteration 16154 : loss : 0.043927, loss_ce: 0.017532
[01:55:20.890] iteration 16155 : loss : 0.052757, loss_ce: 0.019101
[01:55:21.194] iteration 16156 : loss : 0.055396, loss_ce: 0.013491
[01:55:21.494] iteration 16157 : loss : 0.153323, loss_ce: 0.007588
[01:55:21.797] iteration 16158 : loss : 0.046405, loss_ce: 0.016051
[01:55:22.102] iteration 16159 : loss : 0.060696, loss_ce: 0.011261
[01:55:22.405] iteration 16160 : loss : 0.046688, loss_ce: 0.018003
[01:55:22.730] iteration 16161 : loss : 0.045972, loss_ce: 0.018213
[01:55:23.033] iteration 16162 : loss : 0.048644, loss_ce: 0.012737
[01:55:23.340] iteration 16163 : loss : 0.074223, loss_ce: 0.010170
[01:55:23.642] iteration 16164 : loss : 0.233691, loss_ce: 0.002726
[01:55:23.945] iteration 16165 : loss : 0.044260, loss_ce: 0.022297
[01:55:24.247] iteration 16166 : loss : 0.053506, loss_ce: 0.017145
[01:55:24.551] iteration 16167 : loss : 0.104121, loss_ce: 0.010093
[01:55:24.857] iteration 16168 : loss : 0.104060, loss_ce: 0.013392
[01:55:25.162] iteration 16169 : loss : 0.116980, loss_ce: 0.016015
[01:55:25.466] iteration 16170 : loss : 0.165619, loss_ce: 0.004496
[01:55:25.775] iteration 16171 : loss : 0.061713, loss_ce: 0.011920
[01:55:26.079] iteration 16172 : loss : 0.044458, loss_ce: 0.019104
[01:55:26.383] iteration 16173 : loss : 0.040007, loss_ce: 0.012004
[01:55:26.687] iteration 16174 : loss : 0.043551, loss_ce: 0.018983
[01:55:26.991] iteration 16175 : loss : 0.049818, loss_ce: 0.015050
[01:55:27.296] iteration 16176 : loss : 0.055403, loss_ce: 0.009678
[01:55:27.601] iteration 16177 : loss : 0.045550, loss_ce: 0.018000
[01:55:27.903] iteration 16178 : loss : 0.048934, loss_ce: 0.014625
[01:55:28.212] iteration 16179 : loss : 0.042573, loss_ce: 0.011638
[01:55:28.517] iteration 16180 : loss : 0.040941, loss_ce: 0.013991
[01:55:28.841] iteration 16181 : loss : 0.042748, loss_ce: 0.010277
[01:55:29.145] iteration 16182 : loss : 0.167146, loss_ce: 0.014819
[01:55:29.446] iteration 16183 : loss : 0.045592, loss_ce: 0.016262
[01:55:29.752] iteration 16184 : loss : 0.049972, loss_ce: 0.018968
[01:55:30.056] iteration 16185 : loss : 0.058679, loss_ce: 0.009385
[01:55:30.356] iteration 16186 : loss : 0.051606, loss_ce: 0.018942
[01:55:30.658] iteration 16187 : loss : 0.050245, loss_ce: 0.013222
[01:55:30.964] iteration 16188 : loss : 0.054338, loss_ce: 0.008426
[01:55:31.266] iteration 16189 : loss : 0.038215, loss_ce: 0.014373
[01:55:31.569] iteration 16190 : loss : 0.086375, loss_ce: 0.010375
[01:55:31.871] iteration 16191 : loss : 0.107889, loss_ce: 0.006432
[01:55:32.175] iteration 16192 : loss : 0.036899, loss_ce: 0.007921
[01:55:32.481] iteration 16193 : loss : 0.045557, loss_ce: 0.013225
[01:55:32.790] iteration 16194 : loss : 0.043751, loss_ce: 0.012071
[01:55:33.096] iteration 16195 : loss : 0.043021, loss_ce: 0.012686
[01:55:33.403] iteration 16196 : loss : 0.048937, loss_ce: 0.017386
[01:55:33.712] iteration 16197 : loss : 0.039670, loss_ce: 0.015206
[01:55:34.018] iteration 16198 : loss : 0.046253, loss_ce: 0.016841
[01:55:34.325] iteration 16199 : loss : 0.043731, loss_ce: 0.011687
[01:55:34.632] iteration 16200 : loss : 0.042213, loss_ce: 0.019405
[01:55:34.959] iteration 16201 : loss : 0.043220, loss_ce: 0.008484
[01:55:35.268] iteration 16202 : loss : 0.055407, loss_ce: 0.022596
[01:55:35.580] iteration 16203 : loss : 0.048766, loss_ce: 0.022257
[01:55:35.884] iteration 16204 : loss : 0.047758, loss_ce: 0.018811
[01:55:36.193] iteration 16205 : loss : 0.057908, loss_ce: 0.018407
[01:55:36.502] iteration 16206 : loss : 0.035457, loss_ce: 0.011342
[01:55:36.806] iteration 16207 : loss : 0.044876, loss_ce: 0.015458
[01:55:37.116] iteration 16208 : loss : 0.048453, loss_ce: 0.017167
[01:55:37.425] iteration 16209 : loss : 0.055967, loss_ce: 0.013561
[01:55:37.737] iteration 16210 : loss : 0.044370, loss_ce: 0.009538
[01:55:38.042] iteration 16211 : loss : 0.069800, loss_ce: 0.006996
[01:55:38.350] iteration 16212 : loss : 0.046400, loss_ce: 0.015844
[01:55:38.662] iteration 16213 : loss : 0.047085, loss_ce: 0.015388
[01:55:38.974] iteration 16214 : loss : 0.045197, loss_ce: 0.008532
[01:55:39.280] iteration 16215 : loss : 0.045549, loss_ce: 0.018725
[01:55:39.590] iteration 16216 : loss : 0.066800, loss_ce: 0.017420
[01:55:39.898] iteration 16217 : loss : 0.053932, loss_ce: 0.025946
[01:55:40.209] iteration 16218 : loss : 0.098443, loss_ce: 0.008584
[01:55:40.518] iteration 16219 : loss : 0.045531, loss_ce: 0.018878
[01:55:40.830] iteration 16220 : loss : 0.048761, loss_ce: 0.021082
[01:55:41.153] iteration 16221 : loss : 0.040666, loss_ce: 0.013598
[01:55:41.459] iteration 16222 : loss : 0.050633, loss_ce: 0.009836
[01:55:41.776] iteration 16223 : loss : 0.043543, loss_ce: 0.012492
[01:55:42.082] iteration 16224 : loss : 0.112878, loss_ce: 0.012060
[01:55:42.389] iteration 16225 : loss : 0.050440, loss_ce: 0.008279
[01:55:42.697] iteration 16226 : loss : 0.105123, loss_ce: 0.011521
[01:55:43.007] iteration 16227 : loss : 0.111598, loss_ce: 0.016216
[01:55:43.315] iteration 16228 : loss : 0.051433, loss_ce: 0.015599
[01:55:43.626] iteration 16229 : loss : 0.045115, loss_ce: 0.012923
[01:55:43.932] iteration 16230 : loss : 0.054395, loss_ce: 0.027775
[01:55:44.247] iteration 16231 : loss : 0.061263, loss_ce: 0.011554
[01:55:44.555] iteration 16232 : loss : 0.048851, loss_ce: 0.006121
[01:55:44.863] iteration 16233 : loss : 0.034658, loss_ce: 0.014861
[01:55:45.169] iteration 16234 : loss : 0.043572, loss_ce: 0.010035
[01:55:45.483] iteration 16235 : loss : 0.045501, loss_ce: 0.017619
[01:55:45.788] iteration 16236 : loss : 0.117856, loss_ce: 0.010936
[01:55:46.096] iteration 16237 : loss : 0.048505, loss_ce: 0.013043
[01:55:46.401] iteration 16238 : loss : 0.046615, loss_ce: 0.015796
[01:55:46.708] iteration 16239 : loss : 0.105452, loss_ce: 0.016135
[01:55:47.013] iteration 16240 : loss : 0.049214, loss_ce: 0.018435
[01:55:47.342] iteration 16241 : loss : 0.053337, loss_ce: 0.014157
[01:55:47.652] iteration 16242 : loss : 0.039881, loss_ce: 0.007833
[01:55:47.956] iteration 16243 : loss : 0.037732, loss_ce: 0.007404
[01:55:48.271] iteration 16244 : loss : 0.056783, loss_ce: 0.012180
[01:55:48.581] iteration 16245 : loss : 0.050526, loss_ce: 0.010530
[01:55:48.887] iteration 16246 : loss : 0.044098, loss_ce: 0.014741
[01:55:49.199] iteration 16247 : loss : 0.053402, loss_ce: 0.020291
[01:55:49.514] iteration 16248 : loss : 0.168939, loss_ce: 0.007467
[01:55:49.822] iteration 16249 : loss : 0.103550, loss_ce: 0.009726
[01:55:50.140] iteration 16250 : loss : 0.038220, loss_ce: 0.013119
[01:55:50.453] iteration 16251 : loss : 0.050163, loss_ce: 0.015913
[01:55:50.768] iteration 16252 : loss : 0.098169, loss_ce: 0.007278
[01:55:51.084] iteration 16253 : loss : 0.051921, loss_ce: 0.020284
[01:55:51.394] iteration 16254 : loss : 0.181440, loss_ce: 0.008076
[01:55:51.712] iteration 16255 : loss : 0.099242, loss_ce: 0.010581
[01:55:52.019] iteration 16256 : loss : 0.054132, loss_ce: 0.012428
[01:55:52.334] iteration 16257 : loss : 0.050972, loss_ce: 0.019578
[01:55:52.649] iteration 16258 : loss : 0.058687, loss_ce: 0.009046
[01:55:52.961] iteration 16259 : loss : 0.106991, loss_ce: 0.009583
[01:55:53.273] iteration 16260 : loss : 0.041520, loss_ce: 0.007955
[01:55:53.606] iteration 16261 : loss : 0.052530, loss_ce: 0.016770
[01:55:53.917] iteration 16262 : loss : 0.046661, loss_ce: 0.012566
[01:55:53.997] iteration 16263 : loss : 0.108913, loss_ce: 0.013901
[01:56:11.352] iteration 16264 : loss : 0.042385, loss_ce: 0.014898
[01:56:11.651] iteration 16265 : loss : 0.059969, loss_ce: 0.015213
[01:56:11.953] iteration 16266 : loss : 0.055643, loss_ce: 0.013805
[01:56:12.254] iteration 16267 : loss : 0.106329, loss_ce: 0.012370
[01:56:12.557] iteration 16268 : loss : 0.032516, loss_ce: 0.006029
[01:56:12.858] iteration 16269 : loss : 0.052500, loss_ce: 0.017259
[01:56:13.160] iteration 16270 : loss : 0.055805, loss_ce: 0.015264
[01:56:13.464] iteration 16271 : loss : 0.052570, loss_ce: 0.010874
[01:56:13.766] iteration 16272 : loss : 0.040478, loss_ce: 0.011789
[01:56:14.066] iteration 16273 : loss : 0.043633, loss_ce: 0.015504
[01:56:14.368] iteration 16274 : loss : 0.047584, loss_ce: 0.014756
[01:56:14.670] iteration 16275 : loss : 0.048899, loss_ce: 0.007067
[01:56:14.973] iteration 16276 : loss : 0.162925, loss_ce: 0.016229
[01:56:15.275] iteration 16277 : loss : 0.103603, loss_ce: 0.006391
[01:56:15.574] iteration 16278 : loss : 0.106747, loss_ce: 0.017677
[01:56:15.879] iteration 16279 : loss : 0.175767, loss_ce: 0.004906
[01:56:16.178] iteration 16280 : loss : 0.103977, loss_ce: 0.012762
[01:56:16.499] iteration 16281 : loss : 0.071457, loss_ce: 0.030729
[01:56:16.803] iteration 16282 : loss : 0.039457, loss_ce: 0.017879
[01:56:17.105] iteration 16283 : loss : 0.042096, loss_ce: 0.008851
[01:56:17.406] iteration 16284 : loss : 0.048803, loss_ce: 0.018506
[01:56:17.706] iteration 16285 : loss : 0.041480, loss_ce: 0.013033
[01:56:18.009] iteration 16286 : loss : 0.047456, loss_ce: 0.016854
[01:56:18.313] iteration 16287 : loss : 0.034010, loss_ce: 0.014794
[01:56:18.616] iteration 16288 : loss : 0.111946, loss_ce: 0.009794
[01:56:18.921] iteration 16289 : loss : 0.053467, loss_ce: 0.016973
[01:56:19.223] iteration 16290 : loss : 0.128527, loss_ce: 0.009771
[01:56:19.528] iteration 16291 : loss : 0.068196, loss_ce: 0.015028
[01:56:19.831] iteration 16292 : loss : 0.052060, loss_ce: 0.015815
[01:56:20.131] iteration 16293 : loss : 0.044266, loss_ce: 0.015932
[01:56:20.435] iteration 16294 : loss : 0.045329, loss_ce: 0.016696
[01:56:20.740] iteration 16295 : loss : 0.064423, loss_ce: 0.019382
[01:56:21.041] iteration 16296 : loss : 0.055198, loss_ce: 0.019265
[01:56:21.344] iteration 16297 : loss : 0.055499, loss_ce: 0.022714
[01:56:21.648] iteration 16298 : loss : 0.046344, loss_ce: 0.008699
[01:56:21.954] iteration 16299 : loss : 0.053716, loss_ce: 0.018838
[01:56:22.262] iteration 16300 : loss : 0.043523, loss_ce: 0.020380
[01:56:22.581] iteration 16301 : loss : 0.042241, loss_ce: 0.018749
[01:56:22.883] iteration 16302 : loss : 0.041997, loss_ce: 0.010401
[01:56:23.191] iteration 16303 : loss : 0.059155, loss_ce: 0.014492
[01:56:23.497] iteration 16304 : loss : 0.045297, loss_ce: 0.021760
[01:56:23.800] iteration 16305 : loss : 0.038142, loss_ce: 0.009658
[01:56:24.108] iteration 16306 : loss : 0.059439, loss_ce: 0.008356
[01:56:24.413] iteration 16307 : loss : 0.049215, loss_ce: 0.015419
[01:56:24.721] iteration 16308 : loss : 0.047737, loss_ce: 0.021726
[01:56:25.029] iteration 16309 : loss : 0.102065, loss_ce: 0.006405
[01:56:25.335] iteration 16310 : loss : 0.054618, loss_ce: 0.011250
[01:56:25.648] iteration 16311 : loss : 0.044906, loss_ce: 0.009354
[01:56:25.954] iteration 16312 : loss : 0.093609, loss_ce: 0.007339
[01:56:26.262] iteration 16313 : loss : 0.110594, loss_ce: 0.005795
[01:56:26.568] iteration 16314 : loss : 0.041981, loss_ce: 0.010100
[01:56:26.875] iteration 16315 : loss : 0.044960, loss_ce: 0.011233
[01:56:27.187] iteration 16316 : loss : 0.049521, loss_ce: 0.018261
[01:56:27.494] iteration 16317 : loss : 0.114250, loss_ce: 0.009637
[01:56:27.803] iteration 16318 : loss : 0.035768, loss_ce: 0.006001
[01:56:28.105] iteration 16319 : loss : 0.036880, loss_ce: 0.012349
[01:56:28.415] iteration 16320 : loss : 0.045159, loss_ce: 0.017566
[01:56:28.741] iteration 16321 : loss : 0.038696, loss_ce: 0.012584
[01:56:29.047] iteration 16322 : loss : 0.040429, loss_ce: 0.013632
[01:56:29.356] iteration 16323 : loss : 0.038689, loss_ce: 0.013671
[01:56:29.663] iteration 16324 : loss : 0.042535, loss_ce: 0.012016
[01:56:29.969] iteration 16325 : loss : 0.166839, loss_ce: 0.002792
[01:56:30.279] iteration 16326 : loss : 0.045922, loss_ce: 0.013554
[01:56:30.587] iteration 16327 : loss : 0.042539, loss_ce: 0.013197
[01:56:30.897] iteration 16328 : loss : 0.058288, loss_ce: 0.019139
[01:56:31.202] iteration 16329 : loss : 0.096211, loss_ce: 0.009581
[01:56:31.507] iteration 16330 : loss : 0.171475, loss_ce: 0.011152
[01:56:31.816] iteration 16331 : loss : 0.043416, loss_ce: 0.013858
[01:56:32.122] iteration 16332 : loss : 0.096077, loss_ce: 0.004976
[01:56:32.429] iteration 16333 : loss : 0.061506, loss_ce: 0.012134
[01:56:32.734] iteration 16334 : loss : 0.046386, loss_ce: 0.014854
[01:56:33.043] iteration 16335 : loss : 0.036534, loss_ce: 0.013441
[01:56:33.349] iteration 16336 : loss : 0.102214, loss_ce: 0.014152
[01:56:33.658] iteration 16337 : loss : 0.047315, loss_ce: 0.017229
[01:56:33.964] iteration 16338 : loss : 0.047746, loss_ce: 0.007810
[01:56:34.272] iteration 16339 : loss : 0.043221, loss_ce: 0.020071
[01:56:34.580] iteration 16340 : loss : 0.161207, loss_ce: 0.014366
[01:56:34.904] iteration 16341 : loss : 0.102899, loss_ce: 0.005125
[01:56:35.212] iteration 16342 : loss : 0.034183, loss_ce: 0.012102
[01:56:35.521] iteration 16343 : loss : 0.106086, loss_ce: 0.013493
[01:56:35.829] iteration 16344 : loss : 0.105159, loss_ce: 0.006972
[01:56:36.137] iteration 16345 : loss : 0.057982, loss_ce: 0.015148
[01:56:36.446] iteration 16346 : loss : 0.043706, loss_ce: 0.011758
[01:56:36.757] iteration 16347 : loss : 0.037519, loss_ce: 0.009007
[01:56:37.064] iteration 16348 : loss : 0.036353, loss_ce: 0.008328
[01:56:37.371] iteration 16349 : loss : 0.046570, loss_ce: 0.016134
[01:56:37.685] iteration 16350 : loss : 0.040536, loss_ce: 0.011685
[01:56:37.989] iteration 16351 : loss : 0.097360, loss_ce: 0.010266
[01:56:38.301] iteration 16352 : loss : 0.048825, loss_ce: 0.016270
[01:56:38.606] iteration 16353 : loss : 0.042964, loss_ce: 0.013368
[01:56:38.915] iteration 16354 : loss : 0.061252, loss_ce: 0.013137
[01:56:39.224] iteration 16355 : loss : 0.223439, loss_ce: 0.008147
[01:56:39.531] iteration 16356 : loss : 0.042749, loss_ce: 0.012533
[01:56:39.842] iteration 16357 : loss : 0.180514, loss_ce: 0.005625
[01:56:40.151] iteration 16358 : loss : 0.047535, loss_ce: 0.014338
[01:56:40.459] iteration 16359 : loss : 0.043892, loss_ce: 0.016556
[01:56:40.764] iteration 16360 : loss : 0.051016, loss_ce: 0.011076
[01:56:41.086] iteration 16361 : loss : 0.044404, loss_ce: 0.009948
[01:56:41.393] iteration 16362 : loss : 0.050553, loss_ce: 0.018938
[01:56:41.700] iteration 16363 : loss : 0.047178, loss_ce: 0.024760
[01:56:42.008] iteration 16364 : loss : 0.053016, loss_ce: 0.019877
[01:56:42.317] iteration 16365 : loss : 0.056261, loss_ce: 0.015390
[01:56:42.625] iteration 16366 : loss : 0.045121, loss_ce: 0.012650
[01:56:42.933] iteration 16367 : loss : 0.215255, loss_ce: 0.001881
[01:56:43.244] iteration 16368 : loss : 0.043122, loss_ce: 0.014306
[01:56:43.551] iteration 16369 : loss : 0.055168, loss_ce: 0.013286
[01:56:43.864] iteration 16370 : loss : 0.041076, loss_ce: 0.018822
[01:56:44.170] iteration 16371 : loss : 0.042526, loss_ce: 0.014274
[01:56:44.477] iteration 16372 : loss : 0.044524, loss_ce: 0.015704
[01:56:44.783] iteration 16373 : loss : 0.041468, loss_ce: 0.011823
[01:56:45.086] iteration 16374 : loss : 0.040115, loss_ce: 0.013724
[01:56:45.392] iteration 16375 : loss : 0.047894, loss_ce: 0.016571
[01:56:45.695] iteration 16376 : loss : 0.056044, loss_ce: 0.020663
[01:56:45.999] iteration 16377 : loss : 0.108841, loss_ce: 0.014873
[01:56:46.300] iteration 16378 : loss : 0.107815, loss_ce: 0.017765
[01:56:46.605] iteration 16379 : loss : 0.102113, loss_ce: 0.012492
[01:56:46.906] iteration 16380 : loss : 0.048112, loss_ce: 0.023129
[01:56:47.221] iteration 16381 : loss : 0.050816, loss_ce: 0.010583
[01:56:47.523] iteration 16382 : loss : 0.045971, loss_ce: 0.012838
[01:56:47.827] iteration 16383 : loss : 0.069561, loss_ce: 0.011933
[01:56:48.130] iteration 16384 : loss : 0.040513, loss_ce: 0.010638
[01:56:48.434] iteration 16385 : loss : 0.045503, loss_ce: 0.019866
[01:56:48.744] iteration 16386 : loss : 0.042659, loss_ce: 0.015154
[01:56:49.056] iteration 16387 : loss : 0.046069, loss_ce: 0.013835
[01:56:49.362] iteration 16388 : loss : 0.100150, loss_ce: 0.005811
[01:56:49.670] iteration 16389 : loss : 0.045095, loss_ce: 0.015999
[01:56:49.975] iteration 16390 : loss : 0.051085, loss_ce: 0.015269
[01:56:50.289] iteration 16391 : loss : 0.057381, loss_ce: 0.022671
[01:56:50.601] iteration 16392 : loss : 0.048036, loss_ce: 0.012265
[01:56:50.919] iteration 16393 : loss : 0.040918, loss_ce: 0.009400
[01:56:51.225] iteration 16394 : loss : 0.078481, loss_ce: 0.007530
[01:56:51.537] iteration 16395 : loss : 0.053370, loss_ce: 0.013153
[01:56:51.855] iteration 16396 : loss : 0.153409, loss_ce: 0.012812
[01:56:52.162] iteration 16397 : loss : 0.052830, loss_ce: 0.017046
[01:56:52.475] iteration 16398 : loss : 0.048123, loss_ce: 0.008385
[01:56:52.786] iteration 16399 : loss : 0.050031, loss_ce: 0.014174
[01:56:53.102] iteration 16400 : loss : 0.043617, loss_ce: 0.017373
[01:56:53.443] iteration 16401 : loss : 0.053250, loss_ce: 0.016890
[01:56:53.522] iteration 16402 : loss : 0.410818, loss_ce: 0.001502
[01:57:10.907] iteration 16403 : loss : 0.052033, loss_ce: 0.017471
[01:57:11.208] iteration 16404 : loss : 0.038923, loss_ce: 0.008648
[01:57:11.505] iteration 16405 : loss : 0.039421, loss_ce: 0.014237
[01:57:11.806] iteration 16406 : loss : 0.063331, loss_ce: 0.019875
[01:57:12.108] iteration 16407 : loss : 0.044948, loss_ce: 0.011925
[01:57:12.416] iteration 16408 : loss : 0.052999, loss_ce: 0.009106
[01:57:12.721] iteration 16409 : loss : 0.102075, loss_ce: 0.015155
[01:57:13.027] iteration 16410 : loss : 0.039355, loss_ce: 0.012666
[01:57:13.332] iteration 16411 : loss : 0.050506, loss_ce: 0.017290
[01:57:13.641] iteration 16412 : loss : 0.043052, loss_ce: 0.014627
[01:57:13.947] iteration 16413 : loss : 0.049499, loss_ce: 0.010957
[01:57:14.254] iteration 16414 : loss : 0.106977, loss_ce: 0.014888
[01:57:14.562] iteration 16415 : loss : 0.048257, loss_ce: 0.016140
[01:57:14.864] iteration 16416 : loss : 0.053836, loss_ce: 0.020997
[01:57:15.169] iteration 16417 : loss : 0.033685, loss_ce: 0.011464
[01:57:15.475] iteration 16418 : loss : 0.041742, loss_ce: 0.012648
[01:57:15.780] iteration 16419 : loss : 0.104664, loss_ce: 0.013280
[01:57:16.085] iteration 16420 : loss : 0.050074, loss_ce: 0.012708
[01:57:16.409] iteration 16421 : loss : 0.216285, loss_ce: 0.005529
[01:57:16.712] iteration 16422 : loss : 0.103904, loss_ce: 0.014842
[01:57:17.017] iteration 16423 : loss : 0.103495, loss_ce: 0.014789
[01:57:17.322] iteration 16424 : loss : 0.052785, loss_ce: 0.011952
[01:57:17.627] iteration 16425 : loss : 0.051800, loss_ce: 0.011132
[01:57:17.934] iteration 16426 : loss : 0.101959, loss_ce: 0.013263
[01:57:18.240] iteration 16427 : loss : 0.040346, loss_ce: 0.012955
[01:57:18.544] iteration 16428 : loss : 0.100263, loss_ce: 0.008006
[01:57:18.848] iteration 16429 : loss : 0.157393, loss_ce: 0.006347
[01:57:19.156] iteration 16430 : loss : 0.057129, loss_ce: 0.017061
[01:57:19.463] iteration 16431 : loss : 0.046475, loss_ce: 0.012850
[01:57:19.768] iteration 16432 : loss : 0.100635, loss_ce: 0.011572
[01:57:20.073] iteration 16433 : loss : 0.050068, loss_ce: 0.011514
[01:57:20.379] iteration 16434 : loss : 0.040992, loss_ce: 0.018490
[01:57:20.680] iteration 16435 : loss : 0.047993, loss_ce: 0.013556
[01:57:20.986] iteration 16436 : loss : 0.047880, loss_ce: 0.013294
[01:57:21.289] iteration 16437 : loss : 0.059358, loss_ce: 0.004706
[01:57:21.593] iteration 16438 : loss : 0.048290, loss_ce: 0.017027
[01:57:21.893] iteration 16439 : loss : 0.060581, loss_ce: 0.019972
[01:57:22.198] iteration 16440 : loss : 0.049280, loss_ce: 0.012301
[01:57:22.518] iteration 16441 : loss : 0.049185, loss_ce: 0.012614
[01:57:22.821] iteration 16442 : loss : 0.052458, loss_ce: 0.014631
[01:57:23.127] iteration 16443 : loss : 0.115811, loss_ce: 0.015029
[01:57:23.436] iteration 16444 : loss : 0.033842, loss_ce: 0.012046
[01:57:23.738] iteration 16445 : loss : 0.041013, loss_ce: 0.013172
[01:57:24.044] iteration 16446 : loss : 0.042841, loss_ce: 0.007881
[01:57:24.345] iteration 16447 : loss : 0.046189, loss_ce: 0.013511
[01:57:24.646] iteration 16448 : loss : 0.218833, loss_ce: 0.002595
[01:57:24.952] iteration 16449 : loss : 0.049338, loss_ce: 0.017935
[01:57:25.256] iteration 16450 : loss : 0.036423, loss_ce: 0.009890
[01:57:25.564] iteration 16451 : loss : 0.037091, loss_ce: 0.009119
[01:57:25.868] iteration 16452 : loss : 0.041224, loss_ce: 0.013125
[01:57:26.173] iteration 16453 : loss : 0.054306, loss_ce: 0.021412
[01:57:26.479] iteration 16454 : loss : 0.045568, loss_ce: 0.011110
[01:57:26.785] iteration 16455 : loss : 0.046553, loss_ce: 0.012618
[01:57:27.089] iteration 16456 : loss : 0.055496, loss_ce: 0.013350
[01:57:27.400] iteration 16457 : loss : 0.057370, loss_ce: 0.016688
[01:57:27.711] iteration 16458 : loss : 0.045753, loss_ce: 0.009270
[01:57:28.021] iteration 16459 : loss : 0.044038, loss_ce: 0.016490
[01:57:28.335] iteration 16460 : loss : 0.048822, loss_ce: 0.020962
[01:57:28.657] iteration 16461 : loss : 0.038475, loss_ce: 0.011837
[01:57:28.965] iteration 16462 : loss : 0.152674, loss_ce: 0.007109
[01:57:29.280] iteration 16463 : loss : 0.039524, loss_ce: 0.012808
[01:57:29.581] iteration 16464 : loss : 0.035778, loss_ce: 0.011280
[01:57:29.888] iteration 16465 : loss : 0.103686, loss_ce: 0.017442
[01:57:30.190] iteration 16466 : loss : 0.057476, loss_ce: 0.013445
[01:57:30.496] iteration 16467 : loss : 0.054218, loss_ce: 0.018398
[01:57:30.799] iteration 16468 : loss : 0.045200, loss_ce: 0.011808
[01:57:31.105] iteration 16469 : loss : 0.053428, loss_ce: 0.014226
[01:57:31.407] iteration 16470 : loss : 0.106383, loss_ce: 0.014864
[01:57:31.715] iteration 16471 : loss : 0.070693, loss_ce: 0.021528
[01:57:32.020] iteration 16472 : loss : 0.055695, loss_ce: 0.018758
[01:57:32.325] iteration 16473 : loss : 0.041591, loss_ce: 0.021794
[01:57:32.627] iteration 16474 : loss : 0.055887, loss_ce: 0.008837
[01:57:32.934] iteration 16475 : loss : 0.044895, loss_ce: 0.012410
[01:57:33.238] iteration 16476 : loss : 0.050114, loss_ce: 0.012635
[01:57:33.542] iteration 16477 : loss : 0.043203, loss_ce: 0.012040
[01:57:33.846] iteration 16478 : loss : 0.043135, loss_ce: 0.013383
[01:57:34.153] iteration 16479 : loss : 0.102190, loss_ce: 0.020375
[01:57:34.460] iteration 16480 : loss : 0.040214, loss_ce: 0.011943
[01:57:34.784] iteration 16481 : loss : 0.061684, loss_ce: 0.009836
[01:57:35.085] iteration 16482 : loss : 0.037920, loss_ce: 0.011670
[01:57:35.387] iteration 16483 : loss : 0.101047, loss_ce: 0.010238
[01:57:35.691] iteration 16484 : loss : 0.051399, loss_ce: 0.023958
[01:57:35.999] iteration 16485 : loss : 0.044290, loss_ce: 0.014526
[01:57:36.307] iteration 16486 : loss : 0.045346, loss_ce: 0.011152
[01:57:36.611] iteration 16487 : loss : 0.055799, loss_ce: 0.019062
[01:57:36.915] iteration 16488 : loss : 0.055688, loss_ce: 0.012961
[01:57:37.219] iteration 16489 : loss : 0.043227, loss_ce: 0.015071
[01:57:37.521] iteration 16490 : loss : 0.047055, loss_ce: 0.011581
[01:57:37.823] iteration 16491 : loss : 0.049074, loss_ce: 0.012258
[01:57:38.127] iteration 16492 : loss : 0.045051, loss_ce: 0.017702
[01:57:38.432] iteration 16493 : loss : 0.046221, loss_ce: 0.024926
[01:57:38.734] iteration 16494 : loss : 0.122942, loss_ce: 0.018425
[01:57:39.036] iteration 16495 : loss : 0.095285, loss_ce: 0.010666
[01:57:39.342] iteration 16496 : loss : 0.064347, loss_ce: 0.010581
[01:57:39.644] iteration 16497 : loss : 0.053039, loss_ce: 0.012647
[01:57:39.950] iteration 16498 : loss : 0.039558, loss_ce: 0.018944
[01:57:40.256] iteration 16499 : loss : 0.163059, loss_ce: 0.011881
[01:57:40.562] iteration 16500 : loss : 0.052417, loss_ce: 0.021622
[01:57:40.888] iteration 16501 : loss : 0.043861, loss_ce: 0.013531
[01:57:41.190] iteration 16502 : loss : 0.046228, loss_ce: 0.016143
[01:57:41.494] iteration 16503 : loss : 0.056547, loss_ce: 0.010892
[01:57:41.799] iteration 16504 : loss : 0.102148, loss_ce: 0.005923
[01:57:42.102] iteration 16505 : loss : 0.040439, loss_ce: 0.010899
[01:57:42.403] iteration 16506 : loss : 0.047205, loss_ce: 0.021112
[01:57:42.712] iteration 16507 : loss : 0.052407, loss_ce: 0.012485
[01:57:43.019] iteration 16508 : loss : 0.040562, loss_ce: 0.011635
[01:57:43.326] iteration 16509 : loss : 0.060435, loss_ce: 0.017032
[01:57:43.630] iteration 16510 : loss : 0.052031, loss_ce: 0.017885
[01:57:43.935] iteration 16511 : loss : 0.039136, loss_ce: 0.010729
[01:57:44.243] iteration 16512 : loss : 0.040848, loss_ce: 0.006074
[01:57:44.549] iteration 16513 : loss : 0.044234, loss_ce: 0.010148
[01:57:44.853] iteration 16514 : loss : 0.043926, loss_ce: 0.022909
[01:57:45.157] iteration 16515 : loss : 0.053822, loss_ce: 0.016222
[01:57:45.470] iteration 16516 : loss : 0.041332, loss_ce: 0.013652
[01:57:45.777] iteration 16517 : loss : 0.052214, loss_ce: 0.020947
[01:57:46.090] iteration 16518 : loss : 0.051302, loss_ce: 0.010658
[01:57:46.397] iteration 16519 : loss : 0.099843, loss_ce: 0.006893
[01:57:46.708] iteration 16520 : loss : 0.044987, loss_ce: 0.015196
[01:57:47.033] iteration 16521 : loss : 0.039133, loss_ce: 0.009377
[01:57:47.339] iteration 16522 : loss : 0.047413, loss_ce: 0.023529
[01:57:47.647] iteration 16523 : loss : 0.099732, loss_ce: 0.012123
[01:57:47.954] iteration 16524 : loss : 0.070249, loss_ce: 0.013759
[01:57:48.268] iteration 16525 : loss : 0.043023, loss_ce: 0.015658
[01:57:48.582] iteration 16526 : loss : 0.045771, loss_ce: 0.014327
[01:57:48.892] iteration 16527 : loss : 0.042556, loss_ce: 0.013662
[01:57:49.205] iteration 16528 : loss : 0.066129, loss_ce: 0.010284
[01:57:49.518] iteration 16529 : loss : 0.036725, loss_ce: 0.007063
[01:57:49.830] iteration 16530 : loss : 0.040331, loss_ce: 0.013102
[01:57:50.148] iteration 16531 : loss : 0.105767, loss_ce: 0.007586
[01:57:50.463] iteration 16532 : loss : 0.053731, loss_ce: 0.015568
[01:57:50.771] iteration 16533 : loss : 0.100200, loss_ce: 0.007728
[01:57:51.082] iteration 16534 : loss : 0.104471, loss_ce: 0.012220
[01:57:51.399] iteration 16535 : loss : 0.099435, loss_ce: 0.005734
[01:57:51.709] iteration 16536 : loss : 0.071040, loss_ce: 0.011505
[01:57:52.020] iteration 16537 : loss : 0.040707, loss_ce: 0.011132
[01:57:52.335] iteration 16538 : loss : 0.037798, loss_ce: 0.014739
[01:57:52.648] iteration 16539 : loss : 0.099694, loss_ce: 0.010887
[01:57:52.961] iteration 16540 : loss : 0.064561, loss_ce: 0.014776
[01:57:53.064] iteration 16541 : loss : 0.286879, loss_ce: 0.014312
[01:58:11.393] iteration 16542 : loss : 0.049205, loss_ce: 0.019092
[01:58:11.692] iteration 16543 : loss : 0.056579, loss_ce: 0.018936
[01:58:11.993] iteration 16544 : loss : 0.051128, loss_ce: 0.012842
[01:58:12.294] iteration 16545 : loss : 0.039177, loss_ce: 0.008070
[01:58:12.598] iteration 16546 : loss : 0.039588, loss_ce: 0.020554
[01:58:12.901] iteration 16547 : loss : 0.042149, loss_ce: 0.009470
[01:58:13.206] iteration 16548 : loss : 0.042240, loss_ce: 0.012466
[01:58:13.512] iteration 16549 : loss : 0.036830, loss_ce: 0.008893
[01:58:13.818] iteration 16550 : loss : 0.051336, loss_ce: 0.010737
[01:58:14.120] iteration 16551 : loss : 0.101349, loss_ce: 0.012275
[01:58:14.424] iteration 16552 : loss : 0.072893, loss_ce: 0.009280
[01:58:14.726] iteration 16553 : loss : 0.039357, loss_ce: 0.015904
[01:58:15.027] iteration 16554 : loss : 0.044510, loss_ce: 0.012030
[01:58:15.330] iteration 16555 : loss : 0.041866, loss_ce: 0.014119
[01:58:15.631] iteration 16556 : loss : 0.042803, loss_ce: 0.012412
[01:58:15.935] iteration 16557 : loss : 0.043909, loss_ce: 0.011948
[01:58:16.239] iteration 16558 : loss : 0.049023, loss_ce: 0.017646
[01:58:16.542] iteration 16559 : loss : 0.042614, loss_ce: 0.009843
[01:58:16.843] iteration 16560 : loss : 0.056116, loss_ce: 0.019740
[01:58:17.161] iteration 16561 : loss : 0.052832, loss_ce: 0.017075
[01:58:17.475] iteration 16562 : loss : 0.067495, loss_ce: 0.022760
[01:58:17.781] iteration 16563 : loss : 0.109425, loss_ce: 0.021250
[01:58:18.089] iteration 16564 : loss : 0.053027, loss_ce: 0.018504
[01:58:18.398] iteration 16565 : loss : 0.045350, loss_ce: 0.014986
[01:58:18.706] iteration 16566 : loss : 0.069144, loss_ce: 0.007399
[01:58:19.017] iteration 16567 : loss : 0.051151, loss_ce: 0.021820
[01:58:19.319] iteration 16568 : loss : 0.051532, loss_ce: 0.012339
[01:58:19.624] iteration 16569 : loss : 0.037579, loss_ce: 0.012882
[01:58:19.930] iteration 16570 : loss : 0.066808, loss_ce: 0.017841
[01:58:20.233] iteration 16571 : loss : 0.097814, loss_ce: 0.016885
[01:58:20.540] iteration 16572 : loss : 0.076651, loss_ce: 0.011999
[01:58:20.843] iteration 16573 : loss : 0.043813, loss_ce: 0.011439
[01:58:21.146] iteration 16574 : loss : 0.106369, loss_ce: 0.010327
[01:58:21.449] iteration 16575 : loss : 0.056388, loss_ce: 0.013644
[01:58:21.754] iteration 16576 : loss : 0.159124, loss_ce: 0.006098
[01:58:22.053] iteration 16577 : loss : 0.054779, loss_ce: 0.019514
[01:58:22.355] iteration 16578 : loss : 0.039737, loss_ce: 0.017125
[01:58:22.659] iteration 16579 : loss : 0.050029, loss_ce: 0.012780
[01:58:22.960] iteration 16580 : loss : 0.051609, loss_ce: 0.007348
[01:58:23.280] iteration 16581 : loss : 0.048362, loss_ce: 0.011073
[01:58:23.584] iteration 16582 : loss : 0.053936, loss_ce: 0.016400
[01:58:23.889] iteration 16583 : loss : 0.051173, loss_ce: 0.013112
[01:58:24.191] iteration 16584 : loss : 0.076545, loss_ce: 0.017071
[01:58:24.495] iteration 16585 : loss : 0.105256, loss_ce: 0.012521
[01:58:24.794] iteration 16586 : loss : 0.106240, loss_ce: 0.006939
[01:58:25.099] iteration 16587 : loss : 0.045858, loss_ce: 0.011024
[01:58:25.404] iteration 16588 : loss : 0.044482, loss_ce: 0.016218
[01:58:25.706] iteration 16589 : loss : 0.041251, loss_ce: 0.009789
[01:58:26.009] iteration 16590 : loss : 0.043187, loss_ce: 0.011462
[01:58:26.315] iteration 16591 : loss : 0.044853, loss_ce: 0.020751
[01:58:26.618] iteration 16592 : loss : 0.049256, loss_ce: 0.008606
[01:58:26.920] iteration 16593 : loss : 0.046341, loss_ce: 0.015568
[01:58:27.223] iteration 16594 : loss : 0.050446, loss_ce: 0.019677
[01:58:27.528] iteration 16595 : loss : 0.101682, loss_ce: 0.013873
[01:58:27.829] iteration 16596 : loss : 0.158985, loss_ce: 0.006445
[01:58:28.132] iteration 16597 : loss : 0.339738, loss_ce: 0.001146
[01:58:28.436] iteration 16598 : loss : 0.113114, loss_ce: 0.008247
[01:58:28.737] iteration 16599 : loss : 0.036119, loss_ce: 0.012897
[01:58:29.042] iteration 16600 : loss : 0.060783, loss_ce: 0.014523
[01:58:29.363] iteration 16601 : loss : 0.048401, loss_ce: 0.018528
[01:58:29.666] iteration 16602 : loss : 0.044292, loss_ce: 0.011976
[01:58:29.970] iteration 16603 : loss : 0.100594, loss_ce: 0.009466
[01:58:30.274] iteration 16604 : loss : 0.046691, loss_ce: 0.009446
[01:58:30.578] iteration 16605 : loss : 0.033228, loss_ce: 0.015946
[01:58:30.884] iteration 16606 : loss : 0.045374, loss_ce: 0.015783
[01:58:31.186] iteration 16607 : loss : 0.068733, loss_ce: 0.017650
[01:58:31.491] iteration 16608 : loss : 0.053537, loss_ce: 0.025753
[01:58:31.795] iteration 16609 : loss : 0.043711, loss_ce: 0.014771
[01:58:32.097] iteration 16610 : loss : 0.104983, loss_ce: 0.015872
[01:58:32.401] iteration 16611 : loss : 0.054495, loss_ce: 0.012785
[01:58:32.713] iteration 16612 : loss : 0.103846, loss_ce: 0.007323
[01:58:33.020] iteration 16613 : loss : 0.050540, loss_ce: 0.017223
[01:58:33.331] iteration 16614 : loss : 0.051360, loss_ce: 0.018515
[01:58:33.641] iteration 16615 : loss : 0.042866, loss_ce: 0.012855
[01:58:33.951] iteration 16616 : loss : 0.045139, loss_ce: 0.016430
[01:58:34.261] iteration 16617 : loss : 0.050978, loss_ce: 0.016933
[01:58:34.564] iteration 16618 : loss : 0.051181, loss_ce: 0.014016
[01:58:34.867] iteration 16619 : loss : 0.043371, loss_ce: 0.008789
[01:58:35.174] iteration 16620 : loss : 0.051256, loss_ce: 0.013116
[01:58:35.498] iteration 16621 : loss : 0.044086, loss_ce: 0.015065
[01:58:35.804] iteration 16622 : loss : 0.055281, loss_ce: 0.013030
[01:58:36.106] iteration 16623 : loss : 0.119750, loss_ce: 0.011747
[01:58:36.410] iteration 16624 : loss : 0.041440, loss_ce: 0.014353
[01:58:36.715] iteration 16625 : loss : 0.054156, loss_ce: 0.013320
[01:58:37.018] iteration 16626 : loss : 0.044131, loss_ce: 0.016859
[01:58:37.320] iteration 16627 : loss : 0.048792, loss_ce: 0.010408
[01:58:37.623] iteration 16628 : loss : 0.036424, loss_ce: 0.010655
[01:58:37.928] iteration 16629 : loss : 0.036997, loss_ce: 0.009690
[01:58:38.234] iteration 16630 : loss : 0.046555, loss_ce: 0.017563
[01:58:38.541] iteration 16631 : loss : 0.100578, loss_ce: 0.013329
[01:58:38.845] iteration 16632 : loss : 0.047198, loss_ce: 0.014920
[01:58:39.151] iteration 16633 : loss : 0.040709, loss_ce: 0.011782
[01:58:39.458] iteration 16634 : loss : 0.046193, loss_ce: 0.012044
[01:58:39.757] iteration 16635 : loss : 0.050889, loss_ce: 0.015538
[01:58:40.063] iteration 16636 : loss : 0.055569, loss_ce: 0.011573
[01:58:40.363] iteration 16637 : loss : 0.050644, loss_ce: 0.010995
[01:58:40.665] iteration 16638 : loss : 0.048695, loss_ce: 0.011874
[01:58:40.966] iteration 16639 : loss : 0.042348, loss_ce: 0.007287
[01:58:41.270] iteration 16640 : loss : 0.035589, loss_ce: 0.013638
[01:58:41.587] iteration 16641 : loss : 0.050252, loss_ce: 0.011802
[01:58:41.890] iteration 16642 : loss : 0.098550, loss_ce: 0.010417
[01:58:42.195] iteration 16643 : loss : 0.043165, loss_ce: 0.014250
[01:58:42.498] iteration 16644 : loss : 0.108518, loss_ce: 0.013559
[01:58:42.804] iteration 16645 : loss : 0.100630, loss_ce: 0.005175
[01:58:43.109] iteration 16646 : loss : 0.049991, loss_ce: 0.011721
[01:58:43.412] iteration 16647 : loss : 0.053966, loss_ce: 0.017161
[01:58:43.716] iteration 16648 : loss : 0.039119, loss_ce: 0.010864
[01:58:44.022] iteration 16649 : loss : 0.034624, loss_ce: 0.010885
[01:58:44.325] iteration 16650 : loss : 0.122937, loss_ce: 0.014342
[01:58:44.629] iteration 16651 : loss : 0.046197, loss_ce: 0.019545
[01:58:44.936] iteration 16652 : loss : 0.247332, loss_ce: 0.003100
[01:58:45.241] iteration 16653 : loss : 0.059664, loss_ce: 0.016592
[01:58:45.544] iteration 16654 : loss : 0.050405, loss_ce: 0.020977
[01:58:45.845] iteration 16655 : loss : 0.052481, loss_ce: 0.011808
[01:58:46.152] iteration 16656 : loss : 0.040949, loss_ce: 0.008274
[01:58:46.456] iteration 16657 : loss : 0.049537, loss_ce: 0.015771
[01:58:46.760] iteration 16658 : loss : 0.034546, loss_ce: 0.011339
[01:58:47.064] iteration 16659 : loss : 0.046087, loss_ce: 0.018152
[01:58:47.373] iteration 16660 : loss : 0.044941, loss_ce: 0.017297
[01:58:47.696] iteration 16661 : loss : 0.055677, loss_ce: 0.018738
[01:58:48.010] iteration 16662 : loss : 0.046767, loss_ce: 0.016532
[01:58:48.318] iteration 16663 : loss : 0.051159, loss_ce: 0.017832
[01:58:48.630] iteration 16664 : loss : 0.101070, loss_ce: 0.012667
[01:58:48.944] iteration 16665 : loss : 0.047820, loss_ce: 0.010906
[01:58:49.258] iteration 16666 : loss : 0.046095, loss_ce: 0.017093
[01:58:49.565] iteration 16667 : loss : 0.052434, loss_ce: 0.018944
[01:58:49.878] iteration 16668 : loss : 0.056697, loss_ce: 0.018526
[01:58:50.184] iteration 16669 : loss : 0.286020, loss_ce: 0.001508
[01:58:50.496] iteration 16670 : loss : 0.038658, loss_ce: 0.012146
[01:58:50.804] iteration 16671 : loss : 0.112068, loss_ce: 0.011418
[01:58:51.114] iteration 16672 : loss : 0.049572, loss_ce: 0.017581
[01:58:51.428] iteration 16673 : loss : 0.069830, loss_ce: 0.006805
[01:58:51.739] iteration 16674 : loss : 0.232930, loss_ce: 0.004919
[01:58:52.047] iteration 16675 : loss : 0.082714, loss_ce: 0.016494
[01:58:52.360] iteration 16676 : loss : 0.044465, loss_ce: 0.015017
[01:58:52.664] iteration 16677 : loss : 0.035717, loss_ce: 0.012972
[01:58:52.977] iteration 16678 : loss : 0.047751, loss_ce: 0.020667
[01:58:53.283] iteration 16679 : loss : 0.048600, loss_ce: 0.018469
[01:58:53.366] iteration 16680 : loss : 0.167875, loss_ce: 0.021500
[01:59:11.492] iteration 16681 : loss : 0.044140, loss_ce: 0.013453
[01:59:11.796] iteration 16682 : loss : 0.045644, loss_ce: 0.012932
[01:59:12.104] iteration 16683 : loss : 0.045363, loss_ce: 0.016534
[01:59:12.409] iteration 16684 : loss : 0.103486, loss_ce: 0.009050
[01:59:12.715] iteration 16685 : loss : 0.042654, loss_ce: 0.014128
[01:59:13.019] iteration 16686 : loss : 0.040395, loss_ce: 0.010346
[01:59:13.327] iteration 16687 : loss : 0.036845, loss_ce: 0.011944
[01:59:13.633] iteration 16688 : loss : 0.045418, loss_ce: 0.022132
[01:59:13.943] iteration 16689 : loss : 0.047564, loss_ce: 0.012432
[01:59:14.253] iteration 16690 : loss : 0.109590, loss_ce: 0.007729
[01:59:14.562] iteration 16691 : loss : 0.042723, loss_ce: 0.013914
[01:59:14.872] iteration 16692 : loss : 0.057520, loss_ce: 0.011162
[01:59:15.183] iteration 16693 : loss : 0.051072, loss_ce: 0.019218
[01:59:15.490] iteration 16694 : loss : 0.050571, loss_ce: 0.008748
[01:59:15.799] iteration 16695 : loss : 0.109124, loss_ce: 0.008708
[01:59:16.106] iteration 16696 : loss : 0.040877, loss_ce: 0.010305
[01:59:16.415] iteration 16697 : loss : 0.042964, loss_ce: 0.015950
[01:59:16.726] iteration 16698 : loss : 0.044832, loss_ce: 0.014253
[01:59:17.039] iteration 16699 : loss : 0.085816, loss_ce: 0.010710
[01:59:17.348] iteration 16700 : loss : 0.049578, loss_ce: 0.014631
[01:59:17.671] iteration 16701 : loss : 0.283550, loss_ce: 0.003143
[01:59:17.983] iteration 16702 : loss : 0.054782, loss_ce: 0.009835
[01:59:18.294] iteration 16703 : loss : 0.044550, loss_ce: 0.007696
[01:59:18.603] iteration 16704 : loss : 0.038453, loss_ce: 0.020264
[01:59:18.912] iteration 16705 : loss : 0.037527, loss_ce: 0.010685
[01:59:19.220] iteration 16706 : loss : 0.050870, loss_ce: 0.009834
[01:59:19.530] iteration 16707 : loss : 0.036511, loss_ce: 0.019702
[01:59:19.838] iteration 16708 : loss : 0.044946, loss_ce: 0.015713
[01:59:20.145] iteration 16709 : loss : 0.044883, loss_ce: 0.013807
[01:59:20.453] iteration 16710 : loss : 0.041900, loss_ce: 0.011648
[01:59:20.760] iteration 16711 : loss : 0.042431, loss_ce: 0.012554
[01:59:21.067] iteration 16712 : loss : 0.043578, loss_ce: 0.014116
[01:59:21.371] iteration 16713 : loss : 0.052902, loss_ce: 0.011842
[01:59:21.679] iteration 16714 : loss : 0.059859, loss_ce: 0.012783
[01:59:21.984] iteration 16715 : loss : 0.044836, loss_ce: 0.012193
[01:59:22.294] iteration 16716 : loss : 0.038613, loss_ce: 0.018109
[01:59:22.601] iteration 16717 : loss : 0.042129, loss_ce: 0.010997
[01:59:22.911] iteration 16718 : loss : 0.065498, loss_ce: 0.012944
[01:59:23.221] iteration 16719 : loss : 0.052416, loss_ce: 0.007698
[01:59:23.532] iteration 16720 : loss : 0.056896, loss_ce: 0.024784
[01:59:23.861] iteration 16721 : loss : 0.043861, loss_ce: 0.010786
[01:59:24.165] iteration 16722 : loss : 0.041709, loss_ce: 0.008768
[01:59:24.465] iteration 16723 : loss : 0.055031, loss_ce: 0.026379
[01:59:24.768] iteration 16724 : loss : 0.073919, loss_ce: 0.011908
[01:59:25.072] iteration 16725 : loss : 0.040151, loss_ce: 0.013401
[01:59:25.372] iteration 16726 : loss : 0.043153, loss_ce: 0.013385
[01:59:25.676] iteration 16727 : loss : 0.101975, loss_ce: 0.016021
[01:59:25.981] iteration 16728 : loss : 0.053341, loss_ce: 0.009325
[01:59:26.286] iteration 16729 : loss : 0.037564, loss_ce: 0.012787
[01:59:26.588] iteration 16730 : loss : 0.033445, loss_ce: 0.007642
[01:59:26.888] iteration 16731 : loss : 0.044901, loss_ce: 0.014936
[01:59:27.190] iteration 16732 : loss : 0.060125, loss_ce: 0.013592
[01:59:27.496] iteration 16733 : loss : 0.101742, loss_ce: 0.015074
[01:59:27.800] iteration 16734 : loss : 0.281900, loss_ce: 0.005822
[01:59:28.105] iteration 16735 : loss : 0.105848, loss_ce: 0.004919
[01:59:28.412] iteration 16736 : loss : 0.041080, loss_ce: 0.013016
[01:59:28.716] iteration 16737 : loss : 0.064020, loss_ce: 0.009460
[01:59:29.021] iteration 16738 : loss : 0.037079, loss_ce: 0.010863
[01:59:29.325] iteration 16739 : loss : 0.118556, loss_ce: 0.014324
[01:59:29.627] iteration 16740 : loss : 0.049495, loss_ce: 0.016658
[01:59:29.948] iteration 16741 : loss : 0.048595, loss_ce: 0.013746
[01:59:30.248] iteration 16742 : loss : 0.040549, loss_ce: 0.010753
[01:59:30.557] iteration 16743 : loss : 0.051092, loss_ce: 0.020576
[01:59:30.860] iteration 16744 : loss : 0.058819, loss_ce: 0.013913
[01:59:31.164] iteration 16745 : loss : 0.049865, loss_ce: 0.013818
[01:59:31.469] iteration 16746 : loss : 0.052979, loss_ce: 0.012322
[01:59:31.775] iteration 16747 : loss : 0.061322, loss_ce: 0.022005
[01:59:32.078] iteration 16748 : loss : 0.035964, loss_ce: 0.014387
[01:59:32.380] iteration 16749 : loss : 0.225939, loss_ce: 0.007773
[01:59:32.683] iteration 16750 : loss : 0.058958, loss_ce: 0.020553
[01:59:32.985] iteration 16751 : loss : 0.032112, loss_ce: 0.009842
[01:59:33.287] iteration 16752 : loss : 0.056006, loss_ce: 0.014624
[01:59:33.590] iteration 16753 : loss : 0.046428, loss_ce: 0.020996
[01:59:33.894] iteration 16754 : loss : 0.049984, loss_ce: 0.022507
[01:59:34.199] iteration 16755 : loss : 0.050087, loss_ce: 0.013109
[01:59:34.502] iteration 16756 : loss : 0.042389, loss_ce: 0.021928
[01:59:34.803] iteration 16757 : loss : 0.048990, loss_ce: 0.016542
[01:59:35.107] iteration 16758 : loss : 0.041606, loss_ce: 0.012329
[01:59:35.407] iteration 16759 : loss : 0.043386, loss_ce: 0.019027
[01:59:35.711] iteration 16760 : loss : 0.061120, loss_ce: 0.014489
[01:59:36.031] iteration 16761 : loss : 0.047907, loss_ce: 0.010353
[01:59:36.334] iteration 16762 : loss : 0.050068, loss_ce: 0.014126
[01:59:36.638] iteration 16763 : loss : 0.043181, loss_ce: 0.018261
[01:59:36.940] iteration 16764 : loss : 0.048526, loss_ce: 0.010357
[01:59:37.244] iteration 16765 : loss : 0.042777, loss_ce: 0.011827
[01:59:37.554] iteration 16766 : loss : 0.049754, loss_ce: 0.020387
[01:59:37.862] iteration 16767 : loss : 0.043679, loss_ce: 0.012265
[01:59:38.171] iteration 16768 : loss : 0.043122, loss_ce: 0.016595
[01:59:38.480] iteration 16769 : loss : 0.050649, loss_ce: 0.018294
[01:59:38.790] iteration 16770 : loss : 0.070248, loss_ce: 0.019545
[01:59:39.098] iteration 16771 : loss : 0.105368, loss_ce: 0.016403
[01:59:39.407] iteration 16772 : loss : 0.066526, loss_ce: 0.015048
[01:59:39.710] iteration 16773 : loss : 0.054771, loss_ce: 0.013735
[01:59:40.015] iteration 16774 : loss : 0.053041, loss_ce: 0.014820
[01:59:40.317] iteration 16775 : loss : 0.044666, loss_ce: 0.013182
[01:59:40.622] iteration 16776 : loss : 0.038050, loss_ce: 0.006317
[01:59:40.923] iteration 16777 : loss : 0.050148, loss_ce: 0.019184
[01:59:41.226] iteration 16778 : loss : 0.045071, loss_ce: 0.010494
[01:59:41.531] iteration 16779 : loss : 0.044131, loss_ce: 0.014236
[01:59:41.834] iteration 16780 : loss : 0.101447, loss_ce: 0.008420
[01:59:42.147] iteration 16781 : loss : 0.103619, loss_ce: 0.009768
[01:59:42.450] iteration 16782 : loss : 0.050770, loss_ce: 0.018204
[01:59:42.757] iteration 16783 : loss : 0.043045, loss_ce: 0.015115
[01:59:43.057] iteration 16784 : loss : 0.082703, loss_ce: 0.015112
[01:59:43.362] iteration 16785 : loss : 0.042022, loss_ce: 0.015165
[01:59:43.665] iteration 16786 : loss : 0.095950, loss_ce: 0.008975
[01:59:43.967] iteration 16787 : loss : 0.073943, loss_ce: 0.014636
[01:59:44.276] iteration 16788 : loss : 0.041657, loss_ce: 0.013348
[01:59:44.581] iteration 16789 : loss : 0.052529, loss_ce: 0.017528
[01:59:44.885] iteration 16790 : loss : 0.053177, loss_ce: 0.027008
[01:59:45.190] iteration 16791 : loss : 0.046595, loss_ce: 0.017618
[01:59:45.492] iteration 16792 : loss : 0.111001, loss_ce: 0.010694
[01:59:45.796] iteration 16793 : loss : 0.062915, loss_ce: 0.012245
[01:59:46.100] iteration 16794 : loss : 0.032718, loss_ce: 0.005298
[01:59:46.401] iteration 16795 : loss : 0.058220, loss_ce: 0.018185
[01:59:46.704] iteration 16796 : loss : 0.042930, loss_ce: 0.010099
[01:59:47.010] iteration 16797 : loss : 0.043873, loss_ce: 0.015385
[01:59:47.316] iteration 16798 : loss : 0.104120, loss_ce: 0.005057
[01:59:47.619] iteration 16799 : loss : 0.106767, loss_ce: 0.015975
[01:59:47.921] iteration 16800 : loss : 0.040377, loss_ce: 0.006935
[01:59:48.243] iteration 16801 : loss : 0.036868, loss_ce: 0.017652
[01:59:48.546] iteration 16802 : loss : 0.100798, loss_ce: 0.008320
[01:59:48.850] iteration 16803 : loss : 0.046774, loss_ce: 0.015722
[01:59:49.161] iteration 16804 : loss : 0.044642, loss_ce: 0.017748
[01:59:49.474] iteration 16805 : loss : 0.109684, loss_ce: 0.010349
[01:59:49.785] iteration 16806 : loss : 0.045942, loss_ce: 0.009749
[01:59:50.090] iteration 16807 : loss : 0.076719, loss_ce: 0.013775
[01:59:50.402] iteration 16808 : loss : 0.043574, loss_ce: 0.009102
[01:59:50.703] iteration 16809 : loss : 0.107355, loss_ce: 0.010293
[01:59:51.014] iteration 16810 : loss : 0.039875, loss_ce: 0.010590
[01:59:51.321] iteration 16811 : loss : 0.106651, loss_ce: 0.011109
[01:59:51.631] iteration 16812 : loss : 0.044723, loss_ce: 0.015342
[01:59:51.951] iteration 16813 : loss : 0.039037, loss_ce: 0.011204
[01:59:52.261] iteration 16814 : loss : 0.394098, loss_ce: 0.001220
[01:59:52.571] iteration 16815 : loss : 0.037886, loss_ce: 0.011689
[01:59:52.883] iteration 16816 : loss : 0.048993, loss_ce: 0.018733
[01:59:53.195] iteration 16817 : loss : 0.166656, loss_ce: 0.009325
[01:59:53.511] iteration 16818 : loss : 0.045788, loss_ce: 0.019344
[01:59:53.589] iteration 16819 : loss : 0.295820, loss_ce: 0.005224
[01:59:54.165] save model to ./logs/swin_unet\epoch_120.pth
[02:00:11.784] iteration 16820 : loss : 0.060106, loss_ce: 0.020034
[02:00:12.113] iteration 16821 : loss : 0.041579, loss_ce: 0.014908
[02:00:12.417] iteration 16822 : loss : 0.108555, loss_ce: 0.014671
[02:00:12.731] iteration 16823 : loss : 0.108170, loss_ce: 0.007063
[02:00:13.041] iteration 16824 : loss : 0.088697, loss_ce: 0.010331
[02:00:13.360] iteration 16825 : loss : 0.106800, loss_ce: 0.012803
[02:00:13.689] iteration 16826 : loss : 0.046701, loss_ce: 0.017682
[02:00:14.015] iteration 16827 : loss : 0.037866, loss_ce: 0.011121
[02:00:14.329] iteration 16828 : loss : 0.038122, loss_ce: 0.014493
[02:00:14.641] iteration 16829 : loss : 0.065293, loss_ce: 0.012998
[02:00:14.949] iteration 16830 : loss : 0.103826, loss_ce: 0.010537
[02:00:15.259] iteration 16831 : loss : 0.060165, loss_ce: 0.014514
[02:00:15.589] iteration 16832 : loss : 0.045926, loss_ce: 0.012173
[02:00:15.908] iteration 16833 : loss : 0.045796, loss_ce: 0.012696
[02:00:16.232] iteration 16834 : loss : 0.049251, loss_ce: 0.013098
[02:00:16.558] iteration 16835 : loss : 0.056507, loss_ce: 0.010431
[02:00:16.889] iteration 16836 : loss : 0.110161, loss_ce: 0.016444
[02:00:17.189] iteration 16837 : loss : 0.042770, loss_ce: 0.015839
[02:00:17.491] iteration 16838 : loss : 0.049737, loss_ce: 0.017868
[02:00:17.794] iteration 16839 : loss : 0.059456, loss_ce: 0.009793
[02:00:18.098] iteration 16840 : loss : 0.052267, loss_ce: 0.012250
[02:00:18.422] iteration 16841 : loss : 0.053788, loss_ce: 0.017630
[02:00:18.726] iteration 16842 : loss : 0.045153, loss_ce: 0.011863
[02:00:19.028] iteration 16843 : loss : 0.051482, loss_ce: 0.008277
[02:00:19.330] iteration 16844 : loss : 0.054645, loss_ce: 0.012512
[02:00:19.633] iteration 16845 : loss : 0.050709, loss_ce: 0.009474
[02:00:19.935] iteration 16846 : loss : 0.049043, loss_ce: 0.011945
[02:00:20.236] iteration 16847 : loss : 0.054454, loss_ce: 0.012792
[02:00:20.537] iteration 16848 : loss : 0.044630, loss_ce: 0.022047
[02:00:20.838] iteration 16849 : loss : 0.189977, loss_ce: 0.005116
[02:00:21.140] iteration 16850 : loss : 0.096087, loss_ce: 0.008787
[02:00:21.440] iteration 16851 : loss : 0.047890, loss_ce: 0.020417
[02:00:21.741] iteration 16852 : loss : 0.050510, loss_ce: 0.011154
[02:00:22.044] iteration 16853 : loss : 0.109999, loss_ce: 0.011381
[02:00:22.349] iteration 16854 : loss : 0.033276, loss_ce: 0.010435
[02:00:22.653] iteration 16855 : loss : 0.063306, loss_ce: 0.015587
[02:00:22.959] iteration 16856 : loss : 0.046527, loss_ce: 0.012480
[02:00:23.264] iteration 16857 : loss : 0.037259, loss_ce: 0.011402
[02:00:23.570] iteration 16858 : loss : 0.040520, loss_ce: 0.012104
[02:00:23.876] iteration 16859 : loss : 0.050786, loss_ce: 0.023505
[02:00:24.181] iteration 16860 : loss : 0.101628, loss_ce: 0.013155
[02:00:24.496] iteration 16861 : loss : 0.050748, loss_ce: 0.016398
[02:00:24.801] iteration 16862 : loss : 0.101845, loss_ce: 0.010700
[02:00:25.105] iteration 16863 : loss : 0.043541, loss_ce: 0.015343
[02:00:25.409] iteration 16864 : loss : 0.042892, loss_ce: 0.011895
[02:00:25.716] iteration 16865 : loss : 0.046680, loss_ce: 0.018253
[02:00:26.022] iteration 16866 : loss : 0.051876, loss_ce: 0.019241
[02:00:26.329] iteration 16867 : loss : 0.038731, loss_ce: 0.015259
[02:00:26.634] iteration 16868 : loss : 0.037842, loss_ce: 0.017957
[02:00:26.942] iteration 16869 : loss : 0.055272, loss_ce: 0.020925
[02:00:27.248] iteration 16870 : loss : 0.049756, loss_ce: 0.015398
[02:00:27.553] iteration 16871 : loss : 0.047603, loss_ce: 0.023841
[02:00:27.863] iteration 16872 : loss : 0.101179, loss_ce: 0.003857
[02:00:28.173] iteration 16873 : loss : 0.097810, loss_ce: 0.006381
[02:00:28.479] iteration 16874 : loss : 0.093164, loss_ce: 0.012230
[02:00:28.790] iteration 16875 : loss : 0.040784, loss_ce: 0.011099
[02:00:29.099] iteration 16876 : loss : 0.056870, loss_ce: 0.021713
[02:00:29.408] iteration 16877 : loss : 0.050324, loss_ce: 0.014320
[02:00:29.717] iteration 16878 : loss : 0.047619, loss_ce: 0.011028
[02:00:30.024] iteration 16879 : loss : 0.039273, loss_ce: 0.007357
[02:00:30.331] iteration 16880 : loss : 0.053717, loss_ce: 0.015434
[02:00:30.655] iteration 16881 : loss : 0.053433, loss_ce: 0.010609
[02:00:30.961] iteration 16882 : loss : 0.115663, loss_ce: 0.007983
[02:00:31.266] iteration 16883 : loss : 0.050929, loss_ce: 0.012930
[02:00:31.574] iteration 16884 : loss : 0.041358, loss_ce: 0.011191
[02:00:31.881] iteration 16885 : loss : 0.051973, loss_ce: 0.011500
[02:00:32.190] iteration 16886 : loss : 0.043904, loss_ce: 0.021049
[02:00:32.497] iteration 16887 : loss : 0.036053, loss_ce: 0.012316
[02:00:32.805] iteration 16888 : loss : 0.043943, loss_ce: 0.014451
[02:00:33.113] iteration 16889 : loss : 0.040028, loss_ce: 0.015986
[02:00:33.423] iteration 16890 : loss : 0.110650, loss_ce: 0.015977
[02:00:33.729] iteration 16891 : loss : 0.046974, loss_ce: 0.008035
[02:00:34.037] iteration 16892 : loss : 0.043706, loss_ce: 0.016903
[02:00:34.342] iteration 16893 : loss : 0.040823, loss_ce: 0.007865
[02:00:34.650] iteration 16894 : loss : 0.105368, loss_ce: 0.010168
[02:00:34.960] iteration 16895 : loss : 0.161444, loss_ce: 0.009888
[02:00:35.273] iteration 16896 : loss : 0.038571, loss_ce: 0.016864
[02:00:35.579] iteration 16897 : loss : 0.103806, loss_ce: 0.016765
[02:00:35.890] iteration 16898 : loss : 0.042847, loss_ce: 0.015665
[02:00:36.196] iteration 16899 : loss : 0.039682, loss_ce: 0.007766
[02:00:36.507] iteration 16900 : loss : 0.043639, loss_ce: 0.014788
[02:00:36.837] iteration 16901 : loss : 0.064100, loss_ce: 0.022555
[02:00:37.140] iteration 16902 : loss : 0.043088, loss_ce: 0.010975
[02:00:37.450] iteration 16903 : loss : 0.110194, loss_ce: 0.009904
[02:00:37.757] iteration 16904 : loss : 0.043188, loss_ce: 0.022521
[02:00:38.062] iteration 16905 : loss : 0.044491, loss_ce: 0.012039
[02:00:38.371] iteration 16906 : loss : 0.040282, loss_ce: 0.010584
[02:00:38.680] iteration 16907 : loss : 0.161867, loss_ce: 0.012677
[02:00:38.987] iteration 16908 : loss : 0.055338, loss_ce: 0.009411
[02:00:39.297] iteration 16909 : loss : 0.051033, loss_ce: 0.016463
[02:00:39.603] iteration 16910 : loss : 0.053702, loss_ce: 0.011360
[02:00:39.913] iteration 16911 : loss : 0.102693, loss_ce: 0.009766
[02:00:40.219] iteration 16912 : loss : 0.043570, loss_ce: 0.012226
[02:00:40.526] iteration 16913 : loss : 0.109139, loss_ce: 0.020911
[02:00:40.837] iteration 16914 : loss : 0.057633, loss_ce: 0.014559
[02:00:41.150] iteration 16915 : loss : 0.049019, loss_ce: 0.016573
[02:00:41.457] iteration 16916 : loss : 0.051160, loss_ce: 0.010884
[02:00:41.768] iteration 16917 : loss : 0.048189, loss_ce: 0.017233
[02:00:42.074] iteration 16918 : loss : 0.051907, loss_ce: 0.016782
[02:00:42.386] iteration 16919 : loss : 0.046068, loss_ce: 0.013428
[02:00:42.693] iteration 16920 : loss : 0.055449, loss_ce: 0.016971
[02:00:43.013] iteration 16921 : loss : 0.039609, loss_ce: 0.009543
[02:00:43.320] iteration 16922 : loss : 0.061262, loss_ce: 0.009963
[02:00:43.628] iteration 16923 : loss : 0.155147, loss_ce: 0.008175
[02:00:43.935] iteration 16924 : loss : 0.044114, loss_ce: 0.021297
[02:00:44.242] iteration 16925 : loss : 0.044226, loss_ce: 0.010353
[02:00:44.547] iteration 16926 : loss : 0.049448, loss_ce: 0.017278
[02:00:44.852] iteration 16927 : loss : 0.106269, loss_ce: 0.014454
[02:00:45.158] iteration 16928 : loss : 0.036019, loss_ce: 0.008492
[02:00:45.462] iteration 16929 : loss : 0.042754, loss_ce: 0.007988
[02:00:45.767] iteration 16930 : loss : 0.092541, loss_ce: 0.008018
[02:00:46.070] iteration 16931 : loss : 0.056369, loss_ce: 0.014619
[02:00:46.374] iteration 16932 : loss : 0.164568, loss_ce: 0.007403
[02:00:46.677] iteration 16933 : loss : 0.035650, loss_ce: 0.014267
[02:00:46.984] iteration 16934 : loss : 0.059861, loss_ce: 0.018613
[02:00:47.286] iteration 16935 : loss : 0.047569, loss_ce: 0.014988
[02:00:47.593] iteration 16936 : loss : 0.099390, loss_ce: 0.020679
[02:00:47.898] iteration 16937 : loss : 0.049162, loss_ce: 0.018081
[02:00:48.202] iteration 16938 : loss : 0.102639, loss_ce: 0.004822
[02:00:48.503] iteration 16939 : loss : 0.044437, loss_ce: 0.018379
[02:00:48.806] iteration 16940 : loss : 0.044123, loss_ce: 0.014223
[02:00:49.122] iteration 16941 : loss : 0.047894, loss_ce: 0.015906
[02:00:49.425] iteration 16942 : loss : 0.048995, loss_ce: 0.010089
[02:00:49.730] iteration 16943 : loss : 0.046868, loss_ce: 0.010207
[02:00:50.033] iteration 16944 : loss : 0.101588, loss_ce: 0.012853
[02:00:50.340] iteration 16945 : loss : 0.117776, loss_ce: 0.006437
[02:00:50.654] iteration 16946 : loss : 0.044431, loss_ce: 0.007826
[02:00:50.965] iteration 16947 : loss : 0.066234, loss_ce: 0.008694
[02:00:51.277] iteration 16948 : loss : 0.160955, loss_ce: 0.005812
[02:00:51.588] iteration 16949 : loss : 0.069390, loss_ce: 0.022757
[02:00:51.896] iteration 16950 : loss : 0.057398, loss_ce: 0.018115
[02:00:52.202] iteration 16951 : loss : 0.043275, loss_ce: 0.017406
[02:00:52.519] iteration 16952 : loss : 0.159125, loss_ce: 0.011891
[02:00:52.832] iteration 16953 : loss : 0.039436, loss_ce: 0.013811
[02:00:53.146] iteration 16954 : loss : 0.039110, loss_ce: 0.009651
[02:00:53.455] iteration 16955 : loss : 0.102415, loss_ce: 0.016683
[02:00:53.762] iteration 16956 : loss : 0.057055, loss_ce: 0.013886
[02:00:54.070] iteration 16957 : loss : 0.041586, loss_ce: 0.013857
[02:00:54.163] iteration 16958 : loss : 0.190169, loss_ce: 0.025431
[02:01:11.456] iteration 16959 : loss : 0.052935, loss_ce: 0.018134
[02:01:11.762] iteration 16960 : loss : 0.115275, loss_ce: 0.013518
[02:01:12.077] iteration 16961 : loss : 0.040106, loss_ce: 0.013054
[02:01:12.384] iteration 16962 : loss : 0.042466, loss_ce: 0.015431
[02:01:12.690] iteration 16963 : loss : 0.059855, loss_ce: 0.005563
[02:01:13.003] iteration 16964 : loss : 0.051002, loss_ce: 0.018729
[02:01:13.311] iteration 16965 : loss : 0.044861, loss_ce: 0.015462
[02:01:13.619] iteration 16966 : loss : 0.040639, loss_ce: 0.005459
[02:01:13.925] iteration 16967 : loss : 0.033664, loss_ce: 0.008767
[02:01:14.235] iteration 16968 : loss : 0.044968, loss_ce: 0.015244
[02:01:14.538] iteration 16969 : loss : 0.109155, loss_ce: 0.009744
[02:01:14.845] iteration 16970 : loss : 0.050580, loss_ce: 0.020030
[02:01:15.147] iteration 16971 : loss : 0.109088, loss_ce: 0.014919
[02:01:15.451] iteration 16972 : loss : 0.042707, loss_ce: 0.020068
[02:01:15.752] iteration 16973 : loss : 0.048972, loss_ce: 0.017093
[02:01:16.058] iteration 16974 : loss : 0.056568, loss_ce: 0.016075
[02:01:16.362] iteration 16975 : loss : 0.098800, loss_ce: 0.008689
[02:01:16.669] iteration 16976 : loss : 0.217151, loss_ce: 0.009988
[02:01:16.973] iteration 16977 : loss : 0.057242, loss_ce: 0.018649
[02:01:17.277] iteration 16978 : loss : 0.049240, loss_ce: 0.015548
[02:01:17.584] iteration 16979 : loss : 0.044991, loss_ce: 0.011318
[02:01:17.890] iteration 16980 : loss : 0.054985, loss_ce: 0.018257
[02:01:18.211] iteration 16981 : loss : 0.052644, loss_ce: 0.012157
[02:01:18.514] iteration 16982 : loss : 0.047262, loss_ce: 0.013064
[02:01:18.823] iteration 16983 : loss : 0.049518, loss_ce: 0.018287
[02:01:19.129] iteration 16984 : loss : 0.043291, loss_ce: 0.012482
[02:01:19.431] iteration 16985 : loss : 0.051266, loss_ce: 0.013276
[02:01:19.735] iteration 16986 : loss : 0.099897, loss_ce: 0.013525
[02:01:20.045] iteration 16987 : loss : 0.219983, loss_ce: 0.009092
[02:01:20.349] iteration 16988 : loss : 0.045695, loss_ce: 0.009772
[02:01:20.651] iteration 16989 : loss : 0.196514, loss_ce: 0.014729
[02:01:20.956] iteration 16990 : loss : 0.044884, loss_ce: 0.017768
[02:01:21.263] iteration 16991 : loss : 0.067738, loss_ce: 0.019365
[02:01:21.569] iteration 16992 : loss : 0.106284, loss_ce: 0.008544
[02:01:21.874] iteration 16993 : loss : 0.049082, loss_ce: 0.012643
[02:01:22.178] iteration 16994 : loss : 0.037529, loss_ce: 0.010865
[02:01:22.480] iteration 16995 : loss : 0.041989, loss_ce: 0.008919
[02:01:22.779] iteration 16996 : loss : 0.065058, loss_ce: 0.016676
[02:01:23.081] iteration 16997 : loss : 0.086176, loss_ce: 0.006624
[02:01:23.386] iteration 16998 : loss : 0.046863, loss_ce: 0.011783
[02:01:23.691] iteration 16999 : loss : 0.279059, loss_ce: 0.003608
[02:01:23.993] iteration 17000 : loss : 0.044490, loss_ce: 0.010802
[02:01:24.311] iteration 17001 : loss : 0.039819, loss_ce: 0.018623
[02:01:24.612] iteration 17002 : loss : 0.054045, loss_ce: 0.005422
[02:01:24.915] iteration 17003 : loss : 0.044730, loss_ce: 0.022250
[02:01:25.218] iteration 17004 : loss : 0.101303, loss_ce: 0.011007
[02:01:25.518] iteration 17005 : loss : 0.047799, loss_ce: 0.014989
[02:01:25.824] iteration 17006 : loss : 0.044659, loss_ce: 0.014663
[02:01:26.124] iteration 17007 : loss : 0.040687, loss_ce: 0.016120
[02:01:26.425] iteration 17008 : loss : 0.047234, loss_ce: 0.013023
[02:01:26.730] iteration 17009 : loss : 0.109343, loss_ce: 0.013981
[02:01:27.033] iteration 17010 : loss : 0.037220, loss_ce: 0.011507
[02:01:27.341] iteration 17011 : loss : 0.048716, loss_ce: 0.016089
[02:01:27.652] iteration 17012 : loss : 0.040873, loss_ce: 0.013946
[02:01:27.960] iteration 17013 : loss : 0.079663, loss_ce: 0.013234
[02:01:28.273] iteration 17014 : loss : 0.158425, loss_ce: 0.007224
[02:01:28.579] iteration 17015 : loss : 0.110164, loss_ce: 0.010847
[02:01:28.891] iteration 17016 : loss : 0.046239, loss_ce: 0.017642
[02:01:29.200] iteration 17017 : loss : 0.061935, loss_ce: 0.018243
[02:01:29.504] iteration 17018 : loss : 0.043445, loss_ce: 0.018870
[02:01:29.811] iteration 17019 : loss : 0.045303, loss_ce: 0.012304
[02:01:30.115] iteration 17020 : loss : 0.074171, loss_ce: 0.018843
[02:01:30.434] iteration 17021 : loss : 0.045500, loss_ce: 0.014804
[02:01:30.736] iteration 17022 : loss : 0.045995, loss_ce: 0.013325
[02:01:31.044] iteration 17023 : loss : 0.034525, loss_ce: 0.010575
[02:01:31.349] iteration 17024 : loss : 0.045471, loss_ce: 0.013613
[02:01:31.655] iteration 17025 : loss : 0.047043, loss_ce: 0.015810
[02:01:31.958] iteration 17026 : loss : 0.048224, loss_ce: 0.010417
[02:01:32.261] iteration 17027 : loss : 0.031267, loss_ce: 0.012769
[02:01:32.560] iteration 17028 : loss : 0.059063, loss_ce: 0.020046
[02:01:32.863] iteration 17029 : loss : 0.050303, loss_ce: 0.019098
[02:01:33.166] iteration 17030 : loss : 0.040393, loss_ce: 0.012336
[02:01:33.472] iteration 17031 : loss : 0.047212, loss_ce: 0.021117
[02:01:33.775] iteration 17032 : loss : 0.091049, loss_ce: 0.012424
[02:01:34.079] iteration 17033 : loss : 0.096950, loss_ce: 0.010765
[02:01:34.383] iteration 17034 : loss : 0.041615, loss_ce: 0.007812
[02:01:34.686] iteration 17035 : loss : 0.159176, loss_ce: 0.011934
[02:01:34.987] iteration 17036 : loss : 0.104034, loss_ce: 0.015925
[02:01:35.288] iteration 17037 : loss : 0.034197, loss_ce: 0.008659
[02:01:35.590] iteration 17038 : loss : 0.057032, loss_ce: 0.016819
[02:01:35.893] iteration 17039 : loss : 0.048781, loss_ce: 0.022163
[02:01:36.197] iteration 17040 : loss : 0.098240, loss_ce: 0.011260
[02:01:36.512] iteration 17041 : loss : 0.045435, loss_ce: 0.014767
[02:01:36.813] iteration 17042 : loss : 0.044865, loss_ce: 0.013411
[02:01:37.118] iteration 17043 : loss : 0.045106, loss_ce: 0.012837
[02:01:37.423] iteration 17044 : loss : 0.052133, loss_ce: 0.022571
[02:01:37.728] iteration 17045 : loss : 0.044570, loss_ce: 0.013805
[02:01:38.030] iteration 17046 : loss : 0.036277, loss_ce: 0.014916
[02:01:38.335] iteration 17047 : loss : 0.107131, loss_ce: 0.015815
[02:01:38.639] iteration 17048 : loss : 0.037953, loss_ce: 0.013039
[02:01:38.941] iteration 17049 : loss : 0.055076, loss_ce: 0.008886
[02:01:39.249] iteration 17050 : loss : 0.041562, loss_ce: 0.011766
[02:01:39.553] iteration 17051 : loss : 0.045037, loss_ce: 0.013132
[02:01:39.854] iteration 17052 : loss : 0.043873, loss_ce: 0.011748
[02:01:40.160] iteration 17053 : loss : 0.041651, loss_ce: 0.006619
[02:01:40.463] iteration 17054 : loss : 0.129628, loss_ce: 0.011321
[02:01:40.765] iteration 17055 : loss : 0.055377, loss_ce: 0.019786
[02:01:41.069] iteration 17056 : loss : 0.061438, loss_ce: 0.007182
[02:01:41.375] iteration 17057 : loss : 0.101529, loss_ce: 0.010576
[02:01:41.678] iteration 17058 : loss : 0.061794, loss_ce: 0.025594
[02:01:41.982] iteration 17059 : loss : 0.112013, loss_ce: 0.014093
[02:01:42.283] iteration 17060 : loss : 0.047065, loss_ce: 0.012222
[02:01:42.609] iteration 17061 : loss : 0.044301, loss_ce: 0.013143
[02:01:42.912] iteration 17062 : loss : 0.037353, loss_ce: 0.011615
[02:01:43.221] iteration 17063 : loss : 0.052063, loss_ce: 0.013161
[02:01:43.528] iteration 17064 : loss : 0.053150, loss_ce: 0.012770
[02:01:43.836] iteration 17065 : loss : 0.112527, loss_ce: 0.006520
[02:01:44.140] iteration 17066 : loss : 0.044000, loss_ce: 0.014130
[02:01:44.446] iteration 17067 : loss : 0.047519, loss_ce: 0.017115
[02:01:44.752] iteration 17068 : loss : 0.117594, loss_ce: 0.013103
[02:01:45.059] iteration 17069 : loss : 0.040066, loss_ce: 0.007062
[02:01:45.370] iteration 17070 : loss : 0.049660, loss_ce: 0.011383
[02:01:45.679] iteration 17071 : loss : 0.097589, loss_ce: 0.008451
[02:01:45.989] iteration 17072 : loss : 0.047191, loss_ce: 0.014007
[02:01:46.299] iteration 17073 : loss : 0.053932, loss_ce: 0.021706
[02:01:46.611] iteration 17074 : loss : 0.042312, loss_ce: 0.014946
[02:01:46.920] iteration 17075 : loss : 0.051826, loss_ce: 0.013303
[02:01:47.228] iteration 17076 : loss : 0.048677, loss_ce: 0.015861
[02:01:47.538] iteration 17077 : loss : 0.102959, loss_ce: 0.010540
[02:01:47.846] iteration 17078 : loss : 0.069601, loss_ce: 0.015770
[02:01:48.155] iteration 17079 : loss : 0.045078, loss_ce: 0.022097
[02:01:48.462] iteration 17080 : loss : 0.057213, loss_ce: 0.010188
[02:01:48.789] iteration 17081 : loss : 0.036739, loss_ce: 0.010339
[02:01:49.098] iteration 17082 : loss : 0.057202, loss_ce: 0.023260
[02:01:49.409] iteration 17083 : loss : 0.048646, loss_ce: 0.022829
[02:01:49.722] iteration 17084 : loss : 0.053378, loss_ce: 0.023265
[02:01:50.033] iteration 17085 : loss : 0.106266, loss_ce: 0.018607
[02:01:50.343] iteration 17086 : loss : 0.105785, loss_ce: 0.008975
[02:01:50.655] iteration 17087 : loss : 0.048134, loss_ce: 0.014095
[02:01:50.963] iteration 17088 : loss : 0.044152, loss_ce: 0.009322
[02:01:51.274] iteration 17089 : loss : 0.041098, loss_ce: 0.014389
[02:01:51.587] iteration 17090 : loss : 0.048054, loss_ce: 0.013028
[02:01:51.899] iteration 17091 : loss : 0.038766, loss_ce: 0.009113
[02:01:52.213] iteration 17092 : loss : 0.041048, loss_ce: 0.008692
[02:01:52.527] iteration 17093 : loss : 0.041298, loss_ce: 0.008351
[02:01:52.839] iteration 17094 : loss : 0.042420, loss_ce: 0.017228
[02:01:53.155] iteration 17095 : loss : 0.039279, loss_ce: 0.007656
[02:01:53.461] iteration 17096 : loss : 0.101055, loss_ce: 0.005805
[02:01:53.543] iteration 17097 : loss : 0.222146, loss_ce: 0.018626
[02:02:12.983] iteration 17098 : loss : 0.062292, loss_ce: 0.016367
[02:02:13.282] iteration 17099 : loss : 0.046217, loss_ce: 0.016735
[02:02:13.579] iteration 17100 : loss : 0.043484, loss_ce: 0.010455
[02:02:13.892] iteration 17101 : loss : 0.100012, loss_ce: 0.008442
[02:02:14.193] iteration 17102 : loss : 0.105534, loss_ce: 0.014313
[02:02:14.496] iteration 17103 : loss : 0.050592, loss_ce: 0.016189
[02:02:14.799] iteration 17104 : loss : 0.043598, loss_ce: 0.014311
[02:02:15.101] iteration 17105 : loss : 0.035883, loss_ce: 0.013156
[02:02:15.403] iteration 17106 : loss : 0.046621, loss_ce: 0.009546
[02:02:15.702] iteration 17107 : loss : 0.099553, loss_ce: 0.012473
[02:02:16.004] iteration 17108 : loss : 0.039731, loss_ce: 0.013607
[02:02:16.304] iteration 17109 : loss : 0.038663, loss_ce: 0.009779
[02:02:16.604] iteration 17110 : loss : 0.055312, loss_ce: 0.015274
[02:02:16.910] iteration 17111 : loss : 0.052811, loss_ce: 0.011857
[02:02:17.214] iteration 17112 : loss : 0.043521, loss_ce: 0.012248
[02:02:17.520] iteration 17113 : loss : 0.053366, loss_ce: 0.013950
[02:02:17.832] iteration 17114 : loss : 0.056314, loss_ce: 0.023235
[02:02:18.142] iteration 17115 : loss : 0.048611, loss_ce: 0.016387
[02:02:18.449] iteration 17116 : loss : 0.045882, loss_ce: 0.011792
[02:02:18.756] iteration 17117 : loss : 0.045481, loss_ce: 0.012701
[02:02:19.066] iteration 17118 : loss : 0.039378, loss_ce: 0.013739
[02:02:19.367] iteration 17119 : loss : 0.041481, loss_ce: 0.016790
[02:02:19.673] iteration 17120 : loss : 0.041115, loss_ce: 0.009237
[02:02:19.991] iteration 17121 : loss : 0.050464, loss_ce: 0.009104
[02:02:20.293] iteration 17122 : loss : 0.034735, loss_ce: 0.010232
[02:02:20.593] iteration 17123 : loss : 0.107750, loss_ce: 0.013164
[02:02:20.895] iteration 17124 : loss : 0.057538, loss_ce: 0.020744
[02:02:21.197] iteration 17125 : loss : 0.103135, loss_ce: 0.008951
[02:02:21.501] iteration 17126 : loss : 0.045785, loss_ce: 0.015141
[02:02:21.803] iteration 17127 : loss : 0.041395, loss_ce: 0.012519
[02:02:22.107] iteration 17128 : loss : 0.056076, loss_ce: 0.007574
[02:02:22.411] iteration 17129 : loss : 0.056330, loss_ce: 0.019014
[02:02:22.714] iteration 17130 : loss : 0.047998, loss_ce: 0.005338
[02:02:23.016] iteration 17131 : loss : 0.087376, loss_ce: 0.011817
[02:02:23.319] iteration 17132 : loss : 0.043999, loss_ce: 0.011575
[02:02:23.620] iteration 17133 : loss : 0.047957, loss_ce: 0.010526
[02:02:23.928] iteration 17134 : loss : 0.093957, loss_ce: 0.009497
[02:02:24.231] iteration 17135 : loss : 0.049680, loss_ce: 0.015100
[02:02:24.533] iteration 17136 : loss : 0.034537, loss_ce: 0.011198
[02:02:24.835] iteration 17137 : loss : 0.044111, loss_ce: 0.013367
[02:02:25.142] iteration 17138 : loss : 0.104607, loss_ce: 0.008731
[02:02:25.445] iteration 17139 : loss : 0.047096, loss_ce: 0.018944
[02:02:25.751] iteration 17140 : loss : 0.046122, loss_ce: 0.011892
[02:02:26.071] iteration 17141 : loss : 0.051721, loss_ce: 0.017996
[02:02:26.372] iteration 17142 : loss : 0.048798, loss_ce: 0.018790
[02:02:26.678] iteration 17143 : loss : 0.054648, loss_ce: 0.017500
[02:02:26.986] iteration 17144 : loss : 0.105851, loss_ce: 0.008025
[02:02:27.287] iteration 17145 : loss : 0.034328, loss_ce: 0.010048
[02:02:27.594] iteration 17146 : loss : 0.041572, loss_ce: 0.014418
[02:02:27.900] iteration 17147 : loss : 0.054859, loss_ce: 0.008980
[02:02:28.203] iteration 17148 : loss : 0.045824, loss_ce: 0.013913
[02:02:28.506] iteration 17149 : loss : 0.040861, loss_ce: 0.021304
[02:02:28.812] iteration 17150 : loss : 0.051495, loss_ce: 0.019076
[02:02:29.114] iteration 17151 : loss : 0.043509, loss_ce: 0.018880
[02:02:29.414] iteration 17152 : loss : 0.038466, loss_ce: 0.011220
[02:02:29.716] iteration 17153 : loss : 0.034066, loss_ce: 0.017962
[02:02:30.020] iteration 17154 : loss : 0.055442, loss_ce: 0.012650
[02:02:30.323] iteration 17155 : loss : 0.041606, loss_ce: 0.017655
[02:02:30.627] iteration 17156 : loss : 0.118375, loss_ce: 0.007076
[02:02:30.928] iteration 17157 : loss : 0.043543, loss_ce: 0.011649
[02:02:31.233] iteration 17158 : loss : 0.058610, loss_ce: 0.010221
[02:02:31.539] iteration 17159 : loss : 0.044549, loss_ce: 0.007896
[02:02:31.840] iteration 17160 : loss : 0.045670, loss_ce: 0.020116
[02:02:32.155] iteration 17161 : loss : 0.043352, loss_ce: 0.018049
[02:02:32.462] iteration 17162 : loss : 0.039489, loss_ce: 0.007800
[02:02:32.770] iteration 17163 : loss : 0.102761, loss_ce: 0.012511
[02:02:33.076] iteration 17164 : loss : 0.045188, loss_ce: 0.017851
[02:02:33.390] iteration 17165 : loss : 0.102822, loss_ce: 0.010505
[02:02:33.700] iteration 17166 : loss : 0.050797, loss_ce: 0.009651
[02:02:34.009] iteration 17167 : loss : 0.070627, loss_ce: 0.012291
[02:02:34.318] iteration 17168 : loss : 0.107781, loss_ce: 0.008741
[02:02:34.629] iteration 17169 : loss : 0.042922, loss_ce: 0.017122
[02:02:34.932] iteration 17170 : loss : 0.101341, loss_ce: 0.016574
[02:02:35.235] iteration 17171 : loss : 0.067891, loss_ce: 0.013002
[02:02:35.539] iteration 17172 : loss : 0.047199, loss_ce: 0.016341
[02:02:35.844] iteration 17173 : loss : 0.046565, loss_ce: 0.012693
[02:02:36.149] iteration 17174 : loss : 0.041017, loss_ce: 0.011229
[02:02:36.451] iteration 17175 : loss : 0.044071, loss_ce: 0.016584
[02:02:36.756] iteration 17176 : loss : 0.055615, loss_ce: 0.017054
[02:02:37.063] iteration 17177 : loss : 0.044759, loss_ce: 0.012656
[02:02:37.368] iteration 17178 : loss : 0.098340, loss_ce: 0.003854
[02:02:37.670] iteration 17179 : loss : 0.045375, loss_ce: 0.015934
[02:02:37.973] iteration 17180 : loss : 0.047856, loss_ce: 0.011645
[02:02:38.289] iteration 17181 : loss : 0.037414, loss_ce: 0.012076
[02:02:38.593] iteration 17182 : loss : 0.051897, loss_ce: 0.025802
[02:02:38.899] iteration 17183 : loss : 0.043240, loss_ce: 0.013866
[02:02:39.202] iteration 17184 : loss : 0.043247, loss_ce: 0.019330
[02:02:39.506] iteration 17185 : loss : 0.054286, loss_ce: 0.016897
[02:02:39.813] iteration 17186 : loss : 0.047809, loss_ce: 0.013387
[02:02:40.120] iteration 17187 : loss : 0.054266, loss_ce: 0.011050
[02:02:40.423] iteration 17188 : loss : 0.104804, loss_ce: 0.011287
[02:02:40.730] iteration 17189 : loss : 0.054751, loss_ce: 0.013667
[02:02:41.037] iteration 17190 : loss : 0.051963, loss_ce: 0.015011
[02:02:41.340] iteration 17191 : loss : 0.041120, loss_ce: 0.011577
[02:02:41.644] iteration 17192 : loss : 0.049628, loss_ce: 0.018955
[02:02:41.949] iteration 17193 : loss : 0.046661, loss_ce: 0.015639
[02:02:42.251] iteration 17194 : loss : 0.044927, loss_ce: 0.013688
[02:02:42.553] iteration 17195 : loss : 0.037175, loss_ce: 0.008636
[02:02:42.859] iteration 17196 : loss : 0.044754, loss_ce: 0.012529
[02:02:43.165] iteration 17197 : loss : 0.094474, loss_ce: 0.007573
[02:02:43.471] iteration 17198 : loss : 0.053099, loss_ce: 0.010727
[02:02:43.778] iteration 17199 : loss : 0.042005, loss_ce: 0.012610
[02:02:44.085] iteration 17200 : loss : 0.116808, loss_ce: 0.010202
[02:02:44.407] iteration 17201 : loss : 0.047500, loss_ce: 0.017819
[02:02:44.710] iteration 17202 : loss : 0.074709, loss_ce: 0.010561
[02:02:45.017] iteration 17203 : loss : 0.036303, loss_ce: 0.011092
[02:02:45.323] iteration 17204 : loss : 0.051664, loss_ce: 0.009636
[02:02:45.630] iteration 17205 : loss : 0.038294, loss_ce: 0.013462
[02:02:45.936] iteration 17206 : loss : 0.106787, loss_ce: 0.009085
[02:02:46.239] iteration 17207 : loss : 0.044786, loss_ce: 0.016442
[02:02:46.541] iteration 17208 : loss : 0.037178, loss_ce: 0.019540
[02:02:46.846] iteration 17209 : loss : 0.048312, loss_ce: 0.015445
[02:02:47.151] iteration 17210 : loss : 0.032222, loss_ce: 0.010773
[02:02:47.463] iteration 17211 : loss : 0.035219, loss_ce: 0.015817
[02:02:47.770] iteration 17212 : loss : 0.099052, loss_ce: 0.011272
[02:02:48.084] iteration 17213 : loss : 0.045013, loss_ce: 0.021785
[02:02:48.391] iteration 17214 : loss : 0.052052, loss_ce: 0.011197
[02:02:48.703] iteration 17215 : loss : 0.100195, loss_ce: 0.014528
[02:02:49.016] iteration 17216 : loss : 0.101727, loss_ce: 0.010575
[02:02:49.320] iteration 17217 : loss : 0.100923, loss_ce: 0.011810
[02:02:49.624] iteration 17218 : loss : 0.098028, loss_ce: 0.010107
[02:02:49.928] iteration 17219 : loss : 0.047065, loss_ce: 0.021778
[02:02:50.237] iteration 17220 : loss : 0.041531, loss_ce: 0.014356
[02:02:50.566] iteration 17221 : loss : 0.054147, loss_ce: 0.010335
[02:02:50.874] iteration 17222 : loss : 0.054332, loss_ce: 0.019952
[02:02:51.184] iteration 17223 : loss : 0.046036, loss_ce: 0.014963
[02:02:51.493] iteration 17224 : loss : 0.036474, loss_ce: 0.009520
[02:02:51.808] iteration 17225 : loss : 0.063296, loss_ce: 0.014277
[02:02:52.123] iteration 17226 : loss : 0.048153, loss_ce: 0.012146
[02:02:52.434] iteration 17227 : loss : 0.039489, loss_ce: 0.010519
[02:02:52.748] iteration 17228 : loss : 0.107389, loss_ce: 0.007485
[02:02:53.058] iteration 17229 : loss : 0.043112, loss_ce: 0.015319
[02:02:53.363] iteration 17230 : loss : 0.054248, loss_ce: 0.014339
[02:02:53.672] iteration 17231 : loss : 0.056254, loss_ce: 0.012245
[02:02:53.987] iteration 17232 : loss : 0.036854, loss_ce: 0.010702
[02:02:54.299] iteration 17233 : loss : 0.046616, loss_ce: 0.010824
[02:02:54.603] iteration 17234 : loss : 0.043630, loss_ce: 0.013203
[02:02:54.909] iteration 17235 : loss : 0.042003, loss_ce: 0.015774
[02:02:55.000] iteration 17236 : loss : 0.224745, loss_ce: 0.016418
[02:03:13.327] iteration 17237 : loss : 0.037050, loss_ce: 0.017177
[02:03:13.632] iteration 17238 : loss : 0.054110, loss_ce: 0.010096
[02:03:13.938] iteration 17239 : loss : 0.050911, loss_ce: 0.015851
[02:03:14.246] iteration 17240 : loss : 0.041231, loss_ce: 0.008717
[02:03:14.568] iteration 17241 : loss : 0.049597, loss_ce: 0.013779
[02:03:14.874] iteration 17242 : loss : 0.040706, loss_ce: 0.012301
[02:03:15.184] iteration 17243 : loss : 0.045605, loss_ce: 0.013707
[02:03:15.488] iteration 17244 : loss : 0.044978, loss_ce: 0.009334
[02:03:15.800] iteration 17245 : loss : 0.054623, loss_ce: 0.017681
[02:03:16.108] iteration 17246 : loss : 0.043445, loss_ce: 0.011009
[02:03:16.418] iteration 17247 : loss : 0.045128, loss_ce: 0.012749
[02:03:16.730] iteration 17248 : loss : 0.100615, loss_ce: 0.009685
[02:03:17.042] iteration 17249 : loss : 0.056203, loss_ce: 0.013787
[02:03:17.354] iteration 17250 : loss : 0.037122, loss_ce: 0.005589
[02:03:17.662] iteration 17251 : loss : 0.099728, loss_ce: 0.012801
[02:03:17.973] iteration 17252 : loss : 0.041821, loss_ce: 0.009739
[02:03:18.280] iteration 17253 : loss : 0.101306, loss_ce: 0.020944
[02:03:18.589] iteration 17254 : loss : 0.097879, loss_ce: 0.006843
[02:03:18.898] iteration 17255 : loss : 0.038183, loss_ce: 0.010856
[02:03:19.206] iteration 17256 : loss : 0.046677, loss_ce: 0.010002
[02:03:19.514] iteration 17257 : loss : 0.045155, loss_ce: 0.019549
[02:03:19.824] iteration 17258 : loss : 0.156502, loss_ce: 0.006801
[02:03:20.129] iteration 17259 : loss : 0.046450, loss_ce: 0.014892
[02:03:20.438] iteration 17260 : loss : 0.037633, loss_ce: 0.010400
[02:03:20.760] iteration 17261 : loss : 0.037755, loss_ce: 0.008014
[02:03:21.065] iteration 17262 : loss : 0.043648, loss_ce: 0.019046
[02:03:21.374] iteration 17263 : loss : 0.038840, loss_ce: 0.012782
[02:03:21.683] iteration 17264 : loss : 0.035387, loss_ce: 0.010931
[02:03:21.990] iteration 17265 : loss : 0.058217, loss_ce: 0.016617
[02:03:22.298] iteration 17266 : loss : 0.038079, loss_ce: 0.008547
[02:03:22.604] iteration 17267 : loss : 0.103070, loss_ce: 0.010321
[02:03:22.911] iteration 17268 : loss : 0.097442, loss_ce: 0.010142
[02:03:23.217] iteration 17269 : loss : 0.056949, loss_ce: 0.011721
[02:03:23.526] iteration 17270 : loss : 0.077132, loss_ce: 0.009216
[02:03:23.838] iteration 17271 : loss : 0.044461, loss_ce: 0.010938
[02:03:24.146] iteration 17272 : loss : 0.044383, loss_ce: 0.019254
[02:03:24.446] iteration 17273 : loss : 0.042971, loss_ce: 0.017922
[02:03:24.748] iteration 17274 : loss : 0.056210, loss_ce: 0.018476
[02:03:25.056] iteration 17275 : loss : 0.105061, loss_ce: 0.006637
[02:03:25.354] iteration 17276 : loss : 0.042686, loss_ce: 0.020853
[02:03:25.655] iteration 17277 : loss : 0.104828, loss_ce: 0.012641
[02:03:25.964] iteration 17278 : loss : 0.034594, loss_ce: 0.010039
[02:03:26.264] iteration 17279 : loss : 0.104683, loss_ce: 0.010655
[02:03:26.565] iteration 17280 : loss : 0.104066, loss_ce: 0.016174
[02:03:26.880] iteration 17281 : loss : 0.033798, loss_ce: 0.009489
[02:03:27.181] iteration 17282 : loss : 0.043703, loss_ce: 0.012462
[02:03:27.486] iteration 17283 : loss : 0.042292, loss_ce: 0.015233
[02:03:27.791] iteration 17284 : loss : 0.042735, loss_ce: 0.021089
[02:03:28.097] iteration 17285 : loss : 0.163417, loss_ce: 0.008323
[02:03:28.402] iteration 17286 : loss : 0.050560, loss_ce: 0.018288
[02:03:28.706] iteration 17287 : loss : 0.098123, loss_ce: 0.017219
[02:03:29.012] iteration 17288 : loss : 0.057449, loss_ce: 0.022644
[02:03:29.316] iteration 17289 : loss : 0.114498, loss_ce: 0.014014
[02:03:29.619] iteration 17290 : loss : 0.152076, loss_ce: 0.005868
[02:03:29.921] iteration 17291 : loss : 0.045088, loss_ce: 0.019530
[02:03:30.226] iteration 17292 : loss : 0.037820, loss_ce: 0.009961
[02:03:30.529] iteration 17293 : loss : 0.047573, loss_ce: 0.011422
[02:03:30.830] iteration 17294 : loss : 0.048393, loss_ce: 0.015440
[02:03:31.134] iteration 17295 : loss : 0.047947, loss_ce: 0.019450
[02:03:31.443] iteration 17296 : loss : 0.040948, loss_ce: 0.012967
[02:03:31.748] iteration 17297 : loss : 0.048471, loss_ce: 0.016046
[02:03:32.052] iteration 17298 : loss : 0.040292, loss_ce: 0.013175
[02:03:32.355] iteration 17299 : loss : 0.045898, loss_ce: 0.016757
[02:03:32.658] iteration 17300 : loss : 0.041244, loss_ce: 0.018368
[02:03:32.983] iteration 17301 : loss : 0.042853, loss_ce: 0.020386
[02:03:33.285] iteration 17302 : loss : 0.044708, loss_ce: 0.009815
[02:03:33.590] iteration 17303 : loss : 0.048991, loss_ce: 0.016602
[02:03:33.893] iteration 17304 : loss : 0.053214, loss_ce: 0.026975
[02:03:34.199] iteration 17305 : loss : 0.040009, loss_ce: 0.023979
[02:03:34.500] iteration 17306 : loss : 0.043080, loss_ce: 0.013323
[02:03:34.803] iteration 17307 : loss : 0.046311, loss_ce: 0.011464
[02:03:35.106] iteration 17308 : loss : 0.040719, loss_ce: 0.017276
[02:03:35.411] iteration 17309 : loss : 0.045782, loss_ce: 0.012495
[02:03:35.714] iteration 17310 : loss : 0.045004, loss_ce: 0.016867
[02:03:36.016] iteration 17311 : loss : 0.051325, loss_ce: 0.012362
[02:03:36.318] iteration 17312 : loss : 0.098054, loss_ce: 0.005604
[02:03:36.624] iteration 17313 : loss : 0.039468, loss_ce: 0.015953
[02:03:36.930] iteration 17314 : loss : 0.105948, loss_ce: 0.014332
[02:03:37.243] iteration 17315 : loss : 0.048259, loss_ce: 0.009137
[02:03:37.552] iteration 17316 : loss : 0.037517, loss_ce: 0.016153
[02:03:37.861] iteration 17317 : loss : 0.047580, loss_ce: 0.012849
[02:03:38.171] iteration 17318 : loss : 0.048698, loss_ce: 0.011479
[02:03:38.482] iteration 17319 : loss : 0.057833, loss_ce: 0.021002
[02:03:38.795] iteration 17320 : loss : 0.044327, loss_ce: 0.016591
[02:03:39.116] iteration 17321 : loss : 0.040651, loss_ce: 0.009250
[02:03:39.418] iteration 17322 : loss : 0.171142, loss_ce: 0.005725
[02:03:39.725] iteration 17323 : loss : 0.038864, loss_ce: 0.016406
[02:03:40.030] iteration 17324 : loss : 0.044210, loss_ce: 0.013445
[02:03:40.332] iteration 17325 : loss : 0.045018, loss_ce: 0.011693
[02:03:40.635] iteration 17326 : loss : 0.039116, loss_ce: 0.012525
[02:03:40.941] iteration 17327 : loss : 0.036950, loss_ce: 0.011338
[02:03:41.244] iteration 17328 : loss : 0.050307, loss_ce: 0.018377
[02:03:41.548] iteration 17329 : loss : 0.052351, loss_ce: 0.009970
[02:03:41.857] iteration 17330 : loss : 0.051122, loss_ce: 0.012322
[02:03:42.164] iteration 17331 : loss : 0.053655, loss_ce: 0.017810
[02:03:42.468] iteration 17332 : loss : 0.115484, loss_ce: 0.016107
[02:03:42.771] iteration 17333 : loss : 0.405855, loss_ce: 0.002683
[02:03:43.074] iteration 17334 : loss : 0.033437, loss_ce: 0.007533
[02:03:43.378] iteration 17335 : loss : 0.051981, loss_ce: 0.007925
[02:03:43.681] iteration 17336 : loss : 0.038940, loss_ce: 0.016711
[02:03:43.985] iteration 17337 : loss : 0.046515, loss_ce: 0.006785
[02:03:44.288] iteration 17338 : loss : 0.125689, loss_ce: 0.007033
[02:03:44.594] iteration 17339 : loss : 0.038872, loss_ce: 0.007272
[02:03:44.904] iteration 17340 : loss : 0.101086, loss_ce: 0.012992
[02:03:45.226] iteration 17341 : loss : 0.047571, loss_ce: 0.010128
[02:03:45.527] iteration 17342 : loss : 0.045730, loss_ce: 0.008632
[02:03:45.835] iteration 17343 : loss : 0.108675, loss_ce: 0.010051
[02:03:46.141] iteration 17344 : loss : 0.074823, loss_ce: 0.011612
[02:03:46.443] iteration 17345 : loss : 0.049002, loss_ce: 0.014855
[02:03:46.748] iteration 17346 : loss : 0.048432, loss_ce: 0.019257
[02:03:47.054] iteration 17347 : loss : 0.054076, loss_ce: 0.025496
[02:03:47.362] iteration 17348 : loss : 0.042166, loss_ce: 0.018235
[02:03:47.666] iteration 17349 : loss : 0.047688, loss_ce: 0.013202
[02:03:47.968] iteration 17350 : loss : 0.136237, loss_ce: 0.004639
[02:03:48.272] iteration 17351 : loss : 0.055438, loss_ce: 0.008600
[02:03:48.577] iteration 17352 : loss : 0.039449, loss_ce: 0.007847
[02:03:48.884] iteration 17353 : loss : 0.054220, loss_ce: 0.012060
[02:03:49.189] iteration 17354 : loss : 0.115231, loss_ce: 0.014056
[02:03:49.495] iteration 17355 : loss : 0.054003, loss_ce: 0.016661
[02:03:49.798] iteration 17356 : loss : 0.068522, loss_ce: 0.018163
[02:03:50.101] iteration 17357 : loss : 0.038388, loss_ce: 0.010294
[02:03:50.404] iteration 17358 : loss : 0.051611, loss_ce: 0.013570
[02:03:50.706] iteration 17359 : loss : 0.044118, loss_ce: 0.013006
[02:03:51.014] iteration 17360 : loss : 0.042486, loss_ce: 0.017831
[02:03:51.337] iteration 17361 : loss : 0.039056, loss_ce: 0.010022
[02:03:51.647] iteration 17362 : loss : 0.098731, loss_ce: 0.007127
[02:03:51.951] iteration 17363 : loss : 0.107556, loss_ce: 0.014394
[02:03:52.255] iteration 17364 : loss : 0.101873, loss_ce: 0.008751
[02:03:52.566] iteration 17365 : loss : 0.050709, loss_ce: 0.018816
[02:03:52.876] iteration 17366 : loss : 0.065044, loss_ce: 0.010634
[02:03:53.189] iteration 17367 : loss : 0.042679, loss_ce: 0.011296
[02:03:53.497] iteration 17368 : loss : 0.058877, loss_ce: 0.015829
[02:03:53.807] iteration 17369 : loss : 0.045180, loss_ce: 0.013683
[02:03:54.114] iteration 17370 : loss : 0.036478, loss_ce: 0.011948
[02:03:54.427] iteration 17371 : loss : 0.046748, loss_ce: 0.008980
[02:03:54.733] iteration 17372 : loss : 0.039528, loss_ce: 0.015621
[02:03:55.045] iteration 17373 : loss : 0.038580, loss_ce: 0.011363
[02:03:55.355] iteration 17374 : loss : 0.048051, loss_ce: 0.016404
[02:03:55.436] iteration 17375 : loss : 0.343935, loss_ce: 0.003376
[02:04:12.463] iteration 17376 : loss : 0.044285, loss_ce: 0.017050
[02:04:12.766] iteration 17377 : loss : 0.042955, loss_ce: 0.020024
[02:04:13.068] iteration 17378 : loss : 0.047267, loss_ce: 0.019083
[02:04:13.376] iteration 17379 : loss : 0.043766, loss_ce: 0.015476
[02:04:13.685] iteration 17380 : loss : 0.044863, loss_ce: 0.011532
[02:04:14.004] iteration 17381 : loss : 0.044978, loss_ce: 0.012351
[02:04:14.306] iteration 17382 : loss : 0.050168, loss_ce: 0.019138
[02:04:14.606] iteration 17383 : loss : 0.040363, loss_ce: 0.015466
[02:04:14.910] iteration 17384 : loss : 0.046301, loss_ce: 0.019051
[02:04:15.212] iteration 17385 : loss : 0.048885, loss_ce: 0.021330
[02:04:15.515] iteration 17386 : loss : 0.109905, loss_ce: 0.017169
[02:04:15.816] iteration 17387 : loss : 0.119918, loss_ce: 0.006498
[02:04:16.121] iteration 17388 : loss : 0.153568, loss_ce: 0.005222
[02:04:16.424] iteration 17389 : loss : 0.048700, loss_ce: 0.012290
[02:04:16.726] iteration 17390 : loss : 0.050344, loss_ce: 0.011032
[02:04:17.028] iteration 17391 : loss : 0.041863, loss_ce: 0.009948
[02:04:17.332] iteration 17392 : loss : 0.049725, loss_ce: 0.005869
[02:04:17.633] iteration 17393 : loss : 0.039416, loss_ce: 0.010628
[02:04:17.938] iteration 17394 : loss : 0.041631, loss_ce: 0.009882
[02:04:18.240] iteration 17395 : loss : 0.038666, loss_ce: 0.017044
[02:04:18.543] iteration 17396 : loss : 0.039588, loss_ce: 0.012114
[02:04:18.847] iteration 17397 : loss : 0.097527, loss_ce: 0.008586
[02:04:19.150] iteration 17398 : loss : 0.047863, loss_ce: 0.007881
[02:04:19.452] iteration 17399 : loss : 0.042251, loss_ce: 0.015172
[02:04:19.756] iteration 17400 : loss : 0.053160, loss_ce: 0.018709
[02:04:20.075] iteration 17401 : loss : 0.041664, loss_ce: 0.014378
[02:04:20.373] iteration 17402 : loss : 0.038184, loss_ce: 0.016271
[02:04:20.677] iteration 17403 : loss : 0.044220, loss_ce: 0.013905
[02:04:20.979] iteration 17404 : loss : 0.221225, loss_ce: 0.007135
[02:04:21.281] iteration 17405 : loss : 0.100978, loss_ce: 0.009610
[02:04:21.583] iteration 17406 : loss : 0.043030, loss_ce: 0.008138
[02:04:21.886] iteration 17407 : loss : 0.055179, loss_ce: 0.020662
[02:04:22.190] iteration 17408 : loss : 0.107205, loss_ce: 0.016078
[02:04:22.493] iteration 17409 : loss : 0.053390, loss_ce: 0.015728
[02:04:22.797] iteration 17410 : loss : 0.084141, loss_ce: 0.015292
[02:04:23.098] iteration 17411 : loss : 0.044368, loss_ce: 0.010424
[02:04:23.397] iteration 17412 : loss : 0.099635, loss_ce: 0.002370
[02:04:23.701] iteration 17413 : loss : 0.068058, loss_ce: 0.020024
[02:04:24.004] iteration 17414 : loss : 0.046090, loss_ce: 0.011054
[02:04:24.306] iteration 17415 : loss : 0.108162, loss_ce: 0.011581
[02:04:24.608] iteration 17416 : loss : 0.041532, loss_ce: 0.021774
[02:04:24.907] iteration 17417 : loss : 0.197146, loss_ce: 0.007454
[02:04:25.210] iteration 17418 : loss : 0.108724, loss_ce: 0.009298
[02:04:25.511] iteration 17419 : loss : 0.063562, loss_ce: 0.009273
[02:04:25.815] iteration 17420 : loss : 0.055037, loss_ce: 0.015741
[02:04:26.134] iteration 17421 : loss : 0.048491, loss_ce: 0.017565
[02:04:26.437] iteration 17422 : loss : 0.041102, loss_ce: 0.014166
[02:04:26.741] iteration 17423 : loss : 0.035030, loss_ce: 0.013498
[02:04:27.046] iteration 17424 : loss : 0.107112, loss_ce: 0.013952
[02:04:27.355] iteration 17425 : loss : 0.053369, loss_ce: 0.008232
[02:04:27.664] iteration 17426 : loss : 0.115273, loss_ce: 0.005095
[02:04:27.973] iteration 17427 : loss : 0.045988, loss_ce: 0.020065
[02:04:28.281] iteration 17428 : loss : 0.049938, loss_ce: 0.015145
[02:04:28.591] iteration 17429 : loss : 0.043557, loss_ce: 0.015594
[02:04:28.899] iteration 17430 : loss : 0.073628, loss_ce: 0.008267
[02:04:29.210] iteration 17431 : loss : 0.043667, loss_ce: 0.015976
[02:04:29.513] iteration 17432 : loss : 0.092765, loss_ce: 0.007843
[02:04:29.818] iteration 17433 : loss : 0.038895, loss_ce: 0.006860
[02:04:30.121] iteration 17434 : loss : 0.047195, loss_ce: 0.011449
[02:04:30.422] iteration 17435 : loss : 0.098385, loss_ce: 0.013572
[02:04:30.724] iteration 17436 : loss : 0.097086, loss_ce: 0.007622
[02:04:31.028] iteration 17437 : loss : 0.046897, loss_ce: 0.014959
[02:04:31.331] iteration 17438 : loss : 0.044345, loss_ce: 0.012984
[02:04:31.634] iteration 17439 : loss : 0.093313, loss_ce: 0.007023
[02:04:31.938] iteration 17440 : loss : 0.128448, loss_ce: 0.020547
[02:04:32.264] iteration 17441 : loss : 0.106471, loss_ce: 0.010732
[02:04:32.564] iteration 17442 : loss : 0.054332, loss_ce: 0.013165
[02:04:32.868] iteration 17443 : loss : 0.041364, loss_ce: 0.011569
[02:04:33.170] iteration 17444 : loss : 0.038857, loss_ce: 0.014092
[02:04:33.470] iteration 17445 : loss : 0.034828, loss_ce: 0.007499
[02:04:33.782] iteration 17446 : loss : 0.044188, loss_ce: 0.011139
[02:04:34.085] iteration 17447 : loss : 0.058182, loss_ce: 0.021285
[02:04:34.388] iteration 17448 : loss : 0.120096, loss_ce: 0.006947
[02:04:34.689] iteration 17449 : loss : 0.045987, loss_ce: 0.013569
[02:04:34.992] iteration 17450 : loss : 0.045027, loss_ce: 0.019063
[02:04:35.295] iteration 17451 : loss : 0.047206, loss_ce: 0.017095
[02:04:35.599] iteration 17452 : loss : 0.055458, loss_ce: 0.021950
[02:04:35.904] iteration 17453 : loss : 0.037847, loss_ce: 0.009480
[02:04:36.208] iteration 17454 : loss : 0.104262, loss_ce: 0.009097
[02:04:36.513] iteration 17455 : loss : 0.042219, loss_ce: 0.016121
[02:04:36.816] iteration 17456 : loss : 0.102953, loss_ce: 0.006689
[02:04:37.122] iteration 17457 : loss : 0.113134, loss_ce: 0.008555
[02:04:37.425] iteration 17458 : loss : 0.033740, loss_ce: 0.012825
[02:04:37.730] iteration 17459 : loss : 0.037732, loss_ce: 0.014254
[02:04:38.035] iteration 17460 : loss : 0.046296, loss_ce: 0.017428
[02:04:38.355] iteration 17461 : loss : 0.061900, loss_ce: 0.011264
[02:04:38.660] iteration 17462 : loss : 0.161077, loss_ce: 0.008825
[02:04:38.970] iteration 17463 : loss : 0.163945, loss_ce: 0.005183
[02:04:39.272] iteration 17464 : loss : 0.057597, loss_ce: 0.011034
[02:04:39.575] iteration 17465 : loss : 0.103608, loss_ce: 0.013976
[02:04:39.879] iteration 17466 : loss : 0.044203, loss_ce: 0.016195
[02:04:40.180] iteration 17467 : loss : 0.052659, loss_ce: 0.017799
[02:04:40.481] iteration 17468 : loss : 0.045970, loss_ce: 0.019991
[02:04:40.783] iteration 17469 : loss : 0.057795, loss_ce: 0.011734
[02:04:41.090] iteration 17470 : loss : 0.041095, loss_ce: 0.011223
[02:04:41.393] iteration 17471 : loss : 0.044142, loss_ce: 0.020977
[02:04:41.696] iteration 17472 : loss : 0.051435, loss_ce: 0.016001
[02:04:41.999] iteration 17473 : loss : 0.044033, loss_ce: 0.011037
[02:04:42.307] iteration 17474 : loss : 0.062816, loss_ce: 0.013349
[02:04:42.612] iteration 17475 : loss : 0.042331, loss_ce: 0.015083
[02:04:42.921] iteration 17476 : loss : 0.035548, loss_ce: 0.011626
[02:04:43.231] iteration 17477 : loss : 0.170848, loss_ce: 0.019145
[02:04:43.538] iteration 17478 : loss : 0.038667, loss_ce: 0.013471
[02:04:43.848] iteration 17479 : loss : 0.095365, loss_ce: 0.006335
[02:04:44.158] iteration 17480 : loss : 0.098476, loss_ce: 0.011003
[02:04:44.484] iteration 17481 : loss : 0.043442, loss_ce: 0.019375
[02:04:44.786] iteration 17482 : loss : 0.038560, loss_ce: 0.008240
[02:04:45.094] iteration 17483 : loss : 0.056689, loss_ce: 0.013252
[02:04:45.397] iteration 17484 : loss : 0.044053, loss_ce: 0.010183
[02:04:45.701] iteration 17485 : loss : 0.061506, loss_ce: 0.015648
[02:04:46.006] iteration 17486 : loss : 0.046137, loss_ce: 0.012160
[02:04:46.313] iteration 17487 : loss : 0.042272, loss_ce: 0.015368
[02:04:46.617] iteration 17488 : loss : 0.051829, loss_ce: 0.017370
[02:04:46.920] iteration 17489 : loss : 0.063743, loss_ce: 0.017580
[02:04:47.225] iteration 17490 : loss : 0.049782, loss_ce: 0.024623
[02:04:47.529] iteration 17491 : loss : 0.043960, loss_ce: 0.015149
[02:04:47.835] iteration 17492 : loss : 0.055791, loss_ce: 0.017307
[02:04:48.137] iteration 17493 : loss : 0.055038, loss_ce: 0.019747
[02:04:48.441] iteration 17494 : loss : 0.041813, loss_ce: 0.013779
[02:04:48.746] iteration 17495 : loss : 0.047140, loss_ce: 0.021488
[02:04:49.050] iteration 17496 : loss : 0.038935, loss_ce: 0.017487
[02:04:49.352] iteration 17497 : loss : 0.130494, loss_ce: 0.010444
[02:04:49.658] iteration 17498 : loss : 0.119866, loss_ce: 0.015799
[02:04:49.968] iteration 17499 : loss : 0.039482, loss_ce: 0.013850
[02:04:50.280] iteration 17500 : loss : 0.054004, loss_ce: 0.018946
[02:04:50.619] iteration 17501 : loss : 0.221437, loss_ce: 0.010715
[02:04:50.926] iteration 17502 : loss : 0.050432, loss_ce: 0.008900
[02:04:51.237] iteration 17503 : loss : 0.095852, loss_ce: 0.006577
[02:04:51.551] iteration 17504 : loss : 0.042734, loss_ce: 0.014474
[02:04:51.861] iteration 17505 : loss : 0.110670, loss_ce: 0.014710
[02:04:52.168] iteration 17506 : loss : 0.042798, loss_ce: 0.008579
[02:04:52.477] iteration 17507 : loss : 0.046691, loss_ce: 0.016007
[02:04:52.789] iteration 17508 : loss : 0.049424, loss_ce: 0.010022
[02:04:53.096] iteration 17509 : loss : 0.039659, loss_ce: 0.005340
[02:04:53.404] iteration 17510 : loss : 0.109946, loss_ce: 0.016770
[02:04:53.711] iteration 17511 : loss : 0.052226, loss_ce: 0.016231
[02:04:54.023] iteration 17512 : loss : 0.050475, loss_ce: 0.013628
[02:04:54.329] iteration 17513 : loss : 0.047678, loss_ce: 0.019292
[02:04:54.431] iteration 17514 : loss : 0.293748, loss_ce: 0.006200
[02:05:11.421] iteration 17515 : loss : 0.044187, loss_ce: 0.013024
[02:05:11.719] iteration 17516 : loss : 0.049938, loss_ce: 0.016577
[02:05:12.023] iteration 17517 : loss : 0.054021, loss_ce: 0.026600
[02:05:12.331] iteration 17518 : loss : 0.100134, loss_ce: 0.010185
[02:05:12.635] iteration 17519 : loss : 0.043506, loss_ce: 0.008351
[02:05:12.938] iteration 17520 : loss : 0.067214, loss_ce: 0.009443
[02:05:13.258] iteration 17521 : loss : 0.161683, loss_ce: 0.009586
[02:05:13.563] iteration 17522 : loss : 0.046425, loss_ce: 0.011749
[02:05:13.873] iteration 17523 : loss : 0.049533, loss_ce: 0.013199
[02:05:14.181] iteration 17524 : loss : 0.048259, loss_ce: 0.015294
[02:05:14.487] iteration 17525 : loss : 0.039469, loss_ce: 0.020418
[02:05:14.799] iteration 17526 : loss : 0.046150, loss_ce: 0.015812
[02:05:15.111] iteration 17527 : loss : 0.042206, loss_ce: 0.012805
[02:05:15.421] iteration 17528 : loss : 0.040660, loss_ce: 0.010695
[02:05:15.732] iteration 17529 : loss : 0.041963, loss_ce: 0.009221
[02:05:16.036] iteration 17530 : loss : 0.035652, loss_ce: 0.012203
[02:05:16.345] iteration 17531 : loss : 0.046060, loss_ce: 0.020166
[02:05:16.655] iteration 17532 : loss : 0.053927, loss_ce: 0.006444
[02:05:16.968] iteration 17533 : loss : 0.110312, loss_ce: 0.006404
[02:05:17.279] iteration 17534 : loss : 0.106659, loss_ce: 0.021449
[02:05:17.586] iteration 17535 : loss : 0.047092, loss_ce: 0.024615
[02:05:17.895] iteration 17536 : loss : 0.047041, loss_ce: 0.016960
[02:05:18.203] iteration 17537 : loss : 0.040818, loss_ce: 0.012533
[02:05:18.513] iteration 17538 : loss : 0.039152, loss_ce: 0.012182
[02:05:18.825] iteration 17539 : loss : 0.060763, loss_ce: 0.017006
[02:05:19.136] iteration 17540 : loss : 0.051196, loss_ce: 0.021543
[02:05:19.461] iteration 17541 : loss : 0.099309, loss_ce: 0.005991
[02:05:19.773] iteration 17542 : loss : 0.059202, loss_ce: 0.022274
[02:05:20.081] iteration 17543 : loss : 0.112210, loss_ce: 0.003683
[02:05:20.391] iteration 17544 : loss : 0.037888, loss_ce: 0.009229
[02:05:20.699] iteration 17545 : loss : 0.061254, loss_ce: 0.015807
[02:05:21.004] iteration 17546 : loss : 0.051674, loss_ce: 0.012505
[02:05:21.310] iteration 17547 : loss : 0.041600, loss_ce: 0.009041
[02:05:21.620] iteration 17548 : loss : 0.103386, loss_ce: 0.010950
[02:05:21.926] iteration 17549 : loss : 0.040226, loss_ce: 0.011240
[02:05:22.237] iteration 17550 : loss : 0.103795, loss_ce: 0.014572
[02:05:22.545] iteration 17551 : loss : 0.039621, loss_ce: 0.015552
[02:05:22.856] iteration 17552 : loss : 0.120740, loss_ce: 0.011893
[02:05:23.161] iteration 17553 : loss : 0.113851, loss_ce: 0.009166
[02:05:23.470] iteration 17554 : loss : 0.148705, loss_ce: 0.006449
[02:05:23.777] iteration 17555 : loss : 0.038185, loss_ce: 0.012295
[02:05:24.083] iteration 17556 : loss : 0.041013, loss_ce: 0.014486
[02:05:24.395] iteration 17557 : loss : 0.037861, loss_ce: 0.010592
[02:05:24.699] iteration 17558 : loss : 0.038714, loss_ce: 0.013030
[02:05:25.009] iteration 17559 : loss : 0.184899, loss_ce: 0.011339
[02:05:25.313] iteration 17560 : loss : 0.049066, loss_ce: 0.023278
[02:05:25.635] iteration 17561 : loss : 0.045920, loss_ce: 0.015462
[02:05:25.946] iteration 17562 : loss : 0.061576, loss_ce: 0.011727
[02:05:26.251] iteration 17563 : loss : 0.069646, loss_ce: 0.016541
[02:05:26.559] iteration 17564 : loss : 0.039857, loss_ce: 0.018508
[02:05:26.867] iteration 17565 : loss : 0.053908, loss_ce: 0.015878
[02:05:27.177] iteration 17566 : loss : 0.046331, loss_ce: 0.013702
[02:05:27.486] iteration 17567 : loss : 0.047597, loss_ce: 0.015382
[02:05:27.794] iteration 17568 : loss : 0.038250, loss_ce: 0.017378
[02:05:28.101] iteration 17569 : loss : 0.057127, loss_ce: 0.020115
[02:05:28.409] iteration 17570 : loss : 0.078488, loss_ce: 0.008592
[02:05:28.719] iteration 17571 : loss : 0.048877, loss_ce: 0.011331
[02:05:29.028] iteration 17572 : loss : 0.153890, loss_ce: 0.008040
[02:05:29.338] iteration 17573 : loss : 0.105617, loss_ce: 0.015160
[02:05:29.646] iteration 17574 : loss : 0.045123, loss_ce: 0.017554
[02:05:29.951] iteration 17575 : loss : 0.056908, loss_ce: 0.007935
[02:05:30.253] iteration 17576 : loss : 0.044381, loss_ce: 0.017521
[02:05:30.560] iteration 17577 : loss : 0.090608, loss_ce: 0.009544
[02:05:30.869] iteration 17578 : loss : 0.047893, loss_ce: 0.020696
[02:05:31.179] iteration 17579 : loss : 0.047639, loss_ce: 0.010891
[02:05:31.487] iteration 17580 : loss : 0.046095, loss_ce: 0.006876
[02:05:31.808] iteration 17581 : loss : 0.067061, loss_ce: 0.015494
[02:05:32.115] iteration 17582 : loss : 0.230519, loss_ce: 0.004584
[02:05:32.428] iteration 17583 : loss : 0.044740, loss_ce: 0.010992
[02:05:32.735] iteration 17584 : loss : 0.122255, loss_ce: 0.014019
[02:05:33.044] iteration 17585 : loss : 0.046122, loss_ce: 0.012272
[02:05:33.353] iteration 17586 : loss : 0.037261, loss_ce: 0.009497
[02:05:33.660] iteration 17587 : loss : 0.035955, loss_ce: 0.009383
[02:05:33.970] iteration 17588 : loss : 0.040762, loss_ce: 0.020302
[02:05:34.276] iteration 17589 : loss : 0.056823, loss_ce: 0.012927
[02:05:34.584] iteration 17590 : loss : 0.042375, loss_ce: 0.012056
[02:05:34.887] iteration 17591 : loss : 0.057065, loss_ce: 0.020961
[02:05:35.191] iteration 17592 : loss : 0.042800, loss_ce: 0.012908
[02:05:35.494] iteration 17593 : loss : 0.048172, loss_ce: 0.014770
[02:05:35.796] iteration 17594 : loss : 0.042982, loss_ce: 0.010902
[02:05:36.098] iteration 17595 : loss : 0.410081, loss_ce: 0.001643
[02:05:36.403] iteration 17596 : loss : 0.056118, loss_ce: 0.019333
[02:05:36.707] iteration 17597 : loss : 0.104065, loss_ce: 0.011247
[02:05:37.011] iteration 17598 : loss : 0.097951, loss_ce: 0.011685
[02:05:37.314] iteration 17599 : loss : 0.063130, loss_ce: 0.014621
[02:05:37.618] iteration 17600 : loss : 0.052512, loss_ce: 0.016572
[02:05:37.934] iteration 17601 : loss : 0.042073, loss_ce: 0.011129
[02:05:38.236] iteration 17602 : loss : 0.048886, loss_ce: 0.011148
[02:05:38.541] iteration 17603 : loss : 0.046772, loss_ce: 0.007737
[02:05:38.841] iteration 17604 : loss : 0.036851, loss_ce: 0.010829
[02:05:39.144] iteration 17605 : loss : 0.220820, loss_ce: 0.009215
[02:05:39.449] iteration 17606 : loss : 0.044267, loss_ce: 0.008780
[02:05:39.751] iteration 17607 : loss : 0.051796, loss_ce: 0.017888
[02:05:40.055] iteration 17608 : loss : 0.042651, loss_ce: 0.013956
[02:05:40.357] iteration 17609 : loss : 0.173541, loss_ce: 0.008379
[02:05:40.664] iteration 17610 : loss : 0.050362, loss_ce: 0.018649
[02:05:40.968] iteration 17611 : loss : 0.052286, loss_ce: 0.014314
[02:05:41.267] iteration 17612 : loss : 0.103756, loss_ce: 0.007990
[02:05:41.569] iteration 17613 : loss : 0.033397, loss_ce: 0.010140
[02:05:41.878] iteration 17614 : loss : 0.101917, loss_ce: 0.014931
[02:05:42.181] iteration 17615 : loss : 0.047433, loss_ce: 0.017082
[02:05:42.484] iteration 17616 : loss : 0.051633, loss_ce: 0.014708
[02:05:42.785] iteration 17617 : loss : 0.045844, loss_ce: 0.010900
[02:05:43.089] iteration 17618 : loss : 0.046818, loss_ce: 0.018563
[02:05:43.396] iteration 17619 : loss : 0.051875, loss_ce: 0.014571
[02:05:43.698] iteration 17620 : loss : 0.049100, loss_ce: 0.020454
[02:05:44.023] iteration 17621 : loss : 0.049207, loss_ce: 0.014463
[02:05:44.329] iteration 17622 : loss : 0.039054, loss_ce: 0.011357
[02:05:44.634] iteration 17623 : loss : 0.041571, loss_ce: 0.019616
[02:05:44.938] iteration 17624 : loss : 0.057699, loss_ce: 0.018040
[02:05:45.242] iteration 17625 : loss : 0.037271, loss_ce: 0.013225
[02:05:45.546] iteration 17626 : loss : 0.114977, loss_ce: 0.009793
[02:05:45.847] iteration 17627 : loss : 0.049382, loss_ce: 0.017575
[02:05:46.150] iteration 17628 : loss : 0.040524, loss_ce: 0.012802
[02:05:46.451] iteration 17629 : loss : 0.160476, loss_ce: 0.008235
[02:05:46.755] iteration 17630 : loss : 0.046886, loss_ce: 0.017023
[02:05:47.058] iteration 17631 : loss : 0.047930, loss_ce: 0.024473
[02:05:47.365] iteration 17632 : loss : 0.043829, loss_ce: 0.017609
[02:05:47.678] iteration 17633 : loss : 0.040592, loss_ce: 0.017615
[02:05:47.991] iteration 17634 : loss : 0.097354, loss_ce: 0.011659
[02:05:48.299] iteration 17635 : loss : 0.090760, loss_ce: 0.008014
[02:05:48.611] iteration 17636 : loss : 0.042478, loss_ce: 0.012788
[02:05:48.929] iteration 17637 : loss : 0.099841, loss_ce: 0.008758
[02:05:49.243] iteration 17638 : loss : 0.054629, loss_ce: 0.013321
[02:05:49.551] iteration 17639 : loss : 0.101714, loss_ce: 0.007964
[02:05:49.859] iteration 17640 : loss : 0.054194, loss_ce: 0.012481
[02:05:50.190] iteration 17641 : loss : 0.104211, loss_ce: 0.016460
[02:05:50.500] iteration 17642 : loss : 0.037907, loss_ce: 0.009205
[02:05:50.813] iteration 17643 : loss : 0.043204, loss_ce: 0.010404
[02:05:51.119] iteration 17644 : loss : 0.118666, loss_ce: 0.007283
[02:05:51.429] iteration 17645 : loss : 0.099761, loss_ce: 0.014316
[02:05:51.736] iteration 17646 : loss : 0.106495, loss_ce: 0.008415
[02:05:52.045] iteration 17647 : loss : 0.036743, loss_ce: 0.019234
[02:05:52.355] iteration 17648 : loss : 0.107756, loss_ce: 0.014138
[02:05:52.667] iteration 17649 : loss : 0.045093, loss_ce: 0.007303
[02:05:52.976] iteration 17650 : loss : 0.045667, loss_ce: 0.011014
[02:05:53.287] iteration 17651 : loss : 0.105591, loss_ce: 0.004575
[02:05:53.592] iteration 17652 : loss : 0.054991, loss_ce: 0.021166
[02:05:53.671] iteration 17653 : loss : 0.048985, loss_ce: 0.035038
[02:06:13.017] iteration 17654 : loss : 0.218060, loss_ce: 0.008785
[02:06:13.315] iteration 17655 : loss : 0.042355, loss_ce: 0.016549
[02:06:13.615] iteration 17656 : loss : 0.048279, loss_ce: 0.014201
[02:06:13.917] iteration 17657 : loss : 0.042684, loss_ce: 0.004767
[02:06:14.218] iteration 17658 : loss : 0.045414, loss_ce: 0.012536
[02:06:14.520] iteration 17659 : loss : 0.096828, loss_ce: 0.004634
[02:06:14.822] iteration 17660 : loss : 0.108883, loss_ce: 0.015734
[02:06:15.137] iteration 17661 : loss : 0.050928, loss_ce: 0.010434
[02:06:15.439] iteration 17662 : loss : 0.043783, loss_ce: 0.010570
[02:06:15.742] iteration 17663 : loss : 0.048542, loss_ce: 0.015458
[02:06:16.045] iteration 17664 : loss : 0.038549, loss_ce: 0.009716
[02:06:16.346] iteration 17665 : loss : 0.046320, loss_ce: 0.011325
[02:06:16.650] iteration 17666 : loss : 0.037969, loss_ce: 0.008690
[02:06:16.955] iteration 17667 : loss : 0.054508, loss_ce: 0.025022
[02:06:17.257] iteration 17668 : loss : 0.100137, loss_ce: 0.014681
[02:06:17.563] iteration 17669 : loss : 0.047231, loss_ce: 0.012939
[02:06:17.866] iteration 17670 : loss : 0.039898, loss_ce: 0.016053
[02:06:18.170] iteration 17671 : loss : 0.045447, loss_ce: 0.011600
[02:06:18.474] iteration 17672 : loss : 0.050341, loss_ce: 0.017352
[02:06:18.778] iteration 17673 : loss : 0.040154, loss_ce: 0.015841
[02:06:19.083] iteration 17674 : loss : 0.035615, loss_ce: 0.008254
[02:06:19.390] iteration 17675 : loss : 0.042904, loss_ce: 0.014825
[02:06:19.697] iteration 17676 : loss : 0.049934, loss_ce: 0.014963
[02:06:20.002] iteration 17677 : loss : 0.047604, loss_ce: 0.019391
[02:06:20.306] iteration 17678 : loss : 0.052065, loss_ce: 0.015520
[02:06:20.611] iteration 17679 : loss : 0.036737, loss_ce: 0.011925
[02:06:20.920] iteration 17680 : loss : 0.030589, loss_ce: 0.010488
[02:06:21.240] iteration 17681 : loss : 0.032325, loss_ce: 0.009825
[02:06:21.544] iteration 17682 : loss : 0.039017, loss_ce: 0.010087
[02:06:21.854] iteration 17683 : loss : 0.095881, loss_ce: 0.011116
[02:06:22.162] iteration 17684 : loss : 0.032249, loss_ce: 0.009309
[02:06:22.473] iteration 17685 : loss : 0.038230, loss_ce: 0.018768
[02:06:22.779] iteration 17686 : loss : 0.043633, loss_ce: 0.015124
[02:06:23.086] iteration 17687 : loss : 0.099627, loss_ce: 0.008880
[02:06:23.396] iteration 17688 : loss : 0.094493, loss_ce: 0.011391
[02:06:23.700] iteration 17689 : loss : 0.083685, loss_ce: 0.011584
[02:06:24.006] iteration 17690 : loss : 0.038458, loss_ce: 0.015255
[02:06:24.318] iteration 17691 : loss : 0.096234, loss_ce: 0.012423
[02:06:24.622] iteration 17692 : loss : 0.038142, loss_ce: 0.014893
[02:06:24.927] iteration 17693 : loss : 0.042705, loss_ce: 0.013934
[02:06:25.238] iteration 17694 : loss : 0.048008, loss_ce: 0.013522
[02:06:25.543] iteration 17695 : loss : 0.046528, loss_ce: 0.012210
[02:06:25.848] iteration 17696 : loss : 0.101820, loss_ce: 0.015820
[02:06:26.156] iteration 17697 : loss : 0.048092, loss_ce: 0.014618
[02:06:26.465] iteration 17698 : loss : 0.038038, loss_ce: 0.016256
[02:06:26.772] iteration 17699 : loss : 0.043163, loss_ce: 0.014719
[02:06:27.079] iteration 17700 : loss : 0.036524, loss_ce: 0.013539
[02:06:27.410] iteration 17701 : loss : 0.042793, loss_ce: 0.013546
[02:06:27.713] iteration 17702 : loss : 0.057201, loss_ce: 0.016732
[02:06:28.027] iteration 17703 : loss : 0.102348, loss_ce: 0.013203
[02:06:28.335] iteration 17704 : loss : 0.100487, loss_ce: 0.008071
[02:06:28.644] iteration 17705 : loss : 0.040024, loss_ce: 0.016353
[02:06:28.954] iteration 17706 : loss : 0.051234, loss_ce: 0.019091
[02:06:29.264] iteration 17707 : loss : 0.053866, loss_ce: 0.013682
[02:06:29.578] iteration 17708 : loss : 0.041414, loss_ce: 0.013747
[02:06:29.886] iteration 17709 : loss : 0.102631, loss_ce: 0.011969
[02:06:30.192] iteration 17710 : loss : 0.053045, loss_ce: 0.011572
[02:06:30.500] iteration 17711 : loss : 0.052696, loss_ce: 0.020543
[02:06:30.811] iteration 17712 : loss : 0.038133, loss_ce: 0.010760
[02:06:31.116] iteration 17713 : loss : 0.044723, loss_ce: 0.016202
[02:06:31.424] iteration 17714 : loss : 0.135799, loss_ce: 0.004770
[02:06:31.733] iteration 17715 : loss : 0.041029, loss_ce: 0.009550
[02:06:32.043] iteration 17716 : loss : 0.038568, loss_ce: 0.012776
[02:06:32.349] iteration 17717 : loss : 0.110533, loss_ce: 0.016246
[02:06:32.658] iteration 17718 : loss : 0.045717, loss_ce: 0.016758
[02:06:32.971] iteration 17719 : loss : 0.050188, loss_ce: 0.017464
[02:06:33.277] iteration 17720 : loss : 0.046371, loss_ce: 0.010769
[02:06:33.596] iteration 17721 : loss : 0.035133, loss_ce: 0.009754
[02:06:33.905] iteration 17722 : loss : 0.043986, loss_ce: 0.013092
[02:06:34.209] iteration 17723 : loss : 0.101624, loss_ce: 0.011401
[02:06:34.520] iteration 17724 : loss : 0.042090, loss_ce: 0.018050
[02:06:34.827] iteration 17725 : loss : 0.045201, loss_ce: 0.011889
[02:06:35.138] iteration 17726 : loss : 0.103568, loss_ce: 0.008953
[02:06:35.446] iteration 17727 : loss : 0.044129, loss_ce: 0.014878
[02:06:35.750] iteration 17728 : loss : 0.039303, loss_ce: 0.011214
[02:06:36.064] iteration 17729 : loss : 0.041670, loss_ce: 0.011451
[02:06:36.374] iteration 17730 : loss : 0.039348, loss_ce: 0.018595
[02:06:36.680] iteration 17731 : loss : 0.061702, loss_ce: 0.014293
[02:06:36.994] iteration 17732 : loss : 0.037111, loss_ce: 0.009329
[02:06:37.300] iteration 17733 : loss : 0.044638, loss_ce: 0.011314
[02:06:37.612] iteration 17734 : loss : 0.039393, loss_ce: 0.010872
[02:06:37.923] iteration 17735 : loss : 0.046147, loss_ce: 0.008888
[02:06:38.233] iteration 17736 : loss : 0.043582, loss_ce: 0.008897
[02:06:38.549] iteration 17737 : loss : 0.042854, loss_ce: 0.017441
[02:06:38.860] iteration 17738 : loss : 0.057250, loss_ce: 0.013379
[02:06:39.171] iteration 17739 : loss : 0.044914, loss_ce: 0.018967
[02:06:39.480] iteration 17740 : loss : 0.094391, loss_ce: 0.007344
[02:06:39.798] iteration 17741 : loss : 0.041247, loss_ce: 0.013396
[02:06:40.101] iteration 17742 : loss : 0.045553, loss_ce: 0.012944
[02:06:40.406] iteration 17743 : loss : 0.041380, loss_ce: 0.013545
[02:06:40.706] iteration 17744 : loss : 0.048211, loss_ce: 0.017395
[02:06:41.009] iteration 17745 : loss : 0.043315, loss_ce: 0.014381
[02:06:41.314] iteration 17746 : loss : 0.051217, loss_ce: 0.018678
[02:06:41.619] iteration 17747 : loss : 0.100731, loss_ce: 0.010777
[02:06:41.923] iteration 17748 : loss : 0.060988, loss_ce: 0.025386
[02:06:42.229] iteration 17749 : loss : 0.049303, loss_ce: 0.012176
[02:06:42.532] iteration 17750 : loss : 0.049597, loss_ce: 0.012698
[02:06:42.838] iteration 17751 : loss : 0.043013, loss_ce: 0.014290
[02:06:43.140] iteration 17752 : loss : 0.066603, loss_ce: 0.013349
[02:06:43.444] iteration 17753 : loss : 0.046282, loss_ce: 0.011570
[02:06:43.747] iteration 17754 : loss : 0.162345, loss_ce: 0.004830
[02:06:44.049] iteration 17755 : loss : 0.105387, loss_ce: 0.010663
[02:06:44.352] iteration 17756 : loss : 0.155921, loss_ce: 0.004637
[02:06:44.653] iteration 17757 : loss : 0.058247, loss_ce: 0.029840
[02:06:44.962] iteration 17758 : loss : 0.058137, loss_ce: 0.014828
[02:06:45.264] iteration 17759 : loss : 0.159479, loss_ce: 0.010002
[02:06:45.569] iteration 17760 : loss : 0.046243, loss_ce: 0.015861
[02:06:45.891] iteration 17761 : loss : 0.048269, loss_ce: 0.014880
[02:06:46.196] iteration 17762 : loss : 0.044501, loss_ce: 0.014842
[02:06:46.504] iteration 17763 : loss : 0.047386, loss_ce: 0.012010
[02:06:46.808] iteration 17764 : loss : 0.051551, loss_ce: 0.020538
[02:06:47.112] iteration 17765 : loss : 0.047530, loss_ce: 0.015401
[02:06:47.417] iteration 17766 : loss : 0.099438, loss_ce: 0.010082
[02:06:47.722] iteration 17767 : loss : 0.042333, loss_ce: 0.013723
[02:06:48.030] iteration 17768 : loss : 0.049548, loss_ce: 0.009339
[02:06:48.336] iteration 17769 : loss : 0.056669, loss_ce: 0.018985
[02:06:48.641] iteration 17770 : loss : 0.045017, loss_ce: 0.012236
[02:06:48.945] iteration 17771 : loss : 0.051649, loss_ce: 0.016255
[02:06:49.247] iteration 17772 : loss : 0.117025, loss_ce: 0.007136
[02:06:49.551] iteration 17773 : loss : 0.044097, loss_ce: 0.016440
[02:06:49.858] iteration 17774 : loss : 0.045269, loss_ce: 0.015941
[02:06:50.165] iteration 17775 : loss : 0.048600, loss_ce: 0.018573
[02:06:50.473] iteration 17776 : loss : 0.037680, loss_ce: 0.013924
[02:06:50.787] iteration 17777 : loss : 0.042348, loss_ce: 0.016693
[02:06:51.094] iteration 17778 : loss : 0.151826, loss_ce: 0.004424
[02:06:51.406] iteration 17779 : loss : 0.108554, loss_ce: 0.017875
[02:06:51.722] iteration 17780 : loss : 0.038524, loss_ce: 0.008506
[02:06:52.077] iteration 17781 : loss : 0.052051, loss_ce: 0.016650
[02:06:52.391] iteration 17782 : loss : 0.034439, loss_ce: 0.010012
[02:06:52.710] iteration 17783 : loss : 0.102656, loss_ce: 0.016273
[02:06:53.024] iteration 17784 : loss : 0.051686, loss_ce: 0.016127
[02:06:53.340] iteration 17785 : loss : 0.042608, loss_ce: 0.009196
[02:06:53.661] iteration 17786 : loss : 0.158169, loss_ce: 0.003133
[02:06:53.979] iteration 17787 : loss : 0.116633, loss_ce: 0.008346
[02:06:54.293] iteration 17788 : loss : 0.043537, loss_ce: 0.012845
[02:06:54.608] iteration 17789 : loss : 0.045841, loss_ce: 0.009603
[02:06:54.917] iteration 17790 : loss : 0.052785, loss_ce: 0.013396
[02:06:55.227] iteration 17791 : loss : 0.080603, loss_ce: 0.014987
[02:06:55.321] iteration 17792 : loss : 0.402377, loss_ce: 0.002466
[02:07:12.819] iteration 17793 : loss : 0.044340, loss_ce: 0.007201
[02:07:13.119] iteration 17794 : loss : 0.047263, loss_ce: 0.021838
[02:07:13.421] iteration 17795 : loss : 0.110450, loss_ce: 0.004877
[02:07:13.724] iteration 17796 : loss : 0.042529, loss_ce: 0.013651
[02:07:14.026] iteration 17797 : loss : 0.104381, loss_ce: 0.014595
[02:07:14.324] iteration 17798 : loss : 0.216336, loss_ce: 0.005569
[02:07:14.629] iteration 17799 : loss : 0.088688, loss_ce: 0.008724
[02:07:14.934] iteration 17800 : loss : 0.040988, loss_ce: 0.011851
[02:07:15.252] iteration 17801 : loss : 0.047829, loss_ce: 0.011082
[02:07:15.552] iteration 17802 : loss : 0.032903, loss_ce: 0.013542
[02:07:15.856] iteration 17803 : loss : 0.041686, loss_ce: 0.015740
[02:07:16.163] iteration 17804 : loss : 0.038518, loss_ce: 0.010211
[02:07:16.463] iteration 17805 : loss : 0.097106, loss_ce: 0.009954
[02:07:16.769] iteration 17806 : loss : 0.041576, loss_ce: 0.015869
[02:07:17.075] iteration 17807 : loss : 0.054317, loss_ce: 0.012076
[02:07:17.379] iteration 17808 : loss : 0.053180, loss_ce: 0.016993
[02:07:17.677] iteration 17809 : loss : 0.101670, loss_ce: 0.012065
[02:07:17.979] iteration 17810 : loss : 0.048402, loss_ce: 0.023498
[02:07:18.282] iteration 17811 : loss : 0.104382, loss_ce: 0.010254
[02:07:18.581] iteration 17812 : loss : 0.099936, loss_ce: 0.014567
[02:07:18.884] iteration 17813 : loss : 0.104034, loss_ce: 0.008444
[02:07:19.186] iteration 17814 : loss : 0.097059, loss_ce: 0.012873
[02:07:19.488] iteration 17815 : loss : 0.036185, loss_ce: 0.008295
[02:07:19.790] iteration 17816 : loss : 0.049069, loss_ce: 0.017306
[02:07:20.090] iteration 17817 : loss : 0.034362, loss_ce: 0.009529
[02:07:20.392] iteration 17818 : loss : 0.041508, loss_ce: 0.007833
[02:07:20.696] iteration 17819 : loss : 0.053660, loss_ce: 0.019278
[02:07:20.999] iteration 17820 : loss : 0.044233, loss_ce: 0.015308
[02:07:21.318] iteration 17821 : loss : 0.056523, loss_ce: 0.013677
[02:07:21.620] iteration 17822 : loss : 0.103574, loss_ce: 0.011648
[02:07:21.921] iteration 17823 : loss : 0.114153, loss_ce: 0.017060
[02:07:22.224] iteration 17824 : loss : 0.166722, loss_ce: 0.006814
[02:07:22.528] iteration 17825 : loss : 0.050125, loss_ce: 0.016898
[02:07:22.833] iteration 17826 : loss : 0.044165, loss_ce: 0.009333
[02:07:23.139] iteration 17827 : loss : 0.103674, loss_ce: 0.017255
[02:07:23.441] iteration 17828 : loss : 0.036418, loss_ce: 0.007768
[02:07:23.745] iteration 17829 : loss : 0.047225, loss_ce: 0.018137
[02:07:24.054] iteration 17830 : loss : 0.048578, loss_ce: 0.022055
[02:07:24.359] iteration 17831 : loss : 0.056609, loss_ce: 0.010295
[02:07:24.664] iteration 17832 : loss : 0.102366, loss_ce: 0.010424
[02:07:24.969] iteration 17833 : loss : 0.048366, loss_ce: 0.020286
[02:07:25.281] iteration 17834 : loss : 0.104029, loss_ce: 0.014118
[02:07:25.588] iteration 17835 : loss : 0.042692, loss_ce: 0.014561
[02:07:25.897] iteration 17836 : loss : 0.067404, loss_ce: 0.011232
[02:07:26.204] iteration 17837 : loss : 0.045448, loss_ce: 0.013274
[02:07:26.520] iteration 17838 : loss : 0.051964, loss_ce: 0.018905
[02:07:26.827] iteration 17839 : loss : 0.040043, loss_ce: 0.014462
[02:07:27.138] iteration 17840 : loss : 0.041219, loss_ce: 0.011626
[02:07:27.460] iteration 17841 : loss : 0.051009, loss_ce: 0.019585
[02:07:27.766] iteration 17842 : loss : 0.103240, loss_ce: 0.017900
[02:07:28.072] iteration 17843 : loss : 0.039506, loss_ce: 0.011047
[02:07:28.384] iteration 17844 : loss : 0.037760, loss_ce: 0.017617
[02:07:28.692] iteration 17845 : loss : 0.043509, loss_ce: 0.012395
[02:07:29.001] iteration 17846 : loss : 0.036953, loss_ce: 0.010333
[02:07:29.308] iteration 17847 : loss : 0.104803, loss_ce: 0.010102
[02:07:29.620] iteration 17848 : loss : 0.040740, loss_ce: 0.013229
[02:07:29.925] iteration 17849 : loss : 0.103097, loss_ce: 0.008634
[02:07:30.236] iteration 17850 : loss : 0.045465, loss_ce: 0.014413
[02:07:30.543] iteration 17851 : loss : 0.109983, loss_ce: 0.018498
[02:07:30.852] iteration 17852 : loss : 0.045274, loss_ce: 0.012939
[02:07:31.161] iteration 17853 : loss : 0.099602, loss_ce: 0.010642
[02:07:31.467] iteration 17854 : loss : 0.051837, loss_ce: 0.026911
[02:07:31.777] iteration 17855 : loss : 0.039428, loss_ce: 0.010476
[02:07:32.086] iteration 17856 : loss : 0.053848, loss_ce: 0.007606
[02:07:32.393] iteration 17857 : loss : 0.048069, loss_ce: 0.013312
[02:07:32.700] iteration 17858 : loss : 0.046458, loss_ce: 0.008260
[02:07:33.006] iteration 17859 : loss : 0.046907, loss_ce: 0.007958
[02:07:33.315] iteration 17860 : loss : 0.050697, loss_ce: 0.021271
[02:07:33.639] iteration 17861 : loss : 0.046951, loss_ce: 0.018894
[02:07:33.944] iteration 17862 : loss : 0.101896, loss_ce: 0.004542
[02:07:34.252] iteration 17863 : loss : 0.044626, loss_ce: 0.012737
[02:07:34.568] iteration 17864 : loss : 0.049436, loss_ce: 0.016302
[02:07:34.882] iteration 17865 : loss : 0.041663, loss_ce: 0.009902
[02:07:35.194] iteration 17866 : loss : 0.038202, loss_ce: 0.013592
[02:07:35.500] iteration 17867 : loss : 0.043282, loss_ce: 0.015026
[02:07:35.813] iteration 17868 : loss : 0.045468, loss_ce: 0.010402
[02:07:36.118] iteration 17869 : loss : 0.046248, loss_ce: 0.015814
[02:07:36.431] iteration 17870 : loss : 0.040643, loss_ce: 0.012473
[02:07:36.736] iteration 17871 : loss : 0.046381, loss_ce: 0.017701
[02:07:37.045] iteration 17872 : loss : 0.062893, loss_ce: 0.014858
[02:07:37.353] iteration 17873 : loss : 0.062434, loss_ce: 0.009101
[02:07:37.658] iteration 17874 : loss : 0.110109, loss_ce: 0.008284
[02:07:37.970] iteration 17875 : loss : 0.044201, loss_ce: 0.020985
[02:07:38.276] iteration 17876 : loss : 0.041964, loss_ce: 0.015568
[02:07:38.585] iteration 17877 : loss : 0.040337, loss_ce: 0.015133
[02:07:38.893] iteration 17878 : loss : 0.056434, loss_ce: 0.021800
[02:07:39.204] iteration 17879 : loss : 0.100330, loss_ce: 0.014987
[02:07:39.512] iteration 17880 : loss : 0.043441, loss_ce: 0.012526
[02:07:39.832] iteration 17881 : loss : 0.093673, loss_ce: 0.006302
[02:07:40.140] iteration 17882 : loss : 0.049265, loss_ce: 0.017637
[02:07:40.450] iteration 17883 : loss : 0.061820, loss_ce: 0.008179
[02:07:40.757] iteration 17884 : loss : 0.037148, loss_ce: 0.017175
[02:07:41.063] iteration 17885 : loss : 0.051557, loss_ce: 0.020426
[02:07:41.371] iteration 17886 : loss : 0.053451, loss_ce: 0.005891
[02:07:41.681] iteration 17887 : loss : 0.043237, loss_ce: 0.009381
[02:07:41.989] iteration 17888 : loss : 0.033115, loss_ce: 0.006639
[02:07:42.300] iteration 17889 : loss : 0.048288, loss_ce: 0.020481
[02:07:42.610] iteration 17890 : loss : 0.045454, loss_ce: 0.018292
[02:07:42.923] iteration 17891 : loss : 0.041431, loss_ce: 0.009020
[02:07:43.232] iteration 17892 : loss : 0.052148, loss_ce: 0.014570
[02:07:43.544] iteration 17893 : loss : 0.038510, loss_ce: 0.011531
[02:07:43.857] iteration 17894 : loss : 0.036982, loss_ce: 0.015709
[02:07:44.168] iteration 17895 : loss : 0.060609, loss_ce: 0.018925
[02:07:44.472] iteration 17896 : loss : 0.042712, loss_ce: 0.007223
[02:07:44.779] iteration 17897 : loss : 0.111270, loss_ce: 0.019026
[02:07:45.082] iteration 17898 : loss : 0.112141, loss_ce: 0.009172
[02:07:45.384] iteration 17899 : loss : 0.103071, loss_ce: 0.008710
[02:07:45.688] iteration 17900 : loss : 0.122068, loss_ce: 0.002441
[02:07:46.005] iteration 17901 : loss : 0.056175, loss_ce: 0.013052
[02:07:46.306] iteration 17902 : loss : 0.045793, loss_ce: 0.019148
[02:07:46.608] iteration 17903 : loss : 0.106681, loss_ce: 0.014020
[02:07:46.912] iteration 17904 : loss : 0.050538, loss_ce: 0.011509
[02:07:47.216] iteration 17905 : loss : 0.045214, loss_ce: 0.013506
[02:07:47.520] iteration 17906 : loss : 0.043354, loss_ce: 0.017699
[02:07:47.826] iteration 17907 : loss : 0.049814, loss_ce: 0.007915
[02:07:48.126] iteration 17908 : loss : 0.179815, loss_ce: 0.008241
[02:07:48.427] iteration 17909 : loss : 0.047223, loss_ce: 0.011308
[02:07:48.730] iteration 17910 : loss : 0.042099, loss_ce: 0.018595
[02:07:49.033] iteration 17911 : loss : 0.043922, loss_ce: 0.015523
[02:07:49.340] iteration 17912 : loss : 0.046208, loss_ce: 0.003956
[02:07:49.645] iteration 17913 : loss : 0.113021, loss_ce: 0.012282
[02:07:49.949] iteration 17914 : loss : 0.147767, loss_ce: 0.003632
[02:07:50.255] iteration 17915 : loss : 0.038782, loss_ce: 0.017546
[02:07:50.561] iteration 17916 : loss : 0.099967, loss_ce: 0.013154
[02:07:50.866] iteration 17917 : loss : 0.106511, loss_ce: 0.012306
[02:07:51.173] iteration 17918 : loss : 0.041587, loss_ce: 0.011180
[02:07:51.482] iteration 17919 : loss : 0.129229, loss_ce: 0.023898
[02:07:51.790] iteration 17920 : loss : 0.053485, loss_ce: 0.018263
[02:07:52.141] iteration 17921 : loss : 0.045797, loss_ce: 0.016388
[02:07:52.446] iteration 17922 : loss : 0.047547, loss_ce: 0.016588
[02:07:52.758] iteration 17923 : loss : 0.049997, loss_ce: 0.012153
[02:07:53.064] iteration 17924 : loss : 0.046196, loss_ce: 0.020332
[02:07:53.372] iteration 17925 : loss : 0.128810, loss_ce: 0.006890
[02:07:53.681] iteration 17926 : loss : 0.104744, loss_ce: 0.008167
[02:07:53.997] iteration 17927 : loss : 0.114333, loss_ce: 0.010334
[02:07:54.303] iteration 17928 : loss : 0.161743, loss_ce: 0.007319
[02:07:54.611] iteration 17929 : loss : 0.047283, loss_ce: 0.010930
[02:07:54.922] iteration 17930 : loss : 0.061339, loss_ce: 0.017789
[02:07:55.006] iteration 17931 : loss : 0.281178, loss_ce: 0.009695
[02:08:12.634] iteration 17932 : loss : 0.105314, loss_ce: 0.012035
[02:08:12.938] iteration 17933 : loss : 0.068824, loss_ce: 0.009916
[02:08:13.242] iteration 17934 : loss : 0.044455, loss_ce: 0.016320
[02:08:13.555] iteration 17935 : loss : 0.046328, loss_ce: 0.017769
[02:08:13.860] iteration 17936 : loss : 0.047073, loss_ce: 0.010249
[02:08:14.162] iteration 17937 : loss : 0.050058, loss_ce: 0.007797
[02:08:14.465] iteration 17938 : loss : 0.049563, loss_ce: 0.022742
[02:08:14.766] iteration 17939 : loss : 0.047114, loss_ce: 0.012177
[02:08:15.067] iteration 17940 : loss : 0.098830, loss_ce: 0.014411
[02:08:15.386] iteration 17941 : loss : 0.278898, loss_ce: 0.003142
[02:08:15.688] iteration 17942 : loss : 0.050907, loss_ce: 0.028109
[02:08:15.989] iteration 17943 : loss : 0.045750, loss_ce: 0.024115
[02:08:16.291] iteration 17944 : loss : 0.045770, loss_ce: 0.007215
[02:08:16.594] iteration 17945 : loss : 0.053012, loss_ce: 0.024418
[02:08:16.900] iteration 17946 : loss : 0.066869, loss_ce: 0.021045
[02:08:17.202] iteration 17947 : loss : 0.046533, loss_ce: 0.015968
[02:08:17.503] iteration 17948 : loss : 0.036007, loss_ce: 0.010642
[02:08:17.804] iteration 17949 : loss : 0.057346, loss_ce: 0.023379
[02:08:18.108] iteration 17950 : loss : 0.045283, loss_ce: 0.017053
[02:08:18.410] iteration 17951 : loss : 0.104569, loss_ce: 0.018040
[02:08:18.714] iteration 17952 : loss : 0.043413, loss_ce: 0.011723
[02:08:19.017] iteration 17953 : loss : 0.037022, loss_ce: 0.013104
[02:08:19.323] iteration 17954 : loss : 0.041820, loss_ce: 0.012225
[02:08:19.623] iteration 17955 : loss : 0.041437, loss_ce: 0.013526
[02:08:19.926] iteration 17956 : loss : 0.048479, loss_ce: 0.020472
[02:08:20.228] iteration 17957 : loss : 0.097991, loss_ce: 0.007497
[02:08:20.530] iteration 17958 : loss : 0.043426, loss_ce: 0.009017
[02:08:20.834] iteration 17959 : loss : 0.048223, loss_ce: 0.011642
[02:08:21.136] iteration 17960 : loss : 0.052095, loss_ce: 0.011875
[02:08:21.454] iteration 17961 : loss : 0.038780, loss_ce: 0.009807
[02:08:21.757] iteration 17962 : loss : 0.041124, loss_ce: 0.012179
[02:08:22.061] iteration 17963 : loss : 0.153360, loss_ce: 0.005716
[02:08:22.362] iteration 17964 : loss : 0.046733, loss_ce: 0.013841
[02:08:22.666] iteration 17965 : loss : 0.043392, loss_ce: 0.007353
[02:08:22.969] iteration 17966 : loss : 0.043097, loss_ce: 0.012698
[02:08:23.276] iteration 17967 : loss : 0.095210, loss_ce: 0.008455
[02:08:23.578] iteration 17968 : loss : 0.046529, loss_ce: 0.008275
[02:08:23.880] iteration 17969 : loss : 0.097018, loss_ce: 0.010122
[02:08:24.185] iteration 17970 : loss : 0.044813, loss_ce: 0.011522
[02:08:24.488] iteration 17971 : loss : 0.034384, loss_ce: 0.007022
[02:08:24.790] iteration 17972 : loss : 0.103741, loss_ce: 0.008614
[02:08:25.094] iteration 17973 : loss : 0.045223, loss_ce: 0.021826
[02:08:25.396] iteration 17974 : loss : 0.049881, loss_ce: 0.013199
[02:08:25.702] iteration 17975 : loss : 0.043963, loss_ce: 0.011846
[02:08:26.005] iteration 17976 : loss : 0.055626, loss_ce: 0.015084
[02:08:26.307] iteration 17977 : loss : 0.043656, loss_ce: 0.011849
[02:08:26.610] iteration 17978 : loss : 0.035710, loss_ce: 0.013176
[02:08:26.915] iteration 17979 : loss : 0.046005, loss_ce: 0.017682
[02:08:27.223] iteration 17980 : loss : 0.041663, loss_ce: 0.007703
[02:08:27.540] iteration 17981 : loss : 0.051441, loss_ce: 0.017973
[02:08:27.846] iteration 17982 : loss : 0.105787, loss_ce: 0.018637
[02:08:28.161] iteration 17983 : loss : 0.046609, loss_ce: 0.017468
[02:08:28.468] iteration 17984 : loss : 0.045312, loss_ce: 0.016932
[02:08:28.777] iteration 17985 : loss : 0.046711, loss_ce: 0.018350
[02:08:29.092] iteration 17986 : loss : 0.044009, loss_ce: 0.007357
[02:08:29.397] iteration 17987 : loss : 0.045095, loss_ce: 0.007865
[02:08:29.699] iteration 17988 : loss : 0.046088, loss_ce: 0.011807
[02:08:30.005] iteration 17989 : loss : 0.048088, loss_ce: 0.015701
[02:08:30.308] iteration 17990 : loss : 0.113312, loss_ce: 0.007295
[02:08:30.614] iteration 17991 : loss : 0.047899, loss_ce: 0.009980
[02:08:30.921] iteration 17992 : loss : 0.107338, loss_ce: 0.006608
[02:08:31.226] iteration 17993 : loss : 0.102318, loss_ce: 0.008589
[02:08:31.529] iteration 17994 : loss : 0.099022, loss_ce: 0.015584
[02:08:31.829] iteration 17995 : loss : 0.039095, loss_ce: 0.013423
[02:08:32.132] iteration 17996 : loss : 0.048888, loss_ce: 0.019973
[02:08:32.437] iteration 17997 : loss : 0.042924, loss_ce: 0.013207
[02:08:32.737] iteration 17998 : loss : 0.055957, loss_ce: 0.012313
[02:08:33.040] iteration 17999 : loss : 0.039848, loss_ce: 0.013332
[02:08:33.345] iteration 18000 : loss : 0.097876, loss_ce: 0.014103
[02:08:33.663] iteration 18001 : loss : 0.055825, loss_ce: 0.013271
[02:08:33.965] iteration 18002 : loss : 0.042051, loss_ce: 0.011905
[02:08:34.268] iteration 18003 : loss : 0.040173, loss_ce: 0.016396
[02:08:34.572] iteration 18004 : loss : 0.049854, loss_ce: 0.016357
[02:08:34.874] iteration 18005 : loss : 0.056032, loss_ce: 0.011417
[02:08:35.177] iteration 18006 : loss : 0.063882, loss_ce: 0.009376
[02:08:35.479] iteration 18007 : loss : 0.034926, loss_ce: 0.013918
[02:08:35.784] iteration 18008 : loss : 0.045590, loss_ce: 0.008874
[02:08:36.088] iteration 18009 : loss : 0.046142, loss_ce: 0.007821
[02:08:36.392] iteration 18010 : loss : 0.038231, loss_ce: 0.019747
[02:08:36.693] iteration 18011 : loss : 0.051345, loss_ce: 0.015594
[02:08:36.997] iteration 18012 : loss : 0.057448, loss_ce: 0.010043
[02:08:37.300] iteration 18013 : loss : 0.042653, loss_ce: 0.014153
[02:08:37.605] iteration 18014 : loss : 0.102918, loss_ce: 0.004011
[02:08:37.912] iteration 18015 : loss : 0.059337, loss_ce: 0.018489
[02:08:38.218] iteration 18016 : loss : 0.042362, loss_ce: 0.009301
[02:08:38.521] iteration 18017 : loss : 0.044603, loss_ce: 0.017651
[02:08:38.824] iteration 18018 : loss : 0.047189, loss_ce: 0.017138
[02:08:39.127] iteration 18019 : loss : 0.104898, loss_ce: 0.011576
[02:08:39.432] iteration 18020 : loss : 0.041046, loss_ce: 0.017170
[02:08:39.758] iteration 18021 : loss : 0.042285, loss_ce: 0.017395
[02:08:40.061] iteration 18022 : loss : 0.044782, loss_ce: 0.011068
[02:08:40.364] iteration 18023 : loss : 0.103153, loss_ce: 0.010135
[02:08:40.668] iteration 18024 : loss : 0.043279, loss_ce: 0.009775
[02:08:40.977] iteration 18025 : loss : 0.103439, loss_ce: 0.014604
[02:08:41.281] iteration 18026 : loss : 0.039515, loss_ce: 0.018705
[02:08:41.588] iteration 18027 : loss : 0.042055, loss_ce: 0.013166
[02:08:41.891] iteration 18028 : loss : 0.045119, loss_ce: 0.025608
[02:08:42.193] iteration 18029 : loss : 0.091640, loss_ce: 0.005356
[02:08:42.498] iteration 18030 : loss : 0.106883, loss_ce: 0.004086
[02:08:42.802] iteration 18031 : loss : 0.110726, loss_ce: 0.013706
[02:08:43.106] iteration 18032 : loss : 0.163744, loss_ce: 0.005686
[02:08:43.410] iteration 18033 : loss : 0.120652, loss_ce: 0.015017
[02:08:43.716] iteration 18034 : loss : 0.046021, loss_ce: 0.011000
[02:08:44.022] iteration 18035 : loss : 0.112041, loss_ce: 0.010779
[02:08:44.327] iteration 18036 : loss : 0.045193, loss_ce: 0.021284
[02:08:44.633] iteration 18037 : loss : 0.048995, loss_ce: 0.014478
[02:08:44.940] iteration 18038 : loss : 0.113099, loss_ce: 0.007512
[02:08:45.249] iteration 18039 : loss : 0.041920, loss_ce: 0.012162
[02:08:45.552] iteration 18040 : loss : 0.153266, loss_ce: 0.005557
[02:08:45.880] iteration 18041 : loss : 0.038210, loss_ce: 0.014286
[02:08:46.188] iteration 18042 : loss : 0.036665, loss_ce: 0.014471
[02:08:46.497] iteration 18043 : loss : 0.052990, loss_ce: 0.019153
[02:08:46.802] iteration 18044 : loss : 0.046695, loss_ce: 0.019663
[02:08:47.110] iteration 18045 : loss : 0.042046, loss_ce: 0.016274
[02:08:47.418] iteration 18046 : loss : 0.052214, loss_ce: 0.013260
[02:08:47.731] iteration 18047 : loss : 0.054283, loss_ce: 0.009387
[02:08:48.038] iteration 18048 : loss : 0.047670, loss_ce: 0.012505
[02:08:48.349] iteration 18049 : loss : 0.097990, loss_ce: 0.007057
[02:08:48.658] iteration 18050 : loss : 0.051455, loss_ce: 0.013315
[02:08:48.971] iteration 18051 : loss : 0.048099, loss_ce: 0.013103
[02:08:49.278] iteration 18052 : loss : 0.035634, loss_ce: 0.007517
[02:08:49.587] iteration 18053 : loss : 0.039040, loss_ce: 0.015762
[02:08:49.894] iteration 18054 : loss : 0.049791, loss_ce: 0.013176
[02:08:50.209] iteration 18055 : loss : 0.052436, loss_ce: 0.016361
[02:08:50.527] iteration 18056 : loss : 0.056160, loss_ce: 0.010825
[02:08:50.840] iteration 18057 : loss : 0.129869, loss_ce: 0.010101
[02:08:51.154] iteration 18058 : loss : 0.041517, loss_ce: 0.008969
[02:08:51.471] iteration 18059 : loss : 0.104551, loss_ce: 0.005932
[02:08:51.787] iteration 18060 : loss : 0.036608, loss_ce: 0.015599
[02:08:52.124] iteration 18061 : loss : 0.047656, loss_ce: 0.011722
[02:08:52.441] iteration 18062 : loss : 0.098711, loss_ce: 0.010967
[02:08:52.758] iteration 18063 : loss : 0.043132, loss_ce: 0.016964
[02:08:53.071] iteration 18064 : loss : 0.045149, loss_ce: 0.014150
[02:08:53.385] iteration 18065 : loss : 0.043757, loss_ce: 0.015747
[02:08:53.699] iteration 18066 : loss : 0.119024, loss_ce: 0.014234
[02:08:54.014] iteration 18067 : loss : 0.058204, loss_ce: 0.010921
[02:08:54.327] iteration 18068 : loss : 0.060878, loss_ce: 0.018709
[02:08:54.645] iteration 18069 : loss : 0.108783, loss_ce: 0.012277
[02:08:54.725] iteration 18070 : loss : 0.052425, loss_ce: 0.038296
[02:09:12.115] iteration 18071 : loss : 0.063547, loss_ce: 0.013535
[02:09:12.413] iteration 18072 : loss : 0.054080, loss_ce: 0.012965
[02:09:12.712] iteration 18073 : loss : 0.093783, loss_ce: 0.013266
[02:09:13.013] iteration 18074 : loss : 0.046072, loss_ce: 0.014998
[02:09:13.316] iteration 18075 : loss : 0.051974, loss_ce: 0.016772
[02:09:13.618] iteration 18076 : loss : 0.053764, loss_ce: 0.009265
[02:09:13.919] iteration 18077 : loss : 0.038936, loss_ce: 0.007870
[02:09:14.223] iteration 18078 : loss : 0.040226, loss_ce: 0.008775
[02:09:14.528] iteration 18079 : loss : 0.115652, loss_ce: 0.010271
[02:09:14.828] iteration 18080 : loss : 0.052395, loss_ce: 0.023864
[02:09:15.147] iteration 18081 : loss : 0.049628, loss_ce: 0.006045
[02:09:15.453] iteration 18082 : loss : 0.040047, loss_ce: 0.017524
[02:09:15.754] iteration 18083 : loss : 0.040972, loss_ce: 0.007528
[02:09:16.060] iteration 18084 : loss : 0.043468, loss_ce: 0.013647
[02:09:16.365] iteration 18085 : loss : 0.043397, loss_ce: 0.006759
[02:09:16.668] iteration 18086 : loss : 0.044414, loss_ce: 0.012014
[02:09:16.973] iteration 18087 : loss : 0.039712, loss_ce: 0.020216
[02:09:17.279] iteration 18088 : loss : 0.040111, loss_ce: 0.015717
[02:09:17.591] iteration 18089 : loss : 0.042041, loss_ce: 0.013400
[02:09:17.904] iteration 18090 : loss : 0.127316, loss_ce: 0.006041
[02:09:18.210] iteration 18091 : loss : 0.049616, loss_ce: 0.013445
[02:09:18.519] iteration 18092 : loss : 0.043205, loss_ce: 0.013117
[02:09:18.830] iteration 18093 : loss : 0.046606, loss_ce: 0.012964
[02:09:19.140] iteration 18094 : loss : 0.040845, loss_ce: 0.010835
[02:09:19.445] iteration 18095 : loss : 0.099306, loss_ce: 0.010894
[02:09:19.750] iteration 18096 : loss : 0.042513, loss_ce: 0.015626
[02:09:20.059] iteration 18097 : loss : 0.041613, loss_ce: 0.019793
[02:09:20.361] iteration 18098 : loss : 0.043826, loss_ce: 0.006530
[02:09:20.670] iteration 18099 : loss : 0.104542, loss_ce: 0.008129
[02:09:20.974] iteration 18100 : loss : 0.044522, loss_ce: 0.015103
[02:09:21.291] iteration 18101 : loss : 0.033535, loss_ce: 0.008067
[02:09:21.595] iteration 18102 : loss : 0.051341, loss_ce: 0.012775
[02:09:21.899] iteration 18103 : loss : 0.112539, loss_ce: 0.008233
[02:09:22.201] iteration 18104 : loss : 0.051107, loss_ce: 0.015234
[02:09:22.503] iteration 18105 : loss : 0.043709, loss_ce: 0.014163
[02:09:22.804] iteration 18106 : loss : 0.047641, loss_ce: 0.018273
[02:09:23.105] iteration 18107 : loss : 0.043494, loss_ce: 0.020057
[02:09:23.405] iteration 18108 : loss : 0.063731, loss_ce: 0.013360
[02:09:23.708] iteration 18109 : loss : 0.046477, loss_ce: 0.014802
[02:09:24.012] iteration 18110 : loss : 0.036680, loss_ce: 0.009554
[02:09:24.318] iteration 18111 : loss : 0.049476, loss_ce: 0.021868
[02:09:24.626] iteration 18112 : loss : 0.041380, loss_ce: 0.012247
[02:09:24.927] iteration 18113 : loss : 0.045421, loss_ce: 0.012545
[02:09:25.229] iteration 18114 : loss : 0.035909, loss_ce: 0.009931
[02:09:25.531] iteration 18115 : loss : 0.101344, loss_ce: 0.011038
[02:09:25.834] iteration 18116 : loss : 0.036567, loss_ce: 0.011474
[02:09:26.139] iteration 18117 : loss : 0.054746, loss_ce: 0.026483
[02:09:26.444] iteration 18118 : loss : 0.047160, loss_ce: 0.010962
[02:09:26.750] iteration 18119 : loss : 0.116742, loss_ce: 0.017546
[02:09:27.057] iteration 18120 : loss : 0.069711, loss_ce: 0.005006
[02:09:27.376] iteration 18121 : loss : 0.044504, loss_ce: 0.014410
[02:09:27.682] iteration 18122 : loss : 0.035783, loss_ce: 0.007760
[02:09:27.981] iteration 18123 : loss : 0.103874, loss_ce: 0.008734
[02:09:28.288] iteration 18124 : loss : 0.051541, loss_ce: 0.015475
[02:09:28.589] iteration 18125 : loss : 0.107897, loss_ce: 0.007652
[02:09:28.896] iteration 18126 : loss : 0.151433, loss_ce: 0.006312
[02:09:29.199] iteration 18127 : loss : 0.040374, loss_ce: 0.015688
[02:09:29.499] iteration 18128 : loss : 0.102334, loss_ce: 0.010767
[02:09:29.802] iteration 18129 : loss : 0.056828, loss_ce: 0.019796
[02:09:30.104] iteration 18130 : loss : 0.048415, loss_ce: 0.019001
[02:09:30.408] iteration 18131 : loss : 0.048850, loss_ce: 0.007889
[02:09:30.712] iteration 18132 : loss : 0.038335, loss_ce: 0.010026
[02:09:31.015] iteration 18133 : loss : 0.040039, loss_ce: 0.017763
[02:09:31.317] iteration 18134 : loss : 0.045285, loss_ce: 0.016547
[02:09:31.619] iteration 18135 : loss : 0.057648, loss_ce: 0.017152
[02:09:31.922] iteration 18136 : loss : 0.044056, loss_ce: 0.014751
[02:09:32.228] iteration 18137 : loss : 0.041565, loss_ce: 0.016391
[02:09:32.532] iteration 18138 : loss : 0.052964, loss_ce: 0.017802
[02:09:32.837] iteration 18139 : loss : 0.041519, loss_ce: 0.015752
[02:09:33.141] iteration 18140 : loss : 0.121834, loss_ce: 0.008420
[02:09:33.461] iteration 18141 : loss : 0.036893, loss_ce: 0.009871
[02:09:33.766] iteration 18142 : loss : 0.039680, loss_ce: 0.014861
[02:09:34.069] iteration 18143 : loss : 0.055381, loss_ce: 0.017300
[02:09:34.371] iteration 18144 : loss : 0.166799, loss_ce: 0.003143
[02:09:34.676] iteration 18145 : loss : 0.036866, loss_ce: 0.008019
[02:09:34.984] iteration 18146 : loss : 0.152728, loss_ce: 0.007948
[02:09:35.292] iteration 18147 : loss : 0.046807, loss_ce: 0.011497
[02:09:35.598] iteration 18148 : loss : 0.038148, loss_ce: 0.008567
[02:09:35.905] iteration 18149 : loss : 0.049963, loss_ce: 0.015607
[02:09:36.212] iteration 18150 : loss : 0.104079, loss_ce: 0.012605
[02:09:36.519] iteration 18151 : loss : 0.090211, loss_ce: 0.009838
[02:09:36.828] iteration 18152 : loss : 0.047257, loss_ce: 0.009368
[02:09:37.137] iteration 18153 : loss : 0.043223, loss_ce: 0.017613
[02:09:37.444] iteration 18154 : loss : 0.041831, loss_ce: 0.011871
[02:09:37.753] iteration 18155 : loss : 0.057147, loss_ce: 0.013883
[02:09:38.057] iteration 18156 : loss : 0.052378, loss_ce: 0.024162
[02:09:38.372] iteration 18157 : loss : 0.106335, loss_ce: 0.008461
[02:09:38.676] iteration 18158 : loss : 0.123045, loss_ce: 0.014664
[02:09:38.984] iteration 18159 : loss : 0.035512, loss_ce: 0.009803
[02:09:39.292] iteration 18160 : loss : 0.099970, loss_ce: 0.011961
[02:09:39.621] iteration 18161 : loss : 0.039121, loss_ce: 0.012214
[02:09:39.928] iteration 18162 : loss : 0.068955, loss_ce: 0.020775
[02:09:40.235] iteration 18163 : loss : 0.040952, loss_ce: 0.014900
[02:09:40.542] iteration 18164 : loss : 0.050452, loss_ce: 0.019470
[02:09:40.855] iteration 18165 : loss : 0.101828, loss_ce: 0.011095
[02:09:41.159] iteration 18166 : loss : 0.037153, loss_ce: 0.012192
[02:09:41.465] iteration 18167 : loss : 0.045537, loss_ce: 0.016071
[02:09:41.774] iteration 18168 : loss : 0.039387, loss_ce: 0.009593
[02:09:42.079] iteration 18169 : loss : 0.036335, loss_ce: 0.010618
[02:09:42.387] iteration 18170 : loss : 0.056593, loss_ce: 0.021159
[02:09:42.698] iteration 18171 : loss : 0.045817, loss_ce: 0.011429
[02:09:43.003] iteration 18172 : loss : 0.040930, loss_ce: 0.011656
[02:09:43.316] iteration 18173 : loss : 0.046567, loss_ce: 0.020667
[02:09:43.625] iteration 18174 : loss : 0.042430, loss_ce: 0.015485
[02:09:43.936] iteration 18175 : loss : 0.041569, loss_ce: 0.015785
[02:09:44.244] iteration 18176 : loss : 0.048515, loss_ce: 0.018748
[02:09:44.551] iteration 18177 : loss : 0.034898, loss_ce: 0.011547
[02:09:44.857] iteration 18178 : loss : 0.039793, loss_ce: 0.018940
[02:09:45.167] iteration 18179 : loss : 0.047574, loss_ce: 0.015059
[02:09:45.476] iteration 18180 : loss : 0.049371, loss_ce: 0.016953
[02:09:45.801] iteration 18181 : loss : 0.045716, loss_ce: 0.007752
[02:09:46.107] iteration 18182 : loss : 0.097069, loss_ce: 0.008974
[02:09:46.417] iteration 18183 : loss : 0.047813, loss_ce: 0.011436
[02:09:46.728] iteration 18184 : loss : 0.054844, loss_ce: 0.024681
[02:09:47.037] iteration 18185 : loss : 0.042507, loss_ce: 0.007074
[02:09:47.342] iteration 18186 : loss : 0.113367, loss_ce: 0.009953
[02:09:47.652] iteration 18187 : loss : 0.050398, loss_ce: 0.025876
[02:09:47.961] iteration 18188 : loss : 0.044420, loss_ce: 0.014160
[02:09:48.273] iteration 18189 : loss : 0.036683, loss_ce: 0.009556
[02:09:48.582] iteration 18190 : loss : 0.065419, loss_ce: 0.009992
[02:09:48.891] iteration 18191 : loss : 0.104142, loss_ce: 0.010437
[02:09:49.196] iteration 18192 : loss : 0.224443, loss_ce: 0.015689
[02:09:49.507] iteration 18193 : loss : 0.040920, loss_ce: 0.013543
[02:09:49.817] iteration 18194 : loss : 0.047189, loss_ce: 0.015676
[02:09:50.138] iteration 18195 : loss : 0.045023, loss_ce: 0.020049
[02:09:50.444] iteration 18196 : loss : 0.045691, loss_ce: 0.014464
[02:09:50.750] iteration 18197 : loss : 0.043835, loss_ce: 0.011244
[02:09:51.065] iteration 18198 : loss : 0.056184, loss_ce: 0.011278
[02:09:51.389] iteration 18199 : loss : 0.041087, loss_ce: 0.010918
[02:09:51.696] iteration 18200 : loss : 0.103610, loss_ce: 0.011772
[02:09:52.037] iteration 18201 : loss : 0.030281, loss_ce: 0.010087
[02:09:52.349] iteration 18202 : loss : 0.042135, loss_ce: 0.007253
[02:09:52.666] iteration 18203 : loss : 0.050196, loss_ce: 0.014093
[02:09:52.976] iteration 18204 : loss : 0.047975, loss_ce: 0.008099
[02:09:53.284] iteration 18205 : loss : 0.046868, loss_ce: 0.015172
[02:09:53.599] iteration 18206 : loss : 0.045584, loss_ce: 0.016722
[02:09:53.913] iteration 18207 : loss : 0.152881, loss_ce: 0.007998
[02:09:54.229] iteration 18208 : loss : 0.054792, loss_ce: 0.017154
[02:09:54.305] iteration 18209 : loss : 0.325240, loss_ce: 0.003303
[02:10:13.569] iteration 18210 : loss : 0.047869, loss_ce: 0.011029
[02:10:13.867] iteration 18211 : loss : 0.045529, loss_ce: 0.014229
[02:10:14.169] iteration 18212 : loss : 0.040978, loss_ce: 0.013379
[02:10:14.471] iteration 18213 : loss : 0.154464, loss_ce: 0.009324
[02:10:14.772] iteration 18214 : loss : 0.039714, loss_ce: 0.017283
[02:10:15.074] iteration 18215 : loss : 0.051099, loss_ce: 0.014784
[02:10:15.375] iteration 18216 : loss : 0.054367, loss_ce: 0.009187
[02:10:15.680] iteration 18217 : loss : 0.041410, loss_ce: 0.011090
[02:10:15.978] iteration 18218 : loss : 0.039078, loss_ce: 0.017643
[02:10:16.281] iteration 18219 : loss : 0.037806, loss_ce: 0.014779
[02:10:16.585] iteration 18220 : loss : 0.040788, loss_ce: 0.007290
[02:10:16.902] iteration 18221 : loss : 0.044826, loss_ce: 0.014910
[02:10:17.203] iteration 18222 : loss : 0.048787, loss_ce: 0.007216
[02:10:17.506] iteration 18223 : loss : 0.045516, loss_ce: 0.010082
[02:10:17.808] iteration 18224 : loss : 0.052161, loss_ce: 0.019422
[02:10:18.115] iteration 18225 : loss : 0.043437, loss_ce: 0.014199
[02:10:18.414] iteration 18226 : loss : 0.050618, loss_ce: 0.014594
[02:10:18.719] iteration 18227 : loss : 0.041773, loss_ce: 0.012141
[02:10:19.024] iteration 18228 : loss : 0.046903, loss_ce: 0.017039
[02:10:19.328] iteration 18229 : loss : 0.087957, loss_ce: 0.020165
[02:10:19.628] iteration 18230 : loss : 0.036798, loss_ce: 0.015517
[02:10:19.934] iteration 18231 : loss : 0.102252, loss_ce: 0.008703
[02:10:20.237] iteration 18232 : loss : 0.049615, loss_ce: 0.014467
[02:10:20.540] iteration 18233 : loss : 0.048296, loss_ce: 0.011086
[02:10:20.842] iteration 18234 : loss : 0.054130, loss_ce: 0.016790
[02:10:21.141] iteration 18235 : loss : 0.050136, loss_ce: 0.015815
[02:10:21.445] iteration 18236 : loss : 0.044592, loss_ce: 0.023314
[02:10:21.751] iteration 18237 : loss : 0.044018, loss_ce: 0.018084
[02:10:22.054] iteration 18238 : loss : 0.049836, loss_ce: 0.017155
[02:10:22.362] iteration 18239 : loss : 0.046357, loss_ce: 0.007357
[02:10:22.664] iteration 18240 : loss : 0.047817, loss_ce: 0.012759
[02:10:22.989] iteration 18241 : loss : 0.033496, loss_ce: 0.010820
[02:10:23.293] iteration 18242 : loss : 0.034898, loss_ce: 0.017844
[02:10:23.600] iteration 18243 : loss : 0.048665, loss_ce: 0.023013
[02:10:23.904] iteration 18244 : loss : 0.039232, loss_ce: 0.013609
[02:10:24.207] iteration 18245 : loss : 0.122873, loss_ce: 0.006333
[02:10:24.512] iteration 18246 : loss : 0.040373, loss_ce: 0.011007
[02:10:24.816] iteration 18247 : loss : 0.045579, loss_ce: 0.011841
[02:10:25.123] iteration 18248 : loss : 0.100988, loss_ce: 0.005357
[02:10:25.436] iteration 18249 : loss : 0.042610, loss_ce: 0.013671
[02:10:25.743] iteration 18250 : loss : 0.030965, loss_ce: 0.011095
[02:10:26.050] iteration 18251 : loss : 0.105058, loss_ce: 0.014012
[02:10:26.361] iteration 18252 : loss : 0.054556, loss_ce: 0.013895
[02:10:26.668] iteration 18253 : loss : 0.036008, loss_ce: 0.012001
[02:10:26.978] iteration 18254 : loss : 0.045035, loss_ce: 0.017230
[02:10:27.288] iteration 18255 : loss : 0.035304, loss_ce: 0.009282
[02:10:27.594] iteration 18256 : loss : 0.045070, loss_ce: 0.012645
[02:10:27.900] iteration 18257 : loss : 0.050109, loss_ce: 0.013860
[02:10:28.210] iteration 18258 : loss : 0.039053, loss_ce: 0.014205
[02:10:28.516] iteration 18259 : loss : 0.065431, loss_ce: 0.014199
[02:10:28.826] iteration 18260 : loss : 0.039869, loss_ce: 0.015272
[02:10:29.152] iteration 18261 : loss : 0.111897, loss_ce: 0.005312
[02:10:29.456] iteration 18262 : loss : 0.107695, loss_ce: 0.009440
[02:10:29.765] iteration 18263 : loss : 0.054923, loss_ce: 0.009967
[02:10:30.075] iteration 18264 : loss : 0.042594, loss_ce: 0.017160
[02:10:30.385] iteration 18265 : loss : 0.097603, loss_ce: 0.011021
[02:10:30.695] iteration 18266 : loss : 0.044716, loss_ce: 0.013117
[02:10:31.004] iteration 18267 : loss : 0.042869, loss_ce: 0.017836
[02:10:31.310] iteration 18268 : loss : 0.047274, loss_ce: 0.023370
[02:10:31.617] iteration 18269 : loss : 0.038256, loss_ce: 0.013760
[02:10:31.931] iteration 18270 : loss : 0.049956, loss_ce: 0.022973
[02:10:32.244] iteration 18271 : loss : 0.043501, loss_ce: 0.006761
[02:10:32.551] iteration 18272 : loss : 0.057041, loss_ce: 0.016421
[02:10:32.858] iteration 18273 : loss : 0.042115, loss_ce: 0.014194
[02:10:33.168] iteration 18274 : loss : 0.036148, loss_ce: 0.015226
[02:10:33.478] iteration 18275 : loss : 0.042852, loss_ce: 0.015687
[02:10:33.786] iteration 18276 : loss : 0.106354, loss_ce: 0.016042
[02:10:34.098] iteration 18277 : loss : 0.042333, loss_ce: 0.013430
[02:10:34.406] iteration 18278 : loss : 0.046976, loss_ce: 0.015546
[02:10:34.712] iteration 18279 : loss : 0.107663, loss_ce: 0.009734
[02:10:35.023] iteration 18280 : loss : 0.037935, loss_ce: 0.011654
[02:10:35.348] iteration 18281 : loss : 0.036278, loss_ce: 0.012005
[02:10:35.656] iteration 18282 : loss : 0.051840, loss_ce: 0.011656
[02:10:35.965] iteration 18283 : loss : 0.041604, loss_ce: 0.007814
[02:10:36.275] iteration 18284 : loss : 0.049517, loss_ce: 0.011268
[02:10:36.585] iteration 18285 : loss : 0.054725, loss_ce: 0.018799
[02:10:36.894] iteration 18286 : loss : 0.047586, loss_ce: 0.017552
[02:10:37.202] iteration 18287 : loss : 0.048225, loss_ce: 0.015721
[02:10:37.508] iteration 18288 : loss : 0.047759, loss_ce: 0.015130
[02:10:37.817] iteration 18289 : loss : 0.102563, loss_ce: 0.009785
[02:10:38.125] iteration 18290 : loss : 0.046283, loss_ce: 0.015890
[02:10:38.435] iteration 18291 : loss : 0.047093, loss_ce: 0.012693
[02:10:38.742] iteration 18292 : loss : 0.045384, loss_ce: 0.013812
[02:10:39.053] iteration 18293 : loss : 0.044911, loss_ce: 0.015735
[02:10:39.361] iteration 18294 : loss : 0.055983, loss_ce: 0.013540
[02:10:39.671] iteration 18295 : loss : 0.079049, loss_ce: 0.013562
[02:10:39.979] iteration 18296 : loss : 0.040744, loss_ce: 0.005166
[02:10:40.288] iteration 18297 : loss : 0.045421, loss_ce: 0.012353
[02:10:40.597] iteration 18298 : loss : 0.045090, loss_ce: 0.010033
[02:10:40.905] iteration 18299 : loss : 0.098643, loss_ce: 0.006746
[02:10:41.211] iteration 18300 : loss : 0.044109, loss_ce: 0.021351
[02:10:41.540] iteration 18301 : loss : 0.044408, loss_ce: 0.006367
[02:10:41.845] iteration 18302 : loss : 0.050795, loss_ce: 0.011955
[02:10:42.154] iteration 18303 : loss : 0.113480, loss_ce: 0.008462
[02:10:42.464] iteration 18304 : loss : 0.050310, loss_ce: 0.015231
[02:10:42.772] iteration 18305 : loss : 0.037735, loss_ce: 0.007150
[02:10:43.080] iteration 18306 : loss : 0.038629, loss_ce: 0.012892
[02:10:43.385] iteration 18307 : loss : 0.066905, loss_ce: 0.013948
[02:10:43.699] iteration 18308 : loss : 0.047198, loss_ce: 0.010789
[02:10:44.004] iteration 18309 : loss : 0.039875, loss_ce: 0.013618
[02:10:44.314] iteration 18310 : loss : 0.048963, loss_ce: 0.012595
[02:10:44.620] iteration 18311 : loss : 0.041214, loss_ce: 0.013143
[02:10:44.925] iteration 18312 : loss : 0.054959, loss_ce: 0.020816
[02:10:45.231] iteration 18313 : loss : 0.045294, loss_ce: 0.014158
[02:10:45.537] iteration 18314 : loss : 0.041161, loss_ce: 0.018536
[02:10:45.841] iteration 18315 : loss : 0.054297, loss_ce: 0.006182
[02:10:46.143] iteration 18316 : loss : 0.097652, loss_ce: 0.009813
[02:10:46.447] iteration 18317 : loss : 0.151007, loss_ce: 0.006293
[02:10:46.751] iteration 18318 : loss : 0.046710, loss_ce: 0.017360
[02:10:47.055] iteration 18319 : loss : 0.105672, loss_ce: 0.004721
[02:10:47.361] iteration 18320 : loss : 0.047779, loss_ce: 0.008830
[02:10:47.676] iteration 18321 : loss : 0.046760, loss_ce: 0.010766
[02:10:47.980] iteration 18322 : loss : 0.045992, loss_ce: 0.016165
[02:10:48.287] iteration 18323 : loss : 0.033970, loss_ce: 0.008647
[02:10:48.589] iteration 18324 : loss : 0.039691, loss_ce: 0.017198
[02:10:48.894] iteration 18325 : loss : 0.041522, loss_ce: 0.013081
[02:10:49.197] iteration 18326 : loss : 0.107037, loss_ce: 0.011161
[02:10:49.501] iteration 18327 : loss : 0.041829, loss_ce: 0.014338
[02:10:49.806] iteration 18328 : loss : 0.105810, loss_ce: 0.009168
[02:10:50.111] iteration 18329 : loss : 0.031157, loss_ce: 0.012016
[02:10:50.419] iteration 18330 : loss : 0.105715, loss_ce: 0.012426
[02:10:50.725] iteration 18331 : loss : 0.055210, loss_ce: 0.019459
[02:10:51.034] iteration 18332 : loss : 0.045976, loss_ce: 0.015866
[02:10:51.346] iteration 18333 : loss : 0.060424, loss_ce: 0.017652
[02:10:51.654] iteration 18334 : loss : 0.180159, loss_ce: 0.007505
[02:10:51.966] iteration 18335 : loss : 0.069180, loss_ce: 0.020450
[02:10:52.278] iteration 18336 : loss : 0.101517, loss_ce: 0.012469
[02:10:52.586] iteration 18337 : loss : 0.034258, loss_ce: 0.008884
[02:10:52.897] iteration 18338 : loss : 0.045243, loss_ce: 0.009419
[02:10:53.207] iteration 18339 : loss : 0.052316, loss_ce: 0.016227
[02:10:53.515] iteration 18340 : loss : 0.054758, loss_ce: 0.015570
[02:10:53.870] iteration 18341 : loss : 0.171110, loss_ce: 0.010113
[02:10:54.176] iteration 18342 : loss : 0.053967, loss_ce: 0.019307
[02:10:54.486] iteration 18343 : loss : 0.039107, loss_ce: 0.011069
[02:10:54.797] iteration 18344 : loss : 0.042576, loss_ce: 0.011909
[02:10:55.105] iteration 18345 : loss : 0.046673, loss_ce: 0.014508
[02:10:55.415] iteration 18346 : loss : 0.098946, loss_ce: 0.010807
[02:10:55.725] iteration 18347 : loss : 0.077211, loss_ce: 0.014009
[02:10:55.810] iteration 18348 : loss : 0.065519, loss_ce: 0.034425
[02:11:13.138] iteration 18349 : loss : 0.043602, loss_ce: 0.014580
[02:11:13.443] iteration 18350 : loss : 0.038759, loss_ce: 0.017090
[02:11:13.755] iteration 18351 : loss : 0.040227, loss_ce: 0.013743
[02:11:14.060] iteration 18352 : loss : 0.098280, loss_ce: 0.005847
[02:11:14.368] iteration 18353 : loss : 0.044801, loss_ce: 0.015410
[02:11:14.674] iteration 18354 : loss : 0.034430, loss_ce: 0.007530
[02:11:14.977] iteration 18355 : loss : 0.103928, loss_ce: 0.011740
[02:11:15.282] iteration 18356 : loss : 0.042243, loss_ce: 0.020633
[02:11:15.582] iteration 18357 : loss : 0.059944, loss_ce: 0.012503
[02:11:15.885] iteration 18358 : loss : 0.038136, loss_ce: 0.017489
[02:11:16.189] iteration 18359 : loss : 0.058551, loss_ce: 0.007988
[02:11:16.492] iteration 18360 : loss : 0.045608, loss_ce: 0.015398
[02:11:16.819] iteration 18361 : loss : 0.115733, loss_ce: 0.007408
[02:11:17.124] iteration 18362 : loss : 0.048090, loss_ce: 0.012733
[02:11:17.429] iteration 18363 : loss : 0.038300, loss_ce: 0.012094
[02:11:17.732] iteration 18364 : loss : 0.048581, loss_ce: 0.017031
[02:11:18.033] iteration 18365 : loss : 0.098519, loss_ce: 0.018402
[02:11:18.335] iteration 18366 : loss : 0.036598, loss_ce: 0.012391
[02:11:18.640] iteration 18367 : loss : 0.047857, loss_ce: 0.017857
[02:11:18.945] iteration 18368 : loss : 0.043271, loss_ce: 0.014533
[02:11:19.249] iteration 18369 : loss : 0.108893, loss_ce: 0.010379
[02:11:19.557] iteration 18370 : loss : 0.044121, loss_ce: 0.014299
[02:11:19.863] iteration 18371 : loss : 0.045143, loss_ce: 0.006271
[02:11:20.170] iteration 18372 : loss : 0.047023, loss_ce: 0.014480
[02:11:20.472] iteration 18373 : loss : 0.036121, loss_ce: 0.014998
[02:11:20.774] iteration 18374 : loss : 0.043375, loss_ce: 0.010569
[02:11:21.079] iteration 18375 : loss : 0.046951, loss_ce: 0.011826
[02:11:21.382] iteration 18376 : loss : 0.041466, loss_ce: 0.007005
[02:11:21.684] iteration 18377 : loss : 0.098477, loss_ce: 0.005317
[02:11:21.991] iteration 18378 : loss : 0.104735, loss_ce: 0.004092
[02:11:22.298] iteration 18379 : loss : 0.045232, loss_ce: 0.010191
[02:11:22.601] iteration 18380 : loss : 0.095651, loss_ce: 0.007495
[02:11:22.915] iteration 18381 : loss : 0.047293, loss_ce: 0.024765
[02:11:23.221] iteration 18382 : loss : 0.044476, loss_ce: 0.012482
[02:11:23.527] iteration 18383 : loss : 0.101856, loss_ce: 0.015028
[02:11:23.833] iteration 18384 : loss : 0.044493, loss_ce: 0.014951
[02:11:24.137] iteration 18385 : loss : 0.040829, loss_ce: 0.016400
[02:11:24.441] iteration 18386 : loss : 0.042515, loss_ce: 0.018251
[02:11:24.746] iteration 18387 : loss : 0.040446, loss_ce: 0.012806
[02:11:25.047] iteration 18388 : loss : 0.044079, loss_ce: 0.019695
[02:11:25.355] iteration 18389 : loss : 0.082530, loss_ce: 0.017491
[02:11:25.658] iteration 18390 : loss : 0.161054, loss_ce: 0.004774
[02:11:25.966] iteration 18391 : loss : 0.036049, loss_ce: 0.011975
[02:11:26.270] iteration 18392 : loss : 0.041599, loss_ce: 0.012309
[02:11:26.571] iteration 18393 : loss : 0.041778, loss_ce: 0.016706
[02:11:26.880] iteration 18394 : loss : 0.042623, loss_ce: 0.016522
[02:11:27.182] iteration 18395 : loss : 0.038374, loss_ce: 0.005908
[02:11:27.491] iteration 18396 : loss : 0.041373, loss_ce: 0.013815
[02:11:27.802] iteration 18397 : loss : 0.096978, loss_ce: 0.015306
[02:11:28.108] iteration 18398 : loss : 0.033477, loss_ce: 0.008250
[02:11:28.420] iteration 18399 : loss : 0.038304, loss_ce: 0.007949
[02:11:28.729] iteration 18400 : loss : 0.046758, loss_ce: 0.010466
[02:11:29.055] iteration 18401 : loss : 0.043213, loss_ce: 0.009531
[02:11:29.356] iteration 18402 : loss : 0.046818, loss_ce: 0.017522
[02:11:29.659] iteration 18403 : loss : 0.049560, loss_ce: 0.015053
[02:11:29.963] iteration 18404 : loss : 0.049300, loss_ce: 0.012104
[02:11:30.270] iteration 18405 : loss : 0.050626, loss_ce: 0.011719
[02:11:30.572] iteration 18406 : loss : 0.279122, loss_ce: 0.005386
[02:11:30.879] iteration 18407 : loss : 0.068526, loss_ce: 0.020485
[02:11:31.182] iteration 18408 : loss : 0.040280, loss_ce: 0.010899
[02:11:31.487] iteration 18409 : loss : 0.036955, loss_ce: 0.012256
[02:11:31.791] iteration 18410 : loss : 0.037269, loss_ce: 0.012395
[02:11:32.100] iteration 18411 : loss : 0.040008, loss_ce: 0.012295
[02:11:32.406] iteration 18412 : loss : 0.045304, loss_ce: 0.009925
[02:11:32.712] iteration 18413 : loss : 0.098918, loss_ce: 0.013555
[02:11:33.016] iteration 18414 : loss : 0.043197, loss_ce: 0.015588
[02:11:33.321] iteration 18415 : loss : 0.043098, loss_ce: 0.010585
[02:11:33.626] iteration 18416 : loss : 0.039452, loss_ce: 0.012838
[02:11:33.930] iteration 18417 : loss : 0.105734, loss_ce: 0.011360
[02:11:34.239] iteration 18418 : loss : 0.049386, loss_ce: 0.018272
[02:11:34.542] iteration 18419 : loss : 0.284718, loss_ce: 0.008144
[02:11:34.847] iteration 18420 : loss : 0.053421, loss_ce: 0.016569
[02:11:35.169] iteration 18421 : loss : 0.047313, loss_ce: 0.013621
[02:11:35.471] iteration 18422 : loss : 0.102320, loss_ce: 0.011475
[02:11:35.777] iteration 18423 : loss : 0.047358, loss_ce: 0.012820
[02:11:36.081] iteration 18424 : loss : 0.050944, loss_ce: 0.011074
[02:11:36.385] iteration 18425 : loss : 0.040745, loss_ce: 0.008865
[02:11:36.690] iteration 18426 : loss : 0.052803, loss_ce: 0.020158
[02:11:36.992] iteration 18427 : loss : 0.045857, loss_ce: 0.015183
[02:11:37.296] iteration 18428 : loss : 0.041361, loss_ce: 0.010937
[02:11:37.600] iteration 18429 : loss : 0.051458, loss_ce: 0.014193
[02:11:37.901] iteration 18430 : loss : 0.170386, loss_ce: 0.013777
[02:11:38.204] iteration 18431 : loss : 0.036593, loss_ce: 0.007623
[02:11:38.508] iteration 18432 : loss : 0.036693, loss_ce: 0.009006
[02:11:38.811] iteration 18433 : loss : 0.041026, loss_ce: 0.007333
[02:11:39.118] iteration 18434 : loss : 0.098827, loss_ce: 0.012998
[02:11:39.426] iteration 18435 : loss : 0.048053, loss_ce: 0.009552
[02:11:39.727] iteration 18436 : loss : 0.040256, loss_ce: 0.011117
[02:11:40.029] iteration 18437 : loss : 0.041825, loss_ce: 0.016705
[02:11:40.336] iteration 18438 : loss : 0.051148, loss_ce: 0.007988
[02:11:40.640] iteration 18439 : loss : 0.046754, loss_ce: 0.011734
[02:11:40.947] iteration 18440 : loss : 0.102666, loss_ce: 0.013111
[02:11:41.268] iteration 18441 : loss : 0.067251, loss_ce: 0.013683
[02:11:41.570] iteration 18442 : loss : 0.045190, loss_ce: 0.016545
[02:11:41.873] iteration 18443 : loss : 0.287739, loss_ce: 0.007368
[02:11:42.175] iteration 18444 : loss : 0.050060, loss_ce: 0.019952
[02:11:42.475] iteration 18445 : loss : 0.048897, loss_ce: 0.016137
[02:11:42.782] iteration 18446 : loss : 0.038548, loss_ce: 0.009611
[02:11:43.088] iteration 18447 : loss : 0.037138, loss_ce: 0.014679
[02:11:43.393] iteration 18448 : loss : 0.034781, loss_ce: 0.010486
[02:11:43.704] iteration 18449 : loss : 0.050118, loss_ce: 0.014558
[02:11:44.009] iteration 18450 : loss : 0.047642, loss_ce: 0.012778
[02:11:44.318] iteration 18451 : loss : 0.040319, loss_ce: 0.013598
[02:11:44.625] iteration 18452 : loss : 0.039047, loss_ce: 0.014153
[02:11:44.929] iteration 18453 : loss : 0.099670, loss_ce: 0.010417
[02:11:45.237] iteration 18454 : loss : 0.042551, loss_ce: 0.015246
[02:11:45.547] iteration 18455 : loss : 0.039808, loss_ce: 0.010016
[02:11:45.853] iteration 18456 : loss : 0.041592, loss_ce: 0.016102
[02:11:46.160] iteration 18457 : loss : 0.054138, loss_ce: 0.016273
[02:11:46.468] iteration 18458 : loss : 0.031303, loss_ce: 0.009970
[02:11:46.779] iteration 18459 : loss : 0.039988, loss_ce: 0.013414
[02:11:47.086] iteration 18460 : loss : 0.046736, loss_ce: 0.017487
[02:11:47.412] iteration 18461 : loss : 0.099597, loss_ce: 0.006892
[02:11:47.722] iteration 18462 : loss : 0.040906, loss_ce: 0.019228
[02:11:48.031] iteration 18463 : loss : 0.042989, loss_ce: 0.014645
[02:11:48.336] iteration 18464 : loss : 0.041637, loss_ce: 0.014933
[02:11:48.649] iteration 18465 : loss : 0.108937, loss_ce: 0.010891
[02:11:48.954] iteration 18466 : loss : 0.220909, loss_ce: 0.008089
[02:11:49.262] iteration 18467 : loss : 0.059216, loss_ce: 0.010262
[02:11:49.572] iteration 18468 : loss : 0.064249, loss_ce: 0.012414
[02:11:49.874] iteration 18469 : loss : 0.039860, loss_ce: 0.014126
[02:11:50.181] iteration 18470 : loss : 0.062935, loss_ce: 0.018668
[02:11:50.496] iteration 18471 : loss : 0.043399, loss_ce: 0.012636
[02:11:50.805] iteration 18472 : loss : 0.062062, loss_ce: 0.015369
[02:11:51.113] iteration 18473 : loss : 0.045428, loss_ce: 0.006386
[02:11:51.431] iteration 18474 : loss : 0.063733, loss_ce: 0.024228
[02:11:51.742] iteration 18475 : loss : 0.112731, loss_ce: 0.016175
[02:11:52.058] iteration 18476 : loss : 0.038751, loss_ce: 0.010714
[02:11:52.370] iteration 18477 : loss : 0.056886, loss_ce: 0.016427
[02:11:52.683] iteration 18478 : loss : 0.047008, loss_ce: 0.012161
[02:11:52.993] iteration 18479 : loss : 0.043235, loss_ce: 0.016178
[02:11:53.306] iteration 18480 : loss : 0.072821, loss_ce: 0.013569
[02:11:53.654] iteration 18481 : loss : 0.058908, loss_ce: 0.028427
[02:11:53.964] iteration 18482 : loss : 0.044222, loss_ce: 0.017784
[02:11:54.275] iteration 18483 : loss : 0.052242, loss_ce: 0.014282
[02:11:54.588] iteration 18484 : loss : 0.057158, loss_ce: 0.013471
[02:11:54.906] iteration 18485 : loss : 0.039310, loss_ce: 0.014333
[02:11:55.217] iteration 18486 : loss : 0.041848, loss_ce: 0.018676
[02:11:55.294] iteration 18487 : loss : 0.058691, loss_ce: 0.017122
[02:12:12.849] iteration 18488 : loss : 0.116987, loss_ce: 0.014011
[02:12:13.147] iteration 18489 : loss : 0.045737, loss_ce: 0.011951
[02:12:13.446] iteration 18490 : loss : 0.092493, loss_ce: 0.010482
[02:12:13.744] iteration 18491 : loss : 0.103856, loss_ce: 0.006668
[02:12:14.047] iteration 18492 : loss : 0.059688, loss_ce: 0.027826
[02:12:14.354] iteration 18493 : loss : 0.098087, loss_ce: 0.014004
[02:12:14.654] iteration 18494 : loss : 0.052575, loss_ce: 0.024154
[02:12:14.957] iteration 18495 : loss : 0.098480, loss_ce: 0.011738
[02:12:15.261] iteration 18496 : loss : 0.052309, loss_ce: 0.005722
[02:12:15.562] iteration 18497 : loss : 0.039777, loss_ce: 0.012592
[02:12:15.863] iteration 18498 : loss : 0.041504, loss_ce: 0.011857
[02:12:16.164] iteration 18499 : loss : 0.049030, loss_ce: 0.019279
[02:12:16.465] iteration 18500 : loss : 0.044436, loss_ce: 0.015447
[02:12:16.788] iteration 18501 : loss : 0.047025, loss_ce: 0.011080
[02:12:17.091] iteration 18502 : loss : 0.048829, loss_ce: 0.019365
[02:12:17.399] iteration 18503 : loss : 0.064919, loss_ce: 0.017579
[02:12:17.708] iteration 18504 : loss : 0.040342, loss_ce: 0.016925
[02:12:18.016] iteration 18505 : loss : 0.035661, loss_ce: 0.007583
[02:12:18.322] iteration 18506 : loss : 0.168174, loss_ce: 0.004820
[02:12:18.629] iteration 18507 : loss : 0.042850, loss_ce: 0.020503
[02:12:18.937] iteration 18508 : loss : 0.042616, loss_ce: 0.015673
[02:12:19.244] iteration 18509 : loss : 0.036914, loss_ce: 0.014136
[02:12:19.549] iteration 18510 : loss : 0.099755, loss_ce: 0.007185
[02:12:19.849] iteration 18511 : loss : 0.048395, loss_ce: 0.019635
[02:12:20.150] iteration 18512 : loss : 0.040930, loss_ce: 0.013301
[02:12:20.453] iteration 18513 : loss : 0.055088, loss_ce: 0.015020
[02:12:20.756] iteration 18514 : loss : 0.116720, loss_ce: 0.012970
[02:12:21.059] iteration 18515 : loss : 0.105459, loss_ce: 0.010566
[02:12:21.360] iteration 18516 : loss : 0.044925, loss_ce: 0.014325
[02:12:21.666] iteration 18517 : loss : 0.035916, loss_ce: 0.009313
[02:12:21.966] iteration 18518 : loss : 0.061507, loss_ce: 0.010515
[02:12:22.269] iteration 18519 : loss : 0.047059, loss_ce: 0.011274
[02:12:22.574] iteration 18520 : loss : 0.040812, loss_ce: 0.016257
[02:12:22.888] iteration 18521 : loss : 0.168196, loss_ce: 0.010162
[02:12:23.191] iteration 18522 : loss : 0.043677, loss_ce: 0.004796
[02:12:23.494] iteration 18523 : loss : 0.044599, loss_ce: 0.017984
[02:12:23.797] iteration 18524 : loss : 0.031902, loss_ce: 0.010253
[02:12:24.101] iteration 18525 : loss : 0.043709, loss_ce: 0.014601
[02:12:24.401] iteration 18526 : loss : 0.164975, loss_ce: 0.006927
[02:12:24.704] iteration 18527 : loss : 0.044068, loss_ce: 0.014857
[02:12:25.007] iteration 18528 : loss : 0.063635, loss_ce: 0.009102
[02:12:25.311] iteration 18529 : loss : 0.040490, loss_ce: 0.016136
[02:12:25.616] iteration 18530 : loss : 0.091372, loss_ce: 0.005425
[02:12:25.919] iteration 18531 : loss : 0.037894, loss_ce: 0.006561
[02:12:26.221] iteration 18532 : loss : 0.220185, loss_ce: 0.007925
[02:12:26.522] iteration 18533 : loss : 0.037173, loss_ce: 0.010659
[02:12:26.829] iteration 18534 : loss : 0.059585, loss_ce: 0.018577
[02:12:27.136] iteration 18535 : loss : 0.031233, loss_ce: 0.006231
[02:12:27.437] iteration 18536 : loss : 0.280873, loss_ce: 0.010332
[02:12:27.740] iteration 18537 : loss : 0.067826, loss_ce: 0.019019
[02:12:28.042] iteration 18538 : loss : 0.044593, loss_ce: 0.011134
[02:12:28.344] iteration 18539 : loss : 0.045098, loss_ce: 0.011444
[02:12:28.647] iteration 18540 : loss : 0.049763, loss_ce: 0.019291
[02:12:28.967] iteration 18541 : loss : 0.046800, loss_ce: 0.014805
[02:12:29.270] iteration 18542 : loss : 0.057863, loss_ce: 0.010752
[02:12:29.570] iteration 18543 : loss : 0.111483, loss_ce: 0.011288
[02:12:29.875] iteration 18544 : loss : 0.042315, loss_ce: 0.012067
[02:12:30.176] iteration 18545 : loss : 0.407501, loss_ce: 0.002900
[02:12:30.478] iteration 18546 : loss : 0.046680, loss_ce: 0.013036
[02:12:30.780] iteration 18547 : loss : 0.047015, loss_ce: 0.019264
[02:12:31.080] iteration 18548 : loss : 0.044068, loss_ce: 0.013291
[02:12:31.383] iteration 18549 : loss : 0.093960, loss_ce: 0.007077
[02:12:31.688] iteration 18550 : loss : 0.048998, loss_ce: 0.017713
[02:12:31.989] iteration 18551 : loss : 0.095395, loss_ce: 0.006397
[02:12:32.295] iteration 18552 : loss : 0.039717, loss_ce: 0.018436
[02:12:32.600] iteration 18553 : loss : 0.049172, loss_ce: 0.013085
[02:12:32.909] iteration 18554 : loss : 0.046589, loss_ce: 0.019820
[02:12:33.216] iteration 18555 : loss : 0.042375, loss_ce: 0.009612
[02:12:33.525] iteration 18556 : loss : 0.051280, loss_ce: 0.016705
[02:12:33.834] iteration 18557 : loss : 0.096154, loss_ce: 0.008215
[02:12:34.141] iteration 18558 : loss : 0.040496, loss_ce: 0.018924
[02:12:34.444] iteration 18559 : loss : 0.040073, loss_ce: 0.012515
[02:12:34.764] iteration 18560 : loss : 0.039421, loss_ce: 0.016853
[02:12:35.086] iteration 18561 : loss : 0.052679, loss_ce: 0.012346
[02:12:35.387] iteration 18562 : loss : 0.052776, loss_ce: 0.012837
[02:12:35.693] iteration 18563 : loss : 0.041472, loss_ce: 0.013011
[02:12:35.996] iteration 18564 : loss : 0.098932, loss_ce: 0.013351
[02:12:36.296] iteration 18565 : loss : 0.094641, loss_ce: 0.007603
[02:12:36.600] iteration 18566 : loss : 0.096163, loss_ce: 0.004351
[02:12:36.902] iteration 18567 : loss : 0.187244, loss_ce: 0.008638
[02:12:37.203] iteration 18568 : loss : 0.046024, loss_ce: 0.013038
[02:12:37.506] iteration 18569 : loss : 0.282476, loss_ce: 0.007358
[02:12:37.808] iteration 18570 : loss : 0.047912, loss_ce: 0.024272
[02:12:38.111] iteration 18571 : loss : 0.038972, loss_ce: 0.016767
[02:12:38.418] iteration 18572 : loss : 0.052582, loss_ce: 0.014192
[02:12:38.722] iteration 18573 : loss : 0.041906, loss_ce: 0.014902
[02:12:39.027] iteration 18574 : loss : 0.051497, loss_ce: 0.012337
[02:12:39.332] iteration 18575 : loss : 0.094453, loss_ce: 0.007002
[02:12:39.634] iteration 18576 : loss : 0.053312, loss_ce: 0.018177
[02:12:39.935] iteration 18577 : loss : 0.097516, loss_ce: 0.005893
[02:12:40.239] iteration 18578 : loss : 0.057040, loss_ce: 0.026709
[02:12:40.544] iteration 18579 : loss : 0.102102, loss_ce: 0.008624
[02:12:40.847] iteration 18580 : loss : 0.048453, loss_ce: 0.017560
[02:12:41.174] iteration 18581 : loss : 0.060721, loss_ce: 0.022265
[02:12:41.475] iteration 18582 : loss : 0.046508, loss_ce: 0.016960
[02:12:41.782] iteration 18583 : loss : 0.039303, loss_ce: 0.011346
[02:12:42.086] iteration 18584 : loss : 0.048907, loss_ce: 0.008812
[02:12:42.386] iteration 18585 : loss : 0.040462, loss_ce: 0.011772
[02:12:42.690] iteration 18586 : loss : 0.165805, loss_ce: 0.006952
[02:12:42.993] iteration 18587 : loss : 0.039430, loss_ce: 0.014548
[02:12:43.293] iteration 18588 : loss : 0.052908, loss_ce: 0.021208
[02:12:43.596] iteration 18589 : loss : 0.036218, loss_ce: 0.013804
[02:12:43.904] iteration 18590 : loss : 0.046315, loss_ce: 0.018685
[02:12:44.208] iteration 18591 : loss : 0.049415, loss_ce: 0.017369
[02:12:44.512] iteration 18592 : loss : 0.065039, loss_ce: 0.030604
[02:12:44.815] iteration 18593 : loss : 0.034006, loss_ce: 0.008392
[02:12:45.119] iteration 18594 : loss : 0.040361, loss_ce: 0.011109
[02:12:45.420] iteration 18595 : loss : 0.057633, loss_ce: 0.009690
[02:12:45.721] iteration 18596 : loss : 0.047317, loss_ce: 0.014272
[02:12:46.023] iteration 18597 : loss : 0.055117, loss_ce: 0.015022
[02:12:46.330] iteration 18598 : loss : 0.048333, loss_ce: 0.015057
[02:12:46.633] iteration 18599 : loss : 0.098502, loss_ce: 0.007991
[02:12:46.939] iteration 18600 : loss : 0.053669, loss_ce: 0.013462
[02:12:47.257] iteration 18601 : loss : 0.097756, loss_ce: 0.005349
[02:12:47.563] iteration 18602 : loss : 0.029760, loss_ce: 0.008399
[02:12:47.869] iteration 18603 : loss : 0.039391, loss_ce: 0.016039
[02:12:48.173] iteration 18604 : loss : 0.036118, loss_ce: 0.011800
[02:12:48.477] iteration 18605 : loss : 0.045504, loss_ce: 0.010736
[02:12:48.782] iteration 18606 : loss : 0.044084, loss_ce: 0.019165
[02:12:49.086] iteration 18607 : loss : 0.038802, loss_ce: 0.011241
[02:12:49.392] iteration 18608 : loss : 0.032725, loss_ce: 0.010951
[02:12:49.697] iteration 18609 : loss : 0.085431, loss_ce: 0.011332
[02:12:50.005] iteration 18610 : loss : 0.098735, loss_ce: 0.006843
[02:12:50.316] iteration 18611 : loss : 0.110373, loss_ce: 0.002982
[02:12:50.626] iteration 18612 : loss : 0.057493, loss_ce: 0.017177
[02:12:50.939] iteration 18613 : loss : 0.044687, loss_ce: 0.022063
[02:12:51.252] iteration 18614 : loss : 0.053754, loss_ce: 0.020448
[02:12:51.570] iteration 18615 : loss : 0.044510, loss_ce: 0.010000
[02:12:51.882] iteration 18616 : loss : 0.046943, loss_ce: 0.013369
[02:12:52.195] iteration 18617 : loss : 0.038601, loss_ce: 0.015422
[02:12:52.514] iteration 18618 : loss : 0.050485, loss_ce: 0.013734
[02:12:52.830] iteration 18619 : loss : 0.044229, loss_ce: 0.011817
[02:12:53.143] iteration 18620 : loss : 0.044888, loss_ce: 0.008296
[02:12:53.474] iteration 18621 : loss : 0.046618, loss_ce: 0.016938
[02:12:53.787] iteration 18622 : loss : 0.044533, loss_ce: 0.016436
[02:12:54.103] iteration 18623 : loss : 0.047251, loss_ce: 0.014266
[02:12:54.413] iteration 18624 : loss : 0.046298, loss_ce: 0.019114
[02:12:54.725] iteration 18625 : loss : 0.037522, loss_ce: 0.010344
[02:12:54.810] iteration 18626 : loss : 0.344521, loss_ce: 0.000641
[02:13:12.665] iteration 18627 : loss : 0.044410, loss_ce: 0.017264
[02:13:12.963] iteration 18628 : loss : 0.043564, loss_ce: 0.007040
[02:13:13.264] iteration 18629 : loss : 0.106503, loss_ce: 0.012532
[02:13:13.562] iteration 18630 : loss : 0.043207, loss_ce: 0.007631
[02:13:13.862] iteration 18631 : loss : 0.101176, loss_ce: 0.012342
[02:13:14.162] iteration 18632 : loss : 0.053937, loss_ce: 0.020440
[02:13:14.462] iteration 18633 : loss : 0.049817, loss_ce: 0.014343
[02:13:14.763] iteration 18634 : loss : 0.043894, loss_ce: 0.011623
[02:13:15.068] iteration 18635 : loss : 0.050959, loss_ce: 0.011675
[02:13:15.368] iteration 18636 : loss : 0.039181, loss_ce: 0.014026
[02:13:15.670] iteration 18637 : loss : 0.052422, loss_ce: 0.015808
[02:13:15.975] iteration 18638 : loss : 0.041793, loss_ce: 0.013148
[02:13:16.278] iteration 18639 : loss : 0.031478, loss_ce: 0.012233
[02:13:16.586] iteration 18640 : loss : 0.103794, loss_ce: 0.008514
[02:13:16.903] iteration 18641 : loss : 0.060879, loss_ce: 0.020420
[02:13:17.206] iteration 18642 : loss : 0.045591, loss_ce: 0.005967
[02:13:17.508] iteration 18643 : loss : 0.104884, loss_ce: 0.007558
[02:13:17.812] iteration 18644 : loss : 0.042373, loss_ce: 0.010817
[02:13:18.117] iteration 18645 : loss : 0.049564, loss_ce: 0.009139
[02:13:18.420] iteration 18646 : loss : 0.052322, loss_ce: 0.023808
[02:13:18.722] iteration 18647 : loss : 0.042004, loss_ce: 0.019762
[02:13:19.026] iteration 18648 : loss : 0.048287, loss_ce: 0.007184
[02:13:19.330] iteration 18649 : loss : 0.045396, loss_ce: 0.008780
[02:13:19.638] iteration 18650 : loss : 0.050498, loss_ce: 0.018526
[02:13:19.942] iteration 18651 : loss : 0.037666, loss_ce: 0.010844
[02:13:20.245] iteration 18652 : loss : 0.052625, loss_ce: 0.017438
[02:13:20.546] iteration 18653 : loss : 0.049544, loss_ce: 0.011453
[02:13:20.847] iteration 18654 : loss : 0.045957, loss_ce: 0.012181
[02:13:21.150] iteration 18655 : loss : 0.046138, loss_ce: 0.007639
[02:13:21.452] iteration 18656 : loss : 0.040312, loss_ce: 0.023496
[02:13:21.753] iteration 18657 : loss : 0.043885, loss_ce: 0.015978
[02:13:22.053] iteration 18658 : loss : 0.034239, loss_ce: 0.009166
[02:13:22.360] iteration 18659 : loss : 0.064076, loss_ce: 0.020296
[02:13:22.666] iteration 18660 : loss : 0.038746, loss_ce: 0.014113
[02:13:22.993] iteration 18661 : loss : 0.098908, loss_ce: 0.009972
[02:13:23.296] iteration 18662 : loss : 0.118784, loss_ce: 0.008608
[02:13:23.611] iteration 18663 : loss : 0.038915, loss_ce: 0.012140
[02:13:23.922] iteration 18664 : loss : 0.040606, loss_ce: 0.010389
[02:13:24.228] iteration 18665 : loss : 0.041083, loss_ce: 0.015402
[02:13:24.533] iteration 18666 : loss : 0.037629, loss_ce: 0.004631
[02:13:24.837] iteration 18667 : loss : 0.053564, loss_ce: 0.009998
[02:13:25.139] iteration 18668 : loss : 0.046488, loss_ce: 0.014962
[02:13:25.441] iteration 18669 : loss : 0.054984, loss_ce: 0.024557
[02:13:25.742] iteration 18670 : loss : 0.045882, loss_ce: 0.009015
[02:13:26.042] iteration 18671 : loss : 0.038491, loss_ce: 0.006307
[02:13:26.346] iteration 18672 : loss : 0.046881, loss_ce: 0.017509
[02:13:26.654] iteration 18673 : loss : 0.101258, loss_ce: 0.005973
[02:13:26.958] iteration 18674 : loss : 0.050352, loss_ce: 0.016686
[02:13:27.261] iteration 18675 : loss : 0.070332, loss_ce: 0.008875
[02:13:27.565] iteration 18676 : loss : 0.051102, loss_ce: 0.012012
[02:13:27.874] iteration 18677 : loss : 0.036184, loss_ce: 0.015800
[02:13:28.175] iteration 18678 : loss : 0.044308, loss_ce: 0.010869
[02:13:28.478] iteration 18679 : loss : 0.040495, loss_ce: 0.017271
[02:13:28.781] iteration 18680 : loss : 0.054784, loss_ce: 0.024019
[02:13:29.100] iteration 18681 : loss : 0.040814, loss_ce: 0.013313
[02:13:29.398] iteration 18682 : loss : 0.062990, loss_ce: 0.017583
[02:13:29.701] iteration 18683 : loss : 0.103862, loss_ce: 0.013995
[02:13:30.004] iteration 18684 : loss : 0.052490, loss_ce: 0.015828
[02:13:30.303] iteration 18685 : loss : 0.099302, loss_ce: 0.009672
[02:13:30.605] iteration 18686 : loss : 0.161460, loss_ce: 0.011022
[02:13:30.909] iteration 18687 : loss : 0.043549, loss_ce: 0.015065
[02:13:31.212] iteration 18688 : loss : 0.040586, loss_ce: 0.020890
[02:13:31.514] iteration 18689 : loss : 0.109249, loss_ce: 0.013854
[02:13:31.815] iteration 18690 : loss : 0.098584, loss_ce: 0.013661
[02:13:32.115] iteration 18691 : loss : 0.037132, loss_ce: 0.010932
[02:13:32.415] iteration 18692 : loss : 0.046233, loss_ce: 0.013531
[02:13:32.721] iteration 18693 : loss : 0.172609, loss_ce: 0.010064
[02:13:33.026] iteration 18694 : loss : 0.055454, loss_ce: 0.014285
[02:13:33.331] iteration 18695 : loss : 0.049620, loss_ce: 0.007922
[02:13:33.632] iteration 18696 : loss : 0.047384, loss_ce: 0.005128
[02:13:33.935] iteration 18697 : loss : 0.064404, loss_ce: 0.006610
[02:13:34.239] iteration 18698 : loss : 0.063367, loss_ce: 0.015902
[02:13:34.543] iteration 18699 : loss : 0.040233, loss_ce: 0.013395
[02:13:34.849] iteration 18700 : loss : 0.095979, loss_ce: 0.008279
[02:13:35.168] iteration 18701 : loss : 0.048012, loss_ce: 0.012958
[02:13:35.474] iteration 18702 : loss : 0.056243, loss_ce: 0.021936
[02:13:35.778] iteration 18703 : loss : 0.100973, loss_ce: 0.012471
[02:13:36.082] iteration 18704 : loss : 0.052857, loss_ce: 0.016779
[02:13:36.384] iteration 18705 : loss : 0.102275, loss_ce: 0.014684
[02:13:36.689] iteration 18706 : loss : 0.054604, loss_ce: 0.018008
[02:13:36.993] iteration 18707 : loss : 0.042727, loss_ce: 0.009556
[02:13:37.296] iteration 18708 : loss : 0.045083, loss_ce: 0.014798
[02:13:37.608] iteration 18709 : loss : 0.035462, loss_ce: 0.010696
[02:13:37.918] iteration 18710 : loss : 0.063436, loss_ce: 0.027529
[02:13:38.226] iteration 18711 : loss : 0.039319, loss_ce: 0.007761
[02:13:38.534] iteration 18712 : loss : 0.104625, loss_ce: 0.016014
[02:13:38.846] iteration 18713 : loss : 0.043218, loss_ce: 0.011743
[02:13:39.161] iteration 18714 : loss : 0.050760, loss_ce: 0.009571
[02:13:39.465] iteration 18715 : loss : 0.045081, loss_ce: 0.018099
[02:13:39.770] iteration 18716 : loss : 0.039122, loss_ce: 0.006582
[02:13:40.074] iteration 18717 : loss : 0.049404, loss_ce: 0.009080
[02:13:40.378] iteration 18718 : loss : 0.044987, loss_ce: 0.009071
[02:13:40.683] iteration 18719 : loss : 0.057052, loss_ce: 0.022763
[02:13:40.986] iteration 18720 : loss : 0.036116, loss_ce: 0.009510
[02:13:41.309] iteration 18721 : loss : 0.047466, loss_ce: 0.022037
[02:13:41.610] iteration 18722 : loss : 0.057029, loss_ce: 0.016369
[02:13:41.917] iteration 18723 : loss : 0.059519, loss_ce: 0.022988
[02:13:42.223] iteration 18724 : loss : 0.039011, loss_ce: 0.013001
[02:13:42.528] iteration 18725 : loss : 0.043936, loss_ce: 0.014424
[02:13:42.833] iteration 18726 : loss : 0.038758, loss_ce: 0.017363
[02:13:43.138] iteration 18727 : loss : 0.101769, loss_ce: 0.013044
[02:13:43.442] iteration 18728 : loss : 0.216515, loss_ce: 0.003213
[02:13:43.744] iteration 18729 : loss : 0.051416, loss_ce: 0.015771
[02:13:44.051] iteration 18730 : loss : 0.060509, loss_ce: 0.024641
[02:13:44.355] iteration 18731 : loss : 0.108902, loss_ce: 0.010428
[02:13:44.659] iteration 18732 : loss : 0.041173, loss_ce: 0.013922
[02:13:44.962] iteration 18733 : loss : 0.038495, loss_ce: 0.007631
[02:13:45.264] iteration 18734 : loss : 0.044377, loss_ce: 0.016408
[02:13:45.568] iteration 18735 : loss : 0.040337, loss_ce: 0.008389
[02:13:45.871] iteration 18736 : loss : 0.042874, loss_ce: 0.011802
[02:13:46.175] iteration 18737 : loss : 0.045631, loss_ce: 0.009860
[02:13:46.479] iteration 18738 : loss : 0.037727, loss_ce: 0.013427
[02:13:46.783] iteration 18739 : loss : 0.048622, loss_ce: 0.018024
[02:13:47.090] iteration 18740 : loss : 0.033905, loss_ce: 0.009168
[02:13:47.411] iteration 18741 : loss : 0.109580, loss_ce: 0.007901
[02:13:47.712] iteration 18742 : loss : 0.040489, loss_ce: 0.019173
[02:13:48.016] iteration 18743 : loss : 0.035334, loss_ce: 0.015481
[02:13:48.320] iteration 18744 : loss : 0.043095, loss_ce: 0.011061
[02:13:48.620] iteration 18745 : loss : 0.053351, loss_ce: 0.014761
[02:13:48.926] iteration 18746 : loss : 0.063160, loss_ce: 0.013918
[02:13:49.229] iteration 18747 : loss : 0.046183, loss_ce: 0.018302
[02:13:49.532] iteration 18748 : loss : 0.052849, loss_ce: 0.009334
[02:13:49.835] iteration 18749 : loss : 0.049025, loss_ce: 0.015564
[02:13:50.139] iteration 18750 : loss : 0.029903, loss_ce: 0.010529
[02:13:50.441] iteration 18751 : loss : 0.057734, loss_ce: 0.022499
[02:13:50.748] iteration 18752 : loss : 0.043803, loss_ce: 0.017630
[02:13:51.054] iteration 18753 : loss : 0.055141, loss_ce: 0.014980
[02:13:51.364] iteration 18754 : loss : 0.042558, loss_ce: 0.018342
[02:13:51.673] iteration 18755 : loss : 0.056247, loss_ce: 0.009051
[02:13:51.981] iteration 18756 : loss : 0.038419, loss_ce: 0.012271
[02:13:52.288] iteration 18757 : loss : 0.039445, loss_ce: 0.013311
[02:13:52.607] iteration 18758 : loss : 0.103945, loss_ce: 0.013286
[02:13:52.918] iteration 18759 : loss : 0.036814, loss_ce: 0.008171
[02:13:53.229] iteration 18760 : loss : 0.038970, loss_ce: 0.013297
[02:13:53.561] iteration 18761 : loss : 0.067755, loss_ce: 0.005691
[02:13:53.872] iteration 18762 : loss : 0.052396, loss_ce: 0.012549
[02:13:54.181] iteration 18763 : loss : 0.037530, loss_ce: 0.013132
[02:13:54.488] iteration 18764 : loss : 0.039676, loss_ce: 0.010710
[02:13:54.570] iteration 18765 : loss : 0.259820, loss_ce: 0.001459
[02:14:14.029] iteration 18766 : loss : 0.044384, loss_ce: 0.011514
[02:14:14.332] iteration 18767 : loss : 0.046172, loss_ce: 0.006493
[02:14:14.637] iteration 18768 : loss : 0.041370, loss_ce: 0.015362
[02:14:14.943] iteration 18769 : loss : 0.034142, loss_ce: 0.011673
[02:14:15.251] iteration 18770 : loss : 0.100837, loss_ce: 0.014986
[02:14:15.555] iteration 18771 : loss : 0.089025, loss_ce: 0.010392
[02:14:15.861] iteration 18772 : loss : 0.053824, loss_ce: 0.018915
[02:14:16.169] iteration 18773 : loss : 0.052387, loss_ce: 0.014215
[02:14:16.475] iteration 18774 : loss : 0.109519, loss_ce: 0.010924
[02:14:16.781] iteration 18775 : loss : 0.053465, loss_ce: 0.011574
[02:14:17.085] iteration 18776 : loss : 0.045882, loss_ce: 0.020443
[02:14:17.388] iteration 18777 : loss : 0.070148, loss_ce: 0.012986
[02:14:17.696] iteration 18778 : loss : 0.120481, loss_ce: 0.025339
[02:14:18.005] iteration 18779 : loss : 0.055326, loss_ce: 0.017012
[02:14:18.308] iteration 18780 : loss : 0.104729, loss_ce: 0.013085
[02:14:18.632] iteration 18781 : loss : 0.110506, loss_ce: 0.014786
[02:14:18.938] iteration 18782 : loss : 0.058439, loss_ce: 0.015253
[02:14:19.246] iteration 18783 : loss : 0.048031, loss_ce: 0.020566
[02:14:19.555] iteration 18784 : loss : 0.043968, loss_ce: 0.014435
[02:14:19.861] iteration 18785 : loss : 0.038432, loss_ce: 0.015474
[02:14:20.167] iteration 18786 : loss : 0.049567, loss_ce: 0.019052
[02:14:20.471] iteration 18787 : loss : 0.112521, loss_ce: 0.015380
[02:14:20.779] iteration 18788 : loss : 0.104988, loss_ce: 0.010075
[02:14:21.084] iteration 18789 : loss : 0.049991, loss_ce: 0.016349
[02:14:21.388] iteration 18790 : loss : 0.070989, loss_ce: 0.016361
[02:14:21.696] iteration 18791 : loss : 0.050466, loss_ce: 0.018901
[02:14:22.004] iteration 18792 : loss : 0.054464, loss_ce: 0.017449
[02:14:22.308] iteration 18793 : loss : 0.052897, loss_ce: 0.016049
[02:14:22.617] iteration 18794 : loss : 0.053561, loss_ce: 0.016210
[02:14:22.921] iteration 18795 : loss : 0.073700, loss_ce: 0.008798
[02:14:23.225] iteration 18796 : loss : 0.042874, loss_ce: 0.013807
[02:14:23.533] iteration 18797 : loss : 0.043619, loss_ce: 0.015383
[02:14:23.843] iteration 18798 : loss : 0.041251, loss_ce: 0.015256
[02:14:24.151] iteration 18799 : loss : 0.042224, loss_ce: 0.011375
[02:14:24.456] iteration 18800 : loss : 0.049749, loss_ce: 0.022082
[02:14:24.780] iteration 18801 : loss : 0.283159, loss_ce: 0.006450
[02:14:25.086] iteration 18802 : loss : 0.051654, loss_ce: 0.009553
[02:14:25.393] iteration 18803 : loss : 0.052670, loss_ce: 0.015675
[02:14:25.701] iteration 18804 : loss : 0.152817, loss_ce: 0.007574
[02:14:26.006] iteration 18805 : loss : 0.055599, loss_ce: 0.021181
[02:14:26.320] iteration 18806 : loss : 0.049713, loss_ce: 0.014396
[02:14:26.626] iteration 18807 : loss : 0.076387, loss_ce: 0.015808
[02:14:26.934] iteration 18808 : loss : 0.043637, loss_ce: 0.018181
[02:14:27.245] iteration 18809 : loss : 0.102692, loss_ce: 0.006182
[02:14:27.556] iteration 18810 : loss : 0.045561, loss_ce: 0.014420
[02:14:27.868] iteration 18811 : loss : 0.049076, loss_ce: 0.020295
[02:14:28.174] iteration 18812 : loss : 0.039860, loss_ce: 0.013212
[02:14:28.485] iteration 18813 : loss : 0.050947, loss_ce: 0.016570
[02:14:28.796] iteration 18814 : loss : 0.042048, loss_ce: 0.012548
[02:14:29.106] iteration 18815 : loss : 0.101257, loss_ce: 0.006629
[02:14:29.412] iteration 18816 : loss : 0.043993, loss_ce: 0.013674
[02:14:29.716] iteration 18817 : loss : 0.055317, loss_ce: 0.018947
[02:14:30.018] iteration 18818 : loss : 0.046128, loss_ce: 0.020547
[02:14:30.319] iteration 18819 : loss : 0.094439, loss_ce: 0.005879
[02:14:30.625] iteration 18820 : loss : 0.043942, loss_ce: 0.014092
[02:14:30.942] iteration 18821 : loss : 0.098223, loss_ce: 0.007903
[02:14:31.243] iteration 18822 : loss : 0.105753, loss_ce: 0.006171
[02:14:31.548] iteration 18823 : loss : 0.031053, loss_ce: 0.011715
[02:14:31.851] iteration 18824 : loss : 0.045263, loss_ce: 0.019638
[02:14:32.155] iteration 18825 : loss : 0.131192, loss_ce: 0.005394
[02:14:32.459] iteration 18826 : loss : 0.052591, loss_ce: 0.013282
[02:14:32.761] iteration 18827 : loss : 0.116148, loss_ce: 0.006772
[02:14:33.069] iteration 18828 : loss : 0.111066, loss_ce: 0.009196
[02:14:33.375] iteration 18829 : loss : 0.103528, loss_ce: 0.015890
[02:14:33.679] iteration 18830 : loss : 0.040179, loss_ce: 0.016900
[02:14:33.984] iteration 18831 : loss : 0.044315, loss_ce: 0.007957
[02:14:34.284] iteration 18832 : loss : 0.044582, loss_ce: 0.011052
[02:14:34.587] iteration 18833 : loss : 0.043581, loss_ce: 0.014410
[02:14:34.891] iteration 18834 : loss : 0.039047, loss_ce: 0.012303
[02:14:35.194] iteration 18835 : loss : 0.162712, loss_ce: 0.011460
[02:14:35.500] iteration 18836 : loss : 0.037109, loss_ce: 0.006139
[02:14:35.810] iteration 18837 : loss : 0.052816, loss_ce: 0.022716
[02:14:36.112] iteration 18838 : loss : 0.046845, loss_ce: 0.013398
[02:14:36.418] iteration 18839 : loss : 0.285662, loss_ce: 0.003202
[02:14:36.720] iteration 18840 : loss : 0.054439, loss_ce: 0.019309
[02:14:37.039] iteration 18841 : loss : 0.048866, loss_ce: 0.016924
[02:14:37.341] iteration 18842 : loss : 0.051390, loss_ce: 0.018977
[02:14:37.645] iteration 18843 : loss : 0.104501, loss_ce: 0.010859
[02:14:37.952] iteration 18844 : loss : 0.039519, loss_ce: 0.010187
[02:14:38.254] iteration 18845 : loss : 0.059321, loss_ce: 0.018366
[02:14:38.555] iteration 18846 : loss : 0.041827, loss_ce: 0.013553
[02:14:38.858] iteration 18847 : loss : 0.102328, loss_ce: 0.013118
[02:14:39.162] iteration 18848 : loss : 0.057533, loss_ce: 0.013834
[02:14:39.466] iteration 18849 : loss : 0.047597, loss_ce: 0.013527
[02:14:39.767] iteration 18850 : loss : 0.050815, loss_ce: 0.015582
[02:14:40.069] iteration 18851 : loss : 0.052201, loss_ce: 0.022478
[02:14:40.374] iteration 18852 : loss : 0.043835, loss_ce: 0.006198
[02:14:40.678] iteration 18853 : loss : 0.043540, loss_ce: 0.010843
[02:14:40.981] iteration 18854 : loss : 0.042244, loss_ce: 0.012675
[02:14:41.284] iteration 18855 : loss : 0.043150, loss_ce: 0.017467
[02:14:41.585] iteration 18856 : loss : 0.095753, loss_ce: 0.006006
[02:14:41.891] iteration 18857 : loss : 0.103437, loss_ce: 0.014783
[02:14:42.193] iteration 18858 : loss : 0.192915, loss_ce: 0.012059
[02:14:42.501] iteration 18859 : loss : 0.048483, loss_ce: 0.020256
[02:14:42.816] iteration 18860 : loss : 0.052462, loss_ce: 0.017484
[02:14:43.140] iteration 18861 : loss : 0.037313, loss_ce: 0.012892
[02:14:43.454] iteration 18862 : loss : 0.058851, loss_ce: 0.025982
[02:14:43.770] iteration 18863 : loss : 0.104763, loss_ce: 0.012224
[02:14:44.076] iteration 18864 : loss : 0.037786, loss_ce: 0.005433
[02:14:44.384] iteration 18865 : loss : 0.101921, loss_ce: 0.018337
[02:14:44.690] iteration 18866 : loss : 0.047894, loss_ce: 0.014521
[02:14:44.995] iteration 18867 : loss : 0.041549, loss_ce: 0.014792
[02:14:45.299] iteration 18868 : loss : 0.044554, loss_ce: 0.017347
[02:14:45.606] iteration 18869 : loss : 0.102800, loss_ce: 0.008894
[02:14:45.912] iteration 18870 : loss : 0.048315, loss_ce: 0.021178
[02:14:46.218] iteration 18871 : loss : 0.038957, loss_ce: 0.007243
[02:14:46.522] iteration 18872 : loss : 0.035585, loss_ce: 0.011060
[02:14:46.829] iteration 18873 : loss : 0.152711, loss_ce: 0.006612
[02:14:47.136] iteration 18874 : loss : 0.052480, loss_ce: 0.021454
[02:14:47.439] iteration 18875 : loss : 0.053301, loss_ce: 0.019526
[02:14:47.744] iteration 18876 : loss : 0.043278, loss_ce: 0.013835
[02:14:48.051] iteration 18877 : loss : 0.051361, loss_ce: 0.016420
[02:14:48.354] iteration 18878 : loss : 0.050860, loss_ce: 0.017251
[02:14:48.660] iteration 18879 : loss : 0.053606, loss_ce: 0.011350
[02:14:48.960] iteration 18880 : loss : 0.040514, loss_ce: 0.022663
[02:14:49.276] iteration 18881 : loss : 0.028999, loss_ce: 0.006364
[02:14:49.579] iteration 18882 : loss : 0.039569, loss_ce: 0.014614
[02:14:49.881] iteration 18883 : loss : 0.040727, loss_ce: 0.014133
[02:14:50.187] iteration 18884 : loss : 0.230491, loss_ce: 0.010708
[02:14:50.493] iteration 18885 : loss : 0.043352, loss_ce: 0.008971
[02:14:50.798] iteration 18886 : loss : 0.120357, loss_ce: 0.009988
[02:14:51.106] iteration 18887 : loss : 0.048603, loss_ce: 0.013194
[02:14:51.413] iteration 18888 : loss : 0.066763, loss_ce: 0.013434
[02:14:51.725] iteration 18889 : loss : 0.285337, loss_ce: 0.006764
[02:14:52.034] iteration 18890 : loss : 0.068519, loss_ce: 0.021576
[02:14:52.344] iteration 18891 : loss : 0.036435, loss_ce: 0.009612
[02:14:52.651] iteration 18892 : loss : 0.155513, loss_ce: 0.002853
[02:14:52.960] iteration 18893 : loss : 0.037913, loss_ce: 0.010061
[02:14:53.272] iteration 18894 : loss : 0.053498, loss_ce: 0.018246
[02:14:53.583] iteration 18895 : loss : 0.040860, loss_ce: 0.006975
[02:14:53.893] iteration 18896 : loss : 0.039313, loss_ce: 0.013476
[02:14:54.204] iteration 18897 : loss : 0.049589, loss_ce: 0.013606
[02:14:54.514] iteration 18898 : loss : 0.039711, loss_ce: 0.020095
[02:14:54.829] iteration 18899 : loss : 0.044270, loss_ce: 0.017405
[02:14:55.135] iteration 18900 : loss : 0.047237, loss_ce: 0.013749
[02:14:55.473] iteration 18901 : loss : 0.043304, loss_ce: 0.012433
[02:14:55.784] iteration 18902 : loss : 0.041338, loss_ce: 0.017232
[02:14:56.102] iteration 18903 : loss : 0.047420, loss_ce: 0.013703
[02:14:56.185] iteration 18904 : loss : 0.105040, loss_ce: 0.014513
[02:14:56.730] save model to ./logs/swin_unet\epoch_135.pth
[02:15:14.286] iteration 18905 : loss : 0.052794, loss_ce: 0.010602
[02:15:14.586] iteration 18906 : loss : 0.039050, loss_ce: 0.007531
[02:15:14.885] iteration 18907 : loss : 0.034008, loss_ce: 0.009099
[02:15:15.187] iteration 18908 : loss : 0.043880, loss_ce: 0.013962
[02:15:15.489] iteration 18909 : loss : 0.056779, loss_ce: 0.008455
[02:15:15.789] iteration 18910 : loss : 0.042845, loss_ce: 0.016249
[02:15:16.092] iteration 18911 : loss : 0.053160, loss_ce: 0.019623
[02:15:16.395] iteration 18912 : loss : 0.097177, loss_ce: 0.003715
[02:15:16.698] iteration 18913 : loss : 0.059446, loss_ce: 0.009998
[02:15:16.999] iteration 18914 : loss : 0.047298, loss_ce: 0.016469
[02:15:17.305] iteration 18915 : loss : 0.114343, loss_ce: 0.009421
[02:15:17.606] iteration 18916 : loss : 0.093613, loss_ce: 0.006293
[02:15:17.907] iteration 18917 : loss : 0.043104, loss_ce: 0.015085
[02:15:18.211] iteration 18918 : loss : 0.049528, loss_ce: 0.021004
[02:15:18.513] iteration 18919 : loss : 0.047055, loss_ce: 0.012555
[02:15:18.814] iteration 18920 : loss : 0.039471, loss_ce: 0.013674
[02:15:19.132] iteration 18921 : loss : 0.052730, loss_ce: 0.014571
[02:15:19.432] iteration 18922 : loss : 0.148158, loss_ce: 0.007823
[02:15:19.736] iteration 18923 : loss : 0.038106, loss_ce: 0.009726
[02:15:20.037] iteration 18924 : loss : 0.041753, loss_ce: 0.013518
[02:15:20.342] iteration 18925 : loss : 0.046338, loss_ce: 0.010771
[02:15:20.644] iteration 18926 : loss : 0.100415, loss_ce: 0.012484
[02:15:20.944] iteration 18927 : loss : 0.040688, loss_ce: 0.011753
[02:15:21.244] iteration 18928 : loss : 0.044057, loss_ce: 0.011593
[02:15:21.544] iteration 18929 : loss : 0.040910, loss_ce: 0.015276
[02:15:21.844] iteration 18930 : loss : 0.045617, loss_ce: 0.017299
[02:15:22.144] iteration 18931 : loss : 0.046351, loss_ce: 0.009742
[02:15:22.446] iteration 18932 : loss : 0.039442, loss_ce: 0.010871
[02:15:22.747] iteration 18933 : loss : 0.053574, loss_ce: 0.021187
[02:15:23.049] iteration 18934 : loss : 0.047589, loss_ce: 0.015836
[02:15:23.349] iteration 18935 : loss : 0.041565, loss_ce: 0.007567
[02:15:23.648] iteration 18936 : loss : 0.049862, loss_ce: 0.015906
[02:15:23.950] iteration 18937 : loss : 0.052620, loss_ce: 0.020942
[02:15:24.252] iteration 18938 : loss : 0.038108, loss_ce: 0.014783
[02:15:24.552] iteration 18939 : loss : 0.103946, loss_ce: 0.019579
[02:15:24.855] iteration 18940 : loss : 0.040618, loss_ce: 0.011333
[02:15:25.173] iteration 18941 : loss : 0.042553, loss_ce: 0.012585
[02:15:25.474] iteration 18942 : loss : 0.048220, loss_ce: 0.017773
[02:15:25.779] iteration 18943 : loss : 0.037291, loss_ce: 0.010193
[02:15:26.078] iteration 18944 : loss : 0.041363, loss_ce: 0.009845
[02:15:26.380] iteration 18945 : loss : 0.046730, loss_ce: 0.015422
[02:15:26.681] iteration 18946 : loss : 0.040461, loss_ce: 0.012145
[02:15:26.986] iteration 18947 : loss : 0.107513, loss_ce: 0.008405
[02:15:27.286] iteration 18948 : loss : 0.041196, loss_ce: 0.014052
[02:15:27.588] iteration 18949 : loss : 0.030660, loss_ce: 0.006609
[02:15:27.897] iteration 18950 : loss : 0.098681, loss_ce: 0.011353
[02:15:28.201] iteration 18951 : loss : 0.161600, loss_ce: 0.007425
[02:15:28.507] iteration 18952 : loss : 0.038549, loss_ce: 0.014051
[02:15:28.812] iteration 18953 : loss : 0.098673, loss_ce: 0.006345
[02:15:29.116] iteration 18954 : loss : 0.035576, loss_ce: 0.013556
[02:15:29.423] iteration 18955 : loss : 0.046807, loss_ce: 0.012974
[02:15:29.728] iteration 18956 : loss : 0.048130, loss_ce: 0.010371
[02:15:30.032] iteration 18957 : loss : 0.046583, loss_ce: 0.016348
[02:15:30.338] iteration 18958 : loss : 0.116970, loss_ce: 0.013387
[02:15:30.643] iteration 18959 : loss : 0.039987, loss_ce: 0.013533
[02:15:30.949] iteration 18960 : loss : 0.069685, loss_ce: 0.012572
[02:15:31.271] iteration 18961 : loss : 0.042982, loss_ce: 0.024752
[02:15:31.576] iteration 18962 : loss : 0.049447, loss_ce: 0.022584
[02:15:31.887] iteration 18963 : loss : 0.043000, loss_ce: 0.020014
[02:15:32.193] iteration 18964 : loss : 0.106816, loss_ce: 0.005945
[02:15:32.498] iteration 18965 : loss : 0.042351, loss_ce: 0.014748
[02:15:32.804] iteration 18966 : loss : 0.101370, loss_ce: 0.009636
[02:15:33.112] iteration 18967 : loss : 0.053672, loss_ce: 0.018966
[02:15:33.416] iteration 18968 : loss : 0.066028, loss_ce: 0.005515
[02:15:33.720] iteration 18969 : loss : 0.045466, loss_ce: 0.013158
[02:15:34.028] iteration 18970 : loss : 0.049897, loss_ce: 0.009117
[02:15:34.338] iteration 18971 : loss : 0.099117, loss_ce: 0.011864
[02:15:34.645] iteration 18972 : loss : 0.108387, loss_ce: 0.014520
[02:15:34.952] iteration 18973 : loss : 0.105706, loss_ce: 0.007309
[02:15:35.259] iteration 18974 : loss : 0.056292, loss_ce: 0.016925
[02:15:35.563] iteration 18975 : loss : 0.059794, loss_ce: 0.008843
[02:15:35.871] iteration 18976 : loss : 0.041764, loss_ce: 0.016220
[02:15:36.182] iteration 18977 : loss : 0.037633, loss_ce: 0.016177
[02:15:36.490] iteration 18978 : loss : 0.057731, loss_ce: 0.029389
[02:15:36.798] iteration 18979 : loss : 0.037815, loss_ce: 0.008796
[02:15:37.105] iteration 18980 : loss : 0.056512, loss_ce: 0.006611
[02:15:37.421] iteration 18981 : loss : 0.034489, loss_ce: 0.011387
[02:15:37.727] iteration 18982 : loss : 0.055242, loss_ce: 0.019482
[02:15:38.035] iteration 18983 : loss : 0.064748, loss_ce: 0.017322
[02:15:38.345] iteration 18984 : loss : 0.051649, loss_ce: 0.007403
[02:15:38.650] iteration 18985 : loss : 0.042507, loss_ce: 0.020126
[02:15:38.959] iteration 18986 : loss : 0.096901, loss_ce: 0.007847
[02:15:39.270] iteration 18987 : loss : 0.101582, loss_ce: 0.006702
[02:15:39.572] iteration 18988 : loss : 0.044938, loss_ce: 0.018415
[02:15:39.879] iteration 18989 : loss : 0.042542, loss_ce: 0.014944
[02:15:40.184] iteration 18990 : loss : 0.044592, loss_ce: 0.016446
[02:15:40.492] iteration 18991 : loss : 0.038176, loss_ce: 0.018117
[02:15:40.797] iteration 18992 : loss : 0.040632, loss_ce: 0.015055
[02:15:41.102] iteration 18993 : loss : 0.041447, loss_ce: 0.010663
[02:15:41.418] iteration 18994 : loss : 0.047642, loss_ce: 0.014923
[02:15:41.724] iteration 18995 : loss : 0.044578, loss_ce: 0.012809
[02:15:42.034] iteration 18996 : loss : 0.047798, loss_ce: 0.016000
[02:15:42.339] iteration 18997 : loss : 0.047609, loss_ce: 0.015313
[02:15:42.647] iteration 18998 : loss : 0.108669, loss_ce: 0.013593
[02:15:42.957] iteration 18999 : loss : 0.049795, loss_ce: 0.011640
[02:15:43.263] iteration 19000 : loss : 0.037480, loss_ce: 0.014157
[02:15:43.591] iteration 19001 : loss : 0.044992, loss_ce: 0.019365
[02:15:43.899] iteration 19002 : loss : 0.047567, loss_ce: 0.010066
[02:15:44.205] iteration 19003 : loss : 0.049981, loss_ce: 0.009787
[02:15:44.517] iteration 19004 : loss : 0.045509, loss_ce: 0.012042
[02:15:44.822] iteration 19005 : loss : 0.047923, loss_ce: 0.021228
[02:15:45.131] iteration 19006 : loss : 0.040852, loss_ce: 0.013537
[02:15:45.438] iteration 19007 : loss : 0.053905, loss_ce: 0.019045
[02:15:45.743] iteration 19008 : loss : 0.034255, loss_ce: 0.009994
[02:15:46.052] iteration 19009 : loss : 0.038452, loss_ce: 0.008567
[02:15:46.358] iteration 19010 : loss : 0.035388, loss_ce: 0.009096
[02:15:46.665] iteration 19011 : loss : 0.098571, loss_ce: 0.009675
[02:15:46.974] iteration 19012 : loss : 0.032946, loss_ce: 0.006304
[02:15:47.283] iteration 19013 : loss : 0.050504, loss_ce: 0.013895
[02:15:47.594] iteration 19014 : loss : 0.043910, loss_ce: 0.009262
[02:15:47.900] iteration 19015 : loss : 0.048051, loss_ce: 0.024041
[02:15:48.209] iteration 19016 : loss : 0.041762, loss_ce: 0.014642
[02:15:48.518] iteration 19017 : loss : 0.059440, loss_ce: 0.011757
[02:15:48.823] iteration 19018 : loss : 0.039579, loss_ce: 0.014623
[02:15:49.132] iteration 19019 : loss : 0.114931, loss_ce: 0.011074
[02:15:49.439] iteration 19020 : loss : 0.051817, loss_ce: 0.015015
[02:15:49.761] iteration 19021 : loss : 0.108922, loss_ce: 0.009553
[02:15:50.064] iteration 19022 : loss : 0.042171, loss_ce: 0.011952
[02:15:50.369] iteration 19023 : loss : 0.058230, loss_ce: 0.025353
[02:15:50.671] iteration 19024 : loss : 0.041195, loss_ce: 0.013021
[02:15:50.974] iteration 19025 : loss : 0.040190, loss_ce: 0.006701
[02:15:51.276] iteration 19026 : loss : 0.161363, loss_ce: 0.010176
[02:15:51.582] iteration 19027 : loss : 0.039367, loss_ce: 0.004687
[02:15:51.887] iteration 19028 : loss : 0.036945, loss_ce: 0.012018
[02:15:52.193] iteration 19029 : loss : 0.056286, loss_ce: 0.012808
[02:15:52.495] iteration 19030 : loss : 0.045733, loss_ce: 0.015941
[02:15:52.802] iteration 19031 : loss : 0.054729, loss_ce: 0.013632
[02:15:53.110] iteration 19032 : loss : 0.040242, loss_ce: 0.013641
[02:15:53.416] iteration 19033 : loss : 0.060116, loss_ce: 0.022569
[02:15:53.727] iteration 19034 : loss : 0.045909, loss_ce: 0.013616
[02:15:54.032] iteration 19035 : loss : 0.044580, loss_ce: 0.016632
[02:15:54.336] iteration 19036 : loss : 0.043081, loss_ce: 0.017779
[02:15:54.647] iteration 19037 : loss : 0.105328, loss_ce: 0.008217
[02:15:54.954] iteration 19038 : loss : 0.057687, loss_ce: 0.009693
[02:15:55.256] iteration 19039 : loss : 0.035523, loss_ce: 0.014354
[02:15:55.572] iteration 19040 : loss : 0.055326, loss_ce: 0.020229
[02:15:55.908] iteration 19041 : loss : 0.051853, loss_ce: 0.016521
[02:15:56.213] iteration 19042 : loss : 0.071479, loss_ce: 0.015001
[02:15:56.295] iteration 19043 : loss : 0.160346, loss_ce: 0.013017
[02:16:15.062] iteration 19044 : loss : 0.105097, loss_ce: 0.007866
[02:16:15.362] iteration 19045 : loss : 0.042661, loss_ce: 0.012794
[02:16:15.662] iteration 19046 : loss : 0.101217, loss_ce: 0.009829
[02:16:15.968] iteration 19047 : loss : 0.033864, loss_ce: 0.007800
[02:16:16.271] iteration 19048 : loss : 0.097938, loss_ce: 0.004770
[02:16:16.574] iteration 19049 : loss : 0.038752, loss_ce: 0.010930
[02:16:16.875] iteration 19050 : loss : 0.056123, loss_ce: 0.019358
[02:16:17.176] iteration 19051 : loss : 0.044083, loss_ce: 0.017608
[02:16:17.481] iteration 19052 : loss : 0.039617, loss_ce: 0.006505
[02:16:17.786] iteration 19053 : loss : 0.104581, loss_ce: 0.011622
[02:16:18.090] iteration 19054 : loss : 0.045782, loss_ce: 0.015998
[02:16:18.397] iteration 19055 : loss : 0.057630, loss_ce: 0.017541
[02:16:18.701] iteration 19056 : loss : 0.040372, loss_ce: 0.013536
[02:16:19.011] iteration 19057 : loss : 0.047073, loss_ce: 0.009952
[02:16:19.314] iteration 19058 : loss : 0.102371, loss_ce: 0.006426
[02:16:19.615] iteration 19059 : loss : 0.047417, loss_ce: 0.015139
[02:16:19.919] iteration 19060 : loss : 0.124041, loss_ce: 0.007512
[02:16:20.231] iteration 19061 : loss : 0.226579, loss_ce: 0.004284
[02:16:20.532] iteration 19062 : loss : 0.100135, loss_ce: 0.011793
[02:16:20.836] iteration 19063 : loss : 0.100954, loss_ce: 0.011493
[02:16:21.138] iteration 19064 : loss : 0.052582, loss_ce: 0.022788
[02:16:21.444] iteration 19065 : loss : 0.050272, loss_ce: 0.013392
[02:16:21.746] iteration 19066 : loss : 0.058245, loss_ce: 0.015921
[02:16:22.049] iteration 19067 : loss : 0.041788, loss_ce: 0.012282
[02:16:22.350] iteration 19068 : loss : 0.038768, loss_ce: 0.013163
[02:16:22.650] iteration 19069 : loss : 0.043068, loss_ce: 0.012337
[02:16:22.953] iteration 19070 : loss : 0.040733, loss_ce: 0.010515
[02:16:23.253] iteration 19071 : loss : 0.040157, loss_ce: 0.012182
[02:16:23.555] iteration 19072 : loss : 0.047151, loss_ce: 0.010762
[02:16:23.861] iteration 19073 : loss : 0.035148, loss_ce: 0.013200
[02:16:24.162] iteration 19074 : loss : 0.038760, loss_ce: 0.013804
[02:16:24.465] iteration 19075 : loss : 0.119981, loss_ce: 0.012597
[02:16:24.767] iteration 19076 : loss : 0.037733, loss_ce: 0.006632
[02:16:25.072] iteration 19077 : loss : 0.064661, loss_ce: 0.008496
[02:16:25.375] iteration 19078 : loss : 0.038709, loss_ce: 0.015817
[02:16:25.676] iteration 19079 : loss : 0.038845, loss_ce: 0.013552
[02:16:25.981] iteration 19080 : loss : 0.038895, loss_ce: 0.016518
[02:16:26.295] iteration 19081 : loss : 0.103351, loss_ce: 0.012324
[02:16:26.595] iteration 19082 : loss : 0.045758, loss_ce: 0.015988
[02:16:26.898] iteration 19083 : loss : 0.059897, loss_ce: 0.017476
[02:16:27.203] iteration 19084 : loss : 0.051490, loss_ce: 0.022985
[02:16:27.504] iteration 19085 : loss : 0.039553, loss_ce: 0.019418
[02:16:27.806] iteration 19086 : loss : 0.092979, loss_ce: 0.007837
[02:16:28.108] iteration 19087 : loss : 0.056248, loss_ce: 0.024054
[02:16:28.414] iteration 19088 : loss : 0.044540, loss_ce: 0.022452
[02:16:28.718] iteration 19089 : loss : 0.052437, loss_ce: 0.006620
[02:16:29.016] iteration 19090 : loss : 0.101764, loss_ce: 0.011161
[02:16:29.317] iteration 19091 : loss : 0.038152, loss_ce: 0.015561
[02:16:29.617] iteration 19092 : loss : 0.040278, loss_ce: 0.013066
[02:16:29.917] iteration 19093 : loss : 0.063893, loss_ce: 0.011090
[02:16:30.218] iteration 19094 : loss : 0.040971, loss_ce: 0.013577
[02:16:30.521] iteration 19095 : loss : 0.118404, loss_ce: 0.007288
[02:16:30.823] iteration 19096 : loss : 0.048388, loss_ce: 0.018746
[02:16:31.125] iteration 19097 : loss : 0.098060, loss_ce: 0.009381
[02:16:31.431] iteration 19098 : loss : 0.040373, loss_ce: 0.013259
[02:16:31.732] iteration 19099 : loss : 0.153125, loss_ce: 0.006510
[02:16:32.033] iteration 19100 : loss : 0.161685, loss_ce: 0.008618
[02:16:32.351] iteration 19101 : loss : 0.052281, loss_ce: 0.023013
[02:16:32.655] iteration 19102 : loss : 0.049070, loss_ce: 0.015349
[02:16:32.961] iteration 19103 : loss : 0.060124, loss_ce: 0.018035
[02:16:33.265] iteration 19104 : loss : 0.056505, loss_ce: 0.015696
[02:16:33.568] iteration 19105 : loss : 0.165451, loss_ce: 0.012300
[02:16:33.872] iteration 19106 : loss : 0.153332, loss_ce: 0.004346
[02:16:34.175] iteration 19107 : loss : 0.044712, loss_ce: 0.012002
[02:16:34.479] iteration 19108 : loss : 0.038330, loss_ce: 0.010913
[02:16:34.785] iteration 19109 : loss : 0.108549, loss_ce: 0.007384
[02:16:35.094] iteration 19110 : loss : 0.043838, loss_ce: 0.021612
[02:16:35.399] iteration 19111 : loss : 0.049116, loss_ce: 0.011953
[02:16:35.703] iteration 19112 : loss : 0.050879, loss_ce: 0.017913
[02:16:36.010] iteration 19113 : loss : 0.048146, loss_ce: 0.016812
[02:16:36.321] iteration 19114 : loss : 0.044879, loss_ce: 0.026948
[02:16:36.624] iteration 19115 : loss : 0.104845, loss_ce: 0.008431
[02:16:36.933] iteration 19116 : loss : 0.157942, loss_ce: 0.003628
[02:16:37.240] iteration 19117 : loss : 0.037602, loss_ce: 0.014453
[02:16:37.545] iteration 19118 : loss : 0.046006, loss_ce: 0.020879
[02:16:37.854] iteration 19119 : loss : 0.107979, loss_ce: 0.006915
[02:16:38.162] iteration 19120 : loss : 0.043897, loss_ce: 0.007289
[02:16:38.484] iteration 19121 : loss : 0.044419, loss_ce: 0.006734
[02:16:38.793] iteration 19122 : loss : 0.042914, loss_ce: 0.015475
[02:16:39.101] iteration 19123 : loss : 0.037924, loss_ce: 0.017510
[02:16:39.409] iteration 19124 : loss : 0.040430, loss_ce: 0.011677
[02:16:39.714] iteration 19125 : loss : 0.048180, loss_ce: 0.023770
[02:16:40.018] iteration 19126 : loss : 0.038491, loss_ce: 0.009610
[02:16:40.330] iteration 19127 : loss : 0.040649, loss_ce: 0.017852
[02:16:40.634] iteration 19128 : loss : 0.049303, loss_ce: 0.007434
[02:16:40.941] iteration 19129 : loss : 0.100972, loss_ce: 0.008656
[02:16:41.251] iteration 19130 : loss : 0.024306, loss_ce: 0.008755
[02:16:41.557] iteration 19131 : loss : 0.047399, loss_ce: 0.015768
[02:16:41.864] iteration 19132 : loss : 0.041574, loss_ce: 0.012038
[02:16:42.174] iteration 19133 : loss : 0.040809, loss_ce: 0.015146
[02:16:42.483] iteration 19134 : loss : 0.040053, loss_ce: 0.014187
[02:16:42.791] iteration 19135 : loss : 0.056797, loss_ce: 0.018083
[02:16:43.099] iteration 19136 : loss : 0.051288, loss_ce: 0.015208
[02:16:43.404] iteration 19137 : loss : 0.109552, loss_ce: 0.012669
[02:16:43.713] iteration 19138 : loss : 0.105902, loss_ce: 0.016773
[02:16:44.021] iteration 19139 : loss : 0.039281, loss_ce: 0.006061
[02:16:44.329] iteration 19140 : loss : 0.040751, loss_ce: 0.005598
[02:16:44.659] iteration 19141 : loss : 0.046542, loss_ce: 0.018197
[02:16:44.966] iteration 19142 : loss : 0.101025, loss_ce: 0.014353
[02:16:45.276] iteration 19143 : loss : 0.101419, loss_ce: 0.010160
[02:16:45.580] iteration 19144 : loss : 0.076818, loss_ce: 0.009703
[02:16:45.888] iteration 19145 : loss : 0.061405, loss_ce: 0.017087
[02:16:46.196] iteration 19146 : loss : 0.039550, loss_ce: 0.010459
[02:16:46.501] iteration 19147 : loss : 0.051658, loss_ce: 0.010686
[02:16:46.807] iteration 19148 : loss : 0.047784, loss_ce: 0.014507
[02:16:47.115] iteration 19149 : loss : 0.104056, loss_ce: 0.008763
[02:16:47.421] iteration 19150 : loss : 0.044904, loss_ce: 0.023289
[02:16:47.728] iteration 19151 : loss : 0.038620, loss_ce: 0.006821
[02:16:48.033] iteration 19152 : loss : 0.100292, loss_ce: 0.011310
[02:16:48.342] iteration 19153 : loss : 0.041992, loss_ce: 0.017713
[02:16:48.647] iteration 19154 : loss : 0.178743, loss_ce: 0.007597
[02:16:48.962] iteration 19155 : loss : 0.098872, loss_ce: 0.011902
[02:16:49.270] iteration 19156 : loss : 0.109552, loss_ce: 0.009505
[02:16:49.577] iteration 19157 : loss : 0.223619, loss_ce: 0.011436
[02:16:49.884] iteration 19158 : loss : 0.050099, loss_ce: 0.014606
[02:16:50.197] iteration 19159 : loss : 0.053896, loss_ce: 0.017924
[02:16:50.507] iteration 19160 : loss : 0.039696, loss_ce: 0.011149
[02:16:50.832] iteration 19161 : loss : 0.048461, loss_ce: 0.013233
[02:16:51.142] iteration 19162 : loss : 0.070879, loss_ce: 0.013640
[02:16:51.450] iteration 19163 : loss : 0.045838, loss_ce: 0.014123
[02:16:51.761] iteration 19164 : loss : 0.035020, loss_ce: 0.011505
[02:16:52.070] iteration 19165 : loss : 0.093600, loss_ce: 0.012181
[02:16:52.385] iteration 19166 : loss : 0.041058, loss_ce: 0.009136
[02:16:52.697] iteration 19167 : loss : 0.050446, loss_ce: 0.023940
[02:16:53.011] iteration 19168 : loss : 0.043171, loss_ce: 0.011806
[02:16:53.326] iteration 19169 : loss : 0.206762, loss_ce: 0.006064
[02:16:53.642] iteration 19170 : loss : 0.041513, loss_ce: 0.013785
[02:16:53.959] iteration 19171 : loss : 0.040573, loss_ce: 0.013146
[02:16:54.271] iteration 19172 : loss : 0.096309, loss_ce: 0.018185
[02:16:54.585] iteration 19173 : loss : 0.048664, loss_ce: 0.012938
[02:16:54.898] iteration 19174 : loss : 0.051337, loss_ce: 0.011539
[02:16:55.203] iteration 19175 : loss : 0.059624, loss_ce: 0.012349
[02:16:55.516] iteration 19176 : loss : 0.051327, loss_ce: 0.022143
[02:16:55.821] iteration 19177 : loss : 0.037383, loss_ce: 0.015988
[02:16:56.128] iteration 19178 : loss : 0.076639, loss_ce: 0.011370
[02:16:56.436] iteration 19179 : loss : 0.064766, loss_ce: 0.012522
[02:16:56.748] iteration 19180 : loss : 0.039248, loss_ce: 0.015931
[02:16:57.095] iteration 19181 : loss : 0.049438, loss_ce: 0.015350
[02:16:57.196] iteration 19182 : loss : 0.281058, loss_ce: 0.003827
[02:17:14.216] iteration 19183 : loss : 0.099556, loss_ce: 0.009282
[02:17:14.518] iteration 19184 : loss : 0.042856, loss_ce: 0.013711
[02:17:14.817] iteration 19185 : loss : 0.039404, loss_ce: 0.015010
[02:17:15.112] iteration 19186 : loss : 0.043510, loss_ce: 0.015177
[02:17:15.418] iteration 19187 : loss : 0.110753, loss_ce: 0.008960
[02:17:15.718] iteration 19188 : loss : 0.055484, loss_ce: 0.015038
[02:17:16.020] iteration 19189 : loss : 0.041984, loss_ce: 0.020054
[02:17:16.322] iteration 19190 : loss : 0.070242, loss_ce: 0.011217
[02:17:16.624] iteration 19191 : loss : 0.050842, loss_ce: 0.012260
[02:17:16.927] iteration 19192 : loss : 0.046139, loss_ce: 0.018125
[02:17:17.232] iteration 19193 : loss : 0.105353, loss_ce: 0.019514
[02:17:17.531] iteration 19194 : loss : 0.044507, loss_ce: 0.020166
[02:17:17.828] iteration 19195 : loss : 0.045320, loss_ce: 0.013754
[02:17:18.127] iteration 19196 : loss : 0.043599, loss_ce: 0.015278
[02:17:18.430] iteration 19197 : loss : 0.054547, loss_ce: 0.009981
[02:17:18.733] iteration 19198 : loss : 0.099367, loss_ce: 0.006088
[02:17:19.034] iteration 19199 : loss : 0.044847, loss_ce: 0.013446
[02:17:19.333] iteration 19200 : loss : 0.059986, loss_ce: 0.017560
[02:17:19.646] iteration 19201 : loss : 0.044483, loss_ce: 0.012386
[02:17:19.949] iteration 19202 : loss : 0.045081, loss_ce: 0.019527
[02:17:20.249] iteration 19203 : loss : 0.055021, loss_ce: 0.011967
[02:17:20.555] iteration 19204 : loss : 0.103132, loss_ce: 0.010256
[02:17:20.857] iteration 19205 : loss : 0.050269, loss_ce: 0.021259
[02:17:21.158] iteration 19206 : loss : 0.047232, loss_ce: 0.012847
[02:17:21.461] iteration 19207 : loss : 0.066882, loss_ce: 0.011720
[02:17:21.765] iteration 19208 : loss : 0.047222, loss_ce: 0.008837
[02:17:22.066] iteration 19209 : loss : 0.058515, loss_ce: 0.017877
[02:17:22.370] iteration 19210 : loss : 0.035244, loss_ce: 0.009829
[02:17:22.676] iteration 19211 : loss : 0.049756, loss_ce: 0.011857
[02:17:22.982] iteration 19212 : loss : 0.199645, loss_ce: 0.011151
[02:17:23.284] iteration 19213 : loss : 0.054154, loss_ce: 0.005635
[02:17:23.591] iteration 19214 : loss : 0.123819, loss_ce: 0.006277
[02:17:23.895] iteration 19215 : loss : 0.041793, loss_ce: 0.011513
[02:17:24.202] iteration 19216 : loss : 0.045754, loss_ce: 0.010892
[02:17:24.509] iteration 19217 : loss : 0.054334, loss_ce: 0.018910
[02:17:24.817] iteration 19218 : loss : 0.041392, loss_ce: 0.011159
[02:17:25.122] iteration 19219 : loss : 0.041481, loss_ce: 0.013206
[02:17:25.429] iteration 19220 : loss : 0.096044, loss_ce: 0.005320
[02:17:25.755] iteration 19221 : loss : 0.045642, loss_ce: 0.012365
[02:17:26.062] iteration 19222 : loss : 0.062993, loss_ce: 0.019130
[02:17:26.375] iteration 19223 : loss : 0.047318, loss_ce: 0.019487
[02:17:26.680] iteration 19224 : loss : 0.099864, loss_ce: 0.014704
[02:17:26.987] iteration 19225 : loss : 0.099852, loss_ce: 0.012311
[02:17:27.296] iteration 19226 : loss : 0.058114, loss_ce: 0.012578
[02:17:27.609] iteration 19227 : loss : 0.043678, loss_ce: 0.023036
[02:17:27.916] iteration 19228 : loss : 0.044442, loss_ce: 0.017225
[02:17:28.224] iteration 19229 : loss : 0.033003, loss_ce: 0.007173
[02:17:28.532] iteration 19230 : loss : 0.041093, loss_ce: 0.009860
[02:17:28.836] iteration 19231 : loss : 0.044138, loss_ce: 0.013189
[02:17:29.147] iteration 19232 : loss : 0.040763, loss_ce: 0.014430
[02:17:29.454] iteration 19233 : loss : 0.043508, loss_ce: 0.013892
[02:17:29.765] iteration 19234 : loss : 0.044866, loss_ce: 0.009738
[02:17:30.071] iteration 19235 : loss : 0.162558, loss_ce: 0.004204
[02:17:30.379] iteration 19236 : loss : 0.040548, loss_ce: 0.014126
[02:17:30.686] iteration 19237 : loss : 0.045816, loss_ce: 0.014798
[02:17:30.993] iteration 19238 : loss : 0.033590, loss_ce: 0.018179
[02:17:31.300] iteration 19239 : loss : 0.050825, loss_ce: 0.014227
[02:17:31.608] iteration 19240 : loss : 0.064956, loss_ce: 0.004993
[02:17:31.931] iteration 19241 : loss : 0.045378, loss_ce: 0.011032
[02:17:32.242] iteration 19242 : loss : 0.051462, loss_ce: 0.014544
[02:17:32.554] iteration 19243 : loss : 0.048405, loss_ce: 0.012981
[02:17:32.858] iteration 19244 : loss : 0.053951, loss_ce: 0.018572
[02:17:33.162] iteration 19245 : loss : 0.071231, loss_ce: 0.018184
[02:17:33.470] iteration 19246 : loss : 0.043325, loss_ce: 0.012612
[02:17:33.779] iteration 19247 : loss : 0.036575, loss_ce: 0.012368
[02:17:34.085] iteration 19248 : loss : 0.041289, loss_ce: 0.012866
[02:17:34.397] iteration 19249 : loss : 0.043115, loss_ce: 0.012043
[02:17:34.706] iteration 19250 : loss : 0.036594, loss_ce: 0.015532
[02:17:35.015] iteration 19251 : loss : 0.043392, loss_ce: 0.015534
[02:17:35.321] iteration 19252 : loss : 0.028708, loss_ce: 0.006668
[02:17:35.627] iteration 19253 : loss : 0.043771, loss_ce: 0.012065
[02:17:35.936] iteration 19254 : loss : 0.047989, loss_ce: 0.013370
[02:17:36.246] iteration 19255 : loss : 0.043876, loss_ce: 0.012766
[02:17:36.556] iteration 19256 : loss : 0.046021, loss_ce: 0.009135
[02:17:36.869] iteration 19257 : loss : 0.043548, loss_ce: 0.008883
[02:17:37.175] iteration 19258 : loss : 0.099599, loss_ce: 0.011211
[02:17:37.483] iteration 19259 : loss : 0.048803, loss_ce: 0.013977
[02:17:37.791] iteration 19260 : loss : 0.094411, loss_ce: 0.008676
[02:17:38.114] iteration 19261 : loss : 0.031777, loss_ce: 0.011851
[02:17:38.421] iteration 19262 : loss : 0.047398, loss_ce: 0.009751
[02:17:38.730] iteration 19263 : loss : 0.052084, loss_ce: 0.018556
[02:17:39.039] iteration 19264 : loss : 0.111040, loss_ce: 0.010816
[02:17:39.344] iteration 19265 : loss : 0.041490, loss_ce: 0.012678
[02:17:39.650] iteration 19266 : loss : 0.107084, loss_ce: 0.023127
[02:17:39.963] iteration 19267 : loss : 0.101947, loss_ce: 0.010978
[02:17:40.266] iteration 19268 : loss : 0.043408, loss_ce: 0.013331
[02:17:40.575] iteration 19269 : loss : 0.046315, loss_ce: 0.018413
[02:17:40.883] iteration 19270 : loss : 0.044798, loss_ce: 0.014471
[02:17:41.192] iteration 19271 : loss : 0.045984, loss_ce: 0.014470
[02:17:41.501] iteration 19272 : loss : 0.100851, loss_ce: 0.012292
[02:17:41.809] iteration 19273 : loss : 0.038628, loss_ce: 0.012738
[02:17:42.117] iteration 19274 : loss : 0.047786, loss_ce: 0.007246
[02:17:42.432] iteration 19275 : loss : 0.047785, loss_ce: 0.022380
[02:17:42.743] iteration 19276 : loss : 0.055393, loss_ce: 0.005455
[02:17:43.049] iteration 19277 : loss : 0.039932, loss_ce: 0.010302
[02:17:43.356] iteration 19278 : loss : 0.102560, loss_ce: 0.004481
[02:17:43.663] iteration 19279 : loss : 0.062537, loss_ce: 0.019342
[02:17:43.974] iteration 19280 : loss : 0.108678, loss_ce: 0.012348
[02:17:44.298] iteration 19281 : loss : 0.034140, loss_ce: 0.011736
[02:17:44.602] iteration 19282 : loss : 0.099747, loss_ce: 0.011923
[02:17:44.911] iteration 19283 : loss : 0.037925, loss_ce: 0.010143
[02:17:45.215] iteration 19284 : loss : 0.040234, loss_ce: 0.009499
[02:17:45.517] iteration 19285 : loss : 0.046938, loss_ce: 0.013803
[02:17:45.822] iteration 19286 : loss : 0.041322, loss_ce: 0.012628
[02:17:46.124] iteration 19287 : loss : 0.048320, loss_ce: 0.024170
[02:17:46.428] iteration 19288 : loss : 0.052501, loss_ce: 0.010689
[02:17:46.734] iteration 19289 : loss : 0.089459, loss_ce: 0.005031
[02:17:47.037] iteration 19290 : loss : 0.099279, loss_ce: 0.012883
[02:17:47.342] iteration 19291 : loss : 0.043995, loss_ce: 0.018847
[02:17:47.643] iteration 19292 : loss : 0.045468, loss_ce: 0.016289
[02:17:47.948] iteration 19293 : loss : 0.038166, loss_ce: 0.008324
[02:17:48.253] iteration 19294 : loss : 0.049266, loss_ce: 0.006805
[02:17:48.553] iteration 19295 : loss : 0.056187, loss_ce: 0.017317
[02:17:48.859] iteration 19296 : loss : 0.100771, loss_ce: 0.008945
[02:17:49.159] iteration 19297 : loss : 0.039189, loss_ce: 0.016374
[02:17:49.458] iteration 19298 : loss : 0.044360, loss_ce: 0.011736
[02:17:49.760] iteration 19299 : loss : 0.045048, loss_ce: 0.010099
[02:17:50.064] iteration 19300 : loss : 0.100906, loss_ce: 0.009261
[02:17:50.389] iteration 19301 : loss : 0.045174, loss_ce: 0.010235
[02:17:50.689] iteration 19302 : loss : 0.044671, loss_ce: 0.016414
[02:17:50.992] iteration 19303 : loss : 0.037373, loss_ce: 0.016415
[02:17:51.298] iteration 19304 : loss : 0.037277, loss_ce: 0.014194
[02:17:51.606] iteration 19305 : loss : 0.047246, loss_ce: 0.013218
[02:17:51.916] iteration 19306 : loss : 0.042512, loss_ce: 0.016862
[02:17:52.225] iteration 19307 : loss : 0.051281, loss_ce: 0.012287
[02:17:52.528] iteration 19308 : loss : 0.101867, loss_ce: 0.007513
[02:17:52.834] iteration 19309 : loss : 0.108278, loss_ce: 0.013369
[02:17:53.144] iteration 19310 : loss : 0.040023, loss_ce: 0.007520
[02:17:53.450] iteration 19311 : loss : 0.044107, loss_ce: 0.014970
[02:17:53.757] iteration 19312 : loss : 0.046366, loss_ce: 0.016758
[02:17:54.064] iteration 19313 : loss : 0.105621, loss_ce: 0.010132
[02:17:54.369] iteration 19314 : loss : 0.031198, loss_ce: 0.010295
[02:17:54.681] iteration 19315 : loss : 0.048887, loss_ce: 0.020513
[02:17:54.990] iteration 19316 : loss : 0.177280, loss_ce: 0.005489
[02:17:55.298] iteration 19317 : loss : 0.032825, loss_ce: 0.010170
[02:17:55.601] iteration 19318 : loss : 0.040773, loss_ce: 0.013357
[02:17:55.913] iteration 19319 : loss : 0.044366, loss_ce: 0.022781
[02:17:56.225] iteration 19320 : loss : 0.040329, loss_ce: 0.015438
[02:17:56.322] iteration 19321 : loss : 0.168881, loss_ce: 0.010379
[02:18:15.612] iteration 19322 : loss : 0.042903, loss_ce: 0.015740
[02:18:15.914] iteration 19323 : loss : 0.046178, loss_ce: 0.012325
[02:18:16.217] iteration 19324 : loss : 0.099468, loss_ce: 0.010234
[02:18:16.524] iteration 19325 : loss : 0.186290, loss_ce: 0.003625
[02:18:16.829] iteration 19326 : loss : 0.056064, loss_ce: 0.017061
[02:18:17.133] iteration 19327 : loss : 0.049830, loss_ce: 0.020952
[02:18:17.437] iteration 19328 : loss : 0.044287, loss_ce: 0.007680
[02:18:17.746] iteration 19329 : loss : 0.044894, loss_ce: 0.014599
[02:18:18.055] iteration 19330 : loss : 0.036940, loss_ce: 0.011989
[02:18:18.360] iteration 19331 : loss : 0.045453, loss_ce: 0.019642
[02:18:18.670] iteration 19332 : loss : 0.047025, loss_ce: 0.016009
[02:18:18.976] iteration 19333 : loss : 0.050588, loss_ce: 0.016806
[02:18:19.281] iteration 19334 : loss : 0.067347, loss_ce: 0.014589
[02:18:19.588] iteration 19335 : loss : 0.048803, loss_ce: 0.021093
[02:18:19.895] iteration 19336 : loss : 0.069027, loss_ce: 0.014926
[02:18:20.198] iteration 19337 : loss : 0.043191, loss_ce: 0.013896
[02:18:20.504] iteration 19338 : loss : 0.057374, loss_ce: 0.010573
[02:18:20.813] iteration 19339 : loss : 0.044838, loss_ce: 0.012082
[02:18:21.122] iteration 19340 : loss : 0.037968, loss_ce: 0.009716
[02:18:21.449] iteration 19341 : loss : 0.039124, loss_ce: 0.014148
[02:18:21.751] iteration 19342 : loss : 0.042040, loss_ce: 0.018107
[02:18:22.056] iteration 19343 : loss : 0.104824, loss_ce: 0.013109
[02:18:22.363] iteration 19344 : loss : 0.050356, loss_ce: 0.017985
[02:18:22.669] iteration 19345 : loss : 0.050305, loss_ce: 0.014874
[02:18:22.971] iteration 19346 : loss : 0.039046, loss_ce: 0.016698
[02:18:23.279] iteration 19347 : loss : 0.037759, loss_ce: 0.010648
[02:18:23.586] iteration 19348 : loss : 0.040591, loss_ce: 0.015761
[02:18:23.893] iteration 19349 : loss : 0.036204, loss_ce: 0.014600
[02:18:24.199] iteration 19350 : loss : 0.048103, loss_ce: 0.011500
[02:18:24.501] iteration 19351 : loss : 0.052317, loss_ce: 0.014218
[02:18:24.806] iteration 19352 : loss : 0.106984, loss_ce: 0.011997
[02:18:25.113] iteration 19353 : loss : 0.039671, loss_ce: 0.013031
[02:18:25.419] iteration 19354 : loss : 0.046224, loss_ce: 0.017334
[02:18:25.726] iteration 19355 : loss : 0.164121, loss_ce: 0.009588
[02:18:26.032] iteration 19356 : loss : 0.047210, loss_ce: 0.007629
[02:18:26.339] iteration 19357 : loss : 0.044068, loss_ce: 0.013186
[02:18:26.644] iteration 19358 : loss : 0.097451, loss_ce: 0.006149
[02:18:26.950] iteration 19359 : loss : 0.041667, loss_ce: 0.013287
[02:18:27.260] iteration 19360 : loss : 0.036581, loss_ce: 0.011433
[02:18:27.582] iteration 19361 : loss : 0.103448, loss_ce: 0.013971
[02:18:27.889] iteration 19362 : loss : 0.108178, loss_ce: 0.012851
[02:18:28.201] iteration 19363 : loss : 0.041656, loss_ce: 0.010227
[02:18:28.504] iteration 19364 : loss : 0.041956, loss_ce: 0.008274
[02:18:28.807] iteration 19365 : loss : 0.084716, loss_ce: 0.015528
[02:18:29.114] iteration 19366 : loss : 0.038041, loss_ce: 0.013105
[02:18:29.424] iteration 19367 : loss : 0.093403, loss_ce: 0.009165
[02:18:29.729] iteration 19368 : loss : 0.039587, loss_ce: 0.013292
[02:18:30.038] iteration 19369 : loss : 0.038834, loss_ce: 0.014397
[02:18:30.346] iteration 19370 : loss : 0.041212, loss_ce: 0.014943
[02:18:30.658] iteration 19371 : loss : 0.040274, loss_ce: 0.006641
[02:18:30.964] iteration 19372 : loss : 0.043729, loss_ce: 0.017733
[02:18:31.272] iteration 19373 : loss : 0.051587, loss_ce: 0.012495
[02:18:31.580] iteration 19374 : loss : 0.054468, loss_ce: 0.012656
[02:18:31.890] iteration 19375 : loss : 0.040211, loss_ce: 0.012101
[02:18:32.197] iteration 19376 : loss : 0.043438, loss_ce: 0.011182
[02:18:32.507] iteration 19377 : loss : 0.092570, loss_ce: 0.007449
[02:18:32.816] iteration 19378 : loss : 0.056891, loss_ce: 0.013137
[02:18:33.126] iteration 19379 : loss : 0.096291, loss_ce: 0.007185
[02:18:33.434] iteration 19380 : loss : 0.053396, loss_ce: 0.011943
[02:18:33.758] iteration 19381 : loss : 0.056112, loss_ce: 0.024820
[02:18:34.066] iteration 19382 : loss : 0.041467, loss_ce: 0.011078
[02:18:34.376] iteration 19383 : loss : 0.097552, loss_ce: 0.008983
[02:18:34.682] iteration 19384 : loss : 0.098634, loss_ce: 0.012111
[02:18:34.985] iteration 19385 : loss : 0.041833, loss_ce: 0.011898
[02:18:35.288] iteration 19386 : loss : 0.048374, loss_ce: 0.010636
[02:18:35.591] iteration 19387 : loss : 0.113226, loss_ce: 0.007887
[02:18:35.896] iteration 19388 : loss : 0.044547, loss_ce: 0.020394
[02:18:36.200] iteration 19389 : loss : 0.101847, loss_ce: 0.011356
[02:18:36.508] iteration 19390 : loss : 0.039336, loss_ce: 0.014297
[02:18:36.812] iteration 19391 : loss : 0.050523, loss_ce: 0.008809
[02:18:37.118] iteration 19392 : loss : 0.054295, loss_ce: 0.013321
[02:18:37.425] iteration 19393 : loss : 0.042519, loss_ce: 0.011263
[02:18:37.727] iteration 19394 : loss : 0.168261, loss_ce: 0.007743
[02:18:38.027] iteration 19395 : loss : 0.042154, loss_ce: 0.015340
[02:18:38.328] iteration 19396 : loss : 0.035959, loss_ce: 0.018625
[02:18:38.633] iteration 19397 : loss : 0.043425, loss_ce: 0.010429
[02:18:38.933] iteration 19398 : loss : 0.108773, loss_ce: 0.010666
[02:18:39.240] iteration 19399 : loss : 0.064257, loss_ce: 0.019790
[02:18:39.541] iteration 19400 : loss : 0.044387, loss_ce: 0.020229
[02:18:39.867] iteration 19401 : loss : 0.040556, loss_ce: 0.010014
[02:18:40.169] iteration 19402 : loss : 0.052036, loss_ce: 0.010351
[02:18:40.476] iteration 19403 : loss : 0.032404, loss_ce: 0.009970
[02:18:40.785] iteration 19404 : loss : 0.039126, loss_ce: 0.007661
[02:18:41.091] iteration 19405 : loss : 0.107484, loss_ce: 0.011833
[02:18:41.393] iteration 19406 : loss : 0.043127, loss_ce: 0.017184
[02:18:41.702] iteration 19407 : loss : 0.057889, loss_ce: 0.017914
[02:18:42.002] iteration 19408 : loss : 0.051378, loss_ce: 0.006084
[02:18:42.306] iteration 19409 : loss : 0.037942, loss_ce: 0.010151
[02:18:42.608] iteration 19410 : loss : 0.091576, loss_ce: 0.006858
[02:18:42.912] iteration 19411 : loss : 0.042966, loss_ce: 0.013135
[02:18:43.214] iteration 19412 : loss : 0.054924, loss_ce: 0.013896
[02:18:43.522] iteration 19413 : loss : 0.036551, loss_ce: 0.011051
[02:18:43.827] iteration 19414 : loss : 0.047643, loss_ce: 0.009129
[02:18:44.130] iteration 19415 : loss : 0.039658, loss_ce: 0.010699
[02:18:44.435] iteration 19416 : loss : 0.037079, loss_ce: 0.017341
[02:18:44.739] iteration 19417 : loss : 0.036012, loss_ce: 0.019813
[02:18:45.040] iteration 19418 : loss : 0.112804, loss_ce: 0.008634
[02:18:45.344] iteration 19419 : loss : 0.048660, loss_ce: 0.011138
[02:18:45.646] iteration 19420 : loss : 0.115628, loss_ce: 0.006221
[02:18:45.964] iteration 19421 : loss : 0.046107, loss_ce: 0.009144
[02:18:46.269] iteration 19422 : loss : 0.043107, loss_ce: 0.015783
[02:18:46.572] iteration 19423 : loss : 0.042675, loss_ce: 0.021928
[02:18:46.877] iteration 19424 : loss : 0.049680, loss_ce: 0.013910
[02:18:47.184] iteration 19425 : loss : 0.090756, loss_ce: 0.008373
[02:18:47.495] iteration 19426 : loss : 0.049233, loss_ce: 0.017964
[02:18:47.804] iteration 19427 : loss : 0.036084, loss_ce: 0.013394
[02:18:48.113] iteration 19428 : loss : 0.049044, loss_ce: 0.008602
[02:18:48.421] iteration 19429 : loss : 0.056431, loss_ce: 0.012911
[02:18:48.733] iteration 19430 : loss : 0.049458, loss_ce: 0.014562
[02:18:49.045] iteration 19431 : loss : 0.039337, loss_ce: 0.020929
[02:18:49.350] iteration 19432 : loss : 0.049269, loss_ce: 0.017428
[02:18:49.660] iteration 19433 : loss : 0.036558, loss_ce: 0.011735
[02:18:49.967] iteration 19434 : loss : 0.041724, loss_ce: 0.016375
[02:18:50.271] iteration 19435 : loss : 0.036376, loss_ce: 0.018656
[02:18:50.576] iteration 19436 : loss : 0.052745, loss_ce: 0.007947
[02:18:50.883] iteration 19437 : loss : 0.112613, loss_ce: 0.009883
[02:18:51.189] iteration 19438 : loss : 0.040135, loss_ce: 0.007274
[02:18:51.497] iteration 19439 : loss : 0.107521, loss_ce: 0.015389
[02:18:51.805] iteration 19440 : loss : 0.043750, loss_ce: 0.019709
[02:18:52.127] iteration 19441 : loss : 0.070390, loss_ce: 0.012947
[02:18:52.428] iteration 19442 : loss : 0.047482, loss_ce: 0.014387
[02:18:52.735] iteration 19443 : loss : 0.042531, loss_ce: 0.012483
[02:18:53.044] iteration 19444 : loss : 0.043920, loss_ce: 0.017526
[02:18:53.357] iteration 19445 : loss : 0.043607, loss_ce: 0.014856
[02:18:53.664] iteration 19446 : loss : 0.100878, loss_ce: 0.007722
[02:18:53.978] iteration 19447 : loss : 0.041651, loss_ce: 0.016870
[02:18:54.286] iteration 19448 : loss : 0.049537, loss_ce: 0.021881
[02:18:54.596] iteration 19449 : loss : 0.043022, loss_ce: 0.017159
[02:18:54.908] iteration 19450 : loss : 0.044554, loss_ce: 0.012054
[02:18:55.218] iteration 19451 : loss : 0.031353, loss_ce: 0.007421
[02:18:55.528] iteration 19452 : loss : 0.038914, loss_ce: 0.013237
[02:18:55.838] iteration 19453 : loss : 0.074737, loss_ce: 0.006919
[02:18:56.145] iteration 19454 : loss : 0.042707, loss_ce: 0.009675
[02:18:56.457] iteration 19455 : loss : 0.157917, loss_ce: 0.006609
[02:18:56.768] iteration 19456 : loss : 0.048647, loss_ce: 0.019342
[02:18:57.078] iteration 19457 : loss : 0.109988, loss_ce: 0.004930
[02:18:57.387] iteration 19458 : loss : 0.045533, loss_ce: 0.016591
[02:18:57.695] iteration 19459 : loss : 0.040514, loss_ce: 0.017342
[02:18:57.773] iteration 19460 : loss : 0.217764, loss_ce: 0.010865
[02:19:15.966] iteration 19461 : loss : 0.041075, loss_ce: 0.017110
[02:19:16.268] iteration 19462 : loss : 0.049956, loss_ce: 0.016647
[02:19:16.567] iteration 19463 : loss : 0.043789, loss_ce: 0.024688
[02:19:16.867] iteration 19464 : loss : 0.043338, loss_ce: 0.013420
[02:19:17.172] iteration 19465 : loss : 0.043734, loss_ce: 0.019650
[02:19:17.481] iteration 19466 : loss : 0.043814, loss_ce: 0.014862
[02:19:17.781] iteration 19467 : loss : 0.041435, loss_ce: 0.019074
[02:19:18.081] iteration 19468 : loss : 0.038782, loss_ce: 0.014355
[02:19:18.389] iteration 19469 : loss : 0.041008, loss_ce: 0.011837
[02:19:18.693] iteration 19470 : loss : 0.103675, loss_ce: 0.012986
[02:19:18.997] iteration 19471 : loss : 0.045696, loss_ce: 0.016488
[02:19:19.306] iteration 19472 : loss : 0.048643, loss_ce: 0.013880
[02:19:19.612] iteration 19473 : loss : 0.043415, loss_ce: 0.010270
[02:19:19.917] iteration 19474 : loss : 0.047910, loss_ce: 0.012646
[02:19:20.223] iteration 19475 : loss : 0.170121, loss_ce: 0.005332
[02:19:20.529] iteration 19476 : loss : 0.074940, loss_ce: 0.013834
[02:19:20.836] iteration 19477 : loss : 0.045453, loss_ce: 0.015589
[02:19:21.141] iteration 19478 : loss : 0.039081, loss_ce: 0.016668
[02:19:21.450] iteration 19479 : loss : 0.045480, loss_ce: 0.011487
[02:19:21.756] iteration 19480 : loss : 0.048578, loss_ce: 0.016492
[02:19:22.079] iteration 19481 : loss : 0.089217, loss_ce: 0.015115
[02:19:22.386] iteration 19482 : loss : 0.042764, loss_ce: 0.012934
[02:19:22.692] iteration 19483 : loss : 0.034055, loss_ce: 0.012013
[02:19:23.002] iteration 19484 : loss : 0.040020, loss_ce: 0.012751
[02:19:23.305] iteration 19485 : loss : 0.049373, loss_ce: 0.011228
[02:19:23.611] iteration 19486 : loss : 0.061278, loss_ce: 0.010997
[02:19:23.919] iteration 19487 : loss : 0.048440, loss_ce: 0.022092
[02:19:24.223] iteration 19488 : loss : 0.044367, loss_ce: 0.007670
[02:19:24.531] iteration 19489 : loss : 0.052951, loss_ce: 0.012791
[02:19:24.838] iteration 19490 : loss : 0.047106, loss_ce: 0.018778
[02:19:25.145] iteration 19491 : loss : 0.041607, loss_ce: 0.015654
[02:19:25.452] iteration 19492 : loss : 0.035203, loss_ce: 0.008660
[02:19:25.755] iteration 19493 : loss : 0.041318, loss_ce: 0.013928
[02:19:26.061] iteration 19494 : loss : 0.048817, loss_ce: 0.013175
[02:19:26.370] iteration 19495 : loss : 0.101853, loss_ce: 0.005561
[02:19:26.676] iteration 19496 : loss : 0.048564, loss_ce: 0.009461
[02:19:26.982] iteration 19497 : loss : 0.098520, loss_ce: 0.005677
[02:19:27.290] iteration 19498 : loss : 0.049845, loss_ce: 0.004624
[02:19:27.599] iteration 19499 : loss : 0.103683, loss_ce: 0.006114
[02:19:27.902] iteration 19500 : loss : 0.047103, loss_ce: 0.010342
[02:19:28.221] iteration 19501 : loss : 0.040954, loss_ce: 0.015312
[02:19:28.530] iteration 19502 : loss : 0.040963, loss_ce: 0.009961
[02:19:28.838] iteration 19503 : loss : 0.107212, loss_ce: 0.007330
[02:19:29.144] iteration 19504 : loss : 0.044537, loss_ce: 0.013588
[02:19:29.453] iteration 19505 : loss : 0.049588, loss_ce: 0.015357
[02:19:29.758] iteration 19506 : loss : 0.155216, loss_ce: 0.005891
[02:19:30.068] iteration 19507 : loss : 0.055485, loss_ce: 0.024476
[02:19:30.375] iteration 19508 : loss : 0.095705, loss_ce: 0.005746
[02:19:30.686] iteration 19509 : loss : 0.100595, loss_ce: 0.010173
[02:19:30.991] iteration 19510 : loss : 0.056986, loss_ce: 0.021883
[02:19:31.299] iteration 19511 : loss : 0.046041, loss_ce: 0.013069
[02:19:31.606] iteration 19512 : loss : 0.058827, loss_ce: 0.013197
[02:19:31.912] iteration 19513 : loss : 0.035924, loss_ce: 0.013855
[02:19:32.217] iteration 19514 : loss : 0.055642, loss_ce: 0.019583
[02:19:32.526] iteration 19515 : loss : 0.047915, loss_ce: 0.020675
[02:19:32.833] iteration 19516 : loss : 0.098810, loss_ce: 0.014478
[02:19:33.143] iteration 19517 : loss : 0.035802, loss_ce: 0.008645
[02:19:33.450] iteration 19518 : loss : 0.039553, loss_ce: 0.010819
[02:19:33.759] iteration 19519 : loss : 0.045322, loss_ce: 0.014307
[02:19:34.070] iteration 19520 : loss : 0.105220, loss_ce: 0.009137
[02:19:34.387] iteration 19521 : loss : 0.040565, loss_ce: 0.016431
[02:19:34.691] iteration 19522 : loss : 0.046376, loss_ce: 0.015805
[02:19:35.000] iteration 19523 : loss : 0.041797, loss_ce: 0.016822
[02:19:35.308] iteration 19524 : loss : 0.036481, loss_ce: 0.009560
[02:19:35.616] iteration 19525 : loss : 0.044722, loss_ce: 0.006786
[02:19:35.926] iteration 19526 : loss : 0.103773, loss_ce: 0.015837
[02:19:36.231] iteration 19527 : loss : 0.038528, loss_ce: 0.012305
[02:19:36.544] iteration 19528 : loss : 0.030340, loss_ce: 0.011232
[02:19:36.851] iteration 19529 : loss : 0.039453, loss_ce: 0.013519
[02:19:37.162] iteration 19530 : loss : 0.069777, loss_ce: 0.010042
[02:19:37.471] iteration 19531 : loss : 0.041709, loss_ce: 0.013658
[02:19:37.781] iteration 19532 : loss : 0.043384, loss_ce: 0.018358
[02:19:38.089] iteration 19533 : loss : 0.050250, loss_ce: 0.011376
[02:19:38.398] iteration 19534 : loss : 0.047475, loss_ce: 0.018947
[02:19:38.702] iteration 19535 : loss : 0.038712, loss_ce: 0.010812
[02:19:39.011] iteration 19536 : loss : 0.107117, loss_ce: 0.014661
[02:19:39.316] iteration 19537 : loss : 0.063716, loss_ce: 0.011412
[02:19:39.617] iteration 19538 : loss : 0.043428, loss_ce: 0.007351
[02:19:39.921] iteration 19539 : loss : 0.111746, loss_ce: 0.009824
[02:19:40.224] iteration 19540 : loss : 0.044651, loss_ce: 0.009292
[02:19:40.542] iteration 19541 : loss : 0.050083, loss_ce: 0.012476
[02:19:40.845] iteration 19542 : loss : 0.096166, loss_ce: 0.011204
[02:19:41.150] iteration 19543 : loss : 0.043298, loss_ce: 0.008032
[02:19:41.458] iteration 19544 : loss : 0.103078, loss_ce: 0.008443
[02:19:41.758] iteration 19545 : loss : 0.048524, loss_ce: 0.008710
[02:19:42.060] iteration 19546 : loss : 0.043262, loss_ce: 0.017152
[02:19:42.362] iteration 19547 : loss : 0.036914, loss_ce: 0.016311
[02:19:42.666] iteration 19548 : loss : 0.049976, loss_ce: 0.011166
[02:19:42.966] iteration 19549 : loss : 0.047301, loss_ce: 0.013879
[02:19:43.274] iteration 19550 : loss : 0.040711, loss_ce: 0.010340
[02:19:43.576] iteration 19551 : loss : 0.043593, loss_ce: 0.019674
[02:19:43.880] iteration 19552 : loss : 0.050454, loss_ce: 0.008771
[02:19:44.181] iteration 19553 : loss : 0.057920, loss_ce: 0.013184
[02:19:44.489] iteration 19554 : loss : 0.040679, loss_ce: 0.009944
[02:19:44.793] iteration 19555 : loss : 0.040961, loss_ce: 0.013126
[02:19:45.097] iteration 19556 : loss : 0.105074, loss_ce: 0.013617
[02:19:45.399] iteration 19557 : loss : 0.101300, loss_ce: 0.010732
[02:19:45.700] iteration 19558 : loss : 0.045982, loss_ce: 0.012408
[02:19:46.004] iteration 19559 : loss : 0.033539, loss_ce: 0.009116
[02:19:46.307] iteration 19560 : loss : 0.040671, loss_ce: 0.013521
[02:19:46.622] iteration 19561 : loss : 0.059777, loss_ce: 0.011879
[02:19:46.924] iteration 19562 : loss : 0.041664, loss_ce: 0.014225
[02:19:47.230] iteration 19563 : loss : 0.048220, loss_ce: 0.019435
[02:19:47.536] iteration 19564 : loss : 0.039263, loss_ce: 0.015925
[02:19:47.839] iteration 19565 : loss : 0.050851, loss_ce: 0.017530
[02:19:48.145] iteration 19566 : loss : 0.040515, loss_ce: 0.012877
[02:19:48.450] iteration 19567 : loss : 0.039507, loss_ce: 0.010164
[02:19:48.753] iteration 19568 : loss : 0.044593, loss_ce: 0.013008
[02:19:49.054] iteration 19569 : loss : 0.035517, loss_ce: 0.014820
[02:19:49.361] iteration 19570 : loss : 0.050194, loss_ce: 0.017927
[02:19:49.669] iteration 19571 : loss : 0.041882, loss_ce: 0.019453
[02:19:49.974] iteration 19572 : loss : 0.116719, loss_ce: 0.013946
[02:19:50.276] iteration 19573 : loss : 0.043986, loss_ce: 0.011086
[02:19:50.580] iteration 19574 : loss : 0.043351, loss_ce: 0.013723
[02:19:50.882] iteration 19575 : loss : 0.045869, loss_ce: 0.006976
[02:19:51.183] iteration 19576 : loss : 0.067657, loss_ce: 0.012971
[02:19:51.484] iteration 19577 : loss : 0.050491, loss_ce: 0.013393
[02:19:51.787] iteration 19578 : loss : 0.039926, loss_ce: 0.013417
[02:19:52.090] iteration 19579 : loss : 0.033526, loss_ce: 0.011626
[02:19:52.399] iteration 19580 : loss : 0.048024, loss_ce: 0.016034
[02:19:52.721] iteration 19581 : loss : 0.160601, loss_ce: 0.007569
[02:19:53.028] iteration 19582 : loss : 0.043300, loss_ce: 0.017783
[02:19:53.342] iteration 19583 : loss : 0.037025, loss_ce: 0.013577
[02:19:53.653] iteration 19584 : loss : 0.088775, loss_ce: 0.019060
[02:19:53.964] iteration 19585 : loss : 0.105755, loss_ce: 0.011260
[02:19:54.273] iteration 19586 : loss : 0.043679, loss_ce: 0.014082
[02:19:54.583] iteration 19587 : loss : 0.043284, loss_ce: 0.017363
[02:19:54.890] iteration 19588 : loss : 0.047587, loss_ce: 0.007968
[02:19:55.197] iteration 19589 : loss : 0.040760, loss_ce: 0.013686
[02:19:55.501] iteration 19590 : loss : 0.036222, loss_ce: 0.010625
[02:19:55.809] iteration 19591 : loss : 0.042278, loss_ce: 0.009486
[02:19:56.115] iteration 19592 : loss : 0.163984, loss_ce: 0.006386
[02:19:56.422] iteration 19593 : loss : 0.044990, loss_ce: 0.017070
[02:19:56.731] iteration 19594 : loss : 0.104238, loss_ce: 0.005305
[02:19:57.038] iteration 19595 : loss : 0.056697, loss_ce: 0.017872
[02:19:57.345] iteration 19596 : loss : 0.045661, loss_ce: 0.019580
[02:19:57.654] iteration 19597 : loss : 0.048139, loss_ce: 0.021418
[02:19:57.962] iteration 19598 : loss : 0.058875, loss_ce: 0.015163
[02:19:58.046] iteration 19599 : loss : 0.292747, loss_ce: 0.009955
[02:20:15.327] iteration 19600 : loss : 0.047578, loss_ce: 0.012854
[02:20:15.645] iteration 19601 : loss : 0.108722, loss_ce: 0.015153
[02:20:15.945] iteration 19602 : loss : 0.048024, loss_ce: 0.014993
[02:20:16.246] iteration 19603 : loss : 0.043042, loss_ce: 0.016924
[02:20:16.548] iteration 19604 : loss : 0.041829, loss_ce: 0.011165
[02:20:16.849] iteration 19605 : loss : 0.056438, loss_ce: 0.012765
[02:20:17.149] iteration 19606 : loss : 0.037054, loss_ce: 0.014762
[02:20:17.454] iteration 19607 : loss : 0.047503, loss_ce: 0.020736
[02:20:17.755] iteration 19608 : loss : 0.040604, loss_ce: 0.010467
[02:20:18.060] iteration 19609 : loss : 0.044659, loss_ce: 0.012368
[02:20:18.361] iteration 19610 : loss : 0.050622, loss_ce: 0.018327
[02:20:18.664] iteration 19611 : loss : 0.035246, loss_ce: 0.013410
[02:20:18.970] iteration 19612 : loss : 0.049143, loss_ce: 0.014882
[02:20:19.270] iteration 19613 : loss : 0.046467, loss_ce: 0.013580
[02:20:19.569] iteration 19614 : loss : 0.044382, loss_ce: 0.009821
[02:20:19.871] iteration 19615 : loss : 0.046785, loss_ce: 0.010770
[02:20:20.172] iteration 19616 : loss : 0.040384, loss_ce: 0.008202
[02:20:20.475] iteration 19617 : loss : 0.042369, loss_ce: 0.011106
[02:20:20.781] iteration 19618 : loss : 0.049974, loss_ce: 0.017329
[02:20:21.084] iteration 19619 : loss : 0.051164, loss_ce: 0.010048
[02:20:21.385] iteration 19620 : loss : 0.050662, loss_ce: 0.018701
[02:20:21.702] iteration 19621 : loss : 0.063201, loss_ce: 0.014496
[02:20:22.002] iteration 19622 : loss : 0.037750, loss_ce: 0.016386
[02:20:22.308] iteration 19623 : loss : 0.098565, loss_ce: 0.006884
[02:20:22.617] iteration 19624 : loss : 0.041595, loss_ce: 0.009937
[02:20:22.926] iteration 19625 : loss : 0.217942, loss_ce: 0.003806
[02:20:23.232] iteration 19626 : loss : 0.035750, loss_ce: 0.011431
[02:20:23.541] iteration 19627 : loss : 0.049114, loss_ce: 0.010483
[02:20:23.849] iteration 19628 : loss : 0.100034, loss_ce: 0.008565
[02:20:24.152] iteration 19629 : loss : 0.038492, loss_ce: 0.015151
[02:20:24.453] iteration 19630 : loss : 0.051413, loss_ce: 0.012054
[02:20:24.754] iteration 19631 : loss : 0.039278, loss_ce: 0.014742
[02:20:25.054] iteration 19632 : loss : 0.049834, loss_ce: 0.025214
[02:20:25.356] iteration 19633 : loss : 0.102014, loss_ce: 0.010596
[02:20:25.659] iteration 19634 : loss : 0.100875, loss_ce: 0.008214
[02:20:25.966] iteration 19635 : loss : 0.042422, loss_ce: 0.013407
[02:20:26.269] iteration 19636 : loss : 0.069430, loss_ce: 0.009089
[02:20:26.568] iteration 19637 : loss : 0.039217, loss_ce: 0.010854
[02:20:26.870] iteration 19638 : loss : 0.216142, loss_ce: 0.005174
[02:20:27.169] iteration 19639 : loss : 0.036880, loss_ce: 0.012583
[02:20:27.469] iteration 19640 : loss : 0.051610, loss_ce: 0.019004
[02:20:27.786] iteration 19641 : loss : 0.041358, loss_ce: 0.016867
[02:20:28.087] iteration 19642 : loss : 0.124271, loss_ce: 0.006994
[02:20:28.389] iteration 19643 : loss : 0.043072, loss_ce: 0.015913
[02:20:28.693] iteration 19644 : loss : 0.048324, loss_ce: 0.008864
[02:20:28.994] iteration 19645 : loss : 0.042822, loss_ce: 0.024073
[02:20:29.296] iteration 19646 : loss : 0.038396, loss_ce: 0.011535
[02:20:29.599] iteration 19647 : loss : 0.046500, loss_ce: 0.008708
[02:20:29.901] iteration 19648 : loss : 0.110264, loss_ce: 0.006376
[02:20:30.204] iteration 19649 : loss : 0.041998, loss_ce: 0.017518
[02:20:30.504] iteration 19650 : loss : 0.044932, loss_ce: 0.011485
[02:20:30.808] iteration 19651 : loss : 0.129251, loss_ce: 0.008356
[02:20:31.108] iteration 19652 : loss : 0.115493, loss_ce: 0.014001
[02:20:31.408] iteration 19653 : loss : 0.099639, loss_ce: 0.007730
[02:20:31.709] iteration 19654 : loss : 0.034242, loss_ce: 0.009026
[02:20:32.011] iteration 19655 : loss : 0.030107, loss_ce: 0.009146
[02:20:32.315] iteration 19656 : loss : 0.043886, loss_ce: 0.015892
[02:20:32.618] iteration 19657 : loss : 0.042833, loss_ce: 0.013430
[02:20:32.921] iteration 19658 : loss : 0.100924, loss_ce: 0.013569
[02:20:33.224] iteration 19659 : loss : 0.097907, loss_ce: 0.013124
[02:20:33.528] iteration 19660 : loss : 0.047665, loss_ce: 0.023456
[02:20:33.846] iteration 19661 : loss : 0.040165, loss_ce: 0.019323
[02:20:34.149] iteration 19662 : loss : 0.042167, loss_ce: 0.015750
[02:20:34.454] iteration 19663 : loss : 0.036089, loss_ce: 0.016641
[02:20:34.752] iteration 19664 : loss : 0.051872, loss_ce: 0.015202
[02:20:35.058] iteration 19665 : loss : 0.102937, loss_ce: 0.009109
[02:20:35.358] iteration 19666 : loss : 0.043739, loss_ce: 0.010829
[02:20:35.662] iteration 19667 : loss : 0.118583, loss_ce: 0.007399
[02:20:35.964] iteration 19668 : loss : 0.094642, loss_ce: 0.007918
[02:20:36.267] iteration 19669 : loss : 0.044374, loss_ce: 0.011454
[02:20:36.576] iteration 19670 : loss : 0.046520, loss_ce: 0.021010
[02:20:36.878] iteration 19671 : loss : 0.096261, loss_ce: 0.010460
[02:20:37.179] iteration 19672 : loss : 0.110440, loss_ce: 0.020934
[02:20:37.485] iteration 19673 : loss : 0.050752, loss_ce: 0.017711
[02:20:37.792] iteration 19674 : loss : 0.037493, loss_ce: 0.011085
[02:20:38.098] iteration 19675 : loss : 0.039977, loss_ce: 0.016459
[02:20:38.402] iteration 19676 : loss : 0.090170, loss_ce: 0.005262
[02:20:38.710] iteration 19677 : loss : 0.280013, loss_ce: 0.002130
[02:20:39.011] iteration 19678 : loss : 0.050451, loss_ce: 0.011526
[02:20:39.315] iteration 19679 : loss : 0.038585, loss_ce: 0.013082
[02:20:39.621] iteration 19680 : loss : 0.038822, loss_ce: 0.009209
[02:20:39.947] iteration 19681 : loss : 0.055129, loss_ce: 0.011359
[02:20:40.256] iteration 19682 : loss : 0.168100, loss_ce: 0.009691
[02:20:40.560] iteration 19683 : loss : 0.037817, loss_ce: 0.011692
[02:20:40.867] iteration 19684 : loss : 0.037099, loss_ce: 0.013237
[02:20:41.173] iteration 19685 : loss : 0.033388, loss_ce: 0.018080
[02:20:41.480] iteration 19686 : loss : 0.098243, loss_ce: 0.005355
[02:20:41.786] iteration 19687 : loss : 0.052677, loss_ce: 0.017928
[02:20:42.091] iteration 19688 : loss : 0.041951, loss_ce: 0.012971
[02:20:42.404] iteration 19689 : loss : 0.041594, loss_ce: 0.013008
[02:20:42.708] iteration 19690 : loss : 0.037880, loss_ce: 0.012493
[02:20:43.016] iteration 19691 : loss : 0.156434, loss_ce: 0.004781
[02:20:43.322] iteration 19692 : loss : 0.107631, loss_ce: 0.010129
[02:20:43.628] iteration 19693 : loss : 0.056521, loss_ce: 0.019013
[02:20:43.934] iteration 19694 : loss : 0.055299, loss_ce: 0.013380
[02:20:44.241] iteration 19695 : loss : 0.046481, loss_ce: 0.019329
[02:20:44.545] iteration 19696 : loss : 0.045175, loss_ce: 0.013276
[02:20:44.854] iteration 19697 : loss : 0.041891, loss_ce: 0.022796
[02:20:45.164] iteration 19698 : loss : 0.046974, loss_ce: 0.017460
[02:20:45.470] iteration 19699 : loss : 0.051722, loss_ce: 0.011027
[02:20:45.777] iteration 19700 : loss : 0.049506, loss_ce: 0.010865
[02:20:46.100] iteration 19701 : loss : 0.050470, loss_ce: 0.016433
[02:20:46.406] iteration 19702 : loss : 0.037509, loss_ce: 0.014139
[02:20:46.715] iteration 19703 : loss : 0.079428, loss_ce: 0.013242
[02:20:47.021] iteration 19704 : loss : 0.040217, loss_ce: 0.015966
[02:20:47.326] iteration 19705 : loss : 0.052037, loss_ce: 0.011224
[02:20:47.636] iteration 19706 : loss : 0.040541, loss_ce: 0.012324
[02:20:47.942] iteration 19707 : loss : 0.044378, loss_ce: 0.020990
[02:20:48.245] iteration 19708 : loss : 0.103685, loss_ce: 0.011766
[02:20:48.551] iteration 19709 : loss : 0.040059, loss_ce: 0.013747
[02:20:48.858] iteration 19710 : loss : 0.037443, loss_ce: 0.009060
[02:20:49.164] iteration 19711 : loss : 0.103817, loss_ce: 0.013621
[02:20:49.471] iteration 19712 : loss : 0.103998, loss_ce: 0.008583
[02:20:49.779] iteration 19713 : loss : 0.052111, loss_ce: 0.013695
[02:20:50.086] iteration 19714 : loss : 0.039774, loss_ce: 0.015621
[02:20:50.400] iteration 19715 : loss : 0.059923, loss_ce: 0.021188
[02:20:50.709] iteration 19716 : loss : 0.039324, loss_ce: 0.011454
[02:20:51.017] iteration 19717 : loss : 0.053534, loss_ce: 0.015191
[02:20:51.326] iteration 19718 : loss : 0.047887, loss_ce: 0.011585
[02:20:51.638] iteration 19719 : loss : 0.045760, loss_ce: 0.019071
[02:20:51.947] iteration 19720 : loss : 0.041466, loss_ce: 0.017294
[02:20:52.273] iteration 19721 : loss : 0.047619, loss_ce: 0.012378
[02:20:52.588] iteration 19722 : loss : 0.097027, loss_ce: 0.006925
[02:20:52.904] iteration 19723 : loss : 0.049926, loss_ce: 0.016827
[02:20:53.216] iteration 19724 : loss : 0.040221, loss_ce: 0.012521
[02:20:53.528] iteration 19725 : loss : 0.053242, loss_ce: 0.010889
[02:20:53.840] iteration 19726 : loss : 0.113467, loss_ce: 0.005005
[02:20:54.159] iteration 19727 : loss : 0.107866, loss_ce: 0.014426
[02:20:54.470] iteration 19728 : loss : 0.052020, loss_ce: 0.021582
[02:20:54.781] iteration 19729 : loss : 0.039919, loss_ce: 0.013780
[02:20:55.095] iteration 19730 : loss : 0.046665, loss_ce: 0.008922
[02:20:55.403] iteration 19731 : loss : 0.043164, loss_ce: 0.012714
[02:20:55.716] iteration 19732 : loss : 0.106262, loss_ce: 0.008204
[02:20:56.032] iteration 19733 : loss : 0.049817, loss_ce: 0.017784
[02:20:56.341] iteration 19734 : loss : 0.044498, loss_ce: 0.012864
[02:20:56.650] iteration 19735 : loss : 0.034179, loss_ce: 0.009057
[02:20:56.964] iteration 19736 : loss : 0.041531, loss_ce: 0.011425
[02:20:57.278] iteration 19737 : loss : 0.041655, loss_ce: 0.008396
[02:20:57.360] iteration 19738 : loss : 0.126718, loss_ce: 0.014511
[02:21:14.412] iteration 19739 : loss : 0.048334, loss_ce: 0.008565
[02:21:14.717] iteration 19740 : loss : 0.055923, loss_ce: 0.013601
[02:21:15.030] iteration 19741 : loss : 0.043258, loss_ce: 0.016567
[02:21:15.330] iteration 19742 : loss : 0.043554, loss_ce: 0.010652
[02:21:15.633] iteration 19743 : loss : 0.045193, loss_ce: 0.025493
[02:21:15.934] iteration 19744 : loss : 0.157093, loss_ce: 0.012569
[02:21:16.244] iteration 19745 : loss : 0.044632, loss_ce: 0.015550
[02:21:16.550] iteration 19746 : loss : 0.043968, loss_ce: 0.013672
[02:21:16.853] iteration 19747 : loss : 0.036681, loss_ce: 0.008516
[02:21:17.157] iteration 19748 : loss : 0.098637, loss_ce: 0.007886
[02:21:17.461] iteration 19749 : loss : 0.094554, loss_ce: 0.005941
[02:21:17.764] iteration 19750 : loss : 0.043206, loss_ce: 0.012095
[02:21:18.066] iteration 19751 : loss : 0.038929, loss_ce: 0.015565
[02:21:18.368] iteration 19752 : loss : 0.051171, loss_ce: 0.010335
[02:21:18.673] iteration 19753 : loss : 0.044066, loss_ce: 0.015080
[02:21:18.973] iteration 19754 : loss : 0.040336, loss_ce: 0.009598
[02:21:19.272] iteration 19755 : loss : 0.035141, loss_ce: 0.010044
[02:21:19.579] iteration 19756 : loss : 0.057297, loss_ce: 0.011900
[02:21:19.879] iteration 19757 : loss : 0.096370, loss_ce: 0.008165
[02:21:20.181] iteration 19758 : loss : 0.036897, loss_ce: 0.017796
[02:21:20.484] iteration 19759 : loss : 0.047386, loss_ce: 0.021843
[02:21:20.782] iteration 19760 : loss : 0.047382, loss_ce: 0.018305
[02:21:21.100] iteration 19761 : loss : 0.038203, loss_ce: 0.011810
[02:21:21.401] iteration 19762 : loss : 0.053202, loss_ce: 0.014323
[02:21:21.706] iteration 19763 : loss : 0.040787, loss_ce: 0.012793
[02:21:22.008] iteration 19764 : loss : 0.161704, loss_ce: 0.005879
[02:21:22.311] iteration 19765 : loss : 0.101739, loss_ce: 0.014704
[02:21:22.614] iteration 19766 : loss : 0.043797, loss_ce: 0.021024
[02:21:22.913] iteration 19767 : loss : 0.049757, loss_ce: 0.015138
[02:21:23.221] iteration 19768 : loss : 0.101006, loss_ce: 0.010711
[02:21:23.522] iteration 19769 : loss : 0.038962, loss_ce: 0.013841
[02:21:23.828] iteration 19770 : loss : 0.043708, loss_ce: 0.012696
[02:21:24.130] iteration 19771 : loss : 0.099093, loss_ce: 0.010991
[02:21:24.432] iteration 19772 : loss : 0.046482, loss_ce: 0.007437
[02:21:24.738] iteration 19773 : loss : 0.060277, loss_ce: 0.016358
[02:21:25.038] iteration 19774 : loss : 0.040652, loss_ce: 0.013754
[02:21:25.340] iteration 19775 : loss : 0.045711, loss_ce: 0.009537
[02:21:25.643] iteration 19776 : loss : 0.034658, loss_ce: 0.011382
[02:21:25.946] iteration 19777 : loss : 0.042530, loss_ce: 0.018178
[02:21:26.249] iteration 19778 : loss : 0.047485, loss_ce: 0.019852
[02:21:26.557] iteration 19779 : loss : 0.047396, loss_ce: 0.022228
[02:21:26.858] iteration 19780 : loss : 0.108376, loss_ce: 0.011313
[02:21:27.177] iteration 19781 : loss : 0.043895, loss_ce: 0.022319
[02:21:27.484] iteration 19782 : loss : 0.044843, loss_ce: 0.013958
[02:21:27.790] iteration 19783 : loss : 0.097195, loss_ce: 0.006975
[02:21:28.095] iteration 19784 : loss : 0.049864, loss_ce: 0.022225
[02:21:28.403] iteration 19785 : loss : 0.038360, loss_ce: 0.010551
[02:21:28.715] iteration 19786 : loss : 0.048629, loss_ce: 0.014339
[02:21:29.019] iteration 19787 : loss : 0.040547, loss_ce: 0.012596
[02:21:29.324] iteration 19788 : loss : 0.048592, loss_ce: 0.021138
[02:21:29.632] iteration 19789 : loss : 0.100199, loss_ce: 0.009740
[02:21:29.938] iteration 19790 : loss : 0.052651, loss_ce: 0.012801
[02:21:30.244] iteration 19791 : loss : 0.046146, loss_ce: 0.015614
[02:21:30.556] iteration 19792 : loss : 0.053994, loss_ce: 0.010848
[02:21:30.865] iteration 19793 : loss : 0.044168, loss_ce: 0.017293
[02:21:31.172] iteration 19794 : loss : 0.099945, loss_ce: 0.011311
[02:21:31.481] iteration 19795 : loss : 0.043775, loss_ce: 0.008247
[02:21:31.786] iteration 19796 : loss : 0.041854, loss_ce: 0.016696
[02:21:32.098] iteration 19797 : loss : 0.099723, loss_ce: 0.010060
[02:21:32.406] iteration 19798 : loss : 0.036619, loss_ce: 0.006613
[02:21:32.712] iteration 19799 : loss : 0.100316, loss_ce: 0.008361
[02:21:33.019] iteration 19800 : loss : 0.033077, loss_ce: 0.007135
[02:21:33.344] iteration 19801 : loss : 0.105950, loss_ce: 0.011822
[02:21:33.650] iteration 19802 : loss : 0.050261, loss_ce: 0.009070
[02:21:33.963] iteration 19803 : loss : 0.050605, loss_ce: 0.011848
[02:21:34.267] iteration 19804 : loss : 0.098103, loss_ce: 0.006996
[02:21:34.570] iteration 19805 : loss : 0.043557, loss_ce: 0.009805
[02:21:34.879] iteration 19806 : loss : 0.044635, loss_ce: 0.014506
[02:21:35.187] iteration 19807 : loss : 0.035757, loss_ce: 0.011297
[02:21:35.496] iteration 19808 : loss : 0.068908, loss_ce: 0.016062
[02:21:35.804] iteration 19809 : loss : 0.046548, loss_ce: 0.013385
[02:21:36.113] iteration 19810 : loss : 0.101587, loss_ce: 0.006769
[02:21:36.420] iteration 19811 : loss : 0.037275, loss_ce: 0.017714
[02:21:36.725] iteration 19812 : loss : 0.059662, loss_ce: 0.011562
[02:21:37.035] iteration 19813 : loss : 0.043755, loss_ce: 0.020154
[02:21:37.343] iteration 19814 : loss : 0.040019, loss_ce: 0.007862
[02:21:37.649] iteration 19815 : loss : 0.040669, loss_ce: 0.013259
[02:21:37.958] iteration 19816 : loss : 0.108456, loss_ce: 0.015012
[02:21:38.265] iteration 19817 : loss : 0.106069, loss_ce: 0.011360
[02:21:38.571] iteration 19818 : loss : 0.040418, loss_ce: 0.014189
[02:21:38.880] iteration 19819 : loss : 0.045886, loss_ce: 0.018222
[02:21:39.188] iteration 19820 : loss : 0.046553, loss_ce: 0.019678
[02:21:39.513] iteration 19821 : loss : 0.043513, loss_ce: 0.010761
[02:21:39.822] iteration 19822 : loss : 0.039693, loss_ce: 0.006365
[02:21:40.134] iteration 19823 : loss : 0.037617, loss_ce: 0.015149
[02:21:40.444] iteration 19824 : loss : 0.074857, loss_ce: 0.010157
[02:21:40.750] iteration 19825 : loss : 0.055544, loss_ce: 0.015369
[02:21:41.055] iteration 19826 : loss : 0.053298, loss_ce: 0.018378
[02:21:41.365] iteration 19827 : loss : 0.033719, loss_ce: 0.005882
[02:21:41.671] iteration 19828 : loss : 0.053065, loss_ce: 0.010015
[02:21:41.984] iteration 19829 : loss : 0.104535, loss_ce: 0.009899
[02:21:42.290] iteration 19830 : loss : 0.052777, loss_ce: 0.015914
[02:21:42.599] iteration 19831 : loss : 0.046058, loss_ce: 0.010295
[02:21:42.906] iteration 19832 : loss : 0.047158, loss_ce: 0.022410
[02:21:43.211] iteration 19833 : loss : 0.052222, loss_ce: 0.017517
[02:21:43.521] iteration 19834 : loss : 0.037319, loss_ce: 0.012284
[02:21:43.828] iteration 19835 : loss : 0.045641, loss_ce: 0.017634
[02:21:44.140] iteration 19836 : loss : 0.084940, loss_ce: 0.014152
[02:21:44.447] iteration 19837 : loss : 0.038606, loss_ce: 0.009806
[02:21:44.761] iteration 19838 : loss : 0.101531, loss_ce: 0.009506
[02:21:45.072] iteration 19839 : loss : 0.043971, loss_ce: 0.021954
[02:21:45.380] iteration 19840 : loss : 0.036484, loss_ce: 0.009548
[02:21:45.696] iteration 19841 : loss : 0.049831, loss_ce: 0.016402
[02:21:46.003] iteration 19842 : loss : 0.050446, loss_ce: 0.007621
[02:21:46.314] iteration 19843 : loss : 0.049857, loss_ce: 0.010317
[02:21:46.620] iteration 19844 : loss : 0.045125, loss_ce: 0.018047
[02:21:46.928] iteration 19845 : loss : 0.037812, loss_ce: 0.009293
[02:21:47.238] iteration 19846 : loss : 0.038362, loss_ce: 0.014337
[02:21:47.548] iteration 19847 : loss : 0.040550, loss_ce: 0.011508
[02:21:47.854] iteration 19848 : loss : 0.103274, loss_ce: 0.012790
[02:21:48.160] iteration 19849 : loss : 0.045618, loss_ce: 0.011336
[02:21:48.471] iteration 19850 : loss : 0.159657, loss_ce: 0.006060
[02:21:48.778] iteration 19851 : loss : 0.110175, loss_ce: 0.011470
[02:21:49.086] iteration 19852 : loss : 0.042652, loss_ce: 0.011730
[02:21:49.391] iteration 19853 : loss : 0.051689, loss_ce: 0.009839
[02:21:49.697] iteration 19854 : loss : 0.048082, loss_ce: 0.010003
[02:21:49.999] iteration 19855 : loss : 0.046447, loss_ce: 0.009380
[02:21:50.306] iteration 19856 : loss : 0.052868, loss_ce: 0.008445
[02:21:50.612] iteration 19857 : loss : 0.156223, loss_ce: 0.007200
[02:21:50.916] iteration 19858 : loss : 0.050183, loss_ce: 0.009676
[02:21:51.219] iteration 19859 : loss : 0.048280, loss_ce: 0.009879
[02:21:51.520] iteration 19860 : loss : 0.056995, loss_ce: 0.010018
[02:21:51.841] iteration 19861 : loss : 0.044139, loss_ce: 0.011571
[02:21:52.143] iteration 19862 : loss : 0.037364, loss_ce: 0.011538
[02:21:52.449] iteration 19863 : loss : 0.034780, loss_ce: 0.014127
[02:21:52.759] iteration 19864 : loss : 0.036867, loss_ce: 0.008090
[02:21:53.065] iteration 19865 : loss : 0.053281, loss_ce: 0.014903
[02:21:53.369] iteration 19866 : loss : 0.049630, loss_ce: 0.012633
[02:21:53.678] iteration 19867 : loss : 0.046274, loss_ce: 0.011408
[02:21:53.984] iteration 19868 : loss : 0.034751, loss_ce: 0.013605
[02:21:54.291] iteration 19869 : loss : 0.047489, loss_ce: 0.014687
[02:21:54.595] iteration 19870 : loss : 0.044136, loss_ce: 0.016775
[02:21:54.904] iteration 19871 : loss : 0.050388, loss_ce: 0.013647
[02:21:55.210] iteration 19872 : loss : 0.035902, loss_ce: 0.010277
[02:21:55.519] iteration 19873 : loss : 0.045608, loss_ce: 0.013794
[02:21:55.826] iteration 19874 : loss : 0.097932, loss_ce: 0.009256
[02:21:56.133] iteration 19875 : loss : 0.055596, loss_ce: 0.022291
[02:21:56.441] iteration 19876 : loss : 0.043877, loss_ce: 0.016773
[02:21:56.520] iteration 19877 : loss : 0.287390, loss_ce: 0.017676
[02:22:16.009] iteration 19878 : loss : 0.040747, loss_ce: 0.017302
[02:22:16.312] iteration 19879 : loss : 0.049629, loss_ce: 0.015344
[02:22:16.609] iteration 19880 : loss : 0.041433, loss_ce: 0.017596
[02:22:16.926] iteration 19881 : loss : 0.033878, loss_ce: 0.009398
[02:22:17.232] iteration 19882 : loss : 0.044196, loss_ce: 0.011341
[02:22:17.536] iteration 19883 : loss : 0.048982, loss_ce: 0.009760
[02:22:17.844] iteration 19884 : loss : 0.104270, loss_ce: 0.015385
[02:22:18.153] iteration 19885 : loss : 0.041148, loss_ce: 0.012471
[02:22:18.464] iteration 19886 : loss : 0.038614, loss_ce: 0.015981
[02:22:18.772] iteration 19887 : loss : 0.049971, loss_ce: 0.012592
[02:22:19.082] iteration 19888 : loss : 0.107107, loss_ce: 0.009488
[02:22:19.388] iteration 19889 : loss : 0.045148, loss_ce: 0.017738
[02:22:19.689] iteration 19890 : loss : 0.046291, loss_ce: 0.012475
[02:22:19.992] iteration 19891 : loss : 0.067261, loss_ce: 0.023440
[02:22:20.297] iteration 19892 : loss : 0.033251, loss_ce: 0.007492
[02:22:20.601] iteration 19893 : loss : 0.106602, loss_ce: 0.013251
[02:22:20.902] iteration 19894 : loss : 0.084305, loss_ce: 0.015196
[02:22:21.203] iteration 19895 : loss : 0.044992, loss_ce: 0.017135
[02:22:21.505] iteration 19896 : loss : 0.062895, loss_ce: 0.009754
[02:22:21.809] iteration 19897 : loss : 0.035546, loss_ce: 0.010737
[02:22:22.111] iteration 19898 : loss : 0.047378, loss_ce: 0.017394
[02:22:22.415] iteration 19899 : loss : 0.052906, loss_ce: 0.012674
[02:22:22.718] iteration 19900 : loss : 0.037902, loss_ce: 0.010331
[02:22:23.035] iteration 19901 : loss : 0.044795, loss_ce: 0.011554
[02:22:23.338] iteration 19902 : loss : 0.035262, loss_ce: 0.011339
[02:22:23.642] iteration 19903 : loss : 0.034164, loss_ce: 0.018019
[02:22:23.946] iteration 19904 : loss : 0.048391, loss_ce: 0.025267
[02:22:24.249] iteration 19905 : loss : 0.048268, loss_ce: 0.015326
[02:22:24.550] iteration 19906 : loss : 0.044174, loss_ce: 0.008391
[02:22:24.856] iteration 19907 : loss : 0.045545, loss_ce: 0.011930
[02:22:25.159] iteration 19908 : loss : 0.033894, loss_ce: 0.012036
[02:22:25.462] iteration 19909 : loss : 0.045914, loss_ce: 0.016423
[02:22:25.762] iteration 19910 : loss : 0.044019, loss_ce: 0.012066
[02:22:26.066] iteration 19911 : loss : 0.040152, loss_ce: 0.006073
[02:22:26.366] iteration 19912 : loss : 0.033779, loss_ce: 0.009296
[02:22:26.667] iteration 19913 : loss : 0.044805, loss_ce: 0.014586
[02:22:26.973] iteration 19914 : loss : 0.115211, loss_ce: 0.009381
[02:22:27.277] iteration 19915 : loss : 0.037449, loss_ce: 0.012780
[02:22:27.580] iteration 19916 : loss : 0.041002, loss_ce: 0.006750
[02:22:27.883] iteration 19917 : loss : 0.063080, loss_ce: 0.018504
[02:22:28.188] iteration 19918 : loss : 0.037905, loss_ce: 0.012244
[02:22:28.489] iteration 19919 : loss : 0.104821, loss_ce: 0.020991
[02:22:28.793] iteration 19920 : loss : 0.036051, loss_ce: 0.014075
[02:22:29.111] iteration 19921 : loss : 0.034594, loss_ce: 0.009629
[02:22:29.414] iteration 19922 : loss : 0.058182, loss_ce: 0.021807
[02:22:29.714] iteration 19923 : loss : 0.044968, loss_ce: 0.011472
[02:22:30.020] iteration 19924 : loss : 0.041329, loss_ce: 0.010314
[02:22:30.322] iteration 19925 : loss : 0.042672, loss_ce: 0.005339
[02:22:30.630] iteration 19926 : loss : 0.098750, loss_ce: 0.010732
[02:22:30.938] iteration 19927 : loss : 0.051798, loss_ce: 0.020176
[02:22:31.243] iteration 19928 : loss : 0.058016, loss_ce: 0.016810
[02:22:31.547] iteration 19929 : loss : 0.040805, loss_ce: 0.018000
[02:22:31.852] iteration 19930 : loss : 0.069721, loss_ce: 0.007505
[02:22:32.153] iteration 19931 : loss : 0.096654, loss_ce: 0.009027
[02:22:32.467] iteration 19932 : loss : 0.046448, loss_ce: 0.020764
[02:22:32.770] iteration 19933 : loss : 0.056512, loss_ce: 0.011948
[02:22:33.081] iteration 19934 : loss : 0.049485, loss_ce: 0.017898
[02:22:33.389] iteration 19935 : loss : 0.040306, loss_ce: 0.018519
[02:22:33.700] iteration 19936 : loss : 0.063664, loss_ce: 0.016855
[02:22:34.008] iteration 19937 : loss : 0.053112, loss_ce: 0.014036
[02:22:34.314] iteration 19938 : loss : 0.160339, loss_ce: 0.009218
[02:22:34.619] iteration 19939 : loss : 0.042352, loss_ce: 0.015753
[02:22:34.923] iteration 19940 : loss : 0.054678, loss_ce: 0.013375
[02:22:35.241] iteration 19941 : loss : 0.037816, loss_ce: 0.009189
[02:22:35.544] iteration 19942 : loss : 0.095620, loss_ce: 0.004266
[02:22:35.846] iteration 19943 : loss : 0.100454, loss_ce: 0.008857
[02:22:36.145] iteration 19944 : loss : 0.046009, loss_ce: 0.017118
[02:22:36.450] iteration 19945 : loss : 0.044680, loss_ce: 0.005862
[02:22:36.755] iteration 19946 : loss : 0.118651, loss_ce: 0.010767
[02:22:37.062] iteration 19947 : loss : 0.043618, loss_ce: 0.018152
[02:22:37.365] iteration 19948 : loss : 0.043983, loss_ce: 0.012588
[02:22:37.668] iteration 19949 : loss : 0.093645, loss_ce: 0.007006
[02:22:37.970] iteration 19950 : loss : 0.111389, loss_ce: 0.012051
[02:22:38.274] iteration 19951 : loss : 0.054649, loss_ce: 0.012379
[02:22:38.577] iteration 19952 : loss : 0.039912, loss_ce: 0.010401
[02:22:38.881] iteration 19953 : loss : 0.045696, loss_ce: 0.016315
[02:22:39.185] iteration 19954 : loss : 0.105987, loss_ce: 0.013752
[02:22:39.483] iteration 19955 : loss : 0.040771, loss_ce: 0.018140
[02:22:39.784] iteration 19956 : loss : 0.100741, loss_ce: 0.007679
[02:22:40.087] iteration 19957 : loss : 0.045583, loss_ce: 0.013701
[02:22:40.388] iteration 19958 : loss : 0.037005, loss_ce: 0.009783
[02:22:40.694] iteration 19959 : loss : 0.168924, loss_ce: 0.008970
[02:22:40.998] iteration 19960 : loss : 0.049980, loss_ce: 0.012032
[02:22:41.311] iteration 19961 : loss : 0.044252, loss_ce: 0.012499
[02:22:41.615] iteration 19962 : loss : 0.044218, loss_ce: 0.007759
[02:22:41.920] iteration 19963 : loss : 0.039936, loss_ce: 0.019032
[02:22:42.225] iteration 19964 : loss : 0.039050, loss_ce: 0.010749
[02:22:42.525] iteration 19965 : loss : 0.042702, loss_ce: 0.017687
[02:22:42.827] iteration 19966 : loss : 0.112285, loss_ce: 0.007983
[02:22:43.132] iteration 19967 : loss : 0.037370, loss_ce: 0.006972
[02:22:43.435] iteration 19968 : loss : 0.055571, loss_ce: 0.009597
[02:22:43.738] iteration 19969 : loss : 0.040982, loss_ce: 0.015116
[02:22:44.037] iteration 19970 : loss : 0.053479, loss_ce: 0.021454
[02:22:44.339] iteration 19971 : loss : 0.096219, loss_ce: 0.008751
[02:22:44.644] iteration 19972 : loss : 0.042101, loss_ce: 0.006396
[02:22:44.945] iteration 19973 : loss : 0.040222, loss_ce: 0.011769
[02:22:45.250] iteration 19974 : loss : 0.046784, loss_ce: 0.010699
[02:22:45.555] iteration 19975 : loss : 0.043134, loss_ce: 0.017539
[02:22:45.857] iteration 19976 : loss : 0.036538, loss_ce: 0.012070
[02:22:46.158] iteration 19977 : loss : 0.037510, loss_ce: 0.021277
[02:22:46.461] iteration 19978 : loss : 0.030434, loss_ce: 0.011402
[02:22:46.764] iteration 19979 : loss : 0.051885, loss_ce: 0.006418
[02:22:47.067] iteration 19980 : loss : 0.032509, loss_ce: 0.012444
[02:22:47.385] iteration 19981 : loss : 0.055936, loss_ce: 0.009793
[02:22:47.688] iteration 19982 : loss : 0.048247, loss_ce: 0.016033
[02:22:47.994] iteration 19983 : loss : 0.049825, loss_ce: 0.020835
[02:22:48.297] iteration 19984 : loss : 0.061001, loss_ce: 0.018641
[02:22:48.605] iteration 19985 : loss : 0.044537, loss_ce: 0.010090
[02:22:48.911] iteration 19986 : loss : 0.072762, loss_ce: 0.012954
[02:22:49.215] iteration 19987 : loss : 0.042757, loss_ce: 0.015280
[02:22:49.520] iteration 19988 : loss : 0.038893, loss_ce: 0.014471
[02:22:49.827] iteration 19989 : loss : 0.044794, loss_ce: 0.011860
[02:22:50.136] iteration 19990 : loss : 0.102333, loss_ce: 0.009287
[02:22:50.443] iteration 19991 : loss : 0.052033, loss_ce: 0.010289
[02:22:50.749] iteration 19992 : loss : 0.046489, loss_ce: 0.009989
[02:22:51.057] iteration 19993 : loss : 0.044223, loss_ce: 0.009064
[02:22:51.363] iteration 19994 : loss : 0.041198, loss_ce: 0.013499
[02:22:51.675] iteration 19995 : loss : 0.059863, loss_ce: 0.008493
[02:22:51.982] iteration 19996 : loss : 0.050050, loss_ce: 0.016946
[02:22:52.297] iteration 19997 : loss : 0.047105, loss_ce: 0.009416
[02:22:52.605] iteration 19998 : loss : 0.101953, loss_ce: 0.005917
[02:22:52.916] iteration 19999 : loss : 0.043285, loss_ce: 0.018555
[02:22:53.232] iteration 20000 : loss : 0.096671, loss_ce: 0.009174
[02:22:53.573] iteration 20001 : loss : 0.154126, loss_ce: 0.008723
[02:22:53.885] iteration 20002 : loss : 0.098656, loss_ce: 0.007090
[02:22:54.201] iteration 20003 : loss : 0.042261, loss_ce: 0.014438
[02:22:54.515] iteration 20004 : loss : 0.049603, loss_ce: 0.013591
[02:22:54.831] iteration 20005 : loss : 0.040108, loss_ce: 0.013538
[02:22:55.146] iteration 20006 : loss : 0.074581, loss_ce: 0.013927
[02:22:55.460] iteration 20007 : loss : 0.049945, loss_ce: 0.014021
[02:22:55.773] iteration 20008 : loss : 0.044964, loss_ce: 0.013200
[02:22:56.083] iteration 20009 : loss : 0.108538, loss_ce: 0.010474
[02:22:56.398] iteration 20010 : loss : 0.038630, loss_ce: 0.013231
[02:22:56.711] iteration 20011 : loss : 0.038890, loss_ce: 0.010310
[02:22:57.025] iteration 20012 : loss : 0.094424, loss_ce: 0.006765
[02:22:57.341] iteration 20013 : loss : 0.045961, loss_ce: 0.017808
[02:22:57.655] iteration 20014 : loss : 0.035499, loss_ce: 0.015961
[02:22:57.970] iteration 20015 : loss : 0.038550, loss_ce: 0.010685
[02:22:58.055] iteration 20016 : loss : 0.153850, loss_ce: 0.011208
[02:23:15.619] iteration 20017 : loss : 0.057764, loss_ce: 0.015213
[02:23:15.921] iteration 20018 : loss : 0.042926, loss_ce: 0.005833
[02:23:16.219] iteration 20019 : loss : 0.108068, loss_ce: 0.010597
[02:23:16.518] iteration 20020 : loss : 0.044644, loss_ce: 0.011083
[02:23:16.836] iteration 20021 : loss : 0.051370, loss_ce: 0.008600
[02:23:17.135] iteration 20022 : loss : 0.050881, loss_ce: 0.023826
[02:23:17.439] iteration 20023 : loss : 0.035396, loss_ce: 0.010253
[02:23:17.741] iteration 20024 : loss : 0.042560, loss_ce: 0.010656
[02:23:18.042] iteration 20025 : loss : 0.047848, loss_ce: 0.010272
[02:23:18.346] iteration 20026 : loss : 0.051847, loss_ce: 0.007660
[02:23:18.646] iteration 20027 : loss : 0.038548, loss_ce: 0.014478
[02:23:18.951] iteration 20028 : loss : 0.048783, loss_ce: 0.013471
[02:23:19.253] iteration 20029 : loss : 0.075995, loss_ce: 0.019880
[02:23:19.553] iteration 20030 : loss : 0.105666, loss_ce: 0.016529
[02:23:19.858] iteration 20031 : loss : 0.039279, loss_ce: 0.006269
[02:23:20.159] iteration 20032 : loss : 0.039910, loss_ce: 0.010525
[02:23:20.464] iteration 20033 : loss : 0.131794, loss_ce: 0.005718
[02:23:20.770] iteration 20034 : loss : 0.064505, loss_ce: 0.012849
[02:23:21.071] iteration 20035 : loss : 0.048571, loss_ce: 0.011003
[02:23:21.373] iteration 20036 : loss : 0.048933, loss_ce: 0.022084
[02:23:21.680] iteration 20037 : loss : 0.038231, loss_ce: 0.012135
[02:23:21.982] iteration 20038 : loss : 0.091220, loss_ce: 0.008561
[02:23:22.290] iteration 20039 : loss : 0.044087, loss_ce: 0.019579
[02:23:22.598] iteration 20040 : loss : 0.056031, loss_ce: 0.010573
[02:23:22.924] iteration 20041 : loss : 0.030479, loss_ce: 0.010425
[02:23:23.234] iteration 20042 : loss : 0.066223, loss_ce: 0.011108
[02:23:23.542] iteration 20043 : loss : 0.047212, loss_ce: 0.012325
[02:23:23.848] iteration 20044 : loss : 0.036343, loss_ce: 0.010506
[02:23:24.156] iteration 20045 : loss : 0.047418, loss_ce: 0.013969
[02:23:24.456] iteration 20046 : loss : 0.037586, loss_ce: 0.009899
[02:23:24.757] iteration 20047 : loss : 0.043890, loss_ce: 0.014171
[02:23:25.057] iteration 20048 : loss : 0.044288, loss_ce: 0.008482
[02:23:25.357] iteration 20049 : loss : 0.039568, loss_ce: 0.013406
[02:23:25.663] iteration 20050 : loss : 0.037565, loss_ce: 0.012679
[02:23:25.963] iteration 20051 : loss : 0.155497, loss_ce: 0.005728
[02:23:26.267] iteration 20052 : loss : 0.042516, loss_ce: 0.022222
[02:23:26.570] iteration 20053 : loss : 0.101602, loss_ce: 0.010601
[02:23:26.871] iteration 20054 : loss : 0.040432, loss_ce: 0.009516
[02:23:27.172] iteration 20055 : loss : 0.044961, loss_ce: 0.019176
[02:23:27.475] iteration 20056 : loss : 0.043371, loss_ce: 0.018297
[02:23:27.779] iteration 20057 : loss : 0.035149, loss_ce: 0.011103
[02:23:28.081] iteration 20058 : loss : 0.056351, loss_ce: 0.014544
[02:23:28.385] iteration 20059 : loss : 0.048053, loss_ce: 0.015755
[02:23:28.688] iteration 20060 : loss : 0.056690, loss_ce: 0.015442
[02:23:29.002] iteration 20061 : loss : 0.036953, loss_ce: 0.015567
[02:23:29.304] iteration 20062 : loss : 0.038801, loss_ce: 0.013918
[02:23:29.610] iteration 20063 : loss : 0.091286, loss_ce: 0.006674
[02:23:29.911] iteration 20064 : loss : 0.098589, loss_ce: 0.015734
[02:23:30.214] iteration 20065 : loss : 0.042564, loss_ce: 0.012582
[02:23:30.519] iteration 20066 : loss : 0.042733, loss_ce: 0.017694
[02:23:30.825] iteration 20067 : loss : 0.099143, loss_ce: 0.006830
[02:23:31.129] iteration 20068 : loss : 0.048574, loss_ce: 0.018387
[02:23:31.430] iteration 20069 : loss : 0.045694, loss_ce: 0.005719
[02:23:31.733] iteration 20070 : loss : 0.039723, loss_ce: 0.013922
[02:23:32.035] iteration 20071 : loss : 0.037257, loss_ce: 0.011012
[02:23:32.340] iteration 20072 : loss : 0.047071, loss_ce: 0.019164
[02:23:32.641] iteration 20073 : loss : 0.060042, loss_ce: 0.020690
[02:23:32.942] iteration 20074 : loss : 0.043070, loss_ce: 0.019883
[02:23:33.245] iteration 20075 : loss : 0.038745, loss_ce: 0.015475
[02:23:33.548] iteration 20076 : loss : 0.049200, loss_ce: 0.013805
[02:23:33.854] iteration 20077 : loss : 0.176502, loss_ce: 0.005801
[02:23:34.157] iteration 20078 : loss : 0.042869, loss_ce: 0.016492
[02:23:34.461] iteration 20079 : loss : 0.077039, loss_ce: 0.017564
[02:23:34.762] iteration 20080 : loss : 0.033154, loss_ce: 0.012817
[02:23:35.083] iteration 20081 : loss : 0.034168, loss_ce: 0.006724
[02:23:35.383] iteration 20082 : loss : 0.029671, loss_ce: 0.009810
[02:23:35.688] iteration 20083 : loss : 0.046089, loss_ce: 0.017518
[02:23:35.994] iteration 20084 : loss : 0.055314, loss_ce: 0.008878
[02:23:36.305] iteration 20085 : loss : 0.046249, loss_ce: 0.012505
[02:23:36.610] iteration 20086 : loss : 0.038178, loss_ce: 0.011537
[02:23:36.913] iteration 20087 : loss : 0.167012, loss_ce: 0.006197
[02:23:37.225] iteration 20088 : loss : 0.040426, loss_ce: 0.007832
[02:23:37.533] iteration 20089 : loss : 0.102192, loss_ce: 0.006260
[02:23:37.840] iteration 20090 : loss : 0.052094, loss_ce: 0.022838
[02:23:38.154] iteration 20091 : loss : 0.040389, loss_ce: 0.014148
[02:23:38.467] iteration 20092 : loss : 0.047475, loss_ce: 0.004490
[02:23:38.775] iteration 20093 : loss : 0.036600, loss_ce: 0.009065
[02:23:39.085] iteration 20094 : loss : 0.048096, loss_ce: 0.013312
[02:23:39.391] iteration 20095 : loss : 0.104569, loss_ce: 0.011444
[02:23:39.695] iteration 20096 : loss : 0.100961, loss_ce: 0.018809
[02:23:40.004] iteration 20097 : loss : 0.045579, loss_ce: 0.015647
[02:23:40.307] iteration 20098 : loss : 0.047396, loss_ce: 0.020485
[02:23:40.611] iteration 20099 : loss : 0.038806, loss_ce: 0.015792
[02:23:40.915] iteration 20100 : loss : 0.104017, loss_ce: 0.012415
[02:23:41.236] iteration 20101 : loss : 0.044155, loss_ce: 0.015931
[02:23:41.538] iteration 20102 : loss : 0.048214, loss_ce: 0.006880
[02:23:41.841] iteration 20103 : loss : 0.048973, loss_ce: 0.013106
[02:23:42.143] iteration 20104 : loss : 0.047905, loss_ce: 0.012712
[02:23:42.446] iteration 20105 : loss : 0.051539, loss_ce: 0.019592
[02:23:42.748] iteration 20106 : loss : 0.046690, loss_ce: 0.014733
[02:23:43.052] iteration 20107 : loss : 0.035694, loss_ce: 0.011953
[02:23:43.355] iteration 20108 : loss : 0.101912, loss_ce: 0.009593
[02:23:43.658] iteration 20109 : loss : 0.104744, loss_ce: 0.015367
[02:23:43.964] iteration 20110 : loss : 0.050021, loss_ce: 0.020451
[02:23:44.264] iteration 20111 : loss : 0.046833, loss_ce: 0.012547
[02:23:44.570] iteration 20112 : loss : 0.043977, loss_ce: 0.012922
[02:23:44.876] iteration 20113 : loss : 0.043822, loss_ce: 0.019196
[02:23:45.181] iteration 20114 : loss : 0.044279, loss_ce: 0.016166
[02:23:45.484] iteration 20115 : loss : 0.051542, loss_ce: 0.020167
[02:23:45.788] iteration 20116 : loss : 0.037129, loss_ce: 0.009193
[02:23:46.091] iteration 20117 : loss : 0.042727, loss_ce: 0.013451
[02:23:46.394] iteration 20118 : loss : 0.043500, loss_ce: 0.018617
[02:23:46.698] iteration 20119 : loss : 0.075968, loss_ce: 0.013098
[02:23:47.005] iteration 20120 : loss : 0.044548, loss_ce: 0.012908
[02:23:47.326] iteration 20121 : loss : 0.118340, loss_ce: 0.014125
[02:23:47.628] iteration 20122 : loss : 0.100824, loss_ce: 0.014118
[02:23:47.933] iteration 20123 : loss : 0.100871, loss_ce: 0.010512
[02:23:48.237] iteration 20124 : loss : 0.100967, loss_ce: 0.012643
[02:23:48.539] iteration 20125 : loss : 0.036100, loss_ce: 0.005451
[02:23:48.843] iteration 20126 : loss : 0.042373, loss_ce: 0.003788
[02:23:49.149] iteration 20127 : loss : 0.034397, loss_ce: 0.009988
[02:23:49.449] iteration 20128 : loss : 0.045245, loss_ce: 0.008067
[02:23:49.754] iteration 20129 : loss : 0.040650, loss_ce: 0.008417
[02:23:50.057] iteration 20130 : loss : 0.036950, loss_ce: 0.006934
[02:23:50.360] iteration 20131 : loss : 0.041014, loss_ce: 0.011319
[02:23:50.664] iteration 20132 : loss : 0.042301, loss_ce: 0.017484
[02:23:50.966] iteration 20133 : loss : 0.039380, loss_ce: 0.009696
[02:23:51.267] iteration 20134 : loss : 0.041860, loss_ce: 0.012622
[02:23:51.574] iteration 20135 : loss : 0.101295, loss_ce: 0.010353
[02:23:51.878] iteration 20136 : loss : 0.102097, loss_ce: 0.009120
[02:23:52.181] iteration 20137 : loss : 0.058795, loss_ce: 0.021844
[02:23:52.487] iteration 20138 : loss : 0.059469, loss_ce: 0.009326
[02:23:52.794] iteration 20139 : loss : 0.043817, loss_ce: 0.013287
[02:23:53.102] iteration 20140 : loss : 0.047414, loss_ce: 0.009640
[02:23:53.440] iteration 20141 : loss : 0.046228, loss_ce: 0.012410
[02:23:53.748] iteration 20142 : loss : 0.042339, loss_ce: 0.010230
[02:23:54.057] iteration 20143 : loss : 0.050863, loss_ce: 0.009136
[02:23:54.364] iteration 20144 : loss : 0.056683, loss_ce: 0.008761
[02:23:54.671] iteration 20145 : loss : 0.060864, loss_ce: 0.015533
[02:23:54.988] iteration 20146 : loss : 0.043016, loss_ce: 0.015806
[02:23:55.300] iteration 20147 : loss : 0.038031, loss_ce: 0.014837
[02:23:55.611] iteration 20148 : loss : 0.129605, loss_ce: 0.017912
[02:23:55.926] iteration 20149 : loss : 0.042247, loss_ce: 0.021094
[02:23:56.233] iteration 20150 : loss : 0.050489, loss_ce: 0.011849
[02:23:56.545] iteration 20151 : loss : 0.052787, loss_ce: 0.016653
[02:23:56.856] iteration 20152 : loss : 0.045271, loss_ce: 0.016713
[02:23:57.168] iteration 20153 : loss : 0.040873, loss_ce: 0.013629
[02:23:57.481] iteration 20154 : loss : 0.042894, loss_ce: 0.015064
[02:23:57.576] iteration 20155 : loss : 0.304464, loss_ce: 0.002145
[02:24:14.555] iteration 20156 : loss : 0.038867, loss_ce: 0.016635
[02:24:14.853] iteration 20157 : loss : 0.101960, loss_ce: 0.011676
[02:24:15.154] iteration 20158 : loss : 0.119268, loss_ce: 0.014392
[02:24:15.455] iteration 20159 : loss : 0.046521, loss_ce: 0.011130
[02:24:15.755] iteration 20160 : loss : 0.047739, loss_ce: 0.012830
[02:24:16.071] iteration 20161 : loss : 0.041613, loss_ce: 0.014324
[02:24:16.373] iteration 20162 : loss : 0.048639, loss_ce: 0.017065
[02:24:16.674] iteration 20163 : loss : 0.220894, loss_ce: 0.003642
[02:24:16.976] iteration 20164 : loss : 0.038239, loss_ce: 0.015159
[02:24:17.275] iteration 20165 : loss : 0.048411, loss_ce: 0.022648
[02:24:17.581] iteration 20166 : loss : 0.112605, loss_ce: 0.007609
[02:24:17.883] iteration 20167 : loss : 0.038657, loss_ce: 0.011250
[02:24:18.182] iteration 20168 : loss : 0.037785, loss_ce: 0.007613
[02:24:18.486] iteration 20169 : loss : 0.047272, loss_ce: 0.020656
[02:24:18.786] iteration 20170 : loss : 0.036418, loss_ce: 0.014683
[02:24:19.088] iteration 20171 : loss : 0.101060, loss_ce: 0.006165
[02:24:19.387] iteration 20172 : loss : 0.100761, loss_ce: 0.009953
[02:24:19.689] iteration 20173 : loss : 0.039164, loss_ce: 0.014690
[02:24:19.990] iteration 20174 : loss : 0.043814, loss_ce: 0.010053
[02:24:20.295] iteration 20175 : loss : 0.059594, loss_ce: 0.012156
[02:24:20.596] iteration 20176 : loss : 0.057181, loss_ce: 0.010393
[02:24:20.896] iteration 20177 : loss : 0.098993, loss_ce: 0.005124
[02:24:21.200] iteration 20178 : loss : 0.041344, loss_ce: 0.012258
[02:24:21.503] iteration 20179 : loss : 0.037861, loss_ce: 0.010850
[02:24:21.805] iteration 20180 : loss : 0.102199, loss_ce: 0.008949
[02:24:22.124] iteration 20181 : loss : 0.038866, loss_ce: 0.018039
[02:24:22.425] iteration 20182 : loss : 0.035898, loss_ce: 0.011344
[02:24:22.726] iteration 20183 : loss : 0.043542, loss_ce: 0.010586
[02:24:23.031] iteration 20184 : loss : 0.045857, loss_ce: 0.015010
[02:24:23.332] iteration 20185 : loss : 0.062602, loss_ce: 0.014335
[02:24:23.635] iteration 20186 : loss : 0.097910, loss_ce: 0.011456
[02:24:23.936] iteration 20187 : loss : 0.046908, loss_ce: 0.017987
[02:24:24.240] iteration 20188 : loss : 0.105138, loss_ce: 0.013552
[02:24:24.542] iteration 20189 : loss : 0.049462, loss_ce: 0.007981
[02:24:24.840] iteration 20190 : loss : 0.100456, loss_ce: 0.006530
[02:24:25.144] iteration 20191 : loss : 0.040950, loss_ce: 0.012425
[02:24:25.445] iteration 20192 : loss : 0.040500, loss_ce: 0.015468
[02:24:25.749] iteration 20193 : loss : 0.040569, loss_ce: 0.009470
[02:24:26.052] iteration 20194 : loss : 0.096219, loss_ce: 0.012492
[02:24:26.356] iteration 20195 : loss : 0.056720, loss_ce: 0.013469
[02:24:26.661] iteration 20196 : loss : 0.042553, loss_ce: 0.006114
[02:24:26.959] iteration 20197 : loss : 0.046682, loss_ce: 0.013123
[02:24:27.263] iteration 20198 : loss : 0.177535, loss_ce: 0.010624
[02:24:27.568] iteration 20199 : loss : 0.065281, loss_ce: 0.016487
[02:24:27.876] iteration 20200 : loss : 0.048211, loss_ce: 0.010600
[02:24:28.194] iteration 20201 : loss : 0.040655, loss_ce: 0.012538
[02:24:28.504] iteration 20202 : loss : 0.052559, loss_ce: 0.023694
[02:24:28.811] iteration 20203 : loss : 0.039881, loss_ce: 0.010242
[02:24:29.121] iteration 20204 : loss : 0.039130, loss_ce: 0.013960
[02:24:29.424] iteration 20205 : loss : 0.050305, loss_ce: 0.014859
[02:24:29.726] iteration 20206 : loss : 0.045068, loss_ce: 0.014043
[02:24:30.027] iteration 20207 : loss : 0.044718, loss_ce: 0.016316
[02:24:30.328] iteration 20208 : loss : 0.046229, loss_ce: 0.011483
[02:24:30.631] iteration 20209 : loss : 0.060486, loss_ce: 0.010107
[02:24:30.937] iteration 20210 : loss : 0.043982, loss_ce: 0.021448
[02:24:31.241] iteration 20211 : loss : 0.049544, loss_ce: 0.012667
[02:24:31.547] iteration 20212 : loss : 0.045311, loss_ce: 0.015111
[02:24:31.849] iteration 20213 : loss : 0.049477, loss_ce: 0.015344
[02:24:32.150] iteration 20214 : loss : 0.099039, loss_ce: 0.007553
[02:24:32.454] iteration 20215 : loss : 0.049366, loss_ce: 0.025168
[02:24:32.757] iteration 20216 : loss : 0.041528, loss_ce: 0.013670
[02:24:33.059] iteration 20217 : loss : 0.104409, loss_ce: 0.006929
[02:24:33.361] iteration 20218 : loss : 0.052956, loss_ce: 0.011731
[02:24:33.661] iteration 20219 : loss : 0.044403, loss_ce: 0.010318
[02:24:33.965] iteration 20220 : loss : 0.220914, loss_ce: 0.013067
[02:24:34.289] iteration 20221 : loss : 0.050813, loss_ce: 0.017689
[02:24:34.586] iteration 20222 : loss : 0.055893, loss_ce: 0.014700
[02:24:34.888] iteration 20223 : loss : 0.155916, loss_ce: 0.009080
[02:24:35.188] iteration 20224 : loss : 0.037233, loss_ce: 0.013201
[02:24:35.487] iteration 20225 : loss : 0.053249, loss_ce: 0.017952
[02:24:35.788] iteration 20226 : loss : 0.101725, loss_ce: 0.014077
[02:24:36.093] iteration 20227 : loss : 0.049391, loss_ce: 0.007195
[02:24:36.394] iteration 20228 : loss : 0.050709, loss_ce: 0.013445
[02:24:36.696] iteration 20229 : loss : 0.042632, loss_ce: 0.015114
[02:24:36.998] iteration 20230 : loss : 0.045486, loss_ce: 0.021920
[02:24:37.302] iteration 20231 : loss : 0.041240, loss_ce: 0.014432
[02:24:37.606] iteration 20232 : loss : 0.097227, loss_ce: 0.008344
[02:24:37.907] iteration 20233 : loss : 0.120816, loss_ce: 0.010259
[02:24:38.209] iteration 20234 : loss : 0.042143, loss_ce: 0.009322
[02:24:38.511] iteration 20235 : loss : 0.094335, loss_ce: 0.009395
[02:24:38.813] iteration 20236 : loss : 0.041039, loss_ce: 0.018138
[02:24:39.119] iteration 20237 : loss : 0.034826, loss_ce: 0.013620
[02:24:39.422] iteration 20238 : loss : 0.065663, loss_ce: 0.023183
[02:24:39.723] iteration 20239 : loss : 0.051948, loss_ce: 0.019377
[02:24:40.027] iteration 20240 : loss : 0.044341, loss_ce: 0.015341
[02:24:40.344] iteration 20241 : loss : 0.099421, loss_ce: 0.008000
[02:24:40.646] iteration 20242 : loss : 0.108776, loss_ce: 0.006191
[02:24:40.948] iteration 20243 : loss : 0.039073, loss_ce: 0.011722
[02:24:41.249] iteration 20244 : loss : 0.037683, loss_ce: 0.010003
[02:24:41.554] iteration 20245 : loss : 0.101811, loss_ce: 0.005488
[02:24:41.857] iteration 20246 : loss : 0.046125, loss_ce: 0.014549
[02:24:42.159] iteration 20247 : loss : 0.055372, loss_ce: 0.014829
[02:24:42.467] iteration 20248 : loss : 0.034581, loss_ce: 0.009654
[02:24:42.775] iteration 20249 : loss : 0.069246, loss_ce: 0.019271
[02:24:43.082] iteration 20250 : loss : 0.047495, loss_ce: 0.017994
[02:24:43.387] iteration 20251 : loss : 0.043909, loss_ce: 0.011730
[02:24:43.693] iteration 20252 : loss : 0.045323, loss_ce: 0.008245
[02:24:44.003] iteration 20253 : loss : 0.147571, loss_ce: 0.017938
[02:24:44.308] iteration 20254 : loss : 0.054687, loss_ce: 0.018699
[02:24:44.609] iteration 20255 : loss : 0.051779, loss_ce: 0.005536
[02:24:44.913] iteration 20256 : loss : 0.045465, loss_ce: 0.011033
[02:24:45.214] iteration 20257 : loss : 0.044731, loss_ce: 0.020492
[02:24:45.517] iteration 20258 : loss : 0.090116, loss_ce: 0.011374
[02:24:45.819] iteration 20259 : loss : 0.041627, loss_ce: 0.007380
[02:24:46.121] iteration 20260 : loss : 0.043673, loss_ce: 0.011549
[02:24:46.440] iteration 20261 : loss : 0.044450, loss_ce: 0.013266
[02:24:46.741] iteration 20262 : loss : 0.033696, loss_ce: 0.014459
[02:24:47.046] iteration 20263 : loss : 0.093680, loss_ce: 0.007566
[02:24:47.350] iteration 20264 : loss : 0.052647, loss_ce: 0.011383
[02:24:47.654] iteration 20265 : loss : 0.039806, loss_ce: 0.011099
[02:24:47.957] iteration 20266 : loss : 0.042794, loss_ce: 0.015428
[02:24:48.260] iteration 20267 : loss : 0.096468, loss_ce: 0.013309
[02:24:48.562] iteration 20268 : loss : 0.036770, loss_ce: 0.009935
[02:24:48.865] iteration 20269 : loss : 0.034385, loss_ce: 0.009466
[02:24:49.167] iteration 20270 : loss : 0.041887, loss_ce: 0.008505
[02:24:49.469] iteration 20271 : loss : 0.049546, loss_ce: 0.007910
[02:24:49.768] iteration 20272 : loss : 0.050783, loss_ce: 0.011020
[02:24:50.071] iteration 20273 : loss : 0.051495, loss_ce: 0.012247
[02:24:50.377] iteration 20274 : loss : 0.042130, loss_ce: 0.015865
[02:24:50.684] iteration 20275 : loss : 0.037218, loss_ce: 0.009795
[02:24:50.989] iteration 20276 : loss : 0.050519, loss_ce: 0.016752
[02:24:51.294] iteration 20277 : loss : 0.054645, loss_ce: 0.020931
[02:24:51.605] iteration 20278 : loss : 0.049410, loss_ce: 0.017934
[02:24:51.911] iteration 20279 : loss : 0.045489, loss_ce: 0.011197
[02:24:52.216] iteration 20280 : loss : 0.057141, loss_ce: 0.019243
[02:24:52.539] iteration 20281 : loss : 0.037879, loss_ce: 0.013995
[02:24:52.852] iteration 20282 : loss : 0.038077, loss_ce: 0.010819
[02:24:53.164] iteration 20283 : loss : 0.042669, loss_ce: 0.016404
[02:24:53.475] iteration 20284 : loss : 0.044423, loss_ce: 0.019362
[02:24:53.784] iteration 20285 : loss : 0.045824, loss_ce: 0.014624
[02:24:54.091] iteration 20286 : loss : 0.045002, loss_ce: 0.010950
[02:24:54.402] iteration 20287 : loss : 0.045379, loss_ce: 0.018616
[02:24:54.709] iteration 20288 : loss : 0.057244, loss_ce: 0.020709
[02:24:55.023] iteration 20289 : loss : 0.066900, loss_ce: 0.009692
[02:24:55.335] iteration 20290 : loss : 0.045249, loss_ce: 0.010872
[02:24:55.643] iteration 20291 : loss : 0.034749, loss_ce: 0.013857
[02:24:55.950] iteration 20292 : loss : 0.042867, loss_ce: 0.010302
[02:24:56.260] iteration 20293 : loss : 0.040345, loss_ce: 0.016589
[02:24:56.349] iteration 20294 : loss : 0.033714, loss_ce: 0.016067
[02:25:13.573] iteration 20295 : loss : 0.044495, loss_ce: 0.008032
[02:25:13.877] iteration 20296 : loss : 0.048951, loss_ce: 0.016369
[02:25:14.184] iteration 20297 : loss : 0.038538, loss_ce: 0.014194
[02:25:14.489] iteration 20298 : loss : 0.042276, loss_ce: 0.012187
[02:25:14.796] iteration 20299 : loss : 0.103849, loss_ce: 0.011535
[02:25:15.102] iteration 20300 : loss : 0.182512, loss_ce: 0.002476
[02:25:15.421] iteration 20301 : loss : 0.038331, loss_ce: 0.017833
[02:25:15.724] iteration 20302 : loss : 0.046321, loss_ce: 0.015764
[02:25:16.026] iteration 20303 : loss : 0.049304, loss_ce: 0.020416
[02:25:16.331] iteration 20304 : loss : 0.041946, loss_ce: 0.018485
[02:25:16.638] iteration 20305 : loss : 0.033460, loss_ce: 0.010287
[02:25:16.944] iteration 20306 : loss : 0.041373, loss_ce: 0.016441
[02:25:17.256] iteration 20307 : loss : 0.043195, loss_ce: 0.011225
[02:25:17.568] iteration 20308 : loss : 0.039291, loss_ce: 0.018895
[02:25:17.878] iteration 20309 : loss : 0.046190, loss_ce: 0.012625
[02:25:18.187] iteration 20310 : loss : 0.038935, loss_ce: 0.013716
[02:25:18.501] iteration 20311 : loss : 0.039477, loss_ce: 0.011399
[02:25:18.820] iteration 20312 : loss : 0.040818, loss_ce: 0.019713
[02:25:19.129] iteration 20313 : loss : 0.041905, loss_ce: 0.020635
[02:25:19.434] iteration 20314 : loss : 0.042829, loss_ce: 0.016170
[02:25:19.740] iteration 20315 : loss : 0.043637, loss_ce: 0.009262
[02:25:20.040] iteration 20316 : loss : 0.045822, loss_ce: 0.006440
[02:25:20.343] iteration 20317 : loss : 0.049574, loss_ce: 0.023904
[02:25:20.643] iteration 20318 : loss : 0.104112, loss_ce: 0.015055
[02:25:20.946] iteration 20319 : loss : 0.037575, loss_ce: 0.018552
[02:25:21.246] iteration 20320 : loss : 0.041490, loss_ce: 0.008987
[02:25:21.566] iteration 20321 : loss : 0.041580, loss_ce: 0.013477
[02:25:21.865] iteration 20322 : loss : 0.051909, loss_ce: 0.007502
[02:25:22.167] iteration 20323 : loss : 0.036316, loss_ce: 0.016585
[02:25:22.469] iteration 20324 : loss : 0.054562, loss_ce: 0.009804
[02:25:22.774] iteration 20325 : loss : 0.051902, loss_ce: 0.021897
[02:25:23.076] iteration 20326 : loss : 0.108753, loss_ce: 0.012096
[02:25:23.379] iteration 20327 : loss : 0.040631, loss_ce: 0.008568
[02:25:23.683] iteration 20328 : loss : 0.039170, loss_ce: 0.012359
[02:25:23.984] iteration 20329 : loss : 0.042175, loss_ce: 0.021130
[02:25:24.287] iteration 20330 : loss : 0.058674, loss_ce: 0.012687
[02:25:24.594] iteration 20331 : loss : 0.042873, loss_ce: 0.013363
[02:25:24.896] iteration 20332 : loss : 0.069794, loss_ce: 0.010657
[02:25:25.200] iteration 20333 : loss : 0.042924, loss_ce: 0.010586
[02:25:25.503] iteration 20334 : loss : 0.111078, loss_ce: 0.009834
[02:25:25.803] iteration 20335 : loss : 0.049618, loss_ce: 0.015449
[02:25:26.109] iteration 20336 : loss : 0.105776, loss_ce: 0.011156
[02:25:26.411] iteration 20337 : loss : 0.036475, loss_ce: 0.005472
[02:25:26.714] iteration 20338 : loss : 0.043069, loss_ce: 0.017807
[02:25:27.016] iteration 20339 : loss : 0.147904, loss_ce: 0.005310
[02:25:27.319] iteration 20340 : loss : 0.049342, loss_ce: 0.012330
[02:25:27.636] iteration 20341 : loss : 0.112839, loss_ce: 0.007891
[02:25:27.937] iteration 20342 : loss : 0.040542, loss_ce: 0.010999
[02:25:28.240] iteration 20343 : loss : 0.048351, loss_ce: 0.017914
[02:25:28.542] iteration 20344 : loss : 0.038821, loss_ce: 0.017088
[02:25:28.847] iteration 20345 : loss : 0.053378, loss_ce: 0.020953
[02:25:29.149] iteration 20346 : loss : 0.048760, loss_ce: 0.012053
[02:25:29.451] iteration 20347 : loss : 0.057815, loss_ce: 0.016045
[02:25:29.754] iteration 20348 : loss : 0.051130, loss_ce: 0.013163
[02:25:30.055] iteration 20349 : loss : 0.107345, loss_ce: 0.012510
[02:25:30.362] iteration 20350 : loss : 0.059434, loss_ce: 0.006462
[02:25:30.663] iteration 20351 : loss : 0.103311, loss_ce: 0.007112
[02:25:30.965] iteration 20352 : loss : 0.041808, loss_ce: 0.012995
[02:25:31.270] iteration 20353 : loss : 0.051644, loss_ce: 0.008387
[02:25:31.572] iteration 20354 : loss : 0.157485, loss_ce: 0.003631
[02:25:31.875] iteration 20355 : loss : 0.037109, loss_ce: 0.014941
[02:25:32.180] iteration 20356 : loss : 0.051169, loss_ce: 0.015730
[02:25:32.488] iteration 20357 : loss : 0.035024, loss_ce: 0.009775
[02:25:32.801] iteration 20358 : loss : 0.105682, loss_ce: 0.006999
[02:25:33.109] iteration 20359 : loss : 0.045203, loss_ce: 0.013069
[02:25:33.420] iteration 20360 : loss : 0.041473, loss_ce: 0.016472
[02:25:33.747] iteration 20361 : loss : 0.048771, loss_ce: 0.019804
[02:25:34.056] iteration 20362 : loss : 0.039291, loss_ce: 0.010588
[02:25:34.360] iteration 20363 : loss : 0.053711, loss_ce: 0.010636
[02:25:34.666] iteration 20364 : loss : 0.063042, loss_ce: 0.017561
[02:25:34.968] iteration 20365 : loss : 0.038076, loss_ce: 0.013464
[02:25:35.269] iteration 20366 : loss : 0.042641, loss_ce: 0.016295
[02:25:35.571] iteration 20367 : loss : 0.117124, loss_ce: 0.008612
[02:25:35.875] iteration 20368 : loss : 0.041153, loss_ce: 0.016106
[02:25:36.179] iteration 20369 : loss : 0.044890, loss_ce: 0.013982
[02:25:36.481] iteration 20370 : loss : 0.039368, loss_ce: 0.010254
[02:25:36.781] iteration 20371 : loss : 0.038801, loss_ce: 0.007239
[02:25:37.085] iteration 20372 : loss : 0.050282, loss_ce: 0.021047
[02:25:37.390] iteration 20373 : loss : 0.045109, loss_ce: 0.012816
[02:25:37.694] iteration 20374 : loss : 0.037596, loss_ce: 0.011557
[02:25:37.997] iteration 20375 : loss : 0.102085, loss_ce: 0.015323
[02:25:38.299] iteration 20376 : loss : 0.096898, loss_ce: 0.007042
[02:25:38.600] iteration 20377 : loss : 0.099364, loss_ce: 0.005707
[02:25:38.906] iteration 20378 : loss : 0.040427, loss_ce: 0.010843
[02:25:39.208] iteration 20379 : loss : 0.042906, loss_ce: 0.016731
[02:25:39.510] iteration 20380 : loss : 0.044396, loss_ce: 0.013252
[02:25:39.831] iteration 20381 : loss : 0.036605, loss_ce: 0.010460
[02:25:40.134] iteration 20382 : loss : 0.044869, loss_ce: 0.014266
[02:25:40.439] iteration 20383 : loss : 0.091739, loss_ce: 0.012116
[02:25:40.741] iteration 20384 : loss : 0.164677, loss_ce: 0.003527
[02:25:41.046] iteration 20385 : loss : 0.100737, loss_ce: 0.008045
[02:25:41.347] iteration 20386 : loss : 0.045830, loss_ce: 0.014445
[02:25:41.646] iteration 20387 : loss : 0.099106, loss_ce: 0.009214
[02:25:41.946] iteration 20388 : loss : 0.039576, loss_ce: 0.010974
[02:25:42.250] iteration 20389 : loss : 0.049388, loss_ce: 0.009863
[02:25:42.553] iteration 20390 : loss : 0.048036, loss_ce: 0.025007
[02:25:42.856] iteration 20391 : loss : 0.056783, loss_ce: 0.012714
[02:25:43.162] iteration 20392 : loss : 0.100866, loss_ce: 0.008991
[02:25:43.471] iteration 20393 : loss : 0.046252, loss_ce: 0.018640
[02:25:43.770] iteration 20394 : loss : 0.107018, loss_ce: 0.013416
[02:25:44.072] iteration 20395 : loss : 0.044241, loss_ce: 0.013748
[02:25:44.375] iteration 20396 : loss : 0.039683, loss_ce: 0.014614
[02:25:44.680] iteration 20397 : loss : 0.043965, loss_ce: 0.024872
[02:25:44.982] iteration 20398 : loss : 0.037346, loss_ce: 0.008887
[02:25:45.285] iteration 20399 : loss : 0.036164, loss_ce: 0.012456
[02:25:45.586] iteration 20400 : loss : 0.050620, loss_ce: 0.014452
[02:25:45.908] iteration 20401 : loss : 0.041510, loss_ce: 0.010953
[02:25:46.210] iteration 20402 : loss : 0.088596, loss_ce: 0.013423
[02:25:46.515] iteration 20403 : loss : 0.034945, loss_ce: 0.008273
[02:25:46.822] iteration 20404 : loss : 0.030083, loss_ce: 0.005297
[02:25:47.125] iteration 20405 : loss : 0.037967, loss_ce: 0.017264
[02:25:47.429] iteration 20406 : loss : 0.044129, loss_ce: 0.015992
[02:25:47.736] iteration 20407 : loss : 0.099838, loss_ce: 0.013074
[02:25:48.041] iteration 20408 : loss : 0.037527, loss_ce: 0.013046
[02:25:48.347] iteration 20409 : loss : 0.040745, loss_ce: 0.009846
[02:25:48.654] iteration 20410 : loss : 0.050072, loss_ce: 0.013569
[02:25:48.958] iteration 20411 : loss : 0.034833, loss_ce: 0.003413
[02:25:49.265] iteration 20412 : loss : 0.049949, loss_ce: 0.013153
[02:25:49.571] iteration 20413 : loss : 0.049393, loss_ce: 0.014294
[02:25:49.878] iteration 20414 : loss : 0.062128, loss_ce: 0.006121
[02:25:50.187] iteration 20415 : loss : 0.158546, loss_ce: 0.004365
[02:25:50.495] iteration 20416 : loss : 0.052025, loss_ce: 0.011534
[02:25:50.807] iteration 20417 : loss : 0.042897, loss_ce: 0.016451
[02:25:51.121] iteration 20418 : loss : 0.041950, loss_ce: 0.019109
[02:25:51.430] iteration 20419 : loss : 0.045881, loss_ce: 0.013163
[02:25:51.747] iteration 20420 : loss : 0.045221, loss_ce: 0.012618
[02:25:52.080] iteration 20421 : loss : 0.106132, loss_ce: 0.013239
[02:25:52.389] iteration 20422 : loss : 0.041367, loss_ce: 0.016183
[02:25:52.703] iteration 20423 : loss : 0.043064, loss_ce: 0.015179
[02:25:53.011] iteration 20424 : loss : 0.053032, loss_ce: 0.008454
[02:25:53.314] iteration 20425 : loss : 0.044419, loss_ce: 0.012907
[02:25:53.620] iteration 20426 : loss : 0.037648, loss_ce: 0.017808
[02:25:53.928] iteration 20427 : loss : 0.045523, loss_ce: 0.008186
[02:25:54.243] iteration 20428 : loss : 0.036339, loss_ce: 0.007844
[02:25:54.557] iteration 20429 : loss : 0.041121, loss_ce: 0.017013
[02:25:54.867] iteration 20430 : loss : 0.177093, loss_ce: 0.004776
[02:25:55.177] iteration 20431 : loss : 0.048984, loss_ce: 0.013729
[02:25:55.491] iteration 20432 : loss : 0.066066, loss_ce: 0.019099
[02:25:55.569] iteration 20433 : loss : 0.233661, loss_ce: 0.003748
[02:26:13.895] iteration 20434 : loss : 0.053030, loss_ce: 0.013754
[02:26:14.193] iteration 20435 : loss : 0.043120, loss_ce: 0.009385
[02:26:14.491] iteration 20436 : loss : 0.042947, loss_ce: 0.015473
[02:26:14.795] iteration 20437 : loss : 0.040294, loss_ce: 0.019391
[02:26:15.096] iteration 20438 : loss : 0.048926, loss_ce: 0.016257
[02:26:15.398] iteration 20439 : loss : 0.040773, loss_ce: 0.015984
[02:26:15.699] iteration 20440 : loss : 0.047069, loss_ce: 0.007021
[02:26:16.015] iteration 20441 : loss : 0.132436, loss_ce: 0.008590
[02:26:16.316] iteration 20442 : loss : 0.042290, loss_ce: 0.015524
[02:26:16.616] iteration 20443 : loss : 0.035813, loss_ce: 0.013782
[02:26:16.920] iteration 20444 : loss : 0.283221, loss_ce: 0.005684
[02:26:17.226] iteration 20445 : loss : 0.164833, loss_ce: 0.012369
[02:26:17.529] iteration 20446 : loss : 0.163470, loss_ce: 0.012383
[02:26:17.834] iteration 20447 : loss : 0.112289, loss_ce: 0.007556
[02:26:18.136] iteration 20448 : loss : 0.164484, loss_ce: 0.004354
[02:26:18.437] iteration 20449 : loss : 0.038552, loss_ce: 0.019243
[02:26:18.739] iteration 20450 : loss : 0.042529, loss_ce: 0.017249
[02:26:19.044] iteration 20451 : loss : 0.046879, loss_ce: 0.008544
[02:26:19.344] iteration 20452 : loss : 0.102771, loss_ce: 0.007475
[02:26:19.649] iteration 20453 : loss : 0.044964, loss_ce: 0.010181
[02:26:19.949] iteration 20454 : loss : 0.111175, loss_ce: 0.019610
[02:26:20.253] iteration 20455 : loss : 0.159293, loss_ce: 0.014440
[02:26:20.556] iteration 20456 : loss : 0.033878, loss_ce: 0.011329
[02:26:20.860] iteration 20457 : loss : 0.102163, loss_ce: 0.010439
[02:26:21.164] iteration 20458 : loss : 0.038137, loss_ce: 0.010703
[02:26:21.464] iteration 20459 : loss : 0.038534, loss_ce: 0.012964
[02:26:21.768] iteration 20460 : loss : 0.043765, loss_ce: 0.014924
[02:26:22.087] iteration 20461 : loss : 0.044098, loss_ce: 0.011332
[02:26:22.396] iteration 20462 : loss : 0.043390, loss_ce: 0.016397
[02:26:22.701] iteration 20463 : loss : 0.035708, loss_ce: 0.012876
[02:26:23.011] iteration 20464 : loss : 0.043877, loss_ce: 0.010811
[02:26:23.318] iteration 20465 : loss : 0.043094, loss_ce: 0.014936
[02:26:23.629] iteration 20466 : loss : 0.040955, loss_ce: 0.015846
[02:26:23.936] iteration 20467 : loss : 0.036514, loss_ce: 0.007751
[02:26:24.249] iteration 20468 : loss : 0.042633, loss_ce: 0.015865
[02:26:24.551] iteration 20469 : loss : 0.069896, loss_ce: 0.019102
[02:26:24.853] iteration 20470 : loss : 0.033221, loss_ce: 0.014283
[02:26:25.155] iteration 20471 : loss : 0.043355, loss_ce: 0.009729
[02:26:25.457] iteration 20472 : loss : 0.092903, loss_ce: 0.005376
[02:26:25.764] iteration 20473 : loss : 0.046277, loss_ce: 0.016289
[02:26:26.069] iteration 20474 : loss : 0.037276, loss_ce: 0.013348
[02:26:26.378] iteration 20475 : loss : 0.178425, loss_ce: 0.009340
[02:26:26.680] iteration 20476 : loss : 0.047886, loss_ce: 0.007657
[02:26:26.985] iteration 20477 : loss : 0.048625, loss_ce: 0.015812
[02:26:27.287] iteration 20478 : loss : 0.053330, loss_ce: 0.018707
[02:26:27.590] iteration 20479 : loss : 0.051143, loss_ce: 0.010471
[02:26:27.894] iteration 20480 : loss : 0.038710, loss_ce: 0.018715
[02:26:28.210] iteration 20481 : loss : 0.110810, loss_ce: 0.010383
[02:26:28.514] iteration 20482 : loss : 0.044327, loss_ce: 0.010199
[02:26:28.814] iteration 20483 : loss : 0.049631, loss_ce: 0.017457
[02:26:29.118] iteration 20484 : loss : 0.039466, loss_ce: 0.017440
[02:26:29.421] iteration 20485 : loss : 0.171843, loss_ce: 0.005845
[02:26:29.724] iteration 20486 : loss : 0.051232, loss_ce: 0.017345
[02:26:30.025] iteration 20487 : loss : 0.032473, loss_ce: 0.011416
[02:26:30.330] iteration 20488 : loss : 0.041779, loss_ce: 0.011741
[02:26:30.633] iteration 20489 : loss : 0.057051, loss_ce: 0.019599
[02:26:30.937] iteration 20490 : loss : 0.075987, loss_ce: 0.017025
[02:26:31.239] iteration 20491 : loss : 0.102945, loss_ce: 0.011962
[02:26:31.544] iteration 20492 : loss : 0.041445, loss_ce: 0.015008
[02:26:31.846] iteration 20493 : loss : 0.044679, loss_ce: 0.012091
[02:26:32.149] iteration 20494 : loss : 0.046371, loss_ce: 0.011833
[02:26:32.452] iteration 20495 : loss : 0.043263, loss_ce: 0.010405
[02:26:32.753] iteration 20496 : loss : 0.038856, loss_ce: 0.017898
[02:26:33.054] iteration 20497 : loss : 0.044606, loss_ce: 0.016281
[02:26:33.357] iteration 20498 : loss : 0.109805, loss_ce: 0.007321
[02:26:33.658] iteration 20499 : loss : 0.034167, loss_ce: 0.012616
[02:26:33.964] iteration 20500 : loss : 0.039149, loss_ce: 0.009613
[02:26:34.285] iteration 20501 : loss : 0.107090, loss_ce: 0.010080
[02:26:34.586] iteration 20502 : loss : 0.130672, loss_ce: 0.011995
[02:26:34.892] iteration 20503 : loss : 0.076408, loss_ce: 0.014019
[02:26:35.192] iteration 20504 : loss : 0.047728, loss_ce: 0.009601
[02:26:35.493] iteration 20505 : loss : 0.108213, loss_ce: 0.007853
[02:26:35.794] iteration 20506 : loss : 0.042280, loss_ce: 0.016220
[02:26:36.097] iteration 20507 : loss : 0.094828, loss_ce: 0.011410
[02:26:36.401] iteration 20508 : loss : 0.043577, loss_ce: 0.014895
[02:26:36.710] iteration 20509 : loss : 0.051769, loss_ce: 0.026490
[02:26:37.011] iteration 20510 : loss : 0.046691, loss_ce: 0.016468
[02:26:37.315] iteration 20511 : loss : 0.054660, loss_ce: 0.021944
[02:26:37.623] iteration 20512 : loss : 0.040623, loss_ce: 0.019445
[02:26:37.934] iteration 20513 : loss : 0.041176, loss_ce: 0.014019
[02:26:38.243] iteration 20514 : loss : 0.099876, loss_ce: 0.009901
[02:26:38.553] iteration 20515 : loss : 0.093985, loss_ce: 0.008791
[02:26:38.864] iteration 20516 : loss : 0.036115, loss_ce: 0.006391
[02:26:39.171] iteration 20517 : loss : 0.048580, loss_ce: 0.009519
[02:26:39.478] iteration 20518 : loss : 0.041847, loss_ce: 0.018452
[02:26:39.783] iteration 20519 : loss : 0.053786, loss_ce: 0.008636
[02:26:40.088] iteration 20520 : loss : 0.098484, loss_ce: 0.009301
[02:26:40.404] iteration 20521 : loss : 0.165179, loss_ce: 0.004963
[02:26:40.709] iteration 20522 : loss : 0.044228, loss_ce: 0.014920
[02:26:41.014] iteration 20523 : loss : 0.100179, loss_ce: 0.010843
[02:26:41.316] iteration 20524 : loss : 0.045474, loss_ce: 0.020473
[02:26:41.616] iteration 20525 : loss : 0.104191, loss_ce: 0.013465
[02:26:41.921] iteration 20526 : loss : 0.040475, loss_ce: 0.014028
[02:26:42.224] iteration 20527 : loss : 0.098171, loss_ce: 0.010596
[02:26:42.529] iteration 20528 : loss : 0.048512, loss_ce: 0.008477
[02:26:42.834] iteration 20529 : loss : 0.041550, loss_ce: 0.020448
[02:26:43.136] iteration 20530 : loss : 0.057132, loss_ce: 0.016841
[02:26:43.437] iteration 20531 : loss : 0.049529, loss_ce: 0.020091
[02:26:43.741] iteration 20532 : loss : 0.036623, loss_ce: 0.011435
[02:26:44.047] iteration 20533 : loss : 0.039091, loss_ce: 0.018526
[02:26:44.351] iteration 20534 : loss : 0.146050, loss_ce: 0.005565
[02:26:44.655] iteration 20535 : loss : 0.035024, loss_ce: 0.009540
[02:26:44.965] iteration 20536 : loss : 0.044749, loss_ce: 0.018312
[02:26:45.274] iteration 20537 : loss : 0.062686, loss_ce: 0.011187
[02:26:45.578] iteration 20538 : loss : 0.038599, loss_ce: 0.017248
[02:26:45.881] iteration 20539 : loss : 0.042317, loss_ce: 0.010368
[02:26:46.185] iteration 20540 : loss : 0.103965, loss_ce: 0.003769
[02:26:46.504] iteration 20541 : loss : 0.099613, loss_ce: 0.006456
[02:26:46.811] iteration 20542 : loss : 0.039619, loss_ce: 0.011002
[02:26:47.119] iteration 20543 : loss : 0.038392, loss_ce: 0.012521
[02:26:47.424] iteration 20544 : loss : 0.045835, loss_ce: 0.022484
[02:26:47.724] iteration 20545 : loss : 0.233651, loss_ce: 0.005643
[02:26:48.028] iteration 20546 : loss : 0.039508, loss_ce: 0.015102
[02:26:48.331] iteration 20547 : loss : 0.037678, loss_ce: 0.009558
[02:26:48.634] iteration 20548 : loss : 0.040861, loss_ce: 0.016684
[02:26:48.939] iteration 20549 : loss : 0.038403, loss_ce: 0.009006
[02:26:49.241] iteration 20550 : loss : 0.052434, loss_ce: 0.014427
[02:26:49.542] iteration 20551 : loss : 0.034517, loss_ce: 0.012819
[02:26:49.844] iteration 20552 : loss : 0.048347, loss_ce: 0.011830
[02:26:50.148] iteration 20553 : loss : 0.056259, loss_ce: 0.004477
[02:26:50.454] iteration 20554 : loss : 0.044362, loss_ce: 0.011140
[02:26:50.757] iteration 20555 : loss : 0.042976, loss_ce: 0.011526
[02:26:51.062] iteration 20556 : loss : 0.048401, loss_ce: 0.017511
[02:26:51.372] iteration 20557 : loss : 0.047486, loss_ce: 0.009872
[02:26:51.684] iteration 20558 : loss : 0.036939, loss_ce: 0.017687
[02:26:51.991] iteration 20559 : loss : 0.044474, loss_ce: 0.016207
[02:26:52.305] iteration 20560 : loss : 0.048619, loss_ce: 0.017187
[02:26:52.644] iteration 20561 : loss : 0.112966, loss_ce: 0.016746
[02:26:52.952] iteration 20562 : loss : 0.048662, loss_ce: 0.014272
[02:26:53.270] iteration 20563 : loss : 0.106766, loss_ce: 0.010657
[02:26:53.577] iteration 20564 : loss : 0.102947, loss_ce: 0.007264
[02:26:53.885] iteration 20565 : loss : 0.045715, loss_ce: 0.007197
[02:26:54.194] iteration 20566 : loss : 0.052061, loss_ce: 0.014231
[02:26:54.506] iteration 20567 : loss : 0.050944, loss_ce: 0.017419
[02:26:54.819] iteration 20568 : loss : 0.046546, loss_ce: 0.019581
[02:26:55.132] iteration 20569 : loss : 0.044341, loss_ce: 0.015827
[02:26:55.443] iteration 20570 : loss : 0.044868, loss_ce: 0.014036
[02:26:55.753] iteration 20571 : loss : 0.080764, loss_ce: 0.009641
[02:26:55.840] iteration 20572 : loss : 0.361973, loss_ce: 0.002336
[02:27:13.807] iteration 20573 : loss : 0.042916, loss_ce: 0.015983
[02:27:14.111] iteration 20574 : loss : 0.048059, loss_ce: 0.011380
[02:27:14.413] iteration 20575 : loss : 0.040610, loss_ce: 0.012083
[02:27:14.714] iteration 20576 : loss : 0.103345, loss_ce: 0.009949
[02:27:15.016] iteration 20577 : loss : 0.055713, loss_ce: 0.019396
[02:27:15.317] iteration 20578 : loss : 0.050194, loss_ce: 0.009055
[02:27:15.618] iteration 20579 : loss : 0.050859, loss_ce: 0.019798
[02:27:15.920] iteration 20580 : loss : 0.043917, loss_ce: 0.016765
[02:27:16.238] iteration 20581 : loss : 0.050166, loss_ce: 0.018801
[02:27:16.537] iteration 20582 : loss : 0.046403, loss_ce: 0.012134
[02:27:16.837] iteration 20583 : loss : 0.042884, loss_ce: 0.012854
[02:27:17.140] iteration 20584 : loss : 0.041224, loss_ce: 0.013705
[02:27:17.441] iteration 20585 : loss : 0.108155, loss_ce: 0.013798
[02:27:17.748] iteration 20586 : loss : 0.103985, loss_ce: 0.006258
[02:27:18.053] iteration 20587 : loss : 0.042031, loss_ce: 0.010561
[02:27:18.355] iteration 20588 : loss : 0.036514, loss_ce: 0.015031
[02:27:18.654] iteration 20589 : loss : 0.047217, loss_ce: 0.018351
[02:27:18.960] iteration 20590 : loss : 0.029875, loss_ce: 0.005364
[02:27:19.263] iteration 20591 : loss : 0.049777, loss_ce: 0.019176
[02:27:19.568] iteration 20592 : loss : 0.057203, loss_ce: 0.012138
[02:27:19.872] iteration 20593 : loss : 0.098178, loss_ce: 0.006829
[02:27:20.176] iteration 20594 : loss : 0.052028, loss_ce: 0.011673
[02:27:20.476] iteration 20595 : loss : 0.046916, loss_ce: 0.015899
[02:27:20.779] iteration 20596 : loss : 0.030335, loss_ce: 0.012222
[02:27:21.078] iteration 20597 : loss : 0.050526, loss_ce: 0.017569
[02:27:21.381] iteration 20598 : loss : 0.103304, loss_ce: 0.014021
[02:27:21.684] iteration 20599 : loss : 0.063785, loss_ce: 0.012369
[02:27:21.989] iteration 20600 : loss : 0.041577, loss_ce: 0.012880
[02:27:22.303] iteration 20601 : loss : 0.101003, loss_ce: 0.015773
[02:27:22.606] iteration 20602 : loss : 0.101954, loss_ce: 0.011444
[02:27:22.907] iteration 20603 : loss : 0.039358, loss_ce: 0.018315
[02:27:23.210] iteration 20604 : loss : 0.048206, loss_ce: 0.008518
[02:27:23.514] iteration 20605 : loss : 0.043493, loss_ce: 0.009331
[02:27:23.814] iteration 20606 : loss : 0.038804, loss_ce: 0.010900
[02:27:24.115] iteration 20607 : loss : 0.042711, loss_ce: 0.019365
[02:27:24.421] iteration 20608 : loss : 0.040044, loss_ce: 0.013028
[02:27:24.724] iteration 20609 : loss : 0.037224, loss_ce: 0.011673
[02:27:25.029] iteration 20610 : loss : 0.059792, loss_ce: 0.008685
[02:27:25.329] iteration 20611 : loss : 0.044224, loss_ce: 0.013966
[02:27:25.635] iteration 20612 : loss : 0.049986, loss_ce: 0.009892
[02:27:25.938] iteration 20613 : loss : 0.046593, loss_ce: 0.019549
[02:27:26.240] iteration 20614 : loss : 0.045337, loss_ce: 0.016475
[02:27:26.544] iteration 20615 : loss : 0.166855, loss_ce: 0.005103
[02:27:26.847] iteration 20616 : loss : 0.056093, loss_ce: 0.025304
[02:27:27.149] iteration 20617 : loss : 0.052097, loss_ce: 0.013452
[02:27:27.456] iteration 20618 : loss : 0.101131, loss_ce: 0.005936
[02:27:27.759] iteration 20619 : loss : 0.101832, loss_ce: 0.009903
[02:27:28.067] iteration 20620 : loss : 0.044620, loss_ce: 0.010235
[02:27:28.399] iteration 20621 : loss : 0.034779, loss_ce: 0.011448
[02:27:28.706] iteration 20622 : loss : 0.069003, loss_ce: 0.020685
[02:27:29.012] iteration 20623 : loss : 0.051277, loss_ce: 0.024865
[02:27:29.320] iteration 20624 : loss : 0.047492, loss_ce: 0.021512
[02:27:29.623] iteration 20625 : loss : 0.108648, loss_ce: 0.013665
[02:27:29.927] iteration 20626 : loss : 0.037948, loss_ce: 0.009174
[02:27:30.228] iteration 20627 : loss : 0.104302, loss_ce: 0.014050
[02:27:30.535] iteration 20628 : loss : 0.105492, loss_ce: 0.011777
[02:27:30.836] iteration 20629 : loss : 0.046792, loss_ce: 0.017283
[02:27:31.138] iteration 20630 : loss : 0.043594, loss_ce: 0.016369
[02:27:31.439] iteration 20631 : loss : 0.043476, loss_ce: 0.008212
[02:27:31.743] iteration 20632 : loss : 0.167391, loss_ce: 0.005808
[02:27:32.048] iteration 20633 : loss : 0.061651, loss_ce: 0.014688
[02:27:32.350] iteration 20634 : loss : 0.041971, loss_ce: 0.006258
[02:27:32.655] iteration 20635 : loss : 0.052027, loss_ce: 0.018830
[02:27:32.959] iteration 20636 : loss : 0.041699, loss_ce: 0.016060
[02:27:33.262] iteration 20637 : loss : 0.104150, loss_ce: 0.004644
[02:27:33.564] iteration 20638 : loss : 0.041105, loss_ce: 0.007198
[02:27:33.868] iteration 20639 : loss : 0.052341, loss_ce: 0.011805
[02:27:34.171] iteration 20640 : loss : 0.103848, loss_ce: 0.005510
[02:27:34.492] iteration 20641 : loss : 0.031813, loss_ce: 0.013025
[02:27:34.796] iteration 20642 : loss : 0.114861, loss_ce: 0.009770
[02:27:35.103] iteration 20643 : loss : 0.128428, loss_ce: 0.008220
[02:27:35.408] iteration 20644 : loss : 0.045116, loss_ce: 0.017346
[02:27:35.712] iteration 20645 : loss : 0.043502, loss_ce: 0.016975
[02:27:36.018] iteration 20646 : loss : 0.047588, loss_ce: 0.018423
[02:27:36.321] iteration 20647 : loss : 0.056903, loss_ce: 0.007913
[02:27:36.625] iteration 20648 : loss : 0.040289, loss_ce: 0.014208
[02:27:36.929] iteration 20649 : loss : 0.038879, loss_ce: 0.016020
[02:27:37.234] iteration 20650 : loss : 0.045142, loss_ce: 0.013942
[02:27:37.536] iteration 20651 : loss : 0.039501, loss_ce: 0.012096
[02:27:37.837] iteration 20652 : loss : 0.043724, loss_ce: 0.015712
[02:27:38.141] iteration 20653 : loss : 0.043915, loss_ce: 0.016826
[02:27:38.443] iteration 20654 : loss : 0.045654, loss_ce: 0.015709
[02:27:38.748] iteration 20655 : loss : 0.104991, loss_ce: 0.011985
[02:27:39.049] iteration 20656 : loss : 0.037956, loss_ce: 0.010704
[02:27:39.352] iteration 20657 : loss : 0.053904, loss_ce: 0.012931
[02:27:39.658] iteration 20658 : loss : 0.106470, loss_ce: 0.007936
[02:27:39.962] iteration 20659 : loss : 0.043826, loss_ce: 0.010028
[02:27:40.269] iteration 20660 : loss : 0.037068, loss_ce: 0.007374
[02:27:40.584] iteration 20661 : loss : 0.035511, loss_ce: 0.013452
[02:27:40.888] iteration 20662 : loss : 0.052939, loss_ce: 0.013812
[02:27:41.195] iteration 20663 : loss : 0.046182, loss_ce: 0.014777
[02:27:41.500] iteration 20664 : loss : 0.042497, loss_ce: 0.023136
[02:27:41.802] iteration 20665 : loss : 0.058207, loss_ce: 0.011210
[02:27:42.109] iteration 20666 : loss : 0.032899, loss_ce: 0.011594
[02:27:42.420] iteration 20667 : loss : 0.044276, loss_ce: 0.015505
[02:27:42.727] iteration 20668 : loss : 0.096598, loss_ce: 0.005138
[02:27:43.035] iteration 20669 : loss : 0.049199, loss_ce: 0.023840
[02:27:43.346] iteration 20670 : loss : 0.052359, loss_ce: 0.010520
[02:27:43.653] iteration 20671 : loss : 0.042133, loss_ce: 0.014436
[02:27:43.962] iteration 20672 : loss : 0.351980, loss_ce: 0.001179
[02:27:44.271] iteration 20673 : loss : 0.062399, loss_ce: 0.014320
[02:27:44.572] iteration 20674 : loss : 0.044794, loss_ce: 0.007857
[02:27:44.876] iteration 20675 : loss : 0.095361, loss_ce: 0.007292
[02:27:45.179] iteration 20676 : loss : 0.052729, loss_ce: 0.013268
[02:27:45.485] iteration 20677 : loss : 0.052184, loss_ce: 0.014794
[02:27:45.789] iteration 20678 : loss : 0.088746, loss_ce: 0.009944
[02:27:46.093] iteration 20679 : loss : 0.043121, loss_ce: 0.015816
[02:27:46.395] iteration 20680 : loss : 0.109637, loss_ce: 0.012897
[02:27:46.715] iteration 20681 : loss : 0.052689, loss_ce: 0.013321
[02:27:47.018] iteration 20682 : loss : 0.046185, loss_ce: 0.014984
[02:27:47.321] iteration 20683 : loss : 0.107367, loss_ce: 0.016295
[02:27:47.624] iteration 20684 : loss : 0.099747, loss_ce: 0.005344
[02:27:47.928] iteration 20685 : loss : 0.039231, loss_ce: 0.011369
[02:27:48.232] iteration 20686 : loss : 0.049445, loss_ce: 0.015901
[02:27:48.534] iteration 20687 : loss : 0.043711, loss_ce: 0.015530
[02:27:48.842] iteration 20688 : loss : 0.038469, loss_ce: 0.007598
[02:27:49.144] iteration 20689 : loss : 0.077055, loss_ce: 0.018337
[02:27:49.450] iteration 20690 : loss : 0.098200, loss_ce: 0.007650
[02:27:49.753] iteration 20691 : loss : 0.041081, loss_ce: 0.014393
[02:27:50.059] iteration 20692 : loss : 0.044067, loss_ce: 0.014850
[02:27:50.359] iteration 20693 : loss : 0.095057, loss_ce: 0.007971
[02:27:50.662] iteration 20694 : loss : 0.049017, loss_ce: 0.021769
[02:27:50.970] iteration 20695 : loss : 0.153281, loss_ce: 0.004647
[02:27:51.282] iteration 20696 : loss : 0.098968, loss_ce: 0.005190
[02:27:51.589] iteration 20697 : loss : 0.113579, loss_ce: 0.021959
[02:27:51.893] iteration 20698 : loss : 0.040469, loss_ce: 0.011296
[02:27:52.198] iteration 20699 : loss : 0.041342, loss_ce: 0.017004
[02:27:52.507] iteration 20700 : loss : 0.094272, loss_ce: 0.009300
[02:27:52.831] iteration 20701 : loss : 0.048503, loss_ce: 0.023709
[02:27:53.141] iteration 20702 : loss : 0.057366, loss_ce: 0.013977
[02:27:53.445] iteration 20703 : loss : 0.041022, loss_ce: 0.010010
[02:27:53.750] iteration 20704 : loss : 0.096888, loss_ce: 0.013793
[02:27:54.054] iteration 20705 : loss : 0.110724, loss_ce: 0.009249
[02:27:54.365] iteration 20706 : loss : 0.041552, loss_ce: 0.010388
[02:27:54.674] iteration 20707 : loss : 0.049049, loss_ce: 0.020022
[02:27:54.984] iteration 20708 : loss : 0.038962, loss_ce: 0.014485
[02:27:55.293] iteration 20709 : loss : 0.038871, loss_ce: 0.013299
[02:27:55.599] iteration 20710 : loss : 0.038853, loss_ce: 0.015651
[02:27:55.677] iteration 20711 : loss : 0.163454, loss_ce: 0.013698
[02:28:13.090] iteration 20712 : loss : 0.107491, loss_ce: 0.012301
[02:28:13.394] iteration 20713 : loss : 0.044961, loss_ce: 0.009130
[02:28:13.701] iteration 20714 : loss : 0.039937, loss_ce: 0.013477
[02:28:14.012] iteration 20715 : loss : 0.052282, loss_ce: 0.012140
[02:28:14.317] iteration 20716 : loss : 0.051748, loss_ce: 0.020593
[02:28:14.620] iteration 20717 : loss : 0.051624, loss_ce: 0.012208
[02:28:14.924] iteration 20718 : loss : 0.041754, loss_ce: 0.011607
[02:28:15.232] iteration 20719 : loss : 0.104603, loss_ce: 0.017198
[02:28:15.536] iteration 20720 : loss : 0.051081, loss_ce: 0.007643
[02:28:15.859] iteration 20721 : loss : 0.044063, loss_ce: 0.021530
[02:28:16.165] iteration 20722 : loss : 0.041227, loss_ce: 0.009945
[02:28:16.474] iteration 20723 : loss : 0.048131, loss_ce: 0.019344
[02:28:16.779] iteration 20724 : loss : 0.050323, loss_ce: 0.013484
[02:28:17.087] iteration 20725 : loss : 0.097995, loss_ce: 0.013475
[02:28:17.395] iteration 20726 : loss : 0.074312, loss_ce: 0.019527
[02:28:17.702] iteration 20727 : loss : 0.044965, loss_ce: 0.013908
[02:28:18.010] iteration 20728 : loss : 0.052403, loss_ce: 0.011892
[02:28:18.317] iteration 20729 : loss : 0.047223, loss_ce: 0.010216
[02:28:18.626] iteration 20730 : loss : 0.041533, loss_ce: 0.014444
[02:28:18.934] iteration 20731 : loss : 0.101799, loss_ce: 0.006874
[02:28:19.241] iteration 20732 : loss : 0.052891, loss_ce: 0.006310
[02:28:19.544] iteration 20733 : loss : 0.042318, loss_ce: 0.008552
[02:28:19.848] iteration 20734 : loss : 0.033209, loss_ce: 0.013256
[02:28:20.153] iteration 20735 : loss : 0.037335, loss_ce: 0.013045
[02:28:20.453] iteration 20736 : loss : 0.039521, loss_ce: 0.011974
[02:28:20.758] iteration 20737 : loss : 0.102861, loss_ce: 0.012571
[02:28:21.058] iteration 20738 : loss : 0.037843, loss_ce: 0.016687
[02:28:21.364] iteration 20739 : loss : 0.040295, loss_ce: 0.011907
[02:28:21.667] iteration 20740 : loss : 0.036332, loss_ce: 0.011018
[02:28:21.981] iteration 20741 : loss : 0.108581, loss_ce: 0.008231
[02:28:22.283] iteration 20742 : loss : 0.098312, loss_ce: 0.007111
[02:28:22.586] iteration 20743 : loss : 0.104208, loss_ce: 0.014098
[02:28:22.888] iteration 20744 : loss : 0.042861, loss_ce: 0.013726
[02:28:23.191] iteration 20745 : loss : 0.049045, loss_ce: 0.013676
[02:28:23.494] iteration 20746 : loss : 0.033585, loss_ce: 0.014961
[02:28:23.798] iteration 20747 : loss : 0.049767, loss_ce: 0.022095
[02:28:24.101] iteration 20748 : loss : 0.041612, loss_ce: 0.016292
[02:28:24.404] iteration 20749 : loss : 0.046254, loss_ce: 0.020149
[02:28:24.708] iteration 20750 : loss : 0.043590, loss_ce: 0.013473
[02:28:25.013] iteration 20751 : loss : 0.041462, loss_ce: 0.014174
[02:28:25.314] iteration 20752 : loss : 0.043497, loss_ce: 0.012077
[02:28:25.615] iteration 20753 : loss : 0.049211, loss_ce: 0.015488
[02:28:25.917] iteration 20754 : loss : 0.102738, loss_ce: 0.010068
[02:28:26.223] iteration 20755 : loss : 0.040380, loss_ce: 0.013372
[02:28:26.527] iteration 20756 : loss : 0.035632, loss_ce: 0.010873
[02:28:26.830] iteration 20757 : loss : 0.060665, loss_ce: 0.008109
[02:28:27.130] iteration 20758 : loss : 0.041539, loss_ce: 0.010306
[02:28:27.434] iteration 20759 : loss : 0.045747, loss_ce: 0.013953
[02:28:27.738] iteration 20760 : loss : 0.033153, loss_ce: 0.010997
[02:28:28.054] iteration 20761 : loss : 0.037490, loss_ce: 0.010626
[02:28:28.358] iteration 20762 : loss : 0.048867, loss_ce: 0.011320
[02:28:28.659] iteration 20763 : loss : 0.108305, loss_ce: 0.012379
[02:28:28.962] iteration 20764 : loss : 0.098713, loss_ce: 0.012812
[02:28:29.265] iteration 20765 : loss : 0.107704, loss_ce: 0.009580
[02:28:29.572] iteration 20766 : loss : 0.046566, loss_ce: 0.013841
[02:28:29.873] iteration 20767 : loss : 0.039771, loss_ce: 0.012501
[02:28:30.173] iteration 20768 : loss : 0.045371, loss_ce: 0.013218
[02:28:30.476] iteration 20769 : loss : 0.044471, loss_ce: 0.006339
[02:28:30.780] iteration 20770 : loss : 0.057989, loss_ce: 0.014590
[02:28:31.084] iteration 20771 : loss : 0.049054, loss_ce: 0.013860
[02:28:31.388] iteration 20772 : loss : 0.053115, loss_ce: 0.011219
[02:28:31.692] iteration 20773 : loss : 0.044401, loss_ce: 0.021955
[02:28:31.994] iteration 20774 : loss : 0.039870, loss_ce: 0.010446
[02:28:32.299] iteration 20775 : loss : 0.034590, loss_ce: 0.007006
[02:28:32.605] iteration 20776 : loss : 0.050332, loss_ce: 0.010035
[02:28:32.913] iteration 20777 : loss : 0.051761, loss_ce: 0.010955
[02:28:33.221] iteration 20778 : loss : 0.042845, loss_ce: 0.009341
[02:28:33.534] iteration 20779 : loss : 0.045455, loss_ce: 0.016409
[02:28:33.840] iteration 20780 : loss : 0.045403, loss_ce: 0.017495
[02:28:34.165] iteration 20781 : loss : 0.040846, loss_ce: 0.013021
[02:28:34.470] iteration 20782 : loss : 0.101862, loss_ce: 0.012451
[02:28:34.771] iteration 20783 : loss : 0.036620, loss_ce: 0.015688
[02:28:35.075] iteration 20784 : loss : 0.103033, loss_ce: 0.008811
[02:28:35.374] iteration 20785 : loss : 0.100547, loss_ce: 0.008465
[02:28:35.676] iteration 20786 : loss : 0.045566, loss_ce: 0.011389
[02:28:35.978] iteration 20787 : loss : 0.133577, loss_ce: 0.010633
[02:28:36.281] iteration 20788 : loss : 0.051215, loss_ce: 0.022782
[02:28:36.582] iteration 20789 : loss : 0.138749, loss_ce: 0.005600
[02:28:36.886] iteration 20790 : loss : 0.041245, loss_ce: 0.012654
[02:28:37.193] iteration 20791 : loss : 0.093610, loss_ce: 0.006395
[02:28:37.495] iteration 20792 : loss : 0.047555, loss_ce: 0.020837
[02:28:37.798] iteration 20793 : loss : 0.037563, loss_ce: 0.012977
[02:28:38.103] iteration 20794 : loss : 0.047028, loss_ce: 0.009805
[02:28:38.402] iteration 20795 : loss : 0.055123, loss_ce: 0.023861
[02:28:38.706] iteration 20796 : loss : 0.057691, loss_ce: 0.014367
[02:28:39.007] iteration 20797 : loss : 0.070037, loss_ce: 0.016228
[02:28:39.310] iteration 20798 : loss : 0.049530, loss_ce: 0.008248
[02:28:39.612] iteration 20799 : loss : 0.049456, loss_ce: 0.013031
[02:28:39.915] iteration 20800 : loss : 0.041404, loss_ce: 0.014803
[02:28:40.238] iteration 20801 : loss : 0.063988, loss_ce: 0.019301
[02:28:40.541] iteration 20802 : loss : 0.049103, loss_ce: 0.015626
[02:28:40.843] iteration 20803 : loss : 0.038616, loss_ce: 0.008596
[02:28:41.147] iteration 20804 : loss : 0.040919, loss_ce: 0.013947
[02:28:41.447] iteration 20805 : loss : 0.051282, loss_ce: 0.016847
[02:28:41.749] iteration 20806 : loss : 0.048126, loss_ce: 0.011952
[02:28:42.051] iteration 20807 : loss : 0.041215, loss_ce: 0.019773
[02:28:42.353] iteration 20808 : loss : 0.075046, loss_ce: 0.019527
[02:28:42.659] iteration 20809 : loss : 0.108915, loss_ce: 0.011852
[02:28:42.962] iteration 20810 : loss : 0.056453, loss_ce: 0.008775
[02:28:43.265] iteration 20811 : loss : 0.043603, loss_ce: 0.016329
[02:28:43.566] iteration 20812 : loss : 0.042436, loss_ce: 0.018942
[02:28:43.870] iteration 20813 : loss : 0.152339, loss_ce: 0.010368
[02:28:44.171] iteration 20814 : loss : 0.042553, loss_ce: 0.012806
[02:28:44.473] iteration 20815 : loss : 0.048974, loss_ce: 0.015951
[02:28:44.778] iteration 20816 : loss : 0.040476, loss_ce: 0.008689
[02:28:45.081] iteration 20817 : loss : 0.044178, loss_ce: 0.013903
[02:28:45.383] iteration 20818 : loss : 0.096708, loss_ce: 0.008730
[02:28:45.686] iteration 20819 : loss : 0.037086, loss_ce: 0.008239
[02:28:45.991] iteration 20820 : loss : 0.092756, loss_ce: 0.008583
[02:28:46.308] iteration 20821 : loss : 0.042817, loss_ce: 0.016861
[02:28:46.610] iteration 20822 : loss : 0.039734, loss_ce: 0.008276
[02:28:46.915] iteration 20823 : loss : 0.090419, loss_ce: 0.012820
[02:28:47.216] iteration 20824 : loss : 0.037073, loss_ce: 0.011341
[02:28:47.522] iteration 20825 : loss : 0.039580, loss_ce: 0.011512
[02:28:47.829] iteration 20826 : loss : 0.040317, loss_ce: 0.011272
[02:28:48.140] iteration 20827 : loss : 0.101088, loss_ce: 0.016994
[02:28:48.451] iteration 20828 : loss : 0.113668, loss_ce: 0.006705
[02:28:48.759] iteration 20829 : loss : 0.050509, loss_ce: 0.010455
[02:28:49.071] iteration 20830 : loss : 0.040491, loss_ce: 0.010417
[02:28:49.375] iteration 20831 : loss : 0.106338, loss_ce: 0.006752
[02:28:49.678] iteration 20832 : loss : 0.048500, loss_ce: 0.012972
[02:28:49.979] iteration 20833 : loss : 0.036020, loss_ce: 0.011693
[02:28:50.287] iteration 20834 : loss : 0.045319, loss_ce: 0.017412
[02:28:50.597] iteration 20835 : loss : 0.047056, loss_ce: 0.013181
[02:28:50.908] iteration 20836 : loss : 0.040092, loss_ce: 0.010079
[02:28:51.210] iteration 20837 : loss : 0.052409, loss_ce: 0.016201
[02:28:51.518] iteration 20838 : loss : 0.051632, loss_ce: 0.013772
[02:28:51.831] iteration 20839 : loss : 0.039304, loss_ce: 0.016852
[02:28:52.142] iteration 20840 : loss : 0.067067, loss_ce: 0.011441
[02:28:52.469] iteration 20841 : loss : 0.052147, loss_ce: 0.014160
[02:28:52.774] iteration 20842 : loss : 0.038517, loss_ce: 0.008212
[02:28:53.086] iteration 20843 : loss : 0.044800, loss_ce: 0.021100
[02:28:53.401] iteration 20844 : loss : 0.040287, loss_ce: 0.011179
[02:28:53.708] iteration 20845 : loss : 0.046229, loss_ce: 0.007539
[02:28:54.021] iteration 20846 : loss : 0.051925, loss_ce: 0.015143
[02:28:54.332] iteration 20847 : loss : 0.108883, loss_ce: 0.008098
[02:28:54.641] iteration 20848 : loss : 0.046077, loss_ce: 0.016573
[02:28:54.947] iteration 20849 : loss : 0.046144, loss_ce: 0.016933
[02:28:55.032] iteration 20850 : loss : 0.169894, loss_ce: 0.014192
[02:28:55.598] save model to ./logs/swin_unet\epoch_149.pth
